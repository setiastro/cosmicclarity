#!/usr/bin/env python3
# Standard library imports
import pickle
import os
import tempfile
import sys
import time
import json
import logging
import math
from datetime import datetime
from decimal import getcontext
from urllib.parse import quote
import webbrowser
import warnings
import shutil
import subprocess
from xisf import XISF
import requests
import csv
import lz4.block
import zstandard
import base64
import ast
import platform
import glob
import time
from datetime import datetime
import pywt
from io import BytesIO
import re
from scipy.spatial import Delaunay, KDTree
import random
if sys.stdout is not None:
    sys.stdout.reconfigure(encoding='utf-8')

from astropy.stats import sigma_clipped_stats
from photutils.detection import DAOStarFinder
from scipy.spatial import ConvexHull
from astropy.table import Table, vstack
from numba import njit, prange
from numba_utils import *

from astropy.wcs.utils import skycoord_to_pixel
from astropy.coordinates import SkyCoord
from astropy import units as u
import itertools
from astropy.io.fits import Header

# Reproject for WCS-based alignment
try:
    from reproject import reproject_interp
except ImportError:
    reproject_interp = None  # fallback if not installed

# OpenCV for transform estimation & warping
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False


# Third-party library imports
import requests
import numpy as np
import pandas as pd
import cv2
from PIL import Image, ImageDraw, ImageFont

# Astropy and Astroquery imports
from astropy.io import fits
from astropy.time import Time
from astropy.coordinates import SkyCoord, EarthLocation, AltAz, get_body, get_sun
import astropy.units as u
from astropy.wcs import WCS
from astroquery.simbad import Simbad
from astroquery.mast import Mast
from astroquery.vizier import Vizier
import tifffile as tiff
import pytz
from astropy.utils.data import conf

from scipy.interpolate import PchipInterpolator
from scipy.interpolate import Rbf
from scipy.ndimage import median_filter
from scipy.ndimage import convolve
import exifread


import rawpy


# PyQt5 imports
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton, 
    QFileDialog, QGraphicsView, QGraphicsScene, QMessageBox, QInputDialog, QTreeWidget, 
    QTreeWidgetItem, QCheckBox, QDialog, QFormLayout, QSpinBox, QDialogButtonBox, QGridLayout,
    QGraphicsEllipseItem, QGraphicsLineItem, QGraphicsRectItem, QGraphicsPathItem, QDoubleSpinBox, QPlainTextEdit,
    QColorDialog, QFontDialog, QStyle, QSlider, QTabWidget, QScrollArea, QSizePolicy, QSpacerItem, QAbstractItemView, QToolBar,QGraphicsPixmapItem,QRubberBand,QVBoxLayout,QGroupBox,
    QGraphicsTextItem, QComboBox, QLineEdit, QRadioButton, QButtonGroup, QHeaderView, QStackedWidget, QSplitter, QMenu, QAction, QMenuBar, QTextEdit, QProgressBar, QGraphicsItem, QToolButton, QStatusBar,QShortcut, QTableWidget,
    QTableWidgetItem,    QTableWidget, QProgressDialog,
    QTableWidgetItem,
    QListWidget,
    QListWidgetItem
)
from PyQt5.QtGui import (
    QPixmap, QImage, QPainter, QPen, QColor, QTransform, QIcon, QPainterPath, QFont, QMovie, QCursor, QBrush, QPolygon, QPolygonF, QKeySequence, QPalette, QWheelEvent, QDoubleValidator,QIntValidator)
from PyQt5.QtCore import Qt, QRectF, QLineF, QPointF, QThread, pyqtSignal, QCoreApplication, QPoint, QTimer, QRect, QFileSystemWatcher, QEvent, pyqtSlot, QProcess, QSize, QObject,QSettings, QRunnable, QThreadPool


# Math functions
from math import sqrt
import math
from copy import deepcopy


VERSION = "2.11.8"


if hasattr(sys, '_MEIPASS'):
    # PyInstaller path
    icon_path = os.path.join(sys._MEIPASS, 'astrosuite.png')
    windowslogo_path = os.path.join(sys._MEIPASS, 'astrosuite.ico')
    green_path = os.path.join(sys._MEIPASS, 'green.png')
    neutral_path = os.path.join(sys._MEIPASS, 'neutral.png')
    whitebalance_path = os.path.join(sys._MEIPASS, 'whitebalance.png')
    morpho_path = os.path.join(sys._MEIPASS, 'morpho.png')
    clahe_path = os.path.join(sys._MEIPASS, 'clahe.png')
    starnet_path = os.path.join(sys._MEIPASS, 'starnet.png')
    staradd_path = os.path.join(sys._MEIPASS, 'staradd.png')
    LExtract_path = os.path.join(sys._MEIPASS, 'LExtract.png')
    LInsert_path = os.path.join(sys._MEIPASS, 'LInsert.png')
    slot0_path = os.path.join(sys._MEIPASS, 'slot0.png')
    slot1_path = os.path.join(sys._MEIPASS, 'slot1.png')
    slot2_path = os.path.join(sys._MEIPASS, 'slot2.png')
    slot3_path = os.path.join(sys._MEIPASS, 'slot3.png')
    slot4_path = os.path.join(sys._MEIPASS, 'slot4.png')
    rgbcombo_path = os.path.join(sys._MEIPASS, 'rgbcombo.png')
    rgbextract_path = os.path.join(sys._MEIPASS, 'rgbextract.png')
    copyslot_path = os.path.join(sys._MEIPASS, 'copyslot.png')
    graxperticon_path = os.path.join(sys._MEIPASS, 'graxpert.png')
    cropicon_path = os.path.join(sys._MEIPASS, 'cropicon.png')
    openfile_path = os.path.join(sys._MEIPASS, 'openfile.png')
    abeicon_path = os.path.join(sys._MEIPASS, 'abeicon.png')    
    undoicon_path = os.path.join(sys._MEIPASS, 'undoicon.png')  
    redoicon_path = os.path.join(sys._MEIPASS, 'redoicon.png')  
    blastericon_path = os.path.join(sys._MEIPASS, 'blaster.png')
    hdr_path = os.path.join(sys._MEIPASS, 'hdr.png')  
    invert_path = os.path.join(sys._MEIPASS, 'invert.png')  
    fliphorizontal_path = os.path.join(sys._MEIPASS, 'fliphorizontal.png')
    flipvertical_path = os.path.join(sys._MEIPASS, 'flipvertical.png')
    rotateclockwise_path = os.path.join(sys._MEIPASS, 'rotateclockwise.png')
    rotatecounterclockwise_path = os.path.join(sys._MEIPASS, 'rotatecounterclockwise.png')
    maskcreate_path = os.path.join(sys._MEIPASS, 'maskcreate.png')
    maskapply_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    maskremove_path = os.path.join(sys._MEIPASS, 'maskremove.png')
    slot5_path = os.path.join(sys._MEIPASS, 'slot5.png')
    slot6_path = os.path.join(sys._MEIPASS, 'slot6.png')
    slot7_path = os.path.join(sys._MEIPASS, 'slot7.png')
    slot8_path = os.path.join(sys._MEIPASS, 'slot8.png')
    slot9_path = os.path.join(sys._MEIPASS, 'slot9.png') 
    pixelmath_path = os.path.join(sys._MEIPASS, 'pixelmath.png')   
    histogram_path = os.path.join(sys._MEIPASS, 'histogram.png') 
    mosaic_path = os.path.join(sys._MEIPASS, 'mosaic.png')
    rescale_path = os.path.join(sys._MEIPASS, 'rescale.png')
    staralign_path = os.path.join(sys._MEIPASS, 'staralign.png')
    mask_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    platesolve_path = os.path.join(sys._MEIPASS, 'platesolve.png')
    psf_path = os.path.join(sys._MEIPASS, 'psf.png')
    supernova_path = os.path.join(sys._MEIPASS, 'supernova.png')
    starregistration_path = os.path.join(sys._MEIPASS, 'starregistration.png')
    stacking_path = os.path.join(sys._MEIPASS, 'stacking.png')
else:
    # Development path
    icon_path = 'astrosuite.png'
    windowslogo_path = 'astrosuite.ico'
    green_path = 'green.png'
    neutral_path = 'neutral.png'
    whitebalance_path = 'whitebalance.png'
    morpho_path = 'morpho.png'
    clahe_path = 'clahe.png'
    starnet_path = 'starnet.png'
    staradd_path = 'staradd.png'
    LExtract_path = 'LExtract.png'
    LInsert_path = 'LInsert.png'
    slot1_path = 'slot1.png'
    slot0_path = 'slot0.png'
    slot2_path = 'slot2.png'
    slot3_path  = 'slot3.png'
    slot4_path  = 'slot4.png'
    rgbcombo_path = 'rgbcombo.png'
    rgbextract_path = 'rgbextract.png'
    copyslot_path = 'copyslot.png'
    graxperticon_path = 'graxpert.png'
    cropicon_path = 'cropicon.png'
    openfile_path = 'openfile.png'
    abeicon_path = 'abeicon.png'
    undoicon_path = 'undoicon.png'
    redoicon_path = 'redoicon.png'
    blastericon_path = 'blaster.png'
    hdr_path = 'hdr.png'
    invert_path = 'invert.png'
    fliphorizontal_path = 'fliphorizontal.png'
    flipvertical_path = 'flipvertical.png'
    rotateclockwise_path = 'rotateclockwise.png'
    rotatecounterclockwise_path = 'rotatecounterclockwise.png'
    maskcreate_path = 'maskcreate.png'
    maskapply_path = 'maskapply.png'
    maskremove_path = 'maskremove.png'
    slot5_path = 'slot5.png'
    slot6_path = 'slot6.png'
    slot7_path = 'slot7.png'
    slot8_path  = 'slot8.png'
    slot9_path  = 'slot9.png'
    pixelmath_path = 'pixelmath.png'
    histogram_path = 'histogram.png'
    mosaic_path = 'mosaic.png'
    rescale_path = 'rescale.png'
    staralign_path = 'staralign.png'
    mask_path = 'maskapply.png'
    platesolve_path = 'platesolve.png'
    psf_path = 'psf.png'
    supernova_path = 'supernova.png'
    starregistration_path = 'starregistration.png'
    stacking_path = 'stacking.png'

class AstroEditingSuite(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowIcon(QIcon(icon_path))
        self.setDockNestingEnabled(True)
        self.current_theme = "dark"  # Default theme
        self.image_manager = ImageManager(max_slots=10)  # Initialize ImageManager
        self.mask_manager = self.image_manager.mask_manager
        self.image_manager.image_changed.connect(self.update_file_name)
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")  # Replace "Seti Astro" with your actual organization name
        self.starnet_exe_path = self.settings.value("starnet/exe_path", type=str)  # Load saved path if available
        self.preview_windows = {}

        # NEW: Dictionary to store custom slot names (default names)
        self.slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
        self.slot_actions = {}

        # NEW: Dictionary to store custom mask slot names (default names)
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}
        self.mask_slot_actions = {}

        # Initialize the mask banner
        self.mask_banner = QLabel()  # Initialize QLabel
        self.mask_banner.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.mask_banner.setText("Mask Applied: None")  # Default text
        self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
        self.mask_banner.setVisible(False)  # Hidden by default        

        # Initialize UI
        self.initUI()
        self.connect_mask_manager_signals()        

    def initUI(self):
        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Enable drag and drop
        self.setAcceptDrops(True)

        # Create a menu bar
        menubar = self.menuBar()  # Use the menu bar directly from QMainWindow

        # --------------------
        # File Menu
        # --------------------
        file_menu = menubar.addMenu("File")
        
        # Create File Menu Actions
        open_action = QAction("Open Image", self)
        open_action.setShortcut('Ctrl+O')
        open_action.setStatusTip('Open an image file')
        open_action.triggered.connect(self.open_image)
        
        save_action = QAction("Save As", self)
        save_action.setShortcut('Ctrl+S')
        save_action.setStatusTip('Save the image to disk')
        save_action.triggered.connect(self.save_image)
        
        undo_action = QAction("Undo", self)
        undo_action.setShortcut('Ctrl+Z')
        undo_action.setStatusTip('Undo the last action')
        undo_action.triggered.connect(self.undo_image)
        
        redo_action = QAction("Redo", self)
        redo_action.setShortcut('Ctrl+Y')
        redo_action.setStatusTip('Redo the last undone action')
        redo_action.triggered.connect(self.redo_image)
        
        exit_action = QAction("Exit", self)
        exit_action.setShortcut('Ctrl+Q')  # Common shortcut for Exit
        exit_action.setStatusTip('Exit the application')
        exit_action.triggered.connect(self.close)  # Close the application

        # --- New Project Actions ---
        save_project_action = QAction("Save Project", self)
        save_project_action.setStatusTip("Save the entire project (images, metadata, masks, etc.)")
        save_project_action.triggered.connect(self.save_project)
        
        open_project_action = QAction("Open Project", self)
        open_project_action.setStatusTip("Open a saved project")
        open_project_action.triggered.connect(self.open_project)   

        new_project_action = QAction("New Project", self)
        new_project_action.setStatusTip("Clear the current project and start a new project (this will erase all data)")
        new_project_action.triggered.connect(self.new_project)     

        # Add actions to the File menu
        file_menu.addAction(open_action)
        file_menu.addAction(save_action)
        file_menu.addSeparator()
        file_menu.addAction(undo_action)
        file_menu.addAction(redo_action)
        file_menu.addSeparator()
        file_menu.addAction(save_project_action)   # New action
        file_menu.addAction(open_project_action)   # New action
        file_menu.addAction(new_project_action) 
        file_menu.addSeparator()
        file_menu.addAction(exit_action)

        # --------------------
        # Themes Menu
        # --------------------
        theme_menu = menubar.addMenu("Themes")
        light_theme_action = QAction("Light Theme", self)
        dark_theme_action = QAction("Dark Theme", self)

        light_theme_action.triggered.connect(lambda: self.apply_theme("light"))
        dark_theme_action.triggered.connect(lambda: self.apply_theme("dark"))

        theme_menu.addAction(light_theme_action)
        theme_menu.addAction(dark_theme_action)

        # --------------------
        # Functions Menu
        # --------------------
        functions_menu = menubar.addMenu("Functions")

        # Add Histogram Action
        histogram_action = QAction(QIcon(histogram_path), "Histogram", self)
        histogram_action.setStatusTip("Show histogram of Slot 0")
        histogram_action.triggered.connect(self.open_histogram)
        functions_menu.addAction(histogram_action)

        gradient_removal_icon = QIcon(abeicon_path)  # Replace with the actual path variable
        gradient_removal_action = QAction(gradient_removal_icon, "Remove Gradient with SetiAstro ABE", self)
        gradient_removal_action.setShortcut('Ctrl+Shift+G')  # Assign a keyboard shortcut
        gradient_removal_action.setStatusTip('Remove gradient from the current image')
        gradient_removal_action.triggered.connect(self.remove_gradient)

        # Add the new action to the Functions menu
        functions_menu.addAction(gradient_removal_action)

        remove_gradient_action = QAction(QIcon(graxperticon_path), "Remove Gradient with GraXpert", self)
        remove_gradient_action.triggered.connect(self.remove_gradient_with_graxpert)
        functions_menu.addAction(remove_gradient_action)        
        
        # Add Crop to Functions menu
        crop_action = QAction(QIcon(cropicon_path), "Crop Image", self)
        crop_action.setShortcut('Ctrl+K')
        crop_action.setStatusTip('Crop the current image')
        crop_action.triggered.connect(self.open_crop_tool)
        functions_menu.addAction(crop_action)

        # Create Remove Green QAction
        remove_green_action = QAction("Remove Green", self)
        remove_green_action.setShortcut('Ctrl+G')  # Assign a keyboard shortcut
        remove_green_action.setStatusTip('Remove green noise from the image')
        remove_green_action.triggered.connect(self.open_remove_green_dialog)
        
        # Add Remove Green to Functions menu
        functions_menu.addAction(remove_green_action)

        background_neutralization_action = QAction("Background Neutralization", self)
        background_neutralization_action.setShortcut('Ctrl+N')  # Assign a keyboard shortcut
        background_neutralization_action.setStatusTip('Neutralize background colors based on a sample region')
        background_neutralization_action.triggered.connect(self.open_background_neutralization_dialog)
        
        # Add to Functions menu
        functions_menu.addAction(background_neutralization_action)        

        # White Balance Action
        whitebalance_action = QAction("White Balance", self)
        whitebalance_action.setShortcut('Ctrl+Shift+W')  # Assign a keyboard shortcut
        whitebalance_action.setStatusTip('Adjust white balance of the image')
        whitebalance_action.triggered.connect(self.open_whitebalance_dialog)
        
        # Add White Balance to Functions menu
        functions_menu.addAction(whitebalance_action)   

        # Extract Luminance Action with Icon
        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.setShortcut('Ctrl+Shift+E')  # Assign a keyboard shortcut
        extract_luminance_action.setStatusTip('Extract luminance from the current image')
        extract_luminance_action.triggered.connect(self.extract_luminance)

        # Add Extract Luminance to Functions menu
        functions_menu.addAction(extract_luminance_action)

        # Recombine Luminance Action with Icon
        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.setShortcut('Ctrl+Shift+R')  # Assign a keyboard shortcut
        recombine_luminance_action.setStatusTip('Recombine luminance into the RGB image in slot 1')
        recombine_luminance_action.triggered.connect(self.recombine_luminance)

        # Add Recombine Luminance to Functions menu
        functions_menu.addAction(recombine_luminance_action)

        # RGB Combination Action
        rgb_combination_icon = QIcon(rgbcombo_path)
        rgb_combination_action = QAction(rgb_combination_icon, "RGB Combination", self)
        rgb_combination_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        rgb_combination_action.setStatusTip('Combine separate R, G, B images into an RGB image')
        rgb_combination_action.triggered.connect(self.rgb_combination)
        # Add RGB Combination to Functions menu
        functions_menu.addAction(rgb_combination_action)
        
        # RGB Extract Action
        rgb_extract_icon = QIcon(rgbextract_path)
        rgb_extract_action = QAction(rgb_extract_icon, "RGB Extract", self)
        rgb_extract_action.setShortcut('Ctrl+Shift+X')  # Assign a keyboard shortcut
        rgb_extract_action.setStatusTip('Extract R, G, B channels from an RGB image')
        rgb_extract_action.triggered.connect(self.rgb_extract)
        # Add RGB Extract to Functions menu
        functions_menu.addAction(rgb_extract_action)

        blemish_blaster_icon = QIcon(blastericon_path)  # Ensure 'blastericon_path' is correctly defined
        blemish_blaster_action = QAction(blemish_blaster_icon, "Blemish Blaster", self)
        blemish_blaster_action.setShortcut('Ctrl+B')  # Assign a keyboard shortcut (e.g., Ctrl+B)
        blemish_blaster_action.setStatusTip('Remove blemishes from the current image')
        blemish_blaster_action.triggered.connect(self.open_blemish_blaster)  # Connect to handler method

        # Add the Blemish Blaster action to the Functions menu
        functions_menu.addAction(blemish_blaster_action)

        hdr_icon = QIcon(hdr_path)
        hdr_action = QAction(hdr_icon, "WaveScale HDR", self)
        hdr_action.setShortcut('Ctrl+H')
        hdr_action.setStatusTip('Apply WaveScale HDR to the current image')
        hdr_action.triggered.connect(self.open_hdr_dialog)
        functions_menu.addAction(hdr_action)

        clahe_action = QAction("CLAHE", self)
        clahe_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        clahe_action.setStatusTip('Apply Contrast Limited Adaptive Histogram Equalization')
        clahe_action.triggered.connect(self.open_clahe_dialog)
        
        # Add CLAHE to Functions menu
        functions_menu.addAction(clahe_action)


        # Morphological Operations Action
        morpho_action = QAction("Morphological Operations", self)
        morpho_action.setShortcut('Ctrl+Shift+M')  # Assign a keyboard shortcut
        morpho_action.setStatusTip('Apply morphological operations to the image')
        morpho_action.triggered.connect(self.open_morpho_dialog)
        
        # Add Morphological Operations to Functions menu
        functions_menu.addAction(morpho_action)        

        remove_stars_action = QAction("Remove Stars", self)
        remove_stars_action.setShortcut('Ctrl+R')  # Assign a keyboard shortcut
        remove_stars_action.setStatusTip('Remove stars from the image using StarNet')
        remove_stars_action.triggered.connect(self.remove_stars)

        # Add Remove Stars to Functions menu
        functions_menu.addAction(remove_stars_action)

        add_stars_action = QAction("Add Stars", self)
        add_stars_action.setShortcut('Ctrl+A')  # Assign a keyboard shortcut
        add_stars_action.setStatusTip('Add stars back to the current image')
        add_stars_action.triggered.connect(self.add_stars)

        # Add Add Stars to Functions menu
        functions_menu.addAction(add_stars_action)   

        # Pixel Math Action
        pixel_math_action = QAction(QIcon(pixelmath_path), "Pixel Math", self)
        pixel_math_action.setStatusTip("Perform pixel math operations on the current image")
        pixel_math_action.triggered.connect(self.open_pixel_math_dialog)
        functions_menu.addAction(pixel_math_action)             

        # --------------------
        # Geometry Menu
        # --------------------
        geometry_menu = menubar.addMenu("Geometry")

        invert_icon = QIcon(invert_path)  # Ensure 'invert_path' is correctly defined
        invert_action = QAction(invert_icon, "Invert Image", self)
        invert_action.setShortcut("Ctrl+I")
        invert_action.setStatusTip("Invert the colors of the current image")
        invert_action.triggered.connect(self.invert_image)

        # Add the Invert action to the Functions menu
        geometry_menu.addAction(invert_action)


        # Flip Horizontal Action
        flip_horizontal_icon = QIcon(fliphorizontal_path)
        flip_horizontal_action = QAction(flip_horizontal_icon, "Flip Horizontal", self)
        flip_horizontal_action.setShortcut("Ctrl+Shift+H")
        flip_horizontal_action.setStatusTip("Flip the current image horizontally")
        flip_horizontal_action.triggered.connect(self.flip_horizontal)

        # Add to Functions menu
        geometry_menu.addAction(flip_horizontal_action)



        # Flip Vertical Action
        flip_vertical_icon = QIcon(flipvertical_path)
        flip_vertical_action = QAction(flip_vertical_icon, "Flip Vertical", self)
        flip_vertical_action.setShortcut("Ctrl+Shift+V")
        flip_vertical_action.setStatusTip("Flip the current image vertically")
        flip_vertical_action.triggered.connect(self.flip_vertical)

        # Add to Functions menu
        geometry_menu.addAction(flip_vertical_action)



        # Rotate Clockwise Action
        rotate_clockwise_icon = QIcon(rotateclockwise_path)
        rotate_clockwise_action = QAction(rotate_clockwise_icon, "Rotate Clockwise", self)
        rotate_clockwise_action.setShortcut("Ctrl+Shift+R")
        rotate_clockwise_action.setStatusTip("Rotate the current image 90° clockwise")
        rotate_clockwise_action.triggered.connect(self.rotate_clockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_clockwise_action)


        # Rotate Counterclockwise Action
        rotate_counterclockwise_icon = QIcon(rotatecounterclockwise_path)
        rotate_counterclockwise_action = QAction(rotate_counterclockwise_icon, "Rotate Counterclockwise", self)
        rotate_counterclockwise_action.setShortcut("Ctrl+Shift+L")
        rotate_counterclockwise_action.setStatusTip("Rotate the current image 90° counterclockwise")
        rotate_counterclockwise_action.triggered.connect(self.rotate_counterclockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_counterclockwise_action)

        #rescale
        rescale_action = QAction("Rescale", self)
        rescale_action.setIcon(QIcon(rescale_path))
        rescale_action.setStatusTip("Rescale the current image by a custom factor")
        rescale_action.triggered.connect(self.rescale_image)
        geometry_menu.addAction(rescale_action)

        # --------------------
        # Slot Menu
        # --------------------
        slot_menu = menubar.addMenu("Slots")

        # Dictionary to store menubar slot actions
        self.menubar_slot_actions = {}

        num_slots = self.image_manager.max_slots

        for slot in range(num_slots):
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            slot_icon = QIcon(slot_icon_path)
            
            slot_name = self.slot_names.get(slot, f"Slot {slot}")

            # Create QAction for the menubar slot
            slot_action = QAction(slot_icon, slot_name, self)
            slot_action.setStatusTip(f"Open preview for {slot_name}")
            slot_action.triggered.connect(lambda checked, s=slot: self.open_preview_window(s))
            
            # Store menubar slot actions for later updates
            self.menubar_slot_actions[slot] = slot_action

            # Add to menu
            slot_menu.addAction(slot_action)

        # Separator & Rename Slot Action
        slot_menu.addSeparator()
        rename_slot_action = QAction("Rename Slot", self)
        rename_slot_action.setStatusTip("Rename a slot with a custom name")
        rename_slot_action.triggered.connect(self.rename_slot)
        slot_menu.addAction(rename_slot_action)


        # --------------------
        # Mask Menu
        # --------------------
        masks_menu = menubar.addMenu("&Masks")

        maskcreate_path = resource_path('maskcreate.png')
        maskapply_path = resource_path('maskapply.png')
        maskremove_path = resource_path('maskremove.png')

        maskcreate_icon = QIcon(maskcreate_path)
        maskapply_icon = QIcon(maskapply_path)
        maskremove_icon = QIcon(maskremove_path)

        # Create Mask Actions
        create_mask_action = QAction(maskcreate_icon, "Create Mask", self)
        create_mask_action.setStatusTip("Create a new mask for the current image")
        create_mask_action.triggered.connect(self.create_mask)

        apply_mask_action = QAction(maskapply_icon, "Apply Mask", self)
        apply_mask_action.setStatusTip("Apply the selected mask to the image")
        apply_mask_action.triggered.connect(self.apply_mask)

        remove_mask_action = QAction(maskremove_icon, "Remove Mask", self)
        remove_mask_action.setStatusTip("Remove the currently applied mask")
        remove_mask_action.triggered.connect(self.remove_mask)

        # Add Mask Actions to Masks Menu
        masks_menu.addAction(create_mask_action)
        masks_menu.addAction(apply_mask_action)
        masks_menu.addAction(remove_mask_action)

        # Add Load Mask action
        load_mask_action = QAction("Load Mask", self)
        load_mask_action.triggered.connect(self.load_mask)
        masks_menu.addAction(load_mask_action)

        # Add Save Mask action
        save_mask_action = QAction("Save Mask", self)
        save_mask_action.triggered.connect(self.save_mask)
        masks_menu.addAction(save_mask_action)

        # Mask Slots Submenu
        mask_slots_menu = masks_menu.addMenu("Mask Slots")


        for slot in range(5):  # Five mask slots (0-4)
            # Use the custom name from the dictionary
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            slot_action = QAction(mask_slot_name, self)
            slot_action.triggered.connect(lambda checked, s=slot: self.preview_mask_slot(s))
            mask_slots_menu.addAction(slot_action)
            self.mask_slot_actions[slot] = slot_action

        # Add a separator and a "Rename Mask Slot" action
        mask_slots_menu.addSeparator()
        rename_mask_slot_action = QAction("Rename Mask Slot", self)
        rename_mask_slot_action.setStatusTip("Rename a mask slot with a custom name")
        rename_mask_slot_action.triggered.connect(self.rename_mask_slot)
        mask_slots_menu.addAction(rename_mask_slot_action)

        # --------------------
        # Star Stuff Menu
        # --------------------
        mosaic_menu = menubar.addMenu("Star Stuff")

        # Stacking Suite Action (New!)
        stacking_suite_action = QAction(QIcon(stacking_path), "Stacking Suite", self)
        stacking_suite_action.setStatusTip("Calibrate and stack images with advanced methods")
        stacking_suite_action.triggered.connect(self.stacking_suite_action)
        mosaic_menu.addAction(stacking_suite_action)

        mosaic_master_action = QAction(QIcon(mosaic_path), "Mosaic Master", self)
        mosaic_master_action.setStatusTip("Create a mosaic from multiple images.")
        mosaic_master_action.triggered.connect(self.open_mosaic_master)

        mosaic_menu.addAction(mosaic_master_action)

        # Stellar Alignment Action (added to Mosaic menu and toolbar)
        stellar_align_action = QAction(QIcon(staralign_path), "Stellar Alignment", self)
        stellar_align_action.setStatusTip("Align the target image to the source image using star alignment")
        stellar_align_action.triggered.connect(self.stellar_alignment)
        mosaic_menu.addAction(stellar_align_action)

        star_registration_action = QAction(QIcon(starregistration_path), "Star Registration", self)
        star_registration_action.setStatusTip("Register multiple images based on star alignment")
        star_registration_action.triggered.connect(self.star_registration)
        mosaic_menu.addAction(star_registration_action)        

        plate_solver_action = QAction(QIcon(platesolve_path), "Plate Solver", self)
        plate_solver_action.setStatusTip("Perform plate solving on an image")
        plate_solver_action.triggered.connect(self.launch_plate_solver)
        mosaic_menu.addAction(plate_solver_action)      

        # PSF Viewer Action (New!)
        psf_viewer_action = QAction(QIcon(psf_path), "PSF Viewer", self)
        psf_viewer_action.setStatusTip("View PSF histograms and star statistics")
        psf_viewer_action.triggered.connect(self.psf_viewer)
        mosaic_menu.addAction(psf_viewer_action)        

        # Supernova Action (New!)
        supernova_action = QAction(QIcon(supernova_path), "SuperNova Asteroid Hunter", self)
        supernova_action.setStatusTip("Hunt for anomalies in your images")
        supernova_action.triggered.connect(self.open_supernova_hunter)
        mosaic_menu.addAction(supernova_action)    

        # --------------------
        # Toolbar
        # --------------------
        filebar = QToolBar("File Toolbar")
        filebar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(filebar)

        # Add Open File icon and action
        open_icon = QIcon(openfile_path)  # Replace with the actual path to your "Open File" icon
        open_action = QAction(open_icon, "Open File", self)
        open_action.setStatusTip("Open an image file")
        open_action.triggered.connect(self.open_image)  # Connect to the existing open_image method
        filebar.addAction(open_action)

        # Add Save As disk icon and action
        save_as_icon = QIcon(disk_icon_path)  # Replace with the actual path to your "Save As" icon
        save_as_action = QAction(save_as_icon, "Save As", self)
        save_as_action.setStatusTip("Save the current image")
        save_as_action.triggered.connect(self.save_image)  # Connect to the existing save_image method
        filebar.addAction(save_as_action)

        # Add Undo icon and action
        undo_icon = QIcon(undoicon_path)  # Replace with the actual path to your Undo icon
        undo_action_toolbar = QAction(undo_icon, "Undo", self)
        undo_action_toolbar.setStatusTip("Undo the last action")
        undo_action_toolbar.triggered.connect(self.undo_image)
        filebar.addAction(undo_action_toolbar)

        # Add Redo icon and action
        redo_icon = QIcon(redoicon_path)  # Replace with the actual path to your Redo icon
        redo_action_toolbar = QAction(redo_icon, "Redo", self)
        redo_action_toolbar.setStatusTip("Redo the last undone action")
        redo_action_toolbar.triggered.connect(self.redo_image)
        filebar.addAction(redo_action_toolbar)


        toolbar = QToolBar("Main Toolbar")
        toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(toolbar)

        # Add "Copy Slot" Button to Toolbar with Icon
        copy_slot_icon = QIcon(copyslot_path)  # Ensure 'copyslot.png' is the correct path
        copy_slot_action = QAction(copy_slot_icon, "Copy Slot", self)
        copy_slot_action.setStatusTip("Copy the current image in Slot 0 to another slot")
        copy_slot_action.triggered.connect(self.copy_slot_to_target)
        toolbar.addAction(copy_slot_action)

        toolbar.addAction(histogram_action)

        crop_icon = QIcon(cropicon_path)
        crop_action.setIcon(crop_icon)
        toolbar.addAction(crop_action)

        toolbar.addAction(gradient_removal_action)

        remove_gradient_icon = QIcon(graxperticon_path)
        remove_gradient_action.setIcon(remove_gradient_icon)
        remove_gradient_action.setStatusTip("Remove Gradient with GraXpert AI")
        toolbar.addAction(remove_gradient_action)

        # Add Remove Stars Button to Toolbar with Icon
        remove_stars_icon = QIcon(starnet_path)
        remove_stars_action.setIcon(remove_stars_icon)  # Set the icon to the QAction
        remove_stars_action.setToolTip("Remove Stars using StarNet")
        toolbar.addAction(remove_stars_action)  # Add the same QAction to the toolbar

        # Add Add Stars Button to Toolbar with Icon
        add_stars_icon = QIcon(staradd_path)
        add_stars_action.setIcon(add_stars_icon)  # Set the icon to the QAction
        add_stars_action.setToolTip("Add Stars back to the image")
        toolbar.addAction(add_stars_action)  # Add the same QAction to the toolbar


        # Add "Remove Green" Button to Toolbar with Icon
        remove_green_icon = QIcon(green_path)
        remove_green_action.setIcon(remove_green_icon)  # Set the icon to the QAction
        toolbar.addAction(remove_green_action)  # Add the same QAction to the toolbar

        # Add "Background Neutralization" Button to Toolbar with Icon
        background_neutralization_icon = QIcon(neutral_path)
        background_neutralization_action.setIcon(background_neutralization_icon)  # Set the icon
        background_neutralization_action.setToolTip("Neutralize background colors based on a sample region.")
        toolbar.addAction(background_neutralization_action)  # Add the QAction to the toolbar

        # Add White Balance Button to Toolbar with Icon
        whitebalance_icon = QIcon(whitebalance_path)
        whitebalance_action.setIcon(whitebalance_icon)
        whitebalance_action.setToolTip("Adjust white balance of the image.")
        toolbar.addAction(whitebalance_action)

        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.triggered.connect(self.extract_luminance)
        toolbar.addAction(extract_luminance_action)

        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.triggered.connect(self.recombine_luminance)
        toolbar.addAction(recombine_luminance_action)

        # Add RGB Combination Button to Toolbar
        toolbar.addAction(rgb_combination_action)

        # Add RGB Extract Button to Toolbar
        toolbar.addAction(rgb_extract_action)

        toolbar.addAction(blemish_blaster_action)

        toolbar.addAction(hdr_action)

        # Add CLAHE Button to Toolbar with Icon
        clahe_icon = QIcon(clahe_path)
        clahe_action.setIcon(clahe_icon)
        clahe_action.setToolTip("Apply Contrast Limited Adaptive Histogram Equalization.")
        toolbar.addAction(clahe_action)      

        # Add Morphological Operations Button to Toolbar with Icon
        morpho_icon = QIcon(morpho_path)
        morpho_action.setIcon(morpho_icon)
        morpho_action.setToolTip("Apply morphological operations to the image.")
        toolbar.addAction(morpho_action)    

        toolbar.addAction(pixel_math_action)

        geometrybar = QToolBar("Geometry Toolbar")

        geometrybar.addAction(invert_action)
        self.addToolBar(geometrybar)

        geometrybar.addAction(flip_horizontal_action)
        geometrybar.addAction(flip_vertical_action)        
        geometrybar.addAction(rotate_clockwise_action)
        geometrybar.addAction(rotate_counterclockwise_action)    
        geometrybar.addAction(rescale_action)

        # --------------------
        # Star Stuff Toolbar
        # --------------------        
        mosaictoolbar = QToolBar("Star Stuff Toolbar")
        mosaictoolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mosaictoolbar)  
        mosaictoolbar.addAction(stacking_suite_action)      
        mosaictoolbar.addAction(mosaic_master_action)    
        mosaictoolbar.addAction(stellar_align_action)
        mosaictoolbar.addAction(star_registration_action)
        mosaictoolbar.addAction(plate_solver_action)
        mosaictoolbar.addAction(psf_viewer_action)     
        mosaictoolbar.addAction(supernova_action)   
        
        # --------------------
        # Mask Toolbar
        # --------------------
        mask_toolbar = QToolBar("Mask Toolbar")
        mask_toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mask_toolbar)

        # Add Mask Actions to Mask Toolbar
        mask_toolbar.addAction(create_mask_action)
        mask_toolbar.addAction(apply_mask_action)
        mask_toolbar.addAction(remove_mask_action)
        
        # Create a toolbar for slots and dock it on the left side.
        self.slot_toolbar = QToolBar("Slot Toolbar", self)
        self.slot_toolbar.setAllowedAreas(Qt.ToolBarArea.LeftToolBarArea)
        self.slot_toolbar.setOrientation(Qt.Orientation.Vertical)  # Vertical layout
        self.addToolBar(Qt.ToolBarArea.LeftToolBarArea, self.slot_toolbar)

        # Create a button for each slot
        for slot in range(self.image_manager.max_slots):
            # Create a QToolButton for this slot.
            button = QToolButton()
            
            # Retrieve the icon path using getattr. This will look for an attribute
            # like 'slot0_path', 'slot1_path', etc., in your module, defaulting to 'slot0.png'
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            
            # Set the icon and optionally an icon size
            button.setIcon(QIcon(slot_icon_path))
            button.setIconSize(QSize(32, 32))  # Adjust the size as needed
            
            # Set the slot text and style (text below the icon)
            button.setText(self.slot_names[slot])
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Connect the normal (left-click) signal.
            button.clicked.connect(lambda checked, s=slot: self.set_active_slot(s))
            
            # Enable the custom context menu.
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_slot_context_menu(pos, s))
            
            # Add the button to the toolbar and store a reference.
            self.slot_toolbar.addWidget(button)
            self.slot_actions[slot] = button


        # --- Add a dummy separator button with the mask icon ---

        separator_button = QToolButton()
        separator_button.setIcon(QIcon(mask_path))
        separator_button.setIconSize(QSize(64, 64))
        separator_button.setEnabled(False)  # Disable so it doesn't respond to clicks.
        separator_button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonIconOnly)
        self.slot_toolbar.addWidget(separator_button)

        # --- Create mask slot buttons ---
        for slot in range(5):  # Assuming 5 mask slots (0-4)
            button = QToolButton()
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            button.setText(mask_slot_name)
            # Optionally, set an icon for mask slots:
            # button.setIcon(QIcon("mask_icon.png"))
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Left-click: apply the mask in that slot.
            button.clicked.connect(lambda checked, s=slot: self.apply_mask_from_slot(s))
            
            # Right-click: open a context menu with "Preview Mask Slot" and "Rename Mask Slot".
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_mask_slot_context_menu(pos, s))
            
            self.slot_toolbar.addWidget(button)
            self.mask_slot_actions[slot] = button            

        # Highlight the default active slot.
        self.update_slot_toolbar_highlight()

        # --------------------
        # Status Bar
        # --------------------
        self.statusBar = QStatusBar(self)
        self.setStatusBar(self.statusBar)

        # File label (left side)
        self.file_name_label = QLabel("No file selected")
        self.statusBar.addWidget(self.file_name_label)  # Adds on the left

        # Create a container widget for the active slot label in the center.
        middleWidget = QWidget()
        middleLayout = QHBoxLayout(middleWidget)
        middleLayout.setContentsMargins(0, 0, 0, 0)  # Remove extra margins
        # Add stretch before and after the active slot label to center it.
        middleLayout.addStretch(1)
        self.active_slot_label = QLabel("Active Slot: 0")
        middleLayout.addWidget(self.active_slot_label)
        middleLayout.addStretch(1)
        # Add the middle widget with an expanding stretch factor (here using 1)
        self.statusBar.addWidget(middleWidget, 1)

        # Dimension label (right side)
        self.dim_label = QLabel("0 x 0")
        self.statusBar.addPermanentWidget(self.dim_label)  # Adds on the right

        # Connect the image_manager's signal to update the active slot label.
        self.image_manager.current_slot_changed.connect(self.update_active_slot_label)

        # --------------------
        # Tab Widget
        # --------------------
        self.tabs = QTabWidget()
        # Add individual tabs for each tool
        self.tabs.addTab(XISFViewer(image_manager=self.image_manager), "Image Viewer")
        self.tabs.addTab(BlinkTab(image_manager=self.image_manager), "Blink Comparator")
        self.tabs.addTab(CosmicClarityTab(image_manager=self.image_manager), "Cosmic Clarity Sharpen/Denoise")
        self.tabs.addTab(CosmicClaritySatelliteTab(), "Cosmic Clarity Satellite")
        self.tabs.addTab(StatisticalStretchTab(image_manager=self.image_manager), "Statistical Stretch")
        self.tabs.addTab(FullCurvesTab(image_manager=self.image_manager), "Curves Utility")
        self.tabs.addTab(PerfectPalettePickerTab(image_manager=self.image_manager, parent=self), "Perfect Palette Picker")
        self.tabs.addTab(NBtoRGBstarsTab(image_manager=self.image_manager, parent=self), "NB to RGB Stars")
        self.tabs.addTab(StarStretchTab(image_manager=self.image_manager), "Star Stretch")
        self.tabs.addTab(FrequencySeperationTab(image_manager=self.image_manager), "Frequency Separation")
        self.tabs.addTab(HaloBGonTab(image_manager=self.image_manager), "Halo-B-Gon")
        self.tabs.addTab(ContinuumSubtractTab(image_manager=self.image_manager), "Continuum Subtraction")
        self.tabs.addTab(MainWindow(), "What's In My Image")
        self.tabs.addTab(WhatsInMySky(), "What's In My Sky")
        self.tabs.currentChanged.connect(self.on_tab_changed)

        # Set the layout for the main window
        central_widget = QWidget(self)  # Create a central widget
        layout = QVBoxLayout(central_widget)

        layout.addWidget(self.mask_banner)  # Add banner to the layout        
        layout.addWidget(self.tabs)  # Add tabs to the central widget

        # Set the central widget of the main window
        self.setCentralWidget(central_widget)

        # --------------------
        # Quick Navigation Menu
        # --------------------
        quicknav_menu = menubar.addMenu("Quick Navigation")
        for i in range(self.tabs.count()):
            tab_title = self.tabs.tabText(i)
            action = QAction(tab_title, self)
            # Use lambda with default argument to capture the current value of i
            action.triggered.connect(lambda checked, index=i: self.tabs.setCurrentIndex(index))
            quicknav_menu.addAction(action)

        # --------------------
        # Preferences Menu
        # --------------------
        preferences_menu = menubar.addMenu("Preferences")
        preferences_action = QAction("Open Preferences", self)
        preferences_action.setStatusTip('Modify application settings')
        preferences_action.triggered.connect(self.open_preferences_dialog)
        preferences_menu.addAction(preferences_action)

        update_menu = menubar.addMenu("Update")
        check_update_action = QAction("Check for Updates", self)
        check_update_action.triggered.connect(self.check_for_updates)
        update_menu.addAction(check_update_action)

        # Help Menu with About action
        help_menu = menubar.addMenu("About")
        about_action = QAction("About", self)
        about_action.setStatusTip("About AstroEditingSuite")
        about_action.triggered.connect(self.show_about_dialog)
        help_menu.addAction(about_action)

        # --------------------
        # Apply Default Theme
        # --------------------
        self.apply_theme(self.current_theme)

        # --------------------
        # Window Properties
        # --------------------
        self.setWindowTitle(f'Seti Astro\'s Suite V{VERSION} QT6')
        self.setGeometry(100, 100, 800, 600)  # Set window size as needed

        self.check_for_updatesstartup()  # Call this in your app's init
        self.update_slot_toolbar_highlight()


    def star_registration(self):
        self.star_registration_window = StarRegistrationWindow(self.image_manager)
        self.star_registration_window.show()

    def show_about_dialog(self):
        dialog = AboutDialog(self)
        dialog.show()

    def open_supernova_hunter(self):
        # Instantiate the SuperNova/Asteroid Hunter widget
        self.supernova_hunter_tab = SupernovaAsteroidHunterTab()
        # Show the new window (or tab)
        self.supernova_hunter_tab.show()

    def stacking_suite_action(self):
        """ Opens the Stacking Suite window only if the correct secret code is entered. """

        # Create input dialog
        text, ok = QInputDialog.getText(None, "Stacking Suite - beta",
                                        "If you really want to view it, just say the magic word (please):")

        if ok and text.strip().lower() == "please":
            self.stackingsuitewindow = StackingSuiteDialog()
            self.stackingsuitewindow.show()
        else:
            QMessageBox.information(None, "Access Denied", "Incorrect code or action canceled.")


    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified image slot."""
        # Validate slot range and image availability.
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview is already open.
        if slot in self.preview_windows:
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            return

        # Create and show a new preview window.
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)
        self.preview_windows[slot] = preview
        preview.closed.connect(self.on_preview_closed)
        preview.show()

    def update_mask_slot_toolbar_highlight(self):
        """
        Loops through the mask slot buttons and applies a blue border to any slot that contains a mask.
        """
        for slot, button in self.mask_slot_actions.items():
            mask = self.mask_manager.get_mask(slot)
            if mask is not None:
                # Blue border indicates a mask is saved in this slot.
                button.setStyleSheet("border: 2px solid blue;")
            else:
                # Clear any border if the slot is empty.
                button.setStyleSheet("")


    def connect_mask_manager_signals(self):
        self.mask_manager.mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())
        self.mask_manager.applied_mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())

    def show_mask_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for a mask slot button with options to preview or rename.
        """
        button = self.mask_slot_actions.get(slot)
        if not button:
            return

        menu = QMenu(button)
        action_preview = menu.addAction("Preview Mask Slot")
        action_rename = menu.addAction("Rename Mask Slot")
        global_pos = button.mapToGlobal(pos)
        selected_action = menu.exec(global_pos)
        if selected_action == action_preview:
            self.preview_mask_slot(slot)
        elif selected_action == action_rename:
            self.rename_mask_slot_by_context(slot)

    def rename_mask_slot_by_context(self, slot):
        """
        Prompts the user to rename a mask slot (given by slot number) and updates the UI.
        """
        new_name, ok = QInputDialog.getText(
            self, "Rename Mask Slot", f"Enter new name for mask slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        self.mask_slot_names[slot] = new_name
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Apply or preview mask for {new_name}")
        QMessageBox.information(self, "Rename Mask Slot", f"Mask slot {slot} renamed to '{new_name}'.")


    def show_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for the slot button, with options to show the slot preview, rename the slot, or clear its contents.
        """
        # Retrieve the corresponding button
        button = self.slot_actions.get(slot)
        if not button:
            return

        # Create a QMenu for this button
        menu = QMenu(self)  # In Qt6, pass self as the parent
        
        # Add actions
        action_show_preview = menu.addAction("Show Slot Preview")
        action_rename = menu.addAction("Rename")
        action_clear = menu.addAction("Clear Slot")  # New clear slot option

        # Execute the menu at the global position
        selected_action = menu.exec(button.mapToGlobal(pos))
        
        # Perform actions based on selection
        if selected_action == action_show_preview:
            self.open_preview_window(slot)
        elif selected_action == action_rename:
            self.rename_slot_by_context(slot)
        elif selected_action == action_clear:
            self.clear_slot_contents(slot)  # Call the new clear function


    def rename_slot_by_context(self, slot):
        """
        Prompts the user to enter a new name for the specified slot and updates the UI.
        """
        # Prompt for the new name for this slot.
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", f"Enter new name for slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces.
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary.
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()

        QMessageBox.information(self, "Rename Successful", f"Slot {slot} renamed to {new_name}.")

    def clear_slot_contents(self, slot):
        """
        Completely clears the contents of the specified slot and resets the UI in Qt6.
        """
        # Confirm with the user before clearing
        reply = QMessageBox.question(
            self,
            "Clear Slot",
            f"Are you sure you want to clear slot {slot}?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.No:
            return  # User canceled

        # Ensure the ImageManager exists
        if not hasattr(self, 'image_manager'):
            QMessageBox.warning(self, "Error", "ImageManager is not available.")
            return

        # Remove image and metadata from ImageManager
        self.image_manager._images[slot] = None  # Remove image
        self.image_manager._metadata[slot] = {}  # Clear metadata
        self.image_manager._undo_stacks[slot] = []  # Clear undo history
        self.image_manager._redo_stacks[slot] = []  # Clear redo history


        # Close preview window if it exists
        if slot in self.preview_windows:
            self.preview_windows[slot].close()
            del self.preview_windows[slot]

        # Reset slot button UI
        if slot in self.slot_actions:
            button = self.slot_actions[slot]
            button.setText(f"Slot {slot}")  # Reset text
            button.setToolTip("No content available")  # Reset tooltip

        # Emit signal to update the UI and trigger the image refresh
        self.image_manager.image_changed.emit(slot, np.zeros((1, 1), dtype=np.uint8), {})

        # Notify user that the slot was cleared
        QMessageBox.information(self, "Slot Cleared", f"Slot {slot} has been completely cleared.")



    def stellar_alignment(self):
        dialog = StellarAlignmentDialog(self, self.settings, self.image_manager)
        dialog.show()

    def launch_plate_solver(self):
        # Instantiate and run the PlateSolver dialog.
        solver = PlateSolver(self.settings, self)
        solver.show()  # The PlateSolver dialog handles the full process

    def psf_viewer(self):
        """
        Create and show the PSFViewer dialog using the current image from the image manager.
        """
        # Check if a PSFViewer dialog is already open; if so, bring it to the front.
        if (hasattr(self, 'psf_viewer_dialog') and 
                self.psf_viewer_dialog is not None and 
                self.psf_viewer_dialog.isVisible()):
            self.psf_viewer_dialog.raise_()
            self.psf_viewer_dialog.activateWindow()
            return

        # Get the image from slot 0.
        img = self.image_manager._images.get(0, None)
        if img is None:
            QMessageBox.warning(self, "No Image", "Slot 0 does not contain an image.")
            return

        # If the image is grayscale, replicate to 3 channels.
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)

        # Create the PSFViewer dialog.
        self.psf_viewer_dialog = PSFViewer(img, self)

        # Define a helper function to update the PSFViewer when slot 0 changes.
        def update_psf(slot, image, metadata):
            if slot == 0:
                if image is None:
                    return
                if image.ndim == 2:
                    image = np.stack([image] * 3, axis=-1)
                self.psf_viewer_dialog.updateImage(image)

        # Connect the image_changed signal.
        #self.image_manager.image_changed.connect(update_psf)

        self.psf_viewer_dialog.show()


    def update_slot_toolbar_highlight(self):
        """
        Update the slot toolbar so that:
        - The active slot gets a distinct border (e.g., blue) regardless of occupancy.
        - Non-active slots that are occupied get a green border.
        - Unoccupied non-active slots have no border.
        """
        active_slot = self.image_manager.current_slot
        for slot, button in self.slot_actions.items():
            if button is not None:
                if slot == active_slot:
                    # Active slot: highlight with blue border.
                    button.setStyleSheet("border: 2px solid green; background-color: yellow; color: black;")
                else:
                    # For non-active slots:
                    if self.image_manager._images.get(slot) is not None:
                        # Occupied slot: green border.
                        button.setStyleSheet("border: 2px solid blue;")
                    else:
                        # Unoccupied: clear style.
                        button.setStyleSheet("")


    def set_active_slot(self, slot):
        """Set the specified slot as active and update the slot toolbar highlight."""
        self.image_manager.set_current_slot(slot)
        # Optionally, update other UI elements (such as an "Active Slot" label)
        self.update_slot_toolbar_highlight()


    def on_tab_changed(self, index):
        current_tab = self.tabs.widget(index)
        # Check if the tab has a 'refresh' method.
        if hasattr(current_tab, "refresh"):
            current_tab.refresh()

    def update_active_slot_label(self, slot):
        # Look up the custom name for this slot; if none exists, fall back to "Slot {slot}"
        slot_name = self.slot_names.get(slot, f"Slot {slot}")
        self.active_slot_label.setText(f"Active Slot: {slot_name}")


    def open_mosaic_master(self):
        """
        Opens a new MosaicMasterDialog (or QMainWindow) where the user can
        add multiple images, star-align them, and create a large mosaic.
        """
        # Create the mosaic master window if not already created, or just each time:
        mosaic_window = MosaicMasterDialog(self.settings, parent=self, image_manager=self.image_manager)

        mosaic_window.show()

    def save_project(self):
        """Save all project data to a single file."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getSaveFileName(
            self,
            "Save Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        # Assemble project data into one dictionary.
        project_data = {
            # ImageManager data: images and metadata
            "images": self.image_manager._images,       # dictionary {slot: image array}
            "metadata": self.image_manager._metadata,   # dictionary {slot: metadata dict}
            # Save custom slot names
            "slot_names": self.slot_names,
            # Undo/Redo stacks
            "undo_stacks": self.image_manager._undo_stacks,
            "redo_stacks": self.image_manager._redo_stacks,            
            # MaskManager data
            "masks": self.mask_manager._masks,          # dictionary {slot: mask array}
            "applied_mask_slot": self.mask_manager.applied_mask_slot,
            "applied_mask": self.mask_manager.applied_mask,
            # Save custom mask slot names
            "mask_slot_names": self.mask_slot_names,
            
            # Additional settings
            "current_slot": self.image_manager.current_slot,
            "theme": self.current_theme,
        }

        try:
            with open(fileName, "wb") as f:
                pickle.dump(project_data, f)
            print("Project saved successfully to:", fileName)
        except Exception as e:
            QMessageBox.critical(self, "Save Project Error", f"Error saving project: {str(e)}")


    def open_project(self):
        """Open a project file and repopulate all managers and UI elements."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getOpenFileName(
            self,
            "Open Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        try:
            with open(fileName, "rb") as f:
                project_data = pickle.load(f)
        except Exception as e:
            QMessageBox.critical(self, "Open Project Error", f"Error opening project: {str(e)}")
            return

        # Restore ImageManager data
        if "images" in project_data and "metadata" in project_data:
            self.image_manager._images = project_data["images"]
            self.image_manager._metadata = project_data["metadata"]
            self.image_manager.current_slot = project_data.get("current_slot", 0)
            # Restore undo/redo stacks if available
            self.image_manager._undo_stacks = project_data.get(
                "undo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )
            self.image_manager._redo_stacks = project_data.get(
                "redo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )            
        else:
            QMessageBox.warning(self, "Project Data", "No image data found in project file.")

        # Restore slot names if available
        if "slot_names" in project_data:
            self.slot_names = project_data["slot_names"]

        # Restore MaskManager data
        if "masks" in project_data:
            self.mask_manager._masks = project_data["masks"]
            self.mask_manager.applied_mask_slot = project_data.get("applied_mask_slot")
            self.mask_manager.applied_mask = project_data.get("applied_mask")
        
        # Restore custom mask slot names
        if "mask_slot_names" in project_data:
            self.mask_slot_names = project_data["mask_slot_names"]

        # Restore additional settings, e.g., theme
        if "theme" in project_data:
            self.current_theme = project_data["theme"]

        # Emit a signal to update the UI for the current slot if needed
        self.image_manager.image_changed.emit(
            self.image_manager.current_slot,
            self.image_manager._images[self.image_manager.current_slot],
            self.image_manager._metadata[self.image_manager.current_slot]
        )

        # **Update the slot menu actions to reflect the new custom slot names**
        for slot, action in self.slot_actions.items():
            new_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")
        
        # (Optionally, update mask slot actions similarly if needed.)
        for slot, action in self.mask_slot_actions.items():
            new_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")        

        print("Project loaded successfully from:", fileName)

    def new_project(self):
        """
        Clears all current project data (images, masks, undo/redo stacks, etc.)
        after warning the user that this operation is destructive.
        """
        reply = QMessageBox.question(
            self,
            "New Project",
            "This will erase all data in current slots and undo/redo stacks. Are you sure you want to create a new project?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply != QMessageBox.StandardButton.Yes:
            print("New project canceled by user.")
            return

        # Clear ImageManager data
        self.image_manager._images = {i: None for i in range(self.image_manager.max_slots)}
        self.image_manager._metadata = {i: {} for i in range(self.image_manager.max_slots)}
        self.image_manager._undo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager._redo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager.current_slot = 0

        # Clear MaskManager data
        self.mask_manager._masks = {}
        self.mask_manager.applied_mask = None
        self.mask_manager.applied_mask_slot = None

        # Clear preview windows if any
        self.preview_windows = {}

        # Reset custom slot names to defaults
        self.slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}

        # Update UI elements for slot names (e.g., QToolButtons)
        for slot, action in self.slot_actions.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(default_name)
            action.setStatusTip(f"Open preview for {default_name}")

        # Update any open preview windows
        for slot, window in self.preview_windows.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            window.setWindowTitle(f"Preview - {default_name}")

        # Update UI elements that are managed outside of ImageManager
        # For instance, update file name label or other status indicators.
        # Here we call update_file_name with default parameters.
        self.update_file_name(0, None, {})

        # Clear all tabs that display images.
        self.clear_all_tabs()

        print("New project created: All image, mask, and undo/redo data have been cleared.")


    def clear_all_tabs(self):
        """
        Simulate a tab click by switching to a different tab and back.
        This forces the tab's update logic to clear the image.
        """
        if self.tabs.count() < 2:
            # Only one tab—try calling clear_image() if available.
            current_tab = self.tabs.currentWidget()
            if hasattr(current_tab, "clear_image"):
                current_tab.clear_image()
            return

        # Save the current index.
        current_index = self.tabs.currentIndex()
        # Choose a different tab index.
        new_index = 1 if current_index == 0 else 0
        # Switch to the new index.
        self.tabs.setCurrentIndex(new_index)
        # Immediately switch back.
        self.tabs.setCurrentIndex(current_index)
        print("Simulated tab click to clear image.")

    def open_histogram(self):
        # Check if a histogram dialog is already open; if so, bring it to front.
        if hasattr(self, 'hist_dialog') and self.hist_dialog is not None and self.hist_dialog.isVisible():
            self.hist_dialog.raise_()
            self.hist_dialog.activateWindow()
            return

        # Get the image from slot0 (or change slot as desired).
        img = self.image_manager._images.get(0, None)
        if img is None:
            QMessageBox.warning(self, "No Image", "Slot 0 does not contain an image.")
            return
        # If grayscale, replicate to 3 channels.
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)
        # Create the histogram dialog.
        self.hist_dialog = HistogramDialog(img, self)
        
        # Define a helper function to update the histogram when slot0 changes.
        def update_hist(slot, image, metadata):
            if slot == 0:
                if image is None:
                    return
                if image.ndim == 2:
                    image = np.stack([image]*3, axis=-1)
                self.hist_dialog.updateHistogram(image)
        # Connect the image_changed signal.
        self.image_manager.image_changed.connect(update_hist)
        
        self.hist_dialog.show()

    def rename_slot(self):
        """
        Prompts the user to select a slot and enter a new name (with no spaces).
        The new name is then applied to the slot and updates the UI.
        """
        # Ask the user which slot to rename (0 to max_slots-1)
        slot, ok = QInputDialog.getInt(
            self, "Rename Slot", "Enter slot number to rename:",
            0, 0, self.image_manager.max_slots - 1
        )
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", "Enter new name (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()

        QMessageBox.information(self, "Rename Successful", f"Slot {slot} renamed to {new_name}.")

    def rename_mask_slot(self):
        """
        Prompts the user to select a mask slot (0-4) and enter a new name (without spaces),
        then updates the mask slot name in the dictionary and the corresponding QAction.
        """
        # Ask for the mask slot number
        slot, ok = QInputDialog.getInt(self, "Rename Mask Slot", "Enter mask slot number (0-4):", 0, 0, 4)
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(self, "Rename Mask Slot", "Enter new name (no spaces):")
        if not ok or not new_name:
            return

        # Validate that the new name has no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom mask slot names dictionary
        self.mask_slot_names[slot] = new_name

        # Update the corresponding QAction text and tooltip
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # Optionally, if you keep track of open mask preview dialogs, update their titles as well.
        # For example, if you maintain a dictionary self.mask_preview_windows:
        # if slot in self.mask_preview_windows:
        #     self.mask_preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        QMessageBox.information(self, "Rename Mask Slot", f"Mask slot {slot} renamed to '{new_name}'.")


    def open_pixel_math_dialog(self):
        """Opens the Pixel Math dialog."""
        dialog = PixelMathDialog(self, self.image_manager)
        dialog.exec()  # Using exec() to open as a modal dialog

    def connect_mask_manager_signals(self):
        """
        Connect signals from MaskManager to update the banner dynamically.
        """
        self.mask_manager.applied_mask_changed.connect(self.update_mask_banner)

    def update_mask_banner(self, slot, mask):
        """
        Updates the mask banner to indicate whether a mask is applied,
        using the custom name for the mask slot if available.
        """
        if mask is not None:
            # Check if a custom name exists for this mask slot
            if hasattr(self, 'mask_slot_names'):
                custom_name = self.mask_slot_names.get(slot, f"Slot {slot}")
            else:
                custom_name = f"Slot {slot}"
            self.mask_banner.setText(f"Mask Applied: {custom_name}")
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(True)
        else:
            self.mask_banner.setText("Mask Applied: None")
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(False)


    def preview_mask_slot(self, slot):
        """
        Opens a preview window for the selected mask slot.
        """
        mask = self.mask_manager.get_mask(slot)
        
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask saved in slot {slot}.")
            return

        # Create the mask slot preview dialog
        preview_dialog = MaskSlotPreviewDialog(mask, slot, self)
        preview_dialog.show()


    def create_mask(self):
        """Open the Mask Creation dialog."""
        current_image = self.image_manager.image
        if current_image is None:
            QMessageBox.warning(self, "No Image", "No image available to create a mask.")
            return

        # Open the Mask Creation Dialog
        dialog = MaskCreationDialog(current_image, parent=self)
        dialog.exec()  # Execute the dialog as a modal window


    def apply_mask(self):
        """Prompt user for a mask slot and flag it in MaskManager for application."""
        # Check available mask slots
        available_slots = [slot for slot in range(self.mask_manager.max_slots) if self.mask_manager.get_mask(slot) is not None]

        if not available_slots:
            QMessageBox.warning(self, "No Masks Available", "There are no masks to apply.")
            return

        # Prompt user to select a mask slot
        slot, ok = QInputDialog.getItem(
            self,
            "Select Mask Slot",
            "Choose a mask slot to apply:",
            [f"Slot {s}" for s in available_slots],
            0,  # Default selection
            False  # Do not allow user input outside the options
        )

        if not ok:
            return  # User canceled

        # Extract selected slot number
        selected_slot = int(slot.split()[-1])

        # Flag the mask in MaskManager
        self.mask_manager.apply_mask_from_slot(selected_slot)

        # Update the UI banner to indicate an active mask
        self.update_mask_banner(selected_slot, self.mask_manager.get_applied_mask())

        print(f"Mask from Slot {selected_slot} flagged for application.")

    def apply_mask_from_slot(self, slot):
        """
        Applies the mask stored in the given mask slot.
        Updates the UI (e.g. mask banner) to reflect the applied mask.
        """
        mask = self.mask_manager.get_mask(slot)
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask is saved in slot {slot}.")
            return

        # Apply the mask from the specified slot.
        self.mask_manager.apply_mask_from_slot(slot)
        # Optionally, update any UI elements (for example, a banner) to show the applied mask.
        self.update_mask_banner(slot, self.mask_manager.get_applied_mask())
        print(f"Mask from Slot {slot} flagged for application.")


    def remove_mask(self):
        """Remove the active mask and update the UI."""
        # Check if a mask is currently applied
        if self.mask_manager.get_applied_mask() is None:
            QMessageBox.warning(self, "No Mask", "No mask is currently applied.")
            return

        # Clear the applied mask
        self.mask_manager.clear_applied_mask()


        # Update the UI banner to reflect no active mask
        self.update_mask_banner(-1, None)

        print("Mask removed successfully, banner updated.")


    def load_mask(self):
        """Load a mask from a file."""
        default_dir = self.settings.value("working_directory", "")
        # Open a file dialog to select the mask file
        filename, _ = QFileDialog.getOpenFileName(
            self, 
            "Load Mask", 
            default_dir, 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if not filename:
            return  # User canceled the dialog

        try:
            # Load the mask using the global load_image method
            loaded_image, _, _, _ = load_image(filename)  # Ensure load_image returns (image, header, bit_depth, is_mono)

            # Convert the loaded image to grayscale if it's not already
            if loaded_image.ndim == 3:
                # Assuming RGB; convert to grayscale using OpenCV
                mask = cv2.cvtColor(loaded_image, cv2.COLOR_RGB2GRAY)
            else:
                mask = loaded_image.copy()  # Already single-channel

            # Normalize the mask to [0, 1] if it's not already
            mask = mask.astype(np.float32)
            if mask.max() > 1.0:
                mask /= 255.0
            mask = np.clip(mask, 0.0, 1.0)

            # Prompt the user to select the mask slot
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot", 
                f"Enter mask slot number (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if ok:
                # Set the mask in the selected slot using MaskManager
                self.mask_manager.set_mask(slot_number, mask)
                QMessageBox.information(
                    self, 
                    "Mask Loaded", 
                    f"Mask loaded from {filename} into slot {slot_number}."
                )
                print(f"AstroEditingSuite: Mask loaded from {filename} into slot {slot_number}.")
            else:
                QMessageBox.information(self, "Load Mask", "Mask loading canceled.")
                print("AstroEditingSuite: Mask loading canceled by the user.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load mask:\n{e}")
            print(f"AstroEditingSuite: Failed to load mask: {e}")

    def save_mask(self):
        """Save the active mask to a file."""
        default_dir = self.settings.value("working_directory", "")
        try:
            # Prompt the user to select the mask slot to save
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot to Save", 
                f"Enter mask slot number to save (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if not ok:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Retrieve the mask from the selected slot using MaskManager
            mask = self.mask_manager.get_mask(slot_number)
            if mask is None:
                QMessageBox.warning(
                    self, 
                    "No Mask", 
                    f"No mask available in slot {slot_number} to save."
                )
                print(f"AstroEditingSuite: No mask available in slot {slot_number} to save.")
                return

            # Open a save file dialog to specify the destination file
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save Mask", 
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
            )
            if not filename:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Determine the file format based on the file extension
            file_format = os.path.splitext(filename)[1][1:].lower()  # Extract extension without dot

            # Set bit_depth based on file format
            # For PNG and JPEG, bit_depth is not required as they typically use 8-bit
            # For TIFF and FITS, we'll specify 8-bit
            if file_format in ['tif', 'tiff']:
                bit_depth = "8-bit"
            else:
                bit_depth = None  # Not required for formats like PNG

            # Convert mask to appropriate format for saving
            # Assuming mask is single-channel and normalized between 0 and 1
            mask_to_save = (mask * 255).astype(np.uint8)
            if mask_to_save.ndim == 2:
                # Convert to RGB if the save format expects multi-channel
                mask_to_save = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2RGB)

            # Save the mask using the global save_image method
            save_image(
                img_array=mask_to_save, 
                filename=filename, 
                original_format=file_format, 
                bit_depth=bit_depth, 
                original_header=None,  # Masks typically don't have headers
                is_mono=False,         # Masks are RGB after conversion
                image_meta=None,       # Optional metadata
                file_meta=None         # Optional file metadata
            )
            QMessageBox.information(
                self, 
                "Mask Saved", 
                f"Mask from slot {slot_number} saved to {filename}."
            )
            print(f"AstroEditingSuite: Mask from slot {slot_number} saved to {filename}.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save mask:\n{e}")
            print(f"AstroEditingSuite: Failed to save mask: {e}")

    def rescale_image(self):
        """
        Rescales the current image by a user-defined scaling factor using OpenCV.
        The image is expected to be stored as a 32-bit floating point numpy array.
        For example, a factor of 0.5 scales down the image to 50% of its original size,
        while 2 scales it up to 200%.
        """
        try:
            # Ensure that an image is loaded.
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rescaling.")
                return

            # Prompt the user for a scaling factor.
            factor, ok = QInputDialog.getDouble(
                self,
                "Rescale Image",
                "Enter scaling factor (e.g., 0.5 for 50%, 2 for 200%):",
                1.0,    # default value
                0.1,    # minimum value
                10.0,   # maximum value
                2       # number of decimals
            )
            if not ok:
                return

            # Retrieve a copy of the current image.
            current_image = self.image_manager.image.copy()

            # Determine new dimensions based on the scaling factor.
            # current_image.shape is assumed to be (height, width) for grayscale or (height, width, channels) for RGB.
            height, width = current_image.shape[:2]
            new_width = int(width * factor)
            new_height = int(height * factor)

            # Import cv2 and use cv2.resize with the LANCZOS4 interpolation method.
            resized_image = rescale_image_numba(current_image, factor)

            # Prepare metadata (append a description note about rescaling).
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + f" | Rescaled by factor {factor}"

            # Push the current state onto the undo stack.
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            # Clear the redo stack since a new action invalidates the redo history.
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()

            # Update the ImageManager with the rescaled image.
            self.image_manager.set_image(new_image=resized_image, metadata=metadata)
            self.image_manager.image_changed.emit(
                self.image_manager.current_slot,
                resized_image,
                metadata
            )

            QMessageBox.information(
                self,
                "Image Rescaled",
                f"The image has been successfully rescaled by a factor of {factor}."
            )

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rescale image:\n{e}")
            print(f"Error in rescale_image: {e}")

            
    def flip_horizontal(self):
        """
        Flips the current image horizontally.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the horizontal flip using numpy
            flipped_image = flip_horizontal_numba(current_image)  # Flip horizontally

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Horizontally Flipped"

            # Save the current state to the undo stack
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            print(f"ImageManager: Current state of Slot {self.image_manager.current_slot} pushed to undo stack.")

            # Clear the redo stack as new action invalidates the redo history
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()
            print(f"ImageManager: Redo stack for Slot {self.image_manager.current_slot} cleared.")

            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata)

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Flipped", "The image has been successfully flipped horizontally.")

            print(f"Image in Slot {self.image_manager.current_slot} flipped horizontally successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image horizontally:\n{e}")
            print(f"Error in flip_horizontal: {e}")

    def flip_vertical(self):
        """
        Flips the current image vertically.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the vertical flip using numpy
            flipped_image = flip_vertical_numba(current_image)  # Flip vertically

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Vertically Flipped"

            # Save the current state to the undo stack
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            print(f"ImageManager: Current state of Slot {self.image_manager.current_slot} pushed to undo stack.")

            # Clear the redo stack as new action invalidates the redo history
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()
            print(f"ImageManager: Redo stack for Slot {self.image_manager.current_slot} cleared.")

            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata)

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Flipped", "The image has been successfully flipped vertically.")

            print(f"Image in Slot {self.image_manager.current_slot} flipped vertically successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image vertically:\n{e}")
            print(f"Error in flip_vertical: {e}")

    def rotate_clockwise(self):
        """
        Rotates the current image 90 degrees clockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_clockwise_numba(current_image)  # Rotate clockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Clockwise"

            # Save the current state to the undo stack
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            print(f"ImageManager: Current state of Slot {self.image_manager.current_slot} pushed to undo stack.")

            # Clear the redo stack as new action invalidates the redo history
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()
            print(f"ImageManager: Redo stack for Slot {self.image_manager.current_slot} cleared.")

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata)

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Rotated", "The image has been successfully rotated 90° clockwise.")

            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° clockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image clockwise:\n{e}")
            print(f"Error in rotate_clockwise: {e}")

    def rotate_counterclockwise(self):
        """
        Rotates the current image 90 degrees counterclockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_counterclockwise_numba(current_image)  # Rotate counterclockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Counterclockwise"

            # Save the current state to the undo stack
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            print(f"ImageManager: Current state of Slot {self.image_manager.current_slot} pushed to undo stack.")

            # Clear the redo stack as new action invalidates the redo history
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()
            print(f"ImageManager: Redo stack for Slot {self.image_manager.current_slot} cleared.")

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata)

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Rotated", "The image has been successfully rotated 90° counterclockwise.")

            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° counterclockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image counterclockwise:\n{e}")
            print(f"Error in rotate_counterclockwise: {e}")

    def invert_image(self):
        """
        Inverts the colors of the current image.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before inverting.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Check if the image is in a compatible format (e.g., float32 in [0,1])
            if current_image.dtype not in [np.float32, np.float64]:
                QMessageBox.warning(self, "Unsupported Format", "Image inversion supports floating point images.")
                return

            # Perform the inversion
            inverted_image = invert_image_numba(current_image)

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Inverted Image"

            # Save the current state to the undo stack
            self.image_manager._undo_stacks[self.image_manager.current_slot].append(
                (current_image.copy(), metadata.copy())
            )
            print(f"ImageManager: Current state of Slot {self.image_manager.current_slot} pushed to undo stack.")

            # Clear the redo stack as new action invalidates the redo history
            self.image_manager._redo_stacks[self.image_manager.current_slot].clear()
            print(f"ImageManager: Redo stack for Slot {self.image_manager.current_slot} cleared.")

            # Update the ImageManager with the inverted image
            self.image_manager.set_image(new_image=inverted_image, metadata=metadata)

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, inverted_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Inverted", "The image has been successfully inverted.")

            print(f"Image in Slot {self.image_manager.current_slot} inverted successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to invert image:\n{e}")
            print(f"Error in invert_image: {e}")

    def open_hdr_dialog(self):
        """Open the WaveScale HDR dialog."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before using WaveScale HDR.")
            return

        dialog = WaveScaleHDRDialog(self.image_manager, self)
        dialog.exec()


    def open_blemish_blaster(self):
        """Handler method to open the Blemish Blaster tool."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image Loaded", "Please load an image before using Blemish Blaster.")
            return

        # Initialize and show the Blemish Blaster dialog, passing the ImageManager
        self.blemish_dialog = BlemishBlasterDialog(self.image_manager, self)

        self.blemish_dialog.exec()


    def remove_gradient(self):
        """Handle the Remove Gradient action."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Initialize the GradientRemovalDialog with the current image
        gradient_dialog = GradientRemovalDialog(image=self.image_manager.image.copy(), parent=self)
        gradient_dialog.processing_completed.connect(self.handle_gradient_removal)
        gradient_dialog.exec()


    def handle_gradient_removal(self, corrected_image, gradient_background, save_to_slot_1, selected_slot):
        """
        Handle the processed image after gradient removal.

        Args:
            corrected_image (np.ndarray): The image after gradient removal.
            gradient_background (np.ndarray): The extracted gradient.
            save_to_slot_1 (bool): Whether the user wants to save the gradient background.
            selected_slot (str): The slot number selected (e.g., "Slot 1").
        """
        try:
            # Store the corrected image in the current slot
            current_slot = self.image_manager.current_slot
            metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            metadata['description'] = "Gradient removed"
            self.image_manager.set_image(new_image=corrected_image, metadata=metadata)

            # **Save gradient background only if requested**
            if save_to_slot_1:
                slot_number = int(selected_slot.split(" ")[1])  # Convert "Slot 1" -> 1

                metadata_slot = {
                    'file_path': f"Gradient Background ({selected_slot})",
                    'description': "Extracted Gradient Background",
                    'bit_depth': "32-bit floating point",
                    'is_mono': len(gradient_background.shape) < 3,
                    'gradient_background': gradient_background
                }

                # Save gradient background in the selected slot
                self.image_manager._images[slot_number] = gradient_background
                self.image_manager._metadata[slot_number] = metadata_slot

                print(f"[INFO] Gradient background stored in {selected_slot}.")

                # --- Update slot UI Labels ---
                if hasattr(self, 'slot_names'):
                    self.slot_names[slot_number] = f"Extracted Gradient ({selected_slot})"
                if hasattr(self, 'slot_actions') and slot_number in self.slot_actions:
                    self.slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")
                # --- Update Menubar Slot Name (FIX) ---
                if hasattr(self, 'menubar_slot_actions') and slot_number in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.menubar_slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")

                if hasattr(self, 'preview_windows') and slot_number in self.preview_windows:
                    self.preview_windows[slot_number].setWindowTitle(f"Preview - Extracted Gradient ({selected_slot})")

                self.menuBar().update()
                print(f"[INFO] Gradient removal completed and saved to {selected_slot}.")
            else:
                print("[INFO] User chose not to save the extracted gradient.")

            # Notify the user
            QMessageBox.information(self, "Success", "Gradient removal completed successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply gradient removal:\n{e}")
            print(f"Error in handle_gradient_removal: {e}")




    def check_for_updates(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/refs/heads/main/updates.json"

            # Fetch the JSON data
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()
            update_data = response.json()

            # Convert version strings to tuples for proper comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                msg_box.setDetailedText("\n".join([f"{k}: {v}" for k, v in downloads.items()]))

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    import webbrowser
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        webbrowser.open(downloads.get("Windows", ""))
                    elif platform.startswith("darwin"):
                        webbrowser.open(downloads.get("macOS", ""))
                    elif platform.startswith("linux"):
                        webbrowser.open(downloads.get("Linux", ""))
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
            else:
                QMessageBox.information(self, "No Updates", "You are already running the latest version.")

        except requests.RequestException as e:
            QMessageBox.critical(self, "Error", f"Failed to check for updates:\n{e}")


    def check_for_updatesstartup(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/main/updates.json"

            # Fetch the JSON data with a timeout to prevent hanging
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()  # Raise an exception for HTTP errors
            update_data = response.json()

            # Convert version strings to tuples for accurate comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            if not latest_version_str:
                print("Update check: 'version' key not found in update data.")
                return  # Exit silently

            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                detailed_text = "\n".join([f"{k}: {v}" for k, v in downloads.items()])
                msg_box.setDetailedText(detailed_text)

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    import webbrowser
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        download_link = downloads.get("Windows", "")
                    elif platform.startswith("darwin"):
                        download_link = downloads.get("macOS", "")
                    elif platform.startswith("linux"):
                        download_link = downloads.get("Linux", "")
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
                        download_link = ""

                    if download_link:
                        webbrowser.open(download_link)
                    else:
                        QMessageBox.warning(self, "Error", "Download link not available.")
                else:
                    # If the user declines the update, you might want to log it or simply do nothing.
                    pass
            else:
                # No update available; you might opt to notify the user at startup,
                # but typically it's best to remain silent.
                pass

        except requests.RequestException as e:
            # Log the error and optionally show a non-intrusive warning.
            print(f"Update check failed: {e}")
            msg_box = QMessageBox(self)
            msg_box.setIcon(QMessageBox.Icon.Warning)
            msg_box.setWindowTitle("Update Check Failed")
            msg_box.setText("Unable to check for updates at this time.")
            msg_box.setInformativeText("Please check your internet connection and try again later.")
            msg_box.setStandardButtons(QMessageBox.StandardButton.Ok)
            msg_box.exec()
        
    def version_str_to_tuple(self, version_str):
        """
        Convert a version string into a tuple of integers for comparison.
        Example: "1.10.2" -> (1, 10, 2)
        """
        return tuple(int(part) for part in version_str.split('.') if part.isdigit())

    def open_preferences_dialog(self):
        dialog = QDialog(self)
        dialog.setWindowTitle("Preferences")
        layout = QVBoxLayout(dialog)

        # Display stored settings using a form layout.
        settings_form = QFormLayout()

        # Define settings fields with appropriate selection methods.
        settings_fields = {
            "GraXpert Path": ("graxpert/path", self.settings.value("graxpert/path", "")),  # Needs FILE selection
            "StarNet Executable Path": ("starnet/exe_path", self.settings.value("starnet/exe_path", "")),  # FILE
            "ASTAP Executable Path": ("astap/exe_path", self.settings.value("astap/exe_path", "")),  # FILE
            "Cosmic Clarity Folder": ("cosmic_clarity_folder", self.settings.value("cosmic_clarity_folder", "")),  # FOLDER
            "Working Directory": ("working_directory", self.settings.value("working_directory", ""))  # FOLDER
        }

        # Create input fields dynamically with file/folder selection buttons.
        input_fields = {}
        for label, (key, value) in settings_fields.items():
            field_widget = QWidget()
            field_layout = QHBoxLayout(field_widget)
            field_layout.setContentsMargins(0, 0, 0, 0)

            # Create the QLineEdit with the stored value.
            field = QLineEdit(str(value))
            input_fields[key] = field
            field_layout.addWidget(field)

            # Create selection button.
            select_button = QPushButton("...")
            select_button.setFixedWidth(30)

            # **Use file selection for executable paths, folder selection for directories**
            if label in ["GraXpert Path", "StarNet Executable Path", "ASTAP Executable Path"]:
                select_button.setToolTip(f"Select file for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_file(f))
            else:
                select_button.setToolTip(f"Select folder for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_folder(f))

            field_layout.addWidget(select_button)
            settings_form.addRow(label, field_widget)

        # Additional settings fields (without selection buttons).
        additional_fields = {
            "Astrometry API Key": ("astrometry_api_key", self.settings.value("astrometry_api_key", "")),
            "Latitude": ("latitude", self.settings.value("latitude", "")),
            "Longitude": ("longitude", self.settings.value("longitude", "")),
            "Date": ("date", self.settings.value("date", "")),
            "Time": ("time", self.settings.value("time", "")),
            "Timezone": ("timezone", self.settings.value("timezone", "")),
            "Minimum Altitude": ("min_altitude", self.settings.value("min_altitude", ""))
        }

        for label, (key, value) in additional_fields.items():
            field = QLineEdit(str(value))
            settings_form.addRow(label, field)
            input_fields[key] = field

        layout.addLayout(settings_form)

        # **Add Save, Reset, and Cancel buttons**
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Save |
                                QDialogButtonBox.StandardButton.Reset |
                                QDialogButtonBox.StandardButton.Cancel)

        # Save button: Save preferences
        buttons.accepted.connect(lambda: self.save_preferences(input_fields, dialog))

        # Reset button: Clear preferences
        buttons.button(QDialogButtonBox.StandardButton.Reset).clicked.connect(lambda: self.clear_preferences(input_fields))

        # Cancel button: Close the dialog
        buttons.rejected.connect(dialog.reject)

        layout.addWidget(buttons)
        dialog.exec()

    def select_file(self, field):
        """Open file selection dialog for executable files."""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select Executable File",
            "",
            "Executables (*.exe *.AppImage *.sh *.bin *.run);;All Files (*)"
        )
        if file_path:
            field.setText(file_path)

    def select_folder(self, field):
        """Open folder selection dialog."""
        folder_path = QFileDialog.getExistingDirectory(self, "Select Folder")
        if folder_path:
            field.setText(folder_path)

    def save_preferences(self, input_fields, dialog):
        for key, field in input_fields.items():
            self.settings.setValue(key, field.text())
        dialog.accept()
        QMessageBox.information(self, "Preferences Saved", "Settings have been updated successfully.")

    def clear_preferences(self, input_fields):
        reply = QMessageBox.question(self, "Clear Preferences", "Are you sure you want to clear all preferences?", QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
        if reply == QMessageBox.StandardButton.Yes:
            for key in input_fields.keys():
                self.settings.remove(key)
                input_fields[key].clear()
            QMessageBox.information(self, "Preferences Cleared", "All settings have been reset.")


    def open_crop_tool(self):
        """Open the crop tool to crop the current image."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before cropping.")
            return

        # Open the Crop Tool with correct parameters
        crop_tool = CropTool(self.image_manager, self.image_manager.image, self)
        crop_tool.crop_applied.connect(self.apply_cropped_image)
        crop_tool.exec()

    def apply_cropped_image(self, cropped_image):
        """Apply the cropped image to the current slot."""
        # Update the current slot with the cropped image
        current_slot = self.image_manager.current_slot
        metadata = self.image_manager._metadata.get(current_slot, {}).copy()
        metadata['file_path'] = "Cropped Image"

        # Save current state to undo stack
        self.image_manager._undo_stacks[current_slot].append(
            (self.image_manager._images[current_slot].copy(), metadata.copy())
        )
        print(f"ImageManager: Current state of Slot {current_slot} pushed to undo stack.")

        # Update with the cropped image
        self.image_manager._images[current_slot] = cropped_image
        self.image_manager._metadata[current_slot] = metadata

        # Emit signal to update UI
        self.image_manager.image_changed.emit(current_slot, cropped_image, metadata)
        QMessageBox.information(self, "Success", "Cropped image applied.")


    def rgb_combination(self):
        """Handle the RGB Combination action."""
        dialog = RGBCombinationDialog(self, image_manager=self.image_manager)
        if dialog.exec() == QDialog.DialogCode.Accepted:
            combined_rgb = dialog.rgb_image  # Numpy array with shape (H, W, 3) normalized to [0,1]
            metadata = {
                'file_path': "RGB Combination",
                'is_mono': False,
                'bit_depth': "32-bit floating point",
                'original_header': None  # Add header information if available
            }
            # Store the combined RGB image in Slot 0
            self.image_manager._images[0] = combined_rgb
            self.image_manager._metadata[0] = metadata
            self.image_manager.image_changed.emit(0, combined_rgb, metadata)
            print("RGB image stored in Slot 0.")
            QMessageBox.information(self, "Success", "RGB image combined and stored in Slot 0.")
        else:
            print("RGB Combination cancelled by the user.")

    def rgb_extract(self):
        """Handle the RGB Extract action."""
        # Determine which slot to extract from. For this example, we'll extract from Slot 0.
        slot_to_extract = 0
        image = self.image_manager._images.get(slot_to_extract, None)
        
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot_to_extract} does not contain an image to extract from.")
            print(f"Slot {slot_to_extract} is empty. Cannot perform RGB Extract.")
            return
        
        if image.ndim != 3 or image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", "The selected image is not a valid RGB image.")
            print("Invalid image format for RGB Extract. Expected a 3-channel RGB image.")
            return
        
        try:
            # Split the RGB channels
            r_channel = image[..., 0].copy()
            g_channel = image[..., 1].copy()
            b_channel = image[..., 2].copy()
            
            # Define metadata for each channel
            metadata_r = {
                'file_path': f"RGB Extract - Red Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_g = {
                'file_path': f"RGB Extract - Green Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_b = {
                'file_path': f"RGB Extract - Blue Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            
            # Store each channel in Slot 2, 3, and 4
            self.image_manager._images[2] = r_channel
            self.image_manager._images[3] = g_channel
            self.image_manager._images[4] = b_channel
            self.image_manager._metadata[2] = metadata_r
            self.image_manager._metadata[3] = metadata_g
            self.image_manager._metadata[4] = metadata_b
            
            # Update the custom slot names in the main window's slot_names dictionary
            self.slot_names[2] = "Red"
            self.slot_names[3] = "Green"
            self.slot_names[4] = "Blue"
            
            for slot, name in zip([2, 3, 4], ["Red", "Green", "Blue"]):
                if slot in self.slot_actions:
                    self.slot_actions[slot].setText(name)
                    self.slot_actions[slot].setStatusTip(f"Open preview for {name}")

                if slot in self.preview_windows:
                    self.preview_windows[slot].setWindowTitle(f"Preview - {name}")

                # --- ✅ Update Menubar Slot Names ---
                if hasattr(self, 'menubar_slot_actions') and slot in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot].setText(name)
                    self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {name}")

            self.menuBar().update()
                
            print(f"Extracted R, G, B channels from Slot {slot_to_extract} and stored in Slots 2, 3, 4 as Red, Green, and Blue respectively.")
            QMessageBox.information(self, "Success", "RGB channels extracted and stored in Slots 2 (Red), 3 (Green), and 4 (Blue).")
            
            # Open the preview windows for each extracted channel
            self.open_preview_window(slot=2)
            self.open_preview_window(slot=3)
            self.open_preview_window(slot=4)

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to extract RGB channels: {e}")
            print(f"Error during RGB Extract: {e}")

    def extract_luminance(self):
        """Extracts the luminance from the current image and updates slots."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before extracting luminance.")
            return

        # Ensure the image is RGB
        current_image = self.image_manager.image
        if current_image.ndim != 3 or current_image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", "Luminance extraction requires an RGB image.")
            return

        # Clip the current image to [0, 1] to avoid any unexpected values outside the valid range
        current_image = np.clip(current_image, 0.0, 1.0)

        # Convert the RGB image to Lab to extract L* (luminance)
        lab_image = self.rgb_to_lab(current_image)
        luminance = lab_image[..., 0] / 100.0  # Normalize L* to [0, 1] for storage

        # --- Swap assignments: ---
        # Store the original RGB image in Slot 0.
        self.image_manager._images[0] = current_image
        self.image_manager._metadata[0] = self.image_manager._metadata[self.image_manager.current_slot].copy()
        print("Original RGB image moved to slot 0.")

        # Store the luminance image in Slot 1.
        luminance_metadata = {
            'file_path': "Luminance Extracted",
            'is_mono': True,
            'bit_depth': "32-bit floating point",
        }
        self.image_manager._images[1] = luminance
        self.image_manager._metadata[1] = luminance_metadata
        print("Luminance image updated in slot 1.")

        # Emit signals for both slots to refresh views if necessary.
        self.image_manager.image_changed.emit(0, current_image, self.image_manager._metadata[0])


        # --- Update custom slot names to reflect the new content ---
        # Assuming your main window stores custom names in self.slot_names and slot actions in self.slot_actions.
        if hasattr(self, 'slot_names'):
            self.slot_names[1] = "Luminance"
        if hasattr(self, 'slot_actions') and 1 in self.slot_actions:
            self.slot_actions[1].setText("Luminance")
            self.slot_actions[1].setStatusTip("Open preview for Luminance")
        if hasattr(self, 'preview_windows') and 1 in self.preview_windows:
            self.preview_windows[1].setWindowTitle("Preview - Luminance")

        # --- ✅ Update Menubar Slot Name ---
        if hasattr(self, 'menubar_slot_actions') and 1 in self.menubar_slot_actions:
            self.menubar_slot_actions[1].setText("Luminance")
            self.menubar_slot_actions[1].setStatusTip("Open preview for Luminance")

        self.menuBar().update()

        # Open a preview for the luminance image in Slot 1.
        self.open_preview_window(slot=1)


    def remove_gradient_with_graxpert(self):
        """Integrate GraXpert for gradient removal."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Prompt user for smoothing value
        smoothing, ok = QInputDialog.getDouble(
            self,
            "GraXpert Smoothing Amount",
            "Enter smoothing amount (0.0 to 1.0):",
            decimals=2,
            min=0.0,
            max=1.0,
            value=0.1
        )
        if not ok:
            return  # User cancelled

        # Save the current image as a TIFF file
        input_basename = "input_image"
        input_path = os.path.join(os.getcwd(), f"{input_basename}.tif")
        save_image(self.image_manager.image, input_path, "tiff", "16-bit", None, is_mono=False)

        # Output will have the same base name with `_GraXpert` suffix
        output_basename = f"{input_basename}_GraXpert"
        output_directory = os.getcwd()

        # Determine the platform-specific GraXpert command
        current_os = platform.system()
        if current_os == "Windows":
            graxpert_cmd = "GraXpert.exe"
        elif current_os == "Darwin":  # macOS
            graxpert_cmd = "/Applications/GraXpert.app/Contents/MacOS/GraXpert"
        elif current_os == "Linux":
            graxpert_cmd = self.get_graxpert_path()
            if not graxpert_cmd:
                return  # User cancelled
        else:
            QMessageBox.critical(self, "Unsupported OS", f"Unsupported operating system: {current_os}")
            return

        # Build the command
        command = [
            graxpert_cmd,
            "-cmd", "background-extraction",
            input_path,
            "-cli",
            "-smoothing", str(smoothing),
            "-gpu", "true"
        ]

        # Run the command
        self.run_graxpert_command(command, output_basename, output_directory)

    def get_graxpert_path(self):
        """Prompt user to select the GraXpert path on Linux and save it."""
        graxpert_path = self.settings.value("graxpert/path", type=str)

        if not graxpert_path or not os.path.exists(graxpert_path):
            QMessageBox.information(self, "GraXpert Path", "Please select the GraXpert executable.")

            graxpert_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select GraXpert Executable",
                "",
                "Executable Files (*)"

            )
            if not graxpert_path:
                QMessageBox.warning(self, "Cancelled", "GraXpert path selection was cancelled.")
                return None  # User cancelled
            if not os.access(graxpert_path, os.X_OK):
                try:
                    os.chmod(graxpert_path, 0o755)  # Add execute permissions
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                    return None

            # Save the path for future use
            self.settings.setValue("graxpert/path", graxpert_path)

        return graxpert_path



    def run_graxpert_command(self, command, output_basename, output_directory):
        """Execute GraXpert asynchronously."""
        dialog = QDialog(self)
        dialog.setWindowTitle("GraXpert Progress")
        dialog.setMinimumSize(600, 400)
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        layout.addWidget(text_edit)
        cancel_button = QPushButton("Cancel")
        layout.addWidget(cancel_button)

        thread = GraXpertThread(command)
        thread.stdout_signal.connect(text_edit.append)
        thread.stderr_signal.connect(text_edit.append)
        thread.finished_signal.connect(lambda code: self.on_graxpert_finished(code, output_basename, output_directory, dialog))
        cancel_button.clicked.connect(thread.terminate)

        thread.start()
        dialog.exec()

    def on_graxpert_finished(self, return_code, output_basename, output_directory, dialog):
        """Handle GraXpert process completion."""
        dialog.close()
        if return_code != 0:
            QMessageBox.critical(self, "Error", "GraXpert process failed.")
            return

        # Locate the output file with any extension
        output_file = None
        for ext in ["fits", "tif", "tiff", "png"]:
            candidate = os.path.join(output_directory, f"{output_basename}.{ext}")
            if os.path.exists(candidate):
                output_file = candidate
                break

        if not output_file:
            QMessageBox.critical(self, "Error", "GraXpert output file not found.")
            return

        # Load the processed image back
        processed_image, _, _, _ = load_image(output_file)

        # Check the number of dimensions to determine if the image is mono
        if processed_image.ndim == 2:
            print("GraXpert output is a mono image. Converting to RGB...")
            processed_image = np.stack([processed_image] * 3, axis=-1)

        # Set the processed image in the image manager
        self.image_manager.set_image(
            processed_image,
            {'file_path': output_file, 'description': "GraXpert Gradient Removed"}
        )

        QMessageBox.information(self, "Success", "Gradient removed successfully.")

    def recombine_luminance(self):
        """Recombines luminance from a selected slot with the RGB image from another selected slot."""
        
        # Define the available slot range
        available_slots = list(range(5))  # Slots 0-4
        
        # Initialize and display the custom dialog
        dialog = RecombineDialog(available_slots, self)
        if dialog.exec() != QDialog.DialogCode.Accepted:
            QMessageBox.information(self, "Operation Cancelled", "Recombination operation was cancelled.")
            return
        
        # Retrieve selections
        luminance_slot, rgb_slot = dialog.getSelections()
        
        # Retrieve the images from the selected slots
        luminance = self.image_manager._images[luminance_slot]
        original_rgb = self.image_manager._images[rgb_slot]
        
        # Validate the RGB image
        if original_rgb is None:
            QMessageBox.warning(self, "No Image", f"Slot {rgb_slot} does not contain an RGB image for recombination.")
            return
        if original_rgb.ndim != 3 or original_rgb.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", f"Slot {rgb_slot} must contain an RGB image for recombination.")
            return
        
        # Validate the luminance image
        if luminance is None:
            QMessageBox.warning(self, "No Luminance", f"Slot {luminance_slot} does not contain a luminance image for recombination.")
            return
        if luminance.ndim < 2:
            QMessageBox.warning(self, "Invalid Luminance Image", f"Slot {luminance_slot} must contain a 2D luminance image.")
            return
        
        # If luminance has more than one channel, use only the first channel
        if luminance.ndim == 3 and luminance.shape[2] > 1:
            QMessageBox.information(
                self,
                "Multiple Channels Detected",
                f"Luminance image in slot {luminance_slot} has multiple channels. Only the first channel will be used."
            )
            luminance = luminance[:, :, 0]
        elif luminance.ndim > 3:
            QMessageBox.warning(
                self,
                "Invalid Luminance Image",
                f"Luminance image in slot {luminance_slot} has unsupported number of dimensions."
            )
            return
        
        # Clip luminance to [0, 1] to ensure valid data
        luminance = np.clip(luminance, 0.0, 1.0)
        
        # Convert the RGB image to Lab color space
        lab_image = self.rgb_to_lab(original_rgb)
        
        # Replace the L* channel with the luminance
        lab_image[..., 0] = luminance * 100.0  # L* is scaled to [0, 100] in Lab
        
        # Convert the modified Lab image back to RGB color space
        updated_rgb = self.lab_to_rgb(lab_image)
        
        # Clip to [0, 1] to ensure valid RGB values
        updated_rgb = np.clip(updated_rgb, 0.0, 1.0)
        
        # Retrieve metadata from the RGB slot and update it
        metadata = self.image_manager._metadata[rgb_slot].copy()
        metadata['file_path'] = f"Luminance Recombined (Lum Slot: {luminance_slot}, RGB Slot: {rgb_slot})"
        
        # Update the selected RGB slot with the recombined image
        self.image_manager.set_image(updated_rgb, metadata)
        
        print(f"Recombined image updated in slot {rgb_slot} with luminance from slot {luminance_slot}.")
        


    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)


    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def swap_slots(self, slot_a, slot_b):
        """
        Swap images and metadata between two slots.
        
        :param slot_a: The first slot number.
        :param slot_b: The second slot number.
        """
        try:
            # Retrieve images and metadata from both slots
            image_a = self.image_manager._images.get(slot_a, None)
            metadata_a = self.image_manager._metadata.get(slot_a, {}).copy()
            
            image_b = self.image_manager._images.get(slot_b, None)
            metadata_b = self.image_manager._metadata.get(slot_b, {}).copy()
            
            # Swap the images and metadata
            self.image_manager._images[slot_a] = image_b
            self.image_manager._metadata[slot_a] = metadata_b
            
            self.image_manager._images[slot_b] = image_a
            self.image_manager._metadata[slot_b] = metadata_a
            
            # Emit image_changed signals for both slots
            self.image_manager.image_changed.emit(slot_a, image_b, metadata_b)
            self.image_manager.image_changed.emit(slot_b, image_a, metadata_a)
            
            print(f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            QMessageBox.information(self, "Success", f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to swap images between Slot {slot_a} and Slot {slot_b}: {e}")
            print(f"Error during swapping slots {slot_a} and {slot_b}: {e}")

    def copy_slot_to_target(self):
        """Copy from any source slot (Image or Mask) to any target slot (Image or Mask)."""
        # Open the enhanced CopySlotDialog
        dialog = CopySlotDialog(self, self.image_manager, self.mask_manager)
        result = dialog.exec()
        
        if result == QDialog.DialogCode.Accepted:
            # Retrieve selected source and target
            source_type, source_slot_num = dialog.get_selected_source()
            target_type, target_slot_num = dialog.get_selected_target()
            
            print(f"User selected to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            # Validate that source and target are not the same
            if source_type == target_type and source_slot_num == target_slot_num:
                QMessageBox.warning(self, "Invalid Operation", "Source and target slots are the same.")
                print("Source and target slots are identical. Operation aborted.")
                return
            
            # Retrieve source data
            try:
                if source_type == "Image":
                    source_image = self.image_manager._images.get(source_slot_num, None)
                    source_metadata = self.image_manager._metadata.get(source_slot_num, {}).copy()
                    if source_image is None:
                        QMessageBox.warning(self, "No Image", f"No image found in Image Slot {source_slot_num}.")
                        print(f"No image found in Image Slot {source_slot_num}.")
                        return
                elif source_type == "Mask":
                    source_image = self.mask_manager.get_mask(source_slot_num)
                    if source_image is None:
                        QMessageBox.warning(self, "No Mask", f"No mask found in Mask Slot {source_slot_num}.")
                        print(f"No mask found in Mask Slot {source_slot_num}.")
                        return
                    # Convert mask to grayscale if it's multi-channel
                    if source_image.ndim == 3:
                        source_image = cv2.cvtColor(source_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted multi-channel Mask Slot {source_slot_num} to grayscale.")
                    # Normalize mask to [0,1] if necessary
                    if source_image.max() > 1.0:
                        source_image = source_image.astype(np.float32) / 255.0
                        print(f"Normalized Mask Slot {source_slot_num} to [0,1].")
                    else:
                        source_image = source_image.astype(np.float32)
                        print(f"Mask Slot {source_slot_num} is already normalized.")
                    source_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Source Type", "Selected source type is invalid.")
                    print("Selected source type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve source data:\n{e}")
                print(f"Failed to retrieve source data: {e}")
                return
            
            # Retrieve target data
            try:
                if target_type == "Image":
                    target_image = self.image_manager._images.get(target_slot_num, None)
                    target_metadata = self.image_manager._metadata.get(target_slot_num, {}).copy()
                elif target_type == "Mask":
                    target_image = self.mask_manager.get_mask(target_slot_num)
                    target_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Target Type", "Selected target type is invalid.")
                    print("Selected target type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve target data:\n{e}")
                print(f"Failed to retrieve target data: {e}")
                return
            
            # Check if target slot is occupied
            try:
                if target_type == "Image":
                    is_occupied = self.image_manager._images.get(target_slot_num, None) is not None
                elif target_type == "Mask":
                    is_occupied = self.mask_manager.get_mask(target_slot_num) is not None
                else:
                    is_occupied = False
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to check target slot:\n{e}")
                print(f"Failed to check target slot: {e}")
                return
            
            if is_occupied:
                overwrite = QMessageBox.question(
                    self,
                    "Overwrite Confirmation",
                    f"{target_type} Slot {target_slot_num} already contains data. Do you want to overwrite it?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                    QMessageBox.StandardButton.No
                )
                if overwrite != QMessageBox.StandardButton.Yes:
                    QMessageBox.information(self, "Operation Cancelled", "Copy operation cancelled.")
                    print("User chose not to overwrite the target slot.")
                    return
            
            # Proceed with the copy operation
            try:
                # Save current state of the target slot to undo stack
                if is_occupied:
                    if target_type == "Image":
                        self.image_manager._undo_stacks[target_slot_num].append(
                            (self.image_manager._images[target_slot_num].copy(),
                            self.image_manager._metadata[target_slot_num].copy())
                        )
                    elif target_type == "Mask":
                        self.mask_manager._undo_stacks[target_slot_num].append(
                            (self.mask_manager.get_mask(target_slot_num).copy(),)
                        )
                    print(f"{target_type} Slot {target_slot_num} state saved to undo stack.")
            
            
                # Deep copy to prevent unintended modifications
                copied_image = source_image.copy()
                copied_metadata = source_metadata.copy()
            
                # If copying from a mask to an image slot, ensure grayscale and normalization
                if source_type == "Mask" and target_type == "Image":
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied mask to single-channel grayscale for Image Slot {target_slot_num}.")
                    # Ensure normalization to [0,1]
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied mask to [0,1] for Image Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied mask is already normalized for Image Slot {target_slot_num}.")
            
                # Assign to target slot
                if target_type == "Image":
                    # Ensure image is float32 normalized to [0,1]
                    if copied_image.dtype != np.float32 and copied_image.dtype != np.float64:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Converted copied image to float32 normalized [0,1] for Image Slot {target_slot_num}.")
                    self.image_manager._images[target_slot_num] = copied_image
                    self.image_manager._metadata[target_slot_num] = copied_metadata
                    # Emit image_changed signal
                    self.image_manager.image_changed.emit(target_slot_num, copied_image, copied_metadata)
                    print(f"Copied data assigned to Image Slot {target_slot_num}.")
                    self.update_slot_toolbar_highlight()
                elif target_type == "Mask":
                    # Ensure mask is single-channel and normalized
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied image to single-channel grayscale for Mask Slot {target_slot_num}.")
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied image to [0,1] for Mask Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied image is already normalized for Mask Slot {target_slot_num}.")
                    self.mask_manager.set_mask(target_slot_num, copied_image)
                    # Emit mask_changed signal if available
                    # Assuming MaskManager has a signal similar to image_changed
                    # self.mask_manager.mask_changed.emit(target_slot_num, copied_image)
                    print(f"Copied data assigned to Mask Slot {target_slot_num}.")
            
                QMessageBox.information(
                    self, 
                    "Copy Successful", 
                    f"{source_type} Slot {source_slot_num} successfully copied to {target_type} Slot {target_slot_num}."
                )
                print(f"Copy successful: {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            except Exception as e:
                QMessageBox.critical(
                    self, 
                    "Copy Failed", 
                    f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.\nError: {e}"
                )
                print(f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}. Error: {e}")
        else:
            print("Copy Slot operation cancelled by the user.")

    # --------------------
    # Slot Preview Methods
    # --------------------
    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified slot."""
        print(f"Attempting to open preview window for Slot {slot}. Current preview_windows: {self.preview_windows}")
        # Check if the slot index is valid
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        # Check if the slot has an image
        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview window for this slot already exists
        if slot in self.preview_windows:
            # If the window is already open, bring it to the front
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            print(f"Preview window for Slot {slot} is already open.")
            return

        # Create a new ImagePreview window with a copy of the image data
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)  # Pass parent=self


        # Store the reference to prevent garbage collection
        self.preview_windows[slot] = preview
        print(f"Stored preview window for Slot {slot} in preview_windows.")

        # Connect the custom closed signal to the on_preview_closed method
        preview.closed.connect(self.on_preview_closed)

        # Show the preview window
        preview.show()
        print(f"Opened preview window for Slot {slot}.")

    def on_preview_closed(self, slot):
        """Handles the cleanup when a preview window is closed."""
        if slot in self.preview_windows:
            del self.preview_windows[slot]
            print(f"Preview window for Slot {slot} has been closed and removed from tracking.")
        else:
            print(f"No preview window found for Slot {slot} to remove.")

    def on_image_changed(self, slot, image, metadata):
        """Update the file name in the status bar and refresh preview if open."""
        file_path = metadata.get('file_path', None)
        if file_path:
            self.file_name_label.setText(os.path.basename(file_path))  # Update the label with file name
            self.update_slot_toolbar_highlight()
        else:
            self.file_name_label.setText("No file selected")

        # If a preview window for this slot is open, update its image
        if slot in self.preview_windows:
            preview_window = self.preview_windows[slot]
            preview_window.update_image_data(image.copy())
            self.update_slot_toolbar_highlight()
            print(f"Preview window for Slot {slot} updated with new image.")

     

    def add_stars(self):
        """
        Opens the AddStarsDialog to configure and preview star additions.
        """
        try:
            print("Opening AddStarsDialog...")
            add_stars_dialog = AddStarsDialog(self.image_manager, parent=self)
            add_stars_dialog.stars_added.connect(self.receive_blended_image)
            add_stars_dialog.exec()  # Modal dialog
            print("AddStarsDialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to open AddStarsDialog:\n{e}")
            print(f"Failed to open AddStarsDialog: {e}")

    def receive_blended_image(self, blended_image):
        """
        Receives the blended image from AddStarsDialog and updates the current slot.
        """
        if blended_image is not None:
            current_slot = self.image_manager.current_slot

            # Prepare metadata
            current_metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            addition_note = "Stars added using AddStarsDialog."
            if 'notes' in current_metadata and isinstance(current_metadata['notes'], list):
                current_metadata['notes'].append(addition_note)
            else:
                current_metadata['notes'] = [addition_note]

            # Assign the blended image and metadata to the current slot
            self.image_manager.set_image(blended_image, current_metadata)

            # Emit the image_changed signal with all required arguments
            self.image_manager.image_changed.emit(current_slot, blended_image, current_metadata)

            QMessageBox.information(self, "Success", "Stars added successfully.")
            print("Stars added successfully.")


    def remove_stars(self):
        """
        Removes stars from the current image using StarNet and generates a stars-only image.
        Supports Windows, macOS, and Linux platforms.
        """
        # Refresh the StarNet executable path from preferences.
        self.starnet_exe_path = self.settings.value("starnet/exe_path", "")

        print("Starting star removal process...")

        # Step 1: Verify StarNet Executable Path
        if not self.starnet_exe_path:
            print("StarNet executable path not set. Prompting user to select executable.")
            self.select_starnet_exe()
            if not self.starnet_exe_path:
                print("User cancelled StarNet executable selection.")
                return  # User cancelled the selection
            else:
                print(f"StarNet executable selected: {self.starnet_exe_path}")
        else:
            print(f"Using existing StarNet executable path: {self.starnet_exe_path}")

        # Step 1.5: Check if the executable exists
        if not os.path.exists(self.starnet_exe_path):
            QMessageBox.critical(self, "StarNet Not Found",
                                f"StarNet executable not found at {self.starnet_exe_path}. Aborting star removal process.")
            print(f"StarNet executable not found: {self.starnet_exe_path}")
            return

        # Step 2: Ensure current image is loaded
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing stars.")
            print("No image loaded. Exiting star removal process.")
            return

        print("Image is loaded. Proceeding with star removal.")

        # Step 3: Determine the Operating System
        current_os = platform.system()
        print(f"Operating System detected: {current_os}")
        if current_os not in ["Windows", "Darwin", "Linux"]:
            QMessageBox.critical(self, "Unsupported OS",
                                f"The current operating system '{current_os}' is not supported.")
            print(f"Unsupported operating system: {current_os}")
            return

        # Step 4: Ask if the image is linear
        reply = QMessageBox.question(
            self,
            "Image Linearity",
            "Is the current image linear?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        
        if self.image_manager.image.ndim == 2 or (self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 1):
            print("Converting single-channel image to 3-channel RGB...")
            processing_image = np.stack([self.image_manager.image] * 3, axis=-1)
        else:
            processing_image = self.image_manager.image

        if reply == QMessageBox.StandardButton.Yes:
            print("Image is linear. Applying stretch.")
            dialog_msg = QMessageBox(self)
            dialog_msg.setWindowTitle("Stretching Image")
            dialog_msg.setText("Stretching the image for StarNet processing...")
            dialog_msg.setStandardButtons(QMessageBox.StandardButton.Ok)
            dialog_msg.exec()

            # Apply stretch
            stretched_image = self.stretch_image(processing_image)
            # Use stretched_image for processing
            processing_image = stretched_image
            print("Image stretched successfully.")
            self.image_was_stretched = True
        else:
            print("Image is not linear. Proceeding without stretching.")
            self.image_was_stretched = False

        # Step 4: Set Command Parameters Based on OS
        self.starnet_dir = os.path.dirname(self.starnet_exe_path)
        self.input_image_path = os.path.join(self.starnet_dir, "imagetoremovestars.tif")
        self.output_image_path = os.path.join(self.starnet_dir, "starless.tif")
        original_image = processing_image

        print(f"StarNet directory: {self.starnet_dir}")
        print(f"Input image path: {self.input_image_path}")
        print(f"Output image path: {self.output_image_path}")

        # Convert image from [0,1] to [0, 65535] for 16-bit TIFF
        image_16bit = (original_image * 65535).astype(np.uint16)
        # Convert RGB to BGR for OpenCV
        image_bgr_16bit = cv2.cvtColor(image_16bit, cv2.COLOR_RGB2BGR)
        cv2.imwrite(self.input_image_path, image_bgr_16bit)
        print(f"Input image saved at {self.input_image_path}")

        # Prepare the command based on the OS
        if current_os == "Windows":
            # Windows requires the stride parameter
            stride = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(stride)
            ]
            print("Preparing command for Windows.")
        elif current_os == "Linux":
            # Linux requires the stride parameter
            stride = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(stride)
            ]
            print("Preparing command for Linux.")
        elif current_os == "Darwin":
            executable_name = os.path.basename(self.starnet_exe_path).lower()
            if "starnet2" in executable_name:
                # Using StarNet2's flag-based interface for macOS
                command = [
                    self.starnet_exe_path,
                    "--input", self.input_image_path,
                    "--output", self.output_image_path
                ]
                print("Preparing command for macOS using StarNet2 arguments.")
            else:
                # Using the older StarNet++ style arguments
                command = [
                    self.starnet_exe_path,
                    self.input_image_path,
                    self.output_image_path
                ]
                print("Preparing command for macOS using StarNet++ arguments.")


        print(f"StarNet command: {' '.join(command)}")

        # Step 5: Ensure the StarNet Executable has Execute Permissions (for macOS and Linux)
        if current_os in ["Darwin", "Linux"]:
            if not os.access(self.starnet_exe_path, os.X_OK):
                print(f"StarNet executable not executable. Setting execute permissions for {self.starnet_exe_path}")
                try:
                    os.chmod(self.starnet_exe_path, 0o755)  # Add execute permissions
                    print("Execute permissions set.")
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error",
                                        f"Failed to set execute permissions for StarNet executable: {e}")
                    print(f"Failed to set execute permissions for {self.starnet_exe_path}: {e}")
                    return
            else:
                print("StarNet executable already has execute permissions.")
        else:
            print("No need to set execute permissions for Windows.")

        # Step 6: Initialize and Show StarNetDialog
        starnet_dialog = StarNetDialog()
        starnet_dialog.show()

        # Step 7: Initialize StarNetThread
        self.starnet_thread = StarNetThread(command, self.starnet_dir)
        self.starnet_thread.stdout_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.stderr_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.finished_signal.connect(lambda return_code: self.on_starnet_finished(return_code, starnet_dialog, self.output_image_path))

        # Handle cancellation
        starnet_dialog.cancel_button.clicked.connect(self.starnet_thread.stop)

        # Start the thread
        self.starnet_thread.start()

    def on_starnet_finished(self, return_code, dialog, output_image_path):
        """
        Handles the completion of the StarNet process.
        """
        dialog.append_text(f"\nProcess finished with return code {return_code}.\n")
        if return_code != 0:
            QMessageBox.critical(self, "StarNet Error", f"StarNet failed with return code {return_code}.")
            print(f"StarNet failed with return code {return_code}.")
            dialog.close()
            return

        # Step 8: Load the starless image
        if not os.path.exists(output_image_path):
            QMessageBox.critical(self, "StarNet Error", "Starless image was not created.")
            print(f"Starless image was not created at {output_image_path}.")
            dialog.close()
            return

        print(f"Starless image found at {output_image_path}. Loading image...")
        dialog.append_text(f"Starless image found at {output_image_path}. Loading image...\n")

        starless_bgr = cv2.imread(output_image_path, cv2.IMREAD_UNCHANGED)
        if starless_bgr is None:
            QMessageBox.critical(self, "StarNet Error", "Failed to load starless image.")
            print(f"Failed to load starless image from {output_image_path}.")
            dialog.close()
            return

        print("Starless image loaded successfully.")
        dialog.append_text("Starless image loaded successfully.\n")

        # Convert back to RGB and normalize to [0,1]
        starless_rgb = cv2.cvtColor(starless_bgr, cv2.COLOR_BGR2RGB).astype('float32') / 65535.0



        # Check and apply unstretch if necessary
        if getattr(self, 'image_was_stretched', False):
            print("Unstretching the starless image...")
            starless_rgb = self.unstretch_image(starless_rgb)
            print("Starless image unstretched successfully.")
            dialog.append_text("Starless image unstretched successfully.\n")
        else:
            print("Image was not stretched. Proceeding without unstretching.")
            dialog.append_text("Image was not stretched. Proceeding without unstretching.\n")

        # Convert image_manager.image to 3-channel if needed
        if starless_rgb.ndim == 2 or (starless_rgb.ndim == 3 and starless_rgb.shape[2] == 1):
            print("Converting single-channel original image to 3-channel RGB...")
            starless_rgb = np.stack([starless_rgb] * 3, axis=-1)
        else:
            starless_rgb = starless_rgb

        # Convert image_manager.image to 3-channel if needed
        if self.image_manager.image.ndim == 2 or (self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 1):
            print("Converting single-channel original image to 3-channel RGB...")
            original_image_rgb = np.stack([self.image_manager.image] * 3, axis=-1)
        else:
            original_image_rgb = self.image_manager.image            

        # Step 9: Generate Stars Only Image
        print("Generating stars-only image...")
        dialog.append_text("Generating stars-only image...\n")
        with np.errstate(divide='ignore', invalid='ignore'):
            stars_only = (original_image_rgb - starless_rgb) / (1.0 - starless_rgb)
            stars_only = np.nan_to_num(stars_only, nan=0.0, posinf=0.0, neginf=0.0)
        stars_only = np.clip(stars_only, 0.0, 1.0)
        print("Stars-only image generated.")
        dialog.append_text("Stars-only image generated.\n")

        # Step 10: Prompt user to save Stars Only Image
        working_dir = self.settings.value("working_directory", os.getcwd())
        save_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Stars Only Image",
            working_dir,  # Now using the working directory from preferences
            "TIFF Files (*.tif *.tiff);;PNG Files (*.png)"
        )

        if save_path:
            print(f"Saving stars-only image to {save_path}...")
            dialog.append_text(f"Saving stars-only image to {save_path}...\n")
            try:
                # Determine the format and bit depth based on the file extension
                _, ext = os.path.splitext(save_path)
                ext = ext.lower()
                if ext in ['.tif', '.tiff']:
                    original_format = 'tiff'
                    bit_depth = '16-bit'
                elif ext == '.png':
                    original_format = 'png'
                    bit_depth = '8-bit'
                else:
                    QMessageBox.warning(self, "Unsupported Format", f"The selected format '{ext}' is not supported.")
                    print(f"Unsupported file extension: {ext}")
                    dialog.append_text(f"Unsupported file extension: {ext}\n")
                    dialog.close()
                    return

                # Call the global save_image function
                save_image(
                    img_array=stars_only,
                    filename=save_path,
                    original_format=original_format,
                    bit_depth=bit_depth,
                    original_header=None,  # Pass actual header if available
                    is_mono=False,        # Set to True if image is monochrome
                    image_meta=None,      # Pass image metadata if needed
                    file_meta=None        # Pass file metadata if needed
                )
                QMessageBox.information(self, "Success", "Stars only image saved successfully.")
                print("Stars-only image saved successfully.")
                dialog.append_text("Stars-only image saved successfully.\n")
            except Exception as e:
                QMessageBox.critical(self, "Save Error", f"Failed to save stars only image:\n{e}")
                print(f"Failed to save stars only image: {e}")
                dialog.append_text(f"Failed to save stars only image: {e}\n")
        else:
            QMessageBox.warning(self, "Save Cancelled", "Stars only image was not saved.")
            print("User cancelled saving the stars-only image.")
            dialog.append_text("User cancelled saving the stars-only image.\n")

        # Step 11: Update ImageManager with Starless Image
        print("Updating ImageManager with the starless image.")
        dialog.append_text("Updating ImageManager with the starless image.\n")
        self.image_manager.set_image(
            starless_rgb,
            metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {})
        )
        QMessageBox.information(self, "Success", "Starless image updated successfully.")
        print("ImageManager updated with starless image.")
        dialog.append_text("ImageManager updated with starless image.\n")

        # Optional: Clean up temporary files
        try:
            print("Cleaning up temporary files...")
            dialog.append_text("Cleaning up temporary files...\n")
            if os.path.exists(self.input_image_path):
                os.remove(self.input_image_path)
                print(f"Deleted temporary input image at {self.input_image_path}.")
                dialog.append_text(f"Deleted temporary input image at {self.input_image_path}.\n")
            if os.path.exists(self.output_image_path):
                os.remove(self.output_image_path)
                print(f"Deleted temporary output image at {self.output_image_path}.")
                dialog.append_text(f"Deleted temporary output image at {self.output_image_path}.\n")
        except Exception as e:
            QMessageBox.warning(self, "Cleanup Warning", f"Failed to delete temporary files:\n{e}")
            print(f"Failed to delete temporary files: {e}")
            dialog.append_text(f"Failed to delete temporary files: {e}\n")

        dialog.close()
 
    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def select_starnet_exe(self):
        """
        Prompts the user to select the StarNet executable based on the operating system.
        Saves the path using QSettings for future use.
        """


        current_os = platform.system()

        if current_os == "Windows":
            filter_str = "Executable Files (*.exe)"
        elif current_os in ["Linux", "Darwin"]:
            # For Unix-based systems, executables may not have extensions
            filter_str = "All Executable Files (*)"
        else:
            QMessageBox.critical(self, "Unsupported OS", f"The current operating system '{current_os}' is not supported.")
            return

        exe_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select StarNet Executable",
            "",
            filter_str

        )
        if exe_path:
            # For Windows, ensure the file has .exe extension
            if current_os == "Windows" and not exe_path.lower().endswith('.exe'):
                QMessageBox.warning(self, "Invalid File", "Please select a valid .exe file for StarNet.")
                return
            # For Unix-based systems, optionally check if it's executable
            elif current_os in ["Linux", "Darwin"]:
                if not os.access(exe_path, os.X_OK):
                    reply = QMessageBox.question(
                        self,
                        "Set Execute Permissions",
                        "The selected file does not have execute permissions. Would you like to add them?",
                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                        QMessageBox.StandardButton.Yes
                    )
                    if reply == QMessageBox.StandardButton.Yes:
                        try:
                            os.chmod(exe_path, 0o755)
                        except Exception as e:
                            QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                            return
                    else:
                        QMessageBox.information(self, "Cancelled", "Execute permissions not set. Cannot proceed.")
                        return
            self.starnet_exe_path = exe_path
            # Save the path using QSettings
            self.settings.setValue("starnet/exe_path", self.starnet_exe_path)
            QMessageBox.information(self, "StarNet Executable Set", f"StarNet executable set to:\n{exe_path}")
        else:
            QMessageBox.information(self, "Cancelled", "StarNet executable selection was cancelled.")



    def open_clahe_dialog(self):
        """Opens the CLAHE dialog window."""
        dialog = CLAHEDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_morpho_dialog(self):
        """Opens the Morphological Operations dialog window."""
        dialog = MorphologyDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_whitebalance_dialog(self):
        """Opens the White Balance dialog window."""
        dialog = WhiteBalanceDialog(self.image_manager, self)
        dialog.exec()

    def open_background_neutralization_dialog(self):
        """Opens the Background Neutralization dialog window."""
        dialog = BackgroundNeutralizationDialog(self.image_manager, self)
        dialog.exec()

    def open_remove_green_dialog(self):
        """
        Opens the RemoveGreenDialog.
        """
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "No image loaded in the current slot.")
            return

        dialog = RemoveGreenDialog(
            image_manager=self.image_manager,
            mask_manager=self.mask_manager,
            parent=self
        )
        dialog.exec()


    def dragEnterEvent(self, event):
        """Handle the drag enter event."""
        # Check if the dragged content is a file
        if event.mimeData().hasUrls():
            event.accept()
        else:
            event.ignore()

    def dropEvent(self, event):
        """Handle the drop event."""
        # Get the file path from the dropped file
        file_path = event.mimeData().urls()[0].toLocalFile()
        
        # Check if the file is an image (you can customize this check as needed)
        if file_path.lower().endswith(('.png', '.tif', '.tiff', '.fits', '.xisf', '.fit', '.jpg', '.jpeg', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            try:
                # Load the image into ImageManager
                image, header, bit_depth, is_mono = load_image(file_path)
                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }
                self.image_manager.add_image(self.image_manager.current_slot, image, metadata)  # Make sure to specify the slot here
                print(f"Image {file_path} loaded successfully via drag and drop.")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {e}")
        else:
            QMessageBox.warning(self, "Invalid File", "Only image files are supported.")

    def update_file_name(self, slot, image, metadata):
        """Update the file name in the status bar."""
        file_path = metadata.get('file_path', None)
        
        if file_path:
            # Debugging: Print type and value of file_path
            print(f"DEBUG: file_path type: {type(file_path)}, value: {file_path}")
            
            # Check if file_path is a QLabel
            if isinstance(file_path, QLabel):
                # Extract text from QLabel
                file_path_str = file_path.text()
                print("WARNING: 'file_path' was a QLabel. Extracted text.")
            elif isinstance(file_path, (str, bytes, os.PathLike)):
                # Correct type
                file_path_str = file_path
            else:
                # Unsupported type
                file_path_str = "Invalid file path"
                QMessageBox.warning(
                    self,
                    "Invalid File Path",
                    f"The provided file path is invalid (type: {type(file_path)})."
                )
                print(f"WARNING: 'file_path' is of unsupported type: {type(file_path)}")
                self.file_name_label.setText(file_path_str)
                return  # Exit early since the path is invalid
            
            # Safely set the file name label
            try:
                base_name = os.path.basename(file_path_str)
                self.file_name_label.setText(base_name)
                print(f"File name updated to: {base_name}")
            except Exception as e:
                QMessageBox.critical(
                    self,
                    "Error Updating File Name",
                    f"An error occurred while updating the file name:\n{str(e)}"
                )
                print(f"ERROR: Failed to set file name label: {e}")
        else:
            self.file_name_label.setText("No file selected")
            print("No file path provided in metadata.")
        
        # If slot == 0 and we have a valid image, update dimensions
        if image is not None:
            # image should be a numpy array with shape (height, width[, channels])
            h, w = image.shape[:2]
            self.dim_label.setText(f"{w} x {h}")
            print(f"Image dimensions updated to: {w} x {h}")
        else:
            # If another slot changed or no image, set to "—"
            self.dim_label.setText("—")
            print("Image dimensions not updated.")       

    def apply_theme(self, theme):
        """Apply the selected theme to the application."""
        if theme == "light":
            self.current_theme = "light"
            light_stylesheet = """
            QWidget {
                background-color: #f0f0f0;
                color: #000000;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 2px;
            }
            QPushButton {
                background-color: #e0e0e0;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #d0d0d0;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #ffffff;
            }
            QTreeWidget {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
            }
            QHeaderView::section {
                background-color: #f0f0f0;
                color: #000000;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #cccccc; 
                background-color: #f0f0f0;
            }
            QTabBar::tab {
                background: #e0e0e0;
                color: #000000;
                padding: 5px;
                border: 1px solid #cccccc;
                border-bottom: none;  /* Avoid double border at bottom */
            }
            QTabBar::tab:selected {
                background: #d0d0d0;  /* Highlight for the active tab */
                border-color: #000000;
            }
            QTabBar::tab:hover {
                background: #c0c0c0;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;  /* Push unselected tabs down for better clarity */
            }
            QMenu {
                background-color: #f0f0f0;
                color: #000000;
            }
            QMenu::item:selected {
                background-color: #d0d0d0; 
                color: #000000;
            }            
            """
            self.setStyleSheet(light_stylesheet)

        elif theme == "dark":
            self.current_theme = "dark"
            dark_stylesheet = """
            QWidget {
                background-color: #2b2b2b;
                color: #dcdcdc;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 2px;
            }
            QPushButton {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #4a4a4a;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #3c3f41;
            }
            QTreeWidget {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
            }
            QHeaderView::section {
                background-color: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #5c5c5c; 
                background-color: #2b2b2b;
            }
            QTabBar::tab {
                background: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
                border: 1px solid #5c5c5c;
                border-bottom: none;  /* Avoid double border at bottom */
            }
            QTabBar::tab:selected {
                background: #4a4a4a;  /* Highlight for the active tab */
                border-color: #dcdcdc;
            }
            QTabBar::tab:hover {
                background: #505050;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;  /* Push unselected tabs down for better clarity */
            }
            QMenu {
                background-color: #2b2b2b;
                color: #dcdcdc;
            }
            QMenu::item:selected {
                background-color: #3a75c4;  /* Blue background for selected items */
                color: #ffffff;  /* White text color */
            }       
            """
            self.setStyleSheet(dark_stylesheet)

        # Update mask banner styling based on theme
        if self.mask_manager.get_applied_mask() is not None:
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
        else:
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")

    def open_image(self):
        default_dir = self.settings.value("working_directory", "")
        """Open an image and load it into the ImageManager."""
        file_path, _ = QFileDialog.getOpenFileName(self, "Open Image", default_dir, 
                                            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")

        if file_path:
            try:
                # Load the image into ImageManager
                image, header, bit_depth, is_mono = load_image(file_path)
                if image is not None:
                    print(f"DEBUG: Loaded image max value: {image.max()}")
                    print(f"DEBUG: Loaded image min value: {image.min()}")
                    print(f"DEBUG: Loaded image shape: {image.shape}")
                    print(f"DEBUG: Loaded image dtype: {image.dtype}")
                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }
                self.image_manager.add_image(self.image_manager.current_slot, image, metadata)  # Make sure to specify the slot here
                self.update_slot_toolbar_highlight()
                print(f"Image {file_path} loaded successfully.")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {e}")


    def save_image(self):
        """Save the current image to a selected path."""
        default_dir = self.settings.value("working_directory", "")
        if self.image_manager.image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
            )
            
            if save_file:
                try:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit', 'xisf', 'jpg', 'jpeg']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Define formats that do not require bit depth selection
                    no_bit_depth_formats = ['png', 'jpg', 'jpeg']

                    # Initialize bit_depth variable
                    bit_depth = None

                    if selected_format in no_bit_depth_formats:
                        # For PNG, JPG, JPEG, set bit depth to '8-bit' automatically
                        bit_depth = '8-bit'
                        print(f"Selected format '{selected_format}' does not require bit depth selection. Using bit depth: {bit_depth}.")
                    else:
                        # Prompt the user for bit depth selection for other formats
                        bit_depth, ok = QInputDialog.getItem(
                            self,
                            "Select Bit Depth",
                            "Choose bit depth for saving:",
                            ["16-bit", "32-bit floating point"],
                            0,
                            False
                        )
                        if not ok or not bit_depth:
                            QMessageBox.information(self, "Cancelled", "Save operation cancelled.")
                            print("Save operation cancelled by the user during bit depth selection.")
                            return

                    # Retrieve the image and metadata
                    image_data = self.image_manager.image
                    metadata = self.image_manager._metadata[self.image_manager.current_slot]
                    original_header = metadata.get('original_header', None)
                    is_mono = metadata.get('is_mono', False)

                    # Create a minimal header if the original header is missing and format is FITS
                    if original_header is None and selected_format in ['fits', 'fit']:
                        print("Creating a minimal FITS header for the data...")
                        original_header = self.create_minimal_fits_header(image_data, is_mono)

                    # Pass the image to the global save_image function
                    save_image(
                        img_array=image_data,
                        filename=save_file,
                        original_format=selected_format,
                        bit_depth=bit_depth,
                        original_header=original_header,
                        is_mono=is_mono
                    )
                    print(f"Image successfully saved to {save_file}.")

                    # Correctly access the status bar using the statusBar() method
                    self.statusBar.showMessage(f"Image saved to: {save_file}", 5000)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                    print(f"Error saving image: {e}")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded.")




    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header





    def undo_image(self):
        """Undo the last action."""
        if self.image_manager.can_undo():
            self.image_manager.undo()
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def redo_image(self):
        """Redo the last undone action."""
        if self.image_manager.can_redo():
            self.image_manager.redo()
            print("Redo performed.")
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")            


class AboutDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("About Seti Astro Suite")
        layout = QVBoxLayout()

        # Create a QLabel with rich text (HTML) for clickable links
        about_text = (
            f"<h2>Seti Astro's Suite {VERSION}</h2>"
            "<p>Written by Franklin Marek</p>"
            "<p>Website: <a href='http://www.setiastro.com'>www.setiastro.com</a></p>"
            "<p>Donations: <a href='https://www.setiastro.com/checkout/donate?donatePageId=65ae7e7bac20370d8c04c1ab'>Click here to donate</a></p>"
        )
        label = QLabel(about_text)
        label.setTextFormat(Qt.TextFormat.RichText)
        label.setTextInteractionFlags(Qt.TextInteractionFlag.TextBrowserInteraction)
        label.setOpenExternalLinks(True)
        
        layout.addWidget(label)
        self.setLayout(layout)

class RecombineDialog(QDialog):
    def __init__(self, available_slots, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Recombine Luminance and RGB Images")
        self.selected_lum_slot = None
        self.selected_rgb_slot = None
        self.initUI(available_slots)
    
    def initUI(self, available_slots):
        layout = QVBoxLayout()
        
        # Instruction Label
        instruction_label = QLabel("Select the slots for Luminance and RGB images:")
        layout.addWidget(instruction_label)
        
        # Luminance Slot Selection
        lum_layout = QHBoxLayout()
        lum_label = QLabel("Luminance Slot:")
        self.lum_combo = QComboBox()
        self.lum_combo.addItems([f"Slot {slot}" for slot in available_slots])
        lum_layout.addWidget(lum_label)
        lum_layout.addWidget(self.lum_combo)
        layout.addLayout(lum_layout)
        
        # RGB Slot Selection
        rgb_layout = QHBoxLayout()
        rgb_label = QLabel("RGB Slot:")
        self.rgb_combo = QComboBox()
        self.rgb_combo.addItems([f"Slot {slot}" for slot in available_slots])
        rgb_layout.addWidget(rgb_label)
        rgb_layout.addWidget(self.rgb_combo)
        layout.addLayout(rgb_layout)
        
        # Buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK")
        cancel_button = QPushButton("Cancel")
        ok_button.clicked.connect(self.validate_and_accept)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(ok_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)
        
        self.setLayout(layout)
    
    def validate_and_accept(self):
        """Ensure that the selected slots are different before accepting."""
        lum_slot = self.lum_combo.currentIndex()
        rgb_slot = self.rgb_combo.currentIndex()
        
        if lum_slot == rgb_slot:
            QMessageBox.warning(
                self,
                "Invalid Selection",
                "Luminance and RGB slots must be different. Please select distinct slots."
            )
            return
        self.selected_lum_slot = lum_slot
        self.selected_rgb_slot = rgb_slot
        self.accept()
    
    def getSelections(self):
        """Return the selected luminance and RGB slot numbers."""
        return self.selected_lum_slot, self.selected_rgb_slot


class CopySlotDialog(QDialog):
    def __init__(self, parent, image_manager, mask_manager):
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Copy Slot")
        self.initUI()
    
    def initUI(self):
        layout = QVBoxLayout()
        
        # Source Type Selection
        source_type_layout = QHBoxLayout()
        source_type_label = QLabel("Source Type:")
        self.source_type_combo = QComboBox()
        self.source_type_combo.addItems(["Image", "Mask"])
        self.source_type_combo.currentTextChanged.connect(self.update_source_slots)
        source_type_layout.addWidget(source_type_label)
        source_type_layout.addWidget(self.source_type_combo)
        layout.addLayout(source_type_layout)
        
        # Source Slot Selection
        source_slot_layout = QHBoxLayout()
        source_slot_label = QLabel("Source Slot:")
        self.source_slot_combo = QComboBox()
        source_slot_layout.addWidget(source_slot_label)
        source_slot_layout.addWidget(self.source_slot_combo)
        layout.addLayout(source_slot_layout)
        
        # Target Type Selection
        target_type_layout = QHBoxLayout()
        target_type_label = QLabel("Target Type:")
        self.target_type_combo = QComboBox()
        self.target_type_combo.addItems(["Image", "Mask"])
        self.target_type_combo.currentTextChanged.connect(self.update_target_slots)
        target_type_layout.addWidget(target_type_label)
        target_type_layout.addWidget(self.target_type_combo)
        layout.addLayout(target_type_layout)
        
        # Target Slot Selection
        target_slot_layout = QHBoxLayout()
        target_slot_label = QLabel("Target Slot:")
        self.target_slot_combo = QComboBox()
        target_slot_layout.addWidget(target_slot_label)
        target_slot_layout.addWidget(self.target_slot_combo)
        layout.addLayout(target_slot_layout)
        
        # Initialize slot selections
        self.update_source_slots(self.source_type_combo.currentText())
        self.update_target_slots(self.target_type_combo.currentText())
        
        # Dialog buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)
        
        self.setLayout(layout)
    
    def update_source_slots(self, source_type):
        self.source_slot_combo.clear()
        if source_type == "Image":
            # Use parent's custom names if available; fall back to default text if not.
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif source_type == "Mask":
            # For masks, we use default text (or you could create a similar renaming mechanism)
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.source_slot_combo.addItem(text, slot_number)
    
    def update_target_slots(self, target_type):
        self.target_slot_combo.clear()
        if target_type == "Image":
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif target_type == "Mask":
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.target_slot_combo.addItem(text, slot_number)
    
    def get_selected_source(self):
        source_type = self.source_type_combo.currentText()
        # Retrieve the slot number from the combo box item data.
        source_slot_num = self.source_slot_combo.currentData()
        return (source_type, source_slot_num)
    
    def get_selected_target(self):
        target_type = self.target_type_combo.currentText()
        target_slot_num = self.target_slot_combo.currentData()
        return (target_type, target_slot_num)
           
class CropTool(QDialog):
    """A cropping tool using QGraphicsView for better rectangle handling."""
    crop_applied = pyqtSignal(object)
    # Class-level variable to store the previous crop rectangle
    previous_crop_rect = None

    def __init__(self, image_manager, image_data, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Crop Tool")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowMaximizeButtonHint)
        self.setGeometry(100, 100, 800, 600)  # Initial size

        self.image_manager = image_manager
        self.original_image_data = image_data.copy()  # Keep a copy of the original image
        self.image_data = image_data  # Displayed image (can be autostretched)
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView(self.scene)
        self.pixmap_item = None

        self.origin = QPointF()
        self.current_rect = QRectF()
        self.selection_rect_item = None
        self.drawing = False

        # Set up the layout
        layout = QVBoxLayout()
        layout.addWidget(self.graphics_view)

        # Buttons
        self.autostretch_button = QPushButton("Toggle Autostretch")
        self.autostretch_button.clicked.connect(self.toggle_autostretch)
        layout.addWidget(self.autostretch_button)

        self.load_previous_button = QPushButton("Load Previous Crop")
        self.load_previous_button.clicked.connect(self.load_previous_crop)
        layout.addWidget(self.load_previous_button)

        self.crop_button = QPushButton("Apply Crop")
        self.crop_button.clicked.connect(self.apply_crop)
        layout.addWidget(self.crop_button)

        self.batch_crop_button = QPushButton("Batch Crop All Slots")
        self.batch_crop_button.clicked.connect(self.batch_crop_all_slots)
        layout.addWidget(self.batch_crop_button)

        self.setLayout(layout)

        # Load and display the image
        self.load_image()
        # Install the event filter on the QGraphicsView's viewport to handle drawing
        self.graphics_view.viewport().installEventFilter(self)

    def load_image(self):
        """Load and display the image in the QGraphicsView."""
        if len(self.image_data.shape) == 3:  # Color image
            height, width, channels = self.image_data.shape
            q_image = QImage(
                (self.image_data * 255).astype(np.uint8).tobytes(),
                width,
                height,
                3 * width,
                QImage.Format.Format_RGB888
            )
        elif len(self.image_data.shape) == 2:  # Mono image
            height, width = self.image_data.shape
            q_image = QImage(
                (self.image_data * 255).astype(np.uint8).tobytes(),
                width,
                height,
                width,
                QImage.Format.Format_Grayscale8
            )
        else:
            raise ValueError("Unsupported image format")

        pixmap = QPixmap.fromImage(q_image)
        self.pixmap_item = QGraphicsPixmapItem(pixmap)
        self.scene.clear()
        self.scene.addItem(self.pixmap_item)
        # Fit the image in view while keeping the aspect ratio.
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, event):
        """
        When the CropTool dialog is resized, re-fit the pixmap in the QGraphicsView.
        This ensures that mouse mapping via mapToScene works correctly on the resized view.
        """
        super().resizeEvent(event)
        if self.pixmap_item is not None:
            self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def batch_crop_all_slots(self):
        """Apply the current crop rectangle to all images in the ImageManager."""
        if self.current_rect.isNull():
            QMessageBox.warning(self, "No Selection", "Please draw a crop rectangle before applying batch cropping.")
            return

        # Calculate the number of images (slots with actual images)
        num_images = sum(1 for img in self.image_manager._images.values() if img is not None)
        if num_images == 0:
            QMessageBox.information(self, "No Images", "There are no images to crop.")
            return

        # Confirm the action with the user
        reply = QMessageBox.question(
            self,
            "Confirm Batch Crop",
            f"Are you sure you want to apply the current crop to all {num_images} images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply != QMessageBox.StandardButton.Yes:
            return  # User canceled the action

        # Get the crop rectangle in image coordinates
        scene_rect = self.scene.sceneRect()
        scale_x = self.original_image_data.shape[1] / scene_rect.width()
        scale_y = self.original_image_data.shape[0] / scene_rect.height()

        x = int(self.current_rect.left() * scale_x)
        y = int(self.current_rect.top() * scale_y)
        w = int(self.current_rect.width() * scale_x)
        h = int(self.current_rect.height() * scale_y)

        # Validate and adjust the crop rectangle
        x = max(0, min(x, self.original_image_data.shape[1] - 1))
        y = max(0, min(y, self.original_image_data.shape[0] - 1))
        w = max(1, min(w, self.original_image_data.shape[1] - x))
        h = max(1, min(h, self.original_image_data.shape[0] - y))

        # Flag to track if any image was cropped
        any_cropped = False

        # Iterate through all images and apply the crop
        for slot, img_data in self.image_manager._images.items():
            if img_data is not None:
                # Check if the crop rectangle is within the image bounds
                if y + h > img_data.shape[0] or x + w > img_data.shape[1]:
                    QMessageBox.warning(
                        self,
                        "Crop Out of Bounds",
                        f"Crop rectangle exceeds image dimensions for slot {slot}. Skipping this image."
                    )
                    continue

                # Save current state to undo stack
                self.image_manager._undo_stacks[slot].append(
                    (self.image_manager._images[slot].copy(), self.image_manager._metadata[slot].copy())
                )
                # Clear redo stack since new action invalidates the redo history
                self.image_manager._redo_stacks[slot].clear()
                print(f"ImageManager: Previous state of Slot {slot} pushed to undo stack.")

                # Apply the crop
                cropped_image = img_data[y:y + h, x:x + w]

                # Update the image data in the ImageManager
                self.image_manager._images[slot] = cropped_image

                # Emit the image_changed signal to notify other components
                self.image_manager.image_changed.emit(slot, cropped_image, self.image_manager._metadata[slot])
                print(f"ImageManager: Image in Slot {slot} cropped and updated.")

                any_cropped = True

        if any_cropped:
            QMessageBox.information(
                self,
                "Batch Crop Completed",
                f"Successfully cropped {num_images} images."
            )
            self.accept()
        else:
            QMessageBox.information(
                self,
                "Batch Crop",
                "No images were cropped."
            )


    def eventFilter(self, source, event):
        """Handle mouse events for drawing the cropping rectangle."""
        if source is self.graphics_view.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin = self.graphics_view.mapToScene(event.pos())
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                    pen = QPen(QColor(255, 0, 0), 5, Qt.PenStyle.DashLine)
                    self.selection_rect_item = self.scene.addRect(self.current_rect, pen)
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                    pen = QPen(QColor(0, 255, 0), 5, Qt.PenStyle.SolidLine)
                    self.selection_rect_item = self.scene.addRect(self.current_rect, pen)
        return super().eventFilter(source, event)

    def toggle_autostretch(self):
        """Apply autostretch for visualization purposes only."""
        stretched_image = None
        if len(self.original_image_data.shape) == 2:  # Mono image
            stretched_image = stretch_mono_image(self.original_image_data, target_median=0.5)
        elif len(self.original_image_data.shape) == 3:  # Color image
            stretched_image = stretch_color_image(self.original_image_data, target_median=0.5, linked=False)
        
        if stretched_image is not None:
            self.image_data = stretched_image
            saved_rect = self.current_rect if not self.current_rect.isNull() else None
            self.scene.clear()
            self.load_image()

            if saved_rect:
                pen = QPen(QColor(0, 255, 0), 5, Qt.PenStyle.SolidLine)
                self.selection_rect_item = self.scene.addRect(saved_rect, pen)

    def load_previous_crop(self):
        """Load the previous crop rectangle."""
        if CropTool.previous_crop_rect:
            self.current_rect = CropTool.previous_crop_rect
            if self.selection_rect_item:
                self.scene.removeItem(self.selection_rect_item)
            pen = QPen(QColor(0, 255, 0), 5, Qt.PenStyle.SolidLine)
            self.selection_rect_item = self.scene.addRect(self.current_rect, pen)
        else:
            QMessageBox.information(self, "No Previous Crop", "No previous crop rectangle is available.")

    def apply_crop(self):
        """Crop the original image based on the selected rectangle."""
        if not self.current_rect.isNull():
            # Save the current crop rectangle globally
            CropTool.previous_crop_rect = self.current_rect

            # Get the scene dimensions and scale accordingly
            scene_rect = self.scene.sceneRect()
            scale_x = self.original_image_data.shape[1] / scene_rect.width()
            scale_y = self.original_image_data.shape[0] / scene_rect.height()

            # Convert scene rectangle to image coordinates
            x = int(self.current_rect.left() * scale_x)
            y = int(self.current_rect.top() * scale_y)
            w = int(self.current_rect.width() * scale_x)
            h = int(self.current_rect.height() * scale_y)

            x = max(0, min(x, self.original_image_data.shape[1] - 1))
            y = max(0, min(y, self.original_image_data.shape[0] - 1))
            w = max(1, min(w, self.original_image_data.shape[1] - x))
            h = max(1, min(h, self.original_image_data.shape[0] - y))

            cropped_image = self.original_image_data[y:y + h, x:x + w]

            self.crop_applied.emit(cropped_image)
            self.accept()
        else:
            QMessageBox.warning(self, "No Selection", "Please draw a crop rectangle before applying.")

class ImageManager(QObject):
    """
    Manages multiple image slots with associated metadata and supports undo/redo operations for each slot.
    Emits a signal whenever an image or its metadata changes.
    """
    
    # Signal emitted when an image or its metadata changes.
    # Parameters:
    # - slot (int): The slot number.
    # - image (np.ndarray): The new image data.
    # - metadata (dict): Associated metadata for the image.
    image_changed = pyqtSignal(int, np.ndarray, dict)
    current_slot_changed = pyqtSignal(int)    

    def __init__(self, max_slots=5):
        """
        Initializes the ImageManager with a specified number of slots.
        
        :param max_slots: Maximum number of image slots to manage.
        """
        super().__init__()
        self.max_slots = max_slots
        self._images = {i: None for i in range(max_slots)}
        self._metadata = {i: {} for i in range(max_slots)}
        self._undo_stacks = {i: [] for i in range(max_slots)}
        self._redo_stacks = {i: [] for i in range(max_slots)}
        self.current_slot = 0  # Default to the first slot
        self.active_previews = {}  # Track active preview windows by slot
        self.mask_manager = MaskManager(max_slots)  # Add a MaskManager


    def get_current_image_and_metadata(self):
        slot = self.current_slot
        return self._images[slot], self._metadata[slot]

    def get_mask(self, slot=None):
        """
        Retrieves the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        :return: Mask as numpy array or None.
        """
        if slot is None:
            slot = self.current_slot
        return self.mask_manager.get_mask(slot)

    def set_mask(self, mask, slot=None):
        """
        Sets a mask for the current or specified slot.
        :param mask: Numpy array representing the mask.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.set_mask(slot, mask)

    def clear_mask(self, slot=None):
        """
        Clears the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.clear_mask(slot)        

    def set_current_slot(self, slot):
        if 0 <= slot < self.max_slots:
            self.current_slot = slot
            self.current_slot_changed.emit(slot)
            # Use a non-empty placeholder if the slot is empty
            image_to_emit = self._images[slot] if self._images[slot] is not None and self._images[slot].size > 0 else np.zeros((1, 1), dtype=np.uint8)
            self.image_changed.emit(slot, image_to_emit, self._metadata[slot])
            print(f"ImageManager: Current slot set to {slot}.")
        else:
            print(f"ImageManager: Slot {slot} is out of range.")


    def add_image(self, slot, image, metadata):
        """
        Adds an image and its metadata to a specified slot.
        
        :param slot: The slot number where the image will be added.
        :param image: The image data (numpy array).
        :param metadata: A dictionary containing metadata for the image.
        """
        if 0 <= slot < self.max_slots:
            self._images[slot] = image
            self._metadata[slot] = metadata
            # Clear undo/redo stacks when a new image is added
            self._undo_stacks[slot].clear()
            self._redo_stacks[slot].clear()
            self.current_slot = slot
            self.image_changed.emit(slot, image, metadata)
            print(f"ImageManager: Image added to slot {slot} with metadata.")
        else:
            print(f"ImageManager: Slot {slot} is out of range. Max slots: {self.max_slots}")

    def set_image(self, new_image, metadata):
        """
        Sets a new image and metadata for the current slot, adding the previous state to the undo stack.
        
        :param new_image: The new image data (numpy array).
        :param metadata: A dictionary containing metadata for the new image.
        """
        slot = self.current_slot
        if self._images[slot] is not None:
            # Save current state to undo stack
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
            # Clear redo stack since new action invalidates the redo history
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")
        self._images[slot] = new_image
        self._metadata[slot] = metadata
        self.image_changed.emit(slot, new_image, metadata)
        print(f"ImageManager: Image set for slot {slot} with new metadata.")

    @property
    def image(self):
        """
        Gets the image from the current slot.
        
        :return: The image data (numpy array) of the current slot.
        """
        return self._images[self.current_slot]

    @image.setter
    def image(self, new_image):
        """
        Sets a new image for the current slot, adding the previous state to the undo stack.
        
        :param new_image: The new image data (numpy array).
        """
        slot = self.current_slot
        if self._images[slot] is not None:
            # Save current state to undo stack
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
            # Clear redo stack since new action invalidates the redo history
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack via property setter.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack via property setter.")
        self._images[slot] = new_image
        self.image_changed.emit(slot, new_image, self._metadata[slot])
        print(f"ImageManager: Image set for slot {slot} via property setter.")

    def get_slot_name(self, slot):
        """
        Returns the display name for a given slot.
        If a slot has been renamed (stored under "slot_name" in metadata), that name is returned.
        Otherwise, it returns "Slot X" (using 1-indexed numbering for display).
        """
        metadata = self._metadata.get(slot, {})
        if 'slot_name' in metadata:
            return metadata['slot_name']
        else:
            return f"Slot {slot + 1}"


    def set_metadata(self, metadata):
        """
        Sets new metadata for the current slot, adding the previous state to the undo stack.
        
        :param metadata: A dictionary containing new metadata.
        """
        slot = self.current_slot
        if self._images[slot] is not None:
            # Save current state to undo stack
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
            # Clear redo stack since new action invalidates the redo history
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous metadata in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to set metadata.")
        self._metadata[slot] = metadata
        self.image_changed.emit(slot, self._images[slot], metadata)
        print(f"ImageManager: Metadata set for slot {slot}.")

    def update_image(self, updated_image, metadata=None, slot=None):
        if slot is None:
            slot = self.current_slot

        if slot == 1:
            print("Warning: Attempting to update reserved slot 1.")
            return  # Prevent overwriting slot 1 unless explicitly allowed

        self._images[slot] = updated_image
        if metadata:
            self._metadata[slot] = metadata
        self.image_changed.emit(slot, updated_image, metadata)

    def can_undo(self, slot=None):
        """
        Determines if there are actions available to undo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if undo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._undo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_undo.")
            return False

    def can_redo(self, slot=None):
        """
        Determines if there are actions available to redo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if redo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._redo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_redo.")
            return False

    def undo(self, slot=None):
        """
        Undoes the last change in the specified slot, restoring the previous image and metadata.
        
        :param slot: (Optional) The slot number to perform undo on. If None, uses current_slot.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            if self.can_undo(slot):
                # Save current state to redo stack
                self._redo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
                # Restore the last state from undo stack
                self._images[slot], self._metadata[slot] = self._undo_stacks[slot].pop()
                self.image_changed.emit(slot, self._images[slot], self._metadata[slot])
                print(f"ImageManager: Undo performed on slot {slot}.")
            else:
                print(f"ImageManager: No actions to undo in slot {slot}.")
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot perform undo.")

    def redo(self, slot=None):
        """
        Redoes the last undone change in the specified slot, restoring the image and metadata.
        
        :param slot: (Optional) The slot number to perform redo on. If None, uses current_slot.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            if self.can_redo(slot):
                # Save current state to undo stack
                self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
                # Restore the last state from redo stack
                self._images[slot], self._metadata[slot] = self._redo_stacks[slot].pop()
                self.image_changed.emit(slot, self._images[slot], self._metadata[slot])
                print(f"ImageManager: Redo performed on slot {slot}.")
            else:
                print(f"ImageManager: No actions to redo in slot {slot}.")
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot perform redo.")

class MaskManager(QObject):
    """
    Manages masks and tracks whether a mask is applied to the image.
    """
    mask_changed = pyqtSignal(int, np.ndarray)  # Signal to notify mask changes (slot, mask)
    applied_mask_changed = pyqtSignal(int, np.ndarray)  # Signal for applied mask updates

    def __init__(self, max_slots=5):
        super().__init__()
        self.max_slots = max_slots
        self._masks = {i: None for i in range(max_slots)}  # Store masks for each slot
        self.applied_mask_slot = None  # Slot from which the mask is applied
        self.applied_mask = None  # Currently applied mask (numpy array)

    def set_mask(self, slot, mask):
        """
        Sets the mask for a specific slot.
        """
        if 0 <= slot < self.max_slots:
            self._masks[slot] = mask
            self.mask_changed.emit(slot, mask)

    def get_mask(self, slot):
        """
        Retrieves the mask from a specific slot.
        """
        return self._masks.get(slot, None)

    def clear_applied_mask(self):
        """
        Clears the currently applied mask and emits an empty mask.
        """
        self.applied_mask_slot = None
        self.applied_mask = None

        # Emit an empty mask instead of None
        empty_mask = np.zeros((1, 1), dtype=np.uint8)  
        self.applied_mask_changed.emit(-1, empty_mask)  # Signal that no mask is applied

        print("Applied mask cleared.")



    def apply_mask_from_slot(self, slot):
        """
        Applies the mask from the specified slot.
        """
        if slot in self._masks and self._masks[slot] is not None:
            self.applied_mask_slot = slot
            self.applied_mask = self._masks[slot]
            self.applied_mask_changed.emit(slot, self.applied_mask)
            print(f"Mask from slot {slot} applied.")
        else:
            print(f"Mask from slot {slot} cannot be applied (empty).")

    def get_applied_mask(self):
        """
        Retrieves the currently applied mask.
        """
        return self.applied_mask

    def get_applied_mask_slot(self):
        """
        Retrieves the slot from which the currently applied mask originated.
        """
        return self.applied_mask_slot


class MaskSlotPreviewDialog(QDialog):
    """
    Dialog for displaying, zooming, inverting, and applying a mask from a specific slot with scroll bars.
    Automatically closes after saving the mask.
    """
    # Define a custom signal if needed (e.g., to notify the main window)
    mask_applied = pyqtSignal(int, np.ndarray)  # (slot, mask)

    def __init__(self, mask, slot, parent=None):
        super().__init__(parent)
        # If the parent has a 'mask_slot_names' dictionary, use it
        if parent is not None and hasattr(parent, 'mask_slot_names'):
            custom_name = parent.mask_slot_names.get(slot, f"Mask Slot {slot}")
        else:
            custom_name = f"Mask Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.mask = mask.copy()  # The mask to display (ensure a copy is made)
        self.slot = slot  # Mask slot number
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Store reference to the main window
        self.parent_window = parent

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)

        # Action buttons
        action_layout = QHBoxLayout()
        invert_button = QPushButton("Invert Mask")
        invert_button.clicked.connect(self.invert_mask)
        apply_button = QPushButton(f"Apply Mask from Slot {self.slot}")
        apply_button.clicked.connect(self.apply_mask)

        action_layout.addWidget(invert_button)
        action_layout.addWidget(apply_button)

        # Add action buttons to main layout
        main_layout.addLayout(action_layout)

        # Set the layout
        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods
    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def invert_mask(self):
        """
        Inverts the current mask and updates the display and mask slot,
        while preserving the current zoom and scroll positions.
        """
        reply = QMessageBox.question(
            self, 
            "Confirm Inversion", 
            "Are you sure you want to invert the mask?", 
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, 
            QMessageBox.StandardButton.No
        )
        if reply != QMessageBox.StandardButton.Yes:
            return

        try:
            # Invert the mask (assuming the mask is normalized between 0 and 1)
            inverted_mask = 1.0 - self.mask
            print("Mask inversion performed.")
            
            # Update the internal mask and create a new pixmap
            self.mask = inverted_mask.copy()
            self.pixmap = self.convert_to_pixmap(self.mask)
            
            # Call update_image() to rescale and reposition the image, preserving zoom/scroll.
            self.update_image()
            print("Mask display updated with inverted mask while preserving zoom and scroll positions.")
            
            QMessageBox.information(self, "Mask Inverted", "The mask has been successfully inverted.")
            
        except Exception as e:
            QMessageBox.critical(self, "Inversion Failed", f"Failed to invert the mask:\n{e}")
            print(f"Failed to invert the mask: {e}")


    def apply_mask(self):
        """
        Applies the current mask to the parent through the MaskManager.
        Automatically closes the dialog after successful application.
        """
        if not self.parent_window or not hasattr(self.parent_window, "mask_manager"):
            QMessageBox.warning(self, "Error", "Unable to apply mask: Mask Manager not found.")
            return

        # Apply mask from the given slot using apply_mask_from_slot to emit the correct signal
        try:
            self.parent_window.mask_manager.set_mask(self.slot, self.mask)
            self.parent_window.mask_manager.apply_mask_from_slot(self.slot)
            QMessageBox.information(self, "Mask Applied", f"Mask from Slot {self.slot} has been applied successfully.")
            # Emit the custom signal if connected
            self.mask_applied.emit(self.slot, self.mask.copy())
            self.accept()  # Close the dialog
            print(f"Mask from Slot {self.slot} applied and dialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Application Failed", f"Failed to apply mask:\n{e}")
            print(f"Failed to apply mask from Slot {self.slot}: {e}")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            # Schedule fit_to_window to be called after the dialog is fully shown
            QTimer.singleShot(0, self.fit_to_window)
            self.fitted = True

class MaskCreationDialog(QDialog):
    """
    Dialog for creating masks with various types and customizations.
    """

    def __init__(self, image, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Creation")
        self.image = image.copy()  # Original image
        self.mask = None
        self.drawing = False
        self.current_polygon = []
        self.exclusion_polygons = []  # List of drawn polygons
        self.scale_factor = 1.0

        # Initialize parameters
        self.mask_type = "Binary"
        self.blur_amount = 0

        # UI Components
        self.init_ui()

    def init_ui(self):
        # Main Layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Align with XISFViewer
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Image Preview within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.image_pixmap = self.convert_to_pixmap(self.image)
        self.image_label.setPixmap(self.image_pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Enable mouse event handling
        self.image_label.mousePressEvent = self.mouse_press_event
        self.image_label.mouseMoveEvent = self.mouse_move_event
        self.image_label.mouseReleaseEvent = self.mouse_release_event

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)



        # Zoom and Fit-to-Preview Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_preview_button = QPushButton("Fit to Preview")
        fit_to_preview_button.clicked.connect(self.fit_to_preview)
        select_entire_image_button = QPushButton("Select Entire Image")
        select_entire_image_button.clicked.connect(self.select_entire_image)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_preview_button)
        zoom_layout.addWidget(select_entire_image_button)

        # Mask Type Selection
        mask_type_label = QLabel("Select Mask Type:")
        self.mask_type_dropdown = QComboBox()
        self.mask_type_dropdown.addItems([
            "Binary", "Lightness", "Chrominance",
            "Color: Red", "Color: Orange", "Color: Yellow",
            "Color: Green", "Color: Cyan", "Color: Blue",
            "Color: Magenta"
        ])
        self.mask_type_dropdown.currentTextChanged.connect(self.update_mask_type)

        # Convolution Blur Slider
        blur_layout = QHBoxLayout()
        blur_label = QLabel("Convolution Blur Amount:")
        self.blur_slider = QSlider(Qt.Orientation.Horizontal)
        self.blur_slider.setRange(0, 150)
        self.blur_slider.setValue(0)
        self.blur_slider.valueChanged.connect(self.update_blur_amount)

        # Display the current blur amount
        self.blur_value_label = QLabel("0")  # Initialize with the default value
        self.blur_slider.valueChanged.connect(
            lambda value: self.blur_value_label.setText(str(value))
        )

        blur_layout.addWidget(blur_label)
        blur_layout.addWidget(self.blur_slider)
        blur_layout.addWidget(self.blur_value_label)

        # Buttons
        buttons_layout = QHBoxLayout()
        preview_button = QPushButton("Preview Mask")
        preview_button.clicked.connect(self.preview_mask)

        clear_button = QPushButton("Clear Drawings")
        clear_button.clicked.connect(self.clear_exclusion_areas)

        buttons_layout.addWidget(preview_button)

        buttons_layout.addWidget(clear_button)

        # Add Components to Layout
        controls_layout = QVBoxLayout()
        controls_layout.addWidget(mask_type_label)
        controls_layout.addWidget(self.mask_type_dropdown)
        controls_layout.addLayout(blur_layout)
        controls_layout.addWidget(self.blur_slider)
        controls_layout.addLayout(buttons_layout)

        main_layout.addLayout(zoom_layout)
        main_layout.addLayout(controls_layout)

        self.setLayout(main_layout)
        self.setMinimumSize(800, 500)

    def convert_to_pixmap(self, image):
        """
        Converts a numpy array to QPixmap for display.
        """
        if image.ndim == 3:  # RGB
            h, w, c = image.shape
            image = (image * 255).astype(np.uint8)
            q_image = QImage(image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:  # Grayscale
            h, w = image.shape
            image = (image * 255).astype(np.uint8)
            q_image = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        return QPixmap.fromImage(q_image)

    # Mouse Events for Drawing
    def mouse_press_event(self, event):
        """
        Handles the mouse press event to initiate drawing.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.drawing = True
            adjusted_pos = self.get_adjusted_position(event.pos())
            self.current_polygon = [adjusted_pos]
            self.update_selection()

    def mouse_move_event(self, event):
        """
        Handles the mouse move event to update the current polygon being drawn.
        """
        if self.drawing:
            adjusted_pos = self.get_adjusted_position(event.pos())
            self.current_polygon.append(adjusted_pos)
            self.update_selection()

    def mouse_release_event(self, event):
        """
        Handles the mouse release event to finalize the polygon.
        """
        if event.button() == Qt.MouseButton.LeftButton and self.drawing:
            self.drawing = False
            adjusted_polygon = QPolygon(self.current_polygon)
            self.exclusion_polygons.append(adjusted_polygon)
            self.current_polygon = []
            self.update_selection()

    def select_entire_image(self):
        """
        Selects the entire image as the mask region.
        """
        self.clear_exclusion_areas()  # Clear existing exclusion areas
        height, width = self.image.shape[:2]
        self.exclusion_polygons.append(
            QPolygon([
                QPoint(0, 0),
                QPoint(width - 1, 0),
                QPoint(width - 1, height - 1),
                QPoint(0, height - 1)
            ])
        )
        self.update_selection()

    def update_selection(self):
        """
        Updates the pixmap with all finalized polygons and the current polygon being drawn,
        preserving the current zoom level.
        """
        # Start with the original pixmap scaled by the current zoom level
        scaled_pixmap = self.image_pixmap.scaled(
            self.image_pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.pixmap = scaled_pixmap.copy()

        painter = QPainter(self.pixmap)

        # Draw all finalized exclusion polygons in semi-transparent green
        pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.SolidLine)
        brush = QColor(0, 255, 0, 50)  # Semi-transparent green
        painter.setPen(pen)
        painter.setBrush(brush)
        for polygon in self.exclusion_polygons:
            # Scale polygon points according to zoom
            scaled_polygon = QPolygon(
                [QPoint(int(point.x() * self.scale_factor), int(point.y() * self.scale_factor)) for point in polygon]
            )
            painter.drawPolygon(scaled_polygon)

        # If currently drawing, draw the current polygon outline in red
        if self.drawing and len(self.current_polygon) > 1:
            pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.setBrush(Qt.BrushStyle.NoBrush)
            scaled_current_polygon = QPolygon(
                [QPoint(int(point.x() * self.scale_factor), int(point.y() * self.scale_factor)) for point in self.current_polygon]
            )
            painter.drawPolyline(scaled_current_polygon)

        painter.end()
        self.image_label.setPixmap(self.pixmap)


    def clear_exclusion_areas(self):
        """
        Clears all drawn exclusion polygons and updates the preview.
        """
        self.exclusion_polygons = []
        self.current_polygon = []
        self.update_selection()

    def update_mask_type(self, mask_type):
        """
        Updates the selected mask type.
        """
        self.mask_type = mask_type

    def update_blur_amount(self, value):
        """
        Updates the blur amount.
        """
        self.blur_amount = value


    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to File", "Save to Mask Slot"],
            0,
            False
        )

        if not ok:  # User canceled the dialog
            return

        if choice == "Save to File":
            # Save to a file
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                save_image(self.mask, filename)
        elif choice == "Save to Mask Slot":
            # Save to a mask slot
            slot, ok = QInputDialog.getInt(
                self,
                "Save to Mask Slot",
                f"Enter slot number (0-{self.parent().mask_manager.max_slots - 1}):",
                0,
                0,
                self.parent().mask_manager.max_slots - 1,
            )
            if ok:
                self.parent().mask_manager.set_mask(slot, self.mask)

    def apply_mask(self):
        """
        Applies the current mask to the parent.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to apply.")
            return
        self.parent().mask_manager.set_mask(0, self.mask)

    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        # Convert the mask to an 8-bit image for display
        mask_8bit = (mask * 255).astype(np.uint8)
        q_image = QImage(
            mask_8bit.data,
            mask_8bit.shape[1],
            mask_8bit.shape[0],
            mask_8bit.strides[0],
            QImage.Format_Grayscale8
        )
        mask_pixmap = QPixmap.fromImage(q_image)
        self.image_label.setPixmap(mask_pixmap)

    # Mask Generation and Preview
    def generate_mask(self):
        """
        Generates a mask based on the current settings and exclusion areas.
        """
        height, width = self.image.shape[:2]
        mask = np.zeros((height, width), dtype=np.float32)  # Start with an empty mask

        # Create the exclusion mask
        exclusion_mask = self.create_exclusion_mask(self.image.shape, self.exclusion_polygons)

        # Apply mask type
        if self.mask_type == "Binary":
            mask[exclusion_mask] = 1.0  # Binary mask for exclusion areas
        elif self.mask_type == "Lightness":
            lightness_mask = self.generate_lightness_mask()
            mask[exclusion_mask] = lightness_mask[exclusion_mask]
        elif self.mask_type == "Chrominance":
            chrominance_mask = self.generate_chrominance_mask()
            mask[exclusion_mask] = chrominance_mask[exclusion_mask]
        elif self.mask_type.startswith("Color:"):
            color = self.mask_type.split(":")[1].strip()
            color_mask = self.generate_color_mask(color)
            mask[exclusion_mask] = color_mask[exclusion_mask]

        # Apply convolution blur if specified
        if self.blur_amount > 0:
            kernel_size = self.blur_amount * 2 + 1  # Ensure kernel size is odd
            mask = cv2.GaussianBlur(mask, (kernel_size, kernel_size), 0)

        # Normalize the mask to [0, 1] for visualization
        mask = np.clip(mask, 0, 1)
        return mask
    
    def preview_mask(self):
        """
        Previews the mask with the current settings in a new window.
        """
        if not self.exclusion_polygons:
            QMessageBox.warning(self, "No Exclusions", "No exclusion areas have been drawn.")
            return

        # Generate the mask
        mask = self.generate_mask()
        if mask is not None:
            self.mask = mask
            # Open the mask in a new preview dialog
            preview_dialog = MaskPreviewDialog(self.mask, self)
            preview_dialog.exec()
        else:
            QMessageBox.warning(self, "Mask Generation Failed", "Failed to generate the mask.")


    # Mask Creation and Generation Helpers
    def get_adjusted_position(self, event_pos):
        """
        Adjusts the mouse position based on the current zoom level.

        Args:
            event_pos: The position of the mouse event (QPointF).

        Returns:
            QPoint: Adjusted position.
        """
        # Calculate the position relative to the pixmap without adding scroll offsets
        adjusted_x = event_pos.x() / self.scale_factor
        adjusted_y = event_pos.y() / self.scale_factor

        return QPoint(int(adjusted_x), int(adjusted_y))


    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with True in exclusion areas and False elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                x_original = point.x()
                y_original = point.y()
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Fill polygons
        cv2.fillPoly(mask, polygons, 1)  # Fill the polygons with 1
        return mask.astype(bool)
    
    def generate_lightness_mask(self):
        """
        Generates a lightness mask based on the luminance of the image.
        """
        if self.image.ndim == 3:  # RGB image
            luminance = np.dot(self.image[..., :3], [0.2989, 0.5870, 0.1140])
            return luminance
        else:
            return self.image  # Grayscale image

    def generate_color_mask(self, color):
        """
        Generates a mask for a specific color range using the HSL color model.

        Args:
            color: The name of the color (e.g., "Red", "Orange", "Yellow", etc.).
        
        Returns:
            A mask for the selected color range.
        """
        # Define color ranges in HSL (Hue in degrees)
        color_ranges = {
            "Red": [(0, 10), (350, 360)],  # Red spans from 0-10 and 350-360 degrees
            "Orange": [(10, 40)],
            "Yellow": [(40, 70)],
            "Green": [(70, 170)],
            "Cyan": [(170, 200)],
            "Blue": [(200, 270)],
            "Magenta": [(270, 350)],
        }

        if color not in color_ranges:
            QMessageBox.warning(self, "Invalid Color", f"Color '{color}' is not supported.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

        if self.image.ndim == 3:  # RGB image
            # Convert RGB to HSL
            rgb_image = (self.image * 255).astype(np.uint8)
            hsl_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HLS)

            # Extract the Hue channel
            hue = hsl_image[:, :, 0].astype(np.float32)  # Hue is the first channel in OpenCV HLS

            # Normalize hue to [0, 360] for calculations
            hue = (hue / 180) * 360

            # Create the mask for the selected color range
            mask = np.zeros_like(hue, dtype=np.float32)
            for hue_range in color_ranges[color]:
                lower, upper = hue_range
                if lower < upper:
                    mask = np.maximum(mask, ((hue >= lower) & (hue <= upper)).astype(np.float32))
                else:  # Handle wraparound for red (e.g., 350-360 and 0-10)
                    mask = np.maximum(mask, ((hue >= lower) | (hue <= upper)).astype(np.float32))

            return mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Color mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

    def generate_chrominance_mask(self):
        """
        Generates a chrominance mask based on the chroma components of the image.
        """
        if self.image.ndim == 3:  # RGB image
            # Convert RGB to YCbCr color space
            rgb_image = (self.image * 255).astype(np.uint8)
            ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)

            # Extract the Cb and Cr channels
            cb = ycbcr_image[:, :, 1].astype(np.float32) / 255.0
            cr = ycbcr_image[:, :, 2].astype(np.float32) / 255.0

            # Compute the chrominance mask as the sum of the absolute differences from the mean
            cb_mean = np.mean(cb)
            cr_mean = np.mean(cr)
            chrominance_mask = np.sqrt((cb - cb_mean) ** 2 + (cr - cr_mean) ** 2)

            # Normalize the mask to [0, 1] range
            chrominance_mask = (chrominance_mask - np.min(chrominance_mask)) / (
                np.max(chrominance_mask) - np.min(chrominance_mask)
            )
            return chrominance_mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Chrominance mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)


    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        mask_pixmap = self.convert_to_pixmap(mask)
        self.image_label.setPixmap(mask_pixmap)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    # Zoom Methods
    def zoom_in(self):
        """Zoom in on the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    def zoom_out(self):
        """Zoom out of the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_preview(self):
        """Fit the image to the preview area."""
        # Calculate the required scale factor to fit the image within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        img_width = self.image_pixmap.width()
        img_height = self.image_pixmap.height()

        scale_w = viewport_size.width() / img_width
        scale_h = viewport_size.height() / img_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.convert_to_pixmap(self.image).scaled(
            self.image_pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

        # Redraw polygons with the new scale
        self.update_selection()



class MaskPreviewDialog(QDialog):
    """
    Dialog for displaying and zooming the mask with scroll bars.
    """
    
    def __init__(self, mask, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Preview")
        self.mask = mask.copy()  # Ensure a copy is made to prevent unintended side effects
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)
        save_mask_button = QPushButton("Save Mask")
        save_mask_button.clicked.connect(self.save_mask)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)
        main_layout.addWidget(save_mask_button)

        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods
    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to Mask Slot", "Save to File"],
            0,
            False
        )
        if not ok:
            return

        if choice == "Save to File":
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                self.save_image(self.mask, filename)
                QMessageBox.information(self, "Mask Saved", f"Mask saved to {filename}.")
                self.accept()
        elif choice == "Save to Mask Slot":
            # Traverse parent hierarchy until we find the main window with a mask_manager.
            parent = self.parent()
            while parent and not hasattr(parent, 'mask_manager'):
                parent = parent.parent()
            if parent and hasattr(parent, 'mask_manager'):
                slot, ok = QInputDialog.getInt(
                    self,
                    "Save to Mask Slot",
                    f"Enter slot number (0-{parent.mask_manager.max_slots - 1}):",
                    0,
                    0,
                    parent.mask_manager.max_slots - 1,
                )
                if ok:
                    parent.mask_manager.set_mask(slot, self.mask)
                    # ** Update the mask slot toolbar so that the button for this slot shows a blue border **
                    if hasattr(parent, 'update_mask_slot_toolbar_highlight'):
                        parent.update_mask_slot_toolbar_highlight()
                    QMessageBox.information(self, "Mask Saved", f"Mask saved to Slot {slot}.")
                    self.accept()
            else:
                QMessageBox.warning(self, "No Mask Manager", "Parent does not have a mask_manager.")


    def save_image(self, mask, filename):
        """
        Saves the mask to a file.
        """
        # Convert mask to 8-bit for saving
        mask_8bit = (mask * 255).astype(np.uint8)
        # Save using QPixmap
        pixmap = self.convert_to_pixmap(mask)
        pixmap.save(filename)
        print(f"Mask saved to {filename}.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            self.fit_to_window()
            self.fitted = True

class MaskDisplayWindow(QDialog):
    """
    A separate window to display the luminance mask for debugging purposes.
    Includes Zoom In, Zoom Out, and Fit to Preview controls.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Luminance Mask")
        self.setMinimumSize(300, 300)

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the mask display area (QGraphicsView in a scrollable region)
        self._create_mask_display_area()

        # 2) Create the zoom controls
        self._create_zoom_controls()

    # -------------------------------------------------------------------------
    # 1) MASK DISPLAY AREA
    # -------------------------------------------------------------------------
    def _create_mask_display_area(self):
        """Create a QGraphicsView & QGraphicsScene for the mask display."""
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        # Add the graphics view to the main layout
        self.main_layout.addWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) ZOOM CONTROLS
    # -------------------------------------------------------------------------
    def _create_zoom_controls(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_controls_group = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_controls_group.setLayout(zoom_layout)

        # Add the zoom controls to the main layout
        self.main_layout.addWidget(self.zoom_controls_group)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def _zoom_in(self):
        """Zoom in the mask display."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed in to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")
            print("MaskDisplayWindow: Maximum zoom level reached.")

    def _zoom_out(self):
        """Zoom out the mask display."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed out to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")
            print("MaskDisplayWindow: Minimum zoom level reached.")

    def _fit_to_preview(self):
        """Fit the entire mask within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No mask to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0
        print("MaskDisplayWindow: Fitted mask to preview and reset zoom factor to 1.0.")

    def _apply_zoom(self):
        """Apply the current zoom factor to the graphics view."""
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)
        print(f"MaskDisplayWindow: Applied zoom factor of {self.zoom_factor}x.")

    # -------------------------------------------------------------------------
    # MASK UPDATE METHOD
    # -------------------------------------------------------------------------
    def update_mask(self, mask_array):
        """
        Update the mask display with the given mask array.
        
        Args:
            mask_array (np.ndarray): 2D array with values in [0, 1].
        """
        try:
            # Convert mask array to grayscale image [0..255]
            mask_uint8 = (np.clip(mask_array, 0, 1) * 255).astype(np.uint8)

            # Ensure it's single-channel
            if mask_uint8.ndim == 3 and mask_uint8.shape[2] == 3:
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)
            elif mask_uint8.ndim == 2:
                pass  # Already single-channel
            else:
                # Handle unexpected formats
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)

            # Convert to QImage
            h, w = mask_uint8.shape[:2]
            qimage = QImage(
                mask_uint8.data, w, h, w, QImage.Format.Format_Grayscale8
            )
            pixmap = QPixmap.fromImage(qimage)

            # Update the pixmap item
            self.pixmap_item.setPixmap(pixmap)
            self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

            # Reset zoom to fit the new mask
            self._fit_to_preview()

            print("MaskDisplayWindow: Mask updated and fitted to preview.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")
            print(f"MaskDisplayWindow: Error updating mask - {e}")

class HistogramDialog(QDialog):
    def __init__(self, image, parent=None):
        """
        Initialize the histogram dialog.

        Args:
            image (np.ndarray): The image array (either grayscale or RGB).
                                  Pixel values are expected to be in [0, 1].
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Histogram")
        self.image = image  # The image from which to compute the histogram.
        self.zoom_factor = 1.0  # 1.0 means 100%
        self.log_scale = False  # Default: linear x-axis
        self.initUI()

    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Create a top-level horizontal layout to hold the histogram and the statistics table.
        top_layout = QHBoxLayout()

        # Create a scroll area for the histogram display.
        self.scroll_area = QScrollArea(self)
        # Set a fixed size for the scroll area so the dialog doesn't expand.
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        
        # Create the histogram label that will be placed inside the scroll area.
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)

        # Create the statistics table.
        self.stats_table = QTableWidget(self)
        # We will update the number of columns in updateStatistics() based on image channels.
        self.stats_table.setRowCount(4)  # Min, Max, Median, StdDev
        self.stats_table.setColumnCount(1)  # Default to 1 column for mono; update later if RGB.
        # Set row headers.
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        # Fix the width of the table.
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)
        
        # Add the top_layout to the main layout.
        main_layout.addLayout(top_layout)
        
        # Controls layout: zoom slider and log toggle button.
        controls_layout = QHBoxLayout()
        
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)  # 50% to 1000%
        self.zoom_slider.setValue(100)       # Default 100%
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(QLabel("Zoom:"))
        controls_layout.addWidget(self.zoom_slider)
        
        # Toggle button for log x-axis.
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis scaling.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)
        
        main_layout.addLayout(controls_layout)

        # Add a Close button.
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        self.drawHistogram()

    def updateHistogram(self, new_image):
        """
        Update the histogram with a new image.
        """
        self.image = new_image
        self.drawHistogram()

    def updateZoom(self, value):
        self.zoom_factor = value / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked):
        self.log_scale = checked
        self.drawHistogram()

    def drawHistogram(self):
        """
        Computes and draws the histogram.
        In linear mode, it uses equally spaced bins.
        In log mode, it uses logarithmically spaced bins (with a small epsilon to avoid log(0)).
        Also draws an x-axis with tick marks and labels.
        """
        # Base dimensions.
        base_width = 512
        height = 300
        width = int(base_width * self.zoom_factor)
        
        # Create a pixmap with the computed dimensions.
        pixmap = QPixmap(width, height)
        pixmap.fill(Qt.GlobalColor.white)
        painter = QPainter(pixmap)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        bin_count = 512
        
        # Choose bin edges based on the log_scale toggle.
        if self.log_scale:
            eps = 1e-4  # Cannot start at 0 for log scale.
            bin_edges = np.logspace(np.log10(eps), 0, bin_count + 1)
            log_min = np.log10(eps)
            log_max = 0  # log10(1)=0
            def x_pos(edge):
                return int((np.log10(edge) - log_min) / (log_max - log_min) * width)
        else:
            bin_edges = np.linspace(0, 1, bin_count + 1)
            def x_pos(edge):
                return int(edge * width)
        
        # Draw histogram bars.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # For RGB images, draw each channel histogram.
            channel_colors = [
                QColor(255, 0, 0, 120),
                QColor(0, 255, 0, 120),
                QColor(0, 0, 255, 120)
            ]
            for ch in range(3):
                hist, _ = np.histogram(self.image[..., ch].ravel(), bins=bin_edges)
                if hist.max() > 0:
                    hist = hist.astype(np.float32) / hist.max()
                else:
                    hist = hist.astype(np.float32)
                painter.setPen(QPen(channel_colors[ch]))
                for i in range(bin_count):
                    x0 = x_pos(bin_edges[i])
                    x1 = x_pos(bin_edges[i+1])
                    bar_width = x1 - x0
                    bar_height = hist[i] * height
                    painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        else:
            # Mono: if image is 3D with one channel, squeeze.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                gray = self.image.squeeze()
            else:
                gray = self.image
            hist, _ = np.histogram(gray.ravel(), bins=bin_edges)
            if hist.max() > 0:
                hist = hist.astype(np.float32) / hist.max()
            else:
                hist = hist.astype(np.float32)
            painter.setPen(QPen(QColor(0, 0, 0)))
            for i in range(bin_count):
                x0 = x_pos(bin_edges[i])
                x1 = x_pos(bin_edges[i+1])
                bar_width = x1 - x0
                bar_height = hist[i] * height
                painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        
        # Draw x-axis.
        painter.setPen(QPen(QColor(0, 0, 0), 2))
        painter.drawLine(0, height - 1, width, height - 1)
        
        # Draw tick marks and labels.
        painter.setFont(QFont("Arial", 10))
        if self.log_scale:
            tick_values = np.logspace(np.log10(eps), 0, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.3f}")
        else:
            tick_values = np.linspace(0, 1, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.1f}")
        
        painter.end()
        self.hist_label.setPixmap(pixmap)
        self.hist_label.resize(pixmap.size())
        
        # Update the statistics table.
        self.updateStatistics()

    def updateStatistics(self):
        """
        Computes statistics for the current image and updates the table.
        For an RGB image, computes per-channel min, max, median, and standard deviation.
        For a mono image, computes statistics for the first channel.
        """
        # Determine if the image is color or mono.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # Color image: 3 columns.
            self.stats_table.setColumnCount(3)
            self.stats_table.setHorizontalHeaderLabels(["R", "G", "B"])
            channels = [self.image[..., i] for i in range(3)]
        else:
            # Mono: 1 column.
            self.stats_table.setColumnCount(1)
            self.stats_table.setHorizontalHeaderLabels(["Gray"])
            # If the image is 3D with 1 channel, squeeze it.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                channels = [self.image.squeeze()]
            else:
                channels = [self.image]
        
        # Compute statistics for each channel.
        stats = {"Min": [], "Max": [], "Median": [], "StdDev": []}
        for ch in channels:
            stats["Min"].append(np.min(ch))
            stats["Max"].append(np.max(ch))
            stats["Median"].append(np.median(ch))
            stats["StdDev"].append(np.std(ch))
        
        # Update the table cells.
        row_labels = ["Min", "Max", "Median", "StdDev"]
        for row, label in enumerate(row_labels):
            for col in range(self.stats_table.columnCount()):
                val = stats[label][col]
                item = QTableWidgetItem(f"{val:.3f}")
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(row, col, item)

# --------------------------------------------------
# Stacking Suite
# --------------------------------------------------
class StackingSuiteDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Stacking Suite")
        self.setGeometry(300, 200, 800, 600)
        self.per_group_drizzle = {}
        self.manual_dark_overrides = {}  
        self.manual_flat_overrides = {}

        # QSettings for your app
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")
        

        # Load or default these
        self.stacking_directory = self.settings.value("stacking/dir", "", type=str)
        self.sigma_high = self.settings.value("stacking/sigma_high", 3.0, type=float)
        self.sigma_low = self.settings.value("stacking/sigma_low", 3.0, type=float)
        self.rejection_algorithm = self.settings.value(
            "stacking/rejection_algorithm",
            "Weighted Windsorized Sigma Clipping",
            type=str
        )
        self.kappa = self.settings.value("stacking/kappa", 2.5, type=float)
        self.iterations = self.settings.value("stacking/iterations", 3, type=int)
        self.esd_threshold = self.settings.value("stacking/esd_threshold", 3.0, type=float)
        self.biweight_constant = self.settings.value("stacking/biweight_constant", 6.0, type=float)
        self.trim_fraction = self.settings.value("stacking/trim_fraction", 0.1, type=float)
        self.modz_threshold = self.settings.value("stacking/modz_threshold", 3.5, type=float)

        # Dictionaries to store file paths
        self.conversion_files = {}
        self.dark_files = {}
        self.flat_files = {}
        self.light_files = {}
        self.master_files = {}
        self.master_sizes = {}

        layout = QVBoxLayout(self)
        self.tabs = QTabWidget()
        layout.addWidget(self.tabs)
        self.dir_path_edit = QLineEdit(self.stacking_directory)  # Add this here
        # Create the new Conversion tab.
        self.conversion_tab = self.create_conversion_tab()
        # Existing tabs...
        self.dark_tab = self.create_dark_tab()
        self.flat_tab = self.create_flat_tab()
        self.light_tab = self.create_light_tab()
        self.image_integration_tab = self.create_image_registration_tab()

        # Add the tabs in desired order. (Conversion first)
        self.tabs.addTab(self.conversion_tab, "Debayer && Convert Formats")
        self.tabs.addTab(self.dark_tab, "Darks")
        self.tabs.addTab(self.flat_tab, "Flats")
        self.tabs.addTab(self.light_tab, "Lights")
        self.tabs.addTab(self.image_integration_tab, "Image Integration")
        self.tabs.setCurrentIndex(1)  # Default to Darks tab

        # Wrench button, status bar, etc.
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))
        self.wrench_button.setToolTip("Set Stacking Directory & Sigma Clipping")
        self.wrench_button.clicked.connect(self.open_stacking_settings)
        self.wrench_button.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        layout.addWidget(self.wrench_button, alignment=Qt.AlignmentFlag.AlignLeft)
        self.setup_status_bar(layout)
        self.tabs.currentChanged.connect(self.on_tab_changed)

    def create_conversion_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.addWidget(QLabel("Batch Convert Files to Debayered FITS (.fit)"))

        # 1) Create the tree
        self.conversion_tree = QTreeWidget()
        self.conversion_tree.setColumnCount(2)
        self.conversion_tree.setHeaderLabels(["File", "Status"])

        # 2) Make columns user-resizable (Interactive)
        header = self.conversion_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After populating the tree, do an initial auto-resize
        self.conversion_tree.resizeColumnToContents(0)
        self.conversion_tree.resizeColumnToContents(1)
        layout.addWidget(self.conversion_tree)

        # Buttons for adding files, adding a directory,
        # selecting an output directory, and clearing the list.
        btn_layout = QHBoxLayout()
        self.add_conversion_files_btn = QPushButton("Add Conversion Files")
        self.add_conversion_files_btn.clicked.connect(self.add_conversion_files)
        self.add_conversion_dir_btn = QPushButton("Add Conversion Directory")
        self.add_conversion_dir_btn.clicked.connect(self.add_conversion_directory)
        self.select_conversion_output_btn = QPushButton("Select Output Directory")
        self.select_conversion_output_btn.clicked.connect(self.select_conversion_output_dir)
        self.clear_conversion_btn = QPushButton("Clear List")
        self.clear_conversion_btn.clicked.connect(self.clear_conversion_list)
        btn_layout.addWidget(self.add_conversion_files_btn)
        btn_layout.addWidget(self.add_conversion_dir_btn)
        btn_layout.addWidget(self.select_conversion_output_btn)
        btn_layout.addWidget(self.clear_conversion_btn)
        layout.addLayout(btn_layout)

        # Convert All button (converts all files in the tree).
        self.convert_btn = QPushButton("Convert All Files to FITS")
        self.convert_btn.clicked.connect(self.convert_all_files)
        layout.addWidget(self.convert_btn)

        return tab

    def add_conversion_files(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files for Conversion", last_dir,
                                                "Supported Files (*.fits *.fit *.tiff *.tif *.png *.jpg *.jpeg *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef *.xisf)")
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            for file in files:
                item = QTreeWidgetItem([os.path.basename(file), "Pending"])
                item.setData(0, 1000, file)  # store full path in role 1000
                self.conversion_tree.addTopLevelItem(item)

    def add_conversion_directory(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, "Select Directory for Conversion", last_dir)
        if directory:
            self.settings.setValue("last_opened_folder", directory)
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit", ".tiff", ".tif", ".png", ".jpg", ".jpeg", 
                                           ".cr2", ".nef", ".arw", ".dng", ".orf", ".rw2", ".pef", ".xisf")):
                    full_path = os.path.join(directory, file)
                    item = QTreeWidgetItem([file, "Pending"])
                    item.setData(0, 1000, full_path)
                    self.conversion_tree.addTopLevelItem(item)

    def select_conversion_output_dir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Conversion Output Directory")
        if directory:
            self.conversion_output_directory = directory
            self.update_status(f"Conversion output directory set to: {directory}")

    def clear_conversion_list(self):
        self.conversion_tree.clear()
        self.update_status("Conversion list cleared.")

    def convert_all_files(self):
        if not self.conversion_output_directory:
            QMessageBox.warning(self, "No Output Directory", "Please select a conversion output directory first.")
            return

        count = self.conversion_tree.topLevelItemCount()
        if count == 0:
            QMessageBox.information(self, "No Files", "There are no files to convert.")
            return

        for i in range(count):
            item = self.conversion_tree.topLevelItem(i)
            file_path = item.data(0, 1000)
            result = load_image(file_path)
            if result[0] is None:
                item.setText(1, "Failed to load")
                self.update_status(f"Failed to load {os.path.basename(file_path)}")
                continue

            image, header, bit_depth, is_mono = result

            # Debayer if needed:
            image = self.debayer_image(image, file_path, header)
            if image.ndim == 3:
                is_mono = False

            # If it's a RAW format, definitely treat as color
            if file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                is_mono = False

                # Try extracting EXIF metadata
                try:
                    import exifread
                    with open(file_path, 'rb') as f:
                        tags = exifread.process_file(f, details=False)

                    exptime_tag = tags.get("EXIF ExposureTime")  # e.g. "1/125"
                    iso_tag = tags.get("EXIF ISOSpeedRatings")
                    date_obs_tag = tags.get("EXIF DateTimeOriginal")

                    # Create or replace with a fresh header, but keep some existing fields if desired
                    new_header = fits.Header()
                    new_header['SIMPLE'] = True
                    new_header['BITPIX'] = 16
                    new_header['IMAGETYP'] = header.get('IMAGETYP', "UNKNOWN")

                    # Attempt to parse exptime. If fraction or numeric fails, store 'Unknown'.
                    if exptime_tag:
                        exptime_str = str(exptime_tag.values)  # or exptime_tag.printable
                        # Attempt fraction or float
                        try:
                            if '/' in exptime_str:  
                                # e.g. "1/125"
                                top, bot = exptime_str.split('/', 1)
                                fexp = float(top) / float(bot)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                            else:
                                # e.g. "0.008" or "8"
                                fexp = float(exptime_str)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                        except (ValueError, ZeroDivisionError):
                            new_header['EXPTIME'] = 'Unknown'
                    # If no exptime_tag, set Unknown
                    else:
                        new_header['EXPTIME'] = 'Unknown'

                    if iso_tag:
                        new_header['ISO'] = str(iso_tag.values)
                    if date_obs_tag:
                        new_header['DATE-OBS'] = str(date_obs_tag.values)

                    # Replace old header with new
                    header = new_header

                except Exception as e:
                    # If exif extraction fails for any reason, we just keep the existing header
                    # but ensure we set EXPTIME if missing
                    self.update_status(f"Warning: Failed to extract RAW header from {os.path.basename(file_path)}: {e}")

            # Append or update IMAGETYP based on filename
            lower_name = os.path.basename(file_path).lower()
            if "dark" in lower_name:
                header['IMAGETYP'] = "DARK"
            elif "flat" in lower_name:
                header['IMAGETYP'] = "FLAT"
            elif "light" in lower_name:
                header['IMAGETYP'] = "LIGHT"
            else:
                header['IMAGETYP'] = header.get('IMAGETYP', "UNKNOWN")

            # Remove any existing NAXIS keywords
            for key in ["NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
                header.pop(key, None)

            if image.ndim == 2:
                header['NAXIS'] = 2
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
            elif image.ndim == 3:
                header['NAXIS'] = 3
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
                header['NAXIS3'] = image.shape[2]

            # -- Ensure EXPTIME is defined --
            if 'EXPTIME' not in header:
                # If the camera or exif didn't provide it, we set it to 'Unknown'
                header['EXPTIME'] = 'Unknown'

            # Build output filename and save
            base = os.path.basename(file_path)
            name, _ = os.path.splitext(base)
            output_filename = os.path.join(self.conversion_output_directory, f"{name}.fit")

            try:
                save_image(
                    img_array=image,
                    filename=output_filename,
                    original_format="fit",
                    bit_depth=bit_depth,
                    original_header=header,
                    is_mono=is_mono
                )
                item.setText(1, "Converted")
                self.update_status(
                    f"Converted {os.path.basename(file_path)} to FITS with "
                    f"IMAGETYP={header['IMAGETYP']}, EXPTIME={header['EXPTIME']}."
                )
            except Exception as e:
                item.setText(1, f"Error: {e}")
                self.update_status(f"Error converting {os.path.basename(file_path)}: {e}")

            QApplication.processEvents()

        self.update_status("Conversion complete.")



    def debayer_image(self, image, file_path, header):
        if file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            print(f"Debayering RAW image: {file_path}")
            return debayer_raw_fast(image)
        elif file_path.lower().endswith(('.fits', '.fit')):
            bayer_pattern = header.get('BAYERPAT')
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                return debayer_fits_fast(image, bayer_pattern)
        return image

    def setup_status_bar(self, layout):
        """ Sets up a scrollable status log at the bottom of the UI. """
        self.status_text = QTextEdit()
        self.status_text.setReadOnly(True)
        self.status_text.setMaximumHeight(100)  # Limits visible lines (~5 lines)
        self.status_text.setStyleSheet("background-color: black; color: white; font-family: Monospace; padding: 4px;")
        
        # Wrap in a scroll area for scrolling
        self.status_scroll = QScrollArea()
        self.status_scroll.setWidgetResizable(True)
        self.status_scroll.setWidget(self.status_text)
        
        # Add to the main layout
        layout.addWidget(self.status_scroll)

    def update_status(self, message):
        """ Updates the status log with a scrolling history. """
        self.status_text.append(message)  # Adds new message at the bottom
        self.status_text.verticalScrollBar().setValue(self.status_text.verticalScrollBar().maximum())  # Auto-scroll to bottom
        QApplication.processEvents() 

    def open_stacking_settings(self):
        """ Opens a dialog to set the stacking directory, sigma values, rejection algorithm, and algorithm parameters. """
        dialog = QDialog(self)
        dialog.setWindowTitle("Stacking Settings")
        layout = QVBoxLayout(dialog)

        # Stacking directory selection
        dir_layout = QHBoxLayout()
        dir_label = QLabel("Stacking Directory:")
        self.dir_path_edit = QLineEdit(self.stacking_directory)
        dir_button = QPushButton("Browse")
        dir_button.clicked.connect(self.select_stacking_directory)
        dir_layout.addWidget(dir_label)
        dir_layout.addWidget(self.dir_path_edit)
        dir_layout.addWidget(dir_button)
        layout.addLayout(dir_layout)

        # Sigma High & Low settings
        sigma_layout = QHBoxLayout()
        sigma_layout.addWidget(QLabel("Sigma High:"))
        self.sigma_high_spinbox = QDoubleSpinBox()
        self.sigma_high_spinbox.setRange(0.1, 10.0)
        self.sigma_high_spinbox.setDecimals(2)
        self.sigma_high_spinbox.setValue(self.sigma_high)
        sigma_layout.addWidget(self.sigma_high_spinbox)
        sigma_layout.addWidget(QLabel("Sigma Low:"))
        self.sigma_low_spinbox = QDoubleSpinBox()
        self.sigma_low_spinbox.setRange(0.1, 10.0)
        self.sigma_low_spinbox.setDecimals(2)
        self.sigma_low_spinbox.setValue(self.sigma_low)
        sigma_layout.addWidget(self.sigma_low_spinbox)
        layout.addLayout(sigma_layout)

        # Rejection algorithm selection
        algo_layout = QHBoxLayout()
        algo_label = QLabel("Rejection Algorithm:")
        self.rejection_algo_combo = QComboBox()
        self.rejection_algo_combo.addItems([
            "Weighted Windsorized Sigma Clipping",
            "Kappa-Sigma Clipping",
            "Simple Average (No Rejection)",
            "Simple Median (No Rejection)",
            "Trimmed Mean",
            "Extreme Studentized Deviate (ESD)",
            "Biweight Estimator",
            "Modified Z-Score Clipping"
        ])
        saved_algo = self.settings.value("stacking/rejection_algorithm", "Weighted Windsorized Sigma Clipping")
        index = self.rejection_algo_combo.findText(saved_algo)
        if index >= 0:
            self.rejection_algo_combo.setCurrentIndex(index)
        algo_layout.addWidget(algo_label)
        algo_layout.addWidget(self.rejection_algo_combo)
        layout.addLayout(algo_layout)

        # --- Additional Parameters ---

        # Kappa-Sigma Clipping: Kappa Value
        kappa_layout = QHBoxLayout()
        kappa_label = QLabel("Kappa Value:")
        self.kappa_spinbox = QDoubleSpinBox()
        self.kappa_spinbox.setRange(0.1, 10.0)
        self.kappa_spinbox.setDecimals(2)
        self.kappa_spinbox.setValue(self.settings.value("stacking/kappa", 2.5, type=float))
        kappa_help = QPushButton("?")
        kappa_help.setFixedSize(20, 20)
        kappa_help.clicked.connect(lambda: QMessageBox.information(self, "Kappa Value", 
            "Kappa determines how many standard deviations away from the median are considered outliers. Higher values are more lenient."))
        kappa_layout.addWidget(kappa_label)
        kappa_layout.addWidget(self.kappa_spinbox)
        kappa_layout.addWidget(kappa_help)
        layout.addLayout(kappa_layout)

        # Kappa-Sigma Clipping: Iterations
        iterations_layout = QHBoxLayout()
        iterations_label = QLabel("Iterations:")
        self.iterations_spinbox = QSpinBox()
        self.iterations_spinbox.setRange(1, 10)
        self.iterations_spinbox.setValue(self.settings.value("stacking/iterations", 3, type=int))
        iterations_help = QPushButton("?")
        iterations_help.setFixedSize(20, 20)
        iterations_help.clicked.connect(lambda: QMessageBox.information(self, "Iterations", 
            "The number of iterations to perform kappa-sigma clipping. More iterations may remove more outliers."))
        iterations_layout.addWidget(iterations_label)
        iterations_layout.addWidget(self.iterations_spinbox)
        iterations_layout.addWidget(iterations_help)
        layout.addLayout(iterations_layout)

        # ESD: ESD Threshold
        esd_layout = QHBoxLayout()
        esd_label = QLabel("ESD Threshold:")
        self.esd_spinbox = QDoubleSpinBox()
        self.esd_spinbox.setRange(0.1, 10.0)
        self.esd_spinbox.setDecimals(2)
        self.esd_spinbox.setValue(self.settings.value("stacking/esd_threshold", 3.0, type=float))
        esd_help = QPushButton("?")
        esd_help.setFixedSize(20, 20)
        esd_help.clicked.connect(lambda: QMessageBox.information(self, "ESD Threshold", 
            "Threshold for the Extreme Studentized Deviate test. Lower values are more aggressive in rejecting outliers."))
        esd_layout.addWidget(esd_label)
        esd_layout.addWidget(self.esd_spinbox)
        esd_layout.addWidget(esd_help)
        layout.addLayout(esd_layout)

        # Biweight Estimator: Tuning Constant
        biweight_layout = QHBoxLayout()
        biweight_label = QLabel("Biweight Tuning Constant:")
        self.biweight_spinbox = QDoubleSpinBox()
        self.biweight_spinbox.setRange(1.0, 10.0)
        self.biweight_spinbox.setDecimals(2)
        self.biweight_spinbox.setValue(self.settings.value("stacking/biweight_constant", 6.0, type=float))
        biweight_help = QPushButton("?")
        biweight_help.setFixedSize(20, 20)
        biweight_help.clicked.connect(lambda: QMessageBox.information(self, "Biweight Tuning Constant", 
            "Tuning constant for the biweight estimator; it controls the aggressiveness of down-weighting outliers."))
        biweight_layout.addWidget(biweight_label)
        biweight_layout.addWidget(self.biweight_spinbox)
        biweight_layout.addWidget(biweight_help)
        layout.addLayout(biweight_layout)

        # Trimmed Mean: Trim Fraction
        trim_layout = QHBoxLayout()
        trim_label = QLabel("Trim Fraction:")
        self.trim_spinbox = QDoubleSpinBox()
        self.trim_spinbox.setRange(0.0, 0.5)
        self.trim_spinbox.setDecimals(2)
        self.trim_spinbox.setValue(self.settings.value("stacking/trim_fraction", 0.1, type=float))
        trim_help = QPushButton("?")
        trim_help.setFixedSize(20, 20)
        trim_help.clicked.connect(lambda: QMessageBox.information(self, "Trim Fraction", 
            "Fraction of values to trim from each end before averaging. For example, 0.1 will trim 10% from each end."))
        trim_layout.addWidget(trim_label)
        trim_layout.addWidget(self.trim_spinbox)
        trim_layout.addWidget(trim_help)
        layout.addLayout(trim_layout)

        # Modified Z-Score Clipping: Threshold
        modz_layout = QHBoxLayout()
        modz_label = QLabel("Modified Z-Score Threshold:")
        self.modz_spinbox = QDoubleSpinBox()
        self.modz_spinbox.setRange(0.1, 10.0)
        self.modz_spinbox.setDecimals(2)
        self.modz_spinbox.setValue(self.settings.value("stacking/modz_threshold", 3.5, type=float))
        modz_help = QPushButton("?")
        modz_help.setFixedSize(20, 20)
        modz_help.clicked.connect(lambda: QMessageBox.information(self, "Modified Z-Score Threshold", 
            "Threshold for the modified z-score clipping using the median absolute deviation. Lower values are more aggressive."))
        modz_layout.addWidget(modz_label)
        modz_layout.addWidget(self.modz_spinbox)
        modz_layout.addWidget(modz_help)
        layout.addLayout(modz_layout)

        # Save button
        save_button = QPushButton("Save Settings")
        save_button.clicked.connect(lambda: self.save_stacking_settings(dialog))
        layout.addWidget(save_button)

        dialog.exec()

    def save_stacking_settings(self, dialog):
        """ Saves stacking directory, sigma values, rejection algorithm, and algorithm parameters to QSettings. """
        self.stacking_directory = self.dir_path_edit.text()
        self.sigma_high = self.sigma_high_spinbox.value()
        self.sigma_low = self.sigma_low_spinbox.value()
        self.rejection_algorithm = self.rejection_algo_combo.currentText()
        self.kappa = self.kappa_spinbox.value()
        self.iterations = self.iterations_spinbox.value()
        self.esd_threshold = self.esd_spinbox.value()
        self.biweight_constant = self.biweight_spinbox.value()
        self.trim_fraction = self.trim_spinbox.value()
        self.modz_threshold = self.modz_spinbox.value()

        # Store in QSettings
        self.settings.setValue("stacking/dir", self.stacking_directory)
        self.settings.setValue("stacking/sigma_high", self.sigma_high)
        self.settings.setValue("stacking/sigma_low", self.sigma_low)
        self.settings.setValue("stacking/rejection_algorithm", self.rejection_algorithm)
        self.settings.setValue("stacking/kappa", self.kappa)
        self.settings.setValue("stacking/iterations", self.iterations)
        self.settings.setValue("stacking/esd_threshold", self.esd_threshold)
        self.settings.setValue("stacking/biweight_constant", self.biweight_constant)
        self.settings.setValue("stacking/trim_fraction", self.trim_fraction)
        self.settings.setValue("stacking/modz_threshold", self.modz_threshold)

        print(f"✅ Saved settings - Directory: {self.stacking_directory}, Sigma High: {self.sigma_high}, Sigma Low: {self.sigma_low}, Algorithm: {self.rejection_algorithm}")
        print(f"    Kappa: {self.kappa}, Iterations: {self.iterations}, ESD Threshold: {self.esd_threshold}, Biweight Constant: {self.biweight_constant}, Trim Fraction: {self.trim_fraction}, Modified Z-Score Threshold: {self.modz_threshold}")
        self.update_status("✅ Saved stacking settings.")
        dialog.accept()

    def select_stacking_directory(self):
        """ Opens a dialog to choose a stacking directory. """
        directory = QFileDialog.getExistingDirectory(self, "Select Stacking Directory")
        if directory:
            self.stacking_directory = directory
            self.dir_path_edit.setText(directory)  # No more AttributeError
            self.settings.setValue("stacking/dir", directory)  # Save the new directory


    def create_dark_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Vertical layout to separate sections

        # --- DARK FRAMES TREEBOX (TOP) ---
        darks_layout = QHBoxLayout()  # Left = Dark Tree, Right = Controls

        # Left Side - Dark Frames
        dark_frames_layout = QVBoxLayout()
        dark_frames_layout.addWidget(QLabel("Dark Frames"))
        # 1) Create the tree
        self.dark_tree = QTreeWidget()
        self.dark_tree.setColumnCount(2)
        self.dark_tree.setHeaderLabels(["Exposure Time", "Metadata"])
        self.dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # 2) Make columns user-resizable
        header = self.dark_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After you fill the tree with items, auto-resize
        self.dark_tree.resizeColumnToContents(0)
        self.dark_tree.resizeColumnToContents(1)

        # Then add it to the layout
        dark_frames_layout.addWidget(self.dark_tree)

        # Buttons to Add Dark Files & Directories
        btn_layout = QHBoxLayout()
        self.add_dark_files_btn = QPushButton("Add Dark Files")
        self.add_dark_files_btn.clicked.connect(self.add_dark_files)
        self.add_dark_dir_btn = QPushButton("Add Dark Directory")
        self.add_dark_dir_btn.clicked.connect(self.add_dark_directory)
        btn_layout.addWidget(self.add_dark_files_btn)
        btn_layout.addWidget(self.add_dark_dir_btn)
        dark_frames_layout.addLayout(btn_layout)

        self.clear_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_dark_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.dark_tree))
        dark_frames_layout.addWidget(self.clear_dark_selection_btn)

        darks_layout.addLayout(dark_frames_layout, 2)  # Dark Frames Tree takes more space


        # --- RIGHT SIDE: Exposure Tolerance & Master Darks Button ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.exposure_tolerance_spinbox = QSpinBox()
        self.exposure_tolerance_spinbox.setRange(0, 30)  # Acceptable range
        self.exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)

        # --- "Turn Those Darks Into Master Darks" Button ---
        self.create_master_dark_btn = QPushButton("Turn Those Darks Into Master Darks")
        self.create_master_dark_btn.clicked.connect(self.create_master_dark)

        # Apply a bold font, padding, and a highlighted effect
        self.create_master_dark_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)

        right_controls_layout.addWidget(self.create_master_dark_btn)


        darks_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(darks_layout)

        # --- MASTER DARKS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Darks"))
        self.master_dark_tree = QTreeWidget()
        self.master_dark_tree.setColumnCount(2)
        self.master_dark_tree.setHeaderLabels(["Exposure Time", "Master File"])
        self.master_dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        main_layout.addWidget(self.master_dark_tree)

        # Master Dark Selection Button
        self.master_dark_btn = QPushButton("Load Master Dark")
        self.master_dark_btn.clicked.connect(self.load_master_dark)
        main_layout.addWidget(self.master_dark_btn)

        # Add "Clear Selection" button for Master Darks
        self.clear_master_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_master_dark_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.master_dark_tree))
        main_layout.addWidget(self.clear_master_dark_selection_btn)

        return tab



    def create_flat_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Main layout to organize sections

        # --- FLAT FRAMES TREEBOX (TOP) ---
        flats_layout = QHBoxLayout()  # Left = Flat Tree, Right = Controls

        # Left Side - Flat Frames
        flat_frames_layout = QVBoxLayout()
        flat_frames_layout.addWidget(QLabel("Flat Frames"))

        self.flat_tree = QTreeWidget()
        self.flat_tree.setColumnCount(3)  # Added 3rd column for Master Dark Used
        self.flat_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark Used"])
        self.flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        flat_frames_layout.addWidget(self.flat_tree)

        # Buttons to Add Flat Files & Directories
        btn_layout = QHBoxLayout()
        self.add_flat_files_btn = QPushButton("Add Flat Files")
        self.add_flat_files_btn.clicked.connect(self.add_flat_files)
        self.add_flat_dir_btn = QPushButton("Add Flat Directory")
        self.add_flat_dir_btn.clicked.connect(self.add_flat_directory)
        btn_layout.addWidget(self.add_flat_files_btn)
        btn_layout.addWidget(self.add_flat_dir_btn)
        flat_frames_layout.addLayout(btn_layout)

        # Add "Clear Selection" button for Flat Frames
        self.clear_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_flat_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.flat_tree))
        flat_frames_layout.addWidget(self.clear_flat_selection_btn)

        flats_layout.addLayout(flat_frames_layout, 2)  # Left side takes more space

        # --- RIGHT SIDE: Exposure Tolerance & Master Dark Selection ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.flat_exposure_tolerance_spinbox = QSpinBox()
        self.flat_exposure_tolerance_spinbox.setRange(0, 30)  # Allow ±0 to 30 seconds
        self.flat_exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.flat_exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)

        # Auto-Select Master Dark
        self.auto_select_dark_checkbox = QCheckBox("Auto-Select Closest Master Dark")
        self.auto_select_dark_checkbox.setChecked(True)  # Default enabled
        right_controls_layout.addWidget(self.auto_select_dark_checkbox)

        # Manual Override: Select a Master Dark
        self.override_dark_combo = QComboBox()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.currentIndexChanged.connect(self.override_selected_master_dark)
        right_controls_layout.addWidget(QLabel("Override Master Dark Selection"))
        right_controls_layout.addWidget(self.override_dark_combo)

        self.create_master_flat_btn = QPushButton("Turn Those Flats Into Master Flats")
        self.create_master_flat_btn.clicked.connect(self.create_master_flat)

        # Apply a bold font, padding, and a glowing effect
        self.create_master_flat_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)


        right_controls_layout.addWidget(self.create_master_flat_btn)

        flats_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(flats_layout)

        # --- MASTER FLATS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Flats"))
        self.master_flat_tree = QTreeWidget()
        self.master_flat_tree.setColumnCount(2)
        self.master_flat_tree.setHeaderLabels(["Filter", "Master File"])
        self.master_flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        main_layout.addWidget(self.master_flat_tree)

        # Master Flat Selection Button
        self.master_flat_btn = QPushButton("Load Master Flat")
        self.master_flat_btn.clicked.connect(self.load_master_flat)
        main_layout.addWidget(self.master_flat_btn)

        self.clear_master_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_master_flat_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.master_flat_tree))
        main_layout.addWidget(self.clear_master_flat_selection_btn)

        return tab

    def create_light_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # Tree widget for light frames
        self.light_tree = QTreeWidget()
        self.light_tree.setColumnCount(5)  # Added columns for Master Dark and Flat
        self.light_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark", "Master Flat", "Corrections"])
        self.light_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        layout.addWidget(QLabel("Light Frames"))
        layout.addWidget(self.light_tree)

        # Buttons for adding files and directories
        btn_layout = QHBoxLayout()
        self.add_light_files_btn = QPushButton("Add Light Files")
        self.add_light_files_btn.clicked.connect(self.add_light_files)
        self.add_light_dir_btn = QPushButton("Add Light Directory")
        self.add_light_dir_btn.clicked.connect(self.add_light_directory)
        btn_layout.addWidget(self.add_light_files_btn)
        btn_layout.addWidget(self.add_light_dir_btn)
        layout.addLayout(btn_layout)

        clear_selection_btn = QPushButton("Remove Selected")
        clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.light_tree))
        layout.addWidget(clear_selection_btn)

        # Cosmetic Correction & Pedestal Controls
        correction_layout = QHBoxLayout()

        self.cosmetic_checkbox = QCheckBox("Enable Cosmetic Correction")
        self.pedestal_checkbox = QCheckBox("Apply Pedestal")
        self.bias_checkbox = QCheckBox("Apply Bias Subtraction (For CCD Users)")

        # Pedestal Value (0-1000, converted to 0-1)
        pedestal_layout = QHBoxLayout()
        self.pedestal_spinbox = QSpinBox()
        self.pedestal_spinbox.setRange(0, 1000)
        self.pedestal_spinbox.setValue(50)  # Default pedestal
        pedestal_layout.addWidget(QLabel("Pedestal (0-1000):"))
        pedestal_layout.addWidget(self.pedestal_spinbox)
        layout.addLayout(pedestal_layout)        

        # ✅ Add Tooltip to Bias Checkbox
        self.bias_checkbox.setToolTip(
            "CMOS users: Bias Subtraction is not needed.\n"
            "Modern CMOS cameras use Correlated Double Sampling (CDS),\n"
            "meaning bias is already subtracted at the sensor level."
        )

        # Connect checkboxes to update function
        self.cosmetic_checkbox.stateChanged.connect(self.update_light_corrections)
        self.pedestal_checkbox.stateChanged.connect(self.update_light_corrections)
        self.bias_checkbox.stateChanged.connect(self.update_light_corrections)

        # Add checkboxes to layout
        correction_layout.addWidget(self.cosmetic_checkbox)
        correction_layout.addWidget(self.pedestal_checkbox)
        correction_layout.addWidget(self.bias_checkbox)

        layout.addLayout(correction_layout)        

        # --- RIGHT SIDE CONTROLS: Override Dark & Flat ---
        override_layout = QHBoxLayout()

        # Override Dark Frame Button
        self.override_dark_btn = QPushButton("Override Dark Frame")
        self.override_dark_btn.clicked.connect(self.override_selected_master_dark)
        override_layout.addWidget(self.override_dark_btn)

        # Override Flat Frame Button
        self.override_flat_btn = QPushButton("Override Flat Frame")
        self.override_flat_btn.clicked.connect(self.override_selected_master_flat)
        override_layout.addWidget(self.override_flat_btn)

        layout.addLayout(override_layout)

        # Calibrate Lights Button
        self.calibrate_lights_btn = QPushButton("🚀 Calibrate Light Frames 🚀")
        self.calibrate_lights_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        self.calibrate_lights_btn.clicked.connect(self.calibrate_lights)
        layout.addWidget(self.calibrate_lights_btn)

        # Enable Context Menu
        self.light_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.light_tree.customContextMenuRequested.connect(self.light_tree_context_menu)

        return tab



    def create_image_registration_tab(self):
        """
        Creates an Image Registration tab that mimics how the Light tab handles
        cosmetic corrections—i.e., we have global Drizzle controls (checkbox, combo, spin),
        and we update a text column in the QTreeWidget to show each group's drizzle state.
        """
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # ─────────────────────────────────────────
        # 1) QTreeWidget
        # ─────────────────────────────────────────
        self.reg_tree = QTreeWidget()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels([
            "Filter - Exposure - Size",
            "Metadata",
            "Drizzle"  # We'll display "Drizzle: True, Scale: 2x, Drop:0.65" here
        ])
        self.reg_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Optional: make columns resize nicely
        header = self.reg_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(2, QHeaderView.ResizeMode.Stretch)

        layout.addWidget(QLabel("Calibrated Light Frames"))
        layout.addWidget(self.reg_tree)

        # Populate the tree from your calibrated folder
        self.populate_calibrated_lights()

        # ─────────────────────────────────────────
        # 2) Buttons for Managing Files
        # ─────────────────────────────────────────
        btn_layout = QHBoxLayout()
        self.add_reg_files_btn = QPushButton("Add Light Files")
        self.add_reg_files_btn.clicked.connect(self.add_light_files_to_registration)
        btn_layout.addWidget(self.add_reg_files_btn)

        self.clear_selection_btn = QPushButton("Remove Selected")
        self.clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.reg_tree))
        btn_layout.addWidget(self.clear_selection_btn)

        layout.addLayout(btn_layout)

        # ─────────────────────────────────────────
        # 3) Global Drizzle Controls
        # ─────────────────────────────────────────
        drizzle_layout = QHBoxLayout()

        self.drizzle_checkbox = QCheckBox("Enable Drizzle")
        self.drizzle_checkbox.stateChanged.connect(self.update_drizzle_settings)  # <─ connect signal
        drizzle_layout.addWidget(self.drizzle_checkbox)

        drizzle_layout.addWidget(QLabel("Scale:"))
        self.drizzle_scale_combo = QComboBox()
        self.drizzle_scale_combo.addItems(["1x", "2x", "3x"])
        self.drizzle_scale_combo.currentIndexChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_scale_combo)

        drizzle_layout.addWidget(QLabel("Drop Shrink:"))
        self.drizzle_drop_shrink_spin = QDoubleSpinBox()
        self.drizzle_drop_shrink_spin.setRange(0.0, 1.0)
        self.drizzle_drop_shrink_spin.setSingleStep(0.05)
        self.drizzle_drop_shrink_spin.setValue(0.65)
        self.drizzle_drop_shrink_spin.valueChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_drop_shrink_spin)

        layout.addLayout(drizzle_layout)

        # ─────────────────────────────────────────
        # 4) Reference Frame Selection
        # ─────────────────────────────────────────
        self.ref_frame_label = QLabel("Select Reference Frame:")
        self.ref_frame_path = QLabel("No file selected")
        self.ref_frame_path.setWordWrap(True)
        self.select_ref_frame_btn = QPushButton("Select Reference Frame")
        self.select_ref_frame_btn.clicked.connect(self.select_reference_frame)

        ref_layout = QHBoxLayout()
        ref_layout.addWidget(self.ref_frame_label)
        ref_layout.addWidget(self.ref_frame_path)
        ref_layout.addWidget(self.select_ref_frame_btn)
        layout.addLayout(ref_layout)

        # ─────────────────────────────────────────
        # 5) Register & Integrate Buttons
        # ─────────────────────────────────────────
        self.register_images_btn = QPushButton("🔥🚀Register and Integrate Images🔥🚀")
        self.register_images_btn.clicked.connect(self.register_images)
        self.register_images_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        layout.addWidget(self.register_images_btn)

        self.integrate_registered_btn = QPushButton("Integrate Previously Registered Images")
        self.integrate_registered_btn.clicked.connect(self.integrate_registered_images)
        self.integrate_registered_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;
            }
            QPushButton:hover {
                border: 2px solid #FFD700;
            }
            QPushButton:pressed {
                background-color: #222;
                border: 2px solid #FFA500;
            }
        """)
        layout.addWidget(self.integrate_registered_btn)

        tab.setLayout(layout)
        return tab

    def select_reference_frame(self):
        """ Opens a file dialog to select the reference frame. """
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Frame", "", 
                                                "FITS Images (*.fits *.fit);;All Files (*)")
        if file_path:
            self.reference_frame = file_path
            self.ref_frame_path.setText(os.path.basename(file_path))


    def clear_tree_selection(self, tree):
        """ Clears the selection in the given tree widget and removes items from dictionaries. """
        
        selected_items = tree.selectedItems()
        if not selected_items:
            return  # Nothing to remove

        removed_keys = []

        for item in selected_items:
            parent = item.parent()
            if parent:
                # ✅ Handle child items (specific files)
                group_key = parent.text(0)
                filename = item.text(0)

                if group_key in self.light_files:
                    self.light_files[group_key] = [
                        f for f in self.light_files[group_key] if os.path.basename(f) != filename
                    ]
                    if not self.light_files[group_key]:  # If empty, mark for deletion
                        removed_keys.append(group_key)

                parent.removeChild(item)

            else:
                # ✅ Handle parent groups (remove entire category)
                group_key = item.text(0)
                if group_key in self.light_files:
                    del self.light_files[group_key]  # Remove all associated files
                removed_keys.append(group_key)

                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))

        # ✅ Ensure removed groups are deleted from dictionary
        for key in removed_keys:
            self.light_files.pop(key, None)

        print(f"✅ Cleared selection. Remaining files: {sum(len(v) for v in self.light_files.values())} total")



    def populate_calibrated_lights(self, manual_addition=False):
        """
        Populates the tree with 3 columns:
        0: "Filter - Exposure - Size"
        1: "Metadata"
        2: "Drizzle" (e.g. "Drizzle: False" or "Drizzle: True, Scale: 2x, Drop: 0.65")
        """
        if manual_addition:
            return

        self.reg_tree.clear()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels(["Filter - Exposure - Size", "Metadata", "Drizzle"])

        # Preserve manually added files
        existing_manual_files = self.light_files.copy()
        self.light_files = {}

        # Ensure stacking directory is set
        if not self.stacking_directory:
            # 1) Prompt user to pick a directory
            self.select_stacking_directory()

            # 2) If user still didn't choose one, show warning and return
            if not self.stacking_directory:
                QMessageBox.warning(self, "Error", "Output directory is not set.")
                return

        calibrated_folder = os.path.join(self.stacking_directory, "Calibrated")
        if not os.path.exists(calibrated_folder):
            return

        fits_files = [
            f for f in os.listdir(calibrated_folder)
            if f.lower().endswith((".fits", ".fit"))
        ]
        if not fits_files:
            return

        # Group files by filter/exposure/dimensions
        grouped_files = {}
        for filename in fits_files:
            file_path = os.path.join(calibrated_folder, filename)
            try:
                with fits.open(file_path) as hdul:
                    hdr = hdul[0].header
                    filter_name = hdr.get("FILTER", "Unknown")
                    exposure = hdr.get("EXPOSURE", hdr.get("EXPTIME", "Unknown"))
                    data = hdul[0].data
                    if data is not None:
                        height, width = data.shape[-2:]
                        image_size = f"{width}x{height}"
                    else:
                        image_size = "Unknown"

                    group_key = f"{filter_name} - {exposure}s ({image_size})"
                    if group_key not in grouped_files:
                        grouped_files[group_key] = []
                    grouped_files[group_key].append(file_path)

            except Exception as e:
                self.update_status(f"⚠️ Skipped {filename}: {e}")

        # Populate the tree with top-level items
        for group_key, file_list in grouped_files.items():
            top_item = QTreeWidgetItem()
            top_item.setText(0, group_key)
            top_item.setText(1, f"{len(file_list)} files")
            # By default, Drizzle is off -> just show "Drizzle: False"
            top_item.setText(2, "Drizzle: False")

            # Store file_list in UserRole
            top_item.setData(0, Qt.ItemDataRole.UserRole, file_list)
            self.reg_tree.addTopLevelItem(top_item)

            # Child items for each file
            for fp in file_list:
                child = QTreeWidgetItem([
                    os.path.basename(fp),
                    f"Size: {image_size}"
                ])
                top_item.addChild(child)
            top_item.setExpanded(True)

        # Update self.light_files
        self.light_files.update(grouped_files)

        # Restore any manually added files
        for gkey, flist in existing_manual_files.items():
            if gkey not in self.light_files:
                self.light_files[gkey] = flist


    def update_drizzle_settings(self):
        """
        Called whenever the user toggles the 'Enable Drizzle' checkbox,
        changes the scale combo, or changes the drop shrink spinbox.
        Applies to all *selected* top-level items in the reg_tree.
        """
        # Current states from global controls
        drizzle_enabled = self.drizzle_checkbox.isChecked()
        scale_str = self.drizzle_scale_combo.currentText()  # e.g. "1x","2x","3x"
        drop_val = self.drizzle_drop_shrink_spin.value()    # e.g. 0.65

        # Gather selected items
        selected_items = self.reg_tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            # If the user selected a child row, go up to its parent group
            if item.parent() is not None:
                item = item.parent()

            group_key = item.text(0)

            if drizzle_enabled:
                # Show scale + drop shrink
                drizzle_text = (f"Drizzle: True, "
                                f"Scale: {scale_str}, "
                                f"Drop: {drop_val:.2f}")
            else:
                # Just show "Drizzle: False"
                drizzle_text = "Drizzle: False"

            # Update column 2 with the new text
            item.setText(2, drizzle_text)

            # If you also store it in a dictionary:
            self.per_group_drizzle[group_key] = {
                "enabled": drizzle_enabled,
                "scale": float(scale_str.replace("x","", 1)),
                "drop": drop_val
            }


    def gather_drizzle_settings_from_tree(self):
        """
        Returns a dict of the form:
        {
        "L - 120s (8288x5644)": {
            "files": [...],
            "drizzle_enabled": True,
            "scale_factor": 2.0,
            "drop_shrink": 0.65
        },
        ...
        }
        """
        drizzle_dict = {}
        top_count = self.reg_tree.topLevelItemCount()

        for i in range(top_count):
            item = self.reg_tree.topLevelItem(i)
            if not item:
                continue

            group_key = item.text(0)
            file_list = item.data(0, Qt.ItemDataRole.UserRole)
            drizzle_text = item.text(2)  # e.g. "Drizzle: True, Scale: 2x, Drop: 0.65" or "Drizzle: False"

            # Default
            drizzle_enabled = False
            scale_factor = 1.0
            drop_shrink = 0.65

            if drizzle_text.startswith("Drizzle: False"):
                # Drizzle is off
                drizzle_enabled = False
            else:
                # e.g. "Drizzle: True, Scale: 2x, Drop: 0.65"
                parts = drizzle_text.split(",")
                # parts[0] -> "Drizzle: True"
                # parts[1] -> " Scale: 2x"
                # parts[2] -> " Drop: 0.65"
                if len(parts) == 3:
                    drizzle_enabled_str = parts[0].split(":")[-1].strip()  # "True"
                    drizzle_enabled = (drizzle_enabled_str.lower() == "true")

                    scale_str = parts[1].split(":")[-1].strip()  # "2x"
                    scale_factor = float(scale_str.replace("x",""))

                    drop_str = parts[2].split(":")[-1].strip()
                    drop_shrink = float(drop_str)

            drizzle_dict[group_key] = {
                "files": file_list,
                "drizzle_enabled": drizzle_enabled,
                "scale_factor": scale_factor,
                "drop_shrink": drop_shrink
            }

        return drizzle_dict


    def add_light_files_to_registration(self):
        """ Adds manually selected light frames while preserving grouping. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Light Frames", last_dir, "FITS Files (*.fits *.fit)")
        
        if not files:
            return

        self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))

        # ✅ Only clear tree if no manual files exist yet
        if not self.light_files:
            self.reg_tree.clear()

        for file in files:
            filename = os.path.basename(file)

            # ✅ Extract metadata (filter, exposure, size)
            try:
                with fits.open(file) as hdul:
                    header = hdul[0].header
                    filter_name = header.get("FILTER", "Unknown")
                    exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))

                    # Extract image size
                    data = hdul[0].data
                    if data is not None:
                        height, width = data.shape[-2:]
                        image_size = f"{width}x{height}"
                    else:
                        image_size = "Unknown"

                    group_key = f"{filter_name} - {exposure}s ({image_size})"
            except Exception:
                group_key = "Unknown - Unknown"

            # ✅ Ensure group exists in tree
            existing_groups = {self.reg_tree.topLevelItem(i).text(0) for i in range(self.reg_tree.topLevelItemCount())}
            if group_key not in existing_groups:
                group_item = QTreeWidgetItem([group_key, f"{len(files)} files"])
                self.reg_tree.addTopLevelItem(group_item)
            else:
                for i in range(self.reg_tree.topLevelItemCount()):
                    if self.reg_tree.topLevelItem(i).text(0) == group_key:
                        group_item = self.reg_tree.topLevelItem(i)
                        break

            # ✅ Add file to tree
            file_item = QTreeWidgetItem([file, "Loaded"])
            group_item.addChild(file_item)

            # ✅ Ensure it's stored for processing
            if group_key not in self.light_files:
                self.light_files[group_key] = []
            self.light_files[group_key].append(file)

        print(f"✅ Added {len(files)} light frames.")




    def on_tab_changed(self, index):
        """ Detects when user switches to the Flats tab and triggers auto-assign. """
        if self.tabs.tabText(index) == "Flats":
            print("🔄 Auto-checking best Master Darks for Flats...")
            self.assign_best_master_dark()


    def add_dark_files(self):
        self.add_files(self.dark_tree, "Select Dark Files", "DARK")
    
    def add_dark_directory(self):
        self.add_directory(self.dark_tree, "Select Dark Directory", "DARK")

    def add_flat_files(self):
        self.add_files(self.flat_tree, "Select Flat Files", "FLAT")
        self.assign_best_master_dark()  # Assign best dark after adding flats

    def add_flat_directory(self):
        self.add_directory(self.flat_tree, "Select Flat Directory", "FLAT")
        self.assign_best_master_dark()  # Assign best dark after adding flats

    
    def add_light_files(self):
        self.add_files(self.light_tree, "Select Light Files", "LIGHT")
    
    def add_light_directory(self):
        self.add_directory(self.light_tree, "Select Light Directory", "LIGHT")

    def load_master_dark(self):
        """ Loads a Master Dark and updates the UI. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)  # Get last folder
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Dark", last_dir, "FITS Files (*.fits *.fit)")
        
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last used folder
            self.add_master_files(self.master_dark_tree, "DARK", files)

        self.update_override_dark_combo()
        self.assign_best_master_dark()
        print("DEBUG: Loaded Master Darks and updated assignments.")


    def load_master_flat(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Flat", last_dir, "FITS Files (*.fits *.fit)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            self.add_master_files(self.master_flat_tree, "FLAT", files)


    def add_files(self, tree, title, expected_type):
        """ Adds FITS files and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, title, last_dir, "FITS Files (*.fits *.fit)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last opened folder
            for file in files:
                self.process_fits_header(file, tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()



    def add_directory(self, tree, title, expected_type):
        """ Adds all FITS files from a directory and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, title, last_dir)

        if directory:
            self.settings.setValue("last_opened_folder", directory)  # Save last opened folder
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit")):
                    self.process_fits_header(os.path.join(directory, file), tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()


    
    def process_fits_header(self, file_path, tree, expected_type):
        try:
            # Read only the FITS header (fast)
            header = fits.getheader(file_path)

            try:
                width = int(header.get("NAXIS1"))
                height = int(header.get("NAXIS2"))
            except Exception as e:
                self.update_status(f"Warning: Could not convert dimensions to int for {file_path}: {e}")
                width, height = None, None

            if width is not None and height is not None:
                image_size = f"{width}x{height}"
            else:
                image_size = "Unknown"

            # Retrieve IMAGETYP (default to "UNKNOWN" if not present)
            imagetyp = header.get("IMAGETYP", "UNKNOWN").lower()

            # Retrieve exposure from either EXPOSURE or EXPTIME
            exposure_val = header.get("EXPOSURE")
            if not exposure_val:
                exposure_val = header.get("EXPTIME")
            if not exposure_val:
                exposure_val = "Unknown"  # fallback if neither keyword is present

            # Define forbidden keywords per expected type.
            if expected_type.upper() == "DARK":
                forbidden = ["light", "flat"]
            elif expected_type.upper() == "FLAT":
                forbidden = ["dark", "light"]
            elif expected_type.upper() == "LIGHT":
                forbidden = ["dark", "flat"]
            else:
                forbidden = []

            # Determine attribute name for auto-confirm decision (per expected type)
            decision_attr = f"auto_confirm_{expected_type.lower()}"
            # If a decision has already been made, use it.
            if hasattr(self, decision_attr):
                decision = getattr(self, decision_attr)
                if decision is False:
                    # Skip this file automatically.
                    return
                # If decision is True, then add without prompting.
            elif any(word in imagetyp for word in forbidden):
                # Prompt the user with Yes, Yes to All, No, and No to All options.
                msgBox = QMessageBox(self)
                msgBox.setWindowTitle("Mismatched Image Type")
                msgBox.setText(
                    f"The file:\n{os.path.basename(file_path)}\n"
                    f"has IMAGETYP = {header.get('IMAGETYP')} "
                    f"which does not match the expected type ({expected_type}).\n\n"
                    f"Do you want to add it anyway?"
                )
                yesButton = msgBox.addButton("Yes", QMessageBox.ButtonRole.YesRole)
                yesToAllButton = msgBox.addButton("Yes to All", QMessageBox.ButtonRole.YesRole)
                noButton = msgBox.addButton("No", QMessageBox.ButtonRole.NoRole)
                noToAllButton = msgBox.addButton("No to All", QMessageBox.ButtonRole.NoRole)
                msgBox.exec()
                clicked = msgBox.clickedButton()
                if clicked == yesToAllButton:
                    setattr(self, decision_attr, True)
                elif clicked == noToAllButton:
                    setattr(self, decision_attr, False)
                    return
                elif clicked == noButton:
                    return

            # Now handle each expected type
            if expected_type.upper() == "DARK":
                key = f"{exposure_val} ({image_size})"
                if key not in self.dark_files:
                    self.dark_files[key] = []
                self.dark_files[key].append(file_path)

                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    exposure_item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(exposure_item)
                else:
                    exposure_item = items[0]
                metadata = f"Size: {image_size}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

            elif expected_type.upper() == "FLAT":
                filter_name = header.get("FILTER", "Unknown")
                key = f"{filter_name} - {exposure_val} ({image_size})"
                if key not in self.flat_files:
                    self.flat_files[key] = []
                self.flat_files[key].append(file_path)

                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]
                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)
                metadata = f"Size: {image_size}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

            elif expected_type.upper() == "LIGHT":
                filter_name = header.get("FILTER", "Unknown")
                key = f"{filter_name} - {exposure_val} ({image_size})"
                if key not in self.light_files:
                    self.light_files[key] = []
                self.light_files[key].append(file_path)

                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]
                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)
                metadata = f"Size: {image_size}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

            self.update_status(f"✅ Added {os.path.basename(file_path)} as {expected_type}")
            QApplication.processEvents()

        except Exception as e:
            self.update_status(f"❌ ERROR: Could not read FITS header for {file_path} - {e}")
            QApplication.processEvents()


    def add_master_files(self, tree, file_type, files):
        """ 
        Adds multiple master calibration files to the correct treebox with metadata including image dimensions.
        This version only reads the FITS header to extract image dimensions, making it much faster.
        """
        for file_path in files:
            try:
                # Read only the FITS header (fast)
                header = fits.getheader(file_path)
                
                # Check for both EXPOSURE and EXPTIME
                exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))
                filter_name = header.get("FILTER", "Unknown")
                
                # Extract image dimensions from header keywords NAXIS1 and NAXIS2
                width = header.get("NAXIS1")
                height = header.get("NAXIS2")
                if width is not None and height is not None:
                    image_size = f"{width}x{height}"
                else:
                    image_size = "Unknown"
                
                # Construct key based on file type
                if file_type.upper() == "DARK":
                    key = f"{exposure}s ({image_size})"
                    self.master_files[key] = file_path  # Store master dark
                    self.master_sizes[file_path] = image_size  # Store size
                elif file_type.upper() == "FLAT":
                    key = f"{filter_name} ({image_size})"
                    self.master_files[key] = file_path  # Store master flat
                    self.master_sizes[file_path] = image_size  # Store size

                # Extract additional metadata from header.
                sensor_temp = header.get("CCD-TEMP", "N/A")
                date_obs = header.get("DATE-OBS", "Unknown")
                metadata = f"Size: {image_size}, Temp: {sensor_temp}°C, Date: {date_obs}"

                # Check if category item already exists in the tree.
                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(item)
                else:
                    item = items[0]

                # Add the master file as a child node with metadata.
                item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

                print(f"✅ DEBUG: Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                self.update_status(f"✅ Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                print(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                self.update_status(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                QApplication.processEvents()
                self.assign_best_master_files()

            except Exception as e:
                print(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                self.update_status(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                QApplication.processEvents()



    def create_master_dark(self):
        """ Creates master darks using stacking and saves them in the stacking directory. """

        # Ensure stacking directory is set
        if not self.stacking_directory:
            self.select_stacking_directory()
            if not self.stacking_directory:
                QMessageBox.warning(self, "Error", "Output directory is not set.")
                return

        exposure_tolerance = self.exposure_tolerance_spinbox.value()
        dark_files_by_group = {}  # ✅ Groups by exposure time & image size

        # ✅ Step 1: Group dark files by exposure time & image size within tolerance
        for exposure_key, file_list in self.dark_files.items():
            exposure_time_str, image_size = exposure_key.split(" (")  # Extract exposure and size
            image_size = image_size.rstrip(")")  # Remove trailing parenthesis
            exposure_time = float(exposure_time_str.replace("s", "")) if "Unknown" not in exposure_time_str else 0

            matched_group = None
            for (existing_exposure, existing_size) in dark_files_by_group.keys():
                if abs(existing_exposure - exposure_time) <= exposure_tolerance and existing_size == image_size:
                    matched_group = (existing_exposure, existing_size)
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size)
                dark_files_by_group[matched_group] = []

            dark_files_by_group[matched_group].extend(file_list)

        # ✅ Step 2: Create Master Calibration Directory
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # ✅ Step 3: Stack Each Group
        for (exposure_time, image_size), file_list in dark_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) - Not enough frames to stack.")
                QApplication.processEvents()
                continue

            self.update_status(f"🟢 Processing {len(file_list)} darks for {exposure_time}s ({image_size}) exposure...")
            QApplication.processEvents()

            # ✅ Load dark frames and detect color/mono
            stacked_data = []
            is_mono = True  # Default assumption

            for file in file_list:
                image, original_header, bit_depth, img_is_mono = load_image(file)

                if image is not None:
                    stacked_data.append(image)
                    is_mono = img_is_mono  # Store if it's mono or color
                    self.update_status(f"📂 Loaded {os.path.basename(file)} (Bit Depth: {bit_depth}, Mono: {img_is_mono})")
                else:
                    self.update_status(f"❌ Failed to load {os.path.basename(file)}")

                QApplication.processEvents()

            # ✅ Convert to numpy array with correct shape
            stacked_data = np.stack(stacked_data, axis=0)  # (N, H, W) for mono, (N, H, W, C) for OSC

            # ✅ Step 4: Apply Windsorized Sigma Clipping
            self.update_status(f"📊 Stacking {len(file_list)} frames using sigma clipping...")
            QApplication.processEvents()
            if not is_mono:
                clipped_mean = windsorized_sigma_clip_4d(stacked_data, lower=self.sigma_low, upper=self.sigma_high)
            else:
                clipped_mean = windsorized_sigma_clip_3d(stacked_data, lower=self.sigma_low, upper=self.sigma_high)

            # ✅ Step 5: Save Master Dark
            master_dark_path = os.path.join(master_dir, f"MasterDark_{int(exposure_time)}s_{image_size}.fits")
            self.save_master_dark(clipped_mean, master_dark_path, exposure_time, is_mono)

            # ✅ Step 6: Add to Master Dark Tree
            self.add_master_dark_to_tree(f"{exposure_time}s ({image_size})", master_dark_path)

            self.update_status(f"✅ Master Dark saved: {master_dark_path}")
            QApplication.processEvents()

        # ✅ Assign best master darks after creation
        self.assign_best_master_dark()
        self.update_override_dark_combo()
        self.assign_best_master_files()


    def save_master_dark(self, master_dark, output_path, exposure_time, is_mono):
        """ Saves the master dark as 32-bit floating point FITS while maintaining OSC structure. """

        # ✅ Ensure correct shape for OSC darks
        if is_mono:
            hdu = fits.PrimaryHDU(master_dark.astype(np.float32))  # Mono: (H, W)
            image_size = f"{master_dark.shape[1]}x{master_dark.shape[0]}"  # (W x H)
        else:
            h, w, c = master_dark.shape  # Get the correct dimensions for OSC
            hdu = fits.PrimaryHDU(master_dark.transpose(2, 0, 1).astype(np.float32))  # Save as (C, H, W)
            image_size = f"{w}x{h}"  # ✅ Store (Width x Height), ignore channels

        # ✅ Proper FITS Header
        hdr = hdu.header
        hdr["SIMPLE"] = True  
        hdr["BITPIX"] = -32   
        hdr["NAXIS"] = 3 if not is_mono else 2  # ✅ 3D for OSC, 2D for mono
        hdr["NAXIS1"] = w  # Width
        hdr["NAXIS2"] = h  # Height
        if not is_mono:
            hdr["NAXIS3"] = c  # ✅ RGB channels for OSC
        hdr["BSCALE"] = 1.0  
        hdr["BZERO"] = 0.0    
        hdr["IMAGETYP"] = "MASTER DARK"
        hdr["EXPOSURE"] = exposure_time
        hdr["DATE-OBS"] = datetime.utcnow().isoformat()
        hdr["CREATOR"] = "SetiAstroSuite"

        # ✅ Write the FITS file
        hdu.writeto(output_path, overwrite=True)

        # ✅ Store Master Dark Path with Correct Key
        key = f"{exposure_time}s ({image_size})"  # Always store as Width x Height
        self.master_files[key] = output_path  
        self.master_sizes[output_path] = image_size  # ✅ Ensure size is stored correctly

        print(f"✅ Master Dark FITS saved: {output_path}")
        self.update_status(f"✅ Stored Master Dark -> {key}: {output_path}")


            
    def add_master_dark_to_tree(self, exposure_time, master_dark_path):
        """ Adds the newly created Master Dark to the Master Dark TreeBox and updates the dropdown. """

        exposure_key = f"{exposure_time}s"

        # ✅ Store in the dictionary
        self.master_files[exposure_key] = master_dark_path  # Store master dark
        print(f"📝 DEBUG: Stored Master Dark -> {exposure_key}: {master_dark_path}")

        # ✅ Update UI Tree
        existing_items = self.master_dark_tree.findItems(exposure_key, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            exposure_item = existing_items[0]
        else:
            exposure_item = QTreeWidgetItem([exposure_key])
            self.master_dark_tree.addTopLevelItem(exposure_item)

        master_item = QTreeWidgetItem([os.path.basename(master_dark_path)])
        exposure_item.addChild(master_item)

        # ✅ Refresh the override dropdown
        self.update_override_dark_combo()
        self.assign_best_master_dark()  # 🔥 Ensure auto-selection works

        self.update_status(f"✅ Master Dark saved and added to UI: {master_dark_path}")



    def assign_best_master_dark(self):
        """ Assigns the closest matching master dark based on exposure & image size. """
        print("\n🔍 DEBUG: Assigning best master darks to flats...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Darks available.")
            self.update_status("⚠️ WARNING: No Master Darks available.")
            return  # Exit early if there are no master darks

        print(f"📂 Loaded Master Darks ({len(self.master_files)} total):")
        for key, value in self.master_files.items():
            print(f"   📌 {key} -> {value}")

        # Iterate through all flat filters
        for i in range(self.flat_tree.topLevelItemCount()):
            filter_item = self.flat_tree.topLevelItem(i)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)  # Example: "0.0007s (8288x5644)"

                # Extract exposure time
                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue  # Skip if exposure is invalid

                exposure_time = float(match.group(1))  # Extracted number
                print(f"🟢 Checking Flat Group: {exposure_text} (Parsed: {exposure_time}s)")

                # Extract image size from metadata
                if exposure_item.childCount() > 0:
                    metadata_text = exposure_item.child(0).text(1)  # Metadata column
                    size_match = re.search(r"Size: (\d+x\d+)", metadata_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                else:
                    image_size = "Unknown"

                print(f"✅ Parsed Flat Size: {image_size}")

                # Find the best matching master dark
                best_match = None
                best_diff = float("inf")

                for master_dark_exposure, master_dark_path in self.master_files.items():
                    master_dark_exposure_match = re.match(r"([\d.]+)s?", master_dark_exposure)
                    if not master_dark_exposure_match:
                        continue  # Skip if master dark exposure is invalid

                    master_dark_exposure_time = float(master_dark_exposure_match.group(1))
                    master_dark_size = self.master_sizes.get(master_dark_path, "Unknown")
                    if master_dark_size == "Unknown":
                        with fits.open(master_dark_path) as hdul:
                            master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                            self.master_sizes[master_dark_path] = master_dark_size  # ✅ Store it

                    print(f"🔎 Comparing with Master Dark: {master_dark_exposure_time}s ({master_dark_size})")

                    # Match both image size and exposure time
                    if image_size == master_dark_size:
                        diff = abs(master_dark_exposure_time - exposure_time)
                        if diff < best_diff:
                            best_match = master_dark_path
                            best_diff = diff

                # Assign best match in column 3
                if best_match:
                    exposure_item.setText(2, os.path.basename(best_match))
                    print(f"🔵 Assigned Master Dark: {os.path.basename(best_match)}")
                else:
                    exposure_item.setText(2, "None")
                    print(f"⚠️ No matching Master Dark found for {exposure_text}")

        # 🔥 Force UI update to reflect changes
        self.flat_tree.viewport().update()

        print("\n✅ DEBUG: Finished assigning best matching Master Darks to Flats.\n")



    def update_override_dark_combo(self):
        """ Populates the dropdown with available Master Darks and prevents duplicate entries. """
        self.override_dark_combo.clear()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.addItem("None (Use no Dark to Calibrate)")

        seen_files = set()
        for exposure, path in self.master_files.items():
            file_name = os.path.basename(path)
            if file_name not in seen_files:
                self.override_dark_combo.addItem(f"{file_name} ({exposure})")
                seen_files.add(file_name)

        print("✅ DEBUG: Updated Override Master Dark dropdown with unique entries.")


    def override_selected_master_dark(self):
        """ Overrides the selected master dark for the currently highlighted flat group. """
        selected_items = self.flat_tree.selectedItems()
        if not selected_items:
            return

        new_dark = self.override_dark_combo.currentText()

        # ✅ Handle "None (Use no Dark to Calibrate)" explicitly
        if new_dark == "None (Use no Dark to Calibrate)":
            new_dark = "No Calibration"  # Show "No Calibration" in the UI
        elif new_dark == "None (Use Auto-Select)":
            new_dark = None  # Auto-select behavior

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, new_dark if new_dark else "Auto")

        print(f"✅ DEBUG: Override Master Dark set to: {new_dark}")




    def create_master_flat(self):
        """ Creates master flats using per-frame dark subtraction before stacking. """

        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first using the wrench button.")
            return

        exposure_tolerance = self.flat_exposure_tolerance_spinbox.value()
        flat_files_by_group = {}  # ✅ Group by (Exposure, Image Size, Filter)

        # ✅ Group Flats by Filter, Exposure & Size within Tolerance
        for filter_exposure, file_list in self.flat_files.items():
            try:
                filter_name, exposure_size = filter_exposure.split(" - ")
                exposure_time_str, image_size = exposure_size.split(" (")
                image_size = image_size.rstrip(")")  # Remove trailing parenthesis
            except ValueError:
                self.update_status(f"⚠️ ERROR: Could not parse {filter_exposure}")
                continue  # Skip invalid entries

            # Extract only the exposure time
            match = re.match(r"([\d.]+)s?", exposure_time_str)
            if not match:
                self.update_status(f"⚠️ WARNING: Could not parse exposure time from {exposure_time_str}")
                continue  # Skip invalid entries

            exposure_time = float(match.group(1))  # Extracted number

            matched_group = None
            for key in flat_files_by_group.keys():
                existing_exposure, existing_size, existing_filter = key
                if (
                    abs(existing_exposure - exposure_time) <= exposure_tolerance
                    and existing_size == image_size
                    and existing_filter == filter_name
                ):
                    matched_group = key
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size, filter_name)
                flat_files_by_group[matched_group] = []

            flat_files_by_group[matched_group].extend(file_list)

        # ✅ Create Master Calibration Directory
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # ✅ Stack Each Group
        for (exposure_time, image_size, filter_name), file_list in flat_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) - Not enough frames to stack.")
                QApplication.processEvents()
                continue

            self.update_status(f"🟢 Processing {len(file_list)} flats for {exposure_time}s ({image_size}) exposure...")
            QApplication.processEvents()

            # ✅ Extract best-matching Master Dark
            selected_master_dark = None
            master_dark_data = None

            # Find the best master dark in the treebox
            for i in range(self.flat_tree.topLevelItemCount()):
                filter_item = self.flat_tree.topLevelItem(i)

                if filter_item.text(0) == filter_name:
                    for j in range(filter_item.childCount()):
                        exposure_item = filter_item.child(j)
                        if f"{exposure_time}s" in exposure_item.text(0):
                            master_dark_filename = exposure_item.text(2).strip()

                            if master_dark_filename and master_dark_filename not in ["None", "No Calibration"]:
                                # ✅ Fix: Get the full path from self.master_files
                                for key, full_path in self.master_files.items():
                                    if master_dark_filename in full_path:
                                        selected_master_dark = full_path
                                        break

                            break  # Exit after finding a match

            # ✅ Load the Master Dark file if one was assigned
            if selected_master_dark:
                master_dark_data, _, bit_depth, is_mono = load_image(selected_master_dark)

                if master_dark_data is not None:
                    self.update_status(f"✅ Using Master Dark: {selected_master_dark} (Bit Depth: {bit_depth}, Mono: {is_mono})")
                    print(f"✅ Loaded Master Dark with shape: {master_dark_data.shape}, Bit Depth: {bit_depth}, Mono: {is_mono}")
                else:
                    self.update_status(f"❌ ERROR: Could not load Master Dark {selected_master_dark}")
                    master_dark_data = None


            # ✅ Load flats and apply dark subtraction
            stacked_data = []
            self.update_status(f"📂 Loading flat frames for calibration")
            QApplication.processEvents()

            for file in file_list:
                data, _, _, _ = load_image(file)  # Ignore metadata values

                if data is not None:
                    stacked_data.append(data)
                    self.update_status(f"📂 Loaded {os.path.basename(file)}")

            if not stacked_data:
                self.update_status("⚠️ No valid images loaded for master flat creation!")
                return

            stacked_data = np.stack(stacked_data, axis=0)  # ✅ Convert list to NumPy array (NumFrames, H, W)

            # ✅ Apply Dark Subtraction using optimized `subtract_dark()` method
            if master_dark_data is not None:
                if stacked_data.shape[1:] == master_dark_data.shape:  # ✅ Ensure shape match
                    stacked_data = subtract_dark(stacked_data, master_dark_data)  # ✅ Parallelized dark subtraction
                    self.update_status(f"⚡ Applied dark subtraction to all {stacked_data.shape[0]} flat frames")
                else:
                    self.update_status(
                        f"⚠️ Shape Mismatch: Flats {stacked_data.shape[1:]} vs Master Dark {master_dark_data.shape}"
                    )
                    print(
                        f"❌ ERROR: Skipping dark subtraction due to shape mismatch: {stacked_data.shape[1:]} vs {master_dark_data.shape}"
                    )


            # Ensure we have data before stacking
            if len(stacked_data) == 0:
                self.update_status(f"❌ ERROR: No valid frames to stack for {exposure_time}s ({image_size}).")
                continue

            stacked_data = np.stack(stacked_data, axis=0)  # Shape: (num_frames, height, width)


            # ✅ Apply Windsorized Sigma Clipping
            self.update_status(f"📊 Stacking {len(file_list)} frames using sigma clipping...")
            QApplication.processEvents()
            clipped_mean = windsorized_sigma_clip(stacked_data, lower=self.sigma_low, upper=self.sigma_high)

            # ✅ Save Master Flat
            master_flat_path = os.path.join(master_dir, f"MasterFlat_{int(exposure_time)}s_{image_size}_{filter_name}.fits")
            self.save_master_flat(clipped_mean, master_flat_path, exposure_time, filter_name)

            # ✅ Store Master Flat properly
            key = f"{filter_name} ({image_size})"
            self.master_files[key] = master_flat_path  # ✅ Ensures correct retrieval
            self.master_sizes[master_flat_path] = image_size  # ✅ Store size

            # ✅ Add to Master Flat Tree
            self.add_master_flat_to_tree(filter_name, master_flat_path)
            self.update_status(f"✅ Master Flat saved: {master_flat_path}")

            # ✅ Auto-run best matching Master Dark
            self.assign_best_master_dark()

            # ✅ Ensure Lights See Master Flat
            self.assign_best_master_files()



    def save_master_flat(self, master_flat, output_path, exposure_time, filter_name):
        """ Saves master flat as both a 32-bit floating point FITS and TIFF while ensuring no unintended normalization. """

        # ✅ Retrieve FITS header from a sample flat (to check if it's mono or color)
        original_header = None
        is_mono = True  # Default to mono

        if self.flat_files:
            sample_flat = next(iter(self.flat_files.values()))[0]  # Get the first flat file
            try:
                with fits.open(sample_flat) as hdul:
                    original_header = hdul[0].header

                    # **🔍 Detect if the flat is color by checking NAXIS3**
                    if original_header.get("NAXIS", 2) == 3 and original_header.get("NAXIS3", 1) == 3:
                        is_mono = False  # ✅ It's a color flat

            except Exception as e:
                print(f"⚠️ Warning: Could not retrieve FITS header from {sample_flat}: {e}")

        # ✅ Explicitly ensure we are saving raw values (NO normalization)
        fits_header = original_header if original_header else fits.Header()
        fits_header["BSCALE"] = 1.0  # 🔹 Prevent rescaling
        fits_header["BZERO"] = 0.0   # 🔹 Prevent offset

        # ✅ Save as FITS
        save_image(
            img_array=master_flat,
            filename=output_path,
            original_format="fits",
            bit_depth="32-bit floating point",
            original_header=fits_header,
            is_mono=is_mono
        )

        print(f"✅ Master Flat FITS saved: {output_path}")




    def add_master_flat_to_tree(self, filter_name, master_flat_path):
        """ Adds the newly created Master Flat to the Master Flat TreeBox and stores it. """

        key = f"{filter_name} ({self.master_sizes[master_flat_path]})"
        self.master_files[key] = master_flat_path  # ✅ Store the flat file for future use
        print(f"📝 DEBUG: Stored Master Flat -> {key}: {master_flat_path}")

        existing_items = self.master_flat_tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            filter_item = existing_items[0]
        else:
            filter_item = QTreeWidgetItem([filter_name])
            self.master_flat_tree.addTopLevelItem(filter_item)

        master_item = QTreeWidgetItem([os.path.basename(master_flat_path)])
        filter_item.addChild(master_item)

    def assign_best_master_files(self):
        """ Assigns the best matching Master Dark and Master Flat to each Light Frame. """
        print("\n🔍 DEBUG: Assigning best Master Darks & Flats to Lights...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Calibration Files available.")
            self.update_status("⚠️ WARNING: No Master Calibration Files available.")
            return  

        print(f"📂 Loaded Master Files ({len(self.master_files)} total):")
        for key, value in self.master_files.items():
            print(f"   📌 {key} -> {value}")

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            filter_name = filter_item.text(0)  # Example: "L" or "Ha"

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)  # Example: "120s (8288x5644)"

                # Extract exposure time and image size
                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue  

                exposure_time = float(match.group(1))  # Normalize exposure time
                print(f"🟢 Checking Light Frame: {exposure_text} (Parsed: {exposure_time}s)")

                # Get image size from metadata
                if exposure_item.childCount() > 0:
                    metadata_text = exposure_item.child(0).text(1)  # Metadata column
                    size_match = re.search(r"Size: (\d+x\d+)", metadata_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                else:
                    image_size = "Unknown"

                print(f"✅ Light Frame Size: {image_size}")

                # 🔍 Find best Master Dark (match exposure & size)
                best_match = None
                best_diff = float("inf")

                print("🔹 Stored Master Darks:")
                for stored_key in self.master_files.keys():
                    if "Dark" in stored_key:
                        print(f"   🗄️ {stored_key}")

                for master_dark_exposure, master_dark_path in self.master_files.items():
                    master_dark_exposure_match = re.match(r"([\d.]+)s?", master_dark_exposure)
                    if not master_dark_exposure_match:
                        continue  # Skip if master dark exposure is invalid

                    master_dark_exposure_time = float(master_dark_exposure_match.group(1))
                    master_dark_size = self.master_sizes.get(master_dark_path, "Unknown")
                    
                    # If size is unknown, extract from FITS header
                    if master_dark_size == "Unknown":
                        with fits.open(master_dark_path) as hdul:
                            master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                            self.master_sizes[master_dark_path] = master_dark_size  # ✅ Store it

                    print(f"   🔎 Comparing with Master Dark: {master_dark_exposure_time}s ({master_dark_size}) vs {exposure_time}s ({image_size})")

                    # Match both image size and exposure time
                    if image_size == master_dark_size:
                        diff = abs(master_dark_exposure_time - exposure_time)
                        if diff < best_diff:
                            best_match = master_dark_path
                            best_diff = diff

                # 🔍 Find best Master Flat (match filter & size)
                best_flat_match = self.master_files.get(f"{filter_name} ({image_size})", None)

                # Assign best matches
                exposure_item.setText(2, os.path.basename(best_match) if best_match else "None")
                exposure_item.setText(3, os.path.basename(best_flat_match) if best_flat_match else "None")

                print(f"✅ Final Assignment: Dark -> {os.path.basename(best_match) if best_match else 'None'}, Flat -> {os.path.basename(best_flat_match) if best_flat_match else 'None'}")

        self.light_tree.viewport().update()
        print("\n✅ DEBUG: Finished assigning best Master Files to Lights.\n")

    def update_light_corrections(self):
        """ Updates the light frame corrections when checkboxes change. """
        corrections = []
        if self.cosmetic_checkbox.isChecked():
            corrections.append("Cosmetic: True")
        else:
            corrections.append("Cosmetic: False")

        if self.pedestal_checkbox.isChecked():
            corrections.append("Pedestal: True")
        else:
            corrections.append("Pedestal: False")

        if self.bias_checkbox.isChecked():
            # Show file dialog to select a Master Bias
            bias_file, _ = QFileDialog.getOpenFileName(self, "Select Master Bias Frame", "", "FITS Files (*.fits *.fit)")
            if bias_file:
                self.master_files["Bias"] = bias_file  # ✅ Store bias path
                corrections.append(f"Bias: {os.path.basename(bias_file)}")
            else:
                self.bias_checkbox.setChecked(False)  # If no file selected, uncheck
                return

        # Update all rows
        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_item.setText(4, ", ".join(corrections))

    def light_tree_context_menu(self, pos):
        """
        Display a context menu for the light tree.
        If the clicked item is a group node (has children),
        offer to override assigned Master Darks/Flats.
        """
        item = self.light_tree.itemAt(pos)
        if not item or item.childCount() == 0:
            return  # Only show menu for group nodes

        menu = QMenu(self.light_tree)
        override_dark_action = menu.addAction("Override Dark Frame")
        override_flat_action = menu.addAction("Override Flat Frame")

        action = menu.exec(self.light_tree.viewport().mapToGlobal(pos))

        if action == override_dark_action:
            self.override_selected_master_dark()
        elif action == override_flat_action:
            self.override_selected_master_flat()


    def override_selected_master_dark(self):
        """ Opens a file dialog to manually select a Master Dark for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for dark frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Dark", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, os.path.basename(file_path))  # Update tree UI
                self.manual_dark_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Dark for {item.text(0)} with {file_path}")



    def override_selected_master_flat(self):
        """ Opens a file dialog to manually select a Master Flat for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for flat frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Flat", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(3, os.path.basename(file_path))  # Update tree UI
                self.manual_flat_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Flat for {item.text(0)} with {file_path}")


    def toggle_group_correction(self, group_item, which):
        """
        group_item: a top-level item in the light_tree
        which: either "cosmetic" or "pedestal"
        """
        old_text = group_item.text(4)  # e.g. "Cosmetic: True, Pedestal: False"
        # If there's nothing, default them to False
        if not old_text:
            old_text = "Cosmetic: False, Pedestal: False"

        # Parse
        # old_text might be "Cosmetic: True, Pedestal: False"
        # split by comma
        # part[0] => "Cosmetic: True"
        # part[1] => " Pedestal: False"
        parts = old_text.split(",")
        cosmetic_str = "False"
        pedestal_str = "False"
        if len(parts) == 2:
            # parse cosmetic
            cos_part = parts[0].split(":")[-1].strip()  # "True" or "False"
            cosmetic_str = cos_part
            # parse pedestal
            ped_part = parts[1].split(":")[-1].strip()
            pedestal_str = ped_part

        # Convert to bool
        cosmetic_bool = (cosmetic_str.lower() == "true")
        pedestal_bool = (pedestal_str.lower() == "true")

        # Toggle whichever was requested
        if which == "cosmetic":
            cosmetic_bool = not cosmetic_bool
        elif which == "pedestal":
            pedestal_bool = not pedestal_bool

        # Rebuild the new text
        new_text = f"Cosmetic: {str(cosmetic_bool)}, Pedestal: {str(pedestal_bool)}"
        group_item.setText(4, new_text)



    def calibrate_lights(self):
        """Performs calibration on selected light frames using Master Darks and Flats, considering overrides."""
        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first.")
            return

        calibrated_dir = os.path.join(self.stacking_directory, "Calibrated")
        os.makedirs(calibrated_dir, exist_ok=True)

        total_files = sum(len(files) for files in self.light_files.values())
        processed_files = 0

        # ✅ Load Master Bias if it exists
        master_bias_path = self.master_files.get("Bias", None)
        master_bias = None
        if master_bias_path:
            with fits.open(master_bias_path) as bias_hdul:
                master_bias = bias_hdul[0].data.astype(np.float32)
            self.update_status(f"Using Master Bias: {os.path.basename(master_bias_path)}")  

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)

                # Extract corrections (Cosmetic & Pedestal)
                correction_text = exposure_item.text(4)  
                apply_cosmetic = False
                apply_pedestal = False
                if correction_text:
                    parts = correction_text.split(",")
                    if len(parts) == 2:
                        apply_cosmetic = parts[0].split(":")[-1].strip().lower() == "true"
                        apply_pedestal = parts[1].split(":")[-1].strip().lower() == "true"

                # Determine pedestal value dynamically
                pedestal_value = self.pedestal_spinbox.value() / 65535 if apply_pedestal else 0  

                # 🔹 Master Dark: Use override if available
                master_dark_text = exposure_item.text(2)
                master_dark_path = self.manual_dark_overrides.get(exposure_text)
                if not master_dark_path:
                    for key, path in self.master_files.items():
                        if os.path.basename(path) == master_dark_text:
                            master_dark_path = path
                            break

                if not master_dark_path:
                    self.update_status(f"⚠️ No matching Master Dark found for '{master_dark_text}'")

                # 🔹 Master Flat: Use override if available
                master_flat_text = exposure_item.text(3)
                master_flat_path = self.manual_flat_overrides.get(exposure_text)
                if not master_flat_path:
                    for key, path in self.master_files.items():
                        if os.path.basename(path) == master_flat_text:
                            master_flat_path = path
                            break

                if not master_flat_path:
                    self.update_status(f"⚠️ No matching Master Flat found for '{master_flat_text}'")

                # Process each light file
                for light_file in self.light_files.get(f"{filter_item.text(0)} - {exposure_text}", []):
                    self.update_status(f"Processing: {os.path.basename(light_file)}")  
                    QApplication.processEvents()  

                    # ✅ Use load_image() while preserving the header
                    light_data, hdr, bit_depth, is_mono = load_image(light_file)

                    if light_data is None or hdr is None:
                        self.update_status(f"❌ ERROR: Failed to load {os.path.basename(light_file)}")
                        continue  

                    # ✅ Ensure correct orientation for OSC images
                    if not is_mono and light_data.shape[-1] == 3:
                        light_data = light_data.transpose(2, 0, 1)  # Convert (H, W, C) → (C, H, W)

                    # 🔹 Subtract Master Bias (if available)
                    if master_bias is not None:
                        if is_mono:
                            light_data -= master_bias
                        else:
                            light_data -= master_bias[np.newaxis, :, :]  # Ensure correct broadcasting
                        self.update_status("Bias Subtracted")  
                        QApplication.processEvents()  

                    # 🔹 Subtract Master Dark
                    if master_dark_path:
                        dark_data, _, _, dark_is_mono = load_image(master_dark_path)
                        if dark_data is not None:
                            if not dark_is_mono and dark_data.shape[-1] == 3:
                                dark_data = dark_data.transpose(2, 0, 1)  # Convert (H, W, C) → (C, H, W)
                            light_data = subtract_dark_with_pedestal(
                                light_data[np.newaxis, :, :], dark_data, pedestal_value
                            )[0]  
                            self.update_status(f"Dark Subtracted: {os.path.basename(master_dark_path)}")  
                            QApplication.processEvents()  

                    # 🔹 Apply Flat Division
                    if master_flat_path:
                        flat_data, _, _, flat_is_mono = load_image(master_flat_path)
                        if flat_data is not None:
                            if not flat_is_mono and flat_data.shape[-1] == 3:
                                flat_data = flat_data.transpose(2, 0, 1)  # Convert (H, W, C) → (C, H, W)
                            flat_data[flat_data == 0] = 1.0  
                            light_data = apply_flat_division_numba(light_data, flat_data)  
                            self.update_status(f"Flat Applied: {os.path.basename(master_flat_path)}")  
                            QApplication.processEvents()  

                    # 🔹 Apply Cosmetic Correction
                    if apply_cosmetic:
                        light_data = bulk_cosmetic_correction_numba(light_data)
                        self.update_status("Cosmetic Correction Applied")  
                        QApplication.processEvents()  

                    # ✅ Convert back to (H, W, C) before saving if OSC
                    if not is_mono and light_data.shape[0] == 3:
                        light_data = light_data.transpose(1, 2, 0)  # Convert back (C, H, W) → (H, W, C)

                    # 🔹 Save using global `save_image()`
                    calibrated_filename = os.path.join(
                        calibrated_dir, os.path.basename(light_file).replace(".fits", "_c.fits")
                    )

                    save_image(
                        img_array=light_data,
                        filename=calibrated_filename,
                        original_format="fits",
                        bit_depth=bit_depth,
                        original_header=hdr,
                        is_mono=is_mono
                    )  

                    processed_files += 1

                    self.update_status(f"Saved: {os.path.basename(calibrated_filename)} ({processed_files}/{total_files})")  
                    QApplication.processEvents()  

        self.update_status("✅ Calibration Complete!")  
        QApplication.processEvents()  
        self.populate_calibrated_lights()

    def extract_light_files_from_tree(self):
        """ Extracts the selected light frames from the registration tree and ensures only selected files are processed. """
        new_light_files = {}  # Temporary dictionary for extracted files

        # ✅ Clear light_files before repopulating
        self.light_files = {}

        for i in range(self.reg_tree.topLevelItemCount()):
            group_item = self.reg_tree.topLevelItem(i)
            group_key = group_item.text(0)  # Example: "L - 120s (8288x5644)"

            for j in range(group_item.childCount()):
                child_item = group_item.child(j)
                filename = child_item.text(0)

                # ✅ If it's an absolute path, use it as-is
                if os.path.isabs(filename):
                    full_path = filename
                else:
                    # ✅ Try to find in the Calibrated folder
                    calibrated_path = os.path.join(self.stacking_directory, "Calibrated", filename)
                    full_path = calibrated_path if os.path.exists(calibrated_path) else filename

                if os.path.exists(full_path):
                    if group_key not in new_light_files:
                        new_light_files[group_key] = []
                    new_light_files[group_key].append(full_path)
                else:
                    print(f"⚠️ WARNING: File not found: {full_path}")

        self.light_files = new_light_files  # ✅ Only use extracted files
        print(f"✅ Extracted Light Files: {sum(len(v) for v in self.light_files.values())} total")

    def select_reference_frame_robust(self, frame_weights, sigma_threshold=2.0):
        """
        Return the file path of a more robustly chosen reference frame.
        We exclude outlier frames whose weights are too far from the cluster,
        then pick the max from what remains.

        Parameters
        ----------
        frame_weights : dict
            { file_path: weight_value }
        sigma_threshold : float
            How many std devs away from the median to consider an outlier.

        Returns
        -------
        best_frame : str
            The file path of the chosen reference frame.
        """

        # 1) Convert weights to a list
        items = list(frame_weights.items())  # [(file_path, weight), ...]
        if not items:
            return None  # No frames

        # 2) Compute median & std
        weights_array = np.array([w for (_, w) in items], dtype=np.float32)
        median_w = np.median(weights_array)
        std_w = np.std(weights_array)

        # If std == 0, everything is the same. Just pick any.
        if std_w < 1e-12:
            # everything is identical
            # pick any arbitrary item
            return items[0][0]

        # 3) Create a filtered list that excludes frames whose weights
        #    are far above/below the cluster:
        lower_bound = median_w - sigma_threshold * std_w
        upper_bound = median_w + sigma_threshold * std_w

        filtered = []
        for fp, w in items:
            if lower_bound <= w <= upper_bound:
                filtered.append((fp, w))

        if not filtered:
            # If everything was excluded, just fallback to the median or something.
            # or pick a random frame
            self.update_status("⚠️ All frames are outliers? Falling back to median!")
            # fallback: pick the one with weight closest to the median
            best = min(items, key=lambda x: abs(x[1] - median_w))
            return best[0]

        # 4) Among filtered frames, pick the max weight
        best_frame, best_weight = max(filtered, key=lambda x: x[1])
        return best_frame


    def register_images(self):
        """ Measures all frames, aligns them, and performs weighted stacking with Windsorized Sigma Clipping. """
        self.update_status("🔄 Image Registration Started...")

        # ✅ Extract files from tree before processing
        self.extract_light_files_from_tree()
        if not self.light_files:
            self.update_status("⚠️ No light frames found!")
            return

        self.update_status("📊 Loading in frame image arrays for weight calculation...")

        self.frame_weights = {}  # ✅ Store as an instance variable
        mean_values = {}
        star_counts = {}
        measured_frames = []

        all_files = [file for file_list in self.light_files.values() for file in file_list]

        images = []  # ✅ List to store successfully loaded images
        valid_files = []  # ✅ List to track corresponding file names

        # ✅ Load images using global `load_image()` function
        for file in all_files:
            image_data, _, _, _ = load_image(file)
            self.update_status(f"Loaded {file}")
            QApplication.processEvents

            if image_data is not None:
                images.append(image_data)
                valid_files.append(file)  # Only keep valid files

        if not images:
            self.update_status("⚠️ No valid images loaded!")
            return

        self.update_status(f"✅ Loaded {len(images)} valid frames for registration.")

        # ✅ Step 1: Parallel Processing for Mean Pixel Value
        means = parallel_measure_frames(images)

        for i, file in enumerate(valid_files):
            self.update_status(f"🌍 Measuring frames... {i+1}/{len(valid_files)} global statistics.")
            mean_signal = means[i]
            mean_values[file] = mean_signal
            measured_frames.append(file)

            self.update_status(f"⭐ Measuring frames... {i+1}/{len(valid_files)} stellar statistics.")

            # ✅ Compute Star Count separately
            star_counts[file] = compute_star_count(images[i])

        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status("✅ Frame measurements complete!")

        # 5) Compute Weights for Stacking
        self.update_status("⚖️ Computing frame weights...")
        debug_weight_log = "\n📊 **Frame Weights Debug Log:**\n"

        for file in measured_frames:
            star_count = star_counts[file]
            mean_value = mean_values[file]

            # Avoid division by zero
            star_weight = max(star_count, 1e-6)
            mean_weight = max(mean_value, 1e-6)

            # Ratio-based weight
            raw_weight = star_weight / mean_weight
            self.frame_weights[file] = raw_weight

            debug_weight_log += (
                f"📂 {os.path.basename(file)} → "
                f"Star Count: {star_count}, "
                f"Mean: {mean_value:.4f}, "
                f"Raw Weight: {raw_weight:.4f}\n"
            )

        # 6) Normalize Weights so max = 1.0 (optional but recommended)
        max_w = max(self.frame_weights.values())
        if max_w > 0:
            for k in self.frame_weights:
                self.frame_weights[k] /= max_w

        debug_weight_log += "\n🔧 Normalizing Weights so maximum is 1.0:\n"
        for file in measured_frames:
            debug_weight_log += (
                f"{os.path.basename(file)} => Normalized Weight: {self.frame_weights[file]:.4f}\n"
            )

        self.update_status(debug_weight_log)
        self.update_status("✅ Frame weights computed and normalized!")

        # ✅ Step 2: Determine the Best Reference Frame
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference frame: {self.reference_frame}")
        else:
            # new robust approach
            self.reference_frame = self.select_reference_frame_robust(self.frame_weights, sigma_threshold=2.0)
            self.update_status(f"📌 Auto-selected robust reference frame: {self.reference_frame}")


        # ✅ Step 3: Align All Frames to the Reference
        output_directory = os.path.join(self.stacking_directory, "Aligned_Images")
        os.makedirs(output_directory, exist_ok=True)

        # ✅ Fix: Store thread in instance variable to prevent early destruction
        self.alignment_thread = StarRegistrationThread(self.reference_frame, measured_frames, output_directory)
        self.alignment_thread.progress_update.connect(self.update_status)

        # ✅ Ensure proper cleanup after completion
        self.alignment_thread.registration_complete.connect(self.on_registration_complete)

        self.alignment_thread.start()

    def save_alignment_matrices_sasd(self, transforms_dict):
        out_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        try:
            with open(out_path, "w") as f:
                for file_path, matrix in transforms_dict.items():
                    # *** KEY FIX: normalize the file_path before writing
                    norm_file = os.path.normpath(file_path)

                    a, b, tx = matrix[0]
                    c, d, ty = matrix[1]

                    f.write(f"FILE: {norm_file}\n")
                    f.write("MATRIX:\n")
                    f.write(f"{a:.4f}, {b:.4f}, {tx:.4f}\n")
                    f.write(f"{c:.4f}, {d:.4f}, {ty:.4f}\n")
                    f.write("\n")  # blank line
            self.update_status(f"✅ Transform file saved as {os.path.basename(out_path)}")
        except Exception as e:
            self.update_status(f"⚠️ Failed to save transform file: {e}")

    def load_alignment_matrices_custom(self, file_path):

        transforms = {}
        with open(file_path, "r") as f:
            content = f.read()

        blocks = re.split(r"\n\s*\n", content.strip())

        for block in blocks:
            lines = [line.strip() for line in block.splitlines() if line.strip()]
            if not lines:
                continue
            if lines[0].startswith("FILE:"):
                raw_file_path = lines[0].replace("FILE:", "").strip()
                # *** KEY FIX: normalize here
                curr_file = os.path.normpath(raw_file_path)
            else:
                continue
            
            if len(lines) < 4 or not lines[1].startswith("MATRIX:"):
                continue

            row0 = lines[2].split(",")
            row1 = lines[3].split(",")
            a, b, tx = [float(x) for x in row0]
            c, d, ty = [float(x) for x in row1]

            transforms[curr_file] = np.array([[a, b, tx],
                                            [c, d, ty]], dtype=np.float32)
        return transforms

    def on_registration_complete(self, success, msg):
        self.update_status(msg)

        # Get the final transforms (all normalized paths)
        all_transforms = self.alignment_thread.alignment_matrices
        self.alignment_thread = None

        # Filter out any None transforms
        valid_transforms = {
            path: mat for (path, mat) in all_transforms.items() if mat is not None
        }

        n_valid = len(valid_transforms)
        n_total = len(all_transforms)
        self.update_status(f"Alignment summary: {n_valid} succeeded, {n_total - n_valid} failed.")

        if n_valid == 0:
            self.update_status("⚠️ No frames to stack; aborting.")
            return

        # Optionally save transforms
        self.save_alignment_matrices_sasd(valid_transforms)

        # Gather drizzle
        drizzle_dict = self.gather_drizzle_settings_from_tree()

        # Filter your light_files so you only pass files that appear in valid_transforms
        # Make sure the keys match exactly, i.e. do the same normalization:
        filtered_light_files = {}
        for group, file_list in self.light_files.items():
            filtered_light_files[group] = [
                f for f in file_list
                if os.path.normpath(f) in valid_transforms
            ]
            self.update_status(
                f"Group '{group}' has {len(filtered_light_files[group])} file(s) after filtering."
            )

        # Now do the stacking
        self.stack_images_mixed_drizzle(
            grouped_files=filtered_light_files,
            frame_weights=self.frame_weights,
            transforms_dict=valid_transforms,
            drizzle_dict=drizzle_dict
        )

        # Explicitly delete the thread reference
        self.alignment_thread = None

    def stack_images_mixed_drizzle(self, grouped_files, frame_weights, transforms_dict, drizzle_dict):
        """
        Goes group by group. If drizzle_enabled, do drizzle on that group.
        Otherwise do the normal stacking.
        
        Parameters:
        -----------
        grouped_files : dict
            { group_key: [file_list], ... }
        frame_weights : dict
            { orig_file_path: float_weight, ... }
        transforms_dict : dict
            { orig_file_path: 2x3_affine_matrix, ... }
        drizzle_dict : dict
            {
            group_key: {
                "files": [...],
                "drizzle_enabled": bool,
                "scale_factor": float,
                "drop_shrink": float
            },
            ...
            }
        """
        for group_key, file_list in grouped_files.items():
            # 1) Retrieve drizzle config from drizzle_dict
            dconf = drizzle_dict.get(group_key, None)
            if not dconf:
                # Fallback: no drizzle data => normal stack
                self.stack_one_group_normal(group_key, file_list, frame_weights)
                continue

            drizzle_enabled = dconf["drizzle_enabled"]
            scale_factor = dconf["scale_factor"]
            drop_shrink = dconf["drop_shrink"]

            if drizzle_enabled:
                self.update_status(f"📐 Drizzle for group '{group_key}' at {scale_factor}× (drop={drop_shrink}).")
                self.drizzle_stack_one_group(
                    group_key=group_key,
                    file_list=file_list,
                    transforms_dict=transforms_dict,
                    frame_weights=frame_weights,  # <-- Pass weights here
                    scale_factor=scale_factor,
                    drop_shrink=drop_shrink
                )
            else:
                self.update_status(f"🌀 Normal stacking for group '{group_key}'.")
                self.stack_one_group_normal(group_key, file_list, frame_weights)


    def stack_one_group_normal(self, group_key, file_list, frame_weights):
        """
        Stacks a single group using the same code as 'stack_registered_images()',
        but restricted to one group.
        """
        # Build a tiny dict with just one entry
        single_group_dict = { group_key: file_list }

        # Reuse your existing method
        self.stack_registered_images(single_group_dict, frame_weights)


    def save_registered_images(self, success, msg, frame_weights):
        if not success:
            self.update_status(f"⚠️ Image registration failed: {msg}")
            return

        self.update_status("✅ All frames registered successfully!")
        
        # Use the grouped files already stored from the tree view.
        if not self.light_files:
            self.update_status("⚠️ No light frames available for stacking!")
            return
        
        self.update_status(f"📂 Preparing to stack {sum(len(v) for v in self.light_files.values())} frames in {len(self.light_files)} groups.")
        
        # Pass the dictionary (grouped by filter, exposure, dimensions) to the stacking function.
        self.stack_registered_images(self.light_files, frame_weights)


    def stack_registered_images(self, grouped_files, frame_weights):
        """
        Stacks registered images by group.
        
        Parameters:
        grouped_files (dict): A dictionary where each key represents a grouping
            (for example, a combination of filter, exposure, dimensions) and the value
            is a list of original file paths (as selected in the tree view) in that group.
        frame_weights (dict): A dictionary mapping original file paths to computed weights.
        
        For each group, the function maps the original file to its corresponding aligned file 
        (located in the Aligned_Images folder) – if the file isn’t already there, the "_r" suffix
        is appended (if not already present). Then it stacks the group’s images using weighted
        Windsorized Sigma Clipping and saves the resulting master stack with a dynamic filename.
        """
        # Directory where aligned images are stored.
        aligned_dir = os.path.join(self.stacking_directory, "Aligned_Images")
        
        # Process each group separately.
        for group_key, file_list in grouped_files.items():
            self.update_status(f"📊 Stacking group '{group_key}' with {len(file_list)} files...")
            if len(file_list) < 2:
                self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to stack.")
                continue

            stacked_data = []
            weights = []
            reference_median = None
            reference_header = None

            # Determine the reference frame for this group:
            # If self.reference_frame is in this group, use it; otherwise, use the first file.
            group_ref = self.reference_frame if self.reference_frame in file_list else file_list[0]

            for orig_file in file_list:
                try:
                    # Map the original file to its aligned version.
                    if os.path.dirname(orig_file) == aligned_dir:
                        # Already in the aligned directory.
                        aligned_file_path = orig_file
                    else:
                        base = os.path.basename(orig_file)
                        name, ext = os.path.splitext(base)
                        # Force extension to ".fits" (even if the tree shows ".fit")
                        if ext.lower() not in [".fits", ".fit"]:
                            ext = ".fits"
                        else:
                            ext = ".fits"  # Always use .fits for aligned images

                        if os.path.dirname(orig_file) == aligned_dir:
                            # Already in the aligned directory.
                            aligned_file_path = orig_file
                        else:
                            if not name.endswith("_r"):
                                name_aligned = f"{name}_r"
                            else:
                                name_aligned = name
                            aligned_file_path = os.path.join(aligned_dir, f"{name_aligned}{ext}")

                    # Load the aligned image.
                    image_data, header, _, _ = load_image(aligned_file_path)
                    if image_data is None:
                        self.update_status(f"⚠️ Registration Failed: {aligned_file_path}")
                        continue

                    stacked_data.append(image_data)
                    weight = frame_weights.get(orig_file, 1.0)
                    weights.append(weight)

                    # If this file is the designated reference, capture its median and header.
                    if orig_file == group_ref:
                        reference_median = np.median(image_data)
                        reference_header = header.copy()

                except Exception as e:
                    self.update_status(f"⚠️ Error processing '{orig_file}' (mapped to '{aligned_file_path}'): {e}")

            if len(stacked_data) < 2:
                self.update_status(f"⚠️ Not enough valid frames in group '{group_key}' to stack.")
                continue

            # If we did not capture the reference header/median, try loading the reference frame directly.
            if reference_median is None:
                try:
                    self.update_status("ℹ️ Reference frame median not found in loop. Loading reference frame directly...")
                    if os.path.dirname(group_ref) == aligned_dir:
                        ref_aligned_path = group_ref
                    else:
                        base = os.path.basename(group_ref)
                        name, ext = os.path.splitext(base)
                        if not name.endswith("_r"):
                            name_aligned = f"{name}_r"
                        else:
                            name_aligned = name
                        ref_aligned_path = os.path.join(aligned_dir, f"{name_aligned}{ext}")
                    ref_data, ref_header, _, _ = load_image(ref_aligned_path)
                    if ref_data is None:
                        raise ValueError("Reference image data is None")
                    reference_median = np.median(ref_data)
                    reference_header = ref_header.copy()
                except Exception as e:
                    self.update_status(f"⚠️ Failed to load reference frame for group '{group_key}': {e}. Using first frame as fallback.")
                    reference_median = np.median(stacked_data[0])
                    # Try to set reference_header from the first valid frame.
                    try:
                        first_file = file_list[0]
                        if os.path.dirname(first_file) == aligned_dir:
                            first_aligned = first_file
                        else:
                            base = os.path.basename(first_file)
                            name, ext = os.path.splitext(base)
                            if not name.endswith("_r"):
                                name_aligned = f"{name}_r"
                            else:
                                name_aligned = name
                            first_aligned = os.path.join(aligned_dir, f"{name_aligned}{ext}")
                        _, first_header, _, _ = load_image(first_aligned)
                        reference_header = first_header.copy()
                    except Exception:
                        reference_header = fits.Header()

            # Stack the images.
            stacked_data = np.stack(stacked_data, axis=0)  # Shape: (num_frames, height, width)
            weights = np.array(weights, dtype=np.float32)

            self.update_status(f"📊 Normalizing group '{group_key}' images to reference median: {reference_median:.4f}")
            stacked_data = normalize_images(stacked_data, reference_median)

            # At the point where you apply the rejection algorithm:
            self.update_status(f"📊 Applying {self.rejection_algorithm} on group '{group_key}'...")
            QApplication.processEvents()

            selected_algo = self.rejection_algorithm

            if selected_algo == "Weighted Windsorized Sigma Clipping":
                clipped_mean = windsorized_sigma_clip_weighted(
                    stacked_data, weights,
                    lower=self.sigma_low, upper=self.sigma_high
                )
            elif selected_algo == "Kappa-Sigma Clipping":
                clipped_mean = kappa_sigma_clip_weighted(
                    stacked_data, weights,
                    kappa=self.kappa, iterations=self.iterations
                )
            elif selected_algo == "Simple Average (No Rejection)":
                clipped_mean = np.average(stacked_data, axis=0, weights=weights)
            elif selected_algo == "Simple Median (No Rejection)":
                clipped_mean = np.median(stacked_data, axis=0)
            elif selected_algo == "Trimmed Mean":
                clipped_mean = trimmed_mean_weighted(
                    stacked_data, weights,
                    trim_fraction=self.trim_fraction
                )
            elif selected_algo == "Extreme Studentized Deviate (ESD)":
                clipped_mean = esd_clip_weighted(
                    stacked_data, weights,
                    threshold=self.esd_threshold
                )
            elif selected_algo == "Biweight Estimator":
                clipped_mean = biweight_location_weighted(
                    stacked_data, weights,
                    tuning_constant=self.biweight_constant
                )
            elif selected_algo == "Modified Z-Score Clipping":
                clipped_mean = modified_zscore_clip_weighted(
                    stacked_data, weights,
                    threshold=self.modz_threshold
                )
            else:
                clipped_mean = windsorized_sigma_clip_weighted(
                    stacked_data, weights,
                    lower=self.sigma_low, upper=self.sigma_high
                )

            # Use the group key as part of the output filename.
            # Alternatively, you could derive the key from the header.
            output_filename = f"MasterLight_{group_key}.fits"
            output_path = os.path.join(self.stacking_directory, output_filename)

            # Determine if the stacked image is color or mono
            if clipped_mean.ndim == 3 and clipped_mean.shape[-1] == 3:
                is_mono = False  # Color (H, W, C)
            else:
                is_mono = True   # Mono (H, W)

            # Update the FITS header
            if reference_header is None:
                reference_header = fits.Header()
                
            reference_header["IMAGETYP"] = "MASTER STACK"
            reference_header["BITPIX"] = -32  # 32-bit floating point
            reference_header["STACKED"] = (True, "Stacked using rejection algorithm")
            reference_header["CREATOR"] = "SetiAstroSuite"
            reference_header["DATE-OBS"] = datetime.utcnow().isoformat()

            # ✅ Ensure header matches image dimensions
            if is_mono:
                reference_header["NAXIS"] = 2
                reference_header["NAXIS1"] = clipped_mean.shape[1]  # Width
                reference_header["NAXIS2"] = clipped_mean.shape[0]  # Height
            else:
                reference_header["NAXIS"] = 3
                reference_header["NAXIS1"] = clipped_mean.shape[1]  # Width
                reference_header["NAXIS2"] = clipped_mean.shape[0]  # Height
                reference_header["NAXIS3"] = 3  # OSC: 3 color channels

            # ✅ Save using the global save_image() method.
            save_image(
                img_array=clipped_mean,
                filename=output_path,
                original_format="fits",
                bit_depth="32-bit floating point",
                original_header=reference_header,
                is_mono=is_mono  # Pass corrected flag
            )

            self.update_status(f"✅ Group '{group_key}' stacking complete! Saved: {output_path}")
            print(f"✅ Master Light saved for group '{group_key}': {output_path}")

    def integrate_registered_images(self):
        """ Integrates previously registered images (already aligned) without re-aligning them. """
        self.update_status("🔄 Integrating Previously Registered Images...")

        # Extract the files from the registration tree
        self.extract_light_files_from_tree()
        if not self.light_files:
            self.update_status("⚠️ No registered images found!")
            return

        # Collect all registered files
        all_files = [file for file_list in self.light_files.values() for file in file_list]
        images = []
        valid_files = []
        for file in all_files:
            image_data, _, _, _ = load_image(file)
            if image_data is not None:
                images.append(image_data)
                valid_files.append(file)

        if not images:
            self.update_status("⚠️ No valid registered images loaded!")
            return

        self.update_status(f"✅ Loaded {len(images)} valid registered frames for integration.")

        # Compute frame weights (similar to registration but skipping alignment)
        self.frame_weights = {}
        mean_values = {}
        star_counts = {}
        measured_frames = []

        means = parallel_measure_frames(images)

        for i, file in enumerate(valid_files):
            self.update_status(f"🌍 Measuring frames... {i+1}/{len(valid_files)} global statistics.")
            mean_signal = means[i]
            mean_values[file] = mean_signal
            measured_frames.append(file)

            self.update_status(f"⭐ Measuring frames... {i+1}/{len(valid_files)} stellar statistics.")

            # ✅ Compute Star Count separately
            star_counts[file] = compute_star_count(images[i])

        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status("✅ Frame measurements complete!")

        # ✅ Step 5: Compute Weights for Stacking
        self.update_status("⚖️ Computing frame weights...")

        debug_weight_log = "\n📊 **Frame Weights Debug Log:**\n"

        for file in measured_frames:
            star_count = star_counts[file]
            mean_value = mean_values[file]

            # ✅ Ensure no division by zero
            star_weight = max(star_count, 1e-6)
            mean_weight = max(mean_value, 1e-6)

            # ✅ Ratio-based weight calculation
            self.frame_weights[file] = star_weight / mean_weight  # ✅ Always positive

            # ✅ Add to debug log
            debug_weight_log += f"📂 {os.path.basename(file)} → Star Count: {star_count}, Mean: {mean_value:.4f}, Final Weight: {self.frame_weights[file]:.4f}\n"

        self.update_status(debug_weight_log)  # ✅ Print weights to the status window
        self.update_status("✅ Frame weights computed!")

        # ✅ Step 2: Determine the Best Reference Frame
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference frame: {self.reference_frame}")
        else:
            self.reference_frame = max(self.frame_weights, key=self.frame_weights.get)
            self.update_status(f"📌 Auto-selected reference frame: {self.reference_frame} (Best Weight)")

        # Call the stacking function using the already registered (aligned) images
        self.stack_registered_images(self.light_files, self.frame_weights)

    def drizzle_stack_one_group(
        self,
        group_key,
        file_list,
        transforms_dict,
        frame_weights,
        scale_factor=2.0,
        drop_shrink=0.65
    ):
        """
        Drizzle a single group, handling both mono (H,W) and color (H,W,C).
        We choose naive vs. footprint deposit based on drop_shrink.
        Then we do a final combination with the appropriate finalize function.
        """

        self.update_status(
            f"🔭 Starting drizzle stacking for group '{group_key}' "
            f"at {scale_factor}× with drop shrink={drop_shrink}"
        )

        # 1) Check we have enough frames
        if len(file_list) < 2:
            self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to drizzle.")
            return

        # 2) Load transforms from disk (assuming we always do it this way)
        transforms_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        if not os.path.exists(transforms_path):
            self.update_status(f"⚠️ No alignment_transforms.sasd found at {transforms_path}!")
            return

        new_transforms_dict = self.load_alignment_matrices_custom(transforms_path)
        self.update_status(f"✅ Loaded {len(new_transforms_dict)} transforms from disk for drizzle.")

        # 3) Load the first file to determine shape + color/mono
        first_file = file_list[0]
        first_img, hdr, _, _ = load_image(first_file)
        if first_img is None:
            self.update_status(f"⚠️ Could not load {first_file} to determine drizzle shape!")
            return


        if first_img.ndim == 2:
            # MONO (H,W)
            is_mono = True
            h, w = first_img.shape
        else:
            # COLOR (H,W,C)
            is_mono = False
            h, w, c = first_img.shape

        # 4) Decide deposit function (naive vs footprint) for mono or color
        if drop_shrink >= 0.99:
            # Naive deposit
            if is_mono:
                deposit_func = drizzle_deposit_numba_naive  # your mono naive
                self.update_status("Using naive drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_naive  # you'd need to define drizzle_deposit_color_naive
                self.update_status("Using naive drizzle deposit (color).")
        else:
            # Footprint deposit
            if is_mono:
                deposit_func = drizzle_deposit_numba_footprint  # your mono footprint
                self.update_status("Using footprint drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_footprint # your color footprint
                self.update_status("Using footprint drizzle deposit (color).")

        # 5) Prepare the drizzle/coverage buffers
        if is_mono:
            # first_img.shape => (H, W)
            h, w = first_img.shape
            out_h = int(h * scale_factor)
            out_w = int(w * scale_factor)

            drizzle_buffer = np.zeros((out_h, out_w), dtype=np.float32)
            coverage_buffer = np.zeros((out_h, out_w), dtype=np.float32)

            finalize_func = finalize_drizzle_2d  # 2D final combination
        else:
            # color => (H, W, C)
            h, w, c = first_img.shape
            out_h = int(h * scale_factor)
            out_w = int(w * scale_factor)

            drizzle_buffer = np.zeros((out_h, out_w, c), dtype=np.float32)
            coverage_buffer = np.zeros((out_h, out_w, c), dtype=np.float32)

            finalize_func = finalize_drizzle_3d  # 3D final combination

        # 6) Deposit each file
        for orig_file in file_list:
            img_data, _, _, _ = load_image(orig_file)
            if img_data is None:
                self.update_status(f"⚠️ Could not load {orig_file} for drizzle!")
                continue

            norm_orig = os.path.normpath(orig_file)
            transform = new_transforms_dict.get(norm_orig, None)
            if transform is None:
                self.update_status(f"⚠️ No transform found for {orig_file}! Skipping drizzle.")
                continue

            weight = frame_weights.get(orig_file, 1.0)

            drizzle_buffer, coverage_buffer = deposit_func(
                img_data,
                transform,
                drizzle_buffer,
                coverage_buffer,
                scale_factor,
                drop_shrink,
                weight
            )

        # 7) Final combination
        #    Allocate final array matching drizzle_buffer's shape
        final_drizzle = np.zeros_like(drizzle_buffer, dtype=np.float32)
        final_drizzle = finalize_func(drizzle_buffer, coverage_buffer, final_drizzle)

        # 8) Save
        out_filename = f"MasterLight_{group_key}_drizzle.fits"
        out_path = os.path.join(self.stacking_directory, out_filename)

        if hdr is None:
            hdr = fits.Header()
        hdr["IMAGETYP"]  = "MASTER STACK - DRIZZLE"
        hdr["DRIZFACTOR"] = (scale_factor, "Drizzle scale factor")
        hdr["DROPFRAC"]   = (drop_shrink, "Drizzle drop shrink/pixfrac")
        hdr["CREATOR"]    = "SetiAstroSuite"
        hdr["DATE-OBS"]   = datetime.utcnow().isoformat()

        # Determine if the drizzle-stacked image is color or mono
        if final_drizzle.ndim == 3 and final_drizzle.shape[-1] == 3:
            is_mono = False  # Color (H, W, C)
        else:
            is_mono = True   # Mono (H, W)

        # ✅ Ensure header matches image dimensions
        if is_mono:
            hdr["NAXIS"] = 2
            hdr["NAXIS1"] = final_drizzle.shape[1]  # Width
            hdr["NAXIS2"] = final_drizzle.shape[0]  # Height
        else:
            hdr["NAXIS"] = 3
            hdr["NAXIS1"] = final_drizzle.shape[1]  # Width
            hdr["NAXIS2"] = final_drizzle.shape[0]  # Height
            hdr["NAXIS3"] = 3  # OSC: 3 color channels

        # ✅ Save using the global save_image() method.
        save_image(
            img_array=final_drizzle,
            filename=out_path,
            original_format="fits",
            bit_depth="32-bit floating point",
            original_header=hdr,
            is_mono=is_mono  # Pass corrected flag
        )


        self.update_status(f"✅ Drizzle group '{group_key}' done! Saved: {out_path}")

# --------------------------------------------------
# MosaicMasterDialog with blending/normalization integrated
# --------------------------------------------------
def get_wcs_from_header(header):
    """Attempt to create a WCS from a FITS header."""
    if not header:
        return None
    try:
        # First, try normally:
        wcs = WCS(header)
        if wcs.is_celestial:
            return wcs
        # If not celestial and header has more than 2 axes, force naxis=2.
        if header.get('NAXIS', 0) > 2:
            wcs = WCS(header, naxis=2)
            if wcs.is_celestial:
                return wcs
        return None
    except Exception:
        return None
    
def robust_api_request(method, url, data=None, files=None, prompt_on_failure=False):
    """
    Sends an API request without automatic retries. If the request fails (network error or invalid JSON response),
    prompts the user if they want to start completely over. If the user chooses to try again,
    the function calls itself recursively.
    """
    try:
        if method == "GET":
            response = requests.get(url, timeout=600)
        elif method == "POST":
            response = requests.post(url, data=data, files=files, timeout=600)
        else:
            raise ValueError("Unsupported request method: " + method)

        response.raise_for_status()  # Raise HTTP errors (e.g., 500, 404)

        try:
            return response.json()  # Attempt to parse JSON
        except json.JSONDecodeError:
            error_message = f"Invalid JSON response from {url}."
            print(error_message)
            if prompt_on_failure:
                user_choice = QMessageBox.question(
                    None,
                    "Invalid Response",
                    f"{error_message}\nDo you want to start over?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
                )
                if user_choice == QMessageBox.StandardButton.Yes:
                    return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
                else:
                    return None
            else:
                return None

    except requests.exceptions.RequestException as e:
        error_message = f"Network error when contacting {url}: {e}."
        print(error_message)
        if prompt_on_failure:
            user_choice = QMessageBox.question(
                None,
                "Network Error",
                f"{error_message}\nDo you want to start over?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if user_choice == QMessageBox.StandardButton.Yes:
                return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
            else:
                return None
        else:
            return None


def scale_image_for_display(image):
    """
    Scales a floating point image (0-1) to 8-bit (0-255) for display.
    """
    if np.max(image) == np.min(image):
        return np.zeros_like(image, dtype=np.uint8)  # Prevent division by zero
    scaled = (255 * (image - np.min(image)) / (np.max(image) - np.min(image))).astype(np.uint8)
    return scaled

def generate_minimal_fits_header(image):
    header = Header()
    header['SIMPLE'] = True
    # Set BITPIX according to the image’s data type.
    if np.issubdtype(image.dtype, np.integer):
        header['BITPIX'] = 16  # For 16-bit integer data.
    elif np.issubdtype(image.dtype, np.floating):
        header['BITPIX'] = -32  # For 32-bit float data.
    else:
        raise ValueError("Unsupported image data type for FITS header generation.")
    header['NAXIS'] = 2
    header['NAXIS1'] = image.shape[1]  # width
    header['NAXIS2'] = image.shape[0]  # height
    header['COMMENT'] = "Minimal header generated for blind solve"
    return header


class MosaicPreviewWindow(QDialog):
    def __init__(self, image_array, title="", parent=None):
        super().__init__(parent)
        self.setWindowTitle(title if title else "Preview")

        # Keep the original array around for re-stretch or reset
        self.original_array = image_array.copy()
        # Current displayed array (8-bit or whatever you want)
        self.image_array = image_array.copy()

        # Zoom state
        self.zoom_factor = 1.0

        # Variables for panning (dragging)
        self.dragging = False
        self.last_mouse_pos = QPoint()
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # 1) QScrollArea to enable scrollbars for large images
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # 2) Label inside the scroll area
        self.preview_label = QLabel("No image yet.")
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)
        self.scroll_area.viewport().installEventFilter(self)

        # 3) Auto-Stretch Toggle
        self.stretch_toggle = QCheckBox("Auto-Stretch for Display")
        self.stretch_toggle.setChecked(True)
        self.stretch_toggle.stateChanged.connect(self.update_display)
        layout.addWidget(self.stretch_toggle)

        # 4) Button row (Zoom, Fit, etc.)
        button_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        self.fit_button = QPushButton("Fit to Preview")
        self.fit_button.clicked.connect(self.fit_to_preview)
        button_layout.addWidget(self.fit_button)

        self.autostretch_button = QPushButton("Reapply Stretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        button_layout.addWidget(self.autostretch_button)

        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.close)
        button_layout.addWidget(close_btn)

        layout.addLayout(button_layout)

        self.setLayout(layout)
        # Finally, display the initial image
        self.display_image(self.image_array)

    def display_image(self, arr):
        """
        Convert array to QPixmap and display in preview_label.
        We'll respect self.zoom_factor to scale the pixmap.
        """
        if arr is None or arr.size == 0:
            print("WARNING: Trying to display an empty image.")
            return

        # Possibly apply auto-stretch
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr)
        else:
            # If it's already 8-bit or float, just convert to 8-bit safely
            arr_display = self.to_8bit(arr)
        
        # Convert single-channel => 3 channels if needed
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        # Make QImage => QPixmap
        h, w, c = arr_3ch.shape
        bytes_per_line = w * c
        qimg = QImage(arr_3ch.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(qimg)

        # Apply zoom factor
        new_w = int(w * self.zoom_factor)
        new_h = int(h * self.zoom_factor)
        if new_w < 1: new_w = 1
        if new_h < 1: new_h = 1

        scaled_pixmap = pixmap.scaled(
            new_w, new_h,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # Set the label to the scaled pixmap
        self.preview_label.setPixmap(scaled_pixmap)
        # Important: set the label size so the scroll area can scroll if it's bigger
        self.preview_label.resize(scaled_pixmap.size())

    def stretch_for_display(self, arr):
        """
        Applies an auto-stretch to improve visualization:
          1) Compute 0.5 and 99.5 percentiles
          2) Rescale to [0..255]
        """
        arr = arr.astype(np.float32, copy=False)
        mn, mx = np.percentile(arr, (0.5, 99.5))
        if mx > mn:
            arr = (arr - mn) / (mx - mn)
        else:
            arr = np.zeros_like(arr)
        arr = (arr * 255).clip(0, 255).astype(np.uint8)
        return arr

    def eventFilter(self, source, event):
        """
        Capture mouse events on the scroll_area.viewport():
          - Left-button press => start dragging
          - Mouse move => if dragging, pan
          - Left-button release => stop dragging
          - Wheel => zoom in/out
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = True
                    self.last_mouse_pos = event.pos()
                    return True  # We handled it
            elif event.type() == QEvent.Type.MouseMove:
                if self.dragging:
                    # Compute how far we moved
                    delta = event.pos() - self.last_mouse_pos
                    self.last_mouse_pos = event.pos()

                    # Adjust scrollbars
                    h_bar = self.scroll_area.horizontalScrollBar()
                    v_bar = self.scroll_area.verticalScrollBar()
                    h_bar.setValue(h_bar.value() - delta.x())
                    v_bar.setValue(v_bar.value() - delta.y())

                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = False
                    return True
            elif event.type() == QEvent.Type.Wheel:
                # Zoom in or out
                if event.angleDelta().y() > 0:
                    self.zoom_in()
                else:
                    self.zoom_out()
                event.accept()
                return True
        return super().eventFilter(source, event)

    def to_8bit(self, arr):
        """
        Simple fallback if not using auto-stretch:
        - If float in [0..1], multiply by 255
        - If already 8-bit, do nothing
        """
        if arr.dtype == np.uint8:
            return arr
        # else assume float [0..1]
        return (arr*255).clip(0,255).astype(np.uint8)

    def update_display(self):
        """
        Called when toggling the stretch checkbox. Re-display the image.
        """
        self.display_image(self.image_array)

    def autostretch_image(self):
        """
        Auto-stretch the original image and update preview.
        If the image has multiple channels, we do the same approach as stretch_for_display
        but typically you'd do something more advanced for color.
        """
        arr = self.original_array.copy()
        # e.g., if color, you might do a channel-by-channel approach
        # For simplicity, let's do a grayscale approach using the mean:
        if arr.ndim == 3:
            # we create a single channel for stretch
            g = np.mean(arr, axis=-1)
            arr_stretched = self.stretch_for_display(g)
            # Then broadcast back to 3 channels
            arr_stretched = np.stack([arr_stretched]*3, axis=-1)
        else:
            arr_stretched = self.stretch_for_display(arr)
        self.image_array = arr_stretched
        self.display_image(self.image_array)

    # ---------------------
    # ZOOM Methods
    # ---------------------
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.display_image(self.image_array)

    def zoom_out(self):
        self.zoom_factor /= 1.2
        if self.zoom_factor < 0.05:
            self.zoom_factor = 0.05
        self.display_image(self.image_array)

    def fit_to_preview(self):
        """
        Scale the image so it fits inside the scroll_area's viewport.
        We'll measure the image's actual size, compare to the viewport,
        and adjust zoom_factor accordingly.
        """
        if self.image_array is None or self.image_array.size == 0:
            return

        # We'll figure out the image's *unzoomed* dimensions
        arr_display = self.image_array
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr_display)
        else:
            arr_display = self.to_8bit(arr_display)

        # Convert single-channel => 3 channels if needed, to find w,h
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        h, w, c = arr_3ch.shape

        # The scroll area viewport size
        viewport_size = self.scroll_area.viewport().size()
        vw, vh = viewport_size.width(), viewport_size.height()

        # Compute the scale factor to fit image inside viewport
        scale_w = vw / w if w else 1.0
        scale_h = vh / h if h else 1.0
        new_zoom = min(scale_w, scale_h)
        if new_zoom <= 0:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.display_image(self.image_array)

    def resizeEvent(self, event):
        """
        Refresh displayed pixmap when window is resized,
        only if we want the displayed image to keep fitting automatically.
        But typically, we won't auto-fit on window resize if user is controlling zoom.
        """
        super().resizeEvent(event)
        # Optionally do:
        # self.fit_to_preview()
        # or if you want to keep the user-chosen zoom, just re-display:
        self.display_image(self.image_array)

class MosaicSettingsDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Mosaic Master Settings")
        self.initUI()

    def initUI(self):
        layout = QFormLayout(self)

        # Number of Stars to Attempt to Use
        self.starCountSpin = CustomSpinBox(minimum=1, maximum=1000,
                                        initial=self.settings.value("mosaic/num_stars", 150, type=int),
                                        step=1)
        layout.addRow("Number of Stars:", self.starCountSpin)

        # Translation Max Tolerance
        self.transTolSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/translation_max_tolerance", 3.0, type=float),
                                                step=0.1)
        layout.addRow("Translation Max Tolerance:", self.transTolSpin)

        # Scale Min Tolerance
        self.scaleMinSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_min_tolerance", 0.8, type=float),
                                                step=0.1)
        layout.addRow("Scale Min Tolerance:", self.scaleMinSpin)

        # Scale Max Tolerance
        self.scaleMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_max_tolerance", 1.25, type=float),
                                                step=0.1)
        layout.addRow("Scale Max Tolerance:", self.scaleMaxSpin)

        # Rotation Max Tolerance
        self.rotationMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=180.0,
                                                initial=self.settings.value("mosaic/rotation_max_tolerance", 45.0, type=float),
                                                step=0.1)
        # Force two decimals in display
        self.rotationMaxSpin.lineEdit.setText(f"{self.rotationMaxSpin.value():.2f}")
        layout.addRow("Rotation Max Tolerance (°):", self.rotationMaxSpin)

        # Skew Max Tolerance
        self.skewMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=1.0,
                                            initial=self.settings.value("mosaic/skew_max_tolerance", 0.1, type=float),
                                            step=0.01)
        layout.addRow("Skew Max Tolerance:", self.skewMaxSpin)

        # FWHM for Star Detection
        self.fwhmSpin = CustomDoubleSpinBox(minimum=0.0, maximum=20.0,
                                            initial=self.settings.value("mosaic/star_fwhm", 3.0, type=float),
                                            step=0.1)
        self.fwhmSpin.lineEdit.setText(f"{self.fwhmSpin.value():.2f}")
        layout.addRow("FWHM for Star Detection:", self.fwhmSpin)

        # Sigma for Star Detection
        self.sigmaSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                            initial=self.settings.value("mosaic/star_sigma", 3.0, type=float),
                                            step=0.1)
        self.sigmaSpin.lineEdit.setText(f"{self.sigmaSpin.value():.2f}")
        layout.addRow("Sigma for Star Detection:", self.sigmaSpin)

        # Polynomial Degree
        self.polyDegreeSpin = CustomSpinBox(minimum=1, maximum=6,
                                            initial=self.settings.value("mosaic/poly_degree", 3, type=int),
                                            step=1)
        layout.addRow("Polynomial Degree:", self.polyDegreeSpin)


    def accept(self):
        # Save the values to QSettings
        self.settings.setValue("mosaic/num_stars", self.starCountSpin.value())
        self.settings.setValue("mosaic/translation_max_tolerance", self.transTolSpin.value())
        self.settings.setValue("mosaic/scale_min_tolerance", self.scaleMinSpin.value())
        self.settings.setValue("mosaic/scale_max_tolerance", self.scaleMaxSpin.value())
        self.settings.setValue("mosaic/rotation_max_tolerance", self.rotationMaxSpin.value())
        self.settings.setValue("mosaic/skew_max_tolerance", self.skewMaxSpin.value())
        self.settings.setValue("mosaic/star_fwhm", self.fwhmSpin.value())
        self.settings.setValue("mosaic/star_sigma", self.sigmaSpin.value())
        super().accept()


class MosaicMasterDialog(QDialog):
    def __init__(self, settings: QSettings, parent=None, image_manager=None):
        super().__init__(parent)
        self.settings = settings
        self.image_manager = image_manager
        self.setWindowTitle("Mosaic Master")
        self.resize(600, 400)
        self.loaded_images = []  
        self.final_mosaic = None
        self.weight_mosaic = None
        self.wcs_metadata = None  # To store mosaic WCS header
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        # Variables to store stretching parameters:
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        instructions = QLabel(
            "Mosaic Master:\n"
            "1) Add images - Highly Recommend Images be Linear FITS\n"
            "2) Choose Transformation Type:\n"
            "....Partial Affine - Great for Images with Translation, Rotation, and Scaling Needs\n"
            "....Affine - Great for Images that also have skew distortions\n"
            "....Homography - Great for Images that also have lens or perspective distortion\n"
            "....Polynomial Warp - Useful in large mosaics to bend the images together\n"
            "3) Align & Create Mosaic\n"
            "4) Save to Image Manager"
        )
        instructions.setWordWrap(True)
        layout.addWidget(instructions)

        btn_layout = QHBoxLayout()
        # Button to add image from disk
        add_btn = QPushButton("Add Image")
        add_btn.clicked.connect(self.add_image)
        btn_layout.addWidget(add_btn)

        # New button to add an image from one of the ImageManager slots
        add_from_slot_btn = QPushButton("Add from Slot")
        add_from_slot_btn.clicked.connect(self.add_image_from_slot)
        btn_layout.addWidget(add_from_slot_btn)

        remove_btn = QPushButton("Remove Selected")
        remove_btn.clicked.connect(self.remove_selected)
        btn_layout.addWidget(remove_btn)

        preview_btn = QPushButton("Preview Selected")
        preview_btn.clicked.connect(self.preview_selected)
        btn_layout.addWidget(preview_btn)

        align_btn = QPushButton("Align and Create Mosaic")
        align_btn.clicked.connect(self.align_images)
        btn_layout.addWidget(align_btn)

        save_btn = QPushButton("Save to Image Manager")
        save_btn.clicked.connect(self.create_mosaic)
        btn_layout.addWidget(save_btn)

        layout.addLayout(btn_layout)

        # Add the wrench button for settings.
        wrench_btn = QPushButton()
        wrench_btn.setIcon(QIcon(wrench_path))
        wrench_btn.setToolTip("Mosaic Settings")
        wrench_btn.clicked.connect(self.openSettings)
        btn_layout.addWidget(wrench_btn)

        layout.addLayout(btn_layout)

        # Checkbox for forcing blind solve
        self.forceBlindCheckBox = QCheckBox("Force Blind Solve (ignore existing WCS)")
        layout.addWidget(self.forceBlindCheckBox)

        self.transform_combo = QComboBox()
        self.transform_combo.addItems([
            "Partial Affine Transform",
            "Affine Transform",
            "Homography Transform",
            "Polynomial Warp Based Transform"
        ])
        # Set the default selection to "Affine Transform" (index 1)
        self.transform_combo.setCurrentIndex(1)
        layout.addWidget(QLabel("Select Transformation Method:"))
        layout.addWidget(self.transform_combo)

        self.images_list = QListWidget()
        self.images_list.setSelectionMode(self.images_list.SelectionMode.SingleSelection)
        layout.addWidget(self.images_list)

        self.status_label = QLabel("Status: no images")
        layout.addWidget(self.status_label)

        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide() 
        layout.addWidget(self.spinnerLabel)

        self.setLayout(layout)

    def openSettings(self):
        dlg = MosaicSettingsDialog(self.settings, self)
        if dlg.exec():
            self.status_label.setText("Mosaic settings updated.")

    # ---------- Add / Remove ----------
    def add_image(self):
        paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Add Image(s)",
            "",
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if paths:
            for path in paths:
                arr, header, bitdepth, ismono = load_image(path)
                wcs_obj = get_wcs_from_header(header) if header else None
                d = {
                    "path": path,
                    "image": arr,
                    "header": header,
                    "wcs": wcs_obj,
                    "bit_depth": bitdepth,
                    "is_mono": ismono,
                    "transform": None
                }
                self.loaded_images.append(d)

                text = os.path.basename(path)
                if wcs_obj is not None:
                    text += " [WCS]"
                item = QListWidgetItem(text)
                item.setToolTip(path)
                self.images_list.addItem(item)
            self.update_status()


    # ---------- New Method: Add Image From a Slot ----------
    def add_image_from_slot(self):
        """
        Allow the user to add an image from one of the ImageManager’s slots.
        The dropdown will list only slots that contain an image, showing the renamed name
        (if available via metadata['display_name']), or else falling back to the file basename.
        """
        available_slots = []
        # Iterate through all slots managed by ImageManager
        for slot, img in self.image_manager._images.items():
            if img is not None:
                metadata = self.image_manager._metadata[slot]
                # Use a renamed name if available, otherwise use the file path basename or a default
                display_name = metadata.get("display_name")
                if not display_name:
                    file_path = metadata.get("file_path")
                    display_name = os.path.basename(file_path) if file_path else f"Slot {slot}"
                available_slots.append((slot, display_name))
        
        if not available_slots:
            QMessageBox.information(self, "Add Image", "No images available in slots.")
            return

        # Create a list of strings for the dropdown, e.g., "Slot 0: MyRenamedImage"
        items = [f"Slot {slot}: {name}" for slot, name in available_slots]

        # Let the user choose from the available slots
        item, ok = QInputDialog.getItem(self, "Select Image", "Select an image from slots:", items, 0, False)
        if not ok or not item:
            return

        # Parse the selected slot number. We assume the string format "Slot X: <name>"
        selected_slot = int(item.split(":")[0].split()[1])
        metadata = self.image_manager._metadata[selected_slot]
        image = self.image_manager._images[selected_slot]
        wcs_obj = get_wcs_from_header(metadata.get("original_header", None)) if metadata.get("original_header") else None

        # Create a dictionary similar to that used for loaded images
        d = {
            "path": metadata.get("file_path", f"Slot {selected_slot} image"),
            "image": image,
            "header": metadata.get("original_header"),
            "wcs": wcs_obj,
            "bit_depth": metadata.get("bit_depth"),
            "is_mono": metadata.get("is_mono", False),
            "transform": None
        }
        self.loaded_images.append(d)

        # Determine the text to display. Use the renamed name if available.
        text = metadata.get("display_name")
        if not text:
            file_path = metadata.get("file_path")
            text = os.path.basename(file_path) if file_path else f"Slot {selected_slot} image"
        if wcs_obj is not None:
            text += " [WCS]"
        list_item = QListWidgetItem(text)
        list_item.setToolTip(metadata.get("file_path", ""))
        self.images_list.addItem(list_item)
        self.update_status()

    def remove_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Remove", "No item selected.")
            return
        for itm in s:
            row = self.images_list.row(itm)
            self.images_list.takeItem(row)
            p = itm.toolTip()
            self.loaded_images = [x for x in self.loaded_images if x["path"] != p]
        self.update_status()

    def update_status(self):
        c = len(self.loaded_images)
        self.status_label.setText(f"{c} images loaded.")

    # ---------- Preview ----------
    def preview_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Preview", "No item selected.")
            return
        path = s[0].toolTip()
        for d in self.loaded_images:
            if d["path"] == path:
                preview_image = d["image"]
                if np.all(preview_image == 0):
                    print(f"WARNING: Preview for {path} is completely black!")
                print(f"Previewing {path}, shape={preview_image.shape}, max={np.max(preview_image)}")
                win = MosaicPreviewWindow(preview_image, title=f"Preview - {os.path.basename(path)}", parent=self)
                win.show()
                break

    # ---------- Align (Entry Point) ----------
    def align_images(self):
        if len(self.loaded_images) == 0:
            QMessageBox.warning(self, "Align", "No images to align.")
            return

        # Show spinner and start animation.
        self.spinnerLabel.show()
        self.spinnerMovie.start()
        QApplication.processEvents()

        # Step 1: Force blind solve if requested.
        force_blind = self.forceBlindCheckBox.isChecked()
        images_to_process = self.loaded_images if force_blind else [item for item in self.loaded_images if item.get("wcs") is None]

        for item in images_to_process:
            # Check if ASTAP is set.
            if not self.astap_exe or not os.path.exists(self.astap_exe):
                executable_filter = "Executables (*.exe);;All Files (*)" if sys.platform.startswith("win") else "Executables (astap);;All Files (*)"
                new_path, _ = QFileDialog.getOpenFileName(self, "Select ASTAP Executable", "", executable_filter)
                if new_path:
                    self.astap_exe = new_path
                    self.settings.setValue("astap/exe_path", self.astap_exe)
                    QMessageBox.information(self, "Mosaic Master", "ASTAP path updated successfully.")
                else:
                    QMessageBox.warning(self, "Mosaic Master", "ASTAP path not provided. Falling back to blind solve.")
                    solved_header = self.perform_blind_solve(item)
                    if solved_header:
                        item["wcs"] = WCS(solved_header)
                    continue  # Move to next image

            # Attempt ASTAP solve.
            self.status_label.setText(f"Attempting ASTAP solve for {item['path']}...")
            QApplication.processEvents()
            solved_header = self.attempt_astap_solve(item)

            if solved_header is None:
                self.status_label.setText(f"ASTAP failed for {item['path']}. Falling back to blind solve...")
                QApplication.processEvents()
                solved_header = self.perform_blind_solve(item)
            else:
                self.status_label.setText(f"Plate solve successful using ASTAP for {item['path']}.")

            if solved_header:
                # Remove any unnecessary 3D-related keywords
                for k in list(solved_header.keys()):
                    if (k.startswith("NAXIS3") or k.startswith("CTYPE3") or k.startswith("CUNIT3") or
                        k.startswith("CRVAL3") or k.startswith("CRPIX3") or k.startswith("CDELT3") or
                        k.startswith("CD3_") or k.startswith("PC3_") or k.startswith("PC_3")):
                        del solved_header[k]

                # Ensure mandatory WCS keys are present
                solved_header.setdefault("CTYPE1", "RA---TAN")
                solved_header.setdefault("CTYPE2", "DEC--TAN")
                solved_header.setdefault("RADECSYS", "ICRS")
                solved_header.setdefault("WCSAXES", 2)

                item["wcs"] = WCS(solved_header)
            else:
                print(f"Plate solving failed for {item['path']}.")

        # After processing, get all images with valid WCS.
        wcs_items = [x for x in self.loaded_images if x.get("wcs") is not None]
        if not wcs_items:
            print("No images have WCS, skipping WCS alignment.")
            self.spinnerMovie.stop()
            self.spinnerLabel.hide()
            return

        # Use the first image's WCS as reference and compute the mosaic bounding box.
        reference_wcs = wcs_items[0]["wcs"].deepcopy()
        min_x, min_y, max_x, max_y = self.compute_mosaic_bounding_box(wcs_items, reference_wcs)
        mosaic_width = int(max_x - min_x)
        mosaic_height = int(max_y - min_y)

        if mosaic_width < 1 or mosaic_height < 1:
            print("ERROR: Computed mosaic size is invalid. Check WCS or inputs.")
            return

        # Adjust the reference WCS so that (min_x, min_y) becomes (0,0).
        mosaic_wcs = reference_wcs.deepcopy()
        mosaic_wcs.wcs.crpix[0] -= min_x
        mosaic_wcs.wcs.crpix[1] -= min_y
        self.wcs_metadata = mosaic_wcs.to_header()

        # Set up accumulators.
        is_color = any(not item["is_mono"] for item in wcs_items)
        if is_color:
            self.final_mosaic = np.zeros((mosaic_height, mosaic_width, 3), dtype=np.float32)
        else:
            self.final_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)
        self.weight_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)

        first_image = True
        for idx, itm in enumerate(wcs_items):
            arr = itm["image"]
            self.status_label.setText(f"Projecting {itm['path']} onto the celestial sphere...")
            QApplication.processEvents()

            # Pre-stretch the image.
            stretched_arr = self.stretch_image(arr)
            # Use the first channel for alignment.
            if not itm["is_mono"]:
                red_stretched = stretched_arr[..., 0]
            else:
                red_stretched = stretched_arr[..., 0] if stretched_arr.ndim == 3 else stretched_arr

            # Reproject the image.
            if not itm["is_mono"]:
                channels = []
                for c in range(3):
                    channel = stretched_arr[..., c]
                    reproj, _ = reproject_interp((channel, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                    reproj = np.nan_to_num(reproj, nan=0.0).astype(np.float32)
                    channels.append(reproj)
                reprojected = np.stack(channels, axis=-1)
                reproj_red = reprojected[..., 0]
            else:
                reproj_red, _ = reproject_interp((red_stretched, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                reproj_red = np.nan_to_num(reproj_red, nan=0.0).astype(np.float32)
                reprojected = np.stack([reproj_red, reproj_red, reproj_red], axis=-1)

            self.status_label.setText(f"WCS Reproject: {itm['path']} processed.")
            QApplication.processEvents()

            # --- Stellar Alignment ---
            # --- Stellar Alignment ---
            num_stars = self.settings.value("mosaic/num_stars", 150, type=int)
            if not first_image:
                transform_method = self.transform_combo.currentText()
                # Use the current mosaic as reference.
                mosaic_gray = self.final_mosaic if self.final_mosaic.ndim == 2 else np.mean(self.final_mosaic, axis=-1)
                print("Mosaic gray shape:", mosaic_gray.shape)
                
                self.status_label.setText("Detecting stars in overlap region...")
                QApplication.processEvents()
                
                overlap_mask = (mosaic_gray > 0) & (reproj_red > 0)


                # Detect stars (with flux) in the masked regions.
                mosaic_star_list = self.detect_stars(np.where(overlap_mask, mosaic_gray, 0), max_stars=num_stars)
                new_star_list = self.detect_stars(np.where(overlap_mask, reproj_red, 0), max_stars=num_stars)
                
                print("New star list count:", len(new_star_list))
                print("Mosaic star list count:", len(mosaic_star_list))
                
                self.status_label.setText(f"Overlap stars: new image: {len(new_star_list)}; mosaic: {len(mosaic_star_list)} detected.")
                QApplication.processEvents()
                
                print("New star list count:", len(new_star_list))
                print("Mosaic star list count:", len(mosaic_star_list))
                if new_star_list:
                    new_xs = [s[0] for s in new_star_list]
                    new_ys = [s[1] for s in new_star_list]
                    print("New stars X range: {:.2f} to {:.2f}".format(min(new_xs), max(new_xs)))
                    print("New stars Y range: {:.2f} to {:.2f}".format(min(new_ys), max(new_ys)))
                if mosaic_star_list:
                    mosaic_xs = [s[0] for s in mosaic_star_list]
                    mosaic_ys = [s[1] for s in mosaic_star_list]
                    print("Mosaic stars X range: {:.2f} to {:.2f}".format(min(mosaic_xs), max(mosaic_xs)))
                    print("Mosaic stars Y range: {:.2f} to {:.2f}".format(min(mosaic_ys), max(mosaic_ys)))
                
                self.status_label.setText(f"Overlap stars: new image: {len(new_star_list)}; mosaic: {len(mosaic_star_list)} detected.")
                QApplication.processEvents()
                
                self.status_label.setText("Running RANSAC for initial affine alignment...")
                QApplication.processEvents()
                transform_matrix, inliers = self.estimate_transform_ransac(new_star_list, mosaic_star_list, mosaic_width)
                
                if transform_matrix is not None:
                    print("Computed affine transform matrix:\n", transform_matrix)
                    print("Number of inliers:", inliers)
                    # Compute the effective scale from the transform.
                    A = transform_matrix[:2, :2]
                    scale1 = np.linalg.norm(A[:, 0])
                    scale2 = np.linalg.norm(A[:, 1])
                    print("Computed scales: {:.6f}, {:.6f}".format(scale1, scale2))
                    
                    self.status_label.setText(f"Affine alignment: {inliers} inliers found. Warping image...")
                    QApplication.processEvents()
                    # Try warping with the computed transform (no inversion)
                    affine_aligned = cv2.warpAffine(reprojected, transform_matrix[:2], (mosaic_width, mosaic_height), flags=cv2.INTER_LINEAR)
                    print("Affine aligned image shape:", affine_aligned.shape)
                    print("Affine aligned image mean:", np.mean(affine_aligned))
                    aligned = affine_aligned
                else:
                    self.status_label.setText("Affine transform not found; using reprojected image.")
                    print("No affine transform found; falling back to reprojected image.")
                    QApplication.processEvents()
                    transform_matrix = np.eye(3, dtype=np.float32)
                    affine_aligned = reprojected
                    aligned = affine_aligned

                # If the user selected a refined method, further refine the alignment.
                if transform_method in ["Homography Transform", "Polynomial Warp Based Transform"]:
                    self.status_label.setText(f"Starting refined alignment using {transform_method}...")
                    print("Refined alignment using method:", transform_method)
                    QApplication.processEvents()                    
                    refined_result = self.refined_alignment(affine_aligned, mosaic_gray, method=transform_method)
                    if refined_result is not None:
                        aligned, best_inliers2 = refined_result
                        self.status_label.setText(f"Refined alignment succeeded with {best_inliers2} inliers.")
                        print("Refined alignment inliers:", best_inliers2)
                    else:
                        self.status_label.setText("Refined alignment failed; falling back to affine alignment.")
                        print("Refined alignment failed; using affine alignment.")
                        aligned = affine_aligned
                else:
                    aligned = affine_aligned

                gray_aligned = aligned[..., 0] if aligned.ndim == 3 else aligned
                print("Final aligned image shape:", aligned.shape)
            else:
                aligned = reprojected
                gray_aligned = np.mean(aligned, axis=-1) if not itm["is_mono"] else aligned[..., 0]
                first_image = False




            # Compute weight mask from the grayscale aligned image.
            binary_mask = (gray_aligned > 0).astype(np.uint8)
            smooth_mask = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 5)
            if np.max(smooth_mask) > 0:
                smooth_mask = smooth_mask / np.max(smooth_mask)
            else:
                smooth_mask = binary_mask.astype(np.float32)
            smooth_mask = cv2.GaussianBlur(smooth_mask, (15, 15), 0)

            # Accumulate the aligned image.
            if is_color:
                self.final_mosaic += aligned * smooth_mask[..., np.newaxis]
            else:
                self.final_mosaic += aligned[..., 0] * smooth_mask
            self.weight_mosaic += smooth_mask

            self.status_label.setText(f"Processed: {itm['path']}")
            QApplication.processEvents()

        # Final blending.
        nonzero_mask = (self.weight_mosaic > 0)
        if is_color:
            self.final_mosaic = np.where(self.weight_mosaic[..., None] > 0, self.final_mosaic / self.weight_mosaic[..., None], self.final_mosaic)
        else:
            self.final_mosaic[nonzero_mask] = self.final_mosaic[nonzero_mask] / self.weight_mosaic[nonzero_mask]

        print("WCS + Star Alignment Complete.")
        self.status_label.setText("WCS + Star Alignment Complete. De-Normalizing Mosaic...")
        self.final_mosaic = self.unstretch_image(self.final_mosaic)
        self.status_label.setText("Final Mosaic Ready.")
        QApplication.processEvents()

        if self.final_mosaic.ndim == 2:
            display_image = np.stack([self.final_mosaic] * 3, axis=-1)
        else:
            display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Incremental Mosaic", parent=self)
        mosaic_win.show()

        self.spinnerMovie.stop()
        self.spinnerLabel.hide()
        QApplication.processEvents()

        
    # ---------- Star alignment using triangle matching ----------

    def refined_alignment(self, affine_aligned, mosaic_img, method="Homography Transform"):
        """
        Refined alignment that assumes affine_aligned is the result of the affine alignment step.
        It re-detects stars in the candidate (overlap) region and computes a refined transform from
        affine_aligned to mosaic_img. Then it applies the refined transform to affine_aligned and
        returns the fully warped image.
        
        Returns:
        - For "Homography Transform": (warped_image, inlier_count)
        - For "Polynomial Warp Based Transform": (warped_image, inlier_count)
        - If refinement fails, returns None.
        """
        print("\n--- Starting Refined Alignment ---")
        poly_degree = self.settings.value("mosaic/poly_degree", 3, type=int)
        self.status_label.setText("Refinement: Converting images to grayscale...")
        QApplication.processEvents()
        
        # Convert images to grayscale
        if affine_aligned.ndim == 3:
            affine_aligned_gray = np.mean(affine_aligned, axis=-1)
        else:
            affine_aligned_gray = affine_aligned
        if mosaic_img.ndim == 3:
            mosaic_gray = np.mean(mosaic_img, axis=-1)
        else:
            mosaic_gray = mosaic_img

        print("Grayscale conversion done.")
        
        # Compute overlap mask
        self.status_label.setText("Refinement: Computing overlap mask...")
        QApplication.processEvents()
        overlap_mask = (mosaic_gray > 0) & (affine_aligned_gray > 0)

        # Detect stars
        self.status_label.setText("Refinement: Detecting stars in mosaic and affine-aligned images...")
        QApplication.processEvents()
        # Increase max_stars to 50 for debugging purposes.
        mosaic_stars_masked = self.detect_stars(np.where(overlap_mask, mosaic_gray, 0), max_stars=300)
        new_stars_aligned = self.detect_stars(np.where(overlap_mask, affine_aligned_gray, 0), max_stars=300)

        # Debug: Print out the star lists.
        print("Mosaic stars (refined alignment):")
        for s in mosaic_stars_masked:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")
        print("New stars (refined alignment):")
        for s in new_stars_aligned:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")

        self.status_label.setText(f"Refinement: Detected {len(mosaic_stars_masked)} mosaic stars and {len(new_stars_aligned)} new stars.")
        QApplication.processEvents()

        if len(mosaic_stars_masked) < 4 or len(new_stars_aligned) < 4:
            self.status_label.setText("Refinement: Not enough stars detected in candidate region.")
            return None

        # Match stars using position and flux.
        self.status_label.setText("Refinement: Matching stars...")
        QApplication.processEvents()
        # For debugging, you might try a higher threshold.
        matches = self.match_stars(new_stars_aligned, mosaic_stars_masked, distance_thresh=10.0, flux_thresh=1.0)
        print(f"Matched stars: {len(matches)}")
        self.status_label.setText(f"Refinement: {len(matches)} matches found.")
        if len(matches) < 4:
            self.status_label.setText("Refinement: Not enough matched stars for refined transform.")
            return None

        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)

        if method == "Homography Transform":
            self.status_label.setText("Refinement: Computing homography transform...")
            QApplication.processEvents()
            H_refined, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            inliers = int(np.count_nonzero(mask)) if mask is not None else 0
            self.status_label.setText(f"Refinement: Homography computed with {inliers} inliers. Warping image...")
            QApplication.processEvents()
            if H_refined is None:
                self.status_label.setText("Refinement: Homography estimation failed.")
                return None
            warped_image = cv2.warpPerspective(affine_aligned, H_refined,
                                                (affine_aligned.shape[1], affine_aligned.shape[0]),
                                                flags=cv2.INTER_LINEAR)
            return (warped_image, inliers)
        elif method == "Polynomial Warp Based Transform":
            self.status_label.setText("Refinement: Computing Polynomial Warp based transform...")
            QApplication.processEvents()
            # Extract control points from matches.
            src_pts = np.float32([match[0][:2] for match in matches])
            dst_pts = np.float32([match[1][:2] for match in matches])
            # Call the static Polynomial Warp warp function.
            try:
                warped_image = MosaicMasterDialog.poly_warp(affine_aligned, src_pts, dst_pts, degree=poly_degree, status_label=self.status_label)
                inliers = len(matches)
                self.status_label.setText(f"Refinement: Polynomial Warp warp applied with {inliers} matched points.")
                return (warped_image, inliers)
            except Exception as e:
                self.status_label.setText(f"Refinement: Polynomial Warp warp failed: {e}")
                return None
        else:
            self.status_label.setText("Refinement: Unexpected transformation method.")
            return None

    @staticmethod
    def poly_warp(image, src_pts, dst_pts, degree=3, status_label=None):
        """
        Warp `image` using a polynomial transformation of the specified degree.
        
        The transformation is defined as:
        u = sum_{i+j<=degree} a_{ij} * x^i * y^j
        v = sum_{i+j<=degree} b_{ij} * x^i * y^j
        
        where the coefficients are solved via least squares using the control points.
        
        Parameters:
        image: Input image.
        src_pts: numpy array of shape (N,2) with control points in the source image.
        dst_pts: numpy array of shape (N,2) with corresponding control points in the destination.
        degree: Degree of the polynomial transformation (allowed 1 to 6, default=3).
        status_label: If provided, a Qt widget where progress messages are displayed.
        
        Returns:
        The warped image.
        """
        h, w = image.shape[:2]
        
        # Function to build the design matrix for points given a degree.
        def build_design_matrix(pts, degree):
            # pts: (N,2) array, where each row is (x, y)
            N = pts.shape[0]
            terms = []
            x = pts[:, 0]
            y = pts[:, 1]
            # Loop over exponents i and j with i+j <= degree.
            for i in range(degree + 1):
                for j in range(degree + 1 - i):
                    terms.append((x**i) * (y**j))
            X = np.vstack(terms).T  # shape: (N, number_of_terms)
            return X

        # Build the design matrix for the control points.
        if status_label is not None:
            status_label.setText("Polynomial warp: Building design matrix for control points...")
            QApplication.processEvents()
        X = build_design_matrix(src_pts, degree)
        
        # Destination coordinates.
        U = dst_pts[:, 0]
        V = dst_pts[:, 1]
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Solving for polynomial coefficients...")
            QApplication.processEvents()
        
        # Solve the least-squares problem.
        coeffs_u, _, _, _ = np.linalg.lstsq(X, U, rcond=None)
        coeffs_v, _, _, _ = np.linalg.lstsq(X, V, rcond=None)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Computing full mapping for image...")
            QApplication.processEvents()
        
        # Build a full grid of coordinates.
        grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
        flat_x = grid_x.ravel()
        flat_y = grid_y.ravel()
        pts_full = np.vstack([flat_x, flat_y]).T  # shape: (h*w, 2)
        
        # Build design matrix for the full grid.
        X_full = build_design_matrix(pts_full, degree)
        
        # Evaluate the polynomial mappings.
        map_u = np.dot(X_full, coeffs_u).reshape(h, w).astype(np.float32)
        map_v = np.dot(X_full, coeffs_v).reshape(h, w).astype(np.float32)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Full mapping computed. Remapping image...")
            QApplication.processEvents()
        
        # Remap the image.
        warped = cv2.remap(image, map_u, map_v, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Image warped.")
            QApplication.processEvents()
        
        return warped



    def estimate_homography_from_stars(self, mosaic_stars, new_stars):
        self.status_label.setText("Matching stars for homography...")
        QApplication.processEvents()
        matches = self.match_stars(new_stars, mosaic_stars, distance_thresh=20.0, flux_thresh=0.5)
        if len(matches) < 4:
            self.status_label.setText("Not enough matched stars for homography.")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} matched stars. Computing homography...")
        QApplication.processEvents()
        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)
        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        inliers = int(np.count_nonzero(mask)) if mask is not None else 0
        self.status_label.setText(f"Homography computed with {inliers} inliers.")
        return H, inliers

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, image_width, settings, ransac_iter=500, inlier_thresh=3.0, norm_trans_thresh=0.2, update_callback=None):
        """
        Runs RANSAC to estimate an affine transform between source and target star coordinates.
        Failsafe checks for translation, scale, rotation, and skew use values from the provided QSettings.
        
        The translation tolerance is a percentage of the image width.
        """
        # Retrieve settings values.
        translation_tolerance_percent = settings.value("mosaic/translation_max_tolerance", 0.1, type=float)
        # Compute the absolute translation tolerance in pixels.
        translation_tolerance = translation_tolerance_percent * image_width

        scale_min = settings.value("mosaic/scale_min_tolerance", 0.85, type=float)
        scale_max = settings.value("mosaic/scale_max_tolerance", 1.15, type=float)
        rotation_max_deg = settings.value("mosaic/rotation_max_tolerance", 45.0, type=float)
        rotation_tolerance = np.radians(rotation_max_deg)
        skew_max = settings.value("mosaic/skew_max_tolerance", 0.05, type=float)  # default: 0.1
        axis_ratio_threshold = settings.value("mosaic/axis_ratio_tolerance", 1.15, type=float)


        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(
                pts_src.reshape(-1, 1, 2), pts_tgt.reshape(-1, 1, 2),
                method=cv2.LMEDS)
            if transform is None:
                continue
            full_mat = np.eye(3, dtype=np.float32)
            full_mat[:2] = transform
            
            # Failsafe: scaling check.
            A = full_mat[:2, :2]
            scale1 = np.linalg.norm(A[:, 0])
            scale2 = np.linalg.norm(A[:, 1])
            scale = (scale1 + scale2) / 2.0
            if scale > scale_max or scale < scale_min:
                continue
            
            # Failsafe: translation check.
            t = full_mat[:2, 2]
            if abs(t[0]) > translation_tolerance or abs(t[1]) > translation_tolerance:
                continue
            
            # New failsafe: check ratio between scales to avoid squashed images.
            if (max(scale1, scale2) / (min(scale1, scale2) + 1e-8)) > axis_ratio_threshold:
                continue

            # Failsafe: rotation angle check.
            angle = np.arctan2(A[1, 0], A[0, 0])
            if abs(angle) > rotation_tolerance: #(np.pi / 4):
                continue
            
            # Failsafe: skew check.
            # For a pure rotation plus uniform scale, the columns of A should be orthogonal.
            v1 = A[:, 0] / (np.linalg.norm(A[:, 0]) + 1e-8)
            v2 = A[:, 1] / (np.linalg.norm(A[:, 1]) + 1e-8)
            skew = abs(np.dot(v1, v2))  # 0 means perfectly orthogonal.
            if skew > skew_max:
                continue

            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars, mosaic_width):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        
        # Compute a normalization factor based on the source coordinate range.
        range_x = np.max(src_coords[:, 0]) - np.min(src_coords[:, 0])
        range_y = np.max(src_coords[:, 1]) - np.min(src_coords[:, 1])
        norm_factor = max(range_x, range_y)
        if norm_factor == 0:
            norm_factor = 1.0
        print("Normalization factor:", norm_factor)
        
        # Normalize coordinates.
        src_norm = src_coords / norm_factor
        tgt_norm = tgt_coords / norm_factor

        self.status_label.setText("Computing Delaunay triangulation (normalized)...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_norm)
        tgt_tri_dict = self.build_triangle_dict(tgt_norm)
        self.status_label.setText("Matching triangles (normalized)...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform_norm, best_inliers = self.ransac_affine(src_norm, tgt_norm, matches, image_width=mosaic_width, settings=self.settings, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        
        if best_transform_norm is None:
            return None, best_inliers

        # Unnormalize the transform.
        # If T_norm is:
        #    y_norm = A_norm * x_norm + t_norm
        # and x_norm = x / norm_factor, then
        #    y = norm_factor * y_norm = A_norm * x + norm_factor * t_norm.
        # Thus, T_full = [A_norm, norm_factor * t_norm].
        best_transform = np.eye(3, dtype=np.float32)
        best_transform[:2, :2] = best_transform_norm[:2, :2]
        best_transform[:2, 2] = best_transform_norm[:2, 2] * norm_factor
        print("Unnormalized transform matrix:\n", best_transform)
        return best_transform, best_inliers



    def stretch_for_display(self, arr):
        arr = arr.astype(np.float32)
        mn, mx = np.percentile(arr, (0.5, 99.5))
        if mx > mn:
            arr = (arr - mn) / (mx - mn)
        else:
            arr = np.zeros_like(arr)
        return (arr * 255).clip(0, 255).astype(np.uint8)

    def detect_stars(self, image2d, max_stars=50):
        # Retrieve user-defined values for sigma and fwhm.
        sigma_val = self.settings.value("mosaic/star_sigma", 3.0, type=float)
        fwhm_val = self.settings.value("mosaic/star_fwhm", 3.0, type=float)
        
        mean_val, median_val, std_val = sigma_clipped_stats(image2d, sigma=3.0)
        # Use the user-defined fwhm and scale the threshold by the standard deviation.
        daofind = DAOStarFinder(threshold=sigma_val * std_val, fwhm=fwhm_val)
        sources = daofind(image2d - median_val)
        if sources is None or len(sources) == 0:
            return []
        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        # Sort stars by brightness (flux) and select the top ones.
        sorted_indices = np.argsort(-flux)
        top_indices = sorted_indices[:max_stars]
        stars = [(x_coords[i], y_coords[i], flux[i]) for i in top_indices]
        return stars


    def match_stars(self, new_stars, mosaic_stars, distance_thresh=10.0, flux_thresh=0.2):
        """
        Matches stars between two lists.
        new_stars and mosaic_stars should be lists of (x, y, flux).
        
        This version normalizes the flux values in each list by dividing by the median flux.
        
        distance_thresh: maximum distance (in pixels) allowed for a match.
        flux_thresh: allowed absolute difference in normalized flux.
                    For example, if set to 0.2, then the normalized flux difference must be less than 0.2.
                    
        Returns a list of matched pairs: [(new_star, mosaic_star), ...]
        """
        # If either list is empty, return an empty match list.
        if not new_stars or not mosaic_stars:
            return []
        
        # Compute median fluxes.
        new_fluxes = [s[2] for s in new_stars]
        mosaic_fluxes = [s[2] for s in mosaic_stars]
        new_median = np.median(new_fluxes) if new_fluxes else 1.0
        mosaic_median = np.median(mosaic_fluxes) if mosaic_fluxes else 1.0

        # Normalize the flux for each star.
        norm_new_stars = [(s[0], s[1], s[2] / new_median) for s in new_stars]
        norm_mosaic_stars = [(s[0], s[1], s[2] / mosaic_median) for s in mosaic_stars]

        matches = []
        for ns in norm_new_stars:
            best_match = None
            best_distance = float('inf')
            for ms in norm_mosaic_stars:
                dx = ns[0] - ms[0]
                dy = ns[1] - ms[1]
                dist = np.hypot(dx, dy)
                # Check spatial proximity.
                if dist < distance_thresh and dist < best_distance:
                    # Check if the normalized fluxes are similar.
                    # Here, flux_thresh is an absolute threshold on the difference.
                    if abs(ns[2] - ms[2]) < flux_thresh:
                        best_match = ms
                        best_distance = dist
            if best_match is not None:
                matches.append((ns, best_match))
        return matches

    def estimate_transform(self, source_stars, dest_stars):
        min_len = min(len(source_stars), len(dest_stars))
        if min_len < 3:
            return None
        src_pts = np.float32(source_stars[:min_len])
        dst_pts = np.float32(dest_stars[:min_len])
        matrix, inliers = cv2.estimateAffinePartial2D(
            src_pts, dst_pts,
            method=cv2.RANSAC, ransacReprojThreshold=3.0
        )
        if matrix is None:
            return None
        full_mat = np.eye(3, dtype=np.float32)
        full_mat[:2] = matrix
        return full_mat


    def compute_mosaic_bounding_box(self, wcs_items, reference_wcs):
        """
        Compute the mosaic bounding box in pixel coordinates relative to a shared WCS frame,
        properly accounting for rotation and orientation dynamically.
        """
        all_pixels = []

        for itm in wcs_items:
            wcs = itm["wcs"]
            H, W = itm["image"].shape[:2]  # Use only the height and width

            # Get image corner coordinates in world coordinates (RA/Dec)
            pixel_corners = np.array([
                [0, 0],         # Top-left
                [W - 1, 0],     # Top-right
                [0, H - 1],     # Bottom-left
                [W - 1, H - 1]  # Bottom-right
            ])

            # Convert pixel to world coordinates (RA, Dec)
            world_coords = np.column_stack(wcs.pixel_to_world_values(pixel_corners[:, 0], pixel_corners[:, 1]))

            # Convert RA/Dec to pixel coordinates in the reference WCS
            sky_coords = SkyCoord(ra=world_coords[:, 0] * u.deg, dec=world_coords[:, 1] * u.deg, frame='icrs')
            pixel_coords = skycoord_to_pixel(sky_coords, reference_wcs)

            # Ensure we're only using the first two values (x, y)
            all_pixels.append(np.column_stack(pixel_coords[:2]))

        # Stack all pixel coordinates and compute bounding box
        all_pixels = np.vstack(all_pixels)

        min_x, max_x = np.min(all_pixels[:, 0]), np.max(all_pixels[:, 0])
        min_y, max_y = np.min(all_pixels[:, 1]), np.max(all_pixels[:, 1])

        # **Determine whether the mosaic is wider or taller dynamically**
        width = max_x - min_x
        height = max_y - min_y

        print(f"Detected Bounding Box (X={min_x} to {max_x}, Y={min_y} to {max_y})")
        print(f"Calculated Mosaic Size: Width={width}, Height={height}")
        self.status_label.setText(f"Detected Bounding Box: X={min_x} to {max_x}, Y={min_y} to {max_y}")
        self.status_label.setText(f"Calculated Mosaic Size: Width={width}, Height={height}")
        QApplication.processEvents()

        return int(np.floor(min_x)), int(np.floor(min_y)), int(np.ceil(max_x)), int(np.ceil(max_y))

    # ---------- Finalize / Save Mosaic ----------
    def create_mosaic(self):
        """Finalize the mosaic (including blending/normalization) and push it to the image manager."""
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        self.finalize_mosaic()
        display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Final Mosaic", parent=self)
        mosaic_win.show()

    def finalize_mosaic(self):
        """ Push the final mosaic (and its WCS metadata) to the image manager """
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        print("🔹 Pushing mosaic to image manager...")

        # Convert the Header to a dict before passing it
        meta = dict(self.wcs_metadata)

        # If the final mosaic is 2D (grayscale), replicate it across three channels
        final_img = self.final_mosaic
        if final_img.ndim == 2:
            final_img = np.stack([final_img, final_img, final_img], axis=-1)

        self.image_manager.set_image(final_img, metadata=meta)
        print("✅ Mosaic pushed successfully.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.08

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # If the image is 2D, treat it as a single channel.
        if image.ndim == 2:
            # Process as a single channel:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")

            # Add back the original minimum
            image += original_min

            # Clip to [0, 1]
            image = np.clip(image, 0, 1)
            # Optionally, if you want to keep it 2D (since it was originally mono), just return image.
            # If you want to convert to a 3-channel image for display later, you can do that later.
            return image

        # Otherwise, if the image is 3D, process each channel
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel but has 3 dimensions now, convert it back.
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)

        return image


    # ---------- Blind Solve via Astrometry.net ----------
    def perform_blind_solve(self, item):
        """
        Performs a blind solve using Astrometry.net and constructs the WCS header directly.
        If any step fails (e.g. network error), prompts the user to try again.
        """
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return None

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine the file extension of the original image.
            ext = os.path.splitext(item["path"])[1].lower()
            # If the image is not already FITS or TIFF, convert it.
            if ext not in ('.fits', '.fit'):
                # Create a temporary file with a .fit extension.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close it so that save_image can write to it.

                # Generate a minimal FITS header from the image array.
                minimal_header = generate_minimal_fits_header(item["image"])

                # Save the image as a FITS file using the minimal header.
                # (Adjust bit_depth as needed.)
                save_image(
                    img_array=item["image"],
                    filename=temp_file.name,
                    original_format="fit",
                    bit_depth="16-bit",
                    original_header=minimal_header,
                    is_mono=item.get("is_mono", False)
                )
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            # If we created a temporary file (i.e. the original file wasn’t FITS or TIFF), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)

            # Exit the loop once all steps have succeeded.
            break

        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        item["wcs"] = WCS(wcs_header)
        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    # ---------- Blind Solve via ASTAP ----------
    def attempt_astap_solve(self, item):
        """
        Attempt to plate-solve the image using ASTAP.
        Returns a solved header (as a dict) on success or None on failure.
        """
        # 1) Normalize the image (using your stretch_image).
        normalized_image = self.stretch_image(item["image"])
        
        # 2) Save normalized image to a temporary FITS file for ASTAP.
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, item["path"])
        except Exception as e:
            print("Failed to save temporary FITS file:", e)
            return None

        # 3) Run ASTAP on the temporary file.
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            os.remove(tmp_path)
            return None
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            os.remove(tmp_path)
            return None

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return None

        # 4) Retrieve updated header from the temporary file.
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove some extraneous keywords
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
        except Exception as e:
            print("Error reading solved header:", e)
            os.remove(tmp_path)
            return None

        # 5) Merge .wcs file (if ASTAP wrote one) into the solved_header.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                with open(wcs_path, "r") as f:
                    content = f.read()
                pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                for match in re.finditer(pattern, content):
                    key = match.group(1).strip().upper()
                    val = match.group(2).strip()
                    if val.startswith("'") and val.endswith("'"):
                        val = val[1:-1].strip()
                    solved_header[key] = val
            except Exception as e:
                print("Error reading .wcs file:", e)
            finally:
                try:
                    os.remove(wcs_path)
                except Exception as e:
                    print("Error removing .wcs file:", e)

        # Remove the END keyword if present
        solved_header.pop("END", None)
        # Remove any unneeded keywords
        for keyword in ["RANGE_LOW", "RANGE_HIGH", "HISTORY"]:
            solved_header.pop(keyword, None)

        # --- Ensure required WCS keys are present ---
        if "CTYPE1" not in solved_header or not solved_header["CTYPE1"].strip():
            solved_header["CTYPE1"] = "RA---TAN"
        if "CTYPE2" not in solved_header or not solved_header["CTYPE2"].strip():
            solved_header["CTYPE2"] = "DEC--TAN"
        if "RADECSYS" not in solved_header:
            solved_header["RADECSYS"] = "ICRS"
        if "WCSAXES" not in solved_header:
            solved_header["WCSAXES"] = 2

        # Convert known WCS keys to float or int
        expected_float_keys = {"CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2"}
        expected_int_keys = {"NAXIS", "WCSAXES"}

        for key in expected_float_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to float.")

        for key in expected_int_keys:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to int.")

        try:
            save_image(
                img_array=normalized_image,
                filename=item["path"],  # Overwrite the original file
                original_format="fit",
                bit_depth="32",
                original_header=solved_header,  # Updated WCS header
                is_mono=False
            )
            print(f"✅ Updated FITS header with full WCS solution for {item['path']}.")
        except Exception as e:
            print("Error saving updated FITS file using save_image():", e)
            raise e


        # Remove the temporary FITS
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling


        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

# --------------------------------------------------
# Star Stuff
# --------------------------------------------------      
class StellarAlignmentDialog(QDialog):
    def __init__(self, parent, settings, image_manager):
        """
        Parameters:
          parent: reference to the main window (AstroEditingSuite) so that helper methods
                  (e.g. detect_stars, estimate_transform_from_triangles) can be called.
          settings: QSettings instance (for working directory, etc.)
          image_manager: the ImageManager instance.
        """
        super().__init__(parent)
        self.setWindowTitle("Stellar Alignment")
        self.settings = settings
        self.image_manager = image_manager
        self.parent_window = parent  # for calling helper methods from the main window
        self.stellar_source = None
        self.stellar_target = None
        self.aligned_image = None
        self.autostretch_enabled = False  # Default: No autostretch
        self.initUI()

    def initUI(self):
        main_layout = QHBoxLayout(self)  # Use horizontal layout for side-by-side arrangement

        # ------------------------
        # Left Panel (Selection Controls)
        # ------------------------
        controls_layout = QVBoxLayout()

        # ------------------------
        # Source Image Group
        # ------------------------
        source_group = QGroupBox("Source Image (Reference)")
        source_layout = QVBoxLayout()

        # Radio buttons for selection type.
        source_radio_layout = QHBoxLayout()
        self.source_from_file_radio = QRadioButton("From File")
        self.source_from_slot_radio = QRadioButton("From Slot")
        self.source_from_file_radio.setChecked(True)
        source_radio_layout.addWidget(self.source_from_file_radio)
        source_radio_layout.addWidget(self.source_from_slot_radio)
        source_layout.addLayout(source_radio_layout)

        # File selection controls for source.
        file_source_layout = QHBoxLayout()
        self.source_file_button = QPushButton("Select from File")
        self.source_file_button.clicked.connect(self.select_source_file)
        self.source_file_label = QLabel("No file selected")
        file_source_layout.addWidget(self.source_file_button)
        file_source_layout.addWidget(self.source_file_label)
        source_layout.addLayout(file_source_layout)

        # Slot selection controls for source.
        slot_source_layout = QHBoxLayout()
        self.source_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.source_slot_combo.addItem(slot_name, i)
        self.source_slot_button = QPushButton("Load from Slot")
        self.source_slot_button.clicked.connect(self.load_source_from_slot)
        slot_source_layout.addWidget(self.source_slot_combo)
        slot_source_layout.addWidget(self.source_slot_button)
        source_layout.addLayout(slot_source_layout)

        source_group.setLayout(source_layout)
        controls_layout.addWidget(source_group)

        # ------------------------
        # Target Image Group
        # ------------------------
        target_group = QGroupBox("Target Image (To be Aligned)")
        target_layout = QVBoxLayout()

        # Radio buttons for selection type.
        target_radio_layout = QHBoxLayout()
        self.target_from_file_radio = QRadioButton("From File")
        self.target_from_slot_radio = QRadioButton("From Slot")
        self.target_from_file_radio.setChecked(True)
        target_radio_layout.addWidget(self.target_from_file_radio)
        target_radio_layout.addWidget(self.target_from_slot_radio)
        target_layout.addLayout(target_radio_layout)

        # File selection controls for target.
        file_target_layout = QHBoxLayout()
        self.target_file_button = QPushButton("Select from File")
        self.target_file_button.clicked.connect(self.select_target_file)
        self.target_file_label = QLabel("No file selected")
        file_target_layout.addWidget(self.target_file_button)
        file_target_layout.addWidget(self.target_file_label)
        target_layout.addLayout(file_target_layout)

        # Slot selection controls for target.
        slot_target_layout = QHBoxLayout()
        self.target_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.target_slot_combo.addItem(slot_name, i)
        self.target_slot_button = QPushButton("Load from Slot")
        self.target_slot_button.clicked.connect(self.load_target_from_slot)
        slot_target_layout.addWidget(self.target_slot_combo)
        slot_target_layout.addWidget(self.target_slot_button)
        target_layout.addLayout(slot_target_layout)

        target_group.setLayout(target_layout)
        controls_layout.addWidget(target_group)

        # ------------------------
        # Run Alignment Button
        # ------------------------
        self.run_alignment_button = QPushButton("Run Alignment")
        self.run_alignment_button.clicked.connect(self.run_alignment)
        controls_layout.addWidget(self.run_alignment_button)

        # ------------------------
        # Status Label
        # ------------------------
        self.status_label = QLabel("Status: Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        controls_layout.addWidget(self.status_label)

        main_layout.addLayout(controls_layout)

        # ------------------------
        # Right Panel (Result Preview)
        # ------------------------
        result_layout = QVBoxLayout()
        result_group = QGroupBox("Aligned Image")

        # Preview label
        self.result_preview_label = QLabel()
        self.result_preview_label.setFixedSize(400, 400)
        self.result_preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        result_layout.addWidget(self.result_preview_label)

        # AutoStretch Button
        self.autostretch_button = QPushButton("AutoStretch: OFF")
        self.autostretch_button.clicked.connect(self.toggle_autostretch)
        result_layout.addWidget(self.autostretch_button)

        # Push to Active Slot Button
        self.push_active_button = QPushButton("Push to Active Slot")
        self.push_active_button.clicked.connect(self.push_aligned_to_active)
        result_layout.addWidget(self.push_active_button)

        result_group.setLayout(result_layout)
        main_layout.addWidget(result_group)

        self.setLayout(main_layout)

    def toggle_autostretch(self):
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.aligned_image  # Reset to original image if stretch is disabled

        self.update_preview(self.result_preview_label, self.stretched_image)

    def apply_autostretch(self):
        # Determine if the aligned image is mono or color
        if len(self.aligned_image.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.aligned_image, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.aligned_image, target_median=0.25, linked=False, normalize=False)

    def update_preview(self, label, image):
        """
        Updates the QLabel to display a preview of the given image with optional autostretch.
        """
        if self.autostretch_enabled:
            image = np.clip(image * 255 / np.max(image), 0, 255).astype(np.uint8)  # Auto-stretch

        if image.ndim == 3 and image.shape[2] == 3:
            h, w, _ = image.shape
            qimg = QImage(image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif image.ndim == 2:
            h, w = image.shape
            qimg = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def detect_stars_by_grid(self, image, stars_per_region=4):
        # Convert to grayscale if needed.
        if image.ndim == 3 and image.shape[2] == 3:
            image_gray = np.mean(image, axis=2)
        else:
            image_gray = image

        H, W = image_gray.shape
        grid_rows, grid_cols = 3, 3
        cell_height, cell_width = H // grid_rows, W // grid_cols

        all_selected_stars = []

        # Precompute global statistics once.
        mean_val, median_val, std_val = sigma_clipped_stats(image_gray, sigma=3.0)
        daofind = DAOStarFinder(threshold=3 * std_val, fwhm=3.0)
        sources = daofind(image_gray - median_val)
        if sources is None or len(sources) == 0:
            return []

        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        regions_used = 0
        # Package stars together (initially as 3-element tuples).
        stars = list(zip(x_coords, y_coords, flux))

        for i in range(grid_rows):
            for j in range(grid_cols):
                x_min = j * cell_width
                x_max = (j+1) * cell_width if j < grid_cols - 1 else W
                y_min = i * cell_height
                y_max = (i+1) * cell_height if i < grid_rows - 1 else H

                # Select stars in this region and attach the cell ID.
                cell_stars = [
                    (star[0], star[1], star[2], (i, j))
                    for star in stars
                    if (x_min <= star[0] < x_max and y_min <= star[1] < y_max)
                ]
                # Sort by brightness (flux) descending.
                cell_stars.sort(key=lambda s: s[2], reverse=True)
                if cell_stars:
                    regions_used += 1
                all_selected_stars.extend(cell_stars[:stars_per_region])
                # Update status for this region:
                self.status_label.setText(f"Region ({i},{j}): Found {len(cell_stars)} stars.")
                QApplication.processEvents()             

        # Optionally, remove duplicates and sort by brightness globally.
        all_selected_stars = list(set(all_selected_stars))
        all_selected_stars.sort(key=lambda s: s[2], reverse=True)
        return all_selected_stars

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, ransac_iter=500, inlier_thresh=3.0, update_callback=None):
        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(pts_src.reshape(-1,1,2), pts_tgt.reshape(-1,1,2), method=cv2.LMEDS)
            if transform is None:
                continue
            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            # Update progress if a callback is provided.
            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        self.status_label.setText("Computing Delaunay triangulation...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_coords)
        tgt_tri_dict = self.build_triangle_dict(tgt_coords)
        self.status_label.setText("Matching triangles...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        # Provide a callback to update status during RANSAC.
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform, best_inliers = self.ransac_affine(src_coords, tgt_coords, matches, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        return best_transform, best_inliers
    
    def select_source_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Source Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load source image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_source = image
            self.source_file_label.setText(path)


    def select_target_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Target Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load target image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_target = image
            self.target_file_label.setText(path)


    def load_source_from_slot(self):
        index = self.source_slot_combo.currentData()
        image = self.image_manager._images.get(index)
        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            image = np.stack([image]*3, axis=-1)
        self.stellar_source = image
        self.source_file_label.setText(f"Loaded from Slot {index}")

    def load_target_from_slot(self):
        index = self.target_slot_combo.currentData()
        image = self.image_manager._images.get(index)
        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            image = np.stack([image]*3, axis=-1)
        self.stellar_target = image
        self.target_file_label.setText(f"Loaded from Slot {index}")

    def update_preview(self, label, image):
        """
        Update a QLabel to display a preview of the given image.
        For display purposes, convert to 8-bit if needed.
        """
        # For display only, convert float32 in [0,1] to 8-bit.
        if image.dtype == np.float32:
            disp = np.clip(image * 255, 0, 255).astype(np.uint8)
        else:
            disp = image
        if disp.ndim == 3 and disp.shape[2] == 3:
            h, w, _ = disp.shape
            qimg = QImage(disp.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif disp.ndim == 2:
            h, w = disp.shape
            qimg = QImage(disp.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def select_corner_stars(self, stars, image_shape, margin=0.15):
        """
        Selects stars that are near the corners (or edges) of the image.
        stars: list of tuples (x, y, flux, cell_id)
        image_shape: (H, W)
        margin: fractional distance from the border
        """
        H, W = image_shape
        selected = []
        for star in stars:
            x, y, _, _ = star
            # Choose stars near left/right and top/bottom margins.
            if (x < margin * W or x > (1 - margin) * W) and (y < margin * H or y > (1 - margin) * H):
                selected.append((x, y))
        return selected


    # -----------------------------
    # Run Alignment – Uses RANSAC/Delaunay Approach with Progress Updates
    # -----------------------------
    def run_alignment(self):
        if self.source_from_slot_radio.isChecked() and self.stellar_source is None:
            self.load_source_from_slot()
        if self.target_from_slot_radio.isChecked() and self.stellar_target is None:
            self.load_target_from_slot()
        if self.stellar_source is None:
            QMessageBox.warning(self, "Error", "Please select a source image.")
            return
        if self.stellar_target is None:
            QMessageBox.warning(self, "Error", "Please select a target image.")
            return

        source_img = self.stellar_source
        target_img = self.stellar_target
        H, W = source_img.shape[:2]
        self.status_label.setText("Detecting stars...")
        QApplication.processEvents()
        source_stars = self.detect_stars_by_grid(source_img, stars_per_region=20)
        target_stars = self.detect_stars_by_grid(target_img, stars_per_region=20)
        if len(source_stars) < 3 or len(target_stars) < 3:
            QMessageBox.warning(self, "Alignment Error", "Not enough stars detected for alignment.")
            return

        self.status_label.setText("Running RANSAC for alignment...")
        QApplication.processEvents()
        best_matrix, best_inliers = self.estimate_transform_ransac(source_stars, target_stars)
        if best_matrix is None:
            QMessageBox.warning(self, "Alignment Error", "Failed to compute alignment transform.")
            return

        self.status_label.setText("Warping target image with affine transform...")
        QApplication.processEvents()
        inv_transform = cv2.invertAffineTransform(best_matrix[:2])
        warped_target = cv2.warpAffine(target_img, inv_transform, (W, H), flags=cv2.INTER_LINEAR)
        canvas = np.zeros((H, W, 3), dtype=warped_target.dtype)
        canvas[:] = warped_target
        self.aligned_image = canvas
        self.update_preview(self.result_preview_label, canvas)

        # --- Begin Homography Refinement (TPS block is commented out) ---
        self.status_label.setText("Refining alignment with Homography Transform...")
        QApplication.processEvents()
        # Redetect stars in the overlap region from both the mosaic (affine result) and source.
        mosaic_gray = np.mean(canvas, axis=-1) if canvas.ndim == 3 else canvas
        # Use the current mosaic as the target for refinement.
        # (Note: self.final_mosaic may not have been updated; using canvas as the affine result.)
        overlap_mask = (mosaic_gray > 0)  # simple mask; you can refine this as needed.
        mosaic_stars_refined = self.detect_stars_by_grid(np.where(overlap_mask, mosaic_gray, 0), stars_per_region=50)
        new_stars_refined = self.detect_stars_by_grid(np.where(overlap_mask, mosaic_gray, 0), stars_per_region=50)
        
        self.status_label.setText(f"Refinement: Detected {len(mosaic_stars_refined)} mosaic stars and {len(new_stars_refined)} new stars.")
        QApplication.processEvents()
        
        src_ctrl_pts = self.select_corner_stars(new_stars_refined, (H, W), margin=0.15)
        tgt_ctrl_pts = self.select_corner_stars(mosaic_stars_refined, (H, W), margin=0.15)
        num_ctrl = min(len(src_ctrl_pts), len(tgt_ctrl_pts))
        if num_ctrl < 3:
            self.status_label.setText("Not enough corner control points for homography refinement; skipping refinement.")
            refined_image = canvas
        else:
            src_ctrl_pts = src_ctrl_pts[:num_ctrl]
            tgt_ctrl_pts = tgt_ctrl_pts[:num_ctrl]
            self.status_label.setText("Computing homography from refined stars...")
            QApplication.processEvents()
            H_refined, mask = cv2.findHomography(np.float32(src_ctrl_pts).reshape(-1,1,2),
                                                 np.float32(tgt_ctrl_pts).reshape(-1,1,2),
                                                 cv2.RANSAC, 5.0)
            if H_refined is None:
                self.status_label.setText("Homography estimation failed; using affine result.")
                refined_image = canvas
            else:
                inliers = int(np.count_nonzero(mask)) if mask is not None else 0
                self.status_label.setText(f"Homography computed with {inliers} inliers. Warping image...")
                QApplication.processEvents()
                refined_image = cv2.warpPerspective(canvas, H_refined, (W, H), flags=cv2.INTER_LINEAR)
        # --- End Homography Refinement ---

        self.aligned_image = refined_image
        self.update_preview(self.result_preview_label, refined_image)
        QMessageBox.information(self, "Alignment Complete", f"Alignment completed with {best_inliers} affine inliers.")
        self.show_transform_info(best_matrix)


    def show_transform_info(self, matrix):
        """
        Decomposes the 3x3 affine matrix and displays its translation, scaling,
        rotation (in degrees), and skew (shear) in a pop-up dialog.
        """
        # Assuming matrix is of the form:
        # [[a, b, tx],
        #  [c, d, ty],
        #  [0, 0, 1]]
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]

        # Compute translation directly.
        translation = (tx, ty)

        # Compute scale in x as the length of the first column.
        scale_x = np.sqrt(a * a + c * c)
        # The rotation angle (in degrees) is the arctan of (c/a)
        rotation_rad = np.arctan2(c, a)
        rotation_deg = np.degrees(rotation_rad)

        # Compute shear (skew). One common formula is:
        shear = (a * b + c * d) / (a * a + c * c)
        # Compute scale_y using the formula:
        # det(A) = a*d - b*c = scale_x * scale_y  => scale_y = det / scale_x
        det = a * d - b * c
        scale_y = det / scale_x

        # Alternatively, you can compute scale_y with a method that accounts for shear:
        # scale_y_alt = np.sqrt(b * b + d * d - shear * shear * (a * a + c * c))
        # (Usually the two values should be similar for well-behaved transforms.)

        info_text = (
            f"Transformation Matrix:\n\n"
            f"[{a:.3f}  {b:.3f}  {tx:.3f}]\n"
            f"[{c:.3f}  {d:.3f}  {ty:.3f}]\n"
            f"[0.000  0.000  1.000]\n\n"
            f"Translation: (tx, ty) = ({tx:.3f}, {ty:.3f})\n"
            f"Scaling: scale_x = {scale_x:.3f}, scale_y = {scale_y:.3f}\n"
            f"Rotation: {rotation_deg:.2f}°\n"
            f"Skew (shear): {shear:.3f}\n"
        )

        # Create a dialog to display the transformation details.
        info_dialog = QDialog(self)
        info_dialog.setWindowTitle("Transformation Matrix Details")
        layout = QVBoxLayout(info_dialog)

        text_edit = QTextEdit(info_dialog)
        text_edit.setReadOnly(True)
        text_edit.setText(info_text)
        layout.addWidget(text_edit)

        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok, info_dialog)
        button_box.accepted.connect(info_dialog.accept)
        layout.addWidget(button_box)

        info_dialog.show()

    def push_aligned_to_active(self):
        """
        Push the aligned image (if available) to the active slot in the image manager.
        """
        if self.aligned_image is None:
            QMessageBox.warning(self, "Error", "No aligned image available. Run alignment first.")
            return
        self.image_manager.set_image(new_image=self.aligned_image, metadata={"description": "Stellar aligned image"})
        self.image_manager.image_changed.emit(self.image_manager.current_slot, self.aligned_image, {"description": "Stellar aligned image"})
        QMessageBox.information(self, "Pushed", "Aligned image pushed to the active slot.")
        self.accept()

#############################################
# Worker Signals for Registration Workers
#############################################
class RegistrationWorkerSignals(QObject):
    progress = pyqtSignal(str)           # e.g., "Loaded image X"
    result = pyqtSignal(str)             # e.g., "Saved aligned file path"
    error = pyqtSignal(str)              # e.g., error message
    result_transform = pyqtSignal(str, object)  
    #          ^^^^^^^^^^^^^^^^^^^^^^^
    #  We'll emit (orig_file_path, transform_matrix)

#############################################
# Worker to Process One Image Registration
#############################################
class StarRegistrationWorker(QRunnable):
    def __init__(self, file_path, ref_stars, ref_triangles, output_directory):
        super().__init__()
        self.file_path = file_path
        self.ref_stars = ref_stars
        self.ref_triangles = ref_triangles
        self.output_directory = output_directory
        self.signals = RegistrationWorkerSignals()

    def run(self):
        try:
            # 1) Load image
            img, img_header, img_bit_depth, img_is_mono = load_image(self.file_path)
            if img is None:
                self.signals.error.emit(f"Could not load {self.file_path}")
                QApplication.processEvents()
                return

            self.signals.progress.emit(f"Loaded {os.path.basename(self.file_path)}")
            QApplication.processEvents()
            
            # 2) Detect stars
            img_stars = StarRegistrationThread.detect_grid_stars_static(img)
            if len(img_stars) < 9:
                self.signals.error.emit(f"Not enough stars in {self.file_path}")
                QApplication.processEvents()
                return

            self.signals.progress.emit(f"Detected {len(img_stars)} stars in {os.path.basename(self.file_path)}")
            QApplication.processEvents()

            # 3) Compute affine transform
            transform = StarRegistrationThread.compute_affine_transform_with_ransac_static(
                img_stars, self.ref_stars, self.ref_triangles
            )
            if transform is None:
                self.signals.error.emit(f"Alignment failed for {self.file_path}")
                QApplication.processEvents()
                return

            self.signals.progress.emit(f"Computed transform for {os.path.basename(self.file_path)}")
            QApplication.processEvents()

            # 4) Emit the transform so the main thread can store it
            self.signals.result_transform.emit(self.file_path, transform)

            # 5) Apply the transform
            aligned_image = StarRegistrationThread.apply_affine_transform_static(img, transform)
            if aligned_image is None:
                self.signals.error.emit(f"Transform application failed for {self.file_path}")
                QApplication.processEvents()
                return

            # 6) Build output filename (force extension to .fits)
            base = os.path.basename(self.file_path)
            name, _ = os.path.splitext(base)
            output_filename = os.path.join(self.output_directory, f"{name}_r.fits")
            
            # 7) Save the aligned image
            save_image(
                img_array=aligned_image,
                filename=output_filename,
                original_format="fits",
                bit_depth=img_bit_depth,
                original_header=img_header,
                is_mono=img_is_mono
            )
            self.signals.result.emit(output_filename)
            self.signals.progress.emit(f"Registered {os.path.basename(self.file_path)}")
            QApplication.processEvents()
        except Exception as e:
            self.signals.error.emit(f"Error processing {self.file_path}: {e}")
            QApplication.processEvents()


#############################################
# Main Star Registration Thread (Concurrent)
#############################################

class StarRegistrationThread(QThread):
    progress_update = pyqtSignal(str)
    registration_complete = pyqtSignal(bool, str)

    def __init__(self, reference_image_path, files_to_align, output_directory, 
                 max_refinement_passes=3, shift_tolerance=0.1):
        super().__init__()
        # Always store reference as normalized
        self.reference_image_path = os.path.normpath(reference_image_path)
        # Normalize each file in the list
        self.files_to_align = [os.path.normpath(f) for f in files_to_align]
        self.output_directory = os.path.normpath(output_directory)
        self.max_refinement_passes = max_refinement_passes
        self.shift_tolerance = shift_tolerance

        # alignment_matrices: { normalized_path: 2x3 transform or None }
        self.alignment_matrices = {}
        self.transform_deltas = []

    def run(self):
        try:
            # Load reference
            ref_image, _, _, _ = load_image(self.reference_image_path)
            if ref_image is None:
                self.registration_complete.emit(False, "Reference image failed to load!")
                return

            # Detect reference stars, etc...
            ref_stars = self.detect_stars(ref_image)
            if len(ref_stars) < 10:
                self.registration_complete.emit(False, "Insufficient stars in reference image!")
                return
            ref_triangles = self.build_triangle_dict(ref_stars)

            # Do multiple passes
            for pass_idx in range(self.max_refinement_passes):
                self.progress_update.emit(
                    f"⏳ Refinement Pass {pass_idx+1}/{self.max_refinement_passes}..."
                )
                success, msg = self.run_one_registration_pass(
                    ref_stars, ref_triangles, pass_idx
                )
                if not success:
                    # If everything failed, abort
                    any_aligned = any(
                        x is not None for x in self.alignment_matrices.values()
                    )
                    if not any_aligned:
                        self.registration_complete.emit(False, "No frames could be aligned. Aborting.")
                        return
                    else:
                        self.progress_update.emit("Partial success: some frames permanently failed.")
                        break

                # Check convergence
                if self.transform_deltas and max(self.transform_deltas[-1]) < self.shift_tolerance:
                    self.progress_update.emit("✅ Convergence reached! Stopping refinement.")
                    break

            # Finished passes
            aligned_count = sum(1 for v in self.alignment_matrices.values() if v is not None)
            total_count = len(self.alignment_matrices)
            summary = f"Registration complete. Valid frames: {aligned_count}/{total_count}."
            self.registration_complete.emit(True, summary)

        except Exception as e:
            self.registration_complete.emit(False, f"Error: {e}")

    def run_one_registration_pass(self, ref_stars, ref_triangles, pass_index):
        pool = QThreadPool.globalInstance()
        num_cores = os.cpu_count() or 4
        pool.setMaxThreadCount(num_cores)
        self.progress_update.emit(f"Using {num_cores} cores for pass {pass_index+1}.")

        # Launch a worker for each file
        for file_path in self.files_to_align:
            worker = StarRegistrationWorker(
                file_path, ref_stars, ref_triangles, self.output_directory
            )
            worker.signals.progress.connect(self.on_worker_progress)
            worker.signals.error.connect(self.on_worker_error)
            worker.signals.result_transform.connect(self.on_worker_result_transform)
            pool.start(worker)
        pool.waitForDone()

        pass_deltas = []
        aligned_count = 0
        for fpath in self.files_to_align:
            transform = self.alignment_matrices.get(fpath, None)
            if transform is not None:
                aligned_count += 1
                tx, ty = transform[0,2], transform[1,2]
                pass_deltas.append(np.sqrt(tx*tx + ty*ty))

        self.transform_deltas.append(pass_deltas)
        self.progress_update.emit(
            f"Pass {pass_index+1} shift deltas: {[f'{d:.2f}' for d in pass_deltas]}"
        )

        if aligned_count == 0:
            return False, "All frames failed alignment this pass."

        failed_count = len(self.files_to_align) - aligned_count
        if failed_count > 0:
            return True, f"Pass complete. {failed_count} frame(s) failed."
        return True, "Pass complete (all succeeded)."
    
    def on_worker_progress(self, msg):
        self.progress_update.emit(msg)

    def on_worker_error(self, msg):
        self.progress_update.emit("Error: " + msg)

    def on_worker_result(self, out):
        self.progress_update.emit("Saved: " + out)

    def on_worker_result_transform(self, file_path, transform):
        """
        Called whenever the worker emits `result_transform`.
        We store the transform in `self.alignment_matrices`.
        """

        norm_path = os.path.normpath(file_path)
        self.alignment_matrices[norm_path] = transform
        self.progress_update.emit(f"Stored transform for {os.path.basename(file_path)}")

    def detect_stars(self, image):
        if image.ndim == 3:
            image = np.mean(image, axis=2)
        mean, median, std = sigma_clipped_stats(image)
        daofind = DAOStarFinder(fwhm=3.5, threshold=3.4 * std)
        sources = daofind(image - median)
        if sources is None or len(sources) == 0:
            return np.array([])
        return np.vstack([sources['xcentroid'], sources['ycentroid']]).T

    def build_triangle_dict(self, coords):
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]
            inv = self.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    def compute_triangle_invariant(self, tri_points):
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1] / sides[0], sides[2] / sides[0])

    # NEW METHOD: store transforms in self.alignment_matrices
    def on_worker_result_transform(self, file_path, transform):
        self.alignment_matrices[file_path] = transform
        self.progress_update.emit(f"Stored transform for {os.path.basename(file_path)}")

    # --- Static Methods for use in Workers ---
    @staticmethod
    def detect_stars_static(image):
        if image.ndim == 3:
            image = np.mean(image, axis=2)
        mean, median, std = sigma_clipped_stats(image)
        daofind = DAOStarFinder(fwhm=3.5, threshold=3.4 * std)
        sources = daofind(image - median)
        if sources is None or len(sources) == 0:
            return np.array([])
        return np.vstack([sources['xcentroid'], sources['ycentroid']]).T

    @staticmethod
    def detect_grid_stars_static(image):
        if image.ndim == 3:
            image = np.mean(image, axis=2)
        h, w = image.shape
        margin_x = int(w * 0.05)
        margin_y = int(h * 0.05)
        valid_x_min, valid_x_max = margin_x, w - margin_x
        valid_y_min, valid_y_max = margin_y, h - margin_y
        grid_x = np.linspace(valid_x_min, valid_x_max, 4, dtype=int)
        grid_y = np.linspace(valid_y_min, valid_y_max, 4, dtype=int)
        stars = []
        for i in range(len(grid_x) - 1):
            for j in range(len(grid_y) - 1):
                x_min, x_max = grid_x[i], grid_x[i+1]
                y_min, y_max = grid_y[j], grid_y[j+1]
                sub_img = image[y_min:y_max, x_min:x_max]
                if sub_img.size == 0:
                    continue
                if np.std(sub_img) > 0:
                    local_stars = StarRegistrationThread.detect_stars_static(sub_img)
                    if len(local_stars) > 0:
                        local_stars[:, 0] = np.clip(local_stars[:, 0] + x_min, valid_x_min, valid_x_max-1)
                        local_stars[:, 1] = np.clip(local_stars[:, 1] + y_min, valid_y_min, valid_y_max-1)
                        sorted_stars = sorted(local_stars, key=lambda s: image[int(s[1]), int(s[0])], reverse=True)
                        stars.extend(sorted_stars[:12])
        return np.array(stars) if stars else np.array([])

    @staticmethod
    def compute_affine_transform_with_ransac_static(img_stars, ref_stars, ref_triangles, max_attempts=10, max_iter=10, convergence_thresh=0.2):
        print("DEBUG: Starting compute_affine_transform_with_ransac_static")
        attempt = 0
        transform = None
        while attempt < max_attempts:
            attempt += 1
            print(f"DEBUG: Initial RANSAC attempt {attempt}")
            matches = []
            for img_star in img_stars:
                distances = np.linalg.norm(ref_stars - img_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 20:
                    matches.append((img_star, ref_stars[closest_idx]))
            print(f"DEBUG: Found {len(matches)} matches on attempt {attempt}")
            if len(matches) < 3:
                print("DEBUG: Not enough matches; continuing to next attempt.")
                continue
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            rough_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.LMEDS
            )
            if rough_transform is not None and StarRegistrationThread.is_valid_transform_static(rough_transform):
                transform = rough_transform
                print("DEBUG: Rough transform computed successfully.")
                break
            else:
                print("DEBUG: Rough transform invalid; retrying.")
        if transform is None:
            print("DEBUG: Failed to compute initial rough transform.")
            return None
        for iter_num in range(max_iter):
            transformed_img_stars = cv2.transform(img_stars.reshape(-1, 1, 2), transform).reshape(-1, 2)
            matches = []
            for idx, t_star in enumerate(transformed_img_stars):
                distances = np.linalg.norm(ref_stars - t_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 7:
                    matches.append((img_stars[idx], ref_stars[closest_idx]))
            print(f"DEBUG: Refinement iteration {iter_num+1}: found {len(matches)} matches.")
            if len(matches) < 3:
                print("DEBUG: Not enough matches during refinement; aborting transform.")
                return None
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            new_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.LMEDS
            )
            if new_transform is None:
                print("DEBUG: Refinement failed to compute a new transform; aborting.")
                return None
            delta = np.linalg.norm(new_transform[:, 2] - transform[:, 2])
            print(f"DEBUG: Iteration {iter_num+1}: translation delta = {delta:.3f} pixels")
            transform = new_transform
            if delta < convergence_thresh:
                print("DEBUG: Convergence reached.")
                break
        if not StarRegistrationThread.is_valid_transform_static(transform):
            print("DEBUG: Final transform failed validation.")
            return None
        print("DEBUG: Final transform computed successfully.")
        return transform

    @staticmethod
    def is_valid_transform_static(matrix):
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]
        scale_x = np.sqrt(a**2 + c**2)
        scale_y = np.sqrt(b**2 + d**2)
        skew = np.abs((a * b + c * d) / (a**2 + c**2))
        if not (0.5 <= scale_x <= 2.0 and 0.5 <= scale_y <= 2.0):
            return False
        if skew > 0.01:
            return False
        return True

    @staticmethod
    def apply_affine_transform_static(image, transform_matrix):
        h, w = image.shape[:2]
        return cv2.warpAffine(image, transform_matrix, (w, h), flags=cv2.INTER_LINEAR)
    
class StarRegistrationWindow(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the Image Manager
        self.reference_image_path = None
        self.files_to_align = []
        self.output_directory = None
        self.thread = None  # Store thread reference

        self.initUI()

    def initUI(self):
        self.setWindowTitle("Star Registration")
        self.setGeometry(200, 200, 600, 450)
        main_layout = QVBoxLayout(self)

        # ─────────────────────────────────────────
        # Reference Image Selection
        # ─────────────────────────────────────────
        ref_layout = QHBoxLayout()
        self.ref_label = QLabel("Reference Image:")
        self.ref_path_label = QLabel("No reference selected")
        self.ref_path_label.setWordWrap(True)

        self.select_ref_slot_button = QPushButton("From Slot")
        self.select_ref_slot_button.clicked.connect(self.select_reference_from_slot)

        self.select_ref_file_button = QPushButton("From File")
        self.select_ref_file_button.clicked.connect(self.select_reference_from_file)

        ref_layout.addWidget(self.ref_label)
        ref_layout.addWidget(self.ref_path_label)
        ref_layout.addWidget(self.select_ref_slot_button)
        ref_layout.addWidget(self.select_ref_file_button)

        # ─────────────────────────────────────────
        # Image Selection Section
        # ─────────────────────────────────────────
        file_selection_layout = QHBoxLayout()

        self.add_files_button = QPushButton("Select Files")
        self.add_files_button.clicked.connect(self.select_files_to_align)

        self.add_directory_button = QPushButton("Select Directory")
        self.add_directory_button.clicked.connect(self.select_directory_to_align)

        file_selection_layout.addWidget(self.add_files_button)
        file_selection_layout.addWidget(self.add_directory_button)

        # ─────────────────────────────────────────
        # TreeBox for Selected Files
        # ─────────────────────────────────────────
        self.tree_widget = QTreeWidget()
        self.tree_widget.setColumnCount(1)
        self.tree_widget.setHeaderLabels(["Files to Align"])
        self.tree_widget.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Buttons for managing the TreeBox
        tree_buttons_layout = QHBoxLayout()
        self.remove_selected_button = QPushButton("Remove Selected")
        self.remove_selected_button.clicked.connect(self.remove_selected_files)

        self.clear_tree_button = QPushButton("Clear All")
        self.clear_tree_button.clicked.connect(self.clear_tree)

        tree_buttons_layout.addWidget(self.remove_selected_button)
        tree_buttons_layout.addWidget(self.clear_tree_button)

        # ─────────────────────────────────────────
        # Output Directory Selection
        # ─────────────────────────────────────────
        output_layout = QHBoxLayout()
        self.output_label = QLabel("Output Directory:")
        self.output_path_label = QLabel("No directory selected")
        self.output_path_label.setWordWrap(True)

        self.select_output_button = QPushButton("Select Output Folder")
        self.select_output_button.clicked.connect(self.select_output_directory)

        output_layout.addWidget(self.output_label)
        output_layout.addWidget(self.output_path_label)
        output_layout.addWidget(self.select_output_button)

        # ─────────────────────────────────────────
        # Progress Display
        # ─────────────────────────────────────────
        self.progress_label = QLabel("Status: Waiting...")
        self.progress_label.setStyleSheet("color: blue; font-weight: bold;")
        
        # ─────────────────────────────────────────
        # Start Button
        # ─────────────────────────────────────────
        self.start_button = QPushButton("Start Registration")
        self.start_button.setStyleSheet("font-weight: bold; font-size: 14px;")
        self.start_button.clicked.connect(self.start_registration)

        # ─────────────────────────────────────────
        # Add widgets to main layout
        # ─────────────────────────────────────────
        main_layout.addLayout(ref_layout)
        main_layout.addLayout(file_selection_layout)
        main_layout.addWidget(self.tree_widget)
        main_layout.addLayout(tree_buttons_layout)
        main_layout.addLayout(output_layout)
        main_layout.addWidget(self.progress_label)
        main_layout.addWidget(self.start_button)

    # ─────────────────────────────────────────
    # Slot/File Selection for Reference Image
    # ─────────────────────────────────────────
    def select_reference_from_slot(self):
        if self.image_manager:
            available_slots = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
            slot, ok = QInputDialog.getItem(self, "Select Reference Slot", "Choose a reference image slot:", list(available_slots.values()), 0, False)
            if ok:
                slot_index = list(available_slots.values()).index(slot)
                self.reference_image_path = f"Slot {slot_index}"
                self.ref_path_label.setText(self.reference_image_path)

    def select_reference_from_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if file_path:
            self.reference_image_path = file_path
            self.ref_path_label.setText(os.path.basename(file_path))

    # ─────────────────────────────────────────
    # File Selection for Alignment
    # ─────────────────────────────────────────
    def select_files_to_align(self):
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files to Align", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if files:
            for file in files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    def select_directory_to_align(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            supported_extensions = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.fits', '.fit', '.xisf')
            new_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith(supported_extensions)]
            for file in new_files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    # ─────────────────────────────────────────
    # Managing Files in TreeBox
    # ─────────────────────────────────────────
    def remove_selected_files(self):
        selected_items = self.tree_widget.selectedItems()
        for item in selected_items:
            file_name = item.text(0)
            for file_path in self.files_to_align:
                if os.path.basename(file_path) == file_name:
                    self.files_to_align.remove(file_path)
                    break
            index = self.tree_widget.indexOfTopLevelItem(item)
            self.tree_widget.takeTopLevelItem(index)

    def clear_tree(self):
        self.tree_widget.clear()
        self.files_to_align.clear()

    # ─────────────────────────────────────────
    # Output Directory Selection
    # ─────────────────────────────────────────
    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory", "")
        if directory:
            self.output_directory = directory
            self.output_path_label.setText(directory)

    # ─────────────────────────────────────────
    # Start Registration with Signal Handling
    # ─────────────────────────────────────────
    def start_registration(self):
        if not self.reference_image_path:
            QMessageBox.warning(self, "Missing Reference", "Please select a reference image before starting.")
            return
        if not self.files_to_align:
            QMessageBox.warning(self, "No Files", "Please add files to align before starting.")
            return
        if not self.output_directory:
            QMessageBox.warning(self, "No Output Directory", "Please select an output directory before starting.")
            return

        self.progress_label.setText("Status: Running...")
        self.progress_label.setStyleSheet("color: green; font-weight: bold;")

        self.thread = StarRegistrationThread(self.reference_image_path, self.files_to_align, self.output_directory)
        self.thread.progress_update.connect(self.update_progress)
        self.thread.registration_complete.connect(self.registration_finished)
        self.thread.start()

    def update_progress(self, message):
        """Update the progress label with the latest status."""
        self.progress_label.setText(f"Status: {message}")
        QApplication.processEvents()

    def registration_finished(self, success, message):
        """Handle the completion of the registration process."""
        color = "green" if success else "red"
        self.progress_label.setText(f"Status: {message}")
        self.progress_label.setStyleSheet(f"color: {color}; font-weight: bold;")

        if success:
            QMessageBox.information(self, "Registration Complete", message)
        else:
            QMessageBox.warning(self, "Registration Error", message)


class PlateSolver(QDialog):
    """
    A dialog class to handle plate solving.
    
    This class lets the user choose either an image file or a slot image,
    then attempts to run ASTAP on the image (if the ASTAP executable is available),
    falls back to astrometry.net if needed, and finally updates the image metadata/FITS header.
    """
    def __init__(self, settings: QSettings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Plate Solver")
        self.setMinimumWidth(400)
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        self.starnet_exe = self.settings.value("starnet/exe_path", "", type=str)
        self.debug_mode = False
        
        self.image_path = ""  # Will hold the selected image path
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # Instruction Label
        instr_label = QLabel("Select an image source for plate solving:")
        layout.addWidget(instr_label)
        
        # Selection mode combo box (Slot shown first by default)
        self.mode_combo = QComboBox()
        # Reorder items so that "Slot" is default.
        self.mode_combo.addItems(["Slot", "File"])
        self.mode_combo.currentIndexChanged.connect(self.change_mode)
        layout.addWidget(self.mode_combo)
        
        # Stacked widget to hold different UIs
        self.stacked = QStackedWidget()
        layout.addWidget(self.stacked)
        
        # Page 0: Slot selection UI
        slot_page = QWidget()
        slot_layout = QVBoxLayout(slot_page)
        slot_instr = QLabel("Select a slot from which to use the image:")
        slot_layout.addWidget(slot_instr)
        self.slot_combo = QComboBox()
        # Populate with slot names from parent if available
        if self.parent() and hasattr(self.parent(), "slot_names"):
            # Assume slot_names is a dict: {slot_index: "Slot N"}
            for index, name in self.parent().slot_names.items():
                self.slot_combo.addItem(name, index)
        else:
            self.slot_combo.addItems(["Slot 0", "Slot 1", "Slot 2"])
        slot_layout.addWidget(self.slot_combo)
        self.choose_slot_btn = QPushButton("Select Slot")
        self.choose_slot_btn.clicked.connect(self.choose_slot)
        slot_layout.addWidget(self.choose_slot_btn)
        self.slot_status_label = QLabel("No slot selected.")
        slot_layout.addWidget(self.slot_status_label)
        self.stacked.addWidget(slot_page)
        
        # Page 1: File selection UI
        file_page = QWidget()
        file_layout = QVBoxLayout(file_page)
        self.choose_file_btn = QPushButton("Choose Image File")
        self.choose_file_btn.clicked.connect(self.choose_file)
        file_layout.addWidget(self.choose_file_btn)
        self.file_status_label = QLabel("No file selected.")
        file_layout.addWidget(self.file_status_label)
        self.stacked.addWidget(file_page)

        # Add a dedicated status label for overall status messages.
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)        

        # Solve button
        self.solve_btn = QPushButton("Start Plate Solving")
        self.solve_btn.clicked.connect(self.start_plate_solving)
        layout.addWidget(self.solve_btn)

        # --- NEW: Batch Plate Solve button ---
        self.batch_solve_btn = QPushButton("Batch Plate Solve with ASTAP")
        self.batch_solve_btn.clicked.connect(self.openBatchPlateSolver)
        layout.addWidget(self.batch_solve_btn)        
        
        # Close button
        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.reject)
        layout.addWidget(close_btn)
        
        # Set the default mode to Slot (index 0)
        self.mode_combo.setCurrentIndex(0)
        self.stacked.setCurrentIndex(0)
        self.image_path = ""

    def openBatchPlateSolver(self):
        # Directly create an instance of BatchPlateSolverDialog
        dialog = BatchPlateSolverDialog(self.settings, parent=self)
        dialog.show()

    def change_mode(self, index):
        """Change the stacked widget page based on the selection mode."""
        self.stacked.setCurrentIndex(index)
        # Clear any previous selection status
        if index == 0:  # Slot mode
            self.slot_status_label.setText("No slot selected.")
            self.image_path = ""
        elif index == 1:  # File mode
            self.file_status_label.setText("No file selected.")
            self.image_path = ""

    def choose_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Image for Plate Solving",
            "", "Image Files (*.fit *.fits *.png *.tif *.tiff *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.image_path = file_path
            self.file_status_label.setText(f"Selected: {os.path.basename(file_path)}")
        else:
            self.file_status_label.setText("No file selected.")

    def choose_slot(self):
        """Select an image from a slot."""
        # Check if parent's image_manager is available
        if not (self.parent() and hasattr(self.parent(), "image_manager")):
            QMessageBox.warning(self, "Slot Selection", "Slot images are not available.")
            return

        slot_index = self.slot_combo.currentData()
        img_manager = self.parent().image_manager
        image = img_manager._images.get(slot_index, None)

        # Check if there is image data in the slot.
        if image is not None and hasattr(image, "size") and image.size > 0:
            metadata = img_manager._metadata.get(slot_index, {})
            # Set flag to indicate that we're using slot data.
            self._from_slot = True
            # Use the stored file path if available; otherwise, store a dummy value.
            if "file_path" in metadata and metadata["file_path"]:
                self.image_path = metadata["file_path"]
            else:
                self.image_path = f"slot:{slot_index}"
            self.slot_status_label.setText(
                f"Selected: {self.parent().slot_names.get(slot_index, f'Slot {slot_index}')}"
            )
            # Save slot metadata for later merging.
            self._slot_meta = metadata
        else:
            self.slot_status_label.setText("No image in the selected slot.")
            QMessageBox.warning(self, "Slot Selection", "No image available in the selected slot.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def start_plate_solving(self):
        if not self.image_path:
            QMessageBox.warning(self, "Plate Solver", "Please select an image source first.")
            return

        # Determine the appropriate filter for the ASTAP executable.
        if sys.platform.startswith("win"):
            executable_filter = "Executables (*.exe);;All Files (*)"
        else:
            executable_filter = "Executables (astap);;All Files (*)"

        # Check if ASTAP path is set and valid.
        if not self.astap_exe or not os.path.exists(self.astap_exe):
            # Prompt the user to locate the ASTAP executable.
            new_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select ASTAP Executable",
                "",
                executable_filter
            )
            if new_path:
                self.astap_exe = new_path
                # Save the new ASTAP path in settings.
                self.settings.setValue("astap/exe_path", self.astap_exe)
                QMessageBox.information(self, "Plate Solver", "ASTAP path updated successfully.")
            else:
                # If no ASTAP is provided, skip directly to blind solving via astrometry.net.
                QMessageBox.information(self, "Plate Solver", "ASTAP executable not provided; falling back to astrometry.net blind solve.")
                solved = self.run_astrometry_net(self.image_path)
                if solved:
                    QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
                    self.update_metadata()
                    self.accept()
                else:
                    QMessageBox.critical(self, "Plate Solve", "Plate solve failed with astrometry.net.")
                return

        # Try ASTAP first.
        self.update_status("Running ASTAP plate solving...")
        solved = self.run_astap(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using ASTAP!")
            self.accept()
            return
        else:
            QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Trying astrometry.net...")

        # Fall back to astrometry.net.
        solved = self.run_astrometry_net(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
            self.update_metadata()
            self.accept()
        else:
            QMessageBox.critical(self, "Plate Solve", "Plate solve failed with both ASTAP and astrometry.net.")

    def update_status(self, message: str):
        """Update the status label on the current page."""
        index = self.stacked.currentIndex()
        if index == 0:
            self.file_status_label.setText(message)
        else:
            self.slot_status_label.setText(message)

    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def run_astap(self, image_path: str, update_manager=True) -> bool:
        """
        Loads the image data and metadata based on the user's selection:
        - If the user selected a slot (self._from_slot is True), retrieve the image and metadata
            from the ImageManager.
        - Otherwise, use the global load_image() method to load from a file.
        
        The image is normalized using stretch_image(), saved as a temporary FITS file (via
        save_temp_fits_image()), and ASTAP is run on that temporary file.
        
        If ASTAP is successful, the updated (solved) header is retrieved and:
        1. The metadata dictionary for the current slot is updated with the solved header.
        2. If the image was loaded from file (i.e. not a slot) and is a FITS file, the original
            file is updated with the new header.
        3. The user is prompted to save a new FITS file with the solved header.
        
        Returns True if ASTAP exits with exit code 0.
        """
        if getattr(self, "debug_mode", False):
            print("DEBUG MODE: Skipping ASTAP processing.")
            return False
        # --- Load image data and header ---
        if getattr(self, "_from_slot", False):
            # Use data from the ImageManager.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
                if image_data is None:
                    print("No image data found in the selected slot.")
                    return False
                original_header = meta.get("original_header", meta)
                # Save slot metadata for later merging.
                self._slot_meta = meta
                print("Using image data and metadata from slot.")
            else:
                print("No ImageManager found in parent!")
                return False
        else:
            # Load from file using the global load_image() method.
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False
            print("Loaded image data and header from file.")

        # Keep a copy of the original image data (unsqueezed) for saving the new FITS.
        original_image_data = image_data.copy()

        image_data = image_data.astype(np.float32)

        # --- Normalize the image ---
        normalized_image = self.stretch_image(image_data)

        # --- Save normalized image to a temporary FITS file ---
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, image_path)
        except Exception as e:
            print("Failed to save temporary FITS file:", e)
            return False

        # --- Run ASTAP on the temporary file ---
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            return False
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return False

        # --- Retrieve updated header data from the temporary file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Regular expression to match a FITS header keyword and its value.
                    # It assumes a format like: KEY  =  value / comment
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)        
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2: ideally provided by ASTAP's INI file.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Ensure required WCS keys are present with proper numeric types ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # Convert the value to float. If it's meant to be an integer (like WCSAXES),
                    # you can use int(float(...)) if needed.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Compute CROTA1 and CROTA2 if not present ---
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                print(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                print("CD matrix elements not available; cannot compute CROTA values.")


        print("Final solved header to be used:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        # --- Directly update the metadata dictionary for the current slot ---
        if update_manager:
            if self.parent() and hasattr(self.parent(), "image_manager"):
                try:
                    current_slot = self.parent().image_manager.current_slot
                    self.parent().image_manager._metadata[current_slot].update(solved_header)
                    print("ImageManager metadata for slot", current_slot, "updated with solved header.")
                except Exception as e:
                    print("Error updating ImageManager metadata with solved data:", e)
                    return False
            else:
                print("No parent ImageManager found; cannot update solved metadata.")
                return False
        else:
            print("Batch mode: Skipping image manager metadata update.")

        # --- If the image was loaded from file (not a slot) and is a FITS file, update that file with the new header ---
        if not getattr(self, "_from_slot", False) and image_path.lower().endswith((".fits", ".fit")):
            try:
                with fits.open(image_path, mode="update", memmap=False) as hdul:
                    hdr = hdul[0].header
                    # Remove problematic keys before updating.
                    solved_header.pop("COMMENT", None)
                    solved_header.pop("HISTORY", None)
                    for key, value in solved_header.items():
                        hdr[key] = value
                    hdul.flush()
                print("Original FITS file updated with solved header (inline).")
            except Exception as e:
                print("Error updating original FITS file with solved header:", e)
                # Optionally, do not treat this as fatal.

        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                # Determine if the image is mono.
                if original_image_data.ndim == 2 or (original_image_data.ndim == 3 and original_image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False

                # If mono, expand it to 3-channel
                if is_mono:
                    original_image_data = np.stack([original_image_data] * 3, axis=-1)  # Convert to RGB-equivalent format
                    is_mono = False  # Mark as non-mono since we expanded it

                if "file_path" in solved_header:
                    del solved_header["file_path"]                    
                # Save the original image data with the solved header.

                # Print the final header before saving
                print("\n✅ FINAL HEADER BEFORE SAVING:")
                for key, value in solved_header.items():
                    print(f"{key} = {value}")                
                save_image(
                    img_array=original_image_data,
                    filename=save_path,
                    original_format="fits",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
            # --- Prompt the user to open the newly saved FITS file ---
            reply = QMessageBox.question(
                self, 
                "Open Plate Solved FITS?", 
                "Do you want to open the newly saved plate-solved FITS file?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if reply == QMessageBox.StandardButton.Yes:
                try:
                    # Load the newly saved FITS file using the global load_image() method.
                    new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                    if new_image is None:
                        QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                    else:
                        # Build a metadata dictionary as in your AstroEditingSuite.
                        metadata = {
                            'file_path': save_path,
                            'original_header': new_header,
                            'bit_depth': new_bit_depth,
                            'is_mono': new_is_mono
                        }
                        # Add the new image and metadata to the ImageManager in the current slot.
                        self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                        print("Plate-solved FITS image loaded and added to ImageManager.")
                except Exception as e:
                    print("Error loading plate-solved FITS file:", e)
                    QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
            else:
                print("User chose not to open the plate-solved FITS file.")
                    
        # --- Clean up temporary files ---
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            print("Error removing INI file:", e)

        return True

    def run_astrometry_net(self, image_path: str):
        """
        Performs a blind solve via Astrometry.net following these steps:
        1. Log in to Astrometry.net using an API key.
        2. Upload the image (converting it to FITS if necessary).
        3. Poll for a job ID.
        4. Poll for calibration data.
        5. Construct a WCS header from the calibration data.
        6. If the image was originally FITS, update that file with the new header.
        7. Store the WCS in the item dictionary.
        
        Returns the constructed WCS header (a FITS Header) on success, or False on failure.
        """
        # Build an item dictionary from the image data.
        if getattr(self, "_from_slot", False):
            # Retrieve from ImageManager.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
                if image_data is None:
                    print("No image data found in the selected slot.")
                    return False
                original_header = meta.get("original_header", meta)
                item = {
                    "path": meta.get("file_path", image_path),
                    "image": image_data,
                    "is_mono": meta.get("is_mono", False)
                }
                self._slot_meta = meta  # Save slot metadata for later merging.
                print("Using image data and metadata from slot for blind solve.")
            else:
                print("No ImageManager found in parent!")
                return False
        else:
            # Load from file using load_image().
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False
            item = {
                "path": image_path,
                "image": image_data,
                "is_mono": is_mono
            }
            print("Loaded image data and header from file for blind solve.")

        # --- Begin blind solve loop ---
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return False

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine file extension.
            ext = os.path.splitext(item["path"])[1].lower()
            if ext not in ('.fits', '.fit'):
                # Convert non-FITS image to a temporary FITS file.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close so save_image can write.
                try:
                    minimal_header = generate_minimal_fits_header(item["image"])
                    save_image(
                        img_array=item["image"],
                        filename=temp_file.name,
                        original_format="fit",
                        bit_depth="16-bit",
                        original_header=minimal_header,
                        is_mono=item.get("is_mono", False)
                    )
                except Exception as e:
                    QMessageBox.critical(self, "Conversion Error", f"Failed to convert image to FITS:\n{e}")
                    return False
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            # If a temporary file was created (for non-FITS images), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)
            break  # Exit loop once all steps succeed.

        # --- Construct the WCS header ---
        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        # Store the WCS in the item.
        item["wcs"] = WCS(wcs_header)

        # --- (Optional) Update the metadata of the slot if applicable ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in wcs_header and "file_path" in self._slot_meta:
                wcs_header["file_path"] = self._slot_meta["file_path"]
            # Directly update the metadata dictionary for the current slot.
            self.parent().image_manager._metadata[self.parent().image_manager.current_slot].update(wcs_header)
            print("ImageManager metadata for current slot updated with solved header.")

        # --- Now prompt the user to save the new plate-solved FITS file ---
        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False
                # Save the original (unsqueezed) image data with the solved header.
                save_image(
                    img_array=image_data,
                    filename=save_path,
                    original_format="fits",
                    bit_depth="32-bit floating point",
                    original_header=wcs_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
        else:
            print("User cancelled saving the plate-solved FITS file.")

        # --- Prompt the user to open the new plate-solved FITS file ---
        reply = QMessageBox.question(
            self,
            "Open Plate Solved FITS?",
            "Do you want to open the newly saved plate-solved FITS file?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            try:
                new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                if new_image is None:
                    QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                else:
                    metadata = {
                        'file_path': save_path,
                        'original_header': new_header,
                        'bit_depth': new_bit_depth,
                        'is_mono': new_is_mono
                    }
                    self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                    print("Plate-solved FITS image loaded and added to ImageManager.")
            except Exception as e:
                print("Error loading plate-solved FITS file:", e)
                QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
        else:
            print("User chose not to open the plate-solved FITS file.")

        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    def update_metadata(self):
        """
        Placeholder method to update the metadata or FITS header
        with the plate solving results.
        Extend this method to:
          - Read the .wcs or .ini output files from the plate solver
          - Update the image metadata accordingly.
        """
        print("Updating metadata/FITS header... (this is a placeholder)")
        # TODO: Implement metadata update logic here.

class BatchPlateSolverDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Batch Plate Solve")
        self.setMinimumWidth(500)
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        self.inputDirLineEdit = QLineEdit()
        self.outputDirLineEdit = QLineEdit()
        inputBrowseButton = QPushButton("Browse Input Directory")
        outputBrowseButton = QPushButton("Browse Output Directory")
        self.startButton = QPushButton("Start Batch Plate Solve")
        self.statusTextEdit = QTextEdit()
        self.statusTextEdit.setReadOnly(True)
        
        layout.addWidget(QLabel("Input Directory:"))
        layout.addWidget(self.inputDirLineEdit)
        layout.addWidget(inputBrowseButton)
        layout.addWidget(QLabel("Output Directory:"))
        layout.addWidget(self.outputDirLineEdit)
        layout.addWidget(outputBrowseButton)
        layout.addWidget(self.startButton)
        layout.addWidget(QLabel("Status:"))
        layout.addWidget(self.statusTextEdit)
        
        inputBrowseButton.clicked.connect(self.browseInputDir)
        outputBrowseButton.clicked.connect(self.browseOutputDir)
        self.startButton.clicked.connect(self.startBatchPlateSolve)
        
    def browseInputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.inputDirLineEdit.setText(directory)
        
    def browseOutputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.outputDirLineEdit.setText(directory)
            
    def logStatus(self, message):
        self.statusTextEdit.append(message)
        QApplication.processEvents()
        
    def run_astap_batch(self, image_path: str):
        """
        Batch-mode version of ASTAP processing.
        This method loads an image, normalizes it, saves a temporary FITS file,
        runs ASTAP, retrieves the solved header, and returns it.
        It does not update any ImageManager or prompt the user.
        """
        # Load image from file
        image_data, original_header, bit_depth, is_mono = load_image(image_path)
        if image_data is None:
            self.logStatus(f"Failed to load image from file: {image_path}")
            return False

        # Keep a copy of original image data if needed later.
        original_image_data = image_data.copy()

        image_data = image_data.astype(np.float32)
        # Normalize image (using your existing stretch_image method)
        normalized_image = image_data

        # Save temporary FITS file
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, image_path)
        except Exception as e:
            self.logStatus(f"Failed to save temporary FITS file: {e}")
            return False

        # Run ASTAP on temporary file
        astap_exe = self.settings.value("astap/exe_path", "", type=str)
        if not astap_exe or not os.path.exists(astap_exe):
            self.logStatus("ASTAP executable not found.")
            return False

        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        self.logStatus(f"Running ASTAP with arguments: {args}")
        process.start(astap_exe, args)
        if not process.waitForStarted(5000):
            self.logStatus("Failed to start ASTAP process: " + process.errorString())
            return False
        if not process.waitForFinished(300000):
            self.logStatus("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        self.logStatus(f"ASTAP exit code: {exit_code}")
        self.logStatus("ASTAP STDOUT: " + stdout)
        self.logStatus("ASTAP STDERR: " + stderr)
        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                self.logStatus("Error removing temporary file: " + str(e))
            return False

        # Retrieve solved header from temporary FITS file
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            self.logStatus("Initial solved header retrieved:")
            for key, value in solved_header.items():
                self.logStatus(f"{key} = {value}")
        except Exception as e:
            self.logStatus("Error reading solved header after ASTAP: " + str(e))
            return False

        # Check for a corresponding .wcs file and merge its header if present.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                self.logStatus("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    self.logStatus(f"{key} = {value}")
                solved_header.update(wcs_header)
            except Exception as e:
                self.logStatus("Error reading .wcs file: " + str(e))
        else:
            self.logStatus("No .wcs file found; using header from temporary FITS.")

        # Add missing required keys
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                self.logStatus(f"Added missing key {key} with default value {default}.")

        # Convert expected numeric keys
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    self.logStatus(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # Compute CROTA1 and CROTA2 if missing
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                self.logStatus(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                self.logStatus("CD matrix elements not available; cannot compute CROTA values.")

        self.logStatus("Final solved header:")
        for key, value in solved_header.items():
            self.logStatus(f"{key} = {value}")

        try:
            os.remove(tmp_path)
        except Exception as e:
            self.logStatus("Error removing temporary file: " + str(e))
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            self.logStatus("Error removing .wcs file: " + str(e))
        return solved_header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            # In single-image mode, an ImageManager might be available.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                original_header = meta.get("original_header", None)
            else:
                # In batch mode, no ImageManager is available; try reading the header directly.
                try:
                    with fits.open(image_path, memmap=False) as hdul:
                        original_header = dict(hdul[0].header)
                    print("Original FITS header loaded from file.")
                except Exception as e:
                    print("Failed to load header from FITS file; creating a minimal header. Error:", e)
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header


    def startBatchPlateSolve(self):
        inputDir = self.inputDirLineEdit.text().strip()
        outputDir = self.outputDirLineEdit.text().strip()
        if not inputDir or not outputDir:
            QMessageBox.warning(self, "Missing Directories", "Please select both input and output directories.")
            return
        
        acceptable_exts = ['.xisf', '.fits', '.fit', '.tif', '.tiff', '.png', '.jpg', '.jpeg']
        files = [os.path.join(inputDir, f) for f in os.listdir(inputDir)
                 if os.path.splitext(f)[1].lower() in acceptable_exts]
        
        if not files:
            QMessageBox.information(self, "No Files", "No acceptable image files found in the input directory.")
            return
        
        self.logStatus(f"Found {len(files)} files. Starting batch processing...")
        
        for file in files:
            self.logStatus(f"Processing: {file}")
            try:
                # Load image data
                image_data, original_header, bit_depth, is_mono = load_image(file)
                if image_data is None:
                    self.logStatus(f"Failed to load image: {file}")
                    continue

                # Run our batch ASTAP routine (which does not update the ImageManager)
                solved_header = self.run_astap_batch(file)
                if not solved_header:
                    self.logStatus(f"Plate solving failed for: {file}")
                    continue
                
                base_name = os.path.splitext(os.path.basename(file))[0]
                output_file = os.path.join(outputDir, base_name + "_plate_solved.fits")
                
                # Save the image with the solved header
                save_image(
                    img_array=image_data,
                    filename=output_file,
                    original_format="fits",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                self.logStatus(f"Saved plate-solved image to: {output_file}")
            except Exception as e:
                self.logStatus(f"Error processing {file}: {e}")
        
        self.logStatus("Batch plate solving completed.")


class PSFViewer(QDialog):
    def __init__(self, image, parent=None):
        """
        Initialize the PSF Viewer dialog.
        Prompts the user for a mode (Quick or Detailed) before computing the star catalog.
        """
        super().__init__(parent)
        self.setWindowTitle("PSF Viewer")
        self.image = image
        self.zoom_factor = 1.0
        self.log_scale = False
        self.star_catalog = None
        self.histogram_mode = 'PSF'  # Can be toggled later
        # Prompt the user for mode.
        mode, ok = QInputDialog.getItem(
            self,
            "Select Mode",
            "Select PSF catalog mode:",
            ["Quick", "Detailed"],
            0,
            False
        )
        if ok:
            self.mode = mode
        else:
            self.mode = "Quick"
        
        # Compute the star catalog based on the chosen mode.
        if self.mode == "Quick":
            self.compute_star_catalog_quick()
        else:
            self.compute_star_catalog_detailed()
        
        self.initUI()

    def updateImage(self, new_image):
        """
        Update the current image, recompute the star catalog,
        and redraw the histogram.
        """
        self.image = new_image
        self.compute_star_catalog_quick()
        self.drawHistogram()

    def compute_star_catalog_quick(self):
        """
        Run DAOStarFinder for FWHM values from 2.5, then 3, 4, ..., 10,
        update a progress dialog, and combine results. If a star is detected
        at multiple FWHM values, merge the detections by taking the median of
        the FWHM values (e.g. if detected at 2 and 3, use 2.5; if detected at
        2, 3, and 4, use 3). Duplicate stars (by x,y centroid) are merged.
        
        Note: DAOStarFinder returns various parameters for each star (e.g., 
        xcentroid, ycentroid, sharpness, roundness1, npix, sky, peak, flux). 
        Here we record the detection FWHM value in the column 'fwhm_used'.
        """
        # Build the list of FWHM values: start with 2.5, then 3, 4, ..., 10.
        fwhm_list = [2.5] + list(range(3, 11))
        total_steps = len(fwhm_list)

        # Create a progress dialog with a range from 0 to total_steps.
        progress = QProgressDialog("Computing star catalog...", "Cancel", 0, total_steps, self)
        progress.setWindowTitle("Please Wait")
        progress.setWindowModality(Qt.WindowModality.ApplicationModal)
        progress.setMinimumDuration(0)
        progress.show()

        all_stars = []
        
        # Convert image to grayscale if necessary.
        if self.image.ndim == 3:
            image_gray = np.mean(self.image, axis=2)
        else:
            image_gray = self.image

        # Estimate background statistics.
        mean, median, std = sigma_clipped_stats(image_gray)
        
        # Loop over each FWHM value.
        for i, fwhm in enumerate(fwhm_list):
            progress.setLabelText(f"Processing FWHM = {fwhm}...")
            QApplication.processEvents()  # Allow UI to update.

            daofind = DAOStarFinder(fwhm=float(fwhm), threshold=5.0 * std)
            stars = daofind(image_gray - median)
            if stars is not None and len(stars) > 0:
                # Record the detection FWHM value.
                stars['fwhm_used'] = np.full(len(stars), fwhm)
                all_stars.append(stars)
            
            progress.setValue(i + 1)
            if progress.wasCanceled():
                progress.close()
                return

        progress.close()

        if all_stars:
            # Combine all detections into one table.
            star_catalog = vstack(all_stars)
            # Group stars by rounded x,y centroids.
            grouped = {}
            for star in star_catalog:
                key = (round(star['xcentroid'], 1), round(star['ycentroid'], 1))
                if key not in grouped:
                    grouped[key] = []
                # Convert the Row to a dictionary for easier merging.
                grouped[key].append(dict(star))
            
            merged_entries = []
            for key, group in grouped.items():
                if len(group) == 1:
                    # Only one detection; use it as-is.
                    merged_entries.append(group[0])
                else:
                    # Merge detections: compute the median of the fwhm_used values.
                    fwhm_values = [entry['fwhm_used'] for entry in group]
                    median_fwhm = float(np.median(fwhm_values))
                    # Choose one entry (here, the first) and update its fwhm_used.
                    merged_entry = group[0].copy()
                    merged_entry['fwhm_used'] = median_fwhm
                    merged_entries.append(merged_entry)
            # Create the final star catalog table from the merged entries.
            self.star_catalog = Table(rows=merged_entries)
        else:
            self.star_catalog = None



    def compute_star_catalog_detailed(self):
        """
        Run DAOStarFinder for FWHM values ranging from 2.1 to 10.0 in increments of 0.1,
        update a progress dialog, and combine results. If a star is detected at multiple FWHM values,
        merge the detections by computing the median of the fwhm_used values.
        
        Extra information provided by DAOStarFinder (e.g., sharpness, roundness1, npix, sky, peak, flux)
        is retained. Duplicate detections (grouped by rounded x and y centroids) are merged.
        """
        # Create an array of FWHM values from 2.1 to 10.0 (inclusive) in steps of 0.1.
        fwhm_values = np.arange(2.0, 10.01, 0.1)
        
        # Create a progress dialog.
        progress = QProgressDialog("Computing star catalog...", "Cancel", 0, len(fwhm_values), self)
        progress.setWindowTitle("Please Wait")
        progress.setWindowModality(Qt.WindowModality.ApplicationModal)
        progress.setMinimumDuration(0)
        progress.show()

        all_stars = []
        
        # Convert image to grayscale if necessary.
        if self.image.ndim == 3:
            image_gray = np.mean(self.image, axis=2)
        else:
            image_gray = self.image

        # Estimate background statistics.
        mean, median, std = sigma_clipped_stats(image_gray)
        
        # Loop over each FWHM value.
        for i, fwhm in enumerate(fwhm_values):
            progress.setLabelText(f"Processing FWHM = {fwhm:.1f}...")
            QApplication.processEvents()  # Update the UI.

            daofind = DAOStarFinder(fwhm=float(fwhm), threshold=5.0 * std)
            stars = daofind(image_gray - median)
            if stars is not None and len(stars) > 0:
                # Record the detection FWHM value.
                stars['fwhm_used'] = np.full(len(stars), fwhm)
                all_stars.append(stars)

            progress.setValue(i + 1)
            if progress.wasCanceled():
                progress.close()
                return

        progress.close()

        if all_stars:
            # Combine all detections into one table.
            star_catalog = vstack(all_stars)
            # Group stars by rounded x and y centroids.
            grouped = {}
            for star in star_catalog:
                key = (round(star['xcentroid'], 1), round(star['ycentroid'], 1))
                if key not in grouped:
                    grouped[key] = []
                grouped[key].append(dict(star))  # Convert Row to dict.
            
            merged_entries = []
            for key, group in grouped.items():
                if len(group) == 1:
                    # Only one detection; use it as is.
                    merged_entries.append(group[0])
                else:
                    # Merge detections: compute the median fwhm_used value.
                    fwhm_values_list = [entry['fwhm_used'] for entry in group]
                    median_fwhm = float(np.median(fwhm_values_list))
                    # Use the first entry as the base and update its fwhm_used.
                    merged_entry = group[0].copy()
                    merged_entry['fwhm_used'] = median_fwhm
                    merged_entries.append(merged_entry)
            
            # Create the final star catalog from the merged entries.
            self.star_catalog = Table(rows=merged_entries)
        else:
            self.star_catalog = None




    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Top layout holds the histogram display and the statistics table.
        top_layout = QHBoxLayout()

        # Scroll area for histogram
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)

        # Statistics table (4 rows: Min, Max, Median, StdDev)
        self.stats_table = QTableWidget(self)
        self.stats_table.setRowCount(4)
        # We use 1 column (can update header text later)
        self.stats_table.setColumnCount(1)
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)

        main_layout.addLayout(top_layout)

        # Controls layout: Zoom slider, Log scale toggle, and a histogram mode toggle.
        controls_layout = QHBoxLayout()
        
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)  # 50% to 1000%
        self.zoom_slider.setValue(100)       # Default: 100%
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(QLabel("Zoom:"))
        controls_layout.addWidget(self.zoom_slider)
        
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis scaling.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)
        
        # Button to switch between PSF and Flux histograms.
        self.mode_toggle_button = QPushButton("Show Flux Histogram", self)
        self.mode_toggle_button.setToolTip("Switch between PSF (FWHM) and Flux histograms.")
        self.mode_toggle_button.clicked.connect(self.toggleHistogramMode)
        controls_layout.addWidget(self.mode_toggle_button)
        
        main_layout.addLayout(controls_layout)
        
        # Close button
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        
        # Draw initial histogram
        self.drawHistogram()

    def updateZoom(self, value):
        self.zoom_factor = value / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked):
        self.log_scale = checked
        self.drawHistogram()

    def toggleHistogramMode(self):
        """
        Toggle between displaying a histogram of PSF (FWHM) values and flux values.
        """
        if self.histogram_mode == 'PSF':
            self.histogram_mode = 'Flux'
            self.mode_toggle_button.setText("Show PSF Histogram")
        else:
            self.histogram_mode = 'PSF'
            self.mode_toggle_button.setText("Show Flux Histogram")
        self.drawHistogram()

    def drawHistogram(self):
        """
        Draws the histogram of either PSF (FWHM used) or flux values from the star catalog.
        """
        # Create a pixmap for drawing.
        base_width = 512
        height = 300
        width = int(base_width * self.zoom_factor)
        pixmap = QPixmap(width, height)
        pixmap.fill(Qt.GlobalColor.white)
        painter = QPainter(pixmap)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        bin_count = 50  # Adjust number of bins as desired
        
        # Determine the data to histogram:
        if self.star_catalog is None or len(self.star_catalog) == 0:
            data = np.array([])
            bin_edges = np.linspace(0, 1, bin_count + 1)
        else:
            if self.histogram_mode == 'PSF':
                # Use the HFR (Half Flux Radius) by dividing the FWHM values by 2.
                data = np.array(self.star_catalog['fwhm_used'], dtype=float) / 2.0
                # Set bin range accordingly (e.g. 0 to 5 if original FWHM ranged from 0 to 10).
                bin_edges = np.linspace(0, 5, bin_count + 1)
            else:
                # Use the 'flux' column; let bins span the range of flux.
                data = np.array(self.star_catalog['flux'])
                if data.size > 0:
                    bin_edges = np.linspace(data.min(), data.max(), bin_count + 1)
                else:
                    bin_edges = np.linspace(0, 1, bin_count + 1)
        
        # For log-scale x-axis, adjust the bin edges.
        if self.log_scale:
            # Avoid zero for log scale.
            eps = 1e-4
            # Ensure the lower bound is not below eps.
            lower = max(bin_edges[0], eps)
            upper = bin_edges[-1]
            bin_edges = np.logspace(np.log10(lower), np.log10(upper), bin_count + 1)
            def x_pos(val):
                return int((np.log10(val) - np.log10(lower)) / (np.log10(upper) - np.log10(lower)) * width)
        else:
            def x_pos(val):
                return int((val - bin_edges[0]) / (bin_edges[-1] - bin_edges[0]) * width)
        
        # Compute histogram counts.
        if data.size > 0:
            hist, _ = np.histogram(data, bins=bin_edges)
            # Normalize for display.
            if hist.max() > 0:
                hist = hist.astype(np.float32) / hist.max()
            else:
                hist = hist.astype(np.float32)
        else:
            hist = np.zeros(bin_count)
        
        # Draw histogram bars.
        painter.setPen(QPen(Qt.GlobalColor.black))
        for i in range(bin_count):
            x0 = x_pos(bin_edges[i])
            x1 = x_pos(bin_edges[i+1])
            bar_width = max(x1 - x0, 1)
            bar_height = hist[i] * height
            painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        
        # Draw x-axis.
        painter.setPen(QPen(Qt.GlobalColor.black, 2))
        painter.drawLine(0, height - 1, width, height - 1)
        
        # Draw tick marks and labels.
        painter.setFont(QFont("Arial", 10))
        if self.log_scale:
            tick_values = np.logspace(np.log10(bin_edges[0]), np.log10(bin_edges[-1]), 6)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 15, height - 10, f"{tick:.3f}")
        else:
            tick_values = np.linspace(bin_edges[0], bin_edges[-1], 6)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 15, height - 10, f"{tick:.2f}")
        
        painter.end()
        self.hist_label.setPixmap(pixmap)
        self.hist_label.resize(pixmap.size())
        
        # Update the statistics table.
        self.updateStatistics()

    def updateStatistics(self):
        """
        Compute and update summary statistics (Min, Max, Median, StdDev) for each numeric column
        in the star catalog (excluding id, xcentroid, ycentroid, mag, daofind_mag). The table columns
        are reordered so that 'fwhm_used' appears first.
        """
        if self.star_catalog is None or len(self.star_catalog) == 0:
            colnames = []
        else:
            # Get all column names.
            all_cols = self.star_catalog.colnames
            # Columns to remove.
            skip_cols = ['id', 'xcentroid', 'ycentroid', 'mag', 'daofind_mag']
            # Filter out the unwanted columns.
            colnames = [col for col in all_cols if col not in skip_cols]
            # If 'fwhm_used' is present, move it to the front.
            if 'fwhm_used' in colnames:
                colnames.remove('fwhm_used')
                # Replace with HFR as the displayed column name.
                colnames.insert(0, 'HFR')

        # Update the table to have one column per desired parameter.
        self.stats_table.setColumnCount(len(colnames))
        self.stats_table.setHorizontalHeaderLabels(colnames)
        self.stats_table.setRowCount(4)
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])

        # For each column, compute and display the statistics.
        for col_index, col in enumerate(colnames):
            try:
                if col == 'HFR':
                    # Get the original fwhm_used values and convert them to HFR.
                    col_data = np.array(self.star_catalog['fwhm_used'], dtype=float) / 2.0
                else:
                    col_data = np.array(self.star_catalog[col], dtype=float)
                min_val = np.min(col_data)
                max_val = np.max(col_data)
                med_val = np.median(col_data)
                std_val = np.std(col_data)
            except Exception:
                min_val = max_val = med_val = std_val = 0.0

            for row_index, val in enumerate([min_val, max_val, med_val, std_val]):
                item = QTableWidgetItem(f"{val:.3f}")
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(row_index, col_index, item)


class SupernovaAsteroidHunterTab(QWidget):
    def __init__(self):
        super().__init__()
        # Parameters for the hunter
        self.parameters = {
            "referenceImagePath": "",
            "searchImagePaths": [],
            "threshold": 0.10  # Default threshold value
        }
        # Preprocessed images will be stored here
        self.preprocessed_reference = None
        self.preprocessed_search = []  # List of dicts: {"path": str, "image": np.array}
        # Detected anomaly data for each search image
        self.anomalyData = []
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # Instruction Label
        instructions = QLabel("Select the reference image and search images. Then click Process to hunt for anomalies.")
        layout.addWidget(instructions)

        # --- Reference Image Selection ---
        ref_layout = QHBoxLayout()
        self.ref_line_edit = QLineEdit(self)
        self.ref_line_edit.setPlaceholderText("No reference image selected")
        self.ref_button = QPushButton("Select Reference Image", self)
        self.ref_button.clicked.connect(self.selectReferenceImage)
        ref_layout.addWidget(self.ref_line_edit)
        ref_layout.addWidget(self.ref_button)
        layout.addLayout(ref_layout)

        # --- Search Images Selection ---
        search_layout = QHBoxLayout()
        self.search_list = QListWidget(self)
        self.search_button = QPushButton("Select Search Images", self)
        self.search_button.clicked.connect(self.selectSearchImages)
        search_layout.addWidget(self.search_list)
        search_layout.addWidget(self.search_button)
        layout.addLayout(search_layout)

        # --- Cosmetic Correction Checkbox ---
        self.cosmetic_checkbox = QCheckBox("Apply Cosmetic Correction before Preprocessing", self)
        layout.addWidget(self.cosmetic_checkbox)

        # --- Threshold Slider ---
        thresh_layout = QHBoxLayout()
        self.thresh_label = QLabel("Anomaly Detection Threshold: 0.10", self)
        self.thresh_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.thresh_slider.setMinimum(1)
        self.thresh_slider.setMaximum(50)  # Represents 0.01 to 0.50
        self.thresh_slider.setValue(10)      # 10 => 0.10 threshold
        self.thresh_slider.valueChanged.connect(self.updateThreshold)
        thresh_layout.addWidget(self.thresh_label)
        thresh_layout.addWidget(self.thresh_slider)
        layout.addLayout(thresh_layout)

        # --- Process Button ---
        self.process_button = QPushButton("Process (Cosmetic Correction, Preprocess, and Search)", self)
        self.process_button.clicked.connect(self.process)
        layout.addWidget(self.process_button)

        # --- Progress Labels ---
        self.preprocess_progress_label = QLabel("Preprocessing progress: 0 / 0", self)
        self.search_progress_label = QLabel("Processing progress: 0 / 0", self)
        layout.addWidget(self.preprocess_progress_label)
        layout.addWidget(self.search_progress_label)

        # -- Add a new status label --
        self.status_label = QLabel("Status: Idle", self)
        layout.addWidget(self.status_label)

        # --- New Instance Button ---
        self.new_instance_button = QPushButton("New Instance", self)
        self.new_instance_button.clicked.connect(self.newInstance)
        layout.addWidget(self.new_instance_button)

        self.setLayout(layout)
        self.setWindowTitle("Supernova/Asteroid Hunter")

    def updateThreshold(self, value):
        threshold = value / 100.0  # e.g. slider value 10 becomes 0.10
        self.parameters["threshold"] = threshold
        self.thresh_label.setText(f"Anomaly Detection Threshold: {threshold:.2f}")

    def selectReferenceImage(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "",
                                                   "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_path:
            self.parameters["referenceImagePath"] = file_path
            self.ref_line_edit.setText(os.path.basename(file_path))

    def selectSearchImages(self):
        file_paths, _ = QFileDialog.getOpenFileNames(self, "Select Search Images", "",
                                                     "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_paths:
            self.parameters["searchImagePaths"] = file_paths
            self.search_list.clear()
            for path in file_paths:
                self.search_list.addItem(os.path.basename(path))

    def process(self):
        self.status_label.setText("Process started...")
        QApplication.processEvents()

        # If cosmetic correction is enabled, run it first
        if self.cosmetic_checkbox.isChecked():
            self.status_label.setText("Running Cosmetic Correction...")
            QApplication.processEvents()
            self.runCosmeticCorrectionIfNeeded()

        self.status_label.setText("Preprocessing images...")
        QApplication.processEvents()
        self.preprocessImages()

        self.status_label.setText("Analyzing anomalies...")
        QApplication.processEvents()
        self.runSearch()

        self.status_label.setText("Process complete.")
        QApplication.processEvents()


    def runCosmeticCorrectionIfNeeded(self):
        """
        Runs cosmetic correction on each search image...
        """
        # Dictionary to hold corrected images
        self.cosmetic_images = {}

        for idx, image_path in enumerate(self.parameters["searchImagePaths"]):
            try:
                # Update status label to show which image is being handled
                self.status_label.setText(f"Cosmetic Correction: {idx+1}/{len(self.parameters['searchImagePaths'])} => {os.path.basename(image_path)}")
                QApplication.processEvents()

                img, header, bit_depth, is_mono = load_image(image_path)
                if img is None:
                    print(f"Unable to load image: {image_path}")
                    continue

                # Numba correction
                corrected = bulk_cosmetic_correction_numba(
                    img,
                    hot_sigma=5.0,
                    cold_sigma=5.0,
                    window_size=3
                )
                self.cosmetic_images[image_path] = corrected
                print(f"Cosmetic correction (Numba) applied to: {image_path}")

            except Exception as e:
                print(f"Error in cosmetic correction for {image_path}: {e}")


    def preprocessImages(self):
        # Update status label for reference image
        self.status_label.setText("Preprocessing reference image...")
        QApplication.processEvents()

        ref_path = self.parameters["referenceImagePath"]
        if not ref_path:
            QMessageBox.warning(self, "Error", "No reference image selected.")
            return

        try:
            ref_img, header, bit_depth, is_mono = load_image(ref_path)

            # Create a debug prefix from the reference path (e.g. "C:/data/ref_debug")
            debug_prefix_ref = os.path.splitext(ref_path)[0] + "_debug_ref"

            self.status_label.setText("Applying background neutralization & ABE on reference...")
            QApplication.processEvents()

            # Pass debug_prefix_ref to preprocessImage
            ref_processed = self.preprocessImage(ref_img, debug_prefix=debug_prefix_ref)
            self.preprocessed_reference = ref_processed
            self.preprocess_progress_label.setText("Preprocessing reference image... Done.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to preprocess reference image: {e}")
            return

        self.preprocessed_search = []
        search_paths = self.parameters["searchImagePaths"]
        for i, path in enumerate(search_paths):
            try:
                self.status_label.setText(f"Preprocessing search image {i+1}/{len(search_paths)} => {os.path.basename(path)}")
                QApplication.processEvents()

                # Create a debug prefix from the search path
                debug_prefix_search = os.path.splitext(path)[0] + f"_debug_search_{i+1}"

                if hasattr(self, 'cosmetic_images') and path in self.cosmetic_images:
                    img = self.cosmetic_images[path]
                else:
                    img, header, bit_depth, is_mono = load_image(path)

                # Pass debug_prefix_search to preprocessImage
                processed = self.preprocessImage(img, debug_prefix=debug_prefix_search)
                self.preprocessed_search.append({"path": path, "image": processed})

                self.preprocess_progress_label.setText(f"Preprocessing image {i+1} of {len(search_paths)}... Done.")
                QApplication.processEvents()

            except Exception as e:
                print(f"Failed to preprocess {path}: {e}")

        self.status_label.setText("All search images preprocessed.")
        QApplication.processEvents()



    def preprocessImage(self, img, debug_prefix=None):
        """
        Runs the full preprocessing chain on a single image:
        1. Background Neutralization
        2. Automatic Background Extraction (ABE)
        3. Pixel-math stretching

        Optionally saves debug images if debug_prefix is provided.
        """


        # --- Step 1: Background Neutralization ---
        if img.ndim == 3 and img.shape[2] == 3:
            h, w, _ = img.shape
            sample_x = int(w * 0.45)
            sample_y = int(h * 0.45)
            sample_w = max(1, int(w * 0.1))
            sample_h = max(1, int(h * 0.1))
            sample_region = img[sample_y:sample_y+sample_h, sample_x:sample_x+sample_w, :]
            medians = np.median(sample_region, axis=(0, 1))
            average_median = np.mean(medians)
            neutralized = img.copy()
            for c in range(3):
                diff = medians[c] - average_median
                numerator = neutralized[:, :, c] - diff
                denominator = 1.0 - diff
                if abs(denominator) < 1e-8:
                    denominator = 1e-8
                neutralized[:, :, c] = np.clip(numerator / denominator, 0, 1)
        else:
            neutralized = img


        # --- Step 2: Automatic Background Extraction (ABE) ---
        pgr = PolyGradientRemoval(
            neutralized,
            poly_degree=2,          # or pass in a user choice
            downsample_scale=4,
            num_sample_points=100
        )
        abe = pgr.process()  # returns final polynomial-corrected image in original domain


        # --- Step 3: Pixel Math Stretch ---
        stretched = self.pixel_math_stretch(abe)

        return stretched



    def pixel_math_stretch(self, image):
        """
        Replaces the old pixel math stretch logic by using the existing
        stretch_mono_image or stretch_color_image methods. 
        """
        # Choose a target median (the default you’ve used elsewhere is often 0.25)
        target_median = 0.25

        # Check if the image is mono or color
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Treat it as mono
            stretched = stretch_mono_image(
                image.squeeze(),  # squeeze in case it's (H,W,1)
                target_median=target_median,
                normalize=False,  # Adjust if you want normalization
                apply_curves=False,
                curves_boost=0.0
            )
            # If it was (H,W,1), replicate to 3 channels (optional)
            # or just keep it mono if you prefer
            # For now, replicate to 3 channels:
            stretched = np.stack([stretched]*3, axis=-1)
        else:
            # Full-color image
            stretched = stretch_color_image(
                image,
                target_median=target_median,
                linked=False,      # or False if you want per-channel stretches
                normalize=False,  
                apply_curves=False,
                curves_boost=0.0
            )

        return np.clip(stretched, 0, 1)

    def runSearch(self):
        if self.preprocessed_reference is None:
            QMessageBox.warning(self, "Error", "Reference image not preprocessed.")
            return
        if not self.preprocessed_search:
            QMessageBox.warning(self, "Error", "No search images preprocessed.")
            return

        ref_gray = self.to_grayscale(self.preprocessed_reference)

        self.anomalyData = []
        total = len(self.preprocessed_search)
        for i, search_dict in enumerate(self.preprocessed_search):
            search_img = search_dict["image"]
            search_gray = self.to_grayscale(search_img)

            diff_img = self.subtractImagesOnce(search_gray, ref_gray)
            anomalies = self.detectAnomaliesConnected(diff_img, threshold=self.parameters["threshold"])

            # Just store the anomalies
            self.anomalyData.append({
                "imageName": os.path.basename(search_dict["path"]),
                "anomalyCount": len(anomalies),
                "anomalies": anomalies
            })

            self.search_progress_label.setText(f"Processing image {i+1} of {total}...")
            QApplication.processEvents()

        self.search_progress_label.setText("Search for anomalies complete.")

        # Optionally still show the text-based summary:
        self.showDetailedResultsDialog(self.anomalyData)

        # Now build & show the anomaly tree for user double-click
        self.showAnomalyListDialog()

    def showAnomalyListDialog(self):
        """
        Build a QDialog with a QTreeWidget listing each image and its anomaly count.
        Double-clicking an item will open a non-modal preview.
        """
        if not self.anomalyData:
            QMessageBox.information(self, "Info", "No anomalies or no images processed.")
            return

        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Results")

        layout = QVBoxLayout(dialog)

        self.anomaly_tree = QTreeWidget(dialog)
        self.anomaly_tree.setColumnCount(2)
        self.anomaly_tree.setHeaderLabels(["Image", "Anomaly Count"])
        layout.addWidget(self.anomaly_tree)

        # Populate the tree
        for i, data in enumerate(self.anomalyData):
            item = QTreeWidgetItem([
                data["imageName"],
                str(data["anomalyCount"])
            ])
            # Store an index or reference so we know which image to open
            item.setData(0, Qt.ItemDataRole.UserRole, i)
            self.anomaly_tree.addTopLevelItem(item)

        # Connect double-click
        self.anomaly_tree.itemDoubleClicked.connect(self.onAnomalyItemDoubleClicked)

        dialog.setLayout(layout)
        dialog.resize(300, 200)
        dialog.show()  # non-modal, so the user can keep using the main window

    def onAnomalyItemDoubleClicked(self, item, column):
        """
        Called when the user double-clicks a row in the anomaly tree.
        We'll open a MosaicPreviewWindow showing bounding boxes for that image.
        """
        # Retrieve the index we stored
        idx = item.data(0, Qt.ItemDataRole.UserRole)
        if idx is None:
            return

        # anomalies from anomalyData
        anomalies = self.anomalyData[idx]["anomalies"]
        image_name = self.anomalyData[idx]["imageName"]

        # The preprocessed image from self.preprocessed_search
        # We assume the i-th preprocessed image matches the i-th anomalyData.
        # Make sure your code lines up these two lists the same order.
        # e.g., i=0 => self.preprocessed_search[0], self.anomalyData[0]
        search_img = self.preprocessed_search[idx]["image"]  # already in [0..1], shape (H,W,3)

        if anomalies:
            # Create an annotated image
            annotated_8bit = self.draw_bounding_boxes_on_stretched(search_img, anomalies)

            # Pass to MosaicPreviewWindow
            preview = MosaicPreviewWindow(
                annotated_8bit, 
                title=f"Anomalies in {image_name}", 
                parent=self
            )
            # Optionally disable auto-stretch so the boxes remain bright
            preview.stretch_toggle.setChecked(False)
            preview.resize(1200, 800)
            preview.show()  # non-modal
        else:
            QMessageBox.information(self, "No Anomalies", f"No anomalies found for {image_name}.")


    def draw_bounding_boxes_on_stretched(self,
        stretched_image: np.ndarray, 
        anomalies: list
    ) -> np.ndarray:
        """
        1) Convert 'stretched_image' [0..1] -> [0..255] 8-bit color
        2) Draw red rectangles for each anomaly in 'anomalies'.
        Each anomaly is assumed to have keys: minX, minY, maxX, maxY
        3) Return the 8-bit color image (H,W,3).
        """
        import cv2
        import numpy as np

        # Ensure 3 channels
        if stretched_image.ndim == 2:
            stretched_3ch = np.stack([stretched_image]*3, axis=-1)
        elif stretched_image.ndim == 3 and stretched_image.shape[2] == 1:
            stretched_3ch = np.concatenate([stretched_image]*3, axis=2)
        else:
            stretched_3ch = stretched_image

        # Convert float [0..1] => uint8 [0..255]
        img_bgr = (stretched_3ch * 255).clip(0,255).astype(np.uint8)

        # Define the margin
        margin = 15

        # Draw red boxes in BGR color = (0, 0, 255)
        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Expand the bounding box by a 10-pixel margin
            x1_exp = x1 - margin
            y1_exp = y1 - margin
            x2_exp = x2 + margin
            y2_exp = y2 + margin
            cv2.rectangle(
                img_bgr, (x1_exp, y1_exp), (x2_exp, y2_exp),
                color=(255, 0, 0),
                thickness=5
            )

        return img_bgr


    def subtractImagesOnce(self, search_img, ref_img, debug_prefix=None):
        """
        Compute the absolute difference of two images (both already grayscale).
        Both images must have the same dimensions.

        Optionally, if 'debug_prefix' is provided, save the difference
        as a debug image. For example: "mydebugprefix_diff.tif".
        """
        if search_img.shape != ref_img.shape:
            raise ValueError("Image dimensions do not match for difference.")

        # Both search_img and ref_img are assumed in [0..1]
        # so the absolute difference will also be in [0..1].
        result = search_img - ref_img
        print("Computed difference between search and reference images.")

        # If debug_prefix is specified, save the difference image
        # For example:
        #self.debug_save_image(
        #    result,
        #    prefix=debug_prefix,
        #    step_name="diff",
        #    ext=".tif"
        #)
        np.clip(result, 0, 1)  # Ensure result is in [0..1]
        return result

    def debug_save_image(self, image, prefix="debug", step_name="step", ext=".tif"):
        """
        Saves 'image' to disk for debugging. 
        - 'prefix' can be a directory path or prefix for your debug images.
        - 'step_name' is appended to the filename to indicate which step.
        - 'ext' could be '.tif', '.png', or another format you support.

        This example uses your 'save_image' function from earlier or can
        directly use tiff.imwrite or similar.
        """
        import os
        # Ensure the image is float32 in [0..1] before saving
        image = image.astype(np.float32, copy=False)

        # Build debug filename
        filename = f"{prefix}_{step_name}{ext}"

        # E.g., if you have a global 'save_image' function:
        save_image(
            image, 
            filename,
            original_format="tif",  # or "png", "fits", etc.
            bit_depth="16-bit"
        )
        print(f"[DEBUG] Saved {step_name} => {filename}")

    def to_grayscale(self, image):
        """
        Converts an image to grayscale by averaging channels if needed.
        If the image is already 2D, return it as is.
        """
        if image.ndim == 2:
            # Already grayscale
            return image
        elif image.ndim == 3 and image.shape[2] == 3:
            # Average the three channels
            return np.mean(image, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:
            # Squeeze out that single channel
            return image[:, :, 0]
        else:
            raise ValueError(f"Unsupported image shape for grayscale: {image.shape}")

    def detectAnomaliesConnected(self, diff_img: np.ndarray, threshold: float = 0.1):
        """
        1) Build mask = diff_img > threshold.
        2) Optionally skip 5% border by zeroing out that region in the mask.
        3) connectedComponentsWithStats => bounding boxes.
        4) Filter by min_area, etc.
        5) Return a list of anomalies, each with minX, minY, maxX, maxY, area.
        """
        h, w = diff_img.shape

        # 1) Create the mask
        mask = (diff_img > threshold).astype(np.uint8)

        # 2) Skip 5% border (optional)
        border_x = int(0.05 * w)
        border_y = int(0.05 * h)
        mask[:border_y, :] = 0
        mask[h - border_y:, :] = 0
        mask[:, :border_x] = 0
        mask[:, w - border_x:] = 0

        # 3) connectedComponentsWithStats => label each region
        # connectivity=8 => 8-way adjacency
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)

        # stats[i] = [x, y, width, height, area], for i in [1..num_labels-1]
        # label_id=0 => background

        anomalies = []
        for label_id in range(1, num_labels):
            x, y, width_, height_, area_ = stats[label_id]

            # bounding box corners
            minX = x
            minY = y
            maxX = x + width_ - 1
            maxY = y + height_ - 1

            # 4) Filter out tiny or huge areas if you want:
            # e.g., skip anything <4x4 => area<16
            if area_ < 25:
                continue
            # e.g., skip bounding boxes bigger than 40 in either dimension if you want
            if width_ > 200 or height_ > 200:
                continue

            anomalies.append({
                "minX": minX,
                "minY": minY,
                "maxX": maxX,
                "maxY": maxY,
                "area": area_
            })

        return anomalies


    def showDetailedResultsDialog(self, anomalyData):
        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Detection Results")
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit(dialog)
        text_edit.setReadOnly(True)
        result_text = "Detailed Anomaly Results:\n\n"

        for data in anomalyData:
            result_text += f"Image: {data['imageName']}\nAnomalies: {data['anomalyCount']}\n"
            for group in data["anomalies"]:
                # Now refer to 'minX', 'minY', 'maxX', 'maxY'
                result_text += (
                    f"  Group Bounding Box: "
                    f"Top-Left ({group['minX']}, {group['minY']}), "
                    f"Bottom-Right ({group['maxX']}, {group['maxY']})\n"
                )
            result_text += "\n"

        text_edit.setText(result_text)
        layout.addWidget(text_edit)
        dialog.setLayout(layout)
        dialog.show()

    def showAnomaliesOnImage(self, image: np.ndarray, anomalies: list, window_title="Anomalies"):
        """
        Displays 'image' in a QDialog with red bounding boxes for each anomaly.
        'image' is assumed to be float32 in [0..1], shape (H,W) or (H,W,3).
        'anomalies' is a list of dicts, each with keys: minX, minY, maxX, maxY, etc.
        """
        import cv2
        import numpy as np

        # 1) Convert to 3-channel if needed
        if image.ndim == 2:
            # grayscale => replicate to 3-ch so we can draw colored rectangles
            image_3ch = np.stack([image, image, image], axis=-1)
        elif image.ndim == 3 and image.shape[2] == 1:
            # single-channel in last dimension
            image_3ch = np.concatenate([image, image, image], axis=2)
        else:
            image_3ch = image

        # 2) Convert float [0..1] => uint8 [0..255], and reorder to BGR if needed
        # OpenCV expects BGR order for color. If your array is already RGB, we can just treat it as BGR if color correctness isn't critical. 
        # For a quick approach, let's do it directly:
        image_bgr = (image_3ch * 255).astype(np.uint8)

        # 3) Draw bounding boxes with a margin
        margin = 10  # You can adjust this as desired
        height, width = image_bgr.shape[:2]

        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Inflate the bounding box
            x1 = max(0, x1 - margin)
            y1 = max(0, y1 - margin)
            x2 = min(width - 1,  x2 + margin)
            y2 = min(height - 1, y2 + margin)

            # Draw the rectangle (BGR color=(255,0,0) => Blue if you want red use (0,0,255))
            cv2.rectangle(
                image_bgr, 
                (x1, y1), (x2, y2), 
                color=(255, 0, 0),  # Blue in BGR
                thickness=5
            )


        # 4) Convert the annotated BGR image back to QImage => QPixmap => show in QDialog
        # We can do something like:
        height, width = image_bgr.shape[:2]

        # For color images, QImage.Format_RGB888 expects an RGB order
        # We can convert BGR->RGB by:
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        qimg = QImage(
            image_rgb.data, 
            width, 
            height, 
            3 * width, 
            QImage.Format.Format_RGB888
        )
        pixmap = QPixmap.fromImage(qimg)

        # 5) Show in a simple QDialog with a QLabel or QGraphicsView
        dialog = QDialog(self)
        dialog.setWindowTitle(window_title)
        layout = QVBoxLayout(dialog)

        label = QLabel(dialog)
        label.setPixmap(pixmap)
        layout.addWidget(label)

        dialog.setLayout(layout)
        dialog.resize(width, height)
        dialog.show()


    def newInstance(self):
        # Reset parameters and UI elements for a new run
        self.parameters = {"referenceImagePath": "", "searchImagePaths": [], "threshold": 0.10}
        self.ref_line_edit.clear()
        self.search_list.clear()
        self.cosmetic_checkbox.setChecked(False)
        self.thresh_slider.setValue(10)
        self.preprocess_progress_label.setText("Preprocessing progress: 0 / 0")
        self.search_progress_label.setText("Processing progress: 0 / 0")
        self.preprocessed_reference = None
        self.preprocessed_search = []
        self.anomalyData = []
        QMessageBox.information(self, "New Instance", "Reset for a new instance.")

class HDRWorker(QObject):
    """
    Worker class to perform WaveScale HDRation in a separate thread.
    Emits signals to update progress.
    """
    progress_update = pyqtSignal(str, int)  # Signal: (current_step, percent_complete)
    finished = pyqtSignal(np.ndarray, np.ndarray)  # Signal: (transformed_rgb, mask)

    def __init__(self, rgb_image, n_scales, compression_factor, mask_gamma, b3_spline_kernel):
        super().__init__()
        self.rgb_image = rgb_image
        self.n_scales = n_scales
        self.compression_factor = compression_factor
        self.mask_gamma = mask_gamma
        self.b3_spline_kernel = b3_spline_kernel

    def run(self):
        try:
            # Step 1: Convert to Lab
            self.progress_update.emit("Converting to Lab color space...", 10)
            lab = self.rgb_to_lab(self.rgb_image)
            L_original = lab[..., 0].copy()  # Store original L for median calculation
            L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

            # Step 2: Decompose using à trous wavelet
            self.progress_update.emit("Performing wavelet decomposition...", 20)
            scales = self.atrous_wavelet_decompose(L, self.n_scales)

            # Step 3: Create Luminance Mask
            self.progress_update.emit("Creating luminance mask...", 30)
            mask = self.create_luminance_mask(L, gamma=self.mask_gamma)

            # Step 4: Apply mask to wavelet planes
            self.progress_update.emit("Applying mask to wavelet planes...", 40)
            wavelet_planes = scales[:-1]
            residual = scales[-1]

            # Step 5: Enhance wavelet planes based on mask and compression factor with decaying influence
            self.progress_update.emit("Enhancing wavelet planes...", 50)
            decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
            for i in range(len(wavelet_planes)):
                # Calculate decay factor for the current scale
                decay_factor = decay_rate ** i  # Higher scales have smaller decay_factor
                # Compute scaling factor with decay
                scaling_factor = (1.0 + (self.compression_factor - 1.0) * mask * decay_factor) * 2
                # Apply scaling to the wavelet plane
                wavelet_planes[i] *= scaling_factor
                # Emit intermediate progress
                percent = 50 + int(((i + 1) / len(wavelet_planes)) * 10)  # Distribute 10% across scales
                self.progress_update.emit(f"Enhancing wavelet scale {i+1}...", percent)

            # Step 6: Reconstruct L channel
            self.progress_update.emit("Reconstructing L channel...", 60)
            L_reconstructed = self.atrous_wavelet_reconstruct(wavelet_planes + [residual])

            # Step 7: Apply midtones transfer to align median luminance
            self.progress_update.emit("Applying midtones transfer...", 70)
            median_original = np.median(L_original)
            median_reconstructed = np.median(L_reconstructed)

            if median_reconstructed == 0:
                scaling_midtones = 1.0
            else:
                scaling_midtones = median_original / median_reconstructed

            L_reconstructed *= scaling_midtones
            L_reconstructed = np.clip(L_reconstructed, 0, 100)

            # Update the Lab image with the reconstructed L channel
            lab[..., 0] = L_reconstructed

            # Step 8: Convert back to RGB
            self.progress_update.emit("Converting back to RGB color space...", 80)
            transformed_rgb = self.lab_to_rgb(lab)

            # Step 9: Apply a non-linear curve to the HDR-enhanced image to dim bright areas
            self.progress_update.emit("Applying dimming curve...", 90)
            transformed_rgb = self.apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0 + self.n_scales * 0.2)

            # Step 10: Finish
            self.progress_update.emit("Finalizing...", 100)
            self.finished.emit(transformed_rgb, mask)

        except Exception as e:
            print(f"Error during HDR transformation: {e}")
            self.finished.emit(None, None)

    # Define necessary methods copied from the main dialog
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    def create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100)^gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)


class WaveScaleHDRDialog(QDialog):
    """
    A self-contained WaveScale HDR dialog that:
      - Displays a preview of the image in a QGraphicsView.
      - Uses à trous (starlet) wavelet decomposition on the L channel in Lab space.
      - Lets you adjust # of scales, coarse compression, and mask gamma, then preview or apply.
      - Applies a simple L-based mask (absolute luminance scaled to [0..1]^gamma) so bright areas get full HDR,
        and dark areas get minimal changes.
      - Displays the luminance mask in a separate window for debugging purposes.
    """

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("WaveScale HDR")
        self.setMinimumSize(800, 600)  # Increased width to better accommodate preview and mask display

        self.image_manager = image_manager

        # Detect if the image is grayscale or RGB
        if self.image_manager.image.ndim == 2:
            self.is_grayscale = True
            # Convert to 3-channel by stacking
            self.original_image_rgb = np.stack([self.image_manager.image] * 3, axis=-1)
        elif self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 3:
            self.is_grayscale = False
            self.original_image_rgb = self.image_manager.image.copy()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format.")
            self.reject()
            return  # Exit initialization if image format is unsupported

        # Make local copies for preview and original
        self.original_image = np.clip(self.original_image_rgb.astype(np.float32), 0, 1)
        self.preview_image = self.original_image.copy()

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the preview area (QGraphicsView in a scrollable region)
        self._create_preview_area()
        self._create_zoom_area()

        # 2) Create the HDR controls
        self._create_controls()

        # 3) Lay out preview & controls with progress display
        content_layout = QVBoxLayout()
        content_layout.addWidget(self.scroll_area)
        content_layout.addWidget(self.zoom_group_box)

        # Create the Progress Display Area
        self._create_progress_display()

        # Create a Horizontal Layout to hold controls and progress side by side
        hbox_layout = QHBoxLayout()
        hbox_layout.addWidget(self.controls_group, stretch=3)        # Allocate more space to controls
        hbox_layout.addWidget(self.progress_group_box, stretch=1)   # Allocate less space to progress

        content_layout.addLayout(hbox_layout)  # Add the HBoxLayout to the content_layout

        self.main_layout.addLayout(content_layout)

        # 4) Bottom buttons (Apply / Cancel)
        self._create_bottom_buttons()

        # 5) Initialize and show the mask display window
        self._create_mask_window()

        # B3-spline kernel for à trous wavelet
        self.b3_spline_kernel = np.array([1, 4, 6, 4, 1], dtype=np.float32) / 16.0

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Convert original image to Lab and compute initial mask
        self.lab_original = self.rgb_to_lab(self.original_image)
        self.L_original = self.lab_original[..., 0].copy()  # Store original L for mask computation
        self.mask = self._create_luminance_mask(self.L_original, gamma=self.mask_gamma_slider.value() / 100.0)



        # Show the initial preview
        self._update_preview_pixmap(self.preview_image)

        # Show the initial mask in MaskDisplayWindow
        self.mask_window.update_mask(self.mask)        

        self.apply_button.setEnabled(False)
        self.preview_button.clicked.connect(self._enable_apply_button)   
        self.mask_gamma_slider.valueChanged.connect(self._on_mask_gamma_changed)        

    def _on_mask_gamma_changed(self, value):
        """
        Recompute the luminance mask based on the new gamma value and update the mask display.
        
        Args:
            value (int): The new value from the mask_gamma_slider.
        """
        try:
            gamma = value / 100.0  # Convert slider value to gamma
            self.mask = self._create_luminance_mask(self.L_original, gamma=gamma)
            self.mask_window.update_mask(self.mask)
            print(f"Mask gamma changed to {gamma}, mask updated.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")

    # -------------------------------------------------------------------------
    # 1) Zoom AREA
    # -------------------------------------------------------------------------
    def _create_zoom_area(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_group_box = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_group_box.setLayout(zoom_layout)

    def _fit_to_preview(self):
        """Fit the entire image within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No image to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0

    # -------------------------------------------------------------------------
    # 1) PREVIEW AREA
    # -------------------------------------------------------------------------
    def _create_preview_area(self):
        """Create a QGraphicsView & QGraphicsScene for the preview, inside a scroll area."""
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)

        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Optionally, enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        self.scroll_area.setWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) CONTROLS
    # -------------------------------------------------------------------------
    def _create_controls(self):
        """Create the HDR sliders (# scales, compression, mask gamma) and zoom buttons."""
        self.controls_group = QGroupBox("HDR Controls")
        controls_layout = QFormLayout()

        # Number of scales
        self.scales_slider = QSlider(Qt.Orientation.Horizontal)
        self.scales_slider.setRange(2, 10)
        self.scales_slider.setValue(5)
        self.scales_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.scales_slider.setTickInterval(1)
        controls_layout.addRow("Number of Scales:", self.scales_slider)

        # Coarse compression
        self.compression_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => factor = 0.1..3.0
        self.compression_slider.setRange(10, 500)
        self.compression_slider.setValue(150)
        self.compression_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.compression_slider.setTickInterval(10)
        controls_layout.addRow("Coarse Compression:", self.compression_slider)

        # Mask gamma
        self.mask_gamma_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => gamma = 0.1..3.0
        self.mask_gamma_slider.setRange(10, 1000)
        self.mask_gamma_slider.setValue(500)
        self.mask_gamma_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.mask_gamma_slider.setTickInterval(10)
        controls_layout.addRow("Mask Gamma:", self.mask_gamma_slider)



        # Preview Button
        self.preview_button = QPushButton("Preview")
        self.preview_button.clicked.connect(self._on_preview_clicked)
        controls_layout.addRow(self.preview_button)

        self.controls_group.setLayout(controls_layout)

    # -------------------------------------------------------------------------
    # 3) BOTTOM BUTTONS
    # -------------------------------------------------------------------------
    def _create_bottom_buttons(self):
        bottom_layout = QHBoxLayout()

        self.apply_button = QPushButton("Apply")
        self.apply_button.clicked.connect(self._on_apply_clicked)
        bottom_layout.addWidget(self.apply_button)

        self.reset_button = QPushButton("Reset")
        self.reset_button.clicked.connect(self._on_reset_clicked)
        bottom_layout.addWidget(self.reset_button)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        bottom_layout.addWidget(self.cancel_button)

        self.main_layout.addLayout(bottom_layout)

    # -------------------------------------------------------------------------
    # 4) MASK DISPLAY WINDOW
    # -------------------------------------------------------------------------
    def _create_mask_window(self):
        """Initialize and show the separate mask display window."""
        self.mask_window = MaskDisplayWindow(self)
        self.mask_window.show()

    # -------------------------------------------------------------------------
    # 5) Progress Display Area
    # -------------------------------------------------------------------------
    def _create_progress_display(self):
        """Create a progress display area on the right side of the content_layout."""
        self.progress_group_box = QGroupBox("Processing Progress")
        progress_layout = QVBoxLayout()

        # Current Step Label
        self.current_step_label = QLabel("Idle")
        self.current_step_label.setAlignment(Qt.AlignmentFlag.AlignTop)
        progress_layout.addWidget(self.current_step_label)

        # Progress Bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        progress_layout.addWidget(self.progress_bar)

        self.progress_group_box.setLayout(progress_layout)

    def _on_reset_clicked(self):
        """Reset the image and sliders to their default states."""
        try:
            # Reset sliders to default values
            self.scales_slider.setValue(5)
            self.compression_slider.setValue(150)
            self.mask_gamma_slider.setValue(500)

            # Reset the preview image to the original image
            self.preview_image = self.original_image.copy()
            self._update_preview_pixmap(self.preview_image)

            # Reset progress display
            self.current_step_label.setText("Idle")
            self.progress_bar.setValue(0)

            # Disable the Apply button since no changes are pending
            self.apply_button.setEnabled(False)

            # Optionally, reset the zoom to default
            self.zoom_factor = 1.0
            self.graphics_view.resetTransform()

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to reset: {e}")

    # -------------------------------------------------------------------------
    # PREVIEW / APPLY
    # -------------------------------------------------------------------------
    def _on_preview_clicked(self):
        """Generate a preview image with current settings and display it."""
        try:
            # Disable buttons to prevent multiple clicks
            self.preview_button.setEnabled(False)
            self.apply_button.setEnabled(False)

            # Reset progress display
            self.current_step_label.setText("Starting HDR Transformation...")
            self.progress_bar.setValue(0)

            # Gather current settings
            n_scales = self.scales_slider.value()
            compression_factor = self.compression_slider.value() / 100.0
            mask_gamma = self.mask_gamma_slider.value() / 100.0

            # Initialize worker and thread
            self.worker = HDRWorker(
                rgb_image=self.original_image,
                n_scales=n_scales,
                compression_factor=compression_factor,
                mask_gamma=mask_gamma,
                b3_spline_kernel=self.b3_spline_kernel
            )
            self.thread = QThread()
            self.worker.moveToThread(self.thread)

            # Connect signals
            self.thread.started.connect(self.worker.run)
            self.worker.progress_update.connect(self._update_progress)
            self.worker.finished.connect(self._on_worker_finished)
            self.worker.finished.connect(self.thread.quit)
            self.worker.finished.connect(self.worker.deleteLater)
            self.thread.finished.connect(self.thread.deleteLater)

            # Start the thread
            self.thread.start()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))
            self.preview_button.setEnabled(True)
            self.apply_button.setEnabled(False)

    def _update_progress(self, step, percent):
        """Update the progress display based on signals from the worker."""
        self.current_step_label.setText(step)
        self.progress_bar.setValue(percent)

    def _on_worker_finished(self, transformed_rgb, mask):
        """Handle the completion of the worker thread."""
        if transformed_rgb is not None:
            if self.is_grayscale:
                # For grayscale, take one channel and keep it single-channel
                mask_expanded = mask[:, :, np.newaxis]  # Shape: (h, w, 1)
                blended_preview = self.original_image[:, :, 0:1] * (1 - mask_expanded) + transformed_rgb[:, :, 0:1] * mask_expanded
                # Stack back to 3 channels for consistent display
                blended_preview = np.repeat(blended_preview, 3, axis=2)
            else:
                # For RGB
                mask_expanded = np.repeat(mask[:, :, np.newaxis], 3, axis=2)  # Shape: (h, w, 3)
                blended_preview = self.original_image * (1 - mask_expanded) + transformed_rgb * mask_expanded

            # Update preview image
            self.preview_image = blended_preview
            self._update_preview_pixmap(blended_preview)

            # Enable Apply button
            self.apply_button.setEnabled(True)

        else:
            QMessageBox.critical(self, "Error", "WaveScale HDR failed.")

        # Re-enable preview button
        self.preview_button.setEnabled(True)

    def _enable_apply_button(self):
        """Enable the Apply button after a preview is generated."""
        self.apply_button.setEnabled(True)

    def _on_apply_clicked(self):
        """Apply the HDR transform to the main image manager and close the dialog."""
        try:
            # Check if a preview has been generated
            if not hasattr(self, 'preview_image'):
                QMessageBox.warning(self, "Warning", "Please generate a preview before applying the transformation.")
                return

            # Use the existing preview_image as the output image
            output_image = self.preview_image.copy()

            # Update the main ImageManager
            self.image_manager.set_image(output_image, {"description": "WaveScale HDR"})
            QMessageBox.information(self, "Success", "WaveScale HDR applied.")
            self.accept()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))

    # -------------------------------------------------------------------------
    # UTILITY: UPDATE PREVIEW PIXMAP
    # -------------------------------------------------------------------------
    def _update_preview_pixmap(self, image):
        """Convert `image` (float32 [0..1]) to QPixmap and display."""
        pixmap = self._convert_image_to_pixmap(image)
        self.pixmap_item.setPixmap(pixmap)
        self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

    def _convert_image_to_pixmap(self, image):
        """Convert float32 [0..1] image to QPixmap (RGB888)."""
        image_uint8 = (np.clip(image, 0, 1) * 255).astype(np.uint8)
        h, w = image_uint8.shape[:2]

        if image_uint8.ndim == 2:
            # Grayscale => expand to 3 channels
            image_uint8 = np.repeat(image_uint8[..., None], 3, axis=2)

        bytes_per_line = 3 * w
        qimage = QImage(
            image_uint8.data, w, h, bytes_per_line, QImage.Format.Format_RGB888
        )
        return QPixmap.fromImage(qimage)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self._zoom_in()
        else:
            self._zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def _apply_zoom(self):
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    # -------------------------------------------------------------------------
    # HDR ALGORITHM
    # -------------------------------------------------------------------------
    def _perform_hdr_transform(self, rgb_image, n_scales, compression_factor, mask_gamma):
        """
        1) Convert to Lab
        2) à trous wavelet decompose L
        3) Create L-based mask: M = (L / 100)^gamma
           - bright => near 1
           - dark => near 0
        4) Apply mask to wavelet planes
        5) Compress (enhance) wavelet planes based on mask and compression factor
        6) Reconstruct L
        7) Apply midtones transfer to align median luminance
        8) Convert back to RGB
        9) Return transformed RGB and mask for blending
        """
        # 1) Convert to Lab using custom rgb_to_lab
        lab = self.rgb_to_lab(rgb_image)
        L_original = lab[..., 0].copy()  # Store original L for median calculation

        L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

        # 2) Decompose
        scales = self._atrous_wavelet_decompose(L, n_scales)

        # 3) L-based mask
        mask = self._create_luminance_mask(L, gamma=mask_gamma)
        # => bright areas ~1.0, dark areas ~0.0

        # Update the mask display window
        #self.mask_window.update_mask(mask)

        # 4) Apply mask to wavelet planes
        wavelet_planes = scales[:-1]
        residual = scales[-1]

        # 5) Enhance wavelet planes based on mask and compression factor
        decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
        for i in range(len(wavelet_planes)):
            # Compute scaling factor: 1 + (compression_factor -1) * mask
            decay_factor = decay_rate ** i
            scaling_factor = (1.0 + (compression_factor - 1.0) * mask* decay_factor)*2
            wavelet_planes[i] *= scaling_factor
            print(f"Scale {i} - Scaling Factor Stats: min={scaling_factor.min()}, max={scaling_factor.max()}, mean={scaling_factor.mean()}")
            print(f"Scale {i} - Wavelet Plane Modified Stats: min={wavelet_planes[i].min()}, max={wavelet_planes[i].max()}, mean={wavelet_planes[i].mean()}")

        # Reconstruct L
        L_reconstructed = self._atrous_wavelet_reconstruct(wavelet_planes + [residual])

        # 7) Apply midtones transfer to align median luminance
        median_original = np.median(L_original)
        median_reconstructed = np.median(L_reconstructed)

        if median_reconstructed == 0:
            scaling_midtones = 1.0
        else:
            scaling_midtones = median_original / median_reconstructed

        L_reconstructed *= scaling_midtones
        L_reconstructed = np.clip(L_reconstructed, 0, 100)

        # Update the Lab image with the reconstructed L channel
        lab[..., 0] = L_reconstructed

        # 8) Convert back to RGB using custom lab_to_rgb
        transformed_rgb = self.lab_to_rgb(lab)

        # 9) Return both transformed RGB and mask for blending
        transformed_rgb = self._apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0+n_scales*0.2)
        return transformed_rgb, mask

    def _apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def _create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100) ^ gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)

    def _atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def _atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    # -------------------------------------------------------------------------
    # COLOR SPACE: CUSTOM LAB CONVERSIONS
    # -------------------------------------------------------------------------
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image
            
class BlemishBlasterWorkerSignals(QObject):
    finished = pyqtSignal(np.ndarray)  # Emitted when processing is done

class BlemishBlasterWorker(QRunnable):
    def __init__(self, image, x, y, radius, feather, opacity, channels_to_process=[0,1,2]):
        super().__init__()
        self.image = image.copy()
        self.x = x
        self.y = y
        self.radius = radius
        self.feather = feather
        self.opacity = opacity
        self.channels_to_process = channels_to_process
        self.signals = BlemishBlasterWorkerSignals()

    @pyqtSlot()
    def run(self):
        # Perform blemish removal
        corrected_image = self.remove_blemish(
            self.image, self.x, self.y, self.radius, self.feather, self.opacity, self.channels_to_process
        )
        # Emit the corrected image
        self.signals.finished.emit(corrected_image)

    def remove_blemish(self, image, x, y, radius, feather, opacity, channels_to_process):
        """
        Perform per-pixel blemish removal by sampling from surrounding circles.
        Handles edge cases where correction circles may extend beyond image boundaries.
        """
        corrected_image = image.copy()
        h, w = image.shape[:2]

        # Define angles for surrounding circles
        angles = [0, 60, 120, 180, 240, 300]
        surrounding_centers = []
        for angle in angles:
            rad = math.radians(angle)
            dx = int(math.cos(rad) * (radius * 1.5))  # 1.5 times the radius away
            dy = int(math.sin(rad) * (radius * 1.5))
            surrounding_centers.append((x + dx, y + dy))

        # Calculate medians for each surrounding circle and the target circle
        target_median = self.calculate_median_circle(image, x, y, radius, channels_to_process)
        surrounding_medians = [
            self.calculate_median_circle(image, cx, cy, radius, channels_to_process)
            for cx, cy in surrounding_centers
        ]

        # Determine the three correction circles closest to the target median
        median_diffs = [abs(median - target_median) for median in surrounding_medians]
        closest_indices = np.argsort(median_diffs)[:3]  # Indices of the three closest circles
        selected_circles = [surrounding_centers[i] for i in closest_indices]

        # Iterate through each channel
        for c in channels_to_process:
            # Iterate through each pixel in the target blemish circle
            for i in range(max(y - radius, 0), min(y + radius + 1, h)):
                for j in range(max(x - radius, 0), min(x + radius + 1, w)):
                    dist = math.sqrt((j - x) ** 2 + (i - y) ** 2)
                    if dist <= radius:
                        # Apply feathering based on distance
                        if feather > 0:
                            weight = max(0, min(1, (radius - dist) / (radius * feather)))
                        else:
                            weight = 1

                        # Collect corresponding pixel values from the selected correction circles
                        sampled_values = []
                        for (cx, cy) in selected_circles:
                            # Find the corresponding pixel position
                            corresponding_j = j + (cx - x)
                            corresponding_i = i + (cy - y)

                            # Ensure the corresponding pixel is within image bounds
                            if 0 <= corresponding_i < h and 0 <= corresponding_j < w:
                                if image.ndim == 2:
                                    sampled_values.append(image[corresponding_i, corresponding_j])
                                elif image.ndim == 3:
                                    if image.shape[2] == 1:
                                        sampled_values.append(image[corresponding_i, corresponding_j, 0])
                                    elif image.shape[2] > c:
                                        sampled_values.append(image[corresponding_i, corresponding_j, c])
                                    else:
                                        continue  # Skip if channel is out of bounds

                        if sampled_values:
                            # Calculate the median of the sampled values
                            median_val = np.median(sampled_values)
                        else:
                            # If no valid sampled pixels, retain the original pixel value
                            if image.ndim == 2:
                                median_val = image[i, j]
                            elif image.ndim == 3 and image.shape[2] ==1:
                                median_val = image[i, j,0]
                            else:
                                median_val = image[i,j,c]

                        # Blend the median value into the target pixel using opacity and feathering
                        if image.ndim ==2:
                            original_val = image[i, j]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j] = blended_val
                        elif image.ndim ==3 and image.shape[2] ==1:
                            original_val = image[i, j,0]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j,0] = blended_val
                        elif image.ndim ==3 and image.shape[2] >c:
                            original_val = image[i, j, c]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j, c] = blended_val

        return corrected_image

    def calculate_median_circle(self, image, cx, cy, radius, channels):
        """
        Calculate the median value of a circle for the specified channels.

        Args:
            image (np.ndarray): The image array.
            cx (int): X-coordinate of the circle center.
            cy (int): Y-coordinate of the circle center.
            radius (int): Radius of the circle.
            channels (list): List of channel indices to process.

        Returns:
            float: The overall median value across specified channels.
        """
        values = []
        for c in channels:
            y_min = max(cy - radius, 0)
            y_max = min(cy + radius + 1, image.shape[0])
            x_min = max(cx - radius, 0)
            x_max = min(cx + radius + 1, image.shape[1])

            if image.ndim == 2:
                # Grayscale image (2D)
                roi = image[y_min:y_max, x_min:x_max]
            elif image.ndim == 3:
                if image.shape[2] ==1:
                    # Grayscale image with single channel
                    roi = image[y_min:y_max, x_min:x_max, 0]
                elif image.shape[2] >= c+1:
                    # RGB image
                    roi = image[y_min:y_max, x_min:x_max, c]
                else:
                    continue  # Skip if channel is out of bounds
            else:
                continue  # Unsupported image dimensions

            yy, xx = np.ogrid[:roi.shape[0], :roi.shape[1]]
            dist_from_center = np.sqrt((xx - (cx - x_min))**2 + (yy - (cy - y_min))**2)
            mask = dist_from_center <= radius
            values.extend(roi[mask].flatten())

        return np.median(values) if values else 0.0   
         
class GraphicsView(QGraphicsView):
    """
    Custom QGraphicsView to handle mouse events for blemish removal.
    Emits signals for mouse movements and clicks.
    """
    mouse_moved = pyqtSignal(QPointF)
    mouse_clicked = pyqtSignal(QPointF)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)  # Enable mouse tracking without button presses

    def mouseMoveEvent(self, event):
        pos = self.mapToScene(event.pos().toPoint())
        self.mouse_moved.emit(pos)
        super().mouseMoveEvent(event)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            pos = self.mapToScene(event.pos().toPoint())
            self.mouse_clicked.emit(pos)
        super().mousePressEvent(event)


class BlemishBlasterDialog(QDialog):
    blemish_removed = pyqtSignal(np.ndarray)  # Signal emitted when a blemish is removed

    def __init__(self, image_manager, parent=None):
        """
        Initializes the BlemishBlaster dialog.

        Args:
            image_manager (ImageManager): The ImageManager instance from the main application.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Blemish Blaster")
        self.setMinimumSize(800, 600)  # Set initial size to 800x600

        self.image_manager = image_manager  # Reference to ImageManager
        self.image = self.image_manager.image.copy()  # Work on a copy for display

        # Triplicate single-channel images to ensure 3 channels
        if self.image.ndim == 2:
            self.image = np.repeat(self.image[:, :, np.newaxis], 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 1:
            self.image = np.repeat(self.image, 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 3:
            pass  # RGB image, no action needed
        else:
            raise ValueError(f"Unsupported image shape: {self.image.shape}")

        self.display_image = self.image.copy()

        # Initialize QScrollArea for image display with scroll bars
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)  # Allow the scroll area to resize its widget

        # Initialize QGraphicsScene and QGraphicsView
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable panning via mouse drag
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)  # Center the image if smaller than viewport

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))

        # Initialize QGraphicsEllipseItem for the correction circle
        self.circle_item = QGraphicsEllipseItem()
        self.circle_item.setPen(QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine))
        self.circle_item.setBrush(QBrush(Qt.BrushStyle.NoBrush))  # Corrected Line
        self.circle_item.setVisible(False)  # Initially hidden
        self.scene.addItem(self.circle_item)

        # Set the graphics_view as the widget inside the scroll area
        self.scroll_area.setWidget(self.graphics_view)

        # Main layout
        self.layout = QVBoxLayout()
        self.setLayout(self.layout)
        self.layout.addWidget(self.scroll_area)

        # Create a horizontal layout to hold controls and visualization side by side
        controls_visualization_layout = QHBoxLayout()

        # Sliders and Controls
        controls_group = self.setup_controls()

        # Visualization
        visualization_group = self.setup_visualization()

        # Add controls and visualization to the horizontal layout
        controls_visualization_layout.addWidget(controls_group)
        controls_visualization_layout.addWidget(visualization_group)

        # Add the horizontal layout to the main vertical layout
        self.layout.addLayout(controls_visualization_layout)

        # Undo, Redo, and Apply Changes Buttons
        self.setup_undo_redo_apply()

        # Thread Pool for handling image processing
        self.threadpool = QThreadPool()

        # Current cursor position
        self.current_x = None
        self.current_y = None

        # Install event filter to capture mouse events
        self.graphics_view.installEventFilter(self)

        self.graphics_view.setMouseTracking(True)
        self.graphics_view.mousePressEvent = self.view_mouse_press_event
        self.graphics_view.mouseMoveEvent = self.view_mouse_move_event

        # Shortcut actions for Undo and Redo
        self.setup_shortcuts()
        self.cursor_over_scrollbar = False     

        self.undo_stack = []
        self.redo_stack = []       
        self.is_stretched = False    

        # Initialize Zoom parameters
        self.zoom_factor = 1.0  # Current zoom level
        self.zoom_step = 1.25   # Zoom increment factor
        self.zoom_min = 0.02     # Minimum zoom (10%)
        self.zoom_max = 2     # Maximum zoom (500%)

    def setup_controls(self):
        """Set up sliders for Correction Radius, Feathering, and Opacity."""
        controls_group = QGroupBox("Controls")
        form_layout = QFormLayout()        

        # Zoom Buttons Layout
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Optionally, add a label to display current zoom level
        self.zoom_label = QLabel("100%")
        zoom_layout.addWidget(self.zoom_label)

        form_layout.addRow("Zoom:", zoom_layout)

 

        # Correction Radius Slider
        self.radius_slider = QSlider(Qt.Orientation.Horizontal)
        self.radius_slider.setMinimum(1)
        self.radius_slider.setMaximum(300)
        self.radius_slider.setValue(10)
        self.radius_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.radius_slider.setTickInterval(10)
        self.radius_slider.valueChanged.connect(self.update_visualization)

        form_layout.addRow("Correction Radius:", self.radius_slider)

        # Feathering Slider
        self.feather_slider = QSlider(Qt.Orientation.Horizontal)
        self.feather_slider.setMinimum(0)
        self.feather_slider.setMaximum(100)
        self.feather_slider.setValue(50)
        self.feather_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.feather_slider.setTickInterval(10)
        self.feather_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Feathering:", self.feather_slider)

        # Opacity Slider
        self.opacity_slider = QSlider(Qt.Orientation.Horizontal)
        self.opacity_slider.setMinimum(0)
        self.opacity_slider.setMaximum(100)
        self.opacity_slider.setValue(100)
        self.opacity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.opacity_slider.setTickInterval(10)
        self.opacity_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Opacity:", self.opacity_slider)

        # Autostretch Button
        self.autostretch_button = QPushButton("Autostretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow("Autostretch:", self.autostretch_button)

        controls_group.setLayout(form_layout)
        return controls_group

    def setup_visualization(self):
        """Set up the feathering and opacity visualization."""
        visualization_group = QGroupBox("Feathering & Opacity Visualization")
        visualization_layout = QHBoxLayout()

        self.visualization_label = QLabel()
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)
        visualization_layout.addWidget(self.visualization_label)

        visualization_group.setLayout(visualization_layout)
        return visualization_group

    def setup_undo_redo_apply(self):
        """Set up Undo, Redo, and Apply Changes buttons."""
        history_group = QGroupBox("History")
        history_layout = QHBoxLayout()

        # Apply Changes Button
        self.apply_button = QPushButton("Apply Changes")
        self.apply_button.clicked.connect(self.apply_changes)
        history_layout.addWidget(self.apply_button)

        # Undo Button
        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.perform_undo)
        history_layout.addWidget(self.undo_button)

        # Redo Button
        self.redo_button = QPushButton("Redo")
        self.redo_button.clicked.connect(self.perform_redo)
        history_layout.addWidget(self.redo_button)

        history_group.setLayout(history_layout)
        self.layout.addWidget(history_group)

    def setup_shortcuts(self):
        """Set up keyboard shortcuts for Undo (Ctrl+Z) and Redo (Ctrl+Y)."""
        undo_shortcut = QAction(self)
        undo_shortcut.setShortcut(QKeySequence.StandardKey.Undo)
        undo_shortcut.triggered.connect(self.perform_undo)
        self.addAction(undo_shortcut)

        redo_shortcut = QAction(self)
        redo_shortcut.setShortcut(QKeySequence.StandardKey.Redo)
        redo_shortcut.triggered.connect(self.perform_redo)
        self.addAction(redo_shortcut)

    def perform_undo(self):
        """Perform undo action by interacting with the local undo stack."""
        if self.undo_stack:
            # Push current image to redo stack
            self.redo_stack.append(self.image.copy())
            # Pop the last image from undo stack
            self.image = self.undo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def perform_redo(self):
        """Perform redo action by interacting with the local redo stack."""
        if self.redo_stack:
            # Push current image to undo stack
            self.undo_stack.append(self.image.copy())
            # Pop the last image from redo stack
            self.image = self.redo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Redo performed.")
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")   

    def create_visualization_pixmap(self):
        """
        Create a visualization of feathering and opacity on a white disc.
        """
        size = 100  # Size of the visualization image
        image = np.ones((size, size, 3), dtype=np.float32)  # White background

        center = (size // 2, size // 2)
        radius = self.radius_slider.value()
        feather = self.feather_slider.value() / 100.0
        opacity = self.opacity_slider.value() / 100.0

        yy, xx = np.ogrid[:size, :size]
        dist_from_center = np.sqrt((xx - center[0])**2 + (yy - center[1])**2)
        mask = dist_from_center <= radius

        # Feathering mask
        if feather > 0:
            feather_mask = np.clip((radius - dist_from_center) / (radius * feather), 0, 1)
        else:
            feather_mask = np.ones_like(mask, dtype=np.float32)

        feather_mask = feather_mask * mask

        # Apply opacity
        # Red color for the correction area
        image[mask] = (1 - opacity * feather_mask)[mask, np.newaxis] * image[mask] + \
                      (opacity * feather_mask)[mask, np.newaxis] * np.array([1, 0, 0])

        # Convert to QImage
        image_uint8 = (image * 255).astype(np.uint8)
        q_image = QImage(image_uint8.data, size, size, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        return pixmap

    def update_visualization(self):
        """Update the visualization pixmap based on current feathering and opacity."""
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)

    def view_mouse_press_event(self, event):
        """Handle mouse press events in the graphics view"""
        if event.button() == Qt.MouseButton.LeftButton:
            # Convert mouse position to scene coordinates
            scene_pos = self.graphics_view.mapToScene(event.pos())
            self.on_mouse_click(scene_pos)
        event.accept()

    def view_mouse_move_event(self, event):
        """Handle mouse move events in the graphics view"""
        # Convert mouse position to scene coordinates
        scene_pos = self.graphics_view.mapToScene(event.pos())
        self.on_mouse_move(scene_pos)
        event.accept()

    def convert_image_to_pixmap(self, image):
        """
        Convert a numpy image array to QPixmap for display.

        Args:
            image (np.ndarray): Image array normalized to [0,1].

        Returns:
            QPixmap: The converted pixmap.
        """
        # Convert from [0,1] to [0,255]
        image_uint8 = np.clip(image * 255, 0, 255).astype(np.uint8)

        if image_uint8.ndim == 2:
            # Grayscale image (2D) - Triplicate to make 3 channels
            height, width = image_uint8.shape
            image_triplicated = np.repeat(image_uint8[:, :, np.newaxis], 3, axis=2)
            bytes_per_line = 3 * width
            q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif image_uint8.ndim == 3:
            if image_uint8.shape[2] == 3:
                # RGB image (3 channels)
                height, width, channels = image_uint8.shape
                bytes_per_line = channels * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif image_uint8.shape[2] == 1:
                # Grayscale image represented as (height, width, 1) - Triplicate to make 3 channels
                height, width, channels = image_uint8.shape
                image_triplicated = np.repeat(image_uint8, 3, axis=2)
                bytes_per_line = 3 * width
                q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            else:
                raise ValueError(f"Unsupported number of channels: {image_uint8.shape[2]}")
        else:
            raise ValueError(f"Unsupported image shape: {image_uint8.shape}")

        return QPixmap.fromImage(q_image)


    def eventFilter(self, source, event):
        """Event filter to capture mouse move and click events."""
        if source == self.graphics_view:
            if event.type() == QEvent.Type.MouseMove:
                pos = self.graphics_view.mapToScene(event.pos())
                self.on_mouse_move(pos)
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    pos = self.graphics_view.mapToScene(event.pos())
                    self.on_mouse_click(pos)
            elif event.type() == QEvent.Type.Enter:
                # Optionally, set the cursor to ArrowCursor when entering
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
            elif event.type() == QEvent.Type.Leave:
                self.graphics_view.unsetCursor()
        return super().eventFilter(source, event)

    def on_mouse_move(self, pos):
        """
        Handle mouse move events to display a dynamic circle indicating the blemish removal radius.

        Args:
            pos (QPointF): The position of the mouse in scene coordinates.
        """
        x, y = pos.x(), pos.y()
        self.current_x, self.current_y = x, y

        radius = self.radius_slider.value()

        # Update the circle's position and size
        self.circle_item.setRect(x - radius, y - radius, 2 * radius, 2 * radius)
        self.circle_item.setVisible(True)

        # Detect if cursor is over scroll bars
        viewport_pos = self.graphics_view.mapFromScene(pos)
        scrollbar_over = False

        # Check horizontal scroll bar
        h_scrollbar = self.graphics_view.horizontalScrollBar()
        if h_scrollbar.isVisible():
            h_scrollbar_rect = h_scrollbar.geometry()
            if h_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Check vertical scroll bar
        v_scrollbar = self.graphics_view.verticalScrollBar()
        if v_scrollbar.isVisible():
            v_scrollbar_rect = v_scrollbar.geometry()
            if v_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Update cursor based on position
        if scrollbar_over:
            if self.cursor_over_scrollbar:
                # Already over scrollbar, no action needed
                pass
            else:
                # Now over scrollbar
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = True
        else:
            if self.cursor_over_scrollbar:
                # Moved away from scrollbar, set default cursor
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = False
            else:
                # Already using default cursor, no action needed
                pass
            
    def on_mouse_click(self, pos):
        """
        Handle mouse press events to remove blemishes on click.

        Args:
            pos (QPointF): The position of the mouse click in scene coordinates.
        """
        x, y = int(pos.x()), int(pos.y())

        # Validate coordinates
        if 0 <= x < self.image.shape[1] and 0 <= y < self.image.shape[0]:
            radius = self.radius_slider.value()
            feather = self.feather_slider.value() / 100.0
            opacity = self.opacity_slider.value() / 100.0

            # Determine channels to process based on image dimensionality
            if self.image.ndim == 2:
                channels_to_process = [0]  # Single channel
            elif self.image.ndim == 3:
                channels_to_process = [0, 1, 2]  # RGB channels
            else:
                QMessageBox.warning(self, "Unsupported Image", "Image format not supported for blemish removal.")
                return

            # Start the blemish removal in a separate thread
            worker = BlemishBlasterWorker(
                image=self.image.copy(),  # Pass the current image from ImageManager
                x=x,
                y=y,
                radius=radius,
                feather=feather,
                opacity=opacity,
                channels_to_process=[0, 1, 2]  # RGB channels
            )
            worker.signals.finished.connect(self.on_processing_finished)
            self.threadpool.start(worker)

            self.setEnabled(False)  # Disable the dialog to prevent multiple clicks
            print(f"Started blemish removal at ({x}, {y}) with radius {radius}, feathering {feather}, opacity {opacity}.")

    def on_processing_finished(self, corrected_image):
        """
        Slot to handle the completion of blemish removal.

        Args:
            corrected_image (np.ndarray): The image after blemish removal.
        """
        # Push the current image to the undo stack before updating
        self.undo_stack.append(self.image.copy())
        # Clear the redo stack as new action invalidates future redos
        self.redo_stack.clear()

        # Update the local image with the corrected image
        self.image = corrected_image.copy()
        self.display_image = self.image.copy()
        self.update_display_image()

        self.setEnabled(True)  # Re-enable the dialog
        print("Blemish removal completed.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image

    def autostretch_image(self):
        """Handle the Autostretch button click to stretch or unstretch the image."""
        if not self.is_stretched:
            # Perform stretching
            stretched_image = self.stretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = stretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = True
            self.autostretch_button.setText("Remove Stretch")
            print("Image stretched.")
        else:
            # Optionally, allow removing stretch before applying changes
            # Uncomment the following lines if you want to allow removing stretch manually
            unstretched_image = self.unstretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = unstretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = False
            self.autostretch_button.setText("Autostretch")
            print("Stretch removed.")


    def apply_changes(self):
        """Apply all changes by pushing the final image to the ImageManager."""
        try:
            # If the image is stretched, unstretch it before applying
            if self.is_stretched:
                self.image = self.unstretch_image(self.image)
                self.display_image = self.image.copy()
                self.update_display_image()
                self.is_stretched = False
                self.autostretch_button.setText("Autostretch")
                print("Image unstretched before applying changes.")

            current_slot = self.image_manager.current_slot
            existing_metadata = self.image_manager._metadata.get(current_slot, {}).copy()

            # Ensure 'notes' exists and is a list
            if 'notes' in existing_metadata and isinstance(existing_metadata['notes'], list):
                existing_metadata['notes'].append("Blemish removed using Blemish Blaster.")
                print("Appended blemish removal note to existing metadata.")
            else:
                existing_metadata['notes'] = ["Blemish removed using Blemish Blaster."]
                print("Initialized blemish removal note in metadata.")

            # Push the updated image and metadata to the ImageManager
            self.image_manager.set_image(self.image.copy(), metadata=existing_metadata)
            self.blemish_removed.emit(self.image_manager.image)

            # Clear the undo and redo stacks as changes are now applied
            self.undo_stack.clear()
            self.redo_stack.clear()


            self.accept()
            print("Applied changes to ImageManager.")

        except Exception as e:
            QMessageBox.critical(
                self,
                "Apply Changes Error",
                f"An error occurred while applying changes:\n{str(e)}"
            )
            print(f"ERROR in apply_changes: {e}")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """Zoom in the image by a predefined step."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed in to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def zoom_out(self):
        """Zoom out the image by a predefined step."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed out to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def apply_zoom(self):
        """Apply the current zoom factor to the QGraphicsView."""
        self.graphics_view.resetTransform()  # Reset any existing transformations
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def reset_zoom(self):
        """Reset zoom to the default factor (100%)."""
        self.zoom_factor = 1.0
        self.apply_zoom()
        self.zoom_label.setText("100%")
        print("Zoom reset to 100%.")

    def update_display_image(self):
        """Update the display image from the local image and refresh the pixmap."""
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))
        # Optionally, clear the correction circle
        self.circle_item.setVisible(False)

    def closeEvent(self, event):

        super().closeEvent(event)



class PolyGradientRemoval:
    """
    A headless class that replicates the polynomial background removal
    logic from GradientRemovalDialog, minus the RBF step and UI code.

    Flow:
      1) Stretch the image (unlinked linear stretch).
      2) Downsample.
      3) Build an exclusion mask that:
         - Skips zero-valued pixels in any channel.
         - Optionally skip user-specified mask areas if desired (can pass mask to process()).
      4) Generate sample points from corners, borders, quartiles, do gradient_descent_to_dim_spot, skip bright areas.
      5) Fit a polynomial background and subtract it.
      6) Re-normalize median, clip to [0..1].
      7) Unstretch the final image back to the original domain.
    """

    def __init__(
        self,
        image: np.ndarray,
        poly_degree: int = 2,
        downsample_scale: int = 5,
        num_sample_points: int = 100
    ):
        """
        Args:
            image (np.ndarray): Input image in [0..1], shape (H,W) or (H,W,3), float32 recommended.
            poly_degree (int): Polynomial degree (1=linear,2=quadratic).
            downsample_scale (int): Factor for area downsampling.
            num_sample_points (int): Number of sample points to generate.
        """
        self.image = image.copy()
        self.poly_degree = poly_degree
        self.downsample_scale = downsample_scale
        self.num_sample_points = num_sample_points

        # For the stretch/unstretch logic
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False

    def process(self, user_exclusion_mask: np.ndarray = None) -> np.ndarray:
        """
        Main pipeline to remove polynomial gradient. 
        user_exclusion_mask: optional (H,W) boolean array, False => skip those pixels.
        
        Returns the final corrected image in the original brightness domain.
        """
        # 1) Stretch
        stretched = self.pixel_math_stretch(self.image)
        print("stretching")

        # 2) Downsample
        small_stretched = self.downsample_image(stretched, self.downsample_scale)
        h_s, w_s = small_stretched.shape[:2]
        print("downsampling")

        # 3) Build an exclusion mask in the small domain that:

        # 4) Generate sample points from corners/borders/quartiles
        sample_points = generate_sample_points(
            small_stretched,
            num_points=self.num_sample_points
        )
        print("sample points generated")

        # 5) Fit polynomial on the downsampled image
        poly_background_small = self.fit_polynomial_gradient(
            small_stretched, sample_points, degree=self.poly_degree
        )
        print("fit poly")

        # Upscale background to full size
        poly_background = self.upscale_background(
            poly_background_small, stretched.shape[:2]
        )
        print("upscale")

        # Subtract
        after_poly = stretched - poly_background
        print("subtracted")

        # Re-normalize median to original
        original_median = np.median(stretched)
        after_poly = self.normalize_image(after_poly, original_median)
        print("normalized")

        # Clip
        after_poly = np.clip(after_poly, 0, 1)

        # 6) Unstretch
        corrected = self.unstretch_image(after_poly)

        return corrected

    # ---------------------------------------------------------------
    # Helper: Stretch / Unstretch
    # ---------------------------------------------------------------
    def pixel_math_stretch(self, image: np.ndarray) -> np.ndarray:
        """
        Unlinked linear stretch using your existing Numba functions.

        Steps:
        1) If single-channel, replicate to 3-ch so we can store stats & do consistent logic.
        2) For each channel c: subtract the channel's min => data is >= 0.
        3) Compute the median after min subtraction for that channel.
        4) Call the appropriate Numba function:
            - If single-channel (was originally 1-ch), call numba_mono_final_formula
            on the 1-ch array.
            - If 3-ch color, call numba_color_final_formula_unlinked.
        5) Clip to [0,1].
        6) Store self.stretch_original_mins / medians so we can unstretch later.
        """
        target_median = 0.25

        # 1) Handle single-channel => replicate to 3 channels
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            self.was_single_channel = True
            image_3ch = np.stack([image.squeeze()] * 3, axis=-1)
        else:
            self.was_single_channel = False
            image_3ch = image

        image_3ch = image_3ch.astype(np.float32, copy=True)

        H, W, C = image_3ch.shape
        # We assume C=3 now.

        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # 2) Subtract min per channel
        for c in range(C):
            cmin = image_3ch[..., c].min()
            image_3ch[..., c] -= cmin
            self.stretch_original_mins.append(float(cmin))

        # 3) Compute median after min subtraction
        medians_after_sub = []
        for c in range(C):
            cmed = float(np.median(image_3ch[..., c]))
            medians_after_sub.append(cmed)
        self.stretch_original_medians = medians_after_sub

        # 4) Apply the final formula with your Numba functions
        if self.was_single_channel:
            # If originally single-channel, let's do a single pass with numba_mono_final_formula
            # on the single channel. We can do that by extracting one channel from image_3ch.
            # Then replicate the result to 3 channels, or keep it as 1-ch?
            # Typically we keep it as 1-ch in the end, so let's do that.

            # We'll just pick channel 0, run the mono formula, store it back in a 2D array.
            mono_array = image_3ch[..., 0]  # shape (H,W)
            cmed = medians_after_sub[0]     # The median for that channel
            # We call the numba function
            stretched_mono = numba_mono_final_formula(mono_array, cmed, target_median)

            # Now place it back into image_3ch for consistency
            for c in range(3):
                image_3ch[..., c] = stretched_mono
        else:
            # 3-channel unlinked
            medians_rescaled = np.array(medians_after_sub, dtype=np.float32)
            # 'image_3ch' is our 'rescaled'
            stretched_3ch = numba_color_final_formula_unlinked(
                image_3ch, medians_rescaled, target_median
            )
            image_3ch = stretched_3ch

        # 5) Clip to [0..1]
        np.clip(image_3ch, 0.0, 1.0, out=image_3ch)
        image = image_3ch
        return image


    def pixel_math_stretch(self, image: np.ndarray) -> np.ndarray:
        """
        Unlinked linear stretch using your existing Numba functions.

        Steps:
        1) If single-channel, replicate to 3-ch so we can store stats & do consistent logic.
        2) For each channel c: subtract the channel's min => data is >= 0.
        3) Compute the median after min subtraction for that channel.
        4) Call the appropriate Numba function:
            - If single-channel (was originally 1-ch), call numba_mono_final_formula
            on the 1-ch array.
            - If 3-ch color, call numba_color_final_formula_unlinked.
        5) Clip to [0,1].
        6) Store self.stretch_original_mins / medians so we can unstretch later.
        """
        target_median = 0.25

        # 1) Handle single-channel => replicate to 3 channels
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            self.was_single_channel = True
            image_3ch = np.stack([image.squeeze()] * 3, axis=-1)
        else:
            self.was_single_channel = False
            image_3ch = image

        image_3ch = image_3ch.astype(np.float32, copy=True)

        H, W, C = image_3ch.shape
        # We assume C=3 now.

        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # 2) Subtract min per channel
        for c in range(C):
            cmin = image_3ch[..., c].min()
            image_3ch[..., c] -= cmin
            self.stretch_original_mins.append(float(cmin))

        # 3) Compute median after min subtraction
        medians_after_sub = []
        for c in range(C):
            cmed = float(np.median(image_3ch[..., c]))
            medians_after_sub.append(cmed)
        self.stretch_original_medians = medians_after_sub

        # 4) Apply the final formula with your Numba functions
        if self.was_single_channel:
            # If originally single-channel, let's do a single pass with numba_mono_final_formula
            # on the single channel. We can do that by extracting one channel from image_3ch.
            # Then replicate the result to 3 channels, or keep it as 1-ch?
            # Typically we keep it as 1-ch in the end, so let's do that.

            # We'll just pick channel 0, run the mono formula, store it back in a 2D array.
            mono_array = image_3ch[..., 0]  # shape (H,W)
            cmed = medians_after_sub[0]     # The median for that channel
            # We call the numba function
            stretched_mono = numba_mono_final_formula(mono_array, cmed, target_median)

            # Now place it back into image_3ch for consistency
            for c in range(3):
                image_3ch[..., c] = stretched_mono
        else:
            # 3-channel unlinked
            medians_rescaled = np.array(medians_after_sub, dtype=np.float32)
            # 'image_3ch' is our 'rescaled'
            stretched_3ch = numba_color_final_formula_unlinked(
                image_3ch, medians_rescaled, target_median
            )
            image_3ch = stretched_3ch

        # 5) Clip to [0..1]
        np.clip(image_3ch, 0.0, 1.0, out=image_3ch)
        image = image_3ch
        return image


    def unstretch_image(self, image: np.ndarray) -> np.ndarray:
        """
        Calls the Numba-optimized unstretch function.
        """
        image = image.astype(np.float32, copy=True)

        # Convert lists to NumPy arrays for efficient Numba processing
        stretch_original_medians = np.array(self.stretch_original_medians, dtype=np.float32)
        stretch_original_mins = np.array(self.stretch_original_mins, dtype=np.float32)

        # Call the Numba function
        unstretched = numba_unstretch(image, stretch_original_medians, stretch_original_mins)

        if self.was_single_channel:
            # Convert back to grayscale
            unstretched = np.mean(unstretched, axis=2, keepdims=True)

        return unstretched


    # ---------------------------------------------------------------
    # Helper: Downsample
    # ---------------------------------------------------------------
    def downsample_image(self, image: np.ndarray, scale: int=6) -> np.ndarray:
        """
        Downsamples with area interpolation.
        """
        h, w = image.shape[:2]
        new_w = max(1, w//scale)
        new_h = max(1, h//scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)



    # ---------------------------------------------------------------
    # 5) Fit Polynomial
    # ---------------------------------------------------------------
    def fit_polynomial_gradient(self, image: np.ndarray, sample_points: np.ndarray, degree: int = 2, patch_size: int = 15) -> np.ndarray:
        """
        Optimized polynomial background fitting.
        - Extracts sample points using vectorized NumPy median calculations.
        - Solves for polynomial coefficients in parallel.
        - Precomputes polynomial basis terms for efficiency.
        """

        H, W = image.shape[:2]
        half_patch = patch_size // 2
        num_samples = len(sample_points)

        # Convert sample points to NumPy arrays
        sample_points = np.array(sample_points, dtype=np.int32)
        x_coords, y_coords = sample_points[:, 0], sample_points[:, 1]

        # Precompute polynomial design matrix
        A = build_poly_terms(x_coords, y_coords, degree)

        # Extract sample values efficiently
        if image.ndim == 3 and image.shape[2] == 3:
            # Color image
            background = np.zeros_like(image, dtype=np.float32)
            for c in range(3):
                # Extract patches and compute medians using vectorized NumPy operations
                z_vals = np.array([
                    np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                    max(0, x-half_patch):min(W, x+half_patch+1), c])
                    for x, y in zip(x_coords, y_coords)
                ], dtype=np.float32)

                # Solve for polynomial coefficients
                coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

                # Generate full polynomial background
                background[..., c] = evaluate_polynomial(H, W, coeffs, degree)

        else:
            # Grayscale image
            background = np.zeros((H, W), dtype=np.float32)

            z_vals = np.array([
                np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                max(0, x-half_patch):min(W, x+half_patch+1)])
                for x, y in zip(x_coords, y_coords)
            ], dtype=np.float32)

            # Solve for polynomial coefficients
            coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

            # Generate full polynomial background
            background = evaluate_polynomial(H, W, coeffs, degree)

        return background
    # ---------------------------------------------------------------
    # 6) Upscale
    # ---------------------------------------------------------------
    def upscale_background(self, background: np.ndarray, out_shape: tuple) -> np.ndarray:
        """
        Resizes 'background' to out_shape=(H,W) using OpenCV interpolation.
        """
        oh, ow = out_shape

        if background.ndim == 3 and background.shape[2] == 3:
            # Resizing each channel efficiently without looping in Python
            return np.stack([cv2.resize(background[..., c], (ow, oh), interpolation=cv2.INTER_LINEAR)
                            for c in range(3)], axis=-1)
        else:
            return cv2.resize(background, (ow, oh), interpolation=cv2.INTER_LINEAR).astype(np.float32)
    # ---------------------------------------------------------------
    # 7) Normalize
    # ---------------------------------------------------------------
    def normalize_image(self, image: np.ndarray, target_median: float) -> np.ndarray:
        """
        Shift image so its median matches target_median.
        """
        cmed = np.median(image)
        diff = target_median - cmed
        return image + diff

class CustomDoubleSpinBox(QWidget):
    valueChanged = pyqtSignal(float)

    def __init__(self, minimum=0.0, maximum=10.0, initial=0.0, step=0.1, parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial

        # Create a line edit with a double validator.
        self.lineEdit = QLineEdit(f"{initial:.3f}")
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)
        validator = QDoubleValidator(self.minimum, self.maximum, 3, self)
        validator.setNotation(QDoubleValidator.Notation.StandardNotation)
        self.lineEdit.setValidator(validator)
        self.lineEdit.editingFinished.connect(self.onEditingFinished)

        # Create up and down buttons.
        self.upButton = QToolButton()
        self.upButton.setText("▲")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton = QToolButton()
        self.downButton.setText("▼")
        self.downButton.clicked.connect(self.decreaseValue)

        # Arrange buttons vertically.
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Arrange the line edit and button layout horizontally.
        mainLayout = QHBoxLayout()
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        mainLayout.setSpacing(0)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def onEditingFinished(self):
        try:
            new_val = float(self.lineEdit.text())
        except ValueError:
            new_val = self._value
        self.setValue(new_val)

    def setValue(self, val: float):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if abs(val - self._value) > 1e-9:
            self._value = val
            self.lineEdit.setText(f"{val:.3f}")
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def value(self) -> float:
        return self._value

class CustomSpinBox(QWidget):
    """
    A simple custom spin box that mimics QSpinBox functionality.
    Emits valueChanged(int) when the value changes.
    """
    valueChanged = pyqtSignal(int)

    def __init__(self, minimum=0, maximum=100, initial=0, step=1, parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial

        # Create a line edit to show the value.
        self.lineEdit = QLineEdit(str(initial))
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)

        self.lineEdit.setValidator(QIntValidator(self.minimum, self.maximum, self))
        self.lineEdit.editingFinished.connect(self.editingFinished)

        # Create up and down buttons with arrow text or icons.
        self.upButton = QToolButton()
        self.upButton.setText("▲")
        self.downButton = QToolButton()
        self.downButton.setText("▼")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton.clicked.connect(self.decreaseValue)

        # Arrange the buttons vertically.
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Arrange the line edit and buttons horizontally.
        mainLayout = QHBoxLayout()
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        mainLayout.setSpacing(0)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    @property
    def value(self):
        return self._value

    def setValue(self, val):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if val != self._value:
            self._value = val
            self.lineEdit.setText(str(val))
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def editingFinished(self):
        try:
            newVal = int(self.lineEdit.text())
        except ValueError:
            newVal = self._value
        self.setValue(newVal)

class GradientRemovalDialog(QDialog):
    # Define signals to communicate with AstroEditingSuite
    processing_completed = pyqtSignal(np.ndarray, np.ndarray, bool, str)  # Corrected Image, Gradient Background

    def __init__(self, image, parent=None):
        """
        Initializes the GradientRemoval dialog.

        Args:
            image: Original image as a NumPy array (float32, normalized 0-1).
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Gradient Removal")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowMaximizeButtonHint)
        self.image = image.copy()  # Original image (float32, 0-1)
        self.exclusion_polygons = []  # List of polygons (each polygon is a list of QPoint)
        self.drawing = False
        self.current_polygon = []

        # Initialize parameters with default values
        self.num_sample_points = 100
        self.poly_degree = 2
        self.rbf_smooth = 0.1
        self.show_gradient = False

        # Downsample scale factor (can be made user-definable if needed)
        self.downsample_scale = 4
        self.save_to_slot_1 = False

        # Calculate scale factor to fit image within max_display_size
        original_height, original_width = self.image.shape[:2]
        max_display_size = (800, 600)
        max_width, max_height = max_display_size

        scale_w = max_width / original_width
        scale_h = max_height / original_height
        scale = min(scale_w, scale_h, 1.0)  # Prevent upscaling if image is smaller
        self.scale_factor = scale

        scaled_width = int(original_width * scale)
        scaled_height = int(original_height * scale)

        # Prepare display image (same for grayscale or color)
        display_image = (self.image * 255).astype(np.uint8)
        display_image = cv2.resize(display_image, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)

        # Convert to QImage
        if display_image.ndim == 2:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_Grayscale8)
        else:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_RGB888)

        # Set up QGraphicsScene and QGraphicsView for consistent coordinate mapping
        self.scene = QGraphicsScene(self)
        self.pixmap_item = QGraphicsPixmapItem(QPixmap.fromImage(q_img))
        self.scene.addItem(self.pixmap_item)

        self.view = QGraphicsView(self.scene, self)
        self.view.setRenderHints(QPainter.RenderHint.Antialiasing | QPainter.RenderHint.SmoothPixmapTransform)
        self.view.setAlignment(Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignLeft)
        self.view.setDragMode(QGraphicsView.DragMode.NoDrag)
        self.view.viewport().installEventFilter(self)  # Install event filter on the viewport

        # Set up controls (you can leave your setup_controls() largely unchanged)
        self.setup_controls()

        # Layout
        main_layout = QHBoxLayout()
        main_layout.addWidget(self.view, 1)
        controls_widget = QWidget()
        controls_layout = QVBoxLayout()
        controls_layout.addWidget(self.controls_groupbox)
        controls_layout.addStretch(1)
        self.status_label = QLabel("Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        controls_layout.addWidget(self.status_label)
        controls_widget.setLayout(controls_layout)
        controls_widget.setFixedWidth(300)
        main_layout.addWidget(controls_widget, 0)
        self.setLayout(main_layout)
        self.setMinimumSize(1000, 700)

        # For later use, we keep the original (full-resolution) image and store a scaling factor.
        # Here, self.display_scale is used to display the image. When processing, you work with self.image.
        self.thread = None
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        QTimer.singleShot(0, lambda: self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio))


    def setup_controls(self):
        """
        Sets up the user controls for parameters.
        """
        self.controls_groupbox = QGroupBox("Parameters")
        form_layout = QFormLayout()

        # Number of sample points
        self.sample_points_spinbox = CustomSpinBox(minimum=10, maximum=1000, initial=self.num_sample_points, step=10)
        self.sample_points_spinbox.valueChanged.connect(self.update_num_sample_points)
        form_layout.addRow("Number of Sample Points:", self.sample_points_spinbox)

        # Polynomial degree
        self.poly_degree_spinbox = CustomSpinBox(minimum=1, maximum=10, initial=self.poly_degree, step=1)
        self.poly_degree_spinbox.valueChanged.connect(self.update_poly_degree)
        form_layout.addRow("Polynomial Degree:", self.poly_degree_spinbox)

        # RBF smoothing using CustomDoubleSpinBox
        self.rbf_smooth_spinbox = CustomDoubleSpinBox(minimum=0.0, maximum=10.0, initial=self.rbf_smooth, step=0.1)
        self.rbf_smooth_spinbox.valueChanged.connect(self.update_rbf_smooth)
        form_layout.addRow("RBF Smoothness:", self.rbf_smooth_spinbox)

        # Show gradient removal
        self.show_gradient_checkbox = QCheckBox("Show Gradient Removed")
        self.show_gradient_checkbox.stateChanged.connect(self.update_show_gradient)
        form_layout.addRow(self.show_gradient_checkbox)

        # **New: Slot Selection Dropdown**
        self.save_slot_dropdown = QComboBox()
        self.save_slot_dropdown.addItems(["Slot 1", "Slot 2", "Slot 3", "Slot 4", "Slot 5", "Slot 6", "Slot 7", "Slot 8", "Slot 9"])  # Example slot choices
        form_layout.addRow("Save Gradient To:", self.save_slot_dropdown)

        # Add AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.setStatusTip("Apply auto-stretch to the displayed image")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow(self.autostretch_button)

        # Clear Drawn Exclusion Areas button
        self.clear_exclusion_button = QPushButton("Clear Exclusion Areas")
        self.clear_exclusion_button.setStatusTip("Clear all drawn exclusion areas")
        self.clear_exclusion_button.clicked.connect(self.clear_exclusion_areas)
        form_layout.addRow(self.clear_exclusion_button)

        # Process button
        self.process_button = QPushButton("Process")
        self.process_button.clicked.connect(self.process_image)
        form_layout.addRow(self.process_button)

        # Instruction for Exclusion Zones
        instructions = QLabel("Draw exclusion zones by clicking and dragging on the image.\n"
                            "Press 'Enter' to finalize each polygon.")
        form_layout.addRow(instructions)

        self.controls_groupbox.setLayout(form_layout)

    def autostretch_image(self):
        """
        Applies auto-stretch to the displayed image without affecting the original image.
        """
        # Stretch the original image for display
        stretched_image = self.stretch_image(self.image)

        # Get the current pixmap size from the pixmap_item.
        current_pixmap = self.pixmap_item.pixmap()
        scaled_width = current_pixmap.width()
        scaled_height = current_pixmap.height()

        # Prepare display image (convert from float32 [0,1] to uint8)
        display_image = (stretched_image * 255).astype(np.uint8)

        # Resize for display
        display_image = cv2.resize(
            display_image,
            (scaled_width, scaled_height),
            interpolation=cv2.INTER_AREA,
        )

        # Convert to QImage based on whether image is grayscale or color
        if display_image.ndim == 2:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_Grayscale8,
            )
        else:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_RGB888,
            )

        # Update the pixmap with the stretched image
        stretched_pixmap = QPixmap.fromImage(q_img)
        self.pixmap_item.setPixmap(stretched_pixmap)
        # Optionally, re-fit the view:
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)


    def eventFilter(self, source, event):
        if source is self.view.viewport():
            if event.type() == QEvent.Type.KeyPress:
                # Finalize current polygon on Enter key
                if event.key() == Qt.Key.Key_Return or event.key() == Qt.Key.Key_Enter:
                    if self.current_polygon:
                        self.exclusion_polygons.append(self.current_polygon.copy())
                        self.current_polygon = []
                        self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    # Map the mouse position directly to scene coordinates
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon = [scene_point]
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    # Finalize polygon automatically (or wait for Enter if you prefer)
                    self.exclusion_polygons.append(self.current_polygon.copy())
                    self.current_polygon = []
                    self.update_selection()
                    return True
        return super().eventFilter(source, event)

    def update_selection(self):
        """
        Redraws the pixmap with the exclusion polygons overlaid.
        The polygons are stored in scene coordinates.
        """
        # Start by resetting the pixmap item to the original display image.
        # (Since we're working in scene coordinates, we don't need to re-scale manually.)
        self.pixmap_item.setPixmap(self.pixmap_item.pixmap())

        # Create an overlay pixmap
        overlay = QPixmap(self.pixmap_item.pixmap().size())
        overlay.fill(Qt.GlobalColor.transparent)
        painter = QPainter(overlay)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # Draw finalized polygons in green (semi-transparent)
        QPen_pen = QPen(QColor(0, 255, 0), 2)
        QPen_brush = QColor(0, 255, 0, 50)
        painter.setPen(QPen_pen)
        painter.setBrush(QPen_brush)
        for polygon in self.exclusion_polygons:
            # Convert list of QPointF to QPolygonF and draw it
            poly = QPolygonF(polygon)
            painter.drawPolygon(poly)

        # Draw current (in-progress) polygon in red dashed outline
        if self.drawing and len(self.current_polygon) > 1:
            pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.setBrush(Qt.BrushStyle.NoBrush)
            poly = QPolygonF(self.current_polygon)
            painter.drawPolyline(poly)

        painter.end()

        # Create a new QGraphicsPixmapItem for the overlay and add it on top of the image.
        # Remove any existing overlay items.
        for item in self.scene.items():
            if isinstance(item, QGraphicsPixmapItem) and item != self.pixmap_item:
                self.scene.removeItem(item)
        overlay_item = QGraphicsPixmapItem(overlay)
        overlay_item.setZValue(1)  # Ensure it is on top
        self.scene.addItem(overlay_item)


    def clear_exclusion_areas(self):
        """Clears all drawn exclusion polygons."""
        self.exclusion_polygons = []
        self.current_polygon = []
        self.update_selection()


    def update_num_sample_points(self, value):
        self.num_sample_points = value

    def update_poly_degree(self, value):
        self.poly_degree = value

    def update_rbf_smooth(self, value):
        self.rbf_smooth = value

    def update_show_gradient(self, state):
        self.show_gradient = state == Qt.CheckState.Checked

    def mouse_press_event(self, event):
        """
        Handles the mouse press event to initiate drawing.
        Converts the event's position (in label coordinates) to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            # The label's current pixmap is the scaled (displayed) image.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            # Map the mouse position to base coordinates.
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.drawing = True
            self.current_polygon = [base_point]
            self.update_selection()

    def mouse_move_event(self, event):
        """
        Handles the mouse move event to update the current polygon being drawn.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if self.drawing:
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.update_selection()

    def mouse_release_event(self, event):
        """
        Handles the mouse release event to finalize the polygon.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton and self.drawing:
            # Optionally, update with the final point.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.drawing = False
            # Store the polygon (which is in base coordinates)
            self.exclusion_polygons.append(QPolygon(self.current_polygon))
            self.current_polygon = []
            self.update_selection()



    def process_image(self):
        """
        Processes the image to subtract the background in two stages:
        1. Polynomial gradient removal.
        2. RBF gradient removal.
        """
        # Disable the process button to prevent multiple clicks
        self.save_to_slot_1 = self.show_gradient_checkbox.isChecked()
        self.process_button.setEnabled(False)

        # Stretch the image before processing
        self.status_label.setText("Normalizing image for processing...")
        QApplication.processEvents()
        stretched_image = self.stretch_image(self.image)

        # Check if the image is color
        is_color = len(stretched_image.shape) == 3

        # Store original median
        original_median = np.median(stretched_image)

        # Create exclusion mask
        exclusion_mask = self.create_exclusion_mask(stretched_image.shape, self.exclusion_polygons) if self.exclusion_polygons else None

        # ------------------ First Stage: Polynomial Gradient Removal ------------------
        self.status_label.setText("Step 1: Polynomial Gradient Removal")
        QApplication.processEvents()
        # Downsample for polynomial background fitting
        small_image_poly = self.downsample_image(stretched_image, self.downsample_scale)

        # Create a downsampled exclusion mask for polynomial fitting
        if exclusion_mask is not None:
            small_exclusion_mask_poly = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_poly = None

        # Generate sample points for polynomial fitting with exclusions
        poly_sample_points = self.generate_sample_points(
            small_image_poly, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_poly
        )

        # Fit the polynomial gradient
        if is_color:
            poly_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                poly_bg_channel = self.fit_polynomial_gradient(
                    small_image_poly[:, :, channel], poly_sample_points, degree=self.poly_degree
                )
                poly_background[:, :, channel] = self.upscale_background(poly_bg_channel, stretched_image.shape[:2])
        else:
            poly_background_small = self.fit_polynomial_gradient(small_image_poly, poly_sample_points, degree=self.poly_degree)
            poly_background = self.upscale_background(poly_background_small, stretched_image.shape[:2])

        # Subtract the polynomial background
        image_after_poly = stretched_image - poly_background

        # Normalize to restore original median
        image_after_poly = self.normalize_image(image_after_poly, original_median)

        # Clip the values to valid range
        image_after_poly = np.clip(image_after_poly, 0, 1)

        # ------------------ Second Stage: RBF Gradient Removal ------------------
        self.status_label.setText("Step 2: RBF Gradient Removal")
        QApplication.processEvents()
        # Downsample the image after polynomial removal for RBF fitting
        small_image_rbf = self.downsample_image(image_after_poly, self.downsample_scale)

        # Create a downsampled exclusion mask for RBF fitting
        if exclusion_mask is not None:
            small_exclusion_mask_rbf = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_rbf = None

        # Generate sample points for RBF fitting with exclusions
        rbf_sample_points = self.generate_sample_points(
            small_image_rbf, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_rbf
        )

        # Fit the RBF gradient
        if is_color:
            rbf_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                rbf_bg_channel = self.fit_background(
                    small_image_rbf[:, :, channel], rbf_sample_points, smooth=self.rbf_smooth, patch_size=15
                )
                rbf_background[:, :, channel] = self.upscale_background(rbf_bg_channel, stretched_image.shape[:2])
        else:
            rbf_background_small = self.fit_background(small_image_rbf, rbf_sample_points, smooth=self.rbf_smooth, patch_size=15)
            rbf_background = self.upscale_background(rbf_background_small, stretched_image.shape[:2])

        # Subtract the RBF background
        corrected_image = image_after_poly - rbf_background

        # Normalize to restore original median
        corrected_image = self.normalize_image(corrected_image, original_median)

        # Clip the values to valid range
        corrected_image = np.clip(corrected_image, 0, 1)

        # Unstretch both the corrected image and the gradient background
        self.status_label.setText("De-Normalizing the processed images...")
        QApplication.processEvents()
        corrected_image = self.unstretch_image(corrected_image)
        total_background = poly_background + rbf_background
        gradient_background = self.unstretch_image(total_background)

                # Ensure both images are 3-channel RGB
        # Ensure both images are 3-channel RGB
        corrected_image = self.ensure_rgb(corrected_image)
        gradient_background = self.ensure_rgb(gradient_background)


        print("[DEBUG] Step 2 Completed.")

        # ------------------ Emit Results ------------------
        print("[DEBUG] Emitting results...")
        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()

        # Check if the user wants to save the gradient
        save_gradient = self.show_gradient_checkbox.isChecked()

        # Get the selected slot from the dropdown
        selected_slot = self.save_slot_dropdown.currentText()  # Example: "Slot 1"

        if save_gradient:
            print(f"[INFO] Saving extracted gradient to {selected_slot}")
        else:
            print("[INFO] User chose not to save the extracted gradient.")

        # Emit the processed images back to `AstroEditingSuite`
        self.processing_completed.emit(corrected_image, gradient_background, save_gradient, selected_slot)

        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()
        self.accept()

    # ------------------ Helper Functions ------------------
    # Ensure corrected_image and gradient_background are strictly 3-channel RGB
    def ensure_rgb(self,image):
        """
        Ensures the given image is 3-channel RGB.
        Args:
            image: The input NumPy array (can be 2D or 3D with a single channel).
        Returns:
            A 3D NumPy array with shape (height, width, 3).
        """
        if image.ndim == 2:  # Grayscale image
            return np.repeat(image[:, :, np.newaxis], 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:  # Single-channel image with an extra dimension
            return np.repeat(image, 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 3:  # Already RGB
            return image
        else:
            raise ValueError(f"Unexpected image shape: {image.shape}")




    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def downsample_image(self, image, scale=4):
        """
        Downsamples the image by the specified scale factor using area interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            scale: Downsampling scale factor.

        Returns:
            downsampled_image: Downsampled image.
        """
        new_size = (max(1, image.shape[1] // scale), max(1, image.shape[0] // scale))
        return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)

    def upscale_background(self, background, original_shape):
        """
        Upscales the background model to the original image size.

        Args:
            background: 2D NumPy array (single-channel background model).
            original_shape: Tuple of (height, width) for the target size.

        Returns:
            upscaled_background: Upscaled 2D background model.
        """
        if background.ndim == 2:
            # Single-channel (grayscale) input
            return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR)
        elif background.ndim == 3 and background.shape[2] == 1:
            # Ensure input shape is reduced to 2D for single-channel data
            background = background.squeeze()  # Remove singleton dimension

        return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR)



    def divide_into_quartiles(self, image):
        """
        Divides the image into four quartiles.

        Args:
            image: 2D/3D NumPy array of the image.

        Returns:
            quartiles: Dictionary containing quartile images.
        """
        h, w = image.shape[:2]
        half_h, half_w = h // 2, w // 2
        return {
            'top_left': image[:half_h, :half_w],
            'top_right': image[:half_h, half_w:],
            'bottom_left': image[half_h:, :half_w],
            'bottom_right': image[half_h:, half_w:],
        }

    def exclude_bright_regions(self, quartile, exclusion_fraction=0.5):
        """
        Excludes the brightest regions in a quartile based on the exclusion fraction.

        Args:
            quartile: 2D/3D NumPy array of the quartile image.
            exclusion_fraction: Fraction of the brightest pixels to exclude.

        Returns:
            mask: Boolean mask where True indicates eligible pixels.
        """
        flattened = quartile.flatten()
        threshold = np.percentile(flattened, 100 * (1 - exclusion_fraction))
        mask = quartile < threshold
        return mask

    def gradient_descent_to_dim_spot(self, image, x, y, max_iterations=100, patch_size=15):
        """
        Moves a point to a dimmer spot using gradient descent, considering the median of a patch.

        Args:
            image: 2D/3D NumPy array of the image.
            x, y: Initial coordinates of the point.
            max_iterations: Maximum number of descent steps.
            patch_size: Size of the square patch (e.g., 15 for a 15x15 patch).

        Returns:
            (x, y): Coordinates of the dimmest local spot found.
        """
        half_patch = patch_size // 2

        # Get image dimensions and convert to luminance if color
        if len(image.shape) == 3:
            h, w, _ = image.shape
            luminance = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            h, w = image.shape
            luminance = image

        for _ in range(max_iterations):
            # Define patch around the current point
            xmin, xmax = max(0, x - half_patch), min(w, x + half_patch + 1)
            ymin, ymax = max(0, y - half_patch), min(h, y + half_patch + 1)
            patch = luminance[ymin:ymax, xmin:xmax]
            current_value = np.median(patch)

            # Define a 3x3 window around the point
            neighbors = [
                (nx, ny) for nx in range(max(0, x - 1), min(w, x + 2))
                          for ny in range(max(0, y - 1), min(h, y + 2))
                          if (nx, ny) != (x, y)
            ]

            # Find the dimmest neighbor using patch medians
            def patch_median(coord):
                nx, ny = coord
                xmin_n, xmax_n = max(0, nx - half_patch), min(w, nx + half_patch + 1)
                ymin_n, ymax_n = max(0, ny - half_patch), min(h, ny + half_patch + 1)
                neighbor_patch = luminance[ymin_n:ymax_n, xmin_n:xmax_n]
                return np.median(neighbor_patch)

            dimmest_neighbor = min(neighbors, key=patch_median)
            dimmest_value = patch_median(dimmest_neighbor)

            # If the current point is already the dimmest, stop
            if dimmest_value >= current_value:
                break

            # Move to the dimmest neighbor
            x, y = dimmest_neighbor

        return x, y

    def fit_polynomial_gradient(self, image, sample_points, degree=2, patch_size=15):
        """
        Fits a polynomial gradient (up to the specified degree) to the image using sample points.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            degree: Degree of the polynomial (e.g., 1 for linear, 2 for quadratic).
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The polynomial gradient model across the image.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit polynomial model for this channel
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((x**i) * (y**j))
                A = np.column_stack(terms)
                coeffs, _, _, _ = np.linalg.lstsq(A, z, rcond=None)

                # Generate polynomial model
                xx, yy = np.meshgrid(np.arange(w), np.arange(h))
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((xx**i) * (yy**j))
                terms = np.array(terms)
                background[:, :, channel] = np.sum(coeffs[:, None, None] * terms, axis=0)
            return background
        else:  # Grayscale image
            return self.fit_polynomial_gradient(image[:, :, np.newaxis], sample_points, degree, patch_size)

    def generate_sample_points(self, image, num_points=100, exclusion_mask=None):
        """
        Generates sample points for gradient fitting, avoiding exclusion zones.

        Args:
            image: 2D/3D NumPy array of the image.
            num_points: Total number of sample points to generate.
            exclusion_mask: 2D boolean NumPy array where False indicates exclusion.

        Returns:
            points: NumPy array of shape (N, 2) with (x, y) coordinates.
        """
        h, w = image.shape[:2]
        points = []

        # Add border points: 1 in each corner and 5 along each border
        border_margin = 10

        # Corner points
        corners = [
            (border_margin, border_margin),                # Top-left
            (w - border_margin - 1, border_margin),        # Top-right
            (border_margin, h - border_margin - 1),        # Bottom-left
            (w - border_margin - 1, h - border_margin - 1) # Bottom-right
        ]
        for x, y in corners:
            if exclusion_mask is not None and not exclusion_mask[y, x]:
                continue
            x_new, y_new = self.gradient_descent_to_dim_spot(image, x, y)
            if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                continue
            points.append((x_new, y_new))

        # Top and bottom borders
        for x in np.linspace(border_margin, w - border_margin, 5, dtype=int):
            # Top border
            if exclusion_mask is not None and not exclusion_mask[border_margin, x]:
                continue
            x_top, y_top = self.gradient_descent_to_dim_spot(image, x, border_margin)
            if exclusion_mask is not None and not exclusion_mask[y_top, x_top]:
                continue
            points.append((x_top, y_top))
            # Bottom border
            if exclusion_mask is not None and not exclusion_mask[h - border_margin - 1, x]:
                continue
            x_bottom, y_bottom = self.gradient_descent_to_dim_spot(image, x, h - border_margin - 1)
            if exclusion_mask is not None and not exclusion_mask[y_bottom, x_bottom]:
                continue
            points.append((x_bottom, y_bottom))

        # Left and right borders
        for y in np.linspace(border_margin, h - border_margin, 5, dtype=int):
            # Left border
            if exclusion_mask is not None and not exclusion_mask[y, border_margin]:
                continue
            x_left, y_left = self.gradient_descent_to_dim_spot(image, border_margin, y)
            if exclusion_mask is not None and not exclusion_mask[y_left, x_left]:
                continue
            points.append((x_left, y_left))
            # Right border
            if exclusion_mask is not None and not exclusion_mask[y, w - border_margin - 1]:
                continue
            x_right, y_right = self.gradient_descent_to_dim_spot(image, w - border_margin - 1, y)
            if exclusion_mask is not None and not exclusion_mask[y_right, x_right]:
                continue
            points.append((x_right, y_right))

        # Add random points in eligible areas (using quartiles)
        quartiles = self.divide_into_quartiles(image)
        for key, quartile in quartiles.items():
            # Determine the coordinates of the quartile in the full image
            h_quart, w_quart = quartile.shape[:2]
            if "top" in key:
                y_start = 0
            else:
                y_start = h // 2
            if "left" in key:
                x_start = 0
            else:
                x_start = w // 2

            # Create local exclusion mask for the quartile
            if exclusion_mask is not None:
                quart_exclusion_mask = exclusion_mask[y_start:y_start + h_quart, x_start:x_start + w_quart]
            else:
                quart_exclusion_mask = None

            # Convert quartile to grayscale if it has multiple channels
            if quartile.ndim == 3:
                # Assuming the color channels are last, convert to luminance
                quartile_gray = np.dot(quartile[..., :3], [0.2989, 0.5870, 0.1140])
            else:
                quartile_gray = quartile

            # Exclude bright regions
            mask = self.exclude_bright_regions(quartile_gray, exclusion_fraction=0.5)
            if quart_exclusion_mask is not None:
                mask &= quart_exclusion_mask

            eligible_indices = np.argwhere(mask)

            if len(eligible_indices) == 0:
                continue  # Skip if no eligible points in this quartile

            # Ensure we don't request more points than available
            num_points_in_quartile = min(len(eligible_indices), self.num_sample_points // 4)
            selected_indices = eligible_indices[np.random.choice(len(eligible_indices), num_points_in_quartile, replace=False)]

            for idx in selected_indices:
                y_idx, x_idx = idx  # Unpack row to y, x
                y_coord = y_start + y_idx
                x_coord = x_start + x_idx

                # Apply gradient descent to move to a dimmer spot
                x_new, y_new = self.gradient_descent_to_dim_spot(image, x_coord, y_coord)

                # Check if the new point is in exclusion
                if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                    continue  # Skip points in exclusion areas

                points.append((x_new, y_new))

        return np.array(points)

    def fit_background(self, image, sample_points, smooth=0.1, patch_size=15):
        """
        Fits a background model using RBF interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            smooth: Smoothness parameter for the RBF fitting.
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The RBF-based background model.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit RBF for this channel
                rbf = Rbf(x, y, z, function='multiquadric', smooth=smooth, epsilon=1.0)
                grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
                background[:, :, channel] = rbf(grid_x, grid_y)
            return background
        else:  # Grayscale image
            return self.fit_background(image[:, :, np.newaxis], sample_points, smooth, patch_size)

    def calculate_median(self, values):
        """
        Calculates the median of the given values.

        Args:
            values: NumPy array of values.

        Returns:
            median: Median value.
        """
        return np.median(values)

    def calculate_mad(self, values, median):
        """
        Calculates the Median Absolute Deviation (MAD).

        Args:
            values: NumPy array of values.
            median: Median of the values.

        Returns:
            mad: Median Absolute Deviation.
        """
        deviations = np.abs(values - median)
        return np.median(deviations)

    def calculate_noise_weight(self, median, mad):
        """
        Calculates the noise weight based on median and MAD.

        Args:
            median: Median value.
            mad: Median Absolute Deviation.

        Returns:
            noise_weight: Noise weight (0.0 to 1.0).
        """
        if median == 0:
            median = 1e-6  # Avoid division by zero
        noise_factor = 1.0 - (mad / median)
        return max(0.0, min(1.0, noise_factor))

    def calculate_brightness_weight(self, avg_brightness, median_brightness):
        """
        Calculates the brightness weight based on average and median brightness.

        Args:
            avg_brightness: Average brightness of the patch.
            median_brightness: Median brightness of the patch.

        Returns:
            brightness_weight: Brightness weight (0.8 to 1.0).
        """
        if median_brightness == 0:
            median_brightness = 1e-6  # Avoid division by zero
        weight = 1.0 - abs(avg_brightness - median_brightness) / median_brightness
        return max(0.8, min(1.0, weight))  # Limit range for stability

    def calculate_spatial_weight(self, x, y, width, height):
        """
        Calculates the spatial weight based on the position of the point.

        Args:
            x: X-coordinate.
            y: Y-coordinate.
            width: Image width.
            height: Image height.

        Returns:
            spatial_weight: Spatial weight (0.95 to 1.0).
        """
        center_x = width / 2
        center_y = height / 2
        distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
        max_distance = np.sqrt(center_x ** 2 + center_y ** 2)
        normalized_distance = distance / max_distance
        return 0.95 + 0.05 * normalized_distance

    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with False in exclusion areas and True elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.ones(image_shape[:2], dtype=bool)  # Initialize all True

        if not exclusion_polygons:
            return mask  # No exclusions

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                # Scale back to original image coordinates
                x_original = point.x() / self.scale_factor
                y_original = point.y() / self.scale_factor
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Create a single-channel mask
        exclusion_mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Fill the polygons on the exclusion mask
        cv2.fillPoly(exclusion_mask, polygons, 1)  # 1 inside polygons

        # Update the main mask: False inside exclusion polygons
        mask[exclusion_mask == 1] = False

        return mask

    def normalize_image(self, image, target_median):
        """
        Normalizes the image so that its median matches the target median.

        Args:
            image: 2D/3D NumPy array of the image.
            target_median: The desired median value.

        Returns:
            normalized_image: The median-normalized image.
        """
        current_median = np.median(image)
        median_diff = target_median - current_median
        normalized_image = image + median_diff
        return normalized_image


class ImagePreview(QWidget):
    # Define a custom signal that emits the slot number
    closed = pyqtSignal(int)
    
    def __init__(self, image_data, slot, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        # Use the parent's custom slot name if available; otherwise default to "Slot {slot}"
        if parent is not None and hasattr(parent, 'slot_names'):
            custom_name = parent.slot_names.get(slot, f"Slot {slot}")
        else:
            custom_name = f"Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.image_data = image_data  # Numpy array containing the image
        self.zoom_factor = 1.0
        self.slot = slot
        self.is_autostretched = False  # Track if AutoStretch is applied
        self.stretched_image_data = None  # Store stretched image data for visual purposes

        # Create UI components
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidgetResizable(True)
        
        # Install event filter on the scroll area’s viewport
        self.scroll_area.viewport().installEventFilter(self)

        # Convert numpy image data to QImage and display it
        self.update_image_display()

        # Create Zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)  # Zoom range from 1% to 400%
        self.zoom_slider.setValue(100)  # Default zoom (100%)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(lambda: self.adjust_zoom(10))

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(lambda: self.adjust_zoom(-10))

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)

        # AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.clicked.connect(self.apply_autostretch)

        # Create the "Make Active" Button.
        # (We disable it if this slot is already active.)
        self.make_active_button = QPushButton("Make Active")
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            current_active_slot = self.parent().image_manager.current_slot
            if current_active_slot == self.slot:
                self.make_active_button.setEnabled(False)
        self.make_active_button.clicked.connect(self.make_slot_active)
        
        swap_layout = QHBoxLayout()
        swap_layout.addStretch()
        swap_layout.addWidget(self.make_active_button)

        # Layout for zoom controls
        zoom_layout = QHBoxLayout()
        zoom_layout.addWidget(self.zoom_out_button)
        zoom_layout.addWidget(self.zoom_slider)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.fit_to_preview_button)
        zoom_layout.addWidget(self.autostretch_button)

        # Main layout
        layout = QVBoxLayout(self)
        layout.addWidget(self.scroll_area)
        layout.addLayout(zoom_layout)
        layout.addLayout(swap_layout)  # Add swap button layout
        self.setLayout(layout)

        # Variables to handle panning
        self._panning = False
        self._pan_start_x = 0
        self._pan_start_y = 0

    def make_slot_active(self):
        """Sets this preview's slot as the active slot in the image manager."""
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            self.parent().image_manager.set_current_slot(self.slot)
            self.close()  # Optionally close the preview window after setting the active slot
        else:
            QMessageBox.critical(self, "Error", "Parent does not have an image manager.")

    def eventFilter(self, source, event):
        """
        Intercept events on the scroll area's viewport to implement panning and zooming.
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.Wheel:
                # When the wheel is scrolled, adjust zoom.
                if event.angleDelta().y() > 0:
                    self.adjust_zoom(10)  # Zoom in (increase slider value by 10)
                else:
                    self.adjust_zoom(-10)  # Zoom out (decrease slider value by 10)
                event.accept()
                return True  # Indicate the event has been handled.

            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = True
                    self._pan_start_x = event.x()
                    self._pan_start_y = event.y()
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseMove:
                if self._panning and (event.buttons() & Qt.MouseButton.LeftButton):
                    delta_x = event.x() - self._pan_start_x
                    delta_y = event.y() - self._pan_start_y
                    # Adjust scroll bars for panning.
                    new_h = self.scroll_area.horizontalScrollBar().value() - int(delta_x)
                    new_v = self.scroll_area.verticalScrollBar().value() - int(delta_y)
                    self.scroll_area.horizontalScrollBar().setValue(new_h)
                    self.scroll_area.verticalScrollBar().setValue(new_v)
                    # Update the start position.
                    self._pan_start_x = event.x()
                    self._pan_start_y = event.y()
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = False
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                    return True  # Event handled.
        return super().eventFilter(source, event)


    def apply_autostretch(self):
        """Applies AutoStretch to the displayed image for visualization."""
        if self.is_autostretched:
            # If already stretched, reset to the original image
            self.is_autostretched = False
            self.update_image_display()
        else:
            # Perform AutoStretch using the global stretch functions (target median = 0.25) and display it
            self.is_autostretched = True
            self.stretched_image_data = self.stretch_image(self.image_data)
            self.update_image_display()

    def stretch_image(self, image):
        """
        Apply the global stretch functions to the image with a target median of 0.25.
        For grayscale images, use stretch_mono_image.
        For color images, use stretch_color_image.
        """
        target_median = 0.25
        if image.ndim == 2:
            # Grayscale image
            return stretch_mono_image(image, target_median)
        elif image.ndim == 3:
            # Color image (assumes channels are in the last dimension)
            return stretch_color_image(image, target_median)
        else:
            raise ValueError("Unsupported image dimensions: must be 2D or 3D")

    def update_image_display(self):
        """Update the QLabel with the current image."""
        # Use the stretched image data if AutoStretch is applied
        display_image = self.stretched_image_data if self.is_autostretched else self.image_data

        # Normalize image data to [0, 255] and convert to uint8
        if display_image.dtype != np.uint8:
            image_data_normalized = np.clip(display_image * 255, 0, 255).astype('uint8')
        else:
            image_data_normalized = display_image

        if len(image_data_normalized.shape) == 2:  # Grayscale image
            height, width = image_data_normalized.shape
            bytes_per_line = width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        elif len(image_data_normalized.shape) == 3 and image_data_normalized.shape[2] == 3:  # RGB image
            height, width, channels = image_data_normalized.shape
            bytes_per_line = 3 * width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            QMessageBox.warning(self, "Invalid Image", "Unsupported image format for display.")
            return

        pixmap = QPixmap.fromImage(qimage)
        scaled_pixmap = pixmap.scaled(
            self.image_label.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

    def resizeEvent(self, event):
        """Ensure the image scales appropriately when the window is resized."""
        self.update_image_display()
        super().resizeEvent(event)

    def on_zoom_changed(self, value):
        """Handle changes in zoom slider."""
        self.zoom_factor = value / 100.0  # Convert slider value to zoom factor
        self.update_image_display()

    def adjust_zoom(self, delta):
        """Adjust zoom by a specified delta."""
        new_value = self.zoom_slider.value() + delta
        self.zoom_slider.setValue(max(1, min(400, new_value)))

    def fit_to_preview(self):
        """Fit the image to the preview window."""
        self.zoom_factor = 1.0
        self.zoom_slider.setValue(100)
        self.update_image_display()

    def swap_with_slot_zero(self):
        """Swap images between the current slot and Slot 0."""
        confirmation = QMessageBox.question(
            self,
            "Confirm Swap",
            f"Are you sure you want to swap Slot {self.slot} with Slot 0?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            # Debug: Print parent details
            print(f"Attempting to swap Slot {self.slot} with Slot 0.")
            print(f"Parent: {self.parent()}, Type: {type(self.parent())}")
            print(f"Does parent have 'swap_slots'? {'Yes' if hasattr(self.parent(), 'swap_slots') else 'No'}")
            
            # Call the swap_slots method in the parent (AstroEditingSuite)
            if self.parent() and hasattr(self.parent(), 'swap_slots'):
                self.parent().swap_slots(self.slot, 0)

                # Optionally, close the preview window after swapping
                self.close()
            else:
                QMessageBox.critical(self, "Error", "Parent does not have a swap_slots method.")
                print("Error: Parent does not have a swap_slots method.")

    def closeEvent(self, event):
        """Override the close event to emit the custom closed signal."""
        self.closed.emit(self.slot)  # Emit the slot number
        event.accept()  # Proceed with the standard close event

class GraXpertThread(QThread):
    """Thread to execute GraXpert commands."""
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        """Run the GraXpert command and capture output."""
        process = subprocess.Popen(
            self.command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True
        )
        for line in process.stdout:
            self.stdout_signal.emit(line.strip())
        for line in process.stderr:
            self.stderr_signal.emit(line.strip())
        self.finished_signal.emit(process.wait())

class RGBCombinationDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.setWindowTitle("RGB Combination")
        self.setModal(True)
        self.image_manager = image_manager  # Reference to ImageManager
        
        self.r_image_path = None
        self.g_image_path = None
        self.b_image_path = None
        self.use_existing_slots = False
        
        # Create UI components
        self.mode_label = QLabel("Select RGB Combination Mode:")
        
        # Radio buttons for mode selection
        self.load_files_radio = QRadioButton("Load Individual Files")
        self.use_slots_radio = QRadioButton("Use Existing Slots (2, 3, 4)")
        self.load_files_radio.setChecked(True)  # Default mode
        
        # Button group to ensure only one radio button is selected
        self.mode_group = QButtonGroup()
        self.mode_group.addButton(self.load_files_radio)
        self.mode_group.addButton(self.use_slots_radio)
        self.mode_group.buttonClicked.connect(self.update_mode)
        
        # GroupBox for mode selection
        self.mode_groupbox = QGroupBox()
        mode_layout = QVBoxLayout()
        mode_layout.addWidget(self.load_files_radio)
        mode_layout.addWidget(self.use_slots_radio)
        self.mode_groupbox.setLayout(mode_layout)
        
        # Load File Mode Widgets
        self.load_r_button = QPushButton("Load Red Image")
        self.load_r_button.clicked.connect(self.load_r_image)
        
        self.load_g_button = QPushButton("Load Green Image")
        self.load_g_button.clicked.connect(self.load_g_image)
        
        self.load_b_button = QPushButton("Load Blue Image")
        self.load_b_button.clicked.connect(self.load_b_image)
        
        self.r_label = QLabel("Red Image: Not Selected")
        self.g_label = QLabel("Green Image: Not Selected")
        self.b_label = QLabel("Blue Image: Not Selected")
        
        # Layout for Load Files Mode
        self.load_files_layout = QVBoxLayout()
        self.load_files_layout.addWidget(self.r_label)
        self.load_files_layout.addWidget(self.load_r_button)
        self.load_files_layout.addWidget(self.g_label)
        self.load_files_layout.addWidget(self.load_g_button)
        self.load_files_layout.addWidget(self.b_label)
        self.load_files_layout.addWidget(self.load_b_button)
        
        # Use Existing Slots Mode Widgets
        self.use_slots_label = QLabel("Ensure Slots 2, 3, and 4 contain R, G, B channels respectively.")
        self.use_slots_button = QPushButton("Use Slots 2, 3, 4")
        self.use_slots_button.clicked.connect(self.use_existing_slots_method)
        
        # Layout for Use Slots Mode
        self.use_slots_layout = QVBoxLayout()
        self.use_slots_layout.addWidget(self.use_slots_label)
        self.use_slots_layout.addWidget(self.use_slots_button)
        
        # Combine and Cancel buttons
        self.combine_button = QPushButton("Combine")
        self.combine_button.clicked.connect(self.combine_images)
        self.combine_button.setEnabled(False)  # Disabled until required inputs are available
        
        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        
        # Layout for buttons
        buttons_layout = QHBoxLayout()
        buttons_layout.addStretch()
        buttons_layout.addWidget(self.combine_button)
        buttons_layout.addWidget(self.cancel_button)
        
        # Main Layout
        self.main_layout = QVBoxLayout()
        self.main_layout.addWidget(self.mode_label)
        self.main_layout.addWidget(self.mode_groupbox)
        self.main_layout.addLayout(self.load_files_layout)
        self.main_layout.addLayout(self.use_slots_layout)
        self.main_layout.addLayout(buttons_layout)
        
        self.setLayout(self.main_layout)
    
    def update_mode(self):
        """Update the UI based on the selected mode."""
        if self.load_files_radio.isChecked():
            self.use_existing_slots = False
            self.load_r_button.setEnabled(True)
            self.load_g_button.setEnabled(True)
            self.load_b_button.setEnabled(True)
            self.r_label.setEnabled(True)
            self.g_label.setEnabled(True)
            self.b_label.setEnabled(True)
            self.use_slots_button.setEnabled(False)
        else:
            self.use_existing_slots = True
            self.load_r_button.setEnabled(False)
            self.load_g_button.setEnabled(False)
            self.load_b_button.setEnabled(False)
            self.r_label.setEnabled(False)
            self.g_label.setEnabled(False)
            self.b_label.setEnabled(False)
            self.use_slots_button.setEnabled(True)
        
        self.check_inputs()
    
    def load_r_image(self):
        """Load the Red channel image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Red Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.r_image_path = file_path
            self.r_label.setText(f"Red Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_g_image(self):
        """Load the Green channel image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Green Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.g_image_path = file_path
            self.g_label.setText(f"Green Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_b_image(self):
        """Load the Blue channel image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Blue Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.b_image_path = file_path
            self.b_label.setText(f"Blue Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def use_existing_slots_method(self):
        """Use existing images from slots 2, 3, and 4."""
        # Check if slots 2, 3, and 4 have images
        slots = [2, 3, 4]
        images = []
        for slot in slots:
            img = self.image_manager._images.get(slot, None)
            if img is None:
                QMessageBox.warning(
                    self, 
                    "Missing Image", 
                    f"Slot {slot} does not contain an image. Please extract RGB channels first."
                )
                print(f"Slot {slot} is empty. Cannot use existing slots for RGB Combination.")
                return
            images.append(img)
        
        self.r_image_path = None  # Indicate that we're using existing slots
        self.g_image_path = None
        self.b_image_path = None
        self.combine_button.setEnabled(True)  # Enable Combine button as inputs are ready
    
    def check_inputs(self):
        """Enable the Combine button if all required inputs are available."""
        if self.use_existing_slots:
            # Check if slots 2,3,4 have images
            slots = [2, 3, 4]
            for slot in slots:
                if self.image_manager._images.get(slot, None) is None:
                    self.combine_button.setEnabled(False)
                    return
            self.combine_button.setEnabled(True)
        else:
            # Check if all three images are loaded
            if self.r_image_path and self.g_image_path and self.b_image_path:
                self.combine_button.setEnabled(True)
            else:
                self.combine_button.setEnabled(False)
    
    def combine_images(self):
        """Combine the loaded R, G, B images into a single RGB image."""
        try:
            if self.use_existing_slots:
                # Use images from slots 2, 3, 4
                r = self.image_manager._images.get(2).copy()
                g = self.image_manager._images.get(3).copy()
                b = self.image_manager._images.get(4).copy()
            else:
                # Load images using the global load_image function
                r, _, _, _ = load_image(self.r_image_path)
                g, _, _, _ = load_image(self.g_image_path)
                b, _, _, _ = load_image(self.b_image_path)

                if r is None or g is None or b is None:
                    raise ValueError("One or more images failed to load.")

            # Ensure images are grayscale (extract first channel if they are multi-channel)
            if r.ndim == 3 and r.shape[2] > 1:
                print("Red channel image has multiple channels, extracting first channel.")
                r = r[:, :, 0]
            if g.ndim == 3 and g.shape[2] > 1:
                print("Green channel image has multiple channels, extracting first channel.")
                g = g[:, :, 0]
            if b.ndim == 3 and b.shape[2] > 1:
                print("Blue channel image has multiple channels, extracting first channel.")
                b = b[:, :, 0]

            # Ensure all images have the same dimensions
            if not (r.shape == g.shape == b.shape):
                raise ValueError("All images must have the same dimensions.")

            # Stack channels to form RGB image
            rgb_image = np.stack([r, g, b], axis=2)

            self.rgb_image = rgb_image  # Store the combined image
            self.accept()  # Close the dialog with success
            print("RGB Combination successful.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to combine images: {e}")
            print(f"Error in RGB Combination: {e}")


class StarNetThread(QThread):
    # Define signals to communicate with the main thread
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)  # Emit return code

    def __init__(self, command, cwd):
        super().__init__()
        self.command = command
        self.cwd = cwd
        self._process = None  # To handle process termination

    def run(self):
        try:
            # Start the StarNet process
            self._process = subprocess.Popen(
                self.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=self.cwd,
                bufsize=1,
                universal_newlines=True
            )

            # Read stdout and stderr in real-time
            while True:
                output = self._process.stdout.readline()
                if output:
                    self.stdout_signal.emit(output.strip())
                elif self._process.poll() is not None:
                    break

            # Capture remaining stdout
            remaining_stdout, remaining_stderr = self._process.communicate()
            if remaining_stdout:
                self.stdout_signal.emit(remaining_stdout.strip())
            if remaining_stderr:
                self.stderr_signal.emit(remaining_stderr.strip())

            # Emit the return code
            self.finished_signal.emit(self._process.returncode)

        except Exception as e:
            self.stderr_signal.emit(str(e))
            self.finished_signal.emit(-1)

    def stop(self):
        if self._process and self._process.poll() is None:
            self._process.terminate()
            self.wait()

class StarNetDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("StarNet Progress")
        self.setMinimumSize(600, 400)
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout()
        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        layout.addWidget(self.text_edit)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.cancel_process)
        layout.addWidget(self.cancel_button)

        self.setLayout(layout)

    def append_text(self, text):
        self.text_edit.append(text)
        # Auto-scroll to the bottom
        self.text_edit.verticalScrollBar().setValue(self.text_edit.verticalScrollBar().maximum())

    def cancel_process(self):
        self.reject()  # Close the dialog


class AddStarsDialog(QDialog):
    """
    Dialog for configuring and previewing star additions to an image.
    """
    # Define a custom signal to emit the blended image back to the main application
    stars_added = pyqtSignal(np.ndarray)  # Emitting the blended image

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Add Stars to Image")
        self.image_manager = image_manager  # Reference to ImageManager
        self.current_slot = self.image_manager.current_slot
        self.starless_image = None
        self.stars_only_image = None
        self.blended_image = None
        self.scale_factor = 1.0
        self.fitted = False  # To ensure fit_to_preview is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Preview Area
        self.preview_label = QLabel()
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.preview_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.preview_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.preview_label.setScaledContents(False)

        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        main_layout.addWidget(self.scroll_area)

        # Zoom Controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_button = QPushButton("Fit to Preview")
        fit_button.clicked.connect(self.fit_to_preview)

        # Add tooltips for better user guidance
        zoom_in_button.setToolTip("Increase the zoom level of the preview image.")
        zoom_out_button.setToolTip("Decrease the zoom level of the preview image.")
        fit_button.setToolTip("Automatically fit the image to the preview area.")

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Selection Controls
        selection_layout = QGridLayout()

        # Blend Type Dropdown
        blend_type_label = QLabel("Blend Type:")
        self.blend_type_combo = QComboBox()
        self.blend_type_combo.addItems(["Screen", "Add"])
        self.blend_type_combo.currentIndexChanged.connect(self.update_preview)
        self.blend_type_combo.setToolTip("Select the blend type to apply.")

        selection_layout.addWidget(blend_type_label, 0, 0)
        selection_layout.addWidget(self.blend_type_combo, 0, 1)

        # Starless Image Selection
        starless_label = QLabel("Starless Image:")
        self.starless_combo = QComboBox()
        self.populate_slot_combo(self.starless_combo)
        self.starless_combo.currentIndexChanged.connect(self.load_starless_image)
        starless_file_button = QPushButton("Load from File")
        starless_file_button.clicked.connect(lambda: self.load_image_from_file(source='starless'))
        starless_file_button.setToolTip("Load a starless image from your filesystem.")

        selection_layout.addWidget(starless_label, 1, 0)
        selection_layout.addWidget(self.starless_combo, 1, 1)
        selection_layout.addWidget(starless_file_button, 1, 2)

        # Stars-Only Image Selection
        stars_only_label = QLabel("Stars-Only Image:")
        self.stars_only_combo = QComboBox()
        self.populate_slot_combo(self.stars_only_combo)
        self.stars_only_combo.currentIndexChanged.connect(self.load_stars_only_image)
        stars_only_file_button = QPushButton("Load from File")
        stars_only_file_button.clicked.connect(lambda: self.load_image_from_file(source='stars_only'))
        stars_only_file_button.setToolTip("Load a stars-only image from your filesystem.")

        selection_layout.addWidget(stars_only_label, 2, 0)
        selection_layout.addWidget(self.stars_only_combo, 2, 1)
        selection_layout.addWidget(stars_only_file_button, 2, 2)

        main_layout.addLayout(selection_layout)

        # Blend Ratio Slider
        blend_ratio_layout = QHBoxLayout()
        blend_ratio_label = QLabel("Blend Ratio (Screen/Add Intensity):")
        self.blend_ratio_slider = QSlider(Qt.Orientation.Horizontal)
        self.blend_ratio_slider.setMinimum(0)
        self.blend_ratio_slider.setMaximum(100)
        self.blend_ratio_slider.setValue(100)  # Default to full blend type effect
        self.blend_ratio_slider.setTickInterval(10)
        self.blend_ratio_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.blend_ratio_slider.valueChanged.connect(self.update_preview)
        self.blend_ratio_slider.setToolTip("Adjust the intensity of the selected blend type.")

        blend_ratio_layout.addWidget(blend_ratio_label)
        blend_ratio_layout.addWidget(self.blend_ratio_slider)

        main_layout.addLayout(blend_ratio_layout)

        # Action Buttons
        action_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_blend)
        apply_button.setToolTip("Apply the blended image to the current slot.")
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        cancel_button.setToolTip("Cancel and close the dialog without applying changes.")

        action_layout.addStretch()
        action_layout.addWidget(apply_button)
        action_layout.addWidget(cancel_button)

        main_layout.addLayout(action_layout)

        self.setLayout(main_layout)
        self.setMinimumSize(800, 600)

    def populate_slot_combo(self, combo_box):
        """
        Populates a QComboBox with available image slots from the ImageManager.
        Uses the custom slot names if they have been renamed.
        """
        combo_box.clear()
        # "Select Slot" item, with no slot data
        combo_box.addItem("Select Slot", None)

        parent = self.parent()  # The parent might have slot_names
        for slot in range(self.image_manager.max_slots):
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                if parent is not None and hasattr(parent, "slot_names"):
                    # Use the renamed slot if it exists; otherwise default to "Slot {slot}"
                    name = parent.slot_names.get(slot, f"Slot {slot}")
                else:
                    name = f"Slot {slot}"

                # --> Add the item with the *display text* = name and *data* = slot index
                combo_box.addItem(name, slot)

        # Option to load from file, store a sentinel like "file" or -1
        combo_box.addItem("Load from File", "file")


    def load_image_from_file(self, source):
        """
        Loads an image from a file for either starless or stars-only.
        Utilizes the global load_image method.
        """
        filename, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {'Starless' if source == 'starless' else 'Stars-Only'} Image",
            "",
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.jpg *.jpeg *.raw *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if filename:
            # Utilize the global load_image function
            image, original_header, bit_depth, is_mono = load_image(filename)
            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the selected image.")
                return

            # Assign to the appropriate variable
            if source == 'starless':
                self.starless_image = image
                self.starless_combo.setCurrentIndex(self.starless_combo.count() - 1)  # Select "Load from File"
                print(f"Starless image loaded from file: {filename}")
            elif source == 'stars_only':
                self.stars_only_image = image
                self.stars_only_combo.setCurrentIndex(self.stars_only_combo.count() - 1)  # Select "Load from File"
                print(f"Stars-only image loaded from file: {filename}")

            self.update_preview()

    def load_starless_image(self):
        """Loads the starless image based on the selection in the combo box."""
        selected_data = self.starless_combo.currentData()

        if selected_data is None:
            # This is the "Select Slot" item
            self.starless_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button, so do nothing here
            pass

        else:
            # Here, selected_data should be the integer slot index
            slot = selected_data  
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.starless_image = image.copy()
                print(f"Starless image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.starless_image = None

        self.update_preview()


    def load_stars_only_image(self):
        """Loads the stars-only image based on the selection in the combo box."""
        selected_data = self.stars_only_combo.currentData()

        if selected_data is None:
            # "Select Slot"
            self.stars_only_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button
            pass

        else:
            slot = selected_data
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.stars_only_image = image.copy()
                print(f"Stars-only image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.stars_only_image = None

        self.update_preview()
        
    def blend_images(self):
        """
        Blends the starless and stars-only images based on the selected method and blend ratio.
        Applies the mask to the blended image.
        Returns the final blended image.
        """
        if self.starless_image is None or self.stars_only_image is None:
            return None

        # Ensure both images have the same dimensions
        if self.starless_image.shape != self.stars_only_image.shape:
            QMessageBox.critical(self, "Error", "Images have different dimensions. Please select matching images.")
            return None

        blend_type = self.blend_type_combo.currentText()
        blend_ratio = self.blend_ratio_slider.value() / 100.0  # Convert to [0,1]

        # Compute blended image based on blend type
        if blend_type == "Screen":
            blended_type = self.starless_image + self.stars_only_image - (self.starless_image * self.stars_only_image)
        elif blend_type == "Add":
            blended_type = self.starless_image + self.stars_only_image
        else:
            blended_type = self.starless_image.copy()

        # Apply blend ratio to control the intensity of the blend type
        # blended = (1 - blend_ratio) * starless + blend_ratio * blended_type
        blended = (1 - blend_ratio) * self.starless_image + blend_ratio * blended_type

        # Clip the result to [0,1]
        blended = np.clip(blended, 0.0, 1.0)

        # Retrieve the mask for the current slot
        mask = self.image_manager.mask_manager._masks.get(self.current_slot, None)

        if mask is not None:
            # Ensure mask has the same dimensions as images
            if mask.shape != self.starless_image.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match image dimensions.")
                return None

            # Convert mask to float32 and normalize to [0,1]
            if mask.dtype != np.float32:
                mask = mask.astype('float32') / 255.0

            # If mask has multiple channels, convert to single channel
            if mask.ndim == 3:
                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

            # Expand mask dimensions to match image channels if necessary
            if self.starless_image.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=2)
                mask = np.repeat(mask, self.starless_image.shape[2], axis=2)

            # Ensure mask values are in [0,1]
            mask = np.clip(mask, 0.0, 1.0)

            # Apply the mask to blend the images
            final_image = self.starless_image * (1 - mask) + mask * blended
            final_image = np.clip(final_image, 0.0, 1.0)
            print("Applied mask to the blended image.")
        else:
            # If no mask is applied, use the blended image as final
            final_image = blended
            print("No mask applied. Using blended image as final image.")

        return final_image

    def update_preview(self):
        """
        Updates the preview area with the current blended image while maintaining zoom and scroll position.
        """
        final_image = self.blend_images()
        if final_image is not None:
            self.blended_image = final_image.copy()

            # Convert final image to QPixmap
            pixmap = self.convert_to_pixmap(final_image)

            # Store current scroll positions
            h_scroll = self.scroll_area.horizontalScrollBar().value()
            v_scroll = self.scroll_area.verticalScrollBar().value()

            # Scale the pixmap based on scale_factor
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.scale_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )

            # Update the preview label with the scaled pixmap
            self.preview_label.setPixmap(scaled_pixmap)
            self.preview_label.adjustSize()

            # Restore scroll positions
            self.scroll_area.horizontalScrollBar().setValue(h_scroll)
            self.scroll_area.verticalScrollBar().setValue(v_scroll)
            print("Updated preview with the final blended image.")
        else:
            self.preview_label.clear()
            print("Cleared preview due to missing images or errors.")

    def convert_to_pixmap(self, image):
        """
        Converts a numpy image array to QPixmap for display.
        """
        # Ensure image is in [0,1] range
        image = np.clip(image, 0, 1)

        # Convert to 8-bit
        image_8bit = (image * 255).astype(np.uint8)

        # Handle grayscale and RGB images
        if image_8bit.ndim == 2:
            # Grayscale
            q_image = QImage(
                image_8bit.data,
                image_8bit.shape[1],
                image_8bit.shape[0],
                image_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        elif image_8bit.ndim == 3:
            if image_8bit.shape[2] == 3:
                # RGB
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGB888
                )
            elif image_8bit.shape[2] == 4:
                # RGBA
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGBA8888
                )
            else:
                # Unsupported format
                QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
                return QPixmap()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
            return QPixmap()

        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        """Zoom in on the preview image."""
        self.scale_factor *= 1.25
        self.update_image()
        print(f"Zoomed in. Current scale factor: {self.scale_factor}")

    def zoom_out(self):
        """Zoom out of the preview image."""
        self.scale_factor /= 1.25
        self.update_image()
        print(f"Zoomed out. Current scale factor: {self.scale_factor}")

    def fit_to_preview(self):
        """Fit the blended image to the preview area."""
        if self.blended_image is None:
            return
        QTimer.singleShot(0, self.perform_fit_to_preview)

    def perform_fit_to_preview(self):
        """
        Performs the fit to preview action after the event loop has processed show events.
        """
        if self.blended_image is None:
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap = self.convert_to_pixmap(self.blended_image)
        pixmap_size = pixmap.size()

        # Calculate scale factor to fit the image within the viewport while maintaining aspect ratio
        scale_w = viewport_size.width() / pixmap_size.width()
        scale_h = viewport_size.height() / pixmap_size.height()
        scale_factor = min(scale_w, scale_h)

        # Apply the scale factor
        self.scale_factor = scale_factor
        self.update_preview()
        print(f"Fitted image to preview. New scale factor: {self.scale_factor}")

    def scale_image(self, factor):
        """Scales the image by the given factor."""
        if self.blended_image is None:
            return
        self.scale_factor *= factor
        self.update_preview()
        print(f"Scaled image by a factor of {factor}. New scale factor: {self.scale_factor}")

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor.
        """
        if self.blended_image is None:
            return

        pixmap = self.convert_to_pixmap(self.blended_image)
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.preview_label.setPixmap(scaled_pixmap)
        self.preview_label.adjustSize()
        print("Updated image display based on new scale factor.")

    def apply_blend(self):
        """
        Applies the blended image to the main application and closes the dialog.
        """
        if self.blended_image is None:
            QMessageBox.warning(self, "No Blend", "No blended image to apply.")
            print("Apply blend failed: No blended image available.")
            return

        # Emit the blended image
        self.stars_added.emit(self.blended_image)
        self.accept()
        print("Applied blended image and closed dialog.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            QTimer.singleShot(0, self.fit_to_preview)  # Schedule fit_to_preview after the event loop
            self.fitted = True
            print("Dialog shown and image fitted to preview.")

class BackgroundNeutralizationDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Background Neutralization")
        self.setGeometry(100, 100, 800, 600)  # Set appropriate size
        self.initUI()
        self.selection_rect_item = None  # To store the QGraphicsRectItem

    def initUI(self):
        layout = QVBoxLayout()

        # Instruction Label
        instruction_label = QLabel("Draw a sample box on the image to define the neutralization region.")
        layout.addWidget(instruction_label)

        # Graphics View for Image Display
        self.graphics_view = QGraphicsView()
        self.scene = QGraphicsScene()
        self.graphics_view.setScene(self.scene)
        layout.addWidget(self.graphics_view)

        # Load and Display Image
        self.load_image()

        # Initialize Variables for Drawing
        self.origin = QPointF()
        self.current_rect = QRectF()
        self.drawing = False

        # Connect Mouse Events
        self.graphics_view.viewport().installEventFilter(self)

        # Apply and Cancel Buttons
        button_layout = QVBoxLayout()
        apply_button = QPushButton("Apply Neutralization")
        apply_button.clicked.connect(self.apply_neutralization)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)

        self.setLayout(layout)

    def load_image(self):
        """Loads the current image from the ImageManager and displays it."""
        image = self.image_manager.image
        if image is not None:
            # Assuming image is a NumPy array normalized to [0,1]
            height, width, channels = image.shape
            if channels == 3:
                q_image = QImage(
                    (image * 255).astype(np.uint8).tobytes(),
                    width,
                    height,
                    3 * width,
                    QImage.Format.Format_RGB888
                )
            else:
                # Handle other channel numbers if necessary
                q_image = QImage(
                    (image * 255).astype(np.uint8).tobytes(),
                    width,
                    height,
                    QImage.Format.Format_Grayscale8
                )
            pixmap = QPixmap.fromImage(q_image)
            self.pixmap_item = QGraphicsPixmapItem(pixmap)
            self.scene.addItem(self.pixmap_item)
            self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        else:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            self.reject()

    def eventFilter(self, source, event):
        """Handles mouse events for drawing the sample box."""
        if source is self.graphics_view.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin = self.graphics_view.mapToScene(event.pos())
                    # Remove existing selection rectangle if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Remove existing rectangle item if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
                    # Draw the new rectangle
                    pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.DashLine)
                    self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                    self.selection_rect_item.setPen(pen)
                    self.scene.addItem(self.selection_rect_item)
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    # Finalize the rectangle
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Ensure minimum size to avoid accidental small selections
                    min_size = 10  # pixels
                    if self.current_rect.width() < min_size or self.current_rect.height() < min_size:
                        QMessageBox.warning(self, "Selection Too Small", "Please draw a larger selection box.")
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                            self.selection_rect_item = None
                        self.current_rect = QRectF()
                    else:
                        # Redraw the rectangle to ensure it's persistent
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                        pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.SolidLine)
                        self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                        self.selection_rect_item.setPen(pen)
                        self.scene.addItem(self.selection_rect_item)
        return super().eventFilter(source, event)

    def apply_neutralization(self):
        """Applies background neutralization based on the selected sample region."""
        if self.current_rect.isNull():
            QMessageBox.warning(self, "No Selection", "Please draw a sample box on the image.")
            return

        # Map the selection rectangle to image coordinates
        image = self.image_manager.image
        if image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            return

        # Get the image dimensions
        height, width, channels = image.shape
        if channels != 3:
            QMessageBox.warning(self, "Not RGB", "Background Neutralization currently supports only 3-channel RGB images.")
            return

        # Calculate scaling factors to map from scene coords to image coords
        scene_rect = self.scene.sceneRect()
        scale_x = width / scene_rect.width()
        scale_y = height / scene_rect.height()

        # Convert scene coordinates to image coordinates
        x = int(self.current_rect.left() * scale_x)
        y = int(self.current_rect.top() * scale_y)
        w = int(self.current_rect.width() * scale_x)
        h = int(self.current_rect.height() * scale_y)

        # Ensure the rectangle is within image bounds
        x = max(0, min(x, width - 1))
        y = max(0, min(y, height - 1))
        w = max(1, min(w, width - x))
        h = max(1, min(h, height - y))

        # Extract the sample region
        sample_region = image[y:y + h, x:x + w, :]  # Shape: (h, w, 3)

        # Calculate medians for each channel
        medians = np.median(sample_region, axis=(0, 1))  # Shape: (3,)
        # Compute the average of these three medians
        average_median = np.mean(medians)

        # Create a copy of the image for adjustments
        adjusted_image = image.copy()

        # For each RGB channel, compute the difference and apply the formula
        # newChannel = (oldChannel - diff) / (1 - diff),
        # where diff = median(channel) - average_median
        for c in range(3):
            diff = medians[c] - average_median

            # Numerator = old - diff
            # Denominator = 1 - diff
            # Make sure we handle any extreme edge cases where (1 - diff) could be 0 or negative
            numerator = adjusted_image[:, :, c] - diff
            denominator = 1.0 - diff

            # Avoid division by zero or extremely small denominators
            # (in normal circumstances, diff should be well within -1..1 for images in [0,1])
            if abs(denominator) < 1e-8:
                # If this occurs, you could skip or handle differently.
                # For safety, just skip or clamp in real code:
                denominator = 1e-8 if denominator >= 0 else -1e-8

            new_values = numerator / denominator

            # Clip the results to [0, 1] to remain in valid image range
            new_values = np.clip(new_values, 0.0, 1.0)

            adjusted_image[:, :, c] = new_values

        # Update the image in the ImageManager
        self.image_manager.set_image(
            adjusted_image,
            metadata=self.image_manager._metadata[self.image_manager.current_slot]
        )

        # Inform the user
        QMessageBox.information(self, "Success", "Background neutralization applied successfully.")

        # Close the dialog
        self.accept()

class RemoveGreenDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the RemoveGreenDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Remove Green")
        self.initUI()

    def initUI(self):
        """
        Sets up the UI components.
        """
        layout = QVBoxLayout()

        # Instruction Label
        instruction_label = QLabel("Select the amount to remove green noise:")
        layout.addWidget(instruction_label)

        # Slider Configuration
        self.slider = QSlider(Qt.Orientation.Horizontal)
        self.slider.setMinimum(0)
        self.slider.setMaximum(100)  # Represents 0.0 to 1.0
        self.slider.setValue(100)     # Default to 1.0
        self.slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.slider.setTickInterval(10)
        self.slider.valueChanged.connect(self.update_label)
        layout.addWidget(self.slider)

        # Current Value Display
        self.value_label = QLabel("Amount: 1.00")
        layout.addWidget(self.value_label)

        # Buttons Layout
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        cancel_button = QPushButton("Cancel")
        apply_button.clicked.connect(self.apply)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)

        self.setLayout(layout)

    def update_label(self, value):
        """
        Updates the value label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        amount = value / 100.0
        self.value_label.setText(f"Amount: {amount:.2f}")

    def apply(self):
        """
        Applies the Remove Green operation to the image, considering the applied mask.
        """
        amount = self.slider.value() / 100.0

        if self.image_manager.image is not None:
            try:
                # Apply the global SCNR function to reduce green noise
                new_image = apply_average_neutral_scnr(self.image_manager.image, amount=amount)

                # Retrieve the currently applied mask from MaskManager
                applied_mask = self.mask_manager.get_applied_mask()

                if applied_mask is not None:
                    # Ensure mask dimensions match the image dimensions
                    if applied_mask.shape[:2] != self.image_manager.image.shape[:2]:
                        QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                        return

                    # Ensure mask is a float array with values between 0 and 1
                    if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                        applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                    # Clip mask values to [0,1] to avoid unexpected results
                    applied_mask = np.clip(applied_mask, 0.0, 1.0)

                    # If image has multiple channels, ensure mask has the same number of channels
                    if self.image_manager.image.ndim == 3 and applied_mask.ndim == 2:
                        applied_mask = np.expand_dims(applied_mask, axis=-1)

                    # Perform the blending: combined_image = image * (1 - mask) + new_image * mask
                    combined_image = self.image_manager.image * (1 - applied_mask) + new_image * applied_mask

                    # Ensure the combined image's pixel values are within [0,1]
                    combined_image = np.clip(combined_image, 0.0, 1.0)

                    # Update the ImageManager's current image with the combined image
                    self.image_manager.set_image(
                        combined_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot]
                    )
                else:
                    # No mask applied; update with the processed image directly
                    self.image_manager.set_image(
                        new_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot]
                    )

                # Inform the user of the successful operation
                QMessageBox.information(self, "Success", f"Remove Green applied with amount {amount:.2f}")

                # Close the dialog
                self.accept()
            except Exception as e:
                # Handle any errors during processing
                QMessageBox.critical(self, "Error", f"Failed to apply Remove Green:\n{e}")
        else:
            # Inform the user if no image is loaded
            QMessageBox.warning(self, "No Image", "No image loaded to apply Remove Green.")
            self.reject()

class CLAHEDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the CLAHEDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("CLAHE")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # CLAHE Parameters Group
        parameters_group = QGroupBox("CLAHE Parameters")
        parameters_layout = QGridLayout()

        # Clip Limit Slider and Label
        clip_label = QLabel("Clip Limit:")
        self.clip_slider = QSlider(Qt.Orientation.Horizontal)
        self.clip_slider.setMinimum(1)
        self.clip_slider.setMaximum(40)  # Represents 0.1 to 4.0
        self.clip_slider.setValue(20)     # Default 2.0
        self.clip_slider.setTickInterval(1)
        self.clip_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.clip_value_label = QLabel("2.0")  # Initial value
        self.clip_slider.setToolTip("Adjust the clip limit for contrast enhancement. Higher values increase contrast.")

        self.clip_slider.valueChanged.connect(self.update_clip_value)
        self.clip_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(clip_label, 0, 0)
        parameters_layout.addWidget(self.clip_slider, 0, 1)
        parameters_layout.addWidget(self.clip_value_label, 0, 2)

        # Tile Grid Size Slider and Label
        tile_label = QLabel("Tile Grid Size:")
        self.tile_slider = QSlider(Qt.Orientation.Horizontal)
        self.tile_slider.setMinimum(1)
        self.tile_slider.setMaximum(32)
        self.tile_slider.setValue(8)        # Default (8,8)
        self.tile_slider.setTickInterval(1)
        self.tile_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.tile_value_label = QLabel("8")  # Initial value
        self.tile_slider.setToolTip("Adjust the size of grid for histogram equalization. Larger values affect broader areas.")

        self.tile_slider.valueChanged.connect(self.update_tile_value)
        self.tile_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(tile_label, 1, 0)
        parameters_layout.addWidget(self.tile_slider, 1, 1)
        parameters_layout.addWidget(self.tile_value_label, 1, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_clahe)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_clip_value(self, value):
        """
        Updates the clip limit label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        clip_limit = value / 10.0  # 0.1 to 4.0
        self.clip_value_label.setText(f"{clip_limit:.1f}")

    def update_tile_value(self, value):
        """
        Updates the tile grid size label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        self.tile_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current slider values and applied mask.
        """
        if self.original_image is None:
            # Clear the scene and then re-add the pixmap item.
            self.preview_scene.clear()
            self.pixmap_item = QGraphicsPixmapItem()  # Reinitialize pixmap item.
            self.preview_scene.addItem(self.pixmap_item)
            self.preview_scene.addText("No image loaded.")
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                preview_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use CLAHE image directly
                preview_image = clahe_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate CLAHE preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)

        # Convert QRect to QRectF before setting
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_clahe(self):
        """
        Applies CLAHE with current parameters to the main image, considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply CLAHE.")
            self.reject()
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                combined_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot]
                )
            else:
                # No mask applied; update with the CLAHE-processed image directly
                self.image_manager.set_image(
                    clahe_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot]
                )

            # Inform the user of the successful operation
            QMessageBox.information(self, "Success", "CLAHE applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply CLAHE:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders to their default values and updates the preview.
        """
        self.clip_slider.setValue(20)  # Default 2.0
        self.tile_slider.setValue(8)   # Default (8,8)

class MorphologyDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the MorphologyDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Morphological Operations")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # Morphological Parameters Group
        parameters_group = QGroupBox("Morphological Parameters")
        parameters_layout = QGridLayout()

        # Operation Type Selection
        operation_label = QLabel("Operation Type:")
        self.operation_combo = QComboBox()
        self.operation_combo.addItems(["Erosion", "Dilation", "Opening", "Closing"])
        self.operation_combo.setToolTip("Select the type of morphological operation to apply.")
        self.operation_combo.currentTextChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(operation_label, 0, 0)
        parameters_layout.addWidget(self.operation_combo, 0, 1, 1, 2)

        # Kernel Size Slider and Label
        kernel_label = QLabel("Kernel Size:")
        self.kernel_slider = QSlider(Qt.Orientation.Horizontal)
        self.kernel_slider.setMinimum(1)
        self.kernel_slider.setMaximum(31)
        self.kernel_slider.setValue(3)        # Default kernel size
        self.kernel_slider.setTickInterval(2)
        self.kernel_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.kernel_value_label = QLabel("3")  # Initial value
        self.kernel_slider.setToolTip("Adjust the size of the structuring element. Must be an odd number.")

        self.kernel_slider.valueChanged.connect(self.update_kernel_value)
        self.kernel_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(kernel_label, 1, 0)
        parameters_layout.addWidget(self.kernel_slider, 1, 1)
        parameters_layout.addWidget(self.kernel_value_label, 1, 2)

        # Iterations Slider and Label
        iterations_label = QLabel("Iterations:")
        self.iterations_slider = QSlider(Qt.Orientation.Horizontal)
        self.iterations_slider.setMinimum(1)
        self.iterations_slider.setMaximum(10)
        self.iterations_slider.setValue(1)        # Default iterations
        self.iterations_slider.setTickInterval(1)
        self.iterations_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.iterations_value_label = QLabel("1")  # Initial value
        self.iterations_slider.setToolTip("Adjust the number of times the operation is applied.")

        self.iterations_slider.valueChanged.connect(self.update_iterations_value)
        self.iterations_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(iterations_label, 2, 0)
        parameters_layout.addWidget(self.iterations_slider, 2, 1)
        parameters_layout.addWidget(self.iterations_value_label, 2, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_morphology)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image.copy() is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_kernel_value(self, value):
        """
        Updates the kernel size label based on slider position.
        Ensures that the kernel size is always an odd number.
        
        Args:
            value (int): Current value of the slider.
        """
        if value % 2 == 0:
            value += 1  # Ensure kernel size is odd
            if value > self.kernel_slider.maximum():
                value = self.kernel_slider.maximum() - 1 if self.kernel_slider.maximum() % 2 == 0 else self.kernel_slider.maximum()
            self.kernel_slider.setValue(value)
        self.kernel_value_label.setText(str(value))

    def update_iterations_value(self, value):
        """
        Updates the iterations label based on slider position.
        
        Args:
            value (int): Current value of the slider.
        """
        self.iterations_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer to limit the frequency of preview updates.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current parameters and applied mask.
        """
        if self.original_image is None:
            self.pixmap_item.setPixmap(QPixmap())
            self.preview_scene.clear()
            self.preview_scene.addText("No image loaded.")
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1
            self.kernel_slider.setValue(kernel_size)

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                preview_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use morphed image directly
                preview_image = morphed_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate Morphological preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.

        Args:
            image (np.ndarray): Image to display.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))  # Convert QRect to QRectF

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_morphology(self):
        """
        Applies the selected morphological operation with current parameters to the main image,
        considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply morphological operations.")
            self.reject()
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                combined_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot]
                )
            else:
                # No mask applied; update with the morphed image directly
                self.image_manager.set_image(
                    morphed_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot]
                )

            # Inform the user of the successful operation
            QMessageBox.information(self, "Success", f"{self.operation_combo.currentText()} applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply morphological operations:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders and operation type to default values and updates the preview.
        """
        self.operation_combo.setCurrentIndex(0)  # 'Erosion'
        self.kernel_slider.setValue(3)           # Default kernel size
        self.iterations_slider.setValue(1)       # Default iterations

class WhiteBalanceDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("White Balance")
        self.setGeometry(100, 100, 800, 500)  # Adjusted size to remove preview area
        self.initUI()

    def initUI(self):
        main_layout = QVBoxLayout()

        # White Balance Type Selection
        type_label = QLabel("White Balance Type:")
        self.type_combo = QComboBox()
        self.type_combo.addItems(["Star-Based", "Manual", "Auto"])
        self.type_combo.currentTextChanged.connect(self.update_options)

        type_layout = QHBoxLayout()
        type_layout.addWidget(type_label)
        type_layout.addWidget(self.type_combo)
        type_layout.addStretch()

        main_layout.addLayout(type_layout)

        # Standard White Balance Options
        self.standard_widget = QWidget()
        self.standard_layout = QVBoxLayout()

        # Gain Sliders for R, G, B
        gain_group = QGroupBox("Adjust Gain for Each Channel")
        gain_layout = QGridLayout()

        self.r_slider = QSlider(Qt.Orientation.Horizontal)
        self.r_slider.setMinimum(50)
        self.r_slider.setMaximum(150)
        self.r_slider.setValue(100)  # Represents 0.5 to 1.5
        self.r_slider.setTickInterval(10)
        self.r_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.r_label = QLabel("100")

        self.g_slider = QSlider(Qt.Orientation.Horizontal)
        self.g_slider.setMinimum(50)
        self.g_slider.setMaximum(150)
        self.g_slider.setValue(100)
        self.g_slider.setTickInterval(10)
        self.g_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.g_label = QLabel("100")

        self.b_slider = QSlider(Qt.Orientation.Horizontal)
        self.b_slider.setMinimum(50)
        self.b_slider.setMaximum(150)
        self.b_slider.setValue(100)
        self.b_slider.setTickInterval(10)
        self.b_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.b_label = QLabel("100")

        # Connect sliders to update labels
        self.r_slider.valueChanged.connect(lambda val: self.r_label.setText(str(val)))
        self.g_slider.valueChanged.connect(lambda val: self.g_label.setText(str(val)))
        self.b_slider.valueChanged.connect(lambda val: self.b_label.setText(str(val)))

        # Arrange sliders and labels in grid
        gain_layout.addWidget(QLabel("Red Gain:"), 0, 0)
        gain_layout.addWidget(self.r_slider, 0, 1)
        gain_layout.addWidget(self.r_label, 0, 2)

        gain_layout.addWidget(QLabel("Green Gain:"), 1, 0)
        gain_layout.addWidget(self.g_slider, 1, 1)
        gain_layout.addWidget(self.g_label, 1, 2)

        gain_layout.addWidget(QLabel("Blue Gain:"), 2, 0)
        gain_layout.addWidget(self.b_slider, 2, 1)
        gain_layout.addWidget(self.b_label, 2, 2)

        gain_group.setLayout(gain_layout)
        self.standard_layout.addWidget(gain_group)
        self.standard_widget.setLayout(self.standard_layout)
        main_layout.addWidget(self.standard_widget)

        # Star-Based White Balance Options
        self.star_widget = QWidget()
        self.star_layout = QVBoxLayout()
        self.star_widget.setLayout(self.star_layout)
        self.star_widget.hide()  # Hidden initially

        star_info = QLabel("Star-Based White Balance automatically detects stars to adjust colors.")
        self.star_layout.addWidget(star_info)

        # Sensitivity Slider for Star Detection Threshold
        sensitivity_group = QGroupBox("Detection Sensitivity")
        sensitivity_layout = QHBoxLayout()

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(100)
        self.sensitivity_slider.setMaximum(255)
        self.sensitivity_slider.setValue(180)  # Default threshold
        self.sensitivity_slider.setTickInterval(5)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_label = QLabel("Threshold: 180")

        # Connect slider to update label and re-run detection
        self.sensitivity_slider.valueChanged.connect(self.update_sensitivity_label)
        self.sensitivity_slider.valueChanged.connect(self.detect_and_display_stars)

        sensitivity_layout.addWidget(QLabel("Threshold:"))
        sensitivity_layout.addWidget(self.sensitivity_slider)
        sensitivity_layout.addWidget(self.sensitivity_label)
        sensitivity_group.setLayout(sensitivity_layout)
        self.star_layout.addWidget(sensitivity_group)

        # Label to show number of detected stars
        self.star_count_label = QLabel("Detecting stars...")
        self.star_layout.addWidget(self.star_count_label)

        # Image display for detected stars
        self.star_image_label = QLabel()
        self.star_image_label.setFixedSize(800, 500)  # Reduced size as no preview is needed
        self.star_image_label.setStyleSheet("border: 1px solid black;")
        self.star_layout.addWidget(self.star_image_label)

        main_layout.addWidget(self.star_widget)

        # Apply and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_white_balance)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)

        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # **Set initial selection to "Star-Based" and display relevant widgets**
        self.type_combo.setCurrentText("Star-Based")
        self.update_options("Star-Based")

    def update_sensitivity_label(self, value):
        self.sensitivity_label.setText(f"Threshold: {value}")

    def update_options(self, text):
        if text == "Manual":
            self.star_widget.hide()
            self.standard_widget.show()
        elif text == "Auto":
            self.standard_widget.hide()
            self.star_widget.hide()
        elif text == "Star-Based":
            self.standard_widget.hide()
            self.star_widget.show()
            self.star_count_label.setText("Detecting stars...")
            # Trigger star detection and display
            self.detect_and_display_stars()

    def detect_and_display_stars(self):
        try:
            image = self.image_manager.image
            if image is not None:
                threshold = self.sensitivity_slider.value()
                balanced_image, star_count, image_with_stars = apply_star_based_white_balance(image, threshold)
                
                # Convert the image with stars to QImage and then to QPixmap
                height, width, channel = image_with_stars.shape
                bytes_per_line = 3 * width
                q_image = QImage(image_with_stars.data, width, height, bytes_per_line, QImage.Format.Format_BGR888)
                pixmap = QPixmap.fromImage(q_image).scaled(
                    self.star_image_label.width(),
                    self.star_image_label.height(),
                    Qt.AspectRatioMode.KeepAspectRatio
                )
                self.star_image_label.setPixmap(pixmap)
                self.star_count_label.setText(f"Detected {star_count} stars.")
            else:
                self.star_count_label.setText("No image loaded.")
        except Exception as e:
            self.star_count_label.setText("Detection failed.")
            self.star_image_label.clear()
            QMessageBox.critical(self, "Error", f"Failed to detect stars:\n{e}")

    def apply_white_balance(self):
        wb_type = self.type_combo.currentText()

        try:
            image = self.image_manager.image
            if image is not None:
                if wb_type == "Manual":
                    r_gain = self.r_slider.value() / 100.0  # 0.5 to 1.5
                    g_gain = self.g_slider.value() / 100.0
                    b_gain = self.b_slider.value() / 100.0
                    balanced_image = apply_standard_white_balance(image, r_gain, g_gain, b_gain)
                    self.image_manager.update_image(
                        updated_image=balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {})
                    )
                    QMessageBox.information(self, "Success", "Manual White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Auto":
                    balanced_image = apply_auto_white_balance(image)
                    self.image_manager.update_image(
                        updated_image=balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {})
                    )
                    QMessageBox.information(self, "Success", "Auto White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Star-Based":
                    threshold = self.sensitivity_slider.value()
                    balanced_image, star_count, _ = apply_star_based_white_balance(image, threshold)
                    self.image_manager.update_image(
                        updated_image=balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {})
                    )
                    QMessageBox.information(self, "Success", f"Star-Based White Balance applied successfully.\nDetected {star_count} stars.")
                    self.accept()
                else:
                    raise ValueError("Invalid White Balance Type.")
            else:
                QMessageBox.warning(self, "No Image", "No image loaded to apply White Balance.")
                self.reject()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply White Balance:\n{e}")
            self.reject()

class PixelImage:
    def __init__(self, array):
        self.array = array

    def __getitem__(self, channel_index):
        """
        Return a new PixelImage containing only the requested channel (2D array).
        For example, slot0[0] -> red channel, slot0[1] -> green, slot0[2] -> blue.
        """
        # Make sure the requested channel is valid for this image's shape.
        if self.array.ndim < 3:
            raise ValueError("This image has no channel dimension to index.")
        if not (0 <= channel_index < self.array.shape[2]):
            raise IndexError(f"Channel index {channel_index} is out of range for shape {self.array.shape}")
        
        single_channel = self.array[..., channel_index]  # shape (height, width)
        return PixelImage(single_channel)

    def __add__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array + other.array)
        else:
            return PixelImage(self.array + other)
    __radd__ = __add__

    def __sub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array - other.array)
        else:
            return PixelImage(self.array - other)

    def __rsub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array - self.array)
        else:
            return PixelImage(other - self.array)

    def __mul__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array * other.array)
        else:
            return PixelImage(self.array * other)
    __rmul__ = __mul__

    def __truediv__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array / other.array)
        else:
            return PixelImage(self.array / other)

    def __invert__(self):
        # Overload the ~ operator to mean image inversion: 1 - array.
        return PixelImage(1 - self.array)

    def __xor__(self, other):
        # Overload the ^ operator for exponentiation.
        if isinstance(other, PixelImage):
            return PixelImage(self.array ** other.array)
        else:
            return PixelImage(self.array ** other)

    def __rxor__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array ** self.array)
        else:
            return PixelImage(other ** self.array)

    def __repr__(self):
        return f"PixelImage({self.array})"
    
    def __lt__(self, other):
        if isinstance(other, PixelImage):
            return self.array < other.array
        else:
            return self.array < other   

    def __eq__(self, other):
        if isinstance(other, PixelImage):
            return self.array == other.array
        else:
            return self.array == other

class PixelMathDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Pixel Math")
        
        # Attempt to retrieve QSettings from the parent
        if parent is not None and hasattr(parent, "settings"):
            self.settings = parent.settings
        else:
            self.settings = None

        self.favorites = []
        self.initUI()
        self.load_favorites()

    def initUI(self):
        main_layout = QVBoxLayout(self)

        instruction = QLabel(
            "Enter a pixel math expression using image slot variables.\n"
            "Examples:\n"
            "  (slot0 + slot1) / 2\n"
            "  slot0 - med(slot0)\n"
            "  ~(~slot0 * ~slot1)\n"
            "  slot0 - mean(slot0)\n"
            "  min(slot0) + max(slot0)\n"
            "  log(slot0)\n"
            "  iff(slot0 < med(slot0), 0, 1)\n"
            "  mtf(slot0, 0.25)   <-- midtones transform\n\n"
            "You may also use your renamed slot names (e.g., stars_image, starless_image).\n"
            "Note: The '~' operator means image inversion (i.e., 1 - image),\n"
            "      '^' is overloaded for exponentiation, and 'iff' is a conditional function.\n"
            "      For Separate Expressions use channel indexes ie slot0[0] + slot0[1] etc.\n"
        )
        main_layout.addWidget(instruction)

        # --- Radio Buttons for Single vs. Separate ---
        mode_layout = QHBoxLayout()
        self.single_expr_radio = QRadioButton("Single Expression")
        self.separate_expr_radio = QRadioButton("Separate Expressions (R, G, B)")
        self.single_expr_radio.setChecked(True)
        
        self.mode_button_group = QButtonGroup()
        self.mode_button_group.addButton(self.single_expr_radio)
        self.mode_button_group.addButton(self.separate_expr_radio)
        self.mode_button_group.buttonClicked.connect(self.on_mode_changed)
        
        mode_layout.addWidget(self.single_expr_radio)
        mode_layout.addWidget(self.separate_expr_radio)
        main_layout.addLayout(mode_layout)

        # --- Single Expression Field ---
        self.single_expression_edit = QPlainTextEdit()
        self.single_expression_edit.setPlaceholderText("Enter single pixel math expression")
        self.single_expression_edit.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        main_layout.addWidget(self.single_expression_edit)

        # --- Separate (Per-Channel) Expressions (Tab Widget) ---
        self.tab_widget = QTabWidget()
        self.tab_widget.setVisible(False)  # hidden by default
        # Create a tab for R, G, B
        self.red_edit = QPlainTextEdit()
        self.red_edit.setPlaceholderText("Expression for Red channel")
        self.green_edit = QPlainTextEdit()
        self.green_edit.setPlaceholderText("Expression for Green channel")
        self.blue_edit = QPlainTextEdit()
        self.blue_edit.setPlaceholderText("Expression for Blue channel")

        # Optionally set the same stylesheet on these fields:
        for editor in (self.red_edit, self.green_edit, self.blue_edit):
            editor.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        # Add them as tabs
        tab_r = QWidget()
        tab_r_layout = QVBoxLayout(tab_r)
        tab_r_layout.addWidget(self.red_edit)
        self.tab_widget.addTab(tab_r, "Red")

        tab_g = QWidget()
        tab_g_layout = QVBoxLayout(tab_g)
        tab_g_layout.addWidget(self.green_edit)
        self.tab_widget.addTab(tab_g, "Green")

        tab_b = QWidget()
        tab_b_layout = QVBoxLayout(tab_b)
        tab_b_layout.addWidget(self.blue_edit)
        self.tab_widget.addTab(tab_b, "Blue")

        main_layout.addWidget(self.tab_widget)

        # --- Favorites area ---
        favorites_layout = QHBoxLayout()
        self.favorites_dropdown = QComboBox()
        self.favorites_dropdown.addItem("Select a favorite expression")
        self.favorites_dropdown.currentTextChanged.connect(self.load_favorite)
        favorites_layout.addWidget(self.favorites_dropdown)

        self.save_favorite_button = QPushButton("Save as Favorite")
        self.save_favorite_button.clicked.connect(self.save_favorite)
        favorites_layout.addWidget(self.save_favorite_button)

        # Remove Favorite Button
        self.remove_favorite_button = QPushButton("Remove Favorite")
        self.remove_favorite_button.clicked.connect(self.remove_selected_favorite)
        favorites_layout.addWidget(self.remove_favorite_button)

        # Clear All Favorites Button
        self.clear_all_favorites_button = QPushButton("Clear All Favorites")
        self.clear_all_favorites_button.clicked.connect(self.clear_all_favorites)
        favorites_layout.addWidget(self.clear_all_favorites_button)

        main_layout.addLayout(favorites_layout)

        # --- Buttons (OK, Cancel, Help) ---
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.apply_pixel_math)
        buttons.rejected.connect(self.reject)
        help_button = buttons.addButton("Help", QDialogButtonBox.ButtonRole.HelpRole)
        help_button.clicked.connect(self.show_help)
        main_layout.addWidget(buttons)

        self.setLayout(main_layout)

    def on_mode_changed(self, button):
        """
        Switch UI between single expression mode and separate (R,G,B) mode.
        """
        if button == self.single_expr_radio:
            # Single expression
            self.single_expression_edit.setVisible(True)
            self.tab_widget.setVisible(False)
        else:
            # Separate (R,G,B)
            self.single_expression_edit.setVisible(False)
            self.tab_widget.setVisible(True)

    # --- Favorite Expressions Persistence ---
    def load_favorites(self):
        if self.settings:
            favorites_list = self.settings.value("pixelmath_favorites", [])
            if isinstance(favorites_list, str):
                try:
                    favorites_list = json.loads(favorites_list)
                except Exception:
                    favorites_list = []
            elif not isinstance(favorites_list, list):
                favorites_list = list(favorites_list)
            self.favorites = favorites_list
        else:
            self.favorites = []
        
        self.favorites_dropdown.clear()
        self.favorites_dropdown.addItem("Select a favorite expression")
        for fav in self.favorites:
            self.favorites_dropdown.addItem(fav)

    def save_favorite(self):
        """
        Save the currently visible expression(s) as a favorite.
        For simplicity, we’ll just store the single or the RGB triple.
        """
        if self.single_expr_radio.isChecked():
            expr = self.single_expression_edit.toPlainText().strip()
        else:
            # For separate mode, maybe store the R/G/B together in some notation:
            r_expr = self.red_edit.toPlainText().strip()
            g_expr = self.green_edit.toPlainText().strip()
            b_expr = self.blue_edit.toPlainText().strip()
            expr = f"[R]{r_expr} | [G]{g_expr} | [B]{b_expr}"

        if expr and expr not in self.favorites:
            self.favorites.append(expr)
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.favorites_dropdown.addItem(expr)
            QMessageBox.information(self, "Saved as Favorite", "Expression saved to favorites.")
        else:
            QMessageBox.warning(self, "Invalid Expression", "Expression is empty or already in favorites.")

    def remove_selected_favorite(self):
        """
        Remove the currently selected favorite from the dropdown and from self.favorites.
        """
        current_text = self.favorites_dropdown.currentText()
        if current_text == "Select a favorite expression":
            QMessageBox.information(self, "Remove Favorite", "No valid favorite is selected.")
            return

        # Confirm removal
        reply = QMessageBox.question(
            self, 
            "Remove Favorite", 
            f"Are you sure you want to remove '{current_text}' from favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, 
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            if current_text in self.favorites:
                self.favorites.remove(current_text)
                if self.settings:
                    self.settings.setValue("pixelmath_favorites", self.favorites)
                self.load_favorites()  # reload the dropdown
                QMessageBox.information(self, "Remove Favorite", "Favorite removed successfully.")
            else:
                QMessageBox.warning(self, "Remove Favorite", "Favorite not found in list.")

    def clear_all_favorites(self):
        """
        Clear all favorites after a confirmation.
        """
        reply = QMessageBox.question(
            self,
            "Clear All Favorites",
            "Are you sure you want to remove ALL favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.favorites.clear()
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.load_favorites()
            QMessageBox.information(self, "Clear All Favorites", "All favorites have been removed.")

    def load_favorite(self, favorite_expr):
        """
        If the user picks a favorite that has the [R] [G] [B] format,
        parse it into the separate text fields. Otherwise, treat it as a single expression.
        """
        if favorite_expr == "Select a favorite expression":
            return

        # Quick detection to see if it has the [R] or [G] or [B] tokens
        if "[R]" in favorite_expr or "[G]" in favorite_expr or "[B]" in favorite_expr:
            # Switch to separate mode
            self.separate_expr_radio.setChecked(True)
            self.on_mode_changed(self.separate_expr_radio)

            # Attempt to split them out
            # Simple approach: [R] ... | [G] ... | [B] ...
            parts = favorite_expr.split("|")
            r_expr = ""
            g_expr = ""
            b_expr = ""
            for p in parts:
                p = p.strip()
                if p.startswith("[R]"):
                    r_expr = p[3:].strip()
                elif p.startswith("[G]"):
                    g_expr = p[3:].strip()
                elif p.startswith("[B]"):
                    b_expr = p[3:].strip()

            self.red_edit.setPlainText(r_expr)
            self.green_edit.setPlainText(g_expr)
            self.blue_edit.setPlainText(b_expr)
        else:
            # Single expression
            self.single_expr_radio.setChecked(True)
            self.on_mode_changed(self.single_expr_radio)
            self.single_expression_edit.setPlainText(favorite_expr)
    # --- Pixel Math Evaluation ---
    def show_help(self):
        help_text = (
            "Allowed Operators:\n"
            "  +, -, *, /: Standard arithmetic operations\n"
            "  ^: Exponentiation (overloaded; e.g., slot0 ^ 2 means slot0**2)\n"
            "  ~: Image inversion (i.e., 1 - image)\n"
            "  <, ==: Elementwise comparisons (slot0 < med(slot0))\n\n"
            "Allowed Functions:\n"
            "  med(x), mean(x), min(x), max(x), std(x), mad(x), log(x)\n"
            "  iff(condition, a, b): elementwise conditional\n"
            "  mtf(x, m): Midtones transform\n\n"
            "Variables:\n"
            "  img: The current image (replicated to RGB if needed)\n"
            "  slot0, slot1, ...: image slots\n"
            "  Channels can be accessed via [0],[1],[2]. e.g. slot0[0]\n\n"
            "Notes:\n"
            "  - Grayscale images automatically get 3 channels.\n"
            "  - For separate expressions mode, each expression is evaluated for its channel.\n"
        )
        QMessageBox.information(self, "Pixel Math Help", help_text)

    # Updated helper functions (med, mean, min, max, std, mad, log, iff, mtf) remain unchanged...
    def med(self, x):
        """
        Return a PixelImage where each channel (if present) is replaced by its median value.
        If x is 2D, we replace that entire 2D array with its median.
        """
        if isinstance(x, PixelImage):
            arr = x.array
            if arr.ndim == 2:
                # Single-channel (2D)
                median_val = np.median(arr)
                # Make a new 2D array with every pixel = median_val
                new_arr = np.full_like(arr, median_val)
                return PixelImage(new_arr)
            elif arr.ndim == 3:
                # 3D: compute per-channel medians
                med_vals = np.median(arr, axis=(0, 1))  # shape (3,)
                new_arr = np.empty_like(arr)
                for ch in range(arr.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return PixelImage(new_arr)
            else:
                # Some unexpected dimensionality
                raise ValueError(f"med() got array with unsupported ndim={arr.ndim}")
        else:
            # If x is not a PixelImage but a raw np.ndarray, handle that scenario similarly:
            if x.ndim == 2:
                median_val = np.median(x)
                new_arr = np.full_like(x, median_val)
                return new_arr
            elif x.ndim == 3:
                med_vals = np.median(x, axis=(0,1))
                new_arr = np.empty_like(x)
                for ch in range(x.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return new_arr
            else:
                # 1D or something else
                return np.median(x)
            
    def mean(self, x):
        """Replace each channel (or the single channel) by its mean value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            # Single channel (2D)
            val = np.mean(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            # 3-channel
            means = np.mean(arr, axis=(0, 1))  # shape=(3,)
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = means[ch]
        else:
            # 1D or something else—decide how you want to handle it or just return arr
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def min(self, x):
        """Replace each channel (or the single channel) by its min value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.min(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            mins = np.min(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = mins[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def max(self, x):
        """Replace each channel (or the single channel) by its max value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.max(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            maxs = np.max(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = maxs[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def std(self, x):
        """Replace each channel (or the single channel) by its std value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.std(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            stds = np.std(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = stds[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def mad(self, x):
        """Replace each channel (or the single channel) by its median absolute deviation."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            m = np.median(arr)
            mad_val = np.median(np.abs(arr - m))
            new_arr = np.full(arr.shape, mad_val, dtype=arr.dtype)
        elif arr.ndim == 3:
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                channel = arr[..., ch]
                m = np.median(channel)
                mad_val = np.median(np.abs(channel - m))
                new_arr[..., ch] = mad_val
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def log(self, x):
        if isinstance(x, PixelImage):
            return PixelImage(np.log(x.array))
        else:
            return np.log(x)

    def iff(self, condition, a, b):
        if isinstance(condition, PixelImage):
            cond_val = condition.array
        else:
            cond_val = condition

        if isinstance(a, PixelImage):
            a_val = a.array
        else:
            a_val = a

        if isinstance(b, PixelImage):
            b_val = b.array
        else:
            b_val = b

        result = np.where(cond_val, a_val, b_val)
        if isinstance(condition, PixelImage) or isinstance(a, PixelImage) or isinstance(b, PixelImage):
            return PixelImage(result)
        else:
            return result

    def mtf(self, x, m):
        if isinstance(x, PixelImage):
            arr = x.array
        else:
            arr = x
        with np.errstate(divide='ignore', invalid='ignore'):
            new_arr = ((m - 1) * arr) / (((2 * m - 1) * arr) - m)
            new_arr = np.nan_to_num(new_arr, nan=0.0, posinf=1.0, neginf=0.0)
        if isinstance(x, PixelImage):
            return PixelImage(new_arr)
        else:
            return new_arr

    def evaluate_multiline_expression(self, expr, safe_namespace):
        """
        Allows multiple lines in the user expression.
        - All but the last line are executed with `exec`, so they can contain assignments.
        - The last line is evaluated with `eval` to produce the final result.
        """

        # Split into lines and strip out empty ones
        lines = [line.strip() for line in expr.split('\n') if line.strip()]
        if not lines:
            raise ValueError("No expression provided.")

        # Exec each line except the last
        for line in lines[:-1]:
            exec(line, {"__builtins__": None}, safe_namespace)

        # Evaluate the last line, which must be an expression returning a result
        final_line = lines[-1]
        result = eval(final_line, {"__builtins__": None}, safe_namespace)
        return result

    def apply_pixel_math(self):
        """
        Evaluates the user-entered expression(s) and updates the current image slot.
        If single_expr_radio is checked, we do the usual single-expression approach.
        If separate_expr_radio is checked, we evaluate three expressions (R, G, B).
        """
        if self.single_expr_radio.isChecked():
            # Single expression mode
            expr = self.single_expression_edit.toPlainText().strip()
            if not expr:
                QMessageBox.warning(self, "No Expression", "Please enter a valid pixel math expression.")
                return
            
            try:
                # Evaluate single expression
                result = self.evaluate_expression(expr)

                # Convert PixelImage -> array if needed
                if isinstance(result, PixelImage):
                    new_img = result.array
                else:
                    new_img = result

                # If it's a scalar, fill the current image shape
                current_img = self.image_manager.image
                if current_img.ndim == 2:
                    current_img = np.stack([current_img]*3, axis=-1)
                if np.isscalar(new_img):
                    new_img = np.full(current_img.shape, new_img, dtype=current_img.dtype)

                # Update the image
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = expr
                self.image_manager.set_image(new_img, metadata)
                QMessageBox.information(self, "Pixel Math", "Pixel math operation applied successfully.")
                self.accept()
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

        else:
            # Separate expressions mode
            expr_r = self.red_edit.toPlainText().strip()
            expr_g = self.green_edit.toPlainText().strip()
            expr_b = self.blue_edit.toPlainText().strip()

            if not expr_r and not expr_g and not expr_b:
                QMessageBox.warning(self, "No Expression", 
                                    "Please enter a valid expression for at least one channel.")
                return

            try:
                # Evaluate each channel expression or treat as 0 if blank
                r_result = self.evaluate_expression(expr_r) if expr_r else 0
                g_result = self.evaluate_expression(expr_g) if expr_g else 0
                b_result = self.evaluate_expression(expr_b) if expr_b else 0

                # Convert PixelImages to arrays
                if isinstance(r_result, PixelImage):
                    r_result = r_result.array
                if isinstance(g_result, PixelImage):
                    g_result = g_result.array
                if isinstance(b_result, PixelImage):
                    b_result = b_result.array

                # Validate shapes: must be scalar or 2D
                def ensure_2d_or_scalar(arr, channel_name):
                    if np.isscalar(arr):
                        return
                    if arr.ndim == 3:
                        raise ValueError(
                            f"Expression for {channel_name} returned a 3D array. "
                            "In separate expressions mode, please specify a single channel, e.g. slot0[0]."
                        )

                ensure_2d_or_scalar(r_result, "Red")
                ensure_2d_or_scalar(g_result, "Green")
                ensure_2d_or_scalar(b_result, "Blue")

                # Now get shape of current image for stacking
                current_img = self.image_manager.image
                if current_img is None:
                    QMessageBox.warning(self, "No Image", "There is no image loaded to operate on.")
                    return
                if current_img.ndim == 2:
                    current_img = np.stack([current_img]*3, axis=-1)
                
                h, w, _ = current_img.shape

                # If scalar, fill to (H,W)
                if np.isscalar(r_result):
                    r_result = np.full((h, w), r_result, dtype=current_img.dtype)
                if np.isscalar(g_result):
                    g_result = np.full((h, w), g_result, dtype=current_img.dtype)
                if np.isscalar(b_result):
                    b_result = np.full((h, w), b_result, dtype=current_img.dtype)

                # Stack
                combined = np.stack([r_result, g_result, b_result], axis=-1)

                # Update the slot
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = f"R:{expr_r}, G:{expr_g}, B:{expr_b}"
                self.image_manager.set_image(combined, metadata)

                QMessageBox.information(self, "Pixel Math", 
                                        "Pixel math operation (per-channel) applied successfully.")
                self.accept()

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

    def evaluate_expression(self, expr):
        """
        Evaluates a single expression in the restricted environment (safe_namespace).
        Returns a PixelImage or numpy array. 
        """
        if not expr:
            return 0  # If no expression, treat as 0

        # Create a safe namespace
        safe_namespace = {
            "np": np,
            "med": self.med,
            "mean": self.mean,
            "min": self.min,
            "max": self.max,
            "std": self.std,
            "mad": self.mad,
            "log": self.log,
            "iff": self.iff,
            "mtf": self.mtf,
        }

        # Insert current image as 'img'
        current_img = self.image_manager.image
        if current_img is None:
            raise ValueError("No current image loaded.")
        if current_img.ndim == 2:
            current_img = np.stack([current_img]*3, axis=-1)
        safe_namespace["img"] = PixelImage(current_img)

        # Insert image slots as slot0, slot1, ...
        max_slots = self.image_manager.max_slots
        parent = self.parent()
        for i in range(max_slots):
            img = self.image_manager._images.get(i, None)
            if img is not None:
                if img.ndim == 2:
                    img = np.stack([img]*3, axis=-1)
                pix_img = PixelImage(img)
                safe_namespace[f"slot{i}"] = pix_img
                if parent is not None and hasattr(parent, "slot_names"):
                    custom_name = parent.slot_names.get(i, None)
                    if custom_name:
                        safe_namespace[custom_name] = pix_img

        # Evaluate
            # Instead of a direct `eval`, we now do:
        return self.evaluate_multiline_expression(expr, safe_namespace)
        if isinstance(result, PixelImage):
            return result
        else:
            return result  # Could be scalar or ndarray

class XISFViewer(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.image_data = None
        self.file_meta = None
        self.image_meta = None
        self.is_mono = False
        self.bit_depth = None
        self.scale_factor = 1.0
        self.dragging = False
        self.drag_start_pos = QPoint()
        self.autostretch_enabled = False
        self.current_pixmap = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
    
    def initUI(self):
        main_layout = QHBoxLayout()
        splitter = QSplitter(Qt.Orientation.Horizontal)
        splitter.setHandleWidth(5)



        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Left side layout for image display and save button
        left_widget = QWidget()        
        left_layout = QVBoxLayout(left_widget)
        left_widget.setMinimumSize(600, 600)
        
        self.load_button = QPushButton("Load Image File")
        self.load_button.clicked.connect(self.load_xisf)
        #left_layout.addWidget(self.load_button)

        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        # Add a scroll area to allow panning
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setWidgetResizable(False)  # Keep it resizable
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        left_layout.addWidget(self.scroll_area)

        self.toggle_button = QPushButton("Toggle Autostretch", self)
        self.toggle_button.setCheckable(True)
        self.toggle_button.clicked.connect(self.toggle_autostretch)
        left_layout.addWidget(self.toggle_button)        

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.zoom_out_button)
        # Add the "Fit to Window" button
        self.fit_to_window_button = QPushButton("Fit to Window")
        self.fit_to_window_button.clicked.connect(self.fit_to_window)
        zoom_layout.addWidget(self.fit_to_window_button)       
        left_layout.addLayout(zoom_layout)

        # Inside the initUI method, where the Save button is added
        self.save_button = QPushButton("Save As")
        self.save_button.clicked.connect(self.save_as)
        #self.save_button.setEnabled(False)



        # Add the Save button and checkbox to a horizontal layout
        #save_layout = QHBoxLayout()
        #save_layout.addWidget(self.save_button)

        #left_layout.addLayout(save_layout)

        # Add a Batch Process button
        self.batch_process_button = QPushButton("XISF Converter Batch Process")
        self.batch_process_button.clicked.connect(self.open_batch_process_window)
        left_layout.addWidget(self.batch_process_button)


        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        self.load_logo()

        # Right side layout for metadata display
        right_widget = QWidget()
        right_widget.setMinimumWidth(300)
        right_layout = QVBoxLayout()
        self.metadata_tree = QTreeWidget()
        self.metadata_tree.setHeaderLabels(["Property", "Value"])
        self.metadata_tree.setColumnWidth(0, 150)
        right_layout.addWidget(self.metadata_tree)
        
        # Save Metadata button below metadata tree
        self.save_metadata_button = QPushButton("Save Metadata")
        self.save_metadata_button.clicked.connect(self.save_metadata)
        right_layout.addWidget(self.save_metadata_button)
        
        right_widget.setLayout(right_layout)

        # Add left widget and metadata tree to the splitter
        splitter.addWidget(left_widget)
        splitter.addWidget(right_widget)
        splitter.setSizes([800, 200])  # Initial sizes for the left (preview) and right (metadata) sections
        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 0)

        main_layout.addWidget(splitter)
        self.setLayout(main_layout)
        self.setWindowTitle("XISF Liberator V1.2")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        This method is triggered when the image in ImageManager changes.
        It updates the UI with the new image only if the changed slot is the active slot.
        """
        if not self.isVisible():
            return

        # If image is None, clear the display and metadata.
        if image is None:
            self.image_label.clear()
            self.metadata_tree.clear()
            print(f"XISFViewer: Cleared image display for slot {slot}.")
            return

        # Clear the previous content before updating.
        self.image_label.clear()
        self.metadata_tree.clear()

        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', "Unknown File") 


        # Display metadata
        self.display_metadata(self.filename)

        # If the image is mono, ensure it's in 3-channel RGB format for display.
        if self.is_mono:
            if len(image.shape) == 3 and image.shape[2] == 1:
                image = np.squeeze(image, axis=2)  # Remove singleton channel
            if image.ndim == 2:
                image = np.stack([image] * 3, axis=-1)  # Convert mono to 3-channel RGB

        # Store the final image to be displayed
        self.image_data = image

        # **Ensure the UI updates properly**
        self.display_image()

        print(f"XISFViewer: Image updated from ImageManager slot {slot}.")




    def load_logo(self):
        """
        Load and display the XISF Liberator logo before any image is loaded.
        """
        logo_path = resource_path("astrosuite.png")
        if not os.path.exists(logo_path):
            print(f"Logo image not found at path: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        # Load the logo image
        logo_pixmap = QPixmap(logo_path)
        if logo_pixmap.isNull():
            print(f"Failed to load logo image from: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        self.current_pixmap = logo_pixmap  # Store the logo pixmap
        scaled_pixmap = logo_pixmap.scaled(
            logo_pixmap.size() * self.scale_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.resize(scaled_pixmap.size())

    def toggle_autostretch(self):
        if self.image_data is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply autostretch.")
            return        
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.image_data  # Reset to original image if stretch is disabled

        self.display_image()

    def apply_autostretch(self):
        # Determine if the image is mono or color
        if len(self.image_data.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=False, normalize=False)

    def open_batch_process_window(self):
        self.batch_dialog = BatchProcessDialog(self)
        self.batch_dialog.show()


    def load_xisf(self):
        file_name, _ = QFileDialog.getOpenFileName(
            self, 
            "Open Image File", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )

        if file_name:
            try:
                # Use the global load_image function to load the image and its metadata
                image, header, bit_depth, is_mono = load_image(file_name)
                
                # Apply debayering if needed (for non-mono images)
                if is_mono:  # Only debayer if the image is not mono
                    image, is_mono = self.debayer_image(image, file_name, header, is_mono)

                # Check if the image is mono or RGB
                self.is_mono = is_mono
                self.bit_depth = bit_depth
                self.image_data = image

                # Reset scale factor when a new image is loaded
                self.scale_factor = 0.25

                # If autostretch is enabled, apply stretch immediately after loading
                if self.autostretch_enabled:
                    self.apply_autostretch()

                # Display the image with scaling and normalization
                
                self.display_image()

                # Set image metadata (using header from load_image)
                self.file_meta = header  # Use the loaded header for metadata
                self.image_meta = None  # No separate image metadata for XISF in this example
                
                # Display metadata (using the global display_metadata method for appropriate file types)
                self.display_metadata(file_name)

                # Push the loaded image to ImageManager (only if image_manager exists)
                if hasattr(self, 'image_manager'):
                    metadata = {
                        'file_path': file_name,
                        'is_mono': self.is_mono,
                        'bit_depth': self.bit_depth,
                        'source': 'XISF'  # Or specify 'FITS' if applicable
                    }
                    # Push the numpy array to ImageManager (not memoryview)
                    self.image_manager.update_image(np.array(self.image_data), metadata, slot=0)  # Add image to slot 0 in ImageManager

                # Enable save button if the image is loaded successfully
                self.save_button.setEnabled(True)

            except Exception as e:
                self.image_label.setText(f"Failed to load XISF file: {e}")


    def debayer_image(self, image, file_path, header, is_mono):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        # Check for OSC (Bayer pattern in FITS or RAW data)
        if file_path.lower().endswith(('.fits', '.fit')):
            # Check if the FITS header contains BAYERPAT (Bayer pattern)
            bayer_pattern = header.get('BAYERPAT', None)
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                # Apply debayering logic for FITS
                is_mono = False
                image = self.debayer_fits(image, bayer_pattern)

            else:
                print(f"No Bayer pattern found in FITS header: {file_path}")
        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            # If it's RAW (Bayer pattern detected), debayer it
            print(f"Debayering RAW image: {file_path}")
            # Apply debayering to the RAW image (assuming debayer_raw exists)
            is_mono = False
            image = self.debayer_raw(image)
        
        return image, is_mono

    def debayer_fits(self, image_data, bayer_pattern):
        """Debayer a FITS image using a basic Bayer pattern (2x2)."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern
            r = image_data[::2, ::2]  # Red
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            b = image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = image_data[::2, ::2]  # Blue
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            r = image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            r = image_data[::2, 1::2]  # Red
            b = image_data[1::2, ::2]  # Blue
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            b = image_data[::2, 1::2]  # Blue
            r = image_data[1::2, ::2]  # Red
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")




    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Debayer a RAW image based on the Bayer pattern."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern (Debayering logic example)
            r = raw_image_data[::2, ::2]  # Red
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            b = raw_image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        
        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = raw_image_data[::2, ::2]  # Blue
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            r = raw_image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            r = raw_image_data[::2, 1::2]  # Red
            b = raw_image_data[1::2, ::2]  # Blue
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            b = raw_image_data[::2, 1::2]  # Blue
            r = raw_image_data[1::2, ::2]  # Red
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")


    def display_image(self):
        if self.image_data is None:
            return

        im_data = self.stretched_image if self.autostretch_enabled else self.image_data

        # Handle mono images
        if im_data.ndim == 2:
            print(f"Mono image detected with 2D shape: {im_data.shape}. Converting to 3-channel RGB for display.")
            im_data = np.stack([im_data] * 3, axis=-1)  # Convert to 3-channel RGB
        elif im_data.ndim == 3 and im_data.shape[2] == 1:
            print(f"Mono image with a single channel detected: {im_data.shape}. Converting to 3-channel RGB for display.")
            im_data = np.repeat(im_data, 3, axis=-1)  # Expand single channel to 3 channels

        if im_data.ndim == 3 and im_data.shape[2] == 3:
            # For color images (or converted mono images)
            height, width, channels = im_data.shape
            bytes_per_line = channels * width

            if im_data.dtype == np.uint8:
                q_image = QImage(im_data.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif im_data.dtype == np.uint16:
                im_data = (im_data / 256).astype(np.uint8)
                q_image = QImage(im_data.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif im_data.dtype in [np.float32, np.float64]:
                im_data = np.clip((im_data - im_data.min()) / (im_data.max() - im_data.min()) * 255, 0, 255).astype(np.uint8)
                q_image = QImage(im_data.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            else:
                print(f"Unsupported color image format: {im_data.dtype}")
                return
        else:
            print(f"Unexpected image shape: {im_data.shape}")
            return

        # Calculate scaled dimensions
        scaled_width = int(q_image.width() * self.scale_factor)
        scaled_height = int(q_image.height() * self.scale_factor)

        # Apply scaling
        scaled_image = q_image.scaled(
            scaled_width,
            scaled_height,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        pixmap = QPixmap.fromImage(scaled_image)
        self.current_pixmap = pixmap  # Store the current pixmap
        self.image_label.setPixmap(pixmap)
        self.image_label.resize(scaled_image.size())

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        self.center_image_on_zoom(1.25)

    def zoom_out(self):
        self.center_image_on_zoom(1 / 1.25)

    def fit_to_window(self):
        if self.image_data is None:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        viewport_width = viewport_size.width()
        viewport_height = viewport_size.height()

        # Get the image dimensions
        if self.autostretch_enabled and hasattr(self, 'stretched_image') and self.stretched_image is not None:
            img_height, img_width = self.stretched_image.shape[:2]
        else:
            img_height, img_width = self.image_data.shape[:2]

        # Calculate scale factors for width and height
        scale_factor_width = viewport_width / img_width
        scale_factor_height = viewport_height / img_height

        # Choose the smaller scale factor to ensure the image fits within the viewport
        self.scale_factor = min(scale_factor_width, scale_factor_height)

        # Update the display
        self.display_image()

    def center_image_on_zoom(self, zoom_factor):
        # Get the current center point of the visible area
        current_center_x = self.scroll_area.horizontalScrollBar().value() + (self.scroll_area.viewport().width() / 2)
        current_center_y = self.scroll_area.verticalScrollBar().value() + (self.scroll_area.viewport().height() / 2)
        
        # Adjust the scale factor
        self.scale_factor *= zoom_factor
        
        # Display the image with the new scale factor
        self.display_image()
        
        # Calculate the new center point after zooming
        new_center_x = current_center_x * zoom_factor
        new_center_y = current_center_y * zoom_factor
        
        # Adjust scrollbars to keep the image centered
        self.scroll_area.horizontalScrollBar().setValue(int(new_center_x - self.scroll_area.viewport().width() / 2))
        self.scroll_area.verticalScrollBar().setValue(int(new_center_y - self.scroll_area.viewport().height() / 2))


    def wheelEvent(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def display_metadata(self, file_path):
        """
        Load and display metadata from the given file if the file is an XISF or FITS file.
        For other file types, simply skip without failing.
        """
        if not file_path:
            print("No file path provided. Skipping metadata display.")
            return

        if not isinstance(file_path, str):
            print(f"Invalid file path type: {type(file_path)}. Expected a string.")
            return

        try:
            if file_path.lower().endswith('.xisf'):
                print("Loading metadata from XISF file.")
                # XISF handling
                try:
                    # Load XISF file for metadata
                    xisf = XISF(file_path)
                    file_meta = xisf.get_file_metadata()
                    image_meta = xisf.get_images_metadata()[0]

                    # Assign metadata to instance variables
                    self.file_meta = file_meta
                    self.image_meta = image_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add File Metadata
                    file_meta_item = QTreeWidgetItem(["File Metadata"])
                    self.metadata_tree.addTopLevelItem(file_meta_item)
                    for key, value in file_meta.items():
                        item = QTreeWidgetItem([key, str(value.get('value', ''))])  # Ensure 'value' exists
                        file_meta_item.addChild(item)

                    # Add Image Metadata
                    image_meta_item = QTreeWidgetItem(["Image Metadata"])
                    self.metadata_tree.addTopLevelItem(image_meta_item)
                    for key, value in image_meta.items():
                        if key == 'FITSKeywords':
                            fits_item = QTreeWidgetItem(["FITS Keywords"])
                            image_meta_item.addChild(fits_item)
                            for kw, kw_values in value.items():
                                for kw_value in kw_values:
                                    item = QTreeWidgetItem([kw, str(kw_value.get("value", ''))])
                                    fits_item.addChild(item)
                        elif key == 'XISFProperties':
                            props_item = QTreeWidgetItem(["XISF Properties"])
                            image_meta_item.addChild(props_item)
                            for prop_name, prop in value.items():
                                item = QTreeWidgetItem([prop_name, str(prop.get("value", ''))])
                                props_item.addChild(item)
                        else:
                            item = QTreeWidgetItem([key, str(value)])
                            image_meta_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load XISF metadata: {e}")

            elif file_path.lower().endswith(('.fits', '.fit')):
                print("Loading metadata from FITS file.")
                # FITS handling
                try:
                    # Open the FITS file using Astropy
                    hdul = fits.open(file_path)
                    header = hdul[0].header  # Extract header from primary HDU
                    hdul.close()

                    # Assign metadata to instance variables
                    self.file_meta = header
                    self.image_meta = {}  # FITS files typically don't have separate image-level metadata

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add FITS Header Metadata
                    fits_header_item = QTreeWidgetItem(["FITS Header"])
                    self.metadata_tree.addTopLevelItem(fits_header_item)

                    # Loop through the header and add each keyword
                    for keyword, value in header.items():
                        item = QTreeWidgetItem([keyword, str(value)])
                        fits_header_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load FITS metadata: {e}")

            # Handle Camera Raw files (e.g., .cr2, .nef, .arw, .dng)
            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print("Loading metadata from Camera RAW file.")
                try:
                    # Use rawpy to read RAW file metadata
                    raw_meta = {}
                    with rawpy.imread(file_path) as raw:
                        # Example: Extract some basic metadata
                        raw_meta['camera_whitebalance'] = raw.camera_whitebalance
                        raw_meta['camera_white_level_per_channel'] = raw.camera_white_level_per_channel
                        raw_meta['tone_curve_length'] = len(raw.tone_curve) if raw.tone_curve is not None else 0

                    # Assign metadata to instance variables
                    self.file_meta = {}  # RAW files typically don't have file-level metadata in this context
                    self.image_meta = raw_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add Camera RAW Metadata
                    raw_meta_item = QTreeWidgetItem(["Camera RAW Metadata"])
                    self.metadata_tree.addTopLevelItem(raw_meta_item)

                    for key, value in raw_meta.items():
                        if isinstance(value, (list, tuple, np.ndarray)):
                            for i, item in enumerate(value):
                                raw_meta_item.addChild(QTreeWidgetItem([f"{key}_{i+1}", str(item)]))
                        else:
                            raw_meta_item.addChild(QTreeWidgetItem([key, str(value)]))

                    self.metadata_tree.expandAll()
                except Exception as e:
                    print(f"Failed to load Camera RAW metadata: {e}")

            else:
                # If the file is not a FITS or XISF file, simply return without displaying metadata
                print(f"Skipping metadata for unsupported file type: {file_path}")

        except AttributeError as ae:
            print(f"AttributeError in display_metadata: {ae}")
        except Exception as e:
            print(f"Unexpected error in display_metadata: {e}")


    def save_as(self):
        output_path, _ = QFileDialog.getSaveFileName(self, "Save Image As", "", "XISF (*.xisf);;FITS (*.fits);;TIFF (*.tif);;PNG (*.png)")
        
        if output_path:
            # Determine if we should save the stretched image or the original
            image_to_save = self.stretched_image if self.save_stretched_checkbox.isChecked() and self.stretched_image is not None else self.image_data
            _, ext = os.path.splitext(output_path)
            
            # Determine bit depth and color mode
            is_32bit_float = image_to_save.dtype == np.float32
            is_16bit = image_to_save.dtype == np.uint16
            is_8bit = image_to_save.dtype == np.uint8

            try:
                # Save as FITS file with FITS header only (no XISF properties)
                if ext.lower() in ['.fits', '.fit']:
                    header = fits.Header()
                    crval1, crval2 = None, None
                    
                    # Populate FITS header with FITS keywords and essential WCS keywords only
                    wcs_keywords = ["CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
                    
                    if 'FITSKeywords' in self.image_meta:
                        for keyword, values in self.image_meta['FITSKeywords'].items():
                            for entry in values:
                                if 'value' in entry:
                                    value = entry['value']
                                    if keyword in wcs_keywords:
                                        try:
                                            value = int(value)
                                        except ValueError:
                                            value = float(value)
                                    header[keyword] = value

                    # Manually add WCS information if missing
                    if 'CTYPE1' not in header:
                        header['CTYPE1'] = 'RA---TAN'
                    if 'CTYPE2' not in header:
                        header['CTYPE2'] = 'DEC--TAN'
                    
                    # Add the -SIP suffix if SIP coefficients are present
                    if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                        header['CTYPE1'] = 'RA---TAN-SIP'
                        header['CTYPE2'] = 'DEC--TAN-SIP'

                    # Set default reference pixel (center of the image)
                    if 'CRPIX1' not in header:
                        header['CRPIX1'] = image_to_save.shape[1] / 2  # X center
                    if 'CRPIX2' not in header:
                        header['CRPIX2'] = image_to_save.shape[0] / 2  # Y center

                    # Retrieve RA and DEC values if available
                    if 'FITSKeywords' in self.image_meta:
                        if 'RA' in self.image_meta['FITSKeywords']:
                            crval1 = float(self.image_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
                        if 'DEC' in self.image_meta['FITSKeywords']:
                            crval2 = float(self.image_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

                    # Add CRVAL1 and CRVAL2 to the header if found
                    if crval1 is not None and crval2 is not None:
                        header['CRVAL1'] = crval1
                        header['CRVAL2'] = crval2
                    else:
                        print("RA and DEC values not found in FITS Keywords")

                    # Calculate pixel scale if focal length and pixel size are available
                    if 'FOCALLEN' in self.image_meta['FITSKeywords'] and 'XPIXSZ' in self.image_meta['FITSKeywords']:
                        focal_length = float(self.image_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
                        pixel_size = float(self.image_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
                        pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
                        header['CDELT1'] = -pixel_scale / 3600.0
                        header['CDELT2'] = pixel_scale / 3600.0
                    else:
                        header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
                        header['CDELT2'] = 2.77778e-4

                    # Populate CD matrix using the XISF LinearTransformationMatrix if available
                    if 'XISFProperties' in self.image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in self.image_meta['XISFProperties']:
                        linear_transform = self.image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        header['CD1_1'] = linear_transform[0][0]
                        header['CD1_2'] = linear_transform[0][1]
                        header['CD2_1'] = linear_transform[1][0]
                        header['CD2_2'] = linear_transform[1][1]
                    else:
                        header['CD1_1'] = header['CDELT1']
                        header['CD1_2'] = 0.0
                        header['CD2_1'] = 0.0
                        header['CD2_2'] = header['CDELT2']

                    # Duplicate the mono image to create a 3-channel image if it’s mono
                    if self.is_mono:
                        image_data_fits = np.stack([image_to_save[:, :, 0]] * 3, axis=-1)  # Create 3-channel from mono
                        image_data_fits = np.transpose(image_data_fits, (2, 0, 1))  # Reorder to (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)
                    else:
                        image_data_fits = np.transpose(image_to_save, (2, 0, 1))  # RGB images in (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)

                    hdu = fits.PrimaryHDU(image_data_fits, header=header)
                    hdu.writeto(output_path, overwrite=True)
                    print(f"Saved FITS image with metadata to: {output_path}")

                # Save as TIFF based on bit depth
                elif ext.lower() in ['.tif', '.tiff']:
                    if is_16bit:
                        self.save_tiff(output_path, bit_depth=16)
                    elif is_32bit_float:
                        self.save_tiff(output_path, bit_depth=32)
                    else:
                        self.save_tiff(output_path, bit_depth=8)
                    print(f"Saved TIFF image with {self.bit_depth} bit depth to: {output_path}")

                # Save as PNG
                elif ext.lower() == '.png':
                    # Convert mono images to RGB for PNG format
                    if self.is_mono:
                        image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                        image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)  # Duplicate channel to create RGB
                    else:
                        image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                    Image.fromarray(image_8bit_rgb).save(output_path)
                    print(f"Saved 8-bit PNG image to: {output_path}")

                # Save as XISF with metadata
                elif ext.lower() == '.xisf':
                    XISF.write(output_path, image_to_save, xisf_metadata=self.file_meta)
                    print(f"Saved XISF image with metadata to: {output_path}")

            except Exception as e:
                print(f"Error saving file: {e}")


    def process_batch(self, input_dir, output_dir, file_format, update_status_callback):
        import glob
        from pathlib import Path

        xisf_files = glob.glob(f"{input_dir}/*.xisf")
        if not xisf_files:
            QMessageBox.warning(self, "Error", "No XISF files found in the input directory.")
            update_status_callback("")
            return

        for i, xisf_file in enumerate(xisf_files, start=1):
            try:
                # Update progress
                update_status_callback(f"Processing file {i}/{len(xisf_files)}: {Path(xisf_file).name}")

                # Load the XISF file
                xisf = XISF(xisf_file)
                im_data = xisf.read_image(0)

                # Set metadata
                file_meta = xisf.get_file_metadata()
                image_meta = xisf.get_images_metadata()[0]
                is_mono = im_data.shape[2] == 1 if len(im_data.shape) == 3 else True

                # Determine output file path
                base_name = Path(xisf_file).stem
                output_file = Path(output_dir) / f"{base_name}{file_format}"

                # Save the file using save_direct
                self.save_direct(output_file, im_data, file_meta, image_meta, is_mono)

            except Exception as e:
                update_status_callback(f"Error processing file {Path(xisf_file).name}: {e}")
                continue  # Skip to the next file

        update_status_callback("Batch Processing Complete!")

    def save_direct(self, output_path, image_to_save, file_meta, image_meta, is_mono):
        """
        Save an image directly to the specified path with the given metadata.
        This function does not prompt the user and is suitable for batch processing.
        """
        _, ext = os.path.splitext(output_path)

        # Determine bit depth and color mode
        is_32bit_float = image_to_save.dtype == np.float32
        is_16bit = image_to_save.dtype == np.uint16
        is_8bit = image_to_save.dtype == np.uint8

        try:
            # Save as FITS file with metadata
            if ext.lower() in ['.fits', '.fit']:
                header = fits.Header()
                crval1, crval2 = None, None

                # Populate FITS header with FITS keywords and WCS keywords
                wcs_keywords = [
                    "CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", 
                    "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"
                ]

                if 'FITSKeywords' in image_meta:
                    for keyword, values in image_meta['FITSKeywords'].items():
                        for entry in values:
                            if 'value' in entry:
                                value = entry['value']
                                # Convert only numerical values to float
                                if keyword in wcs_keywords and isinstance(value, (int, float)):
                                    value = float(value)
                                header[keyword] = value

                # Add default WCS information if missing
                if 'CTYPE1' not in header:
                    header['CTYPE1'] = 'RA---TAN'
                if 'CTYPE2' not in header:
                    header['CTYPE2'] = 'DEC--TAN'

                # Add the -SIP suffix for SIP coefficients
                if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                    header['CTYPE1'] = 'RA---TAN-SIP'
                    header['CTYPE2'] = 'DEC--TAN-SIP'

                # Set default reference pixel if missing
                if 'CRPIX1' not in header:
                    header['CRPIX1'] = image_to_save.shape[1] / 2
                if 'CRPIX2' not in header:
                    header['CRPIX2'] = image_to_save.shape[0] / 2

                # Add CRVAL1 and CRVAL2 if available
                if 'RA' in image_meta.get('FITSKeywords', {}):
                    crval1 = float(image_meta['FITSKeywords']['RA'][0]['value'])
                if 'DEC' in image_meta.get('FITSKeywords', {}):
                    crval2 = float(image_meta['FITSKeywords']['DEC'][0]['value'])

                if crval1 is not None and crval2 is not None:
                    header['CRVAL1'] = crval1
                    header['CRVAL2'] = crval2

                # Add CD matrix if available
                if 'XISFProperties' in image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in image_meta['XISFProperties']:
                    linear_transform = image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                    header['CD1_1'] = linear_transform[0][0]
                    header['CD1_2'] = linear_transform[0][1]
                    header['CD2_1'] = linear_transform[1][0]
                    header['CD2_2'] = linear_transform[1][1]
                else:
                    header['CD1_1'] = header['CDELT1'] if 'CDELT1' in header else 0.0
                    header['CD1_2'] = 0.0
                    header['CD2_1'] = 0.0
                    header['CD2_2'] = header['CDELT2'] if 'CDELT2' in header else 0.0

                # Duplicate mono image to create 3-channel if necessary
                if is_mono:
                    image_data_fits = image_to_save[:, :, 0] if len(image_to_save.shape) == 3 else image_to_save
                    header['NAXIS'] = 2  # Mono images are 2-dimensional
                else:
                    image_data_fits = np.transpose(image_to_save, (2, 0, 1))
                    header['NAXIS'] = 3
                    header['NAXIS3'] = 3

                hdu = fits.PrimaryHDU(image_data_fits, header=header)
                hdu.writeto(output_path, overwrite=True)
                print(f"Saved FITS image to: {output_path}")


            # Save as TIFF
            elif ext.lower() in ['.tif', '.tiff']:
                if is_16bit:
                    tiff.imwrite(output_path, (image_to_save * 65535).astype(np.uint16))
                elif is_32bit_float:
                    tiff.imwrite(output_path, image_to_save.astype(np.float32))
                else:
                    tiff.imwrite(output_path, (image_to_save * 255).astype(np.uint8))
                print(f"Saved TIFF image to: {output_path}")

            # Save as PNG
            elif ext.lower() == '.png':
                if is_mono:
                    image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                    image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)
                else:
                    image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                Image.fromarray(image_8bit_rgb).save(output_path)
                print(f"Saved PNG image to: {output_path}")

            # Save as XISF
            elif ext.lower() == '.xisf':
                XISF.write(output_path, image_to_save, xisf_metadata=file_meta)
                print(f"Saved XISF image to: {output_path}")

            else:
                print(f"Unsupported file format: {ext}")

        except Exception as e:
            print(f"Error saving file {output_path}: {e}")


    def save_tiff(self, output_path, bit_depth):
        if bit_depth == 16:
            if self.is_mono:
                tiff.imwrite(output_path, (self.image_data[:, :, 0] * 65535).astype(np.uint16))
            else:
                tiff.imwrite(output_path, (self.image_data * 65535).astype(np.uint16))
        elif bit_depth == 32:
            if self.is_mono:
                tiff.imwrite(output_path, self.image_data[:, :, 0].astype(np.float32))
            else:
                tiff.imwrite(output_path, self.image_data.astype(np.float32))
        else:  # 8-bit
            image_8bit = (self.image_data * 255).astype(np.uint8)
            if self.is_mono:
                tiff.imwrite(output_path, image_8bit[:, :, 0])
            else:
                tiff.imwrite(output_path, image_8bit)

    def save_metadata(self):
        if not self.file_meta and not self.image_meta:
            QMessageBox.warning(self, "Warning", "No metadata to save.")
            return
        file_path, _ = QFileDialog.getSaveFileName(self, "Save Metadata", "", "CSV Files (*.csv);;All Files (*)")
        if file_path:
            try:
                # Flatten metadata function
                def flatten_metadata(data, parent_key=''):
                    items = []
                    for key, value in data.items():
                        new_key = f"{parent_key}.{key}" if parent_key else key
                        if isinstance(value, dict):
                            items.extend(flatten_metadata(value, new_key).items())
                        elif isinstance(value, list):
                            for i, list_item in enumerate(value):
                                list_key = f"{new_key}_{i}"
                                items.extend(flatten_metadata({list_key: list_item}).items())
                        else:
                            items.append((new_key, value if value is not None else ''))  # Replace None with an empty string
                    return dict(items)

                # Flatten both file_meta and image_meta
                flattened_file_meta = flatten_metadata(self.file_meta) if self.file_meta else {}
                flattened_image_meta = flatten_metadata(self.image_meta) if self.image_meta else {}

                # Combine both metadata into one dictionary for CSV
                combined_meta = {**flattened_file_meta, **flattened_image_meta}

                # Write to CSV
                with open(file_path, mode='w', newline='', encoding='utf-8') as file:
                    writer = csv.writer(file)
                    writer.writerow(["Key", "Value"])  # Header row
                    for key, value in combined_meta.items():
                        writer.writerow([key, value])

                QMessageBox.information(self, "Success", f"Metadata saved to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to save metadata: {e}")       

class BatchProcessDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Batch Process")
        self.setMinimumWidth(400)

        layout = QVBoxLayout()

        # Input directory
        self.input_dir_label = QLabel("Input Directory:")
        self.input_dir_button = QPushButton("Select Input Directory")
        self.input_dir_button.clicked.connect(self.select_input_directory)
        self.input_dir = QLineEdit()
        self.input_dir.setReadOnly(True)

        layout.addWidget(self.input_dir_label)
        layout.addWidget(self.input_dir)
        layout.addWidget(self.input_dir_button)

        # Output directory
        self.output_dir_label = QLabel("Output Directory:")
        self.output_dir_button = QPushButton("Select Output Directory")
        self.output_dir_button.clicked.connect(self.select_output_directory)
        self.output_dir = QLineEdit()
        self.output_dir.setReadOnly(True)

        layout.addWidget(self.output_dir_label)
        layout.addWidget(self.output_dir)
        layout.addWidget(self.output_dir_button)

        # File format
        self.format_label = QLabel("Select Output Format:")
        self.format_combo = QComboBox()
        self.format_combo.addItems([".png", ".fit", ".fits", ".tif", ".tiff"])

        layout.addWidget(self.format_label)
        layout.addWidget(self.format_combo)

        # Start Batch Processing button
        self.start_button = QPushButton("Start Batch Processing")
        self.start_button.clicked.connect(self.start_batch_processing)
        layout.addWidget(self.start_button)

        # Status label
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)

        self.setLayout(layout)

    def select_input_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.input_dir.setText(directory)

    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.output_dir.setText(directory)

    def start_batch_processing(self):
        input_dir = self.input_dir.text()
        output_dir = self.output_dir.text()
        file_format = self.format_combo.currentText()

        if not input_dir or not output_dir:
            QMessageBox.warning(self, "Error", "Please select both input and output directories.")
            return

        self.status_label.setText("Initializing batch processing...")
        QApplication.processEvents()  # Ensures UI updates immediately

        # Call the parent function to process files with progress updates
        self.parent().process_batch(input_dir, output_dir, file_format, self.update_status)

        self.status_label.setText("Batch Processing Complete!")

    def update_status(self, message):
        self.status_label.setText(message)
        QApplication.processEvents()  # Ensures UI updates immediately

class BlinkTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()

        self.image_paths = []  # Store the file paths of loaded images
        self.loaded_images = []  # Store the image objects (as numpy arrays)
        self.image_labels = []  # Store corresponding file names for the TreeWidget
        self.image_manager = image_manager  # Reference to ImageManager
        self.zoom_level = 0.5  # Default zoom level
        self.dragging = False  # Track whether the mouse is dragging
        self.last_mouse_pos = None  # Store the last mouse position

        self.initUI()
        self.init_shortcuts()

    def initUI(self):
        main_layout = QHBoxLayout(self)

        # Create a QSplitter to allow resizing between left and right panels
        splitter = QSplitter(Qt.Orientation.Horizontal, self)

        # Left Column for the file loading and TreeView
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)

        # --------------------
        # Instruction Label
        # --------------------
        instruction_text = "Press 'F' to flag/unflag an image.\nRight-click on an image for more options."
        self.instruction_label = QLabel(instruction_text, self)
        self.instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.instruction_label.setWordWrap(True)
        self.instruction_label.setStyleSheet("font-weight: bold;")  # Optional: Make the text bold for emphasis

        self.instruction_label.setStyleSheet(f"""
            QLabel {{
                font-weight: bold;
            }}
        """)

        # Add the instruction label to the left layout at the top
        left_layout.addWidget(self.instruction_label)

        # Horizontal layout for "Select Images" and "Select Directory" buttons
        button_layout = QHBoxLayout()

        # "Select Images" Button
        self.fileButton = QPushButton('Select Images', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        button_layout.addWidget(self.fileButton)

        # "Select Directory" Button
        self.dirButton = QPushButton('Select Directory', self)
        self.dirButton.clicked.connect(self.openDirectoryDialog)
        button_layout.addWidget(self.dirButton)

        left_layout.addLayout(button_layout)

        # "Clear Images" Button
        self.clearButton = QPushButton('Clear Images', self)
        self.clearButton.clicked.connect(self.clearImages)
        left_layout.addWidget(self.clearButton)

        # Playback controls (left arrow, play, pause, right arrow)
        playback_controls_layout = QHBoxLayout()

        # Left Arrow Button
        self.left_arrow_button = QPushButton(self)
        self.left_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        self.left_arrow_button.clicked.connect(self.previous_item)
        playback_controls_layout.addWidget(self.left_arrow_button)

        # Play Button
        self.play_button = QPushButton(self)
        self.play_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPlay))
        self.play_button.clicked.connect(self.start_playback)
        playback_controls_layout.addWidget(self.play_button)

        # Pause Button
        self.pause_button = QPushButton(self)
        self.pause_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPause))
        self.pause_button.clicked.connect(self.stop_playback)
        playback_controls_layout.addWidget(self.pause_button)

        # Right Arrow Button
        self.right_arrow_button = QPushButton(self)
        self.right_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowRight))
        self.right_arrow_button.clicked.connect(self.next_item)
        playback_controls_layout.addWidget(self.right_arrow_button)

        left_layout.addLayout(playback_controls_layout)

        # Tree view for file names
        self.fileTree = QTreeWidget(self)
        self.fileTree.setColumnCount(1)
        self.fileTree.setHeaderLabels(["Image Files"])
        self.fileTree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)  # Allow multiple selections
        self.fileTree.itemClicked.connect(self.on_item_clicked)
        self.fileTree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.fileTree.customContextMenuRequested.connect(self.on_right_click)
        self.fileTree.currentItemChanged.connect(self.on_current_item_changed) 
        self.fileTree.setStyleSheet("""
                QTreeWidget::item:selected {
                    background-color: #3a75c4;  /* Blue background for selected items */
                    color: #ffffff;  /* White text color */
                }
            """)
        left_layout.addWidget(self.fileTree)

        # Add progress bar
        self.progress_bar = QProgressBar(self)
        self.progress_bar.setRange(0, 100)
        left_layout.addWidget(self.progress_bar)

        # Add loading message label
        self.loading_label = QLabel("Loading images...", self)
        left_layout.addWidget(self.loading_label)

        # Set the layout for the left widget
        left_widget.setLayout(left_layout)

        # Add the left widget to the splitter
        splitter.addWidget(left_widget)

        # Right Column for Image Preview
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls: Add Zoom In and Zoom Out buttons
        zoom_controls_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_controls_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_controls_layout.addWidget(self.fit_to_preview_button)

        right_layout.addLayout(zoom_controls_layout)

        # Scroll area for the preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.preview_label = QLabel(self)
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        right_layout.addWidget(self.scroll_area)

        # Set the layout for the right widget
        right_widget.setLayout(right_layout)

        # Add the right widget to the splitter
        splitter.addWidget(right_widget)

        # Set initial splitter sizes
        splitter.setSizes([300, 700])  # Adjust proportions as needed

        # Add the splitter to the main layout
        main_layout.addWidget(splitter)

        # Set the main layout for the widget
        self.setLayout(main_layout)

        # Initialize playback timer
        self.playback_timer = QTimer(self)
        self.playback_timer.setInterval(200)  # Set the playback interval to 500ms
        self.playback_timer.timeout.connect(self.next_item)

        # Connect the selection change signal to update the preview when arrow keys are used
        self.fileTree.selectionModel().selectionChanged.connect(self.on_selection_changed)
        self.setFocusPolicy(Qt.FocusPolicy.StrongFocus)

    def init_shortcuts(self):
        """Initialize keyboard shortcuts."""
        # Create a shortcut for the "F" key to flag images
        flag_shortcut = QShortcut(QKeySequence("F"), self.fileTree)
        flag_shortcut.activated.connect(self.flag_current_image)

    def openDirectoryDialog(self):
        """Allow users to select a directory and load all images within it recursively."""
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            # Supported image extensions
            supported_extensions = (
                '.png', '.tif', '.tiff', '.fits', '.fit',
                '.xisf', '.cr2', '.nef', '.arw', '.dng',
                '.orf', '.rw2', '.pef'
            )

            # Collect all image file paths recursively
            new_file_paths = []
            for root, _, files in os.walk(directory):
                for file in sorted(files, key=str.lower):  # 🔹 Sort alphabetically (case-insensitive)
                    if file.lower().endswith(supported_extensions):
                        full_path = os.path.join(root, file)
                        if full_path not in self.image_paths:  # Avoid duplicates
                            new_file_paths.append(full_path)

            if new_file_paths:
                self.loadImages(new_file_paths)
            else:
                QMessageBox.information(self, "No Images Found", "No supported image files were found in the selected directory.")


    def clearImages(self):
        """Clear all loaded images and reset the tree view."""
        confirmation = QMessageBox.question(
            self,
            "Clear All Images",
            "Are you sure you want to clear all loaded images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            self.stop_playback()
            self.image_paths.clear()
            self.loaded_images.clear()
            self.image_labels.clear()
            self.fileTree.clear()
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')
            self.current_pixmap = None
            self.progress_bar.setValue(0)
            self.loading_label.setText("Loading images...")

    def loadImages(self, file_paths):
        """Load images from the provided file paths and update the tree view."""
        if not file_paths:
            return

        # Append new image paths
        self.image_paths.extend(file_paths)

        # Dictionary to store images grouped by filter and exposure time
        grouped_images = {}

        # Load the images into memory (storing both file path and image data)
        total_files = len(file_paths)

        for index, file_path in enumerate(file_paths):
            try:
                image, header, bit_depth, is_mono = load_image(file_path)
            except Exception as e:
                print(f"Failed to load image {file_path}: {e}")
                continue

            # Check if the image is None or empty and skip if so.
            if image is None or image.size == 0:
                print(f"Image {file_path} is None or empty. Skipping file.")
                continue

            # Debayer the image if needed (for non-mono images)
            if is_mono:
                image = self.debayer_image(image, file_path, header)

            # Stretch the image now while loading it
            target_median = 0.25
            if image.ndim == 2:  # Mono image
                stretched_image = stretch_mono_image(image, target_median)
            else:  # Color image
                stretched_image = stretch_color_image(image, target_median, linked=False)

            # Append the stretched image data
            self.loaded_images.append({
                'file_path': file_path,
                'image_data': stretched_image,
                'header': header,
                'bit_depth': bit_depth,
                'is_mono': is_mono,
                'flagged': False
            })

            # Safely extract filter and exposure time from FITS header if available
            object_name = header.get('OBJECT', 'Unknown') if header else 'Unknown'
            filter_name = header.get('FILTER', 'Unknown') if header else 'Unknown'
            exposure_time = header.get('EXPOSURE', 'Unknown') if header else 'Unknown'

            # Group images by filter and exposure time
            group_key = (object_name, filter_name, exposure_time)
            if group_key not in grouped_images:
                grouped_images[group_key] = []
            grouped_images[group_key].append(file_path)

            # Update progress bar
            progress = int((index + 1) / total_files * 100)
            self.progress_bar.setValue(progress)
            QApplication.processEvents()  # Ensure the UI updates in real-time

        print(f"Loaded {len(self.loaded_images)} images into memory.")
        self.loading_label.setText(f"Loaded {len(self.loaded_images)} images.")

        # Optionally, reset the progress bar and loading message when done
        self.progress_bar.setValue(100)
        self.loading_label.setText("Loading complete.")

        # Display grouped images in the tree view
        grouped_by_object = {}

        # First, group by object_name
        for (object_name, filter_name, exposure_time), paths in grouped_images.items():
            if object_name not in grouped_by_object:
                grouped_by_object[object_name] = {}
            if filter_name not in grouped_by_object[object_name]:
                grouped_by_object[object_name][filter_name] = {}
            if exposure_time not in grouped_by_object[object_name][filter_name]:
                grouped_by_object[object_name][filter_name][exposure_time] = []
            grouped_by_object[object_name][filter_name][exposure_time].extend(paths)

        # Now, create the tree structure
        for object_name, filters in grouped_by_object.items():
            # Check if object already exists in the tree
            object_item = self.findTopLevelItemByName(f"Object: {object_name}")
            if not object_item:
                object_item = QTreeWidgetItem([f"Object: {object_name}"])
                self.fileTree.addTopLevelItem(object_item)
                object_item.setExpanded(True)  # Expand the object item

            for filter_name, exposures in filters.items():
                # Check if filter already exists under the object
                filter_item = self.findChildItemByName(object_item, f"Filter: {filter_name}")
                if not filter_item:
                    filter_item = QTreeWidgetItem([f"Filter: {filter_name}"])
                    object_item.addChild(filter_item)
                    filter_item.setExpanded(True)  # Expand the filter item

                for exposure_time, paths in exposures.items():
                    # Check if exposure exists under the filter
                    exposure_item = self.findChildItemByName(filter_item, f"Exposure: {exposure_time}")
                    if not exposure_item:
                        exposure_item = QTreeWidgetItem([f"Exposure: {exposure_time}"])
                        filter_item.addChild(exposure_item)
                        exposure_item.setExpanded(True)  # Expand the exposure item

                    for file_path in paths:
                        file_name = os.path.basename(file_path)
                        item = QTreeWidgetItem([file_name])
                        exposure_item.addChild(item)

    def findTopLevelItemByName(self, name):
        """Find a top-level item in the tree by its name."""
        for index in range(self.fileTree.topLevelItemCount()):
            item = self.fileTree.topLevelItem(index)
            if item.text(0) == name:
                return item
        return None

    def findChildItemByName(self, parent, name):
        """Find a child item under a given parent by its name."""
        for index in range(parent.childCount()):
            child = parent.child(index)
            if child.text(0) == name:
                return child
        return None

    def flag_current_image(self):
        """Flag or unflag the currently selected image as bad."""
        current_item = self.fileTree.currentItem()
        if not current_item:
            QMessageBox.warning(self, "No Selection", "No image is currently selected to flag.")
            return

        # Remove any existing flag icon before processing
        file_name = current_item.text(0).lstrip("⚠️ ")

        file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

        if file_path:
            index = self.image_paths.index(file_path)
            image_entry = self.loaded_images[index]

            # Toggle the flagged state
            image_entry['flagged'] = not image_entry['flagged']
            RED = Qt.GlobalColor.red

            # Fetch the current text color from the palette
            palette = self.fileTree.palette()
            current_text_color = palette.color(QPalette.ColorRole.WindowText)

            # Update the tree view to reflect the flag
            if image_entry['flagged']:
                # Add a flag icon and change text color to red
                current_item.setText(0, f"⚠️ {file_name}")  # Prefix with a warning icon
                current_item.setForeground(0, QBrush(RED))
            else:
                # Remove the flag icon and reset text color based on the current theme
                current_item.setText(0, file_name)
                current_item.setForeground(0, QBrush(current_text_color))

            # Optional: Provide feedback to the user
            status = "flagged as bad" if image_entry['flagged'] else "unflagged"
            print(f"Image '{file_name}' has been {status}.")


    def on_current_item_changed(self, current, previous):
        """Ensure the selected item is visible by scrolling to it."""
        if current:
            self.fileTree.scrollToItem(current, QAbstractItemView.ScrollHint.PositionAtCenter)

    def previous_item(self):
        """Select the previous item in the TreeWidget."""
        current_item = self.fileTree.currentItem()
        if current_item:
            all_items = self.get_all_leaf_items()
            current_index = all_items.index(current_item)
            if current_index > 0:
                previous_item = all_items[current_index - 1]
            else:
                previous_item = all_items[-1]  # Loop back to the last item
            self.fileTree.setCurrentItem(previous_item)
            self.on_item_clicked(previous_item, 0)  # Update the preview

    def next_item(self):
        """Select the next item in the TreeWidget, looping back to the first item if at the end."""
        current_item = self.fileTree.currentItem()
        if current_item:
            # Get all leaf items
            all_items = self.get_all_leaf_items()

            # Check if the current item is in the leaf items
            try:
                current_index = all_items.index(current_item)
            except ValueError:
                # If the current item is not a leaf, move to the first leaf item
                print("Current item is not a leaf. Selecting the first leaf item.")
                if all_items:
                    next_item = all_items[0]
                    self.fileTree.setCurrentItem(next_item)
                    self.on_item_clicked(next_item, 0)
                return

            # Select the next leaf item or loop back to the first
            if current_index < len(all_items) - 1:
                next_item = all_items[current_index + 1]
            else:
                next_item = all_items[0]  # Loop back to the first item

            self.fileTree.setCurrentItem(next_item)
            self.on_item_clicked(next_item, 0)  # Update the preview
        else:
            print("No current item selected.")

    def get_all_leaf_items(self):
        """Get a flat list of all leaf items (actual files) in the TreeWidget."""
        def recurse(parent):
            items = []
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.childCount() == 0:  # It's a leaf item
                    items.append(child)
                else:
                    items.extend(recurse(child))
            return items

        root = self.fileTree.invisibleRootItem()
        return recurse(root)

    def start_playback(self):
        """Start playing through the items in the TreeWidget."""
        if not self.playback_timer.isActive():
            self.playback_timer.start()

    def stop_playback(self):
        """Stop playing through the items."""
        if self.playback_timer.isActive():
            self.playback_timer.stop()


    def openFileDialog(self):
        """Allow users to select multiple images and add them to the existing list."""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Open Images",
            "",
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )
        
        # Filter out already loaded images to prevent duplicates
        new_file_paths = [path for path in file_paths if path not in self.image_paths]

        if new_file_paths:
            self.loadImages(new_file_paths)
        else:
            QMessageBox.information(self, "No New Images", "No new images were selected or all selected images are already loaded.")


    def debayer_image(self, image, file_path, header):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        # Check for OSC (Bayer pattern in FITS or RAW data)
        if file_path.lower().endswith(('.fits', '.fit')):
            # Check if the FITS header contains BAYERPAT (Bayer pattern)
            bayer_pattern = header.get('BAYERPAT', None)
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                # Apply debayering logic for FITS
                image = self.debayer_fits(image, bayer_pattern)
            else:
                print(f"No Bayer pattern found in FITS header: {file_path}")
        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            # If it's RAW (Bayer pattern detected), debayer it
            print(f"Debayering RAW image: {file_path}")
            # Apply debayering to the RAW image (assuming debayer_raw exists)
            image = self.debayer_raw(image)
        
        return image

    def debayer_fits(self, image_data, bayer_pattern):
        """Debayer a FITS image using a basic Bayer pattern (2x2)."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern
            r = image_data[::2, ::2]  # Red
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            b = image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = image_data[::2, ::2]  # Blue
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            r = image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            r = image_data[::2, 1::2]  # Red
            b = image_data[1::2, ::2]  # Blue
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            b = image_data[::2, 1::2]  # Blue
            r = image_data[1::2, ::2]  # Red
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")

    def remove_item_from_tree(self, file_path):
        """Remove a specific item from the tree view based on file path."""
        file_name = os.path.basename(file_path)
        root = self.fileTree.invisibleRootItem()

        def recurse(parent):
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.text(0).endswith(file_name):
                    parent.removeChild(child)
                    return True
                if recurse(child):
                    return True
            return False

        recurse(root)

    def add_item_to_tree(self, file_path):
        """Add a specific item to the tree view based on file path."""
        # Extract metadata for grouping
        image_entry = next((img for img in self.loaded_images if img['file_path'] == file_path), None)
        if not image_entry:
            return

        header = image_entry['header']
        object_name = header.get('OBJECT', 'Unknown') if header else 'Unknown'
        filter_name = header.get('FILTER', 'Unknown') if header else 'Unknown'
        exposure_time = header.get('EXPOSURE', 'Unknown') if header else 'Unknown'

        # Group images by filter and exposure time
        group_key = (object_name, filter_name, exposure_time)

        # Find or create the object item
        object_item = self.findTopLevelItemByName(f"Object: {object_name}")
        if not object_item:
            object_item = QTreeWidgetItem([f"Object: {object_name}"])
            self.fileTree.addTopLevelItem(object_item)
            object_item.setExpanded(True)

        # Find or create the filter item
        filter_item = self.findChildItemByName(object_item, f"Filter: {filter_name}")
        if not filter_item:
            filter_item = QTreeWidgetItem([f"Filter: {filter_name}"])
            object_item.addChild(filter_item)
            filter_item.setExpanded(True)

        # Find or create the exposure item
        exposure_item = self.findChildItemByName(filter_item, f"Exposure: {exposure_time}")
        if not exposure_item:
            exposure_item = QTreeWidgetItem([f"Exposure: {exposure_time}"])
            filter_item.addChild(exposure_item)
            exposure_item.setExpanded(True)

        # Add the file item
        file_name = os.path.basename(file_path)
        item = QTreeWidgetItem([file_name])
        exposure_item.addChild(item)



    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Debayer a RAW image based on the Bayer pattern."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern (Debayering logic example)
            r = raw_image_data[::2, ::2]  # Red
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            b = raw_image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        
        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = raw_image_data[::2, ::2]  # Blue
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            r = raw_image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            r = raw_image_data[::2, 1::2]  # Red
            b = raw_image_data[1::2, ::2]  # Blue
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            b = raw_image_data[::2, 1::2]  # Blue
            r = raw_image_data[1::2, ::2]  # Red
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")
    


    def on_item_clicked(self, item, column):
        """Handle click on a file name in the tree to preview the image."""
        self.fileTree.setFocus()

        file_name = item.text(0)
        file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

        if file_path:
            # Get the index of the clicked image
            index = self.image_paths.index(file_path)

            # Retrieve the corresponding image data and header from the loaded images
            stretched_image = self.loaded_images[index]['image_data']

            # Convert to QImage and display
            qimage = self.convert_to_qimage(stretched_image)
            pixmap = QPixmap.fromImage(qimage)

            # Store the pixmap for zooming
            self.current_pixmap = pixmap

            # Apply zoom level
            self.apply_zoom()

    def apply_zoom(self):
        """Apply the current zoom level to the pixmap and update the display."""
        if self.current_pixmap:
            # Scale the pixmap based on the zoom level
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_level,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation,
            )

            # Update the QLabel with the scaled pixmap
            self.preview_label.setPixmap(scaled_pixmap)
            self.preview_label.resize(scaled_pixmap.size())

            # Adjust scroll position to center the view
            self.scroll_area.horizontalScrollBar().setValue(
                (self.preview_label.width() - self.scroll_area.viewport().width()) // 2
            )
            self.scroll_area.verticalScrollBar().setValue(
                (self.preview_label.height() - self.scroll_area.viewport().height()) // 2
            )

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        """Increase the zoom level and refresh the image."""
        self.zoom_level = min(self.zoom_level * 1.2, 3.0)  # Cap at 3x
        self.apply_zoom()

    def zoom_out(self):
        """Decrease the zoom level and refresh the image."""
        self.zoom_level = max(self.zoom_level / 1.2, 0.05)  # Cap at 0.2x
        self.apply_zoom()


    def fit_to_preview(self):
        """Adjust the zoom level so the image fits within the QScrollArea viewport."""
        if self.current_pixmap:
            # Get the size of the QScrollArea's viewport
            viewport_size = self.scroll_area.viewport().size()
            pixmap_size = self.current_pixmap.size()

            # Calculate the zoom level required to fit the pixmap in the QScrollArea viewport
            width_ratio = viewport_size.width() / pixmap_size.width()
            height_ratio = viewport_size.height() / pixmap_size.height()
            self.zoom_level = min(width_ratio, height_ratio)

            # Apply the zoom level
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def on_right_click(self, pos):
        """Allow renaming, moving, deleting, and batch operations on images."""
        item = self.fileTree.itemAt(pos)
        menu = QMenu(self)

        if item:
            # Existing actions
            push_action = QAction("Push Image for Processing", self)
            push_action.triggered.connect(lambda: self.push_image_to_manager(item))
            menu.addAction(push_action)

            rename_action = QAction("Rename", self)
            rename_action.triggered.connect(lambda: self.rename_item(item))
            menu.addAction(rename_action)

            move_action = QAction("Move Selected Items", self)
            move_action.triggered.connect(lambda: self.move_items())
            menu.addAction(move_action)

            delete_action = QAction("Delete Selected Items", self)
            delete_action.triggered.connect(lambda: self.delete_items())
            menu.addAction(delete_action)

        # Batch operations
        menu.addSeparator()

        batch_delete_action = QAction("Delete All Flagged Images", self)
        batch_delete_action.triggered.connect(self.batch_delete_flagged_images)
        menu.addAction(batch_delete_action)

        batch_move_action = QAction("Move All Flagged Images", self)
        batch_move_action.triggered.connect(self.batch_move_flagged_images)
        menu.addAction(batch_move_action)

        menu.exec(self.fileTree.mapToGlobal(pos))

    def rename_item(self, item):
        """Allow the user to rename the selected image."""
        current_name = item.text(0).lstrip("⚠️ ")
        new_name, ok = QInputDialog.getText(self, "Rename Image", "Enter new name:", text=current_name)

        if ok and new_name:
            file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)
            if file_path:
                # Get the new file path with the new name
                new_file_path = os.path.join(os.path.dirname(file_path), new_name)

                try:
                    # Rename the file
                    os.rename(file_path, new_file_path)
                    print(f"File renamed from {current_name} to {new_name}")
                    
                    # Update the image paths and tree view
                    self.image_paths[self.image_paths.index(file_path)] = new_file_path
                    item.setText(0, new_name)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

    def batch_rename_items(self):
        """Batch rename selected items by adding a prefix or suffix."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for renaming.")
            return

        # Create a custom dialog for entering the prefix and suffix
        dialog = QDialog(self)
        dialog.setWindowTitle("Batch Rename")
        dialog_layout = QVBoxLayout(dialog)

        instruction_label = QLabel("Enter a prefix or suffix to rename selected files:")
        dialog_layout.addWidget(instruction_label)

        # Create fields for prefix and suffix
        form_layout = QHBoxLayout()

        prefix_field = QLineEdit(dialog)
        prefix_field.setPlaceholderText("Prefix")
        form_layout.addWidget(prefix_field)

        current_filename_label = QLabel("currentfilename", dialog)
        form_layout.addWidget(current_filename_label)

        suffix_field = QLineEdit(dialog)
        suffix_field.setPlaceholderText("Suffix")
        form_layout.addWidget(suffix_field)

        dialog_layout.addLayout(form_layout)

        # Add OK and Cancel buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK", dialog)
        ok_button.clicked.connect(dialog.accept)
        button_layout.addWidget(ok_button)

        cancel_button = QPushButton("Cancel", dialog)
        cancel_button.clicked.connect(dialog.reject)
        button_layout.addWidget(cancel_button)

        dialog_layout.addLayout(button_layout)

        # Show the dialog and handle user input
        if dialog.exec() == QDialog.DialogCode.Accepted:
            prefix = prefix_field.text().strip()
            suffix = suffix_field.text().strip()

            # Rename each selected file
            for item in selected_items:
                current_name = item.text(0)
                file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)

                if file_path:
                    # Construct the new filename
                    directory = os.path.dirname(file_path)
                    new_name = f"{prefix}{current_name}{suffix}"
                    new_file_path = os.path.join(directory, new_name)

                    try:
                        # Rename the file
                        os.rename(file_path, new_file_path)
                        print(f"File renamed from {file_path} to {new_file_path}")

                        # Update the paths and tree view
                        self.image_paths[self.image_paths.index(file_path)] = new_file_path
                        item.setText(0, new_name)

                    except Exception as e:
                        print(f"Failed to rename {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

            print(f"Batch renamed {len(selected_items)} items.")

    def batch_delete_flagged_images(self):
        """Delete all flagged images."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to delete.")
            return

        confirmation = QMessageBox.question(
            self,
            "Confirm Batch Deletion",
            f"Are you sure you want to permanently delete {len(flagged_images)} flagged images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if confirmation == QMessageBox.StandardButton.Yes:
            for img in flagged_images:
                file_path = img['file_path']
                try:
                    os.remove(file_path)
                    print(f"Deleted flagged image: {file_path}")
                except Exception as e:
                    print(f"Failed to delete {file_path}: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to delete {file_path}: {e}")

                # Remove from data structures
                self.image_paths.remove(file_path)
                self.loaded_images.remove(img)

                # Remove from tree view
                self.remove_item_from_tree(file_path)

            QMessageBox.information(self, "Batch Deletion", f"Deleted {len(flagged_images)} flagged images.")

    def batch_move_flagged_images(self):
        """Move all flagged images to a selected directory."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to move.")
            return

        # Select destination directory
        destination_dir = QFileDialog.getExistingDirectory(self, "Select Destination Folder", "")
        if not destination_dir:
            return  # User canceled

        for img in flagged_images:
            src_path = img['file_path']
            file_name = os.path.basename(src_path)
            dest_path = os.path.join(destination_dir, file_name)

            try:
                os.rename(src_path, dest_path)
                print(f"Moved flagged image from {src_path} to {dest_path}")
            except Exception as e:
                print(f"Failed to move {src_path}: {e}")
                QMessageBox.critical(self, "Error", f"Failed to move {src_path}: {e}")
                continue

            # Update data structures
            self.image_paths.remove(src_path)
            self.image_paths.append(dest_path)
            img['file_path'] = dest_path
            img['flagged'] = False  # Reset flag if desired

            # Update tree view
            self.remove_item_from_tree(src_path)
            self.add_item_to_tree(dest_path)

        QMessageBox.information(self, "Batch Move", f"Moved {len(flagged_images)} flagged images.")


    def move_items(self):
        """Allow the user to move selected images to a different directory."""
        selected_items = self.fileTree.selectedItems()
        
        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for moving.")
            return

        # Open file dialog to select a new directory
        new_directory = QFileDialog.getExistingDirectory(self, "Select Destination Folder", "")
        if not new_directory:
            return  # User canceled the directory selection

        for item in selected_items:
            current_name = item.text(0).lstrip("⚠️ ")
            file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)

            if file_path:
                new_file_path = os.path.join(new_directory, current_name)

                try:
                    # Move the file
                    os.rename(file_path, new_file_path)
                    print(f"File moved from {file_path} to {new_file_path}")
                    
                    # Update the image paths
                    self.image_paths[self.image_paths.index(file_path)] = new_file_path
                    item.setText(0, current_name)  # Update the tree view item's text (if needed)

                except Exception as e:
                    print(f"Failed to move {file_path}: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to move the file: {e}")

        # Update the tree view to reflect the moved items
        self.fileTree.clear()
        for file_path in self.image_paths:
            file_name = os.path.basename(file_path)
            item = QTreeWidgetItem([file_name])
            self.fileTree.addTopLevelItem(item)

        print(f"Moved {len(selected_items)} items.")

    def push_image_to_manager(self, item):
        """Push the selected image to the ImageManager."""
        file_name = item.text(0).lstrip("⚠️ ")
        file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

        if file_path and self.image_manager:
            # Load the image into ImageManager
            image, header, bit_depth, is_mono = load_image(file_path)

            # Check for Bayer pattern or RAW image type (For FITS and RAW images)
            if file_path.lower().endswith(('.fits', '.fit')):
                # For FITS, check the header for Bayer pattern
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    print(f"Bayer pattern detected in FITS image: {bayer_pattern}")
                    # Debayer the FITS image based on the Bayer pattern
                    image = self.debayer_fits(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono

            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                # For RAW images, debayer directly using the raw image data
                print(f"Debayering RAW image: {file_path}")
                # We assume `header` contains the Bayer pattern info from rawpy
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    # Debayer the RAW image based on the Bayer pattern
                    image = self.debayer_raw(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono
                else:
                    # If no Bayer pattern in the header, default to RGGB for debayering
                    print("No Bayer pattern found in RAW header. Defaulting to RGGB.")
                    image = self.debayer_raw(image, 'RGGB')
                    is_mono = False  # After debayering, the image is no longer mono

            # Create metadata for the image
            metadata = {
                'file_path': file_path,
                'original_header': header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }

            # Add the debayered image to ImageManager (use the current slot)
            self.image_manager.add_image(self.image_manager.current_slot, image, metadata)
            print(f"Image {file_path} pushed to ImageManager for processing.")

    def delete_items(self):
        """Delete the selected items from the tree, the loaded images list, and the file system."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for deletion.")
            return

        # Confirmation dialog
        reply = QMessageBox.question(
            self,
            'Confirm Deletion',
            f"Are you sure you want to permanently delete {len(selected_items)} selected images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            for item in selected_items:
                file_name = item.text(0).lstrip("⚠️ ")
                file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

                if file_path:
                    try:
                        # Remove the image from image_paths
                        if file_path in self.image_paths:
                            self.image_paths.remove(file_path)
                            print(f"Image path {file_path} removed from image_paths.")
                        else:
                            print(f"Image path {file_path} not found in image_paths.")

                        # Remove the corresponding image from loaded_images
                        matching_image_data = next((entry for entry in self.loaded_images if entry['file_path'] == file_path), None)
                        if matching_image_data:
                            self.loaded_images.remove(matching_image_data)
                            print(f"Image {file_name} removed from loaded_images.")
                        else:
                            print(f"Image {file_name} not found in loaded_images.")

                        # Delete the file from the filesystem
                        os.remove(file_path)
                        print(f"File {file_path} deleted successfully.")

                    except Exception as e:
                        print(f"Failed to delete {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to delete the image file: {e}")

            # Remove the selected items from the TreeWidget
            for item in selected_items:
                parent = item.parent()
                if parent:
                    parent.removeChild(item)
                else:
                    index = self.fileTree.indexOfTopLevelItem(item)
                    if index != -1:
                        self.fileTree.takeTopLevelItem(index)

            print(f"Deleted {len(selected_items)} items.")

            # Clear the preview if the deleted items include the currently displayed image
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')

            self.current_image = None

    def eventFilter(self, source, event):
        """Handle mouse events for dragging."""
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                # Start dragging
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                # Handle dragging
                delta = event.pos() - self.last_mouse_pos
                self.scroll_area.horizontalScrollBar().setValue(
                    self.scroll_area.horizontalScrollBar().value() - delta.x()
                )
                self.scroll_area.verticalScrollBar().setValue(
                    self.scroll_area.verticalScrollBar().value() - delta.y()
                )
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                # Stop dragging
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def on_selection_changed(self, selected, deselected):
        """Handle the selection change event."""
        # Get the selected item from the TreeView
        selected_items = self.fileTree.selectedItems()
        if selected_items:
            item = selected_items[0]  # Get the first selected item (assuming single selection)
            self.on_item_clicked(item, 0)  # Update the preview with the selected image

    def convert_to_qimage(self, img_array):
        """Convert numpy image array to QImage."""
        img_array = (img_array * 255).astype(np.uint8)  # Ensure image is in uint8
        h, w = img_array.shape[:2]

        # Convert the image data to a byte buffer
        img_data = img_array.tobytes()  # This converts the image to a byte buffer

        if img_array.ndim == 3:  # RGB Image
            return QImage(img_data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:  # Grayscale Image
            return QImage(img_data, w, h, w, QImage.Format.Format_Grayscale8)

class CosmicClarityTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.settings_file = "cosmic_clarity_folder.txt"  # Path to save the folder location
        self.zoom_factor = 1  # Zoom level
        self.drag_start_position = QPoint()  # Starting point for drag
        self.is_dragging = False  # Flag to indicate if dragging
        self.scroll_position = QPoint(0, 0)  # Initialize scroll position
        self.original_image = None  # Image before processing
        self.processed_image = None  # Most recent processed image    
        self.is_selecting_preview = False  # Initialize preview selection attribute
        self.preview_start_position = None
        self.preview_end_position = None
        self.preview_rect = None  # Stores the preview selection rectangle
        self.autostretch_enabled = False  # Track autostretch status
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")
        self.cosmic_clarity_folder = None
        self.cropped_operation_queue = []
        self.image = None

        self.initUI()

        self.load_cosmic_clarity_folder()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left panel for controls
        left_layout = QVBoxLayout()

        

        # Load button to load an image
        self.load_button = QPushButton("Load Image")
        self.load_button.clicked.connect(self.load_image)
        left_layout.addWidget(self.load_button)

        # AutoStretch toggle button
        self.auto_stretch_button = QPushButton("AutoStretch (Off)")
        self.auto_stretch_button.setCheckable(True)
        self.auto_stretch_button.toggled.connect(self.toggle_auto_stretch)
        left_layout.addWidget(self.auto_stretch_button)

        # Radio buttons to switch between Sharpen and Denoise
        self.sharpen_radio = QRadioButton("Sharpen")
        self.denoise_radio = QRadioButton("Denoise")
        self.both_radio = QRadioButton("Both")
        
        self.sharpen_radio.setChecked(True)  # Default to Sharpen
        self.sharpen_radio.toggled.connect(self.update_ui_for_mode)
        self.denoise_radio.toggled.connect(self.update_ui_for_mode)
        self.both_radio.toggled.connect(self.update_ui_for_mode)  
        left_layout.addWidget(self.sharpen_radio)
        left_layout.addWidget(self.denoise_radio)
        left_layout.addWidget(self.both_radio)

        # GPU Acceleration dropdown
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Add Sharpening specific controls
        self.sharpen_mode_label = QLabel("Sharpening Mode:")
        self.sharpen_mode_dropdown = QComboBox()
        self.sharpen_mode_dropdown.addItems(["Both", "Stellar Only", "Non-Stellar Only"])
        left_layout.addWidget(self.sharpen_mode_label)
        left_layout.addWidget(self.sharpen_mode_dropdown)

        # Dropdown for Sharpen Channels Separately option
        self.sharpen_channels_label = QLabel("Sharpen RGB Channels Separately:")
        self.sharpen_channels_dropdown = QComboBox()
        self.sharpen_channels_dropdown.addItems(["No", "Yes"])  # "No" means don't separate, "Yes" means separate
        left_layout.addWidget(self.sharpen_channels_label)
        left_layout.addWidget(self.sharpen_channels_dropdown)

        # Non-Stellar Sharpening PSF Slider
        self.psf_slider_label = QLabel("Non-Stellar Sharpening PSF (1-8): 3")
        self.psf_slider = QSlider(Qt.Orientation.Horizontal)
        self.psf_slider.setMinimum(10)
        self.psf_slider.setMaximum(80)
        self.psf_slider.setValue(30)
        self.psf_slider.valueChanged.connect(self.update_psf_slider_label)
        left_layout.addWidget(self.psf_slider_label)
        left_layout.addWidget(self.psf_slider)

        # Stellar Amount Slider
        self.stellar_amount_label = QLabel("Stellar Sharpening Amount (0-1): 0.50")
        self.stellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.stellar_amount_slider.setMinimum(0)
        self.stellar_amount_slider.setMaximum(100)
        self.stellar_amount_slider.setValue(50)
        self.stellar_amount_slider.valueChanged.connect(self.update_stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_slider)

        # Non-Stellar Amount Slider
        self.nonstellar_amount_label = QLabel("Non-Stellar Sharpening Amount (0-1): 0.50")
        self.nonstellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.nonstellar_amount_slider.setMinimum(0)
        self.nonstellar_amount_slider.setMaximum(100)
        self.nonstellar_amount_slider.setValue(50)
        self.nonstellar_amount_slider.valueChanged.connect(self.update_nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_slider)

        # Denoise Strength Slider
        self.denoise_strength_label = QLabel("Denoise Strength (0-1): 0.50")
        self.denoise_strength_slider = QSlider(Qt.Orientation.Horizontal)
        self.denoise_strength_slider.setMinimum(0)
        self.denoise_strength_slider.setMaximum(100)
        self.denoise_strength_slider.setValue(50)
        self.denoise_strength_slider.valueChanged.connect(self.update_denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_slider)

        # Denoise Mode dropdown
        self.denoise_mode_label = QLabel("Denoise Mode:")
        self.denoise_mode_dropdown = QComboBox()
        self.denoise_mode_dropdown.addItems(["luminance", "full"])  # 'luminance' for luminance-only, 'full' for full YCbCr denoising
        left_layout.addWidget(self.denoise_mode_label)
        left_layout.addWidget(self.denoise_mode_dropdown)

        # Execute button
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.run_cosmic_clarity)
        left_layout.addWidget(self.execute_button)

        # Save button to save the processed image
        self.save_button = QPushButton("Save Image")
        self.save_button.clicked.connect(self.save_processed_image_to_disk)
        #left_layout.addWidget(self.save_button)  

        # Spacer to push the wrench button to the bottom
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Cosmic Clarity folder path label
        self.cosmic_clarity_folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.cosmic_clarity_folder_label)

        # Wrench button to select Cosmic Clarity folder
        self.wrench_button = QPushButton()

        # Set the path for the wrench icon
        if hasattr(sys, '_MEIPASS'):
            wrench_path = os.path.join(sys._MEIPASS, "wrench_icon.png")
        else:
            wrench_path = "wrench_icon.png"

        self.wrench_button.setIcon(QIcon(wrench_path))  # Set the wrench icon with the dynamic path
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)  

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)   


        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Right panel for image preview with zoom controls
        right_layout = QVBoxLayout()

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview with click-and-drag functionality
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.image_label)
        right_layout.addWidget(self.scroll_area)

        # Button to open the preview area selection dialog
        self.select_preview_button = QPushButton("Select Preview Area")
        self.select_preview_button.clicked.connect(self.open_preview_dialog)
        right_layout.addWidget(self.select_preview_button)        

        left_widget = QWidget()
        left_widget.setLayout(left_layout)
        left_widget.setFixedWidth(400)

        # Add left and right layouts to the main layout
        main_layout.addWidget(left_widget)
        main_layout.addLayout(right_layout)

        self.setLayout(main_layout)
        self.update_ui_for_mode()

    def update_image_display(self):
        """
        Update the displayed image by scaling the stored base pixmap according
        to the current zoom factor.
        """
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            print("Base pixmap not available. Please update it first.")
            return

        # Calculate new dimensions using the current zoom factor.
        new_width = int(self.base_pixmap.width() * self.zoom_factor)
        new_height = int(self.base_pixmap.height() * self.zoom_factor)
        
        # Scale the base pixmap quickly.
        scaled_pixmap = self.base_pixmap.scaled(
            new_width, new_height,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        
        self.image_label.setPixmap(scaled_pixmap)


        # Optionally, adjust scroll bars to keep the view centered.
        # (You might reuse your current code for centering.)


    def update_base_pixmap(self):
        """
        Process self.image (applying autostretch if enabled) and store it as self.base_pixmap.
        If self.image is empty or not as expected, it skips processing.
        """
        if self.image is None or self.image.size == 0:
            print("[WARNING] No image available to update base pixmap.")
            self.base_pixmap = None
            return

        display_image = self.image.copy()

        # Apply autostretch if enabled.
        if self.auto_stretch_button.isChecked():
            target_median = 0.25
            # Check image dimensions to decide whether it's mono or color.
            if display_image.ndim < 3 or (display_image.ndim == 3 and display_image.shape[2] != 3):
                # Treat as grayscale: if image is 3D but not 3 channels, pick one channel
                try:
                    mono_source = display_image if display_image.ndim == 2 else display_image[:, :, 0]
                    stretched = stretch_mono_image(mono_source, target_median, normalize=True)
                    # Convert grayscale to 3-channel for display.
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            else:
                # Color image with three channels.
                try:
                    display_image = stretch_color_image(display_image, target_median, linked=False, normalize=True)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return

        try:
            display_image_uint8 = (display_image * 255).astype(np.uint8)
        except Exception as e:
            print(f"[ERROR] Converting image to uint8: {e}")
            return

        # Create a QImage from the numpy array.
        if display_image_uint8.ndim == 3 and display_image_uint8.shape[2] == 3:
            height, width, _ = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif display_image_uint8.ndim == 2:
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            print("[ERROR] Unexpected image format!")
            return

        self.base_pixmap = QPixmap.fromImage(qimage)
        print("Base pixmap updated.")

    def update_psf_slider_label(self):
        """Update the label text to display the current value of the PSF slider as a non-integer."""
        psf_value = self.psf_slider.value() / 10  # Convert to a float in the range 1.0 - 8.0
        self.psf_slider_label.setText(f"Non-Stellar Sharpening PSF (1.0-8.0): {psf_value:.1f}")

    def update_stellar_amount_label(self):
        self.stellar_amount_label.setText(f"Stellar Sharpening Amount (0-1): {self.stellar_amount_slider.value() / 100:.2f}")

    def update_nonstellar_amount_label(self):
        self.nonstellar_amount_label.setText(f"Non-Stellar Sharpening Amount (0-1): {self.nonstellar_amount_slider.value() / 100:.2f}")

    def update_denoise_strength_label(self):
        self.denoise_strength_label.setText(f"Denoise Strength (0-1): {self.denoise_strength_slider.value() / 100:.2f}")

    def mousePressEvent(self, event):
        """Handle the start of the drag action or selection of a preview area."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.is_dragging = True
            self.drag_start_position = event.pos()              
                

    def mouseMoveEvent(self, event):
        """Handle dragging or adjusting the preview selection area."""
        if self.is_dragging:
            # Handle image panning
            delta = event.pos() - self.drag_start_position
            self.scroll_area.horizontalScrollBar().setValue(self.scroll_area.horizontalScrollBar().value() - delta.x())
            self.scroll_area.verticalScrollBar().setValue(self.scroll_area.verticalScrollBar().value() - delta.y())
            self.drag_start_position = event.pos()


    def mouseReleaseEvent(self, event):
        """End the drag action or finalize the preview selection area."""
        if event.button() == Qt.MouseButton.LeftButton:
            if self.is_dragging:
                self.is_dragging = False


    def open_preview_dialog(self):
        """Open a preview dialog to select a 640x480 area of the image at 100% scale."""
        if self.image is not None:
            # Pass the 32-bit numpy image directly to maintain bit depth
            self.preview_dialog = PreviewDialog(self.image, parent_tab=self, is_mono=self.is_mono)
            self.preview_dialog.show()
        else:
            print("No image loaded. Please load an image first.")



    def convert_numpy_to_qimage(self, np_img):
        """Convert a numpy array to QImage."""
        # Ensure image is in 8-bit format for QImage compatibility
        if np_img.dtype == np.float32:
            np_img = (np_img * 255).astype(np.uint8)  # Convert normalized float32 to uint8 [0, 255]
        
        if np_img.dtype == np.uint8:
            if len(np_img.shape) == 2:
                # Grayscale image
                height, width = np_img.shape
                bytes_per_line = width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            elif len(np_img.shape) == 3 and np_img.shape[2] == 3:
                # RGB image
                height, width, channels = np_img.shape
                bytes_per_line = 3 * width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            print("Image format not supported for conversion to QImage.")
            return None

    def validate_cosmic_clarity_folder(self):
        """Check if the Cosmic Clarity folder is set and valid."""
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(
                self,
                "Missing Folder",
                "The Cosmic Clarity folder is not set. Please use the wrench icon to select the correct folder."
            )
            return False

        # Determine the expected executable based on the platform
        if os.name == "nt":  # Windows
            expected_executable = "SetiAstroCosmicClarity.exe"
        elif sys.platform == "darwin":  # macOS
            expected_executable = "SetiAstroCosmicClaritymac"
        else:  # Linux
            expected_executable = "SetiAstroCosmicClarity"  # Case-sensitive, no extension

        # Check if the expected executable exists in the folder
        executable_path = os.path.join(self.cosmic_clarity_folder, expected_executable)
        if not os.path.exists(executable_path):
            QMessageBox.warning(
                self,
                "Invalid Folder",
                f"Incorrect Cosmic Clarity folder. Please choose the parent folder containing the Cosmic Clarity executable:\n\n"
                f"Expected file: {expected_executable}"
            )
            return False

        return True



    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.save_cosmic_clarity_folder(folder)
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.update_image_display()

    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.update_image_display()

    def fit_to_preview(self):
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            return
        preview_width = self.scroll_area.viewport().width()
        self.zoom_factor = preview_width / self.base_pixmap.width()
        self.update_image_display()


    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.update_image_display()  # Call without extra arguments; it will calculate dimensions based on zoom factor
    



    def restore_image(self, image_array):
        """Display a given image array, preserving the current zoom level and scroll position."""
        # Save the current zoom level and scroll position
        current_zoom = self.zoom_factor
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Display the image
        self.show_image(image_array)

        # Restore the zoom level and scroll position
        self.zoom_factor = current_zoom
        self.update_image_display()  # Refresh display with the preserved zoom level

        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])


    def save_cosmic_clarity_folder(self, folder):
        """Save the Cosmic Clarity folder path using QSettings."""
        self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
        print(f"Saved Cosmic Clarity folder to QSettings: {folder}")

    def load_cosmic_clarity_folder(self):
        """Load the saved Cosmic Clarity folder path from QSettings."""
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            print(f"Loaded Cosmic Clarity folder from QSettings: {folder}")
        else:
            print("No saved Cosmic Clarity folder found in QSettings.")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return
        if image is None:
            return        
        if slot == self.image_manager.current_slot:
            self.loaded_image_path = metadata.get('file_path', None)
            self.original_header = metadata.get('original_header', None)
            self.bit_depth = metadata.get('bit_depth', None)
            self.is_mono = metadata.get('is_mono', False)

            # Ensure image is in numpy array format
            if not isinstance(image, np.ndarray):
                image = np.array(image)

            # Handle mono and color images
            if self.is_mono:
                # Squeeze the singleton dimension for grayscale images if it exists
                if len(image.shape) == 3 and image.shape[2] == 1:
                    print(f"Mono image detected with shape: {image.shape}. Squeezing singleton dimension.")
                    image = np.squeeze(image, axis=2)  # Convert (H, W, 1) to (H, W)

                # Convert 2D grayscale to RGB by stacking it
                if len(image.shape) == 2:
                    print(f"Converting mono image with shape: {image.shape} to 3-channel RGB.")
                    image = np.stack([image] * 3, axis=-1)

            elif len(image.shape) == 3 and image.shape[2] not in [1, 3]:
                # Catch unexpected formats like (H, W, C) where C is not 1 or 3
                raise ValueError(f"Unexpected image format with shape {image.shape}. Must be RGB or Grayscale.")

            self.image = image

            # Show the image using the show_image method
            self.update_base_pixmap()
            # Now update the display by scaling the base pixmap.
            self.update_image_display()
            print(f"CosmicClarityTab: Image updated from ImageManager slot {slot}.")



    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def load_image(self):
        """Load an image and set it as the current and original image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.jpg *.tif *.tiff *.fits *.fit *.jpeg *.xisf)"
        )
        if file_path:
            print(f"Loading file: {file_path}")

            # Load the image and store it as the original image
            image, original_header, bit_depth, is_mono = load_image(file_path)
            
            # Check if the image was loaded successfully
            if image is None:
                print("Error: Failed to load the image data.")
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            print(f"Image loaded successfully. Shape: {image.shape}, Dtype: {image.dtype}")

            # Make a copy of the original image for reference
            try:
                self.original_image = image.copy()
                print("Original image copied successfully.")
            except Exception as e:
                print(f"Error copying original image: {e}")
                QMessageBox.critical(self, "Error", "Failed to copy the original image.")
                return

            # Clear any existing processed image
            self.processed_image = None

            # Attempt to display the loaded image in the preview
            try:
                self.show_image(image)  # Ensure this function can handle 32-bit float images
                print("Image displayed successfully.")
            except Exception as e:
                print(f"Error displaying image: {e}")
                QMessageBox.critical(self, "Error", "Failed to display the image.")
                return

            # Enable or disable buttons as necessary


            # Center scrollbars after a short delay
            try:
                QTimer.singleShot(50, self.center_scrollbars)  # Delay of 50 ms for centering scrollbars
                print("Scrollbars centered.")
            except Exception as e:
                print(f"Error centering scrollbars: {e}")

            # Update the display after another short delay to ensure scrollbars are centered first
            try:
                QTimer.singleShot(100, self.update_image_display)  # Delay of 100 ms for display update
                print("Image display updated.")
            except Exception as e:
                print(f"Error updating image display: {e}")

            # Update ImageManager with the new image
            metadata = {
                'file_path': file_path,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

        else:
            print("No file selected.")



    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def show_image(self, image=None):
        """
        Display the loaded image by updating the base pixmap (which applies autostretch)
        and then updating the display using that pixmap.
        """
        # Use the passed image if provided; otherwise use self.image.
        if image is not None:
            self.image = image

        if self.image is None:
            print("[ERROR] No image to display.")
            QMessageBox.warning(self, "No Image", "No image data available to display.")
            return False

        # Save the current scroll position so it can be restored.
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Update the base pixmap (this applies autostretch if the auto_stretch_button is checked)
        self.update_base_pixmap()
        
        # Now update the display using the base pixmap.
        self.update_image_display()

        # Restore the scroll position.
        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])

        return True


    def store_processed_image(self, processed_image):
        """Store the processed image and update the ImageManager."""
        if processed_image is not None:
            # Prepare metadata for the ImageManager
            metadata = {
                'file_path': self.loaded_image_path,      # Ensure this is correctly set elsewhere
                'original_header': self.original_header,  # Ensure this is correctly set elsewhere
                'bit_depth': self.bit_depth,              # Ensure this is correctly set elsewhere
                'is_mono': self.is_mono                   # Ensure this is correctly set elsewhere
            }

            # Use ImageManager's set_image method to manage undo/redo stack
            if self.image_manager:
                try:
                    self.image_manager.set_image(processed_image, metadata)
                    print("CosmicClarityTab: Processed image stored in ImageManager with undo/redo support.")
                except Exception as e:
                    # Handle potential errors during the update
                    QMessageBox.critical(self, "Error", f"Failed to store processed image in ImageManager:\n{e}")
                    print(f"Error storing processed image in ImageManager: {e}")
            else:
                print("ImageManager is not initialized.")
                QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
        else:
            print("No processed image available to store.")
            QMessageBox.warning(self, "Warning", "No processed image available to store.")


    def toggle_auto_stretch(self, checked):
        """Toggle autostretch and update the display."""
        self.autostretch_enabled = checked
        self.auto_stretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        # Recalculate the base pixmap using the new autostretch setting.
        self.update_base_pixmap()
        # Then update the displayed image.
        self.update_image_display()



    def save_input_image(self, file_path):
        """Save the current image to the specified path in TIF format."""
        if self.image is not None:
            try:
                from tifffile import imwrite
                # Force saving as `.tif` format
                if not file_path.endswith(".tif"):
                    file_path += ".tif"
                imwrite(file_path, self.image.astype(np.float32))
                print(f"Image saved as TIFF to {file_path}")  # Debug print
            except Exception as e:
                print(f"Error saving input image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save input image:\n{e}")
        else:
            QMessageBox.warning(self, "Warning", "No image to save.")

    def update_ui_for_mode(self):
        # Show/hide controls based on the selected mode
        if self.sharpen_radio.isChecked():
            self.show_sharpen_controls()
            self.hide_denoise_controls()
        elif self.denoise_radio.isChecked():
            self.hide_sharpen_controls()
            self.show_denoise_controls()
        elif self.both_radio.isChecked():
            self.show_sharpen_controls()
            self.show_denoise_controls()

    def show_sharpen_controls(self):
        self.sharpen_mode_label.show()
        self.sharpen_mode_dropdown.show()
        self.psf_slider_label.show()
        self.psf_slider.show()
        self.stellar_amount_label.show()
        self.stellar_amount_slider.show()
        self.nonstellar_amount_label.show()
        self.nonstellar_amount_slider.show()
        self.sharpen_channels_label.show()
        self.sharpen_channels_dropdown.show()

    def hide_sharpen_controls(self):
        self.sharpen_mode_label.hide()
        self.sharpen_mode_dropdown.hide()
        self.psf_slider_label.hide()
        self.psf_slider.hide()
        self.stellar_amount_label.hide()
        self.stellar_amount_slider.hide()
        self.nonstellar_amount_label.hide()
        self.nonstellar_amount_slider.hide()
        self.sharpen_channels_label.hide()
        self.sharpen_channels_dropdown.hide()

    def show_denoise_controls(self):
        self.denoise_strength_label.show()
        self.denoise_strength_slider.show()
        self.denoise_mode_label.show()
        self.denoise_mode_dropdown.show()

    def hide_denoise_controls(self):
        self.denoise_strength_label.hide()
        self.denoise_strength_slider.hide()
        self.denoise_mode_label.hide()
        self.denoise_mode_dropdown.hide()


    def get_psf_value(self):
        """Convert the slider value to a float in the range 1.0 - 8.0."""
        return self.psf_slider.value() / 10.0
    
    def run_cosmic_clarity(self, input_file_path=None):
        """Run Cosmic Clarity with the current parameters."""
        if not self.validate_cosmic_clarity_folder():
            return  # Stop execution if the folder is not valid

        psf_value = self.get_psf_value()
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return
        if self.image is None:  # Ensure an image is currently displayed
            QMessageBox.warning(self, "Warning", "Please load an image first.")
            return

        # Check the current autostretch state
        was_autostretch_enabled = self.auto_stretch_button.isChecked()

        # Disable autostretch if it was enabled
        if was_autostretch_enabled:
            self.auto_stretch_button.setChecked(False)

        # Determine mode from the radio buttons
        if self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        elif self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.operation_queue = list(zip(modes, output_suffixes))



        # Start the first operation
        if self.operation_queue:
            self._execute_cosmic_clarity(*self.operation_queue.pop(0))

    def _execute_cosmic_clarity(self, mode, output_suffix):
        if self.loaded_image_path is None:
            print("Warning: loaded_image_path is None. Using default base filename 'image'.")
            base_filename = "image"
        else:
            base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        print(f"Base filename before saving: {base_filename}")  # Debug print
        """Execute a single Cosmic Clarity operation."""
        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")


        # Save the current previewed image directly to the input folder
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")
        self.save_input_image(input_file_path)  # Save as `.tif`
        self.current_input_file_path = input_file_path

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.tif")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Use QProcess instead of subprocess
        self.process_q = QProcess(self)
        self.process_q.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q.readyReadStandardOutput.connect(self.qprocess_output_main)
        self.process_q.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished(mode, exitCode, exitStatus))

        # Start the process
        self.process_q.setProgram(exe_path)
        self.process_q.setArguments(args)
        self.process_q.start()

        if not self.process_q.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Set up file waiting worker and wait dialog
        self.wait_thread = WaitForFileWorker(output_file_glob, timeout=3000)
        self.wait_thread.fileFound.connect(self.on_file_found)
        self.wait_thread.error.connect(self.on_file_error)
        self.wait_thread.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog = WaitDialog(self)
        self.wait_dialog.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog.show()

        self.wait_thread.start()


    ########################################
    # Below are the new helper slots (methods) to handle signals from worker and dialog.
    ########################################

    def qprocess_output(self):
        if not hasattr(self, 'process_q_cropped') or self.process_q_cropped is None:
            return
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)

    def qprocess_output_main(self):
        """Handle output from the main Cosmic Clarity process."""
        output = self.process_q.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog') and self.wait_dialog:
                        self.wait_dialog.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog') and self.wait_dialog:
                    self.wait_dialog.append_output(line)


    def qprocess_output_cropped(self):
        """Handle output from the cropped Cosmic Clarity process."""
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)


    def qprocess_finished(self, mode, exitCode, exitStatus):
        """Handle process completion for a specific mode."""

        
        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")

        


    def read_process_output(self):
        """Read output from the process and display it in the wait_dialog's text edit."""
        if self.process is None:
            return

        # Read all available lines from stdout
        while True:
            line = self.process.stdout.readline()
            if not line:
                break
            line = line.strip()
            if line:
                # Append the line to the wait_dialog's output text
                self.wait_dialog.append_output(line)

        # Check if process has finished
        if self.process.poll() is not None:
            # Process ended
            self.output_timer.stop()
            # You can handle any cleanup here if needed

    def on_file_found(self, output_file_path):
        print(f"File found: {output_file_path}")
        self.wait_dialog.close()
        self.wait_thread = None

        if getattr(self, 'is_cropped_mode', False):
            # Existing Cropped Mode handling
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                print(f"[ERROR] Failed to load cropped image from {output_file_path}")
                QMessageBox.critical(self, "Error", f"Failed to load cropped image from {output_file_path}.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Apply autostretch if requested
            if getattr(self, 'cropped_apply_autostretch', False):
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to update preview dialog: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update preview dialog:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup with known paths
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tiff")
            self.cleanup_files(input_file_path, output_file_path)

            # Reset cropped mode
            self.is_cropped_mode = False

            # Re-enable Execute button
            self.execute_button.setEnabled(True)
        else:
            # Normal mode logic
            processed_image_path = output_file_path
            self.loaded_image_path = processed_image_path

            # Attempt to load the image with retries
            processed_image, original_header, bit_depth, is_mono = self.load_image_with_retry(processed_image_path)
            if processed_image is None:
                QMessageBox.critical(self, "Error", f"Failed to load image from {processed_image_path} after multiple attempts.")
                print(f"[ERROR] Failed to load image from {processed_image_path} after multiple attempts.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Show the processed image
            try:
                self.show_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Exception occurred while showing image: {e}")
                QMessageBox.critical(self, "Error", f"Exception occurred while showing image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Store the image in memory
            try:
                self.store_processed_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to store processed image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to store processed image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup input and output files
            input_file_path = self.current_input_file_path
            self.cleanup_files(input_file_path, processed_image_path)

            # Check if there are more operations queued
            if hasattr(self, 'operation_queue') and self.operation_queue:
                next_mode, next_suffix = self.operation_queue.pop(0)
                self._execute_cosmic_clarity(next_mode, next_suffix)


    def qprocess_finished_on_cropped(self, mode, exitCode, exitStatus, apply_autostretch):
        """Handle process completion for a specific cropped mode."""
        print(f"Process finished for {mode} operation with exit code {exitCode} and exit status {exitStatus}.")

        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")


        self.wait_dialog_cropped.close()
        print("WaitDialog_cropped closed.")



    def on_file_found_on_cropped(self, output_file_path, mode, apply_autostretch):
        print(f"File found for cropped {mode} operation: {output_file_path}")
        
        try:
            # Load the processed cropped image
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                raise ValueError(f"Failed to load cropped image from {output_file_path}")
            print("Processed image loaded successfully.")

            # Apply autostretch if requested
            if apply_autostretch:
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                    print("Autostretch applied to mono image.")
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)
                    print("Autostretch applied to color image.")

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
                print("Preview dialog updated with processed image.")
            except Exception as e:
                raise RuntimeError(f"Failed to update preview dialog: {e}")

            # Cleanup input and output files with correct extension
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tif")
            self.cleanup_files(input_file_path, output_file_path)
            print("Input and output files cleaned up.")

            # Reset cropped mode flags if necessary
            self.is_cropped_mode = False
            print("Cropped mode flags reset.")

            # Check if there are more operations queued
            if self.cropped_operation_queue:
                next_mode, next_suffix = self.cropped_operation_queue.pop(0)
                print(f"Proceeding to next operation: {next_mode} with suffix {next_suffix}.")
                # Execute the next operation
                self._execute_cosmic_clarity_on_cropped(next_mode, next_suffix, processed_image, apply_autostretch)

        except Exception as e:
            print(f"[ERROR] {e}")
            QMessageBox.critical(self, "Error", f"An error occurred: {e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button




    def on_file_error(self, msg):
        # File not found in time
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.critical(self, "Error", msg)


    def on_file_cancelled(self):
        # The worker was stopped before finding a file
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.information(self, "Cancelled", "File waiting was cancelled.")


    def on_wait_cancelled(self):
        # If we have a QProcess reference, terminate it
        if hasattr(self, 'process_q') and self.process_q is not None:
            self.process_q.kill()  # or self.process_q.terminate()

        QMessageBox.information(self, "Cancelled", "Operation was cancelled by the user.")




    def run_cosmic_clarity_on_cropped(self, cropped_image, apply_autostretch=False):
        """Run Cosmic Clarity on a cropped image, with an option to autostretch upon receipt."""

        if not self.validate_cosmic_clarity_folder():
            return  # Stop execution if the folder is not valid

        if cropped_image is None:  # Ensure a cropped image is provided
            QMessageBox.warning(self, "Warning", "No cropped image provided.")
            return

        # Convert the cropped image to 32-bit floating point format
        cropped_image_32bit = cropped_image.astype(np.float32) / np.max(cropped_image)  # Normalize if needed

        # Determine mode and suffix based on the selected radio button
        if self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        elif self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.cropped_operation_queue = list(zip(modes, output_suffixes))

 
        # Start the first operation
        if self.cropped_operation_queue:
            self._execute_cosmic_clarity_on_cropped(*self.cropped_operation_queue.pop(0), cropped_image_32bit, apply_autostretch)


    def _execute_cosmic_clarity_on_cropped(self, mode, output_suffix, cropped_image_32bit, apply_autostretch):
        """Execute a single Cosmic Clarity operation on a cropped image."""
        print(f"Starting '{mode}' operation with suffix '{output_suffix}'.")

        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        base_filename = "cropped_preview_image"  # Using a fixed name for cropped images
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")  # Changed to .tif

        # Ensure input and output directories exist
        os.makedirs(input_folder, exist_ok=True)
        os.makedirs(output_folder, exist_ok=True)

        # Save the 32-bit floating-point cropped image to the input folder
        try:
            save_image(cropped_image_32bit, input_file_path, "tiff", "32-bit floating point", self.original_header, self.is_mono)
            print(f"Saved cropped image to input path: {input_file_path}")
        except Exception as e:
            print(f"[ERROR] Failed to save cropped image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to save cropped image:\n{e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.*")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Build command arguments
        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Initialize QProcess
        self.process_q_cropped = QProcess(self)
        self.process_q_cropped.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q_cropped.readyReadStandardOutput.connect(self.qprocess_output_cropped)
        self.process_q_cropped.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished_on_cropped(mode, exitCode, exitStatus, apply_autostretch))

        # Start the process
        self.process_q_cropped.setProgram(exe_path)
        self.process_q_cropped.setArguments(args)
        self.process_q_cropped.start()

        if not self.process_q_cropped.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        print(f"Started Cosmic Clarity process for mode '{mode}'.")

        # Set up file waiting worker and wait dialog
        self.wait_thread_cropped = WaitForFileWorker(output_file_glob, timeout=1800)
        self.wait_thread_cropped.fileFound.connect(lambda path: self.on_file_found_on_cropped(path, mode, apply_autostretch))
        self.wait_thread_cropped.error.connect(self.on_file_error)
        self.wait_thread_cropped.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog_cropped = WaitDialog(self)
        self.wait_dialog_cropped.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog_cropped.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog_cropped.show()

        self.wait_thread_cropped.start()
        print("WaitDialog_cropped displayed and WaitForFileWorker started.")


    def build_command_args(self, exe_name, mode):
        """Build the command line arguments for Cosmic Clarity without using a batch file."""
        # exe_name is now fully resolved (including .exe on Windows if needed)
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        cmd = [exe_path]

        # Add sharpening or denoising arguments
        if mode == "sharpen":
            psf_value = self.get_psf_value()
            cmd += [
                "--sharpening_mode", self.sharpen_mode_dropdown.currentText(),
                "--stellar_amount", f"{self.stellar_amount_slider.value() / 100:.2f}",
                "--nonstellar_strength", f"{psf_value:.1f}",
                "--nonstellar_amount", f"{self.nonstellar_amount_slider.value() / 100:.2f}"
            ]
            if self.sharpen_channels_dropdown.currentText() == "Yes":
                cmd.append("--sharpen_channels_separately")
        elif mode == "denoise":
            cmd += [
                "--denoise_strength", f"{self.denoise_strength_slider.value() / 100:.2f}",
                "--denoise_mode", self.denoise_mode_dropdown.currentText()
            ]

        # GPU option
        if self.gpu_dropdown.currentText() == "No":
            cmd.append("--disable_gpu")

        return cmd

    def save_processed_image(self):
        """Save the current displayed image as the processed image."""
        self.processed_image = self.image.copy()


    def save_processed_image_to_disk(self):
        """Save the processed image to disk, using the correct format, bit depth, and header information."""
        if self.processed_image is None:
            QMessageBox.warning(self, "Warning", "No processed image to save.")
            return

        # Prompt user for the file path and format

        save_path, _ = QFileDialog.getSaveFileName(
            self, "Save Processed Image", "", 
            "TIFF Files (*.tif *.tiff);;PNG Files (*.png);;FITS Files (*.fits *.fit)"

        )
        
        if not save_path:
            return  # User cancelled the save dialog

        # Determine the format based on file extension
        _, file_extension = os.path.splitext(save_path)
        file_extension = file_extension.lower().lstrip('.')
        original_format = file_extension if file_extension in ['tiff', 'tif', 'png', 'fits', 'fit'] else 'tiff'

        # Call the save_image function with the necessary parameters
        try:
            save_image(
                img_array=self.processed_image,
                filename=save_path,
                original_format=original_format,
                bit_depth=self.bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            QMessageBox.information(self, "Success", f"Image saved successfully at: {save_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

    def load_image_with_retry(self, file_path, retries=5, delay=2):
        """
        Attempts to load an image multiple times with delays between attempts.

        :param file_path: Path to the image file.
        :param retries: Number of retry attempts.
        :param delay: Delay between retries in seconds.
        :return: Tuple of (image_array, original_header, bit_depth, is_mono) or (None, None, None, None) if failed.
        """

        for attempt in range(1, retries + 1):
            image, original_header, bit_depth, is_mono = load_image(file_path)
            if image is not None:

                return image, original_header, bit_depth, is_mono
            else:
                print(f"[WARNING] Attempt {attempt} failed to load image. Retrying in {delay} seconds...")
                time.sleep(delay)
        print("[ERROR] All attempts to load the image failed.")
        return None, None, None, None


    def wait_for_output_file(self, output_file_glob, timeout=3000, check_interval=1, stable_checks=3):
        """
        Wait for the output file with any extension within the specified timeout.
        Ensures the file size remains constant over a series of checks to confirm it's fully written.

        :param output_file_glob: Glob pattern to match the output file.
        :param timeout: Maximum time to wait in seconds.
        :param check_interval: Time between size checks in seconds.
        :param stable_checks: Number of consecutive checks with the same size.
        :return: Path to the output file or None if not found.
        """
        start_time = time.time()
        last_size = -1
        stable_count = 0

        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                current_size = os.path.getsize(matching_files[0])
                if current_size == last_size:
                    stable_count += 1
                    if stable_count >= stable_checks:
                        print(f"Output file found and stable: {matching_files[0]}")
                        return matching_files[0]
                else:
                    stable_count = 0
                    last_size = current_size
            time.sleep(check_interval)
        
        print("Timeout reached. Output file not found or not stable.")
        return None

    def display_image(self, file_path):
        """Load and display the output image."""
        self.image, self.original_header, self.bit_depth, self.is_mono = load_image(file_path)
        self.display_image()  # Update display with the new image

    def cleanup_files(self, input_file_path, output_file_path):
        """Delete input and output files after processing."""
        try:
            if input_file_path and os.path.exists(input_file_path):
                os.remove(input_file_path)
                print(f"Deleted input file: {input_file_path}")
            else:
                print(f"Input file not found, skipping deletion: {input_file_path}")

            if output_file_path and os.path.exists(output_file_path):
                os.remove(output_file_path)
                print(f"Deleted output file: {output_file_path}")
            else:
                print(f"Output file not found, skipping deletion: {output_file_path}")
        except Exception as e:
            print(f"Failed to delete files: {e}")

class PreviewDialog(QDialog):
    def __init__(self, np_image, parent_tab=None, is_mono=False):
        super().__init__(parent=parent_tab)
        self.setWindowTitle("Select Preview Area")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowContextHelpButtonHint | Qt.WindowType.MSWindowsFixedSizeDialogHint)
        self.setFixedSize(640, 480)  # Fix the size to 640x480
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag

        # Store the 32-bit numpy image for reference
        self.np_image = np_image
        self.original_np_image = np_image.copy()  # Copy to allow undo
        self.parent_tab = parent_tab
        # Track saved scroll positions for Undo
        self.saved_h_scroll = 0
        self.saved_v_scroll = 0        

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch button
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        layout.addWidget(self.autostretch_button)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Add the Process Visible Area and Undo buttons
        button_layout = QHBoxLayout()
        
        self.process_button = QPushButton("Process Visible Area")
        self.process_button.clicked.connect(self.process_visible_area)
        button_layout.addWidget(self.process_button)

        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.undo_last_process)
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        button_layout.addWidget(self.undo_button)

        layout.addLayout(button_layout)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set
                
        # Enable What's This functionality
        self.setWhatsThis(
            "Instructions:\n\n"
            "1. Use the scroll bars to center on the area of the image you want to preview.\n"
            "2. Click and drag to move around the image.\n"
            "3. When ready, click the 'Process Visible Area' button to process the selected section."
        )

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at 100% scale."""
        # Ensure the numpy array is scaled to [0, 255] and converted to uint8
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)
        
        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Display the QImage at 100% scale in QLabel
        self.image_label.setPixmap(QPixmap.fromImage(qimage))
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            # Check the dimensions of self.np_image instead of relying on is_mono.
            if self.np_image.ndim < 3:
                # 2D array: grayscale image.
                try:
                    stretched = stretch_mono_image(self.np_image, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)  # Convert to RGB for display.
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 1:
                # 3D array but with one channel.
                try:
                    mono = np.squeeze(self.np_image, axis=-1)
                    stretched = stretch_mono_image(mono, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch single-channel image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 3:
                # Color image.
                try:
                    display_image = stretch_color_image(self.np_image, target_median, linked=False)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return
            else:
                print("[ERROR] Unexpected image shape during autostretch!")
                return
        else:
            display_image = self.np_image  # Use original image if autostretch is off

        # Convert and display the QImage.
        self.display_qimage(display_image)



    def undo_last_process(self):
        """Revert to the original image in the preview, respecting the autostretch setting."""
        print("Undo last process")
        
        # Reset to the original image
        self.np_image = self.original_np_image.copy()
        
        # Apply autostretch if it is enabled
        if self.autostretch_enabled:
            print("Applying autostretch on undo")
            self.apply_autostretch()
        else:
            # Display the original image without autostretch
            self.display_qimage(self.np_image)
        
        # Restore saved scroll positions with a slight delay
        QTimer.singleShot(0, self.restore_scrollbars)
        print("Scrollbars will be restored to saved positions")


    def restore_scrollbars(self):
        """Restore the scrollbars to the saved positions after a delay."""
        self.scroll_area.horizontalScrollBar().setValue(self.saved_h_scroll)
        self.scroll_area.verticalScrollBar().setValue(self.saved_v_scroll)
        print("Scrollbars restored to saved positions")
   
    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        # Set the horizontal and vertical scrollbar positions to center
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def process_visible_area(self):
        print("Process Visible Area button pressed")  # Initial debug print to confirm button press

        """Crop the image to the visible area and send it to CosmicClarityTab for processing."""

        self.saved_h_scroll = self.scroll_area.horizontalScrollBar().value()
        self.saved_v_scroll = self.scroll_area.verticalScrollBar().value()

        # Calculate the visible area in the original image coordinates
        h_scroll = self.scroll_area.horizontalScrollBar().value()
        v_scroll = self.scroll_area.verticalScrollBar().value()
        visible_rect = QRect(h_scroll, v_scroll, 640, 480)  # 640x480 fixed size
        print(f"Visible area rectangle: {visible_rect}")  # Debug print to confirm visible area coordinates

        # Crop the numpy image array directly using slicing
        if len(self.np_image.shape) == 2:  # Mono image (2D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
            ]
            # Convert cropped mono image to RGB for consistent handling
            cropped_np_image = np.stack([cropped_np_image] * 3, axis=-1)
        elif len(self.np_image.shape) == 3:  # Color image (3D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
                :
            ]
        else:
            print("Error: Unsupported image format")
            return

        if cropped_np_image is None:
            print("Error: Failed to crop numpy image")  # Debug if cropping failed
        else:
            print("Image cropped successfully")  # Debug print to confirm cropping

        # Pass the cropped image to CosmicClarityTab for processing
        if self.parent_tab:
            print("Sending to parent class for processing")  # Debug print before sending to parent
            self.parent_tab.run_cosmic_clarity_on_cropped(cropped_np_image, apply_autostretch=self.autostretch_enabled)
        else:
            print("Error: Failed to send to parent class")  # Debug if parent reference is missing


    def convert_qimage_to_numpy(self, qimage):
        """Convert QImage to a 32-bit float numpy array, preserving the 32-bit precision."""
        qimage = qimage.convertToFormat(QImage.Format.Format_RGB888)
        
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 3)
        
        arr = np.frombuffer(ptr, dtype=np.uint8).reshape((height, width, 3)).astype(np.float32) / 255.0
        return arr

    def closeEvent(self, event):
        """Handle dialog close event if any cleanup is necessary."""
        self.dragging = False
        event.accept()

class WaitDialog(QDialog):
    cancelled = pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Processing...")
        
        self.layout = QVBoxLayout()
        
        self.label = QLabel("Processing, please wait...")
        self.layout.addWidget(self.label)
        
        # Add a QTextEdit to show process output
        self.output_text_edit = QTextEdit()
        self.output_text_edit.setReadOnly(True)
        self.layout.addWidget(self.output_text_edit)

        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.layout.addWidget(self.progress_bar)

        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.cancelled.emit)
        self.layout.addWidget(cancel_button)
        
        self.setLayout(self.layout)

    def append_output(self, text):
        self.output_text_edit.append(text)


class WaitForFileWorker(QThread):
    fileFound = pyqtSignal(str)
    cancelled = pyqtSignal()
    error = pyqtSignal(str)

    def __init__(self, output_file_glob, timeout=1800, parent=None):
        super().__init__(parent)
        self.output_file_glob = output_file_glob
        self.timeout = timeout
        self._running = True

    def run(self):
        start_time = time.time()
        while self._running and (time.time() - start_time < self.timeout):
            matching_files = glob.glob(self.output_file_glob)

            if matching_files:
                self.fileFound.emit(matching_files[0])
                return
            time.sleep(1)
        if self._running:
            self.error.emit("Output file not found within timeout.")
        else:
            self.cancelled.emit()

    def stop(self):
        self._running = False

class CosmicClaritySatelliteTab(QWidget):
    def __init__(self):
        super().__init__()
        self.cosmic_clarity_folder = None
        self.input_folder = None
        self.output_folder = None
        self.settings_file = "cosmic_clarity_satellite_folder.txt"
        self.file_watcher = QFileSystemWatcher()  # Watcher for input and output folders
        self.file_watcher.directoryChanged.connect(self.on_folder_changed)  # Connect signal
        self.sensitivity = 0.1
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")
        self.initUI()
        self.load_cosmic_clarity_folder()

    def initUI(self):
        # Main horizontal layout
        main_layout = QHBoxLayout()

        # Left layout for controls and settings
        left_layout = QVBoxLayout()

        # Input/Output Folder Selection in a Horizontal Sizer
        folder_layout = QHBoxLayout()
        self.input_folder_button = QPushButton("Select Input Folder")
        self.input_folder_button.clicked.connect(self.select_input_folder)
        self.output_folder_button = QPushButton("Select Output Folder")
        self.output_folder_button.clicked.connect(self.select_output_folder)
        folder_layout.addWidget(self.input_folder_button)
        folder_layout.addWidget(self.output_folder_button)
        left_layout.addLayout(folder_layout)

        # GPU Acceleration
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Removal Mode
        self.mode_label = QLabel("Satellite Removal Mode:")
        left_layout.addWidget(self.mode_label)
        self.mode_dropdown = QComboBox()
        self.mode_dropdown.addItems(["Full", "Luminance"])
        left_layout.addWidget(self.mode_dropdown)

        # Clip Trail
        self.clip_trail_checkbox = QCheckBox("Clip Satellite Trail to 0.000")
        self.clip_trail_checkbox.setChecked(True)
        left_layout.addWidget(self.clip_trail_checkbox)

        # **Add Sensitivity Slider**
        sensitivity_layout = QHBoxLayout()
        sensitivity_label = QLabel("Clipping Sensitivity (Lower Values more Aggressive Clipping):")
        sensitivity_layout.addWidget(sensitivity_label)

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(1)    # Represents 0.01
        self.sensitivity_slider.setMaximum(50)   # Represents 0.5
        self.sensitivity_slider.setValue(int(self.sensitivity * 100))  # e.g., 0.1 * 100 = 10
        self.sensitivity_slider.setTickInterval(1)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_slider.valueChanged.connect(self.update_sensitivity)
        sensitivity_layout.addWidget(self.sensitivity_slider)

        # Label to display current sensitivity value
        self.sensitivity_value_label = QLabel(f"{self.sensitivity:.2f}")
        sensitivity_layout.addWidget(self.sensitivity_value_label)

        left_layout.addLayout(sensitivity_layout)        

        # Skip Save
        self.skip_save_checkbox = QCheckBox("Skip Save if No Satellite Trail Detected")
        self.skip_save_checkbox.setChecked(False)
        left_layout.addWidget(self.skip_save_checkbox)

        # Process Single Image and Batch Process in a Horizontal Sizer
        process_layout = QHBoxLayout()
        self.process_single_button = QPushButton("Process Single Image")
        self.process_single_button.clicked.connect(self.process_single_image)
        process_layout.addWidget(self.process_single_button)

        self.batch_process_button = QPushButton("Batch Process Input Folder")
        self.batch_process_button.clicked.connect(self.batch_process_folder)
        process_layout.addWidget(self.batch_process_button)
        left_layout.addLayout(process_layout)

        # Live Monitor
        self.live_monitor_button = QPushButton("Live Monitor Input Folder")
        self.live_monitor_button.clicked.connect(self.live_monitor_folder)
        left_layout.addWidget(self.live_monitor_button)

        # Folder Selection
        self.folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.folder_label)
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))  # Ensure the icon is available
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        # Right layout for TreeBoxes
        right_layout = QVBoxLayout()

        # Input Files TreeBox
        input_files_label = QLabel("Input Folder Files:")
        right_layout.addWidget(input_files_label)
        self.input_files_tree = QTreeWidget()
        self.input_files_tree.setHeaderLabels(["Filename"])
        self.input_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.input_files_tree))
        self.input_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.input_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.input_files_tree, pos))
        right_layout.addWidget(self.input_files_tree)

        # Output Files TreeBox
        output_files_label = QLabel("Output Folder Files:")
        right_layout.addWidget(output_files_label)
        self.output_files_tree = QTreeWidget()
        self.output_files_tree.setHeaderLabels(["Filename"])
        self.output_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.output_files_tree))
        self.output_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.output_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.output_files_tree, pos))
        right_layout.addWidget(self.output_files_tree)


        # Add the left and right layouts to the main layout
        main_layout.addLayout(left_layout, stretch=2)  # More space for the left layout
        main_layout.addLayout(right_layout, stretch=1)  # Less space for the right layout

        self.setLayout(main_layout)

    def update_sensitivity(self, value):
        """
        Update the sensitivity value based on the slider's position.
        """
        self.sensitivity = value / 100.0  # Convert from integer to float (0.01 to 0.5)
        self.sensitivity_value_label.setText(f"{self.sensitivity:.2f}")  # Update label





    def preview_image(self, treebox):
        """Preview the selected image."""
        selected_item = treebox.currentItem()
        if selected_item:
            file_path = os.path.join(self.input_folder if treebox == self.input_files_tree else self.output_folder, selected_item.text(0))
            if os.path.isfile(file_path):
                try:
                    image, _, _, is_mono = load_image(file_path)
                    if image is not None:
                        self.current_preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)  # Store reference
                        self.current_preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure cleanup on close
                        self.current_preview_dialog.show()  # Open non-blocking dialog
                    else:
                        QMessageBox.critical(self, "Error", "Failed to load image for preview.")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to preview image: {e}")


    def open_preview_dialog(self, image, is_mono):
        """Open the preview dialog."""
        preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)
        preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure proper cleanup when closed
        preview_dialog.show()  # Open the dialog without blocking the main UI





    def show_context_menu(self, treebox, pos):
        """Show context menu for the treebox."""
        menu = QMenu()
        delete_action = QAction("Delete File")
        rename_action = QAction("Rename File")
        delete_action.triggered.connect(lambda: self.delete_file(treebox))
        rename_action.triggered.connect(lambda: self.rename_file(treebox))
        menu.addAction(delete_action)
        menu.addAction(rename_action)
        menu.exec(treebox.viewport().mapToGlobal(pos))

    def delete_file(self, treebox):
        """Delete the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            if os.path.exists(file_path):
                reply = QMessageBox.question(self, "Confirm Delete", f"Are you sure you want to delete {selected_item.text(0)}?",
                                             QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, QMessageBox.StandardButton.No)
                if reply == QMessageBox.StandardButton.Yes:
                    os.remove(file_path)
                    self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def rename_file(self, treebox):
        """Rename the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            new_name, ok = QInputDialog.getText(self, "Rename File", "Enter new name:", text=selected_item.text(0))
            if ok and new_name:
                new_path = os.path.join(folder, new_name)
                os.rename(file_path, new_path)
                self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def refresh_input_files(self):
        """Populate the input TreeBox with files from the input folder."""
        self.input_files_tree.clear()
        if not self.input_folder:
            return
        for file_name in os.listdir(self.input_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.input_files_tree, [file_name])

    def refresh_output_files(self):
        """Populate the output TreeBox with files from the output folder."""
        self.output_files_tree.clear()
        if not self.output_folder:
            return
        for file_name in os.listdir(self.output_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.output_files_tree, [file_name])



    def select_input_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Input Folder")
        if folder:
            self.input_folder = folder
            self.input_folder_button.setText(f"Input Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_input_files()

    def select_output_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Output Folder")
        if folder:
            self.output_folder = folder
            self.output_folder_button.setText(f"Output Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_output_files()

    def on_folder_changed(self, path):
        """Refresh the TreeBox when files are added or removed from the watched folder."""
        if path == self.input_folder:
            self.refresh_input_files()
        elif path == self.output_folder:
            self.refresh_output_files()


    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
            self.folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    def load_cosmic_clarity_folder(self):
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.folder_label.setText(f"Folder: {folder}")
            print(f"Loaded Cosmic Clarity folder: {folder}")
        else:
            print("No saved Cosmic Clarity folder found.")

    def process_single_image(self):
        # Step 1: Open File Dialog to Select Image
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if not file_path:
            QMessageBox.warning(self, "Warning", "No file selected.")
            return

        # Create temp input and output folders
        temp_input = self.create_temp_folder()
        temp_output = self.create_temp_folder()

        # Copy the selected file to the temp input folder
        shutil.copy(file_path, temp_input)

        # Run Cosmic Clarity Satellite Removal Tool
        try:
            self.run_cosmic_clarity_satellite(temp_input, temp_output)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Error processing image: {e}")
            return

        # Locate the processed file in the temp output folder
        processed_file = glob.glob(os.path.join(temp_output, "*_satellited.*"))
        if processed_file:
            # Move the processed file back to the original folder
            original_folder = os.path.dirname(file_path)
            destination_path = os.path.join(original_folder, os.path.basename(processed_file[0]))
            shutil.move(processed_file[0], destination_path)

            # Inform the user
            QMessageBox.information(self, "Success", f"Processed image saved to: {destination_path}")
        else:
            QMessageBox.warning(self, "Warning", "No output file found.")

        # Cleanup temporary folders
        if os.path.exists(temp_input):
            shutil.rmtree(temp_input)
        if os.path.exists(temp_output):
            shutil.rmtree(temp_output)

    def batch_process_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--batch"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Batch processing finished."))
        self.satellite_thread.start()

    def live_monitor_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--monitor"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.sensitivity_slider.setEnabled(False)
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Live monitoring stopped."))
        self.satellite_thread.finished.connect(lambda:self.sensitivity_slider.setEnabled(True))
        self.satellite_thread.start()

        # **Disable the sensitivity slider**
        


    def on_live_monitor_finished(self):
        """
        Slot to handle actions after live monitoring has finished.
        """
        QMessageBox.information(self, "Live Monitoring", "Live monitoring has been stopped.")
        self.sensitivity_slider.setEnabled(True)

        self.live_monitor_button.setEnabled(True)
        self.stop_monitor_button.setEnabled(False)
        
    @staticmethod
    def create_temp_folder(base_folder="~"):
        """
        Create a temporary folder for processing in the user's directory.
        :param base_folder: Base folder to create the temp directory in (default is the user's home directory).
        :return: Path to the created temporary folder.
        """
        user_dir = os.path.expanduser(base_folder)
        temp_folder = os.path.join(user_dir, "CosmicClarityTemp")
        os.makedirs(temp_folder, exist_ok=True)  # Create the folder if it doesn't exist
        return temp_folder


    def run_cosmic_clarity_satellite(self, input_dir, output_dir, live_monitor=False):
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        # Check if the executable exists
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct command arguments
        command = [
            exe_path,
            "--input", input_dir,
            "--output", output_dir,
            "--mode", self.mode_dropdown.currentText().lower(),
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")
        if live_monitor:
            command.append("--monitor")
        else:
            command.append("--batch")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])

        # Debugging: Print the command to verify
        print(f"Running command: {' '.join(command)}")

        # Execute the command
        try:
            subprocess.run(command, check=True)
            QMessageBox.information(self, "Success", "Processing complete.")
        except subprocess.CalledProcessError as e:
            QMessageBox.critical(self, "Error", f"Processing failed: {e}")

    def execute_script(self, script_path):
        """Execute the batch or shell script."""
        if os.name == 'nt':  # Windows
            subprocess.Popen(["cmd.exe", "/c", script_path], shell=True)
        else:  # macOS/Linux
            subprocess.Popen(["/bin/sh", script_path], shell=True)

    def wait_for_output_files(self, output_file_glob, timeout=1800):
        """Wait for output files matching the glob pattern within a timeout."""
        start_time = time.time()
        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                time.sleep(2)
                return matching_files
            time.sleep(1)
        return None

class ImagePreviewDialog(QDialog):
    def __init__(self, np_image, is_mono=False):
        super().__init__()
        self.setWindowTitle("Image Preview")
        self.resize(640, 480)  # Set initial size
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag
        self.zoom_factor = 1.0  # Track the zoom level

        # Store the 32-bit numpy image for reference
        self.np_image = np_image

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch and Zoom Buttons
        button_layout = QHBoxLayout()
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        button_layout.addWidget(self.autostretch_button)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        layout.addLayout(button_layout)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Enable mouse wheel for zooming
        self.image_label.installEventFilter(self)

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at the current zoom level."""
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)

        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Apply zoom
        pixmap = QPixmap.fromImage(qimage)
        scaled_width = int(pixmap.width() * self.zoom_factor)  # Convert to integer
        scaled_height = int(pixmap.height() * self.zoom_factor)  # Convert to integer
        scaled_pixmap = pixmap.scaled(scaled_width, scaled_height, Qt.AspectRatioMode.KeepAspectRatio)
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            if self.is_mono:  # Apply mono stretch
                if self.np_image.ndim == 2:  # Ensure single-channel mono
                    stretched_mono = stretch_mono_image(self.np_image, target_median)
                    display_image = np.stack([stretched_mono] * 3, axis=-1)  # Convert to RGB for display
                else:
                    raise ValueError(f"Unexpected mono image shape: {self.np_image.shape}")
            else:  # Apply color stretch
                display_image = stretch_color_image(self.np_image, target_median, linked=False)
        else:
            if self.is_mono and self.np_image.ndim == 2:
                display_image = np.stack([self.np_image] * 3, axis=-1)  # Convert to RGB for display
            else:
                display_image = self.np_image  # Use original image if autostretch is off

        print(f"Debug: Display image shape before QImage conversion: {display_image.shape}")
        self.display_qimage(display_image)



    def zoom_in(self):
        """Increase the zoom factor and refresh the display."""
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        self.display_qimage(self.np_image)

    def zoom_out(self):
        """Decrease the zoom factor and refresh the display."""
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        self.display_qimage(self.np_image)

    def eventFilter(self, source, event):
        """Handle mouse wheel events for zooming."""
        if source == self.image_label and event.type() == QEvent.Type.Wheel:
            if event.angleDelta().y() > 0:
                self.zoom_in()
            else:
                self.zoom_out()
            return True
        return super().eventFilter(source, event)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def resizeEvent(self, event):
        """Handle resizing of the dialog."""
        super().resizeEvent(event)
        self.display_qimage(self.np_image)



class SatelliteProcessingThread(QThread):
    log_signal = pyqtSignal(str)
    finished_signal = pyqtSignal()

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        try:
            self.log_signal.emit(f"Running command: {' '.join(self.command)}")
            subprocess.run(self.command, check=True)
            self.log_signal.emit("Processing complete.")
        except subprocess.CalledProcessError as e:
            self.log_signal.emit(f"Processing failed: {e}")
        except Exception as e:
            self.log_signal.emit(f"Unexpected error: {e}")
        finally:
            self.finished_signal.emit()  # Emit the finished signal            


class StatisticalStretchTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.zoom_factor = 1.0
        self.image = None  # Current image (from ImageManager)
        self.stretched_image = None  # Processed image
        self.current_pixmap = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)


    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # You can adjust this width as needed

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select an image to stretch.
            2. Adjust the target median and optional settings.
            3. Preview the result.
            4. Save the stretched image in your desired format.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton('Select Image', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Target median slider
        self.medianLabel = QLabel('Target Median: 0.25', self)
        self.medianSlider = QSlider(Qt.Orientation.Horizontal)
        self.medianSlider.setMinimum(1)
        self.medianSlider.setMaximum(100)
        self.medianSlider.setValue(25)
        self.medianSlider.valueChanged.connect(self.updateMedianLabel)
        left_layout.addWidget(self.medianLabel)
        left_layout.addWidget(self.medianSlider)

        # Linked/Unlinked stretch checkbox
        self.linkedCheckBox = QCheckBox('Linked Stretch', self)
        self.linkedCheckBox.setChecked(True)
        left_layout.addWidget(self.linkedCheckBox)

        # Normalization checkbox
        self.normalizeCheckBox = QCheckBox('Normalize Image', self)
        left_layout.addWidget(self.normalizeCheckBox)

        # Curves adjustment checkbox
        self.curvesCheckBox = QCheckBox('Apply Curves Adjustment', self)
        self.curvesCheckBox.setCheckState(Qt.CheckState.Unchecked)  # Explicitly set the initial state

        left_layout.addWidget(self.curvesCheckBox)

        # Curves Boost slider (initially hidden)
        self.curvesBoostLabel = QLabel('Curves Boost: 0.00', self)
        self.curvesBoostSlider = QSlider(Qt.Orientation.Horizontal)
        self.curvesBoostSlider.setMinimum(0)
        self.curvesBoostSlider.setMaximum(50)
        self.curvesBoostSlider.setValue(0)
        self.curvesBoostSlider.valueChanged.connect(self.updateCurvesBoostLabel)
        self.curvesBoostLabel.show()
        self.curvesBoostSlider.show()

        left_layout.addWidget(self.curvesBoostLabel)
        left_layout.addWidget(self.curvesBoostSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)      

        # Buttons (Undo and Preview Stretch)
        button_layout = QHBoxLayout()

        self.previewButton = QPushButton('Apply Stretch', self)
        self.previewButton.clicked.connect(self.previewStretch)
        button_layout.addWidget(self.previewButton)

        self.undoButton = QPushButton('Undo', self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undo_image)
        button_layout.addWidget(self.undoButton)

        self.mouseStatusLabel = QLabel('', self)
        left_layout.addWidget(self.mouseStatusLabel)

        left_layout.addLayout(button_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Commented out to move to the right panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton('Zoom In', self)
        # self.zoomInButton.clicked.connect(self.zoom_in)
        # zoom_layout.addWidget(self.zoomInButton)

        # self.zoomOutButton = QPushButton('Zoom Out', self)
        # self.zoomOutButton.clicked.connect(self.zoom_out)
        # zoom_layout.addWidget(self.zoomOutButton)

        # left_layout.addLayout(zoom_layout)



        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 0.25
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.imageLabel.setMouseTracking(True)
        self.imageLabel.installEventFilter(self)

        self.dragging = False
        self.last_pos = QPoint()

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.fileLabel)

            # Update the image display
            self.updateImageDisplay()

            print(f"Statistical Stretch: Image updated from ImageManager slot {slot}.")

    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.update_image(updated_image=self.preview_image, metadata=metadata)
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseMove:
            if source in (self.scrollArea.viewport(), self.imageLabel):
                # Map the event position to imageLabel coordinates
                pos = self.imageLabel.mapFrom(source, event.pos())
                if self.imageLabel.pixmap() is not None:
                    pixmap_size = self.imageLabel.pixmap().size()
                    if 0 <= pos.x() < pixmap_size.width() and 0 <= pos.y() < pixmap_size.height():
                        # Convert scaled coordinates back to original image coordinates
                        img_x = int(pos.x() / self.zoom_factor)
                        img_y = int(pos.y() / self.zoom_factor)
                        if self.image is not None:
                            h, w = self.image.shape[:2]
                            if 0 <= img_x < w and 0 <= img_y < h:
                                pixel_value = self.image[img_y, img_x]
                                if self.image.ndim == 3:
                                    r, g, b = pixel_value
                                    self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} R:{r:.3f} G:{g:.3f} B:{b:.3f}")
                                else:
                                    self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} Val:{pixel_value:.3f}")
        # Retain your dragging logic below...
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)




    def openFileDialog(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        self.filename, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if self.filename:
            self.fileLabel.setText(self.filename)

            # Load the image using ImageManager
            image, original_header, bit_depth, is_mono = load_image(self.filename)

            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            # Update ImageManager with the new image
            metadata = {
                'file_path': self.filename,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

            print("Image added to ImageManager.")

    def undo_image(self):
        """Undo the last action."""
        if self.image_manager.can_undo():
            self.image_manager.undo()  # Reverts to the previous image
            self.updateImageDisplay()  # Update the display with the reverted image
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def updateMedianLabel(self, value):
        self.medianLabel.setText(f'Target Median: {value / 100:.2f}')

    def updateCurvesBoostLabel(self, value):
        self.curvesBoostLabel.setText(f'Curves Boost: {value / 100:.2f}')

    def previewStretch(self):
        if self.image is not None:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = StatisticalStretchProcessingThread(self.image,
                                                                        self.medianSlider.value(),
                                                                        self.linkedCheckBox.isChecked(),
                                                                        self.normalizeCheckBox.isChecked(),
                                                                        self.curvesCheckBox.isChecked(),
                                                                        self.curvesBoostSlider.value() / 100.0)
            self.processing_thread.preview_generated.connect(self.update_preview)
            self.processing_thread.start()


    def update_preview(self, stretched_image):
        # Save the stretched image for later use in zoom functions
        self.stretched_image = stretched_image

        # Update the preview once the processing thread emits the result
        img = (stretched_image * 255).astype(np.uint8)
        h, w = img.shape[:2]

        if img.ndim == 3:
            bytes_per_line = 3 * w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            bytes_per_line = w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)

        # Create QPixmap from QImage
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

        # Prepare metadata with safeguards
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'target_median': self.medianSlider.value() / 100.0,
                'linked_stretch': self.linkedCheckBox.isChecked(),
                'normalize_image': self.normalizeCheckBox.isChecked(),
                'curves_adjustment': self.curvesCheckBox.isChecked(),
                'curves_boost': self.curvesBoostSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.stretched_image, metadata=metadata)
                print("StatisticalStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")


    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()    

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")

    def saveImage(self):
        if hasattr(self, 'stretched_image') and self.stretched_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.stretched_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.stretched_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')


# Thread for Stat Stretch background processing
class StatisticalStretchProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)  # Signal to send the generated preview image back to the main thread

    def __init__(self, image, target_median, linked, normalize, apply_curves, curves_boost):
        super().__init__()
        self.image = image
        self.target_median = target_median / 100.0  # Ensure proper scaling
        self.linked = linked
        self.normalize = normalize
        self.apply_curves = apply_curves
        self.curves_boost = curves_boost

    def run(self):
        # Perform the image stretching in the background
        if self.image.ndim == 2:  # Mono image
            stretched_image = stretch_mono_image(self.image, self.target_median, self.normalize, self.apply_curves, self.curves_boost)
        else:  # Color image
            stretched_image = stretch_color_image(self.image, self.target_median, self.linked, self.normalize, self.apply_curves, self.curves_boost)

        # Emit the result once done
        self.preview_generated.emit(stretched_image)


# Thread for star stretch background processing
class ProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, stretch_factor, sat_amount, scnr_enabled):
        super().__init__()
        self.image = image
        self.stretch_factor = stretch_factor
        self.sat_amount = sat_amount
        self.scnr_enabled = scnr_enabled

    def run(self):
        # Apply fast pixel math
        stretched_image = applyPixelMath_numba(self.image, self.stretch_factor)

        # Apply saturation adjustment
        stretched_image = adjust_saturation_numba(stretched_image, self.sat_amount)

        # Apply SCNR if enabled
        if self.scnr_enabled:
            stretched_image = applySCNR_numba(stretched_image)

        # Emit the processed image
        self.preview_generated.emit(stretched_image)

class StarStretchTab(QWidget):
    def __init__(self, image_manager):
        super().__init__()
        self.image_manager = image_manager  # Store the ImageManager instance
        self.initUI()
        
        # Connect to ImageManager's image_changed signal
        self.image_manager.image_changed.connect(self.on_image_changed)
        self.image = None  # Store the selected image
        self.stretch_factor = 5.0
        self.sat_amount = 1.0
        self.is_mono = True
        self.remove_green = False
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.last_pos = None
        self.processing_thread = None  # Thread for background processing
        self.original_header = None
        self.current_pixmap = None  # **New Attribute**

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fix the left column width

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the stretch and optional settings.
            3. Preview the result.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Select Stars Only Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Stretch Amount slider with more precision
        self.stretchLabel = QLabel("Stretch Amount: 5.00", self)
        self.stretchSlider = QSlider(Qt.Orientation.Horizontal)
        self.stretchSlider.setMinimum(0)
        self.stretchSlider.setMaximum(800)  # Allow two decimal places of precision
        self.stretchSlider.setValue(500)  # 500 corresponds to 5.00
        self.stretchSlider.valueChanged.connect(self.updateStretchLabel)
        left_layout.addWidget(self.stretchLabel)
        left_layout.addWidget(self.stretchSlider)

        # Color Boost Amount slider
        self.satLabel = QLabel("Color Boost: 1.00", self)
        self.satSlider = QSlider(Qt.Orientation.Horizontal)
        self.satSlider.setMinimum(0)
        self.satSlider.setMaximum(200)
        self.satSlider.setValue(100)  # 100 corresponds to 1.0 boost
        self.satSlider.valueChanged.connect(self.updateSatLabel)
        left_layout.addWidget(self.satLabel)
        left_layout.addWidget(self.satSlider)

        # SCNR checkbox
        self.scnrCheckBox = QCheckBox("Remove Green via SCNR (Optional)", self)
        left_layout.addWidget(self.scnrCheckBox)

        # **Create a horizontal layout for Refresh Preview, Undo, and Redo buttons**
        action_buttons_layout = QHBoxLayout()

        # Refresh Preview button
        self.refreshButton = QPushButton("Refresh Preview", self)
        self.refreshButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.refreshButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Redo button with right arrow icon
        self.redoButton = QPushButton("Redo", self)
        redo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowForward)  # Standard right arrow icon
        self.redoButton.setIcon(redo_icon)
        self.redoButton.clicked.connect(self.redoAction)
        self.redoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.redoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)


        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def saveImage(self):
        # Use the processed/stretched image for saving
        if self.preview_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "stretched_image"
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else os.getcwd()

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(
                            self.preview_image, 
                            save_filename, 
                            original_format, 
                            bit_depth, 
                            self.original_header, 
                            self.is_mono
                        )
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(
                        self.preview_image, 
                        save_filename, 
                        original_format
                    )
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')


    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("StarStretchTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("StarStretchTab: No actions to undo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def redoAction(self):
        if self.image_manager and self.image_manager.can_redo():
            try:
                # Perform the redo operation
                self.image_manager.redo()
                print("StarStretchTab: Redo performed.")
            except Exception as e:
                print(f"Error performing redo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform redo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to redo.")
            print("StarStretchTab: No actions to redo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return  
        if image is None:
            return              
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"StarStretchTab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())
                self.redoButton.setEnabled(self.image_manager.can_redo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')


    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(self, "Select Stars Only Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if selected_file:
            try:
                # Load image with header
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)
                self.filename = selected_file  # Store the selected file path
                self.fileLabel.setText(os.path.basename(selected_file))

                # Push the loaded image to ImageManager so it can be tracked for undo/redo
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': 'Unknown',  # You can update this if needed
                    'is_mono': self.is_mono
                }
                self.image_manager.set_image( self.image, metadata)
                print(f"Image {self.filename} pushed to ImageManager.")

                # Update the display with the loaded image (before applying any stretch)
                self.updateImageDisplay()

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"Failed to load image: {e}")

    def updateStretchLabel(self, value):
        self.stretch_factor = value / 100.0  # Precision of two decimals
        self.stretchLabel.setText(f"Stretch Amount: {self.stretch_factor:.2f}")

    def updateSatLabel(self, value):
        self.sat_amount = value / 100.0
        self.satLabel.setText(f"Color Boost: {self.sat_amount:.2f}")

    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = ProcessingThread(self.image, self.stretch_factor, self.sat_amount, self.scnrCheckBox.isChecked())
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'stretch_factor': self.stretch_factor,
                'color_boost': self.sat_amount,
                'remove_green': self.scnrCheckBox.isChecked()
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.preview_image, metadata=metadata)
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()


    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)
    

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")


    def applyStretch(self):
        if self.image is not None and self.image.size > 0:
            print(f"Applying stretch: {self.stretch_factor}, Color Boost: {self.sat_amount:.2f}, SCNR: {self.scnrCheckBox.isChecked()}")
            self.generatePreview()

class FullCurvesTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.initUI()
        self.image = None
        self.image_manager = image_manager
        self.filename = None
        self.original_image = None  # Reference to the original image
        self.preview_image = None   # Reference to the preview image        
        self.zoom_factor = 1.0
        self.original_header = None
        self.bit_depth = None
        self.is_mono = None
        self.curve_mode = "K (Brightness)"  # Default curve mode
        self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)  # Initialize with identity LUT

        # Initialize the Undo stack with a limited size
        self.undo_stack = []
        self.max_undo = 10  # Maximum number of undo steps        

        # Precompute transformation matrices
        self.M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        self.M_inv = np.array([
            [ 3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [ 0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)   

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)             

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        # File label
        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Curve Mode Selection
        self.curveModeLabel = QLabel('Select Curve Mode:', self)
        left_layout.addWidget(self.curveModeLabel)

        self.curveModeGroup = QButtonGroup(self)
        curve_modes = [
            ('K (Brightness)', 0, 0),  # Text, row, column
            ('R', 1, 0),
            ('G', 2, 0),
            ('B', 3, 0),
            ('L*', 0, 1),
            ('a*', 1, 1),
            ('b*', 2, 1),
            ('Chroma', 0, 2),
            ('Saturation', 1, 2)
        ]

        curve_mode_layout = QGridLayout()

        # Connect all buttons to set_curve_mode
        for mode, row, col in curve_modes:
            button = QRadioButton(mode, self)
            if mode == "K (Brightness)":
                button.setChecked(True)  # Default selection
            button.toggled.connect(self.set_curve_mode)  # Update curve_mode on toggle
            self.curveModeGroup.addButton(button)
            curve_mode_layout.addWidget(button, row, col)

        left_layout.addLayout(curve_mode_layout)
        self.set_curve_mode()

        # Curve editor placeholder
        self.curveEditor = CurveEditor(self)
        left_layout.addWidget(self.curveEditor)

        # Connect the CurveEditor preview callback
        self.curveEditor.setPreviewCallback(lambda lut: self.updatePreviewLUT(lut, self.curve_mode))

        self.statusLabel = QLabel('X:0 Y:0', self)
        left_layout.addWidget(self.statusLabel)



        # Horizontal layout for Apply, Undo, and Reset buttons
        button_layout = QHBoxLayout()

        # Apply Curve Button
        self.applyButton = QPushButton('Apply Curve', self)
        self.applyButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        self.applyButton.clicked.connect(self.startProcessing)
        button_layout.addWidget(self.applyButton)

        # Undo Curve Button
        self.undoButton = QPushButton('Undo', self)
        self.undoButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack))
        self.undoButton.setEnabled(False)  # Initially disabled
        self.undoButton.clicked.connect(self.undo)
        button_layout.addWidget(self.undoButton)

        # Reset Curve Button as a small tool button with an icon
        self.resetCurveButton = QToolButton(self)
        self.resetCurveButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_BrowserReload))  # Provide a suitable icon
        self.resetCurveButton.setToolTip("Reset Curve")
        # Set a small icon size if needed
        self.resetCurveButton.setIconSize(QSize(16,16))

        # Optionally, if you want the reset button even smaller, you can also adjust its size:
        # self.resetCurveButton.setFixedSize(24, 24)

        # Connect the clicked signal to the resetCurve method
        self.resetCurveButton.clicked.connect(self.resetCurve)
        button_layout.addWidget(self.resetCurveButton)

        # Add the horizontal layout with buttons to the main left layout
        left_layout.addLayout(button_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Commented out to move to the right panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton('Zoom In', self)
        # self.zoomInButton.clicked.connect(self.zoom_in)
        # zoom_layout.addWidget(self.zoomInButton)

        # self.zoomOutButton = QPushButton('Zoom Out', self)
        # self.zoomOutButton.clicked.connect(self.zoom_out)
        # zoom_layout.addWidget(self.zoomOutButton)

        # left_layout.addLayout(zoom_layout)


        # **Add Spinner Label**
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie("spinner.gif")  # Ensure spinner.gif exists in your project directory
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Initially hidden
        left_layout.addWidget(self.spinnerLabel)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))



        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = ImageLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)
        self.scrollArea.setWidgetResizable(True)
        self.imageLabel.mouseMoved.connect(self.handleImageMouseMove)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 1.0
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.dragging = False
        self.last_pos = QPoint()

    # -----------------------------
    # Spinner Control Methods
    # -----------------------------
    def showSpinner(self):
        """Show the spinner animation."""
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        """Hide the spinner animation."""
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def set_curve_mode(self):
        selected_button = self.curveModeGroup.checkedButton()
        if selected_button:
            self.curve_mode = selected_button.text()
            # Assuming you have the current LUT, update the preview
            if hasattr(self, 'current_lut'):
                self.updatePreviewLUT(self.current_lut, self.curve_mode)

    def get_visible_region(self):
        """Retrieve the coordinates of the visible region in the image."""
        viewport = self.scrollArea.viewport()
        # Top-left corner of the visible area
        x = self.scrollArea.horizontalScrollBar().value()
        y = self.scrollArea.verticalScrollBar().value()
        # Size of the visible area
        w = viewport.width()
        h = viewport.height()
        return x, y, w, h


    def updatePreviewLUT(self, lut, curve_mode):
        """Apply the 8-bit LUT to the preview image for real-time updates on slot 0."""

        # Access slot0 (recombined image) from ImageManager
        if self.image is None:
            print("No preview image loaded.")
            QMessageBox.warning(self, "No Image", "Preview image is not loaded.")
            return

        try:
            current_scroll_x = self.scrollArea.horizontalScrollBar().value()
            current_scroll_y = self.scrollArea.verticalScrollBar().value()

            # 1) Copy the entire preview in float [0..1]
            base_image = self.image.copy()  # shape: (H, W, 3 or 2)

            # 2) Convert the entire base_image to 8-bit
            image_8bit = (base_image * 255).astype(np.uint8)

            # 3) Make a working copy for transformation
            adjusted_8bit = image_8bit.copy()

            if adjusted_8bit.ndim == 3:  # RGB image
                adjusted_image = adjusted_8bit.copy()

                if curve_mode == "K (Brightness)":
                    # Apply LUT to all channels equally (Brightness)
                    for channel in range(3):
                        adjusted_image[:, :, channel] = lut[adjusted_8bit[:, :, channel]]

                elif curve_mode in ["R", "G", "B"]:
                    # Apply LUT to a single channel
                    channel_index = {"R": 0, "G": 1, "B": 2}[curve_mode]
                    adjusted_image[:, :, channel_index] = lut[adjusted_8bit[:, :, channel_index]]

                elif curve_mode in ["L*", "a*", "b*"]:
                    # Manual RGB to Lab Conversion
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Apply LUT to the respective channel
                    if curve_mode == "L*":
                        # L* typically ranges from 0 to 100
                        L_normalized = np.clip(L / 100.0, 0, 1)  # Normalize to [0,1]
                        L_lut_indices = (L_normalized * 255).astype(np.uint8)
                        L_adjusted = lut[L_lut_indices].astype(np.float32) * 100.0 / 255.0  # Scale back to [0,100]
                        L = L_adjusted

                    elif curve_mode == "a*":
                        # a* typically ranges from -128 to +127
                        a_normalized = np.clip((a + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        a_lut_indices = (a_normalized * 255).astype(np.uint8)
                        a_adjusted = lut[a_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        a = a_adjusted

                    elif curve_mode == "b*":
                        # b* typically ranges from -128 to +127
                        b_normalized = np.clip((b + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        b_lut_indices = (b_normalized * 255).astype(np.uint8)
                        b_adjusted = lut[b_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        b = b_adjusted

                    # Update Lab channels
                    lab_new = np.stack([L, a, b], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Chroma":
                    # === Manual RGB to Lab Conversion ===
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Compute Chroma
                    chroma = np.sqrt(a**2 + b**2)

                    # Define a fixed maximum Chroma for normalization to prevent over-scaling
                    fixed_max_chroma = 200.0  # Adjust this value as needed

                    # Normalize Chroma to [0,1] using fixed_max_chroma
                    chroma_norm = np.clip(chroma / fixed_max_chroma, 0, 1)

                    # Apply LUT to Chroma
                    chroma_lut_indices = (chroma_norm * 255).astype(np.uint8)
                    chroma_adjusted = lut[chroma_lut_indices].astype(np.float32)  # Ensure float32

                    # Compute scaling factor, avoiding division by zero
                    scale = np.ones_like(chroma_adjusted, dtype=np.float32)
                    mask = chroma > 0
                    scale[mask] = chroma_adjusted[mask] / chroma[mask]

                    # Scale a* and b* channels
                    a_new = a * scale
                    b_new = b * scale

                    # Update Lab channels
                    lab_new = np.stack([L, a_new, b_new], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Saturation":
                    # === Manual RGB to HSV Conversion ===
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Split channels
                    R, G, B = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]

                    # Compute Cmax, Cmin, Delta
                    Cmax = np.maximum.reduce([R, G, B])
                    Cmin = np.minimum.reduce([R, G, B])
                    Delta = Cmax - Cmin

                    # Initialize Hue (H), Saturation (S), and Value (V)
                    H = np.zeros_like(Cmax)
                    S = np.zeros_like(Cmax)
                    V = Cmax.copy()

                    # Compute Hue (H)
                    mask = Delta != 0
                    H[mask & (Cmax == R)] = ((G[mask & (Cmax == R)] - B[mask & (Cmax == R)]) / Delta[mask & (Cmax == R)]) % 6
                    H[mask & (Cmax == G)] = ((B[mask & (Cmax == G)] - R[mask & (Cmax == G)]) / Delta[mask & (Cmax == G)]) + 2
                    H[mask & (Cmax == B)] = ((R[mask & (Cmax == B)] - G[mask & (Cmax == B)]) / Delta[mask & (Cmax == B)]) + 4
                    H = H / 6.0  # Normalize Hue to [0,1]

                    # Compute Saturation (S)
                    S[Cmax != 0] = Delta[Cmax != 0] / Cmax[Cmax != 0]

                    # Apply LUT to Saturation (S) channel
                    S_normalized = np.clip(S, 0, 1)  # Ensure S is within [0,1]
                    S_lut_indices = (S_normalized * 255).astype(np.uint8)
                    S_adjusted = lut[S_lut_indices].astype(np.float32) / 255.0  # Normalize back to [0,1]
                    S = S_adjusted

                    # Convert HSV back to RGB
                    C = V * S
                    X = C * (1 - np.abs((H * 6) % 2 - 1))
                    m = V - C

                    # Initialize RGB channels
                    R_new = np.zeros_like(R)
                    G_new = np.zeros_like(G)
                    B_new = np.zeros_like(B)

                    # Define masks for different sectors of Hue
                    mask0 = (H >= 0) & (H < 1/6)
                    mask1 = (H >= 1/6) & (H < 2/6)
                    mask2 = (H >= 2/6) & (H < 3/6)
                    mask3 = (H >= 3/6) & (H < 4/6)
                    mask4 = (H >= 4/6) & (H < 5/6)
                    mask5 = (H >= 5/6) & (H < 1)

                    # Assign RGB values based on the sector of Hue
                    R_new[mask0] = C[mask0]
                    G_new[mask0] = X[mask0]
                    B_new[mask0] = 0

                    R_new[mask1] = X[mask1]
                    G_new[mask1] = C[mask1]
                    B_new[mask1] = 0

                    R_new[mask2] = 0
                    G_new[mask2] = C[mask2]
                    B_new[mask2] = X[mask2]

                    R_new[mask3] = 0
                    G_new[mask3] = X[mask3]
                    B_new[mask3] = C[mask3]

                    R_new[mask4] = X[mask4]
                    G_new[mask4] = 0
                    B_new[mask4] = C[mask4]

                    R_new[mask5] = C[mask5]
                    G_new[mask5] = 0
                    B_new[mask5] = X[mask5]

                    # Add m to match the Value (V)
                    R_new += m
                    G_new += m
                    B_new += m

                    # Stack the channels back together
                    rgb_new = np.stack([R_new, G_new, B_new], axis=2)

                    # Clip RGB to [0,1] to maintain valid color ranges
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                else:
                    # Unsupported curve mode
                    print(f"Unsupported curve mode: {curve_mode}")
                    QMessageBox.warning(self, "Unsupported Mode", f"Unsupported curve mode: {curve_mode}")
                    return

            else:  # Grayscale image
                # For grayscale images, apply LUT directly
                adjusted_image = lut[adjusted_8bit]

            # Convert adjusted_image back to float [0..1]
            preview_image = adjusted_image.astype(np.float32) / 255.0

            # 5) Retrieve the active mask
            mask = self.get_active_mask()


            if mask is not None:
                # 5a) Downsample the mask to match the preview image dimensions
                downsampled_mask = self.downsample_for_preview(mask, max_width=1080)

                # 5b) Ensure mask is properly formatted and normalized
                if downsampled_mask.dtype != np.float32 and downsampled_mask.dtype != np.float64:
                    downsampled_mask = downsampled_mask.astype(np.float32) / 255.0

                # 5c) If preview_image is multi-channel but mask is single-channel, expand mask dimensions
                if preview_image.ndim == 3 and downsampled_mask.ndim == 2:
                    downsampled_mask = np.expand_dims(downsampled_mask, axis=-1)

                # 5d) Ensure mask dimensions match the preview image dimensions
                if downsampled_mask.shape[:2] != preview_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Downsampled mask dimensions do not match the preview image dimensions.")
                    return

                # 5e) Blend the adjusted preview_image with the base_image using the mask
                # Formula: blended_preview = adjusted_image * mask + base_image * (1 - mask)
                blended_preview = preview_image * downsampled_mask + base_image * (1 - downsampled_mask)
                blended_preview = np.clip(blended_preview, 0.0, 1.0)  # Ensure values are within [0,1]
            else:
                # No mask applied; use the adjusted image directly
                blended_preview = preview_image

            # 6) Finally, show the blended preview image
            self.show_image(blended_preview)
            self.scrollArea.horizontalScrollBar().setValue(current_scroll_x)
            self.scrollArea.verticalScrollBar().setValue(current_scroll_y)              

        except Exception as e:
            print(f"Error in updatePreviewLUT: {e}")
            QMessageBox.critical(self, "Error", f"Failed to update preview: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.original_image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None

    def handleImageMouseMove(self, x, y):
        if self.image is None:
            return

        h, w = self.image.shape[:2]
        img_x = int(x / self.zoom_factor)
        img_y = int(y / self.zoom_factor)

        if 0 <= img_x < w and 0 <= img_y < h:
            pixel_value = self.image[img_y, img_x]
            if self.image.ndim == 3:
                # RGB pixel: assuming pixel values are in 0-1
                r, g, b = pixel_value
                text = f"X:{img_x} Y:{img_y} R:{r:.3f} G:{g:.3f} B:{b:.3f}"
                self.curveEditor.updateValueLines(r, g, b, grayscale=False)
            else:
                # Grayscale pixel: value is in 0-1
                text = f"X:{img_x} Y:{img_y} Val:{pixel_value:.3f}"
                # Pass the grayscale value for all channels and set grayscale flag to True
                self.curveEditor.updateValueLines(pixel_value, pixel_value, pixel_value, grayscale=True)
            self.statusLabel.setText(text)



    def startProcessing(self):
        if self.original_image is None:
            QMessageBox.warning(self, "Warning", "No image loaded to apply curve.")
            return

        curve_mode = self.curveModeGroup.checkedButton().text()
        curve_func = self.curveEditor.getCurveFunction()


        source_image = self.original_image.copy()

        # Push the current image to the undo stack before modifying
        self.pushUndo(self.original_image.copy())

        # Show the spinner before starting processing
        self.showSpinner()

        # Initialize and start the processing thread
        self.processing_thread = FullCurvesProcessingThread(source_image, curve_mode, curve_func)
        self.processing_thread.result_ready.connect(self.finishProcessing)
        self.processing_thread.start()
        print("Started FullCurvesProcessingThread.")

    def finishProcessing(self, adjusted_image):
        self.hideSpinner()

        if adjusted_image is None:
            QMessageBox.critical(self, "Error", "Image processing failed.")
            return

        # Retrieve the active mask
        mask = self.get_active_mask()

        if mask is not None:
            # Ensure mask is properly formatted and normalized
            # The mask should be a float array with values between 0 and 1
            if mask.dtype != np.float32 and mask.dtype != np.float64:
                mask = mask.astype(np.float32) / 255.0

            # If mask is single-channel but image is multi-channel, expand dimensions
            if self.original_image.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)

            # Ensure mask dimensions match the image dimensions
            if mask.shape[:2] != self.original_image.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                return

            # Blend the adjusted image with the original image using the mask
            # Formula: blended = adjusted * mask + original * (1 - mask)
            blended_image = adjusted_image * mask + self.original_image * (1 - mask)
            blended_image = np.clip(blended_image, 0.0, 1.0)  # Ensure values are within [0,1]
        else:
            # No mask applied; use the adjusted image directly
            blended_image = adjusted_image

        # Update the original image with the blended image
        self.original_image = blended_image.copy()

        # Create a downsampled preview image
        self.preview_image = self.downsample_for_preview(blended_image, max_width=1080)

        # Update the display image
        self.image = self.preview_image.copy()

        # Show the updated image in the UI
        self.show_image(self.image)

        # Reset the curve editor if needed
        self.curveEditor.initCurve()

        # Update the ImageManager with the new image
        if self.image_manager:
            metadata = {
                'file_path': self.loaded_image_path,
                'original_header': self.original_header,
                'bit_depth': self.bit_depth,
                'is_mono': self.is_mono
            }
            self.image_manager.image = self.original_image.copy()  # Update the image directly
            self.image_manager.image_changed.emit(
                self.image_manager.current_slot,
                self.image_manager.image,
                metadata
            )
            print("FullCurvesTab: Image updated in ImageManager.")

    def pushUndo(self, image_state):
        """Push the current image state onto the undo stack."""
        if len(self.undo_stack) >= self.max_undo:
            # Remove the oldest state to maintain the stack size
            self.undo_stack.pop(0)
        self.undo_stack.append(image_state)
        self.updateUndoButtonState()

    def updateUndoButtonState(self):
        """Enable or disable the Undo button based on the undo stack."""
        if hasattr(self, 'undoButton'):
            self.undoButton.setEnabled(len(self.undo_stack) > 0)

    def undo(self):
        """Revert the image to the last state in the undo stack."""
        if not self.undo_stack:
            QMessageBox.information(self, "Undo", "No actions to undo.")
            return

        # Pop the last state from the stack
        last_state = self.undo_stack.pop()

        # Update ImageManager with the previous image state
        if self.image_manager:
            metadata = {
                'file_path': self.loaded_image_path,  # Update as needed
                'original_header': self.original_header,
                'bit_depth': self.bit_depth,
                'is_mono': self.is_mono
            }
            self.image_manager.update_image(updated_image=last_state, metadata=metadata)
            print("Undo: Image reverted in ImageManager.")

        # Update the Undo button state
        self.updateUndoButtonState()


    def resetCurve(self):
        """
        Resets the draggable points in the curve editor without affecting other settings.
        """
        try:
            # Reset the draggable points in the curve editor
            self.curveEditor.initCurve()

            # Clear the preview LUT to match the reset state of draggable points
            self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)
            self.updatePreviewLUT(self.current_lut, self.curve_mode)

        except Exception as e:
            print(f"Error during curve reset: {e}")
            QMessageBox.critical(self, "Error", f"Failed to reset draggable points: {e}")

    def eventFilter(self, source, event):
        # Handle shift+click to add a control point on the curve.
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            # Check if Shift is pressed.
            if event.modifiers() & Qt.KeyboardModifier.ShiftModifier:
                # Map the event position to the imageLabel coordinate system.
                pos = self.imageLabel.mapFrom(source, event.pos())
                if self.imageLabel.pixmap() is not None:
                    pixmap_size = self.imageLabel.pixmap().size()
                    if 0 <= pos.x() < pixmap_size.width() and 0 <= pos.y() < pixmap_size.height():
                        # Convert from the scaled image back to original image coordinates.
                        img_x = int(pos.x() / self.zoom_factor)
                        img_y = int(pos.y() / self.zoom_factor)
                        if self.image is not None:
                            h, w = self.image.shape[:2]
                            if 0 <= img_x < w and 0 <= img_y < h:
                                pixel_value = self.image[img_y, img_x]
                                # Compute the average brightness.
                                if self.image.ndim == 3:
                                    avg = (pixel_value[0] + pixel_value[1] + pixel_value[2]) / 3.0
                                else:
                                    avg = pixel_value
                                # Map avg (0–1) to curve coordinates:
                                new_x = avg * 360.0
                                new_y = 360.0 - (avg * 360.0)
                                # Add a new control point to the curve.
                                self.curveEditor.addControlPoint(new_x, new_y)
                                # Optionally update a status message:
                                self.statusLabel.setText(f"Added control point at X:{new_x:.1f} Y:{new_y:.1f}")
                                return True  # Consume the event.
        # Existing dragging logic:
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)


    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return
        if image is None:
            return                
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
                
            # Set the image and store a copy for later use
            self.loaded_image_path = metadata.get('file_path', None)
            self.image = image
            self.original_image = image.copy()  # Store a copy of the original image
            self.original_header = metadata.get('original_header', None)
            self.bit_depth = metadata.get('bit_depth', None)
            self.is_mono = metadata.get('is_mono', False)

            self.preview_image = self.downsample_for_preview(image, max_width=1080)
            self.image = self.preview_image.copy()
            
            # Save the previous scroll position
            self.previous_scroll_pos = (
                self.scrollArea.horizontalScrollBar().value(),
                self.scrollArea.verticalScrollBar().value()
            )
            
            if not isinstance(self.loaded_image_path, str):
                self.loaded_image_path = ""
            self.fileLabel.setText(self.loaded_image_path)
            
            # Update the UI elements (buttons, etc.)
            self.show_image(image)
            self.update_image_display()

            # Enable or disable buttons based on image processing state
            self.applyButton.setEnabled(True)

            self.undoButton.setEnabled(len(self.undo_stack) > 0)

            print(f"FullCurvesTab: Image updated from ImageManager slot {slot}.")

    def downsample_for_preview(self, image_float32, max_width=1080):
        """
        If image width > max_width, scale it down proportionally.
        Returns a new float32 image in [0..1].
        """


        h, w = image_float32.shape[:2]

        if w <= max_width:
            # No need to downsample
            return image_float32.copy()

        scale_factor = max_width / float(w)
        new_w = max_width
        new_h = int(h * scale_factor)

        # Convert [0..1] float to [0..255] uint8 for OpenCV resizing
        temp_8u = (image_float32 * 255).clip(0,255).astype(np.uint8)

        # Resize with INTER_AREA for best downsampling
        resized_8u = cv2.resize(temp_8u, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # Convert back to float32 in [0..1]
        return resized_8u.astype(np.float32) / 255.0



    def show_image(self, image):
        """
        Display the loaded image in the imageLabel.
        """
        try:
            # Normalize image to 0-255 and convert to uint8
            display_image = (image * 255).astype(np.uint8)

            if display_image.ndim == 3 and display_image.shape[2] == 3:
                # RGB Image
                height, width, channels = display_image.shape
                bytes_per_line = 3 * width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif display_image.ndim == 2:
                # Grayscale Image
                height, width = display_image.shape
                bytes_per_line = width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                print("Unsupported image format for display.")
                QMessageBox.critical(self, "Error", "Unsupported image format for display.")
                return

            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)

        except Exception as e:
            print(f"Error displaying image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to display the image: {e}")


    def update_image_display(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """
        Zoom into the image by increasing the zoom factor.
        """
        if self.image is not None:
            self.zoom_factor *= 1.2
            self.show_image(self.image)
            print(f"Zoomed in. New zoom factor: {self.zoom_factor:.2f}")
        else:
            print("No stretched image to zoom in.")
            QMessageBox.warning(self, "Warning", "No stretched image to zoom in.")

    def zoom_out(self):
        """
        Zoom out of the image by decreasing the zoom factor.
        """
        if self.image is not None:
            self.zoom_factor /= 1.2
            self.show_image(self.image)
            print(f"Zoomed out. New zoom factor: {self.zoom_factor:.2f}")
        else:
            print("No stretched image to zoom out.")
            QMessageBox.warning(self, "Warning", "No stretched image to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.image.ndim == 3:
                image_width = self.image.shape[1]
            elif self.image.ndim == 2:
                image_width = self.image.shape[1]
            else:
                print("Unexpected image dimensions!")
                QMessageBox.warning(self, "Warning", "Cannot fit image to preview due to unexpected dimensions.")
                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.show_image(self.image)
            
            print(f"Fit to preview applied. New zoom factor: {self.zoom_factor:.2f}")
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def refresh_display(self):
        """
        Refresh the image display based on the current zoom factor.
        """
        if self.stretched_image is None:
            print("No stretched image to display.")
            return

        try:
            # Normalize and convert to uint8 for display
            img = (self.stretched_image * 255).astype(np.uint8)
            h, w = img.shape[:2]

            if img.ndim == 3 and img.shape[2] == 3:
                bytes_per_line = 3 * w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
            elif img.ndim == 2:
                bytes_per_line = w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                raise ValueError("Unsupported image format for display.")

            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

            print("Display refreshed successfully.")
        except Exception as e:
            print(f"Error refreshing display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to refresh display: {e}")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updatePreview()  # Call without extra arguments; it will calculate dimensions based on zoom factor            

    def saveImage(self):
        if self.image is not None:
            # Open the file save dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 'Save Image As', '', 
                'Images (*.tiff *.tif *.png *.fit *.fits *.xisf);;All Files (*)'
            )
            
            if save_filename:
                # Extract the file extension from the user-provided filename
                file_extension = save_filename.split('.')[-1].lower()

                # Map the extension to the format expected by save_image
                if file_extension in ['tif', 'tiff']:
                    file_format = 'tiff'
                elif file_extension == 'png':
                    file_format = 'png'
                elif file_extension in ['fit', 'fits']:
                    file_format = 'fits'
                elif file_extension == 'xisf':
                    file_format = 'xisf'
                else:
                    QMessageBox.warning(self, "Error", f"Unsupported file format: .{file_extension}")
                    return
                
                try:
                    # Initialize metadata if not already set (e.g., for PNG)
                    if not hasattr(self, 'image_meta') or self.image_meta is None:
                        self.image_meta = [{
                            'geometry': (self.image.shape[1], self.image.shape[0], self.image.shape[2] if not self.is_mono else 1),
                            'colorSpace': 'Gray' if self.is_mono else 'RGB'
                        }]

                    if not hasattr(self, 'file_meta') or self.file_meta is None:
                        self.file_meta = {}

                    # Initialize a default header for FITS if none exists
                    if not hasattr(self, 'original_header') or self.original_header is None:
                        print("Creating default FITS header...")
                        self.original_header = {
                            'SIMPLE': True,
                            'BITPIX': -32 if self.bit_depth == "32-bit floating point" else 16,
                            'NAXIS': 2 if self.is_mono else 3,
                            'NAXIS1': self.image.shape[1],
                            'NAXIS2': self.image.shape[0],
                            'NAXIS3': 1 if self.is_mono else self.image.shape[2],
                            'BZERO': 0.0,
                            'BSCALE': 1.0,
                            'COMMENT': "Default header created by Seti Astro Suite"
                        }

                    # Call save_image with the appropriate arguments
                    save_image(
                        self.image,
                        save_filename,
                        file_format,  # Use the user-specified format
                        self.bit_depth,
                        self.original_header,
                        self.is_mono,
                        self.image_meta,
                        self.file_meta
                    )
                    print(f"Image saved successfully to {save_filename}")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

class DraggablePoint(QGraphicsEllipseItem):
    def __init__(self, curve_editor, x, y, color=Qt.GlobalColor.green, lock_axis=None, position_type=None):
        super().__init__(-5, -5, 10, 10)
        self.curve_editor = curve_editor
        self.lock_axis = lock_axis
        self.position_type = position_type
        self.setBrush(QBrush(color))
        self.setFlags(QGraphicsItem.GraphicsItemFlag.ItemIsMovable | QGraphicsItem.GraphicsItemFlag.ItemSendsScenePositionChanges)
        self.setCursor(Qt.CursorShape.OpenHandCursor)
        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton | Qt.MouseButton.RightButton)
        self.setPos(x, y)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.RightButton:
            if self in self.curve_editor.control_points:
                self.curve_editor.control_points.remove(self)
                self.curve_editor.scene.removeItem(self)
                self.curve_editor.updateCurve()
            return
        super().mousePressEvent(event)

    def itemChange(self, change, value):
        if change == QGraphicsItem.GraphicsItemChange.ItemPositionHasChanged:
            new_pos = value
            x = new_pos.x()
            y = new_pos.y()

            if self.position_type == 'top_right':
                dist_to_top = abs(y-0)
                dist_to_right = abs(x-360)
                if dist_to_right<dist_to_top:
                    nx=360
                    ny=min(max(y,0),360)
                else:
                    ny=0
                    nx=min(max(x,0),360)
                x,y=nx,ny
            elif self.position_type=='bottom_left':
                dist_to_left=abs(x-0)
                dist_to_bottom=abs(y-360)
                if dist_to_left<dist_to_bottom:
                    nx=0
                    ny=min(max(y,0),360)
                else:
                    ny=360
                    nx=min(max(x,0),360)
                x,y=nx,ny

            all_points=self.curve_editor.end_points+self.curve_editor.control_points
            other_points=[p for p in all_points if p is not self]
            other_points_sorted=sorted(other_points,key=lambda p:p.scenePos().x())

            insert_index=0
            for i,p in enumerate(other_points_sorted):
                if p.scenePos().x()<x:
                    insert_index=i+1
                else:
                    break

            if insert_index>0:
                left_p=other_points_sorted[insert_index-1]
                left_x=left_p.scenePos().x()
                if x<=left_x:
                    x=left_x+0.0001

            if insert_index<len(other_points_sorted):
                right_p=other_points_sorted[insert_index]
                right_x=right_p.scenePos().x()
                if x>=right_x:
                    x=right_x-0.0001

            x=max(0,min(x,360))
            y=max(0,min(y,360))

            super().setPos(x,y)
            self.curve_editor.updateCurve()

        return super().itemChange(change, value)

class ImageLabel(QLabel):
    mouseMoved = pyqtSignal(float, float)
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)
    def mouseMoveEvent(self, event):
        self.mouseMoved.emit(event.pos().x(), event.pos().y())
        super().mouseMoveEvent(event)

class CurveEditor(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.scene = QGraphicsScene(self)
        self.setScene(self.scene)
        self.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.setFixedSize(380, 425)
        self.preview_callback = None  # To trigger real-time updates

        # Initialize control points and curve path
        self.end_points = []  # Start and end points with axis constraints
        self.control_points = []  # Dynamically added control points
        self.curve_path = QPainterPath()
        self.curve_item = None  # Stores the curve line

        # Set scene rectangle
        self.scene.setSceneRect(0, 0, 360, 360)

        self.initGrid()
        self.initCurve()

    def initGrid(self):
        pen = QPen(Qt.GlobalColor.gray)
        pen.setStyle(Qt.PenStyle.DashLine)
        for i in range(0, 361, 45):  # Grid lines at 0,45,...,360
            self.scene.addLine(i, 0, i, 360, pen)  # Vertical lines
            self.scene.addLine(0, i, 360, i, pen)  # Horizontal lines

        # Add X-axis labels
        # Each line corresponds to i/360.0
        for i in range(0, 361, 45):
            val = i/360.0
            label = QGraphicsTextItem(f"{val:.3f}")
            # Position label slightly below the x-axis (360 is bottom)
            # For X-axis, put them near bottom at y=365 for example
            label.setPos(i-5, 365) 
            self.scene.addItem(label)

        # Optionally add Y-axis labels if needed
        # Similar approach for the Y-axis if you want

    def initCurve(self):
        # Remove existing items from the scene
        # First remove control points
        for p in self.control_points:
            self.scene.removeItem(p)
        # Remove end points
        for p in self.end_points:
            self.scene.removeItem(p)
        # Remove the curve item if any
        if self.curve_item:
            self.scene.removeItem(self.curve_item)
            self.curve_item = None

        # Clear existing point lists
        self.end_points = []
        self.control_points = []

        # Add the default endpoints again
        self.addEndPoint(0, 360, lock_axis=None, position_type='bottom_left', color=Qt.GlobalColor.black)
        self.addEndPoint(360, 0, lock_axis=None, position_type='top_right', color=Qt.GlobalColor.white)

        # Redraw the initial line
        self.updateCurve()

    def addEndPoint(self, x, y, lock_axis=None, position_type=None, color=Qt.GlobalColor.red):
        point = DraggablePoint(self, x, y, color=color, lock_axis=lock_axis, position_type=position_type)
        self.scene.addItem(point)
        self.end_points.append(point)

    def addControlPoint(self, x, y, lock_axis=None):

        point = DraggablePoint(self, x, y, color=Qt.GlobalColor.green, lock_axis=lock_axis, position_type=None)
        self.scene.addItem(point)
        self.control_points.append(point)
        self.updateCurve()

    def catmull_rom_spline(self, p0, p1, p2, p3, t):
        """
        Compute a point on a Catmull-Rom spline segment at parameter t (0<=t<=1).
        Each p is a QPointF.
        """
        t2 = t * t
        t3 = t2 * t

        x = 0.5 * (2*p1.x() + (-p0.x() + p2.x()) * t +
                    (2*p0.x() - 5*p1.x() + 4*p2.x() - p3.x()) * t2 +
                    (-p0.x() + 3*p1.x() - 3*p2.x() + p3.x()) * t3)
        y = 0.5 * (2*p1.y() + (-p0.y() + p2.y()) * t +
                    (2*p0.y() - 5*p1.y() + 4*p2.y() - p3.y()) * t2 +
                    (-p0.y() + 3*p1.y() - 3*p2.y() + p3.y()) * t3)

        # Clamp to bounding box
        x = max(0, min(360, x))
        y = max(0, min(360, y))

        return QPointF(x, y)

    def generateSmoothCurvePoints(self, points):
        """
        Given a sorted list of QGraphicsItems (endpoints + control points),
        generate a list of smooth points approximating a Catmull-Rom spline
        through these points.
        """
        if len(points) < 2:
            return []
        if len(points) == 2:
            # Just a straight line between two points
            p0 = points[0].scenePos()
            p1 = points[1].scenePos()
            return [p0, p1]

        # Extract scene positions
        pts = [p.scenePos() for p in points]

        # For Catmull-Rom, we need points before the first and after the last
        # We'll duplicate the first and last points.
        extended_pts = [pts[0]] + pts + [pts[-1]]

        smooth_points = []
        steps_per_segment = 20  # increase for smoother curve
        for i in range(len(pts) - 1):
            p0 = extended_pts[i]
            p1 = extended_pts[i+1]
            p2 = extended_pts[i+2]
            p3 = extended_pts[i+3]

            # Sample the spline segment between p1 and p2
            for step in range(steps_per_segment+1):
                t = step / steps_per_segment
                pos = self.catmull_rom_spline(p0, p1, p2, p3, t)
                smooth_points.append(pos)

        return smooth_points

    # Add a callback for the preview
    def setPreviewCallback(self, callback):
        self.preview_callback = callback

    def get8bitLUT(self):
        import numpy as np

        # 8-bit LUT size
        lut_size = 256

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 255, lut_size, dtype=np.uint8)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:, 0]   # X from 0 to 360
        ys = curve_array[:, 1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys

        # Input positions for interpolation (0..255 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..255
        output_values = (output_values / 360.0) * 255.0
        output_values = np.clip(output_values, 0, 255).astype(np.uint8)

        return output_values

    def updateCurve(self):
        """Update the curve by redrawing based on endpoints and control points."""
        
        all_points = self.end_points + self.control_points
        if not all_points:
            # No points, no curve
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        # Sort points by X coordinate
        sorted_points = sorted(all_points, key=lambda p: p.scenePos().x())

        # Extract arrays of X and Y
        xs = [p.scenePos().x() for p in sorted_points]
        ys = [p.scenePos().y() for p in sorted_points]

        # Ensure X values are strictly increasing
        unique_xs, unique_ys = [], []
        for i in range(len(xs)):
            if i == 0 or xs[i] > xs[i - 1]:  # Skip duplicate X values
                unique_xs.append(xs[i])
                unique_ys.append(ys[i])

        # If there's only one point or none, we can't interpolate
        if len(unique_xs) < 2:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None

            if len(unique_xs) == 1:
                # Optionally draw a single point
                single_path = QPainterPath()
                single_path.addEllipse(unique_xs[0]-2, unique_ys[0]-2, 4, 4)
                pen = QPen(Qt.GlobalColor.white)
                pen.setWidth(3)
                self.curve_item = self.scene.addPath(single_path, pen)
            return

        try:
            # Create a PCHIP interpolator
            interpolator = PchipInterpolator(unique_xs, unique_ys)
            self.curve_function = interpolator

            # Sample the curve
            sample_xs = np.linspace(unique_xs[0], unique_xs[-1], 361)
            sample_ys = interpolator(sample_xs)

        except ValueError as e:
            print(f"Interpolation Error: {e}")  # Log the error instead of crashing
            return  # Exit gracefully

        curve_points = [QPointF(float(x), float(y)) for x, y in zip(sample_xs, sample_ys)]
        self.curve_points = curve_points

        if not curve_points:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        self.curve_path = QPainterPath()
        self.curve_path.moveTo(curve_points[0])
        for pt in curve_points[1:]:
            self.curve_path.lineTo(pt)

        if self.curve_item:
            self.scene.removeItem(self.curve_item)
        pen = QPen(Qt.GlobalColor.white)
        pen.setWidth(3)
        self.curve_item = self.scene.addPath(self.curve_path, pen)

        # Trigger the preview callback
        if hasattr(self, 'preview_callback') and self.preview_callback:
            # Generate the 8-bit LUT and pass it to the callback
            lut = self.get8bitLUT()
            self.preview_callback(lut)

    def getCurveFunction(self):
        return self.curve_function

    def getCurvePoints(self):
        if not hasattr(self, 'curve_points') or not self.curve_points:
            return []
        return [(pt.x(), pt.y()) for pt in self.curve_points]

    def getLUT(self):
        import numpy as np

        # 16-bit LUT size
        lut_size = 65536

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 65535, lut_size, dtype=np.uint16)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:,0]   # X from 0 to 360
        ys = curve_array[:,1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys


        # Input positions for interpolation (0..65535 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..65535
        output_values = (output_values / 360.0) * 65535.0
        output_values = np.clip(output_values, 0, 65535).astype(np.uint16)

        return output_values


    def mouseDoubleClickEvent(self, event):
        """
        Handle double-click events to add a new control point.
        """
        scene_pos = self.mapToScene(event.pos())

        self.addControlPoint(scene_pos.x(), scene_pos.y())
        super().mouseDoubleClickEvent(event)

    def keyPressEvent(self, event):
        """Remove selected points on Delete key press."""
        if event.key() == Qt.Key.Key_Delete:
            for point in self.control_points[:]:
                if point.isSelected():
                    self.scene.removeItem(point)
                    self.control_points.remove(point)
            self.updateCurve()
        super().keyPressEvent(event)

    def updateValueLines(self, r, g, b, grayscale=False):
        """
        Update vertical lines on the curve scene.
        For color images (grayscale=False), three lines (red, green, blue) are drawn.
        For grayscale images (grayscale=True), a single gray line is drawn.
        
        Values are assumed to be in the range [0, 1] and mapped to 0–360.
        """
        if grayscale:
            # Map the 0–1 grayscale value to the scene's X coordinate (0–360)
            x = r * 360.0
            if not hasattr(self, "gray_line") or self.gray_line is None:
                self.gray_line = self.scene.addLine(x, 0, x, 360, QPen(Qt.GlobalColor.gray))
            else:
                self.gray_line.setLine(x, 0, x, 360)
            # Hide any color lines if present
            for attr in ("r_line", "g_line", "b_line"):
                if hasattr(self, attr) and getattr(self, attr) is not None:
                    getattr(self, attr).setVisible(False)
        else:
            # Hide grayscale line if present
            if hasattr(self, "gray_line") and self.gray_line is not None:
                self.gray_line.setVisible(False)
            
            # Map each 0–1 value to X coordinate on scene (0–360)
            r_x = r * 360.0
            g_x = g * 360.0
            b_x = b * 360.0

            # Create or update the red line
            if not hasattr(self, "r_line") or self.r_line is None:
                self.r_line = self.scene.addLine(r_x, 0, r_x, 360, QPen(Qt.GlobalColor.red))
            else:
                self.r_line.setLine(r_x, 0, r_x, 360)
            self.r_line.setVisible(True)

            # Create or update the green line
            if not hasattr(self, "g_line") or self.g_line is None:
                self.g_line = self.scene.addLine(g_x, 0, g_x, 360, QPen(Qt.GlobalColor.green))
            else:
                self.g_line.setLine(g_x, 0, g_x, 360)
            self.g_line.setVisible(True)

            # Create or update the blue line
            if not hasattr(self, "b_line") or self.b_line is None:
                self.b_line = self.scene.addLine(b_x, 0, b_x, 360, QPen(Qt.GlobalColor.blue))
            else:
                self.b_line.setLine(b_x, 0, b_x, 360)
            self.b_line.setVisible(True)


def build_curve_lut(curve_func, size=65536):
    """
    Build a LUT of length 'size' that maps float in [0..1] to [0..1],
    using your existing PCHIP curve_func(x) which is defined on x in [0..360].
    We'll do:
       mapped = 360 - curve_func(x)
       out = clamp( mapped / 360, [0..1] )
    """
    import numpy as np
    lut = np.zeros(size, dtype=np.float32)
    for i in range(size):
        v = i / (size - 1)  # in [0..1]
        x = v * 360.0
        mapped = 360.0 - curve_func(x)
        outv = mapped / 360.0
        if outv < 0.0: outv = 0.0
        elif outv > 1.0: outv = 1.0
        lut[i] = outv
    return lut


class FullCurvesProcessingThread(QThread):
    result_ready = pyqtSignal(np.ndarray)

    def __init__(self, image, curve_mode, curve_func):
        super().__init__()
        self.image = image
        self.curve_mode = curve_mode
        self.curve_func = curve_func

    def run(self):
        adjusted_image = self.process_curve(self.image, self.curve_mode, self.curve_func)
        self.result_ready.emit(adjusted_image)

    @staticmethod
    def process_curve(image, curve_mode, curve_func):
        """
        Main entry point to apply the user's curve in 'curve_mode'
        to 'image' using a single big LUT for [0..1].
        """
        import numpy as np

        if image is None or curve_func is None:
            return image

        # 1) Convert to float32 [0..1]
        if image.dtype != np.float32:
            image = image.astype(np.float32, copy=False)

        # 2) Build a big LUT
        lut = build_curve_lut(curve_func, size=65536)

        # 3) If single-channel, reshape to (H,W,1) for uniform handling
        is_gray = (image.ndim == 2 or image.shape[2] == 1)
        if is_gray:
            image = image.reshape(image.shape[0], image.shape[1], 1)

        mode = curve_mode.lower()

        # ----------------------------------------------------------------------
        # R/G/B/K (Brightness) => direct LUT application
        # ----------------------------------------------------------------------
        if mode == 'r':
            # Apply LUT only to channel 0
            # We do it manually:
            out = image.copy()
            H, W, _ = out.shape
            # channel 0
            apply_lut_mono_inplace(out[...,0], lut)
            return out

        elif mode == 'g':
            # channel 1
            out = image.copy()
            apply_lut_mono_inplace(out[...,1], lut)
            return out

        elif mode == 'b':
            # channel 2
            out = image.copy()
            apply_lut_mono_inplace(out[...,2], lut)
            return out

        elif mode == 'k (brightness)':
            # Apply LUT to all channels
            out = image.copy()
            apply_lut_color_inplace(out, lut)
            return out

        # -------------------------------------------------------
        # L*, a*, b*, Chroma => do color transform => apply LUT => transform back
        # -------------------------------------------------------
        elif mode in ["l*", "a*", "b*", "chroma"]:
            # 1) Convert RGB -> XYZ -> Lab via Numba
            xyz = rgb_to_xyz_numba(image)             # Numba-based
            lab = xyz_to_lab_numba(xyz)               # Numba-based

            if mode == "l*":
                # L in [0..100]
                L = lab[..., 0] / 100.0
                apply_lut_mono_inplace(L, lut)
                lab[..., 0] = L * 100.0

            elif mode == "a*":
                # a in [-128..127], shift => [0..255], then /255 => [0..1]
                a = lab[..., 1]
                a_norm = (a + 128.0) / 255.0
                a_norm = np.clip(a_norm, 0, 1)
                apply_lut_mono_inplace(a_norm, lut)
                lab[..., 1] = a_norm * 255.0 - 128.0

            elif mode == "b*":
                # b in [-128..127]
                b = lab[..., 2]
                b_norm = (b + 128.0) / 255.0
                b_norm = np.clip(b_norm, 0, 1)
                apply_lut_mono_inplace(b_norm, lut)
                lab[..., 2] = b_norm * 255.0 - 128.0

            elif mode == "chroma":
                a_ = lab[..., 1]
                b_ = lab[..., 2]
                C = np.sqrt(a_ * a_ + b_ * b_)
                C_norm = np.clip(C / 200.0, 0, 1)
                apply_lut_mono_inplace(C_norm, lut)
                C_new = C_norm * 200.0
                ratio = np.divide(C_new, C, out=np.zeros_like(C), where=(C != 0))
                lab[..., 1] = a_ * ratio
                lab[..., 2] = b_ * ratio

            # Convert Lab -> XYZ -> RGB
            xyz_new = lab_to_xyz_numba(lab)           # Numba-based
            out = xyz_to_rgb_numba(xyz_new)           # Numba-based
            return out

        # -------------------------------------------------------
        # HSV saturation => same approach
        # -------------------------------------------------------
        elif mode == "saturation":
            hsv = rgb_to_hsv_numba(image)             # Numba-based
            S = hsv[..., 1]
            apply_lut_mono_inplace(S, lut)
            hsv[..., 1] = S
            out = hsv_to_rgb_numba(hsv)               # Numba-based
            return out

        # If none matched, just return the image
        return image

    @staticmethod
    def rgb_to_xyz(rgb):
        M = np.array([[0.4124564, 0.3575761, 0.1804375],
                      [0.2126729, 0.7151522, 0.0721750],
                      [0.0193339, 0.1191920, 0.9503041]], dtype=np.float32)
        shape = rgb.shape
        out = rgb.reshape(-1,3) @ M.T
        return out.reshape(shape)

    @staticmethod
    def xyz_to_rgb(xyz):
        M_inv = np.array([[ 3.2404542, -1.5371385, -0.4985314],
                          [-0.9692660,  1.8760108,  0.0415560],
                          [ 0.0556434, -0.2040259,  1.0572252]], dtype=np.float32)
        shape = xyz.shape
        out = xyz.reshape(-1,3) @ M_inv.T
        out = np.clip(out, 0, 1)
        return out.reshape(shape)

    @staticmethod
    def f_lab(t):
        delta = 6/29
        mask = t > delta**3
        f = np.zeros_like(t)
        f[mask] = np.cbrt(t[mask])
        f[~mask] = t[~mask]/(3*delta*delta)+4/29
        return f

    @staticmethod
    def xyz_to_lab(xyz):
        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = xyz[:,:,0]/Xn
        Y = xyz[:,:,1]/Yn
        Z = xyz[:,:,2]/Zn

        fx = FullCurvesProcessingThread.f_lab(X)
        fy = FullCurvesProcessingThread.f_lab(Y)
        fz = FullCurvesProcessingThread.f_lab(Z)

        L = (116 * fy - 16)
        a = 500*(fx - fy)
        b = 200*(fy - fz)
        return np.dstack([L, a, b]).astype(np.float32)

    @staticmethod
    def lab_to_xyz(lab):
        L = lab[:,:,0]
        a = lab[:,:,1]
        b = lab[:,:,2]

        delta = 6/29
        fy = (L+16)/116
        fx = fy + a/500
        fz = fy - b/200

        def f_inv(ft):
            return np.where(ft > delta, ft**3, 3*delta*delta*(ft - 4/29))

        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = Xn*f_inv(fx)
        Y = Yn*f_inv(fy)
        Z = Zn*f_inv(fz)
        return np.dstack([X, Y, Z]).astype(np.float32)

    @staticmethod
    def rgb_to_hsv(rgb):
        cmax = rgb.max(axis=2)
        cmin = rgb.min(axis=2)
        delta = cmax - cmin

        H = np.zeros_like(cmax)
        S = np.zeros_like(cmax)
        V = cmax

        mask = delta != 0
        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
        H[mask & (cmax==r)] = 60*(((g[mask&(cmax==r)]-b[mask&(cmax==r)])/delta[mask&(cmax==r)])%6)
        H[mask & (cmax==g)] = 60*(((b[mask&(cmax==g)]-r[mask&(cmax==g)])/delta[mask&(cmax==g)])+2)
        H[mask & (cmax==b)] = 60*(((r[mask&(cmax==b)]-g[mask&(cmax==b)])/delta[mask&(cmax==b)])+4)

        S[cmax>0] = delta[cmax>0]/cmax[cmax>0]
        return np.dstack([H,S,V]).astype(np.float32)

    @staticmethod
    def hsv_to_rgb(hsv):
        H, S, V = hsv[:,:,0], hsv[:,:,1], hsv[:,:,2]
        C = V*S
        X = C*(1-np.abs((H/60.0)%2-1))
        m = V-C

        R = np.zeros_like(H)
        G = np.zeros_like(H)
        B = np.zeros_like(H)

        cond0 = (H<60)
        cond1 = (H>=60)&(H<120)
        cond2 = (H>=120)&(H<180)
        cond3 = (H>=180)&(H<240)
        cond4 = (H>=240)&(H<300)
        cond5 = (H>=300)

        R[cond0]=C[cond0]; G[cond0]=X[cond0]; B[cond0]=0
        R[cond1]=X[cond1]; G[cond1]=C[cond1]; B[cond1]=0
        R[cond2]=0; G[cond2]=C[cond2]; B[cond2]=X[cond2]
        R[cond3]=0; G[cond3]=X[cond3]; B[cond3]=C[cond3]
        R[cond4]=X[cond4]; G[cond4]=0; B[cond4]=C[cond4]
        R[cond5]=C[cond5]; G[cond5]=0; B[cond5]=X[cond5]

        rgb = np.dstack([R+m, G+m, B+m])
        rgb = np.clip(rgb, 0, 1)
        return rgb

class FrequencySeperationTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the shared ImageManager
        self.filename = None
        self.image = None  # Original input image
        self.low_freq_image = None
        self.high_freq_image = None
        self.original_header = None
        self.is_mono = False
        self.processing_thread = None
        self.hfEnhancementThread = None
        self.hf_history = []

        # Default parameters
        self.method = 'Gaussian'
        self.radius = 25
        self.mirror = False
        self.tolerance = 50  # new tolerance param

        # Zoom/pan control
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        # For the preview
        self.spinnerLabel = None
        self.spinnerMovie = None

        # A guard variable to avoid infinite scroll loops
        self.syncing_scroll = False

        self.initUI()

        # Connect to ImageManager's image_changed signal if available
        if self.image_manager:
            self.image_manager.image_changed.connect(self.on_image_changed)
            # Load the existing image from ImageManager, if any
            if self.image_manager.image is not None:
                self.on_image_changed(
                    slot=self.image_manager.current_slot,
                    image=self.image_manager.image,
                    metadata=self.image_manager.current_metadata
                )

    def initUI(self):
        """
        Set up the GUI layout:
          - Left panel with controls (Load, Method, Radius, Mirror, Tolerance, Apply, Save, etc.)
          - Right panel with two scroll areas for HF/LF previews
        """
        main_layout = QHBoxLayout(self)
        self.setLayout(main_layout)

        # -----------------------------
        # Left side: Controls
        # -----------------------------
        left_widget = QWidget(self)
        left_widget.setFixedWidth(250)
        left_layout = QVBoxLayout(left_widget)

        # 1) Load image
        self.loadButton = QPushButton("Load Image", self)
        self.loadButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DirOpenIcon))
        self.loadButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.loadButton)

        self.fileLabel = QLabel("", self)
        left_layout.addWidget(self.fileLabel)

        # Method Combo
        self.method_combo = QComboBox(self)
        self.method_combo.addItems(['Gaussian', 'Median', 'Bilateral'])
        self.method_combo.currentTextChanged.connect(self.on_method_changed)
        left_layout.addWidget(QLabel("Method:", self))
        left_layout.addWidget(self.method_combo)

        # Radius Slider + Label
        self.radiusSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.radiusSlider.setRange(1, 100)
        self.radiusSlider.setValue(10)  # or whatever integer in [1..100] you want
        self.radiusSlider.valueChanged.connect(self.on_radius_changed)

        self.radiusLabel = QLabel("Radius:", self)
        left_layout.addWidget(self.radiusLabel)   
        left_layout.addWidget(self.radiusSlider)

        # Now force an initial update so label is correct from the start
        self.on_radius_changed(self.radiusSlider.value())

        # Tolerance Slider + Label
        self.toleranceSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.toleranceSlider.setRange(0, 100)
        self.toleranceSlider.setValue(self.tolerance)
        self.toleranceSlider.valueChanged.connect(self.on_tolerance_changed)
        self.toleranceLabel = QLabel(f"Tolerance: {self.tolerance}%", self)
        self.toleranceSlider.setEnabled(False)
        self.toleranceLabel.setEnabled(False)
        left_layout.addWidget(self.toleranceLabel)
        left_layout.addWidget(self.toleranceSlider)

        # Apply button
        self.applyButton = QPushButton("Apply - Split HF and LF", self)
        self.applyButton.clicked.connect(self.apply_frequency_separation)
        left_layout.addWidget(self.applyButton)        

        # -----------------------------------
        # *** New Sharpening Controls ***
        # -----------------------------------
        # 1) Checkbox for "Enable Sharpen Scale"
        self.sharpenScaleCheckBox = QCheckBox("Enable Sharpen Scale", self)
        self.sharpenScaleCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.sharpenScaleCheckBox)

        # Sharpen Scale Label + Slider
        self.sharpenScaleLabel = QLabel("Sharpen Scale: 1.00", self)
        left_layout.addWidget(self.sharpenScaleLabel)

        self.sharpenScaleSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.sharpenScaleSlider.setRange(10, 300)  # => 0.1..3.0
        self.sharpenScaleSlider.setValue(100)      # 1.00 initially
        self.sharpenScaleSlider.valueChanged.connect(self.onSharpenScaleChanged)
        left_layout.addWidget(self.sharpenScaleSlider)

        # 2) Checkbox for "Enable Wavelet Sharpening"
        self.waveletCheckBox = QCheckBox("Enable Wavelet Sharpening", self)
        self.waveletCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.waveletCheckBox)

        # Wavelet Sharpening Sliders
        wavelet_title = QLabel("<b>Wavelet Sharpening:</b>", self)
        left_layout.addWidget(wavelet_title)

        self.waveletLevelLabel = QLabel("Wavelet Level: 2", self)
        left_layout.addWidget(self.waveletLevelLabel)

        self.waveletLevelSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletLevelSlider.setRange(1, 5)
        self.waveletLevelSlider.setValue(2)
        self.waveletLevelSlider.valueChanged.connect(self.onWaveletLevelChanged)
        left_layout.addWidget(self.waveletLevelSlider)

        self.waveletBoostLabel = QLabel("Wavelet Boost: 1.20", self)
        left_layout.addWidget(self.waveletBoostLabel)

        self.waveletBoostSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletBoostSlider.setRange(50, 300)  # => 0.5..3.0
        self.waveletBoostSlider.setValue(120)      # 1.20 initially
        self.waveletBoostSlider.valueChanged.connect(self.onWaveletBoostChanged)
        left_layout.addWidget(self.waveletBoostSlider)

        self.enableDenoiseCheckBox = QCheckBox("Enable HF Denoise", self)
        self.enableDenoiseCheckBox.setChecked(False)  # default off or on, your choice
        left_layout.addWidget(self.enableDenoiseCheckBox)

        # Label + Slider for denoise strength
        self.denoiseStrengthLabel = QLabel("Denoise Strength: 3.00", self)
        left_layout.addWidget(self.denoiseStrengthLabel)

        self.denoiseStrengthSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.denoiseStrengthSlider.setRange(0, 50)  # Example range -> 1..50 => 1.0..50.0
        self.denoiseStrengthSlider.setValue(3)      # default 3
        self.denoiseStrengthSlider.valueChanged.connect(self.onDenoiseStrengthChanged)
        left_layout.addWidget(self.denoiseStrengthSlider)
        self.onDenoiseStrengthChanged(self.denoiseStrengthSlider.value())

        # Create a horizontal layout for HF Enhancements and Undo
        hfEnhance_hlayout = QHBoxLayout()

        # Apply HF Enhancements button
        self.applyHFEnhancementsButton = QPushButton("Apply HF Enhancements", self)
        self.applyHFEnhancementsButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        self.applyHFEnhancementsButton.clicked.connect(self.applyHFEnhancements)
        hfEnhance_hlayout.addWidget(self.applyHFEnhancementsButton)

        # Undo button (tool button with back arrow icon)
        self.undoHFButton = QToolButton(self)
        self.undoHFButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack))
        self.undoHFButton.setToolTip("Undo last HF enhancement")
        self.undoHFButton.clicked.connect(self.undoHFEnhancement)
        self.undoHFButton.setEnabled(False)  # Initially disabled
        hfEnhance_hlayout.addWidget(self.undoHFButton)

        # Now add this horizontal layout to the main left_layout
        left_layout.addLayout(hfEnhance_hlayout)

        # ------------------------------------
        # Save HF / LF - in a horizontal layout
        # ------------------------------------
        save_hlayout = QHBoxLayout()

        self.saveHFButton = QPushButton("Save HF", self)
        self.saveHFButton.clicked.connect(self.save_high_frequency)
        save_hlayout.addWidget(self.saveHFButton)

        self.saveLFButton = QPushButton("Save LF", self)
        self.saveLFButton.clicked.connect(self.save_low_frequency)
        save_hlayout.addWidget(self.saveLFButton)

        left_layout.addLayout(save_hlayout)

        # ------------------------------------
        # Import HF / LF - in a separate horizontal layout
        # ------------------------------------
        load_hlayout = QHBoxLayout()

        self.importHFButton = QPushButton("Load HF", self)
        self.importHFButton.clicked.connect(self.loadHF)
        load_hlayout.addWidget(self.importHFButton)

        self.importLFButton = QPushButton("Load LF", self)
        self.importLFButton.clicked.connect(self.loadLF)
        load_hlayout.addWidget(self.importLFButton)

        left_layout.addLayout(load_hlayout)

        # Combine HF + LF
        self.combineButton = QPushButton("Combine HF + LF", self)
        self.combineButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogYesButton))
        self.combineButton.clicked.connect(self.combineHFandLF)
        left_layout.addWidget(self.combineButton)

        # Spinner for background processing
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Provide your spinner path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()
        left_layout.addWidget(self.spinnerLabel)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # -----------------------------
        # Right Panel (vertical layout)
        # -----------------------------
        right_widget = QWidget(self)
        right_vbox = QVBoxLayout(right_widget)

        # 1) Zoom Buttons row (top)
        zoom_hbox = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In")
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        zoom_hbox.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out")
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        zoom_hbox.addWidget(self.zoom_out_btn)

        right_vbox.addLayout(zoom_hbox)

        # 2) HF / LF previews row (below)
        scroll_hbox = QHBoxLayout()

        self.scrollHF = QScrollArea(self)
        self.scrollHF.setWidgetResizable(False)
        self.labelHF = QLabel("High Frequency", self)
        self.labelHF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelHF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollHF.setWidget(self.labelHF)

        self.scrollLF = QScrollArea(self)
        self.scrollLF.setWidgetResizable(False)
        self.labelLF = QLabel("Low Frequency", self)
        self.labelLF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelLF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollLF.setWidget(self.labelLF)

        scroll_hbox.addWidget(self.scrollHF, stretch=1)
        scroll_hbox.addWidget(self.scrollLF, stretch=1)

        right_vbox.addLayout(scroll_hbox, stretch=1)
        main_layout.addWidget(right_widget, stretch=1)

        # Sync scrollbars
        self.scrollHF.horizontalScrollBar().valueChanged.connect(self.syncHFHScroll)
        self.scrollHF.verticalScrollBar().valueChanged.connect(self.syncHFVScroll)
        self.scrollLF.horizontalScrollBar().valueChanged.connect(self.syncLFHScroll)
        self.scrollLF.verticalScrollBar().valueChanged.connect(self.syncLFVScroll)

        # Mouse drag panning
        self.scrollHF.viewport().installEventFilter(self)
        self.scrollLF.viewport().installEventFilter(self)

        # Force initial label update
        self.on_radius_changed(self.radiusSlider.value())
        self.on_tolerance_changed(self.toleranceSlider.value())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    # -----------------------------
    # Image Manager Integration
    # -----------------------------
    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the FrequencySeperationTab if the change is relevant.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if needed

            # Update internal state with the new image and metadata
            self.loaded_image_path = metadata.get('file_path', None)
            self.image = image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = self.loaded_image_path

            # Reset HF / LF placeholders
            self.low_freq_image = None
            self.high_freq_image = None

            # Update UI label to show the file name or indicate no file
            # Update the fileLabel in the Frequency Separation Tab (or any other tab)
            if self.image_manager.image is not None:
                # Retrieve the file path from the metadata in ImageManager
                file_path = self.image_manager._metadata[self.image_manager.current_slot].get('file_path', None)

                # If file_path is a string, get the basename; otherwise, use a default message.
                if file_path and isinstance(file_path, str):
                    display_name = os.path.basename(file_path)
                else:
                    display_name = "No file selected"

                self.fileLabel.setText(display_name)
            else:
                self.fileLabel.setText("No file selected")


            # Automatically apply frequency separation
            self.apply_frequency_separation()

            print(f"FrequencySeperationTab: Image updated from ImageManager slot {slot}.")


    def map_slider_to_radius(self, slider_pos):
        """
        Convert a slider position (0..100) into a non-linear float radius.
        Segment A: [0..10]   -> [0.1..1.0]
        Segment B: [10..50]  -> [1.0..10.0]
        Segment C: [50..100] -> [10.0..100.0]
        """
        if slider_pos <= 10:
            # Scale 0..10 -> 0.1..1.0
            t = slider_pos / 10.0           # t in [0..1]
            radius = 0.1 + t*(1.0 - 0.1)    # 0.1 -> 1.0
        elif slider_pos <= 50:
            # Scale 10..50 -> 1.0..10.0
            t = (slider_pos - 10) / 40.0    # t in [0..1]
            radius = 1.0 + t*(10.0 - 1.0)   # 1.0 -> 10.0
        else:
            # Scale 50..100 -> 10.0..100.0
            t = (slider_pos - 50) / 50.0    # t in [0..1]
            radius = 10.0 + t*(100.0 - 10.0)  # 10.0 -> 100.0
        
        return radius

    def onSharpenScaleChanged(self, val):
        scale = val / 100.0  # 10..300 => 0.1..3.0
        self.sharpenScaleLabel.setText(f"Sharpen Scale: {scale:.2f}")

    def onWaveletLevelChanged(self, val):
        self.waveletLevelLabel.setText(f"Wavelet Level: {val}")

    def onWaveletBoostChanged(self, val):
        boost = val / 100.0  # e.g. 50..300 => 0.50..3.00
        self.waveletBoostLabel.setText(f"Wavelet Boost: {boost:.2f}")

    def onDenoiseStrengthChanged(self, val):
        # Map 0..50 => 0..5.0 by dividing by 10
        denoise_strength = val / 10.0
        self.denoiseStrengthLabel.setText(f"Denoise Strength: {denoise_strength:.2f}")

    # -------------------------------------------------
    # Event Filter for Drag Panning
    # -------------------------------------------------
    def eventFilter(self, obj, event):
        if obj in (self.scrollHF.viewport(), self.scrollLF.viewport()):
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()

                if obj == self.scrollHF.viewport():
                    # Move HF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync LF
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                else:
                    # Move LF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync HF
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(obj, event)

    # -----------------------------
    # Scrolling Sync
    # -----------------------------
    def syncHFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncHFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    # -----------------------------
    # Zooming
    # -----------------------------

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        self.zoom_factor *= 1.25
        self.update_previews()

    def zoom_out(self):
        self.zoom_factor /= 1.25
        self.update_previews()

    # -----------------------------
    # Control Handlers
    # -----------------------------
    def on_method_changed(self, text):
        """
        Called whenever the method dropdown changes (Gaussian, Median, Bilateral).
        Enable the tolerance slider only for 'Bilateral'.
        """
        self.method = text
        if self.method == 'Bilateral':
            self.toleranceSlider.setEnabled(True)
            self.toleranceLabel.setEnabled(True)
        else:
            self.toleranceSlider.setEnabled(False)
            self.toleranceLabel.setEnabled(False)

    def on_radius_changed(self, value):
        new_radius = self.map_slider_to_radius(value)  # use self.
        self.radius = new_radius
        self.radiusLabel.setText(f"Radius: {new_radius:.2f}")


    def on_tolerance_changed(self, value):
        self.tolerance = value
        self.toleranceLabel.setText(f"Tolerance: {value}%")  # Update label

    def undoHFEnhancement(self):
        """
        Revert HF to the last state from hf_history, if available.
        Disable Undo if no more history is left.
        """
        if len(self.hf_history) == 0:
            return  # No history to revert
        
        # Pop the last saved HF
        old_hf = self.hf_history.pop()

        # Restore it
        self.high_freq_image = old_hf
        self.update_previews()
        self.fileLabel.setText("Undid last HF enhancement.")

        # If no more states are left, disable the Undo button again
        if len(self.hf_history) == 0:
            self.undoHFButton.setEnabled(False)


    def applyHFEnhancements(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No HF image to enhance.")
            return
        
        self.hf_history.append(self.high_freq_image.copy())

        # Enable the Undo button because now we have at least one state
        self.undoHFButton.setEnabled(True)

        self.showSpinner()

        # If a previous thread is running, kill it safely
        if self.hfEnhancementThread and self.hfEnhancementThread.isRunning():
            self.hfEnhancementThread.quit()
            self.hfEnhancementThread.wait()

        # Check Sharpen Scale
        enable_scale = self.sharpenScaleCheckBox.isChecked()
        sharpen_scale = self.sharpenScaleSlider.value() / 100.0

        # Wavelet
        enable_wavelet = self.waveletCheckBox.isChecked()
        wavelet_level = self.waveletLevelSlider.value()
        wavelet_boost = self.waveletBoostSlider.value() / 100.0

        # Denoise
        enable_denoise = self.enableDenoiseCheckBox.isChecked()
        denoise_strength = float(self.denoiseStrengthSlider.value()/10.0)  # or do /10 if you want finer steps

        # Instantiate HFEnhancementThread with denoise params
        self.hfEnhancementThread = HFEnhancementThread(
            hf_image=self.high_freq_image,
            enable_scale=enable_scale,
            sharpen_scale=sharpen_scale,
            enable_wavelet=enable_wavelet,
            wavelet_level=wavelet_level,
            wavelet_boost=wavelet_boost,
            wavelet_name='db2',
            enable_denoise=enable_denoise,
            denoise_strength=denoise_strength
        )
        self.hfEnhancementThread.enhancement_done.connect(self.onHFEnhancementDone)
        self.hfEnhancementThread.error_signal.connect(self.onHFEnhancementError)
        self.hfEnhancementThread.start()


    def onHFEnhancementDone(self, newHF):
        self.hideSpinner()
        self.high_freq_image = newHF  # updated HF
        self.update_previews()
        self.fileLabel.setText("HF enhancements applied (thread).")

    def onHFEnhancementError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"HF enhancement error: {msg}")

    # -----------------------------
    # Image Selection and Preview Methods
    # -----------------------------
    def selectImage(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        selected_file, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if selected_file:
            try:
                img, header, bit_depth, is_mono = load_image(selected_file)
                if img is None:
                    QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                    return

                print(f"FrequencySeperationTab: Image loaded successfully. Shape: {img.shape}, Dtype: {img.dtype}")

                self.image = img
                self.original_header = header
                self.is_mono = is_mono
                self.filename = selected_file
                self.fileLabel.setText(os.path.basename(selected_file))

                # Reset HF / LF placeholders
                self.low_freq_image = None
                self.high_freq_image = None

                # Update ImageManager with the new image
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': bit_depth,
                    'is_mono': self.is_mono
                }
                self.image_manager.set_current_image(image=img, metadata=metadata)
                print("FrequencySeperationTab: Image updated in ImageManager.")

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"FrequencySeperationTab: Error loading image: {e}")

    def save_high_frequency(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No high-frequency image to save.")
            return
        self._save_image_with_dialog(self.high_freq_image, suffix="_HF")

    def save_low_frequency(self):
        if self.low_freq_image is None:
            self.fileLabel.setText("No low-frequency image to save.")
            return
        self._save_image_with_dialog(self.low_freq_image, suffix="_LF")

    def _save_image_with_dialog(self, image_to_save, suffix=""):
        """
        Always save HF in 32-bit floating point, either .tif or .fits.
        """
        if self.filename:
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + suffix + '.tif'
            original_dir = os.path.dirname(self.filename)
        else:
            default_save_name = "untitled" + suffix + '.tif'
            original_dir = os.getcwd()

        # Restrict the file dialog to TIF/FITS by default,
        # but let's keep .png, etc., in case user tries to pick it.
        # We'll override if they do.
        save_filename, _ = QFileDialog.getSaveFileName(
            self,
            'Save HF Image as 32-bit Float',
            os.path.join(original_dir, default_save_name),
            'TIFF or FITS (*.tif *.tiff *.fits *.fit);;All Files (*)'
        )
        if save_filename:
            # Identify extension
            file_ext = os.path.splitext(save_filename)[1].lower().strip('.')  # e.g. 'tif', 'fits', etc.

            # If user picks something else (png/jpg), override to .tif
            if file_ext not in ['tif', 'tiff', 'fit', 'fits']:
                file_ext = 'tif'
                # Force the filename to end with .tif
                save_filename = os.path.splitext(save_filename)[0] + '.tif'

            # We skip prompting for bit depth since we always want 32-bit float
            bit_depth = "32-bit floating point"

            # Force original_format to the extension we ended up with
            save_image(
                image_to_save,
                save_filename,
                original_format=file_ext,     # e.g. 'tif' or 'fits'
                bit_depth=bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            self.fileLabel.setText(f"Saved 32-bit float HF: {os.path.basename(save_filename)}")


    def loadHF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load High Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                hf, _, _, _ = load_image(selected_file)
                self.high_freq_image = hf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading HF: {str(e)}")

    def loadLF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load Low Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                lf, _, _, _ = load_image(selected_file)
                self.low_freq_image = lf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading LF: {str(e)}")

    def combineHFandLF(self):
        if self.low_freq_image is None or self.high_freq_image is None:
            self.fileLabel.setText("Cannot combine; LF or HF is missing.")
            return

        # Check shape
        if self.low_freq_image.shape != self.high_freq_image.shape:
            self.fileLabel.setText("Error: LF and HF dimensions do not match.")
            return

        # Combine
        combined = self.low_freq_image + self.high_freq_image
        combined = np.clip(combined, 0, 1)  # Ensure values are within [0,1]

        # Retrieve the active mask
        mask = self.get_active_mask()

        if mask is not None:
            # If combined image is multi-channel but mask is single-channel, expand mask dimensions
            if combined.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)

            # Ensure mask dimensions match the combined image dimensions
            if mask.shape[:2] != combined.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the combined image dimensions.")
                return

            # Blend the combined image with the original image using the mask
            # Formula: blended_combined = combined * mask + original_image * (1 - mask)
            blended_combined = combined * mask + self.image * (1 - mask)
            blended_combined = np.clip(blended_combined, 0.0, 1.0)  # Ensure values are within [0,1]
            print("Combined image with mask applied.")
        else:
            # No mask applied; use the combined image directly
            blended_combined = combined
            print("Combined image without mask.")

        # Create a new preview window (non-modal) with the blended combined image
        self.combined_window = CombinedPreviewWindow(
            blended_combined, 
            image_manager=self.image_manager,
            original_header=self.original_header,
            is_mono=self.is_mono
        )
        # Show it. Because we use `show()`, it won't block the main UI
        self.combined_window.show()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Combined image with mask applied.")
        else:
            self.fileLabel.setText("Combined image without mask.")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    # -----------------------------
    # Applying Frequency Separation (background thread)
    # -----------------------------
    def apply_frequency_separation(self):
        if self.image is None:
            self.fileLabel.setText("No input image loaded.")
            return

        self.showSpinner()

        if self.processing_thread and self.processing_thread.isRunning():
            self.processing_thread.quit()
            self.processing_thread.wait()

        # pass in 'tolerance' too
        self.processing_thread = FrequencySeperationThread(
            image=self.image,
            method=self.method,
            radius=self.radius,
            tolerance=self.tolerance
        )
        self.processing_thread.separation_done.connect(self.onSeparationDone)
        self.processing_thread.error_signal.connect(self.onSeparationError)
        self.processing_thread.start()

    def onSeparationDone(self, lf, hf):
        self.hideSpinner()
        self.low_freq_image = lf
        self.high_freq_image = hf
        self.update_previews()

    def onSeparationError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"Error during separation: {msg}")

    # -----------------------------
    # Spinner control
    # -----------------------------
    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # -----------------------------
    # Preview
    # -----------------------------
    def update_previews(self):
        """
        Render HF/LF images with current zoom_factor.
        HF gets an offset of +0.5 for display.
        """
        # Low Frequency
        if self.low_freq_image is not None:
            lf_disp = np.clip(self.low_freq_image, 0, 1)
            pixmap_lf = self._numpy_to_qpixmap(lf_disp)
            # Scale by zoom_factor (cast to int)
            scaled_lf = pixmap_lf.scaled(
                int(pixmap_lf.width() * self.zoom_factor),
                int(pixmap_lf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelLF.setPixmap(scaled_lf)
            self.labelLF.resize(scaled_lf.size())
        else:
            self.labelLF.setText("Low Frequency")
            self.labelLF.resize(self.labelLF.sizeHint())

        # High Frequency
        if self.high_freq_image is not None:
            hf_disp = self.high_freq_image + 0.5
            hf_disp = np.clip(hf_disp, 0, 1)
            pixmap_hf = self._numpy_to_qpixmap(hf_disp)
            scaled_hf = pixmap_hf.scaled(
                int(pixmap_hf.width() * self.zoom_factor),
                int(pixmap_hf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelHF.setPixmap(scaled_hf)
            self.labelHF.resize(scaled_hf.size())
        else:
            self.labelHF.setText("High Frequency")
            self.labelHF.resize(self.labelHF.sizeHint())

    def _numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to a QPixmap for display.
        """
        if img_float32.ndim == 2:
            img_float32 = np.stack([img_float32]*3, axis=-1)

        img_ubyte = (img_float32 * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_img = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_img)

class CombinedPreviewWindow(QWidget):
    """
    A pop-out window that shows the combined HF+LF image in a scrollable, zoomable preview.
    """
    def __init__(self, combined_image, image_manager, original_header=None, is_mono=False, parent=None):
        """
        :param combined_image: Float32 numpy array in [0,1], shape = (H,W) or (H,W,3).
        :param original_header: Optional metadata (for saving as FITS, etc.).
        :param is_mono: Boolean indicating grayscale vs. color.
        """
        super().__init__(parent)
        self.setWindowTitle("Combined HF + LF Preview")
        self.combined_image = combined_image
        self.image_manager = image_manager  # Reference to ImageManage
        self.original_header = original_header
        self.is_mono = is_mono

        # Zoom/panning
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        self.initUI()
        # Render the combined image initially
        self.updatePreview()

    def initUI(self):
        main_layout = QVBoxLayout(self)
        self.setLayout(main_layout)

        # --- Top: Zoom / Fit / Save Buttons ---
        top_btn_layout = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In", self)
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        top_btn_layout.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out", self)
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        top_btn_layout.addWidget(self.zoom_out_btn)

        self.fit_btn = QPushButton("Fit to Preview", self)
        self.fit_btn.clicked.connect(self.fit_to_preview)
        top_btn_layout.addWidget(self.fit_btn)

        # New "Apply Changes" button
        self.apply_btn = QPushButton("Apply Changes/Push for Processing", self)
        self.apply_btn.clicked.connect(self.apply_changes)
        top_btn_layout.addWidget(self.apply_btn)

        main_layout.addLayout(top_btn_layout)

        # --- Scroll Area with a QLabel for image ---
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(False)
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Put the label inside the scroll area
        self.scrollArea.setWidget(self.imageLabel)
        main_layout.addWidget(self.scrollArea)

        # Enable mouse-drag panning
        self.scrollArea.viewport().installEventFilter(self)

        # Provide a decent default window size
        self.resize(1000, 600)

    def eventFilter(self, source, event):
        if source == self.scrollArea.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()
                # Adjust scrollbars
                self.scrollArea.horizontalScrollBar().setValue(
                    self.scrollArea.horizontalScrollBar().value() - delta.x()
                )
                self.scrollArea.verticalScrollBar().setValue(
                    self.scrollArea.verticalScrollBar().value() - delta.y()
                )
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def updatePreview(self):
        """
        Render the combined image into self.imageLabel at the current zoom_factor.
        """
        if self.combined_image is None:
            self.imageLabel.setText("No combined image.")
            return

        # Convert float32 [0,1] -> QPixmap
        pixmap = self.numpy_to_qpixmap(self.combined_image)
        # Scale by zoom_factor
        new_width = int(pixmap.width() * self.zoom_factor)
        new_height = int(pixmap.height() * self.zoom_factor)
        scaled = pixmap.scaled(new_width, new_height, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Update label
        self.imageLabel.setPixmap(scaled)
        self.imageLabel.resize(scaled.size())

    def numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to QPixmap.
        """
        if img_float32.ndim == 2:
            # grayscale
            img_float32 = np.stack([img_float32]*3, axis=-1)
        img_ubyte = (np.clip(img_float32, 0, 1) * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_image = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_image)

    # -----------------------------
    # Zoom
    # -----------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.updatePreview()

    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.updatePreview()

    def fit_to_preview(self):
        """
        Adjust zoom_factor so the combined image width fits in the scrollArea width.
        """
        if self.combined_image is None:
            return

        # Get the actual image size
        h, w = self.combined_image.shape[:2]
        # The scrollArea's viewport is how much space we have to show it
        viewport_width = self.scrollArea.viewport().width()

        # Estimate new zoom factor so image fits horizontally
        # (You could also consider fitting by height or whichever is smaller.)
        # Must convert w from image to display pixel scale.
        # We'll guess the "base" is 1.0 => original width => we guess that is w pixels wide
        # So new_zoom = viewport_width / (w in original scale).
        new_zoom = viewport_width / float(w)
        if new_zoom < 0.01:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.updatePreview()

    def apply_changes(self):
        """
        Push the combined image to ImageManager's slot 0 for further processing.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "No Image", "There is no combined image to apply.")
            return

        # Metadata for the combined image
        metadata = {
            'file_path': "Combined HF+LF Applied",
            'original_header': self.original_header,
            'is_mono': self.is_mono,
            'bit_depth': "32-bit floating point"
        }

        # Push the combined image to slot 0
        self.image_manager.set_image(self.combined_image, metadata)
        QMessageBox.information(self, "Changes Applied", "The combined image has been pushed to slot 0 for processing.")

        # Close the preview window (optional)
        self.close()       

class HFEnhancementThread(QThread):
    """
    A QThread that can:
      1) Scale HF by 'sharpen_scale' (if enabled)
      2) Wavelet-sharpen HF (if enabled)
      3) Denoise HF (if enabled)
    """
    enhancement_done = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(
        self, 
        hf_image, 
        enable_scale=True,
        sharpen_scale=1.0, 
        enable_wavelet=True,
        wavelet_level=2, 
        wavelet_boost=1.2, 
        wavelet_name='db2',
        enable_denoise=False,
        denoise_strength=3.0,
        parent=None
    ):
        super().__init__(parent)
        self.hf_image = hf_image
        self.enable_scale = enable_scale
        self.sharpen_scale = sharpen_scale
        self.enable_wavelet = enable_wavelet
        self.wavelet_level = wavelet_level
        self.wavelet_boost = wavelet_boost
        self.wavelet_name = wavelet_name
        self.enable_denoise = enable_denoise
        self.denoise_strength = denoise_strength

    def run(self):
        try:
            # Make a copy so we don't mutate the original
            enhanced_hf = self.hf_image.copy()

            # 1) Sharpen Scale
            if self.enable_scale:
                enhanced_hf *= self.sharpen_scale

            # 2) Wavelet Sharpen
            if self.enable_wavelet:
                enhanced_hf = self.wavelet_sharpen(
                    enhanced_hf,
                    wavelet=self.wavelet_name,
                    level=self.wavelet_level,
                    boost=self.wavelet_boost
                )

            # 3) Denoise
            if self.enable_denoise:
                enhanced_hf = self.denoise_hf(enhanced_hf, self.denoise_strength)

            self.enhancement_done.emit(enhanced_hf.astype(np.float32))
        except Exception as e:
            self.error_signal.emit(str(e))

    # -------------------------------------
    # Wavelet Sharpen Methods
    # -------------------------------------
    def wavelet_sharpen(self, hf, wavelet='db2', level=2, boost=1.2):
        """
        Apply wavelet sharpening to the HF image.
        Handles both color and monochrome images.
        """
        # Check if the image is color or mono
        if hf.ndim == 3 and hf.shape[2] == 3:
            # Color image: process each channel separately
            channels = []
            for c in range(3):
                c_data = hf[..., c]
                c_sharp = self.wavelet_sharpen_mono(c_data, wavelet, level, boost)
                channels.append(c_sharp)
            # Stack the channels back into a color image
            return np.stack(channels, axis=-1)
        else:
            # Monochrome image
            return self.wavelet_sharpen_mono(hf, wavelet, level, boost)

    def wavelet_sharpen_mono(self, mono_hf, wavelet, level, boost):
        """
        Apply wavelet sharpening to a single-channel (monochrome) HF image.
        Ensures that the output image has the same dimensions as the input.
        """
        # Perform wavelet decomposition with 'periodization' mode to preserve dimensions
        coeffs = pywt.wavedec2(mono_hf, wavelet=wavelet, level=level, mode='periodization')

        # Boost the detail coefficients
        new_coeffs = [coeffs[0]]  # Approximation coefficients remain unchanged
        for detail in coeffs[1:]:
            cH, cV, cD = detail
            cH *= boost
            cV *= boost
            cD *= boost
            new_coeffs.append((cH, cV, cD))

        # Reconstruct the image with 'periodization' mode
        result = pywt.waverec2(new_coeffs, wavelet=wavelet, mode='periodization')

        # Ensure the reconstructed image has the same shape as the original
        original_shape = mono_hf.shape
        reconstructed_shape = result.shape

        if reconstructed_shape != original_shape:
            # Calculate the difference in dimensions                                            
            delta_h = reconstructed_shape[0] - original_shape[0]
            delta_w = reconstructed_shape[1] - original_shape[1]

            # Crop the excess pixels if the reconstructed image is larger
            if delta_h > 0 or delta_w > 0:
                result = result[:original_shape[0], :original_shape[1]]
            # Pad the image with zeros if it's smaller (rare, but for robustness)
            elif delta_h < 0 or delta_w < 0:
                pad_h = max(-delta_h, 0)
                pad_w = max(-delta_w, 0)
                result = np.pad(result, 
                               ((0, pad_h), (0, pad_w)), 
                               mode='constant', 
                               constant_values=0)

        return result

    # -------------------------------------
    # Denoise HF
    # -------------------------------------
    def denoise_hf(self, hf, strength=3.0):
        """
        Use OpenCV's fastNlMeansDenoisingColored or fastNlMeansDenoising for HF.
        Because HF can be negative, we offset +0.5 -> [0..1], scale -> [0..255].
        """
        # If color
        if hf.ndim == 3 and hf.shape[2] == 3:
            bgr = cv2.cvtColor(hf, cv2.COLOR_RGB2BGR)
            tmp = np.clip(bgr + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            # fastNlMeansDenoisingColored(src, None, hColor, hLuminance, templateWindowSize, searchWindowSize)
            denoised8 = cv2.fastNlMeansDenoisingColored(tmp8, None, strength, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            denoised_rgb = cv2.cvtColor(denoised_f32, cv2.COLOR_BGR2RGB)
            return denoised_rgb
        else:
            # Mono
            tmp = np.clip(hf + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            denoised8 = cv2.fastNlMeansDenoising(tmp8, None, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            return denoised_f32

class FrequencySeperationThread(QThread):
    """
    A QThread that performs frequency separation on a float32 [0,1] image array.
    This keeps the GUI responsive while processing.

    Signals:
        separation_done(np.ndarray, np.ndarray):
            Emitted with (low_freq, high_freq) images when finished.
        error_signal(str):
            Emitted if an error or exception occurs.
    """

    # Signal emitted when separation is complete. 
    # The arguments are low-frequency (LF) and high-frequency (HF) images.
    separation_done = pyqtSignal(np.ndarray, np.ndarray)

    # Signal emitted if there's an error during processing
    error_signal = pyqtSignal(str)

    def __init__(self, image, method='Gaussian', radius=5, tolerance=50, parent=None):
        """
        :param image: Float32 NumPy array in [0,1], shape = (H,W) or (H,W,3).
        :param method: 'Gaussian', 'Median', or 'Bilateral' (default: 'Gaussian').
        :param radius: Numeric value controlling the filter's strength (e.g., Gaussian sigma).
        :param mirror: Boolean to indicate if border handling is mirrored (optional example param).
        """
        super().__init__(parent)
        self.image = image
        self.method = method
        self.radius = radius
        self.tolerance = tolerance

    def run(self):
        try:
            # Convert the input image from RGB to BGR if it's 3-channel
            if self.image.ndim == 3 and self.image.shape[2] == 3:
                bgr = cv2.cvtColor(self.image, cv2.COLOR_RGB2BGR)
            else:
                # If mono, just use it as is
                bgr = self.image.copy()

            # Choose the filter based on self.method
            if self.method == 'Gaussian':
                # For Gaussian, interpret radius as sigma
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)
            elif self.method == 'Median':
                # For Median, the radius is the kernel size (must be odd)
                ksize = max(1, int(self.radius) // 2 * 2 + 1)
                low_bgr = cv2.medianBlur(bgr, ksize)
            elif self.method == 'Bilateral':
                # Example usage: interpret "tolerance" as a fraction of the default 50
                # so if tolerance=50 => sigmaColor=50*(50/100)=25, sigmaSpace=25
                # Or do your own logic for how tolerance modifies Bilateral
                sigma = 50 * (self.tolerance / 100.0)
                d = int(self.radius)
                low_bgr = cv2.bilateralFilter(bgr, d, sigma, sigma)
            else:
                # Fallback to Gaussian if unknown
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)

            # Convert low frequency image back to RGB if it's 3-channel
            if low_bgr.ndim == 3 and low_bgr.shape[2] == 3:
                low_rgb = cv2.cvtColor(low_bgr, cv2.COLOR_BGR2RGB)
            else:
                low_rgb = low_bgr

            # Calculate the high frequency
            # (note: keep in float32 to preserve negative/positive values)
            high_rgb = self.image - low_rgb

            # Emit the results
            self.separation_done.emit(low_rgb, high_rgb)

        except Exception as e:
            # Any error gets reported via the error_signal
            self.error_signal.emit(str(e))



class PalettePickerProcessingThread(QThread):
    """
    Thread for processing images to prevent UI freezing.
    """
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image, oiii_image, sii_image, osc1_image, osc2_image, ha_to_oii_ratio, enable_star_stretch, stretch_factor):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc1_image = osc1_image  # Added for OSC1
        self.osc2_image = osc2_image  # Added for OSC2
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        """
        Perform image processing to generate a combined preview.
        """
        try:
            combined_ha = self.ha_image.copy() if self.ha_image is not None else None
            combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None

            # Process OSC1 if available
            if self.osc1_image is not None:
                # Extract synthetic Ha and OIII from OSC1
                ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
                oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc1 = stretch_mono_image(ha_osc1, target_median=self.stretch_factor)
                    oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
                else:
                    combined_ha = ha_osc1

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
                else:
                    combined_oiii = oiii_osc1

            # Process OSC2 if available
            if self.osc2_image is not None:
                # Extract synthetic Ha and OIII from OSC2
                ha_osc2 = self.osc2_image[:, :, 0]  # Red channel -> Ha
                oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc2 = stretch_mono_image(ha_osc2, target_median=self.stretch_factor)
                    oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc2 * 0.5)
                else:
                    combined_ha = ha_osc2

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
                else:
                    combined_oiii = oiii_osc2

            # Ensure that combined Ha and OIII are present
            if combined_ha is not None and combined_oiii is not None:
                # Combine Ha and OIII based on the specified ratio
                combined = (combined_ha * self.ha_to_oii_ratio) + (combined_oiii * (1 - self.ha_to_oii_ratio))

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    combined = stretch_mono_image(combined, target_median=self.stretch_factor)

                # Incorporate SII channel if available
                if self.sii_image is not None:
                    combined = combined + self.sii_image
                    # Normalize to prevent overflow
                    combined = self.normalize_image(combined)

                self.preview_generated.emit(combined)
            else:
                # If required channels are missing, emit a dummy image or handle accordingly
                combined = np.zeros((100, 100, 3))  # Dummy image
                self.preview_generated.emit(combined)
        except Exception as e:
            print(f"Error in PalettePickerProcessingThread: {e}")
            self.preview_generated.emit(None)

    @staticmethod
    def normalize_image(image):
        return image


class PerfectPalettePickerTab(QWidget):
    """
    Perfect Palette Picker Tab for Seti Astro Suite.
    Creates 12 popular NB palettes from Ha/OIII/SII or OSC channels.
    """
    def __init__(self, image_manager=None, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc1_image = None  # Added for OSC1
        self.osc2_image = None  # Added for OSC2
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc1_filename = None  # Added for OSC1
        self.osc2_filename = None  # Added for OSC2      
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"
        self.dragging = False
        self.last_mouse_position = None
        self.selected_palette_button = None
        self.selected_palette = None  # To track the currently selected palette
        
        # Preview scale factor
        self.preview_scale = 1  # Start at no scaling

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            # self.image_manager.image_changed.connect(self.on_image_changed)
            pass

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(300)

        # Title label
        title_label = QLabel("Perfect Palette Picker", self)
        title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        title_label.setFont(QFont("Helvetica", 14, QFont.Weight.Bold))
        left_layout.addWidget(title_label)

        # Instruction label
        instruction_label = QLabel(self)
        instruction_label.setText(
            "Instructions:\n"
            "1. Add narrowband images or an OSC camera image.\n"
            "2. Check the 'Linear Input Data' checkbox if the images are linear.\n"
            "3. Click 'Create Palettes' to generate the palettes.\n"
            "4. Use the Zoom buttons to zoom in and out.\n"
            "5. Resize the UI by dragging the lower right corner.\n"
            "6. Click on a palette from the preview selection to generate that palette.\n\n"
            "Multiple palettes can be generated."
        )
        instruction_label.setWordWrap(True)
        instruction_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        instruction_label.setStyleSheet(
            "font-size: 8pt; padding: 10px;"
        )
        instruction_label.setFixedHeight(200)
        left_layout.addWidget(instruction_label)

        # "Linear Input Data" checkbox
        self.linear_checkbox = QCheckBox("Linear Input Data", self)
        self.linear_checkbox.setChecked(True)
        self.linear_checkbox.setToolTip(
            "When checked, we apply the 0.25 stretch for previews/final images."
        )
        left_layout.addWidget(self.linear_checkbox)

        # Load buttons for Ha, OIII, SII, OSC
        self.load_ha_button = QPushButton("Load Ha Image", self)
        self.load_ha_button.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.load_ha_button)

        self.ha_label = QLabel("No Ha image loaded.", self)
        self.ha_label.setWordWrap(True)
        left_layout.addWidget(self.ha_label)

        self.load_oiii_button = QPushButton("Load OIII Image", self)
        self.load_oiii_button.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.load_oiii_button)

        self.oiii_label = QLabel("No OIII image loaded.", self)
        self.oiii_label.setWordWrap(True)
        left_layout.addWidget(self.oiii_label)

        self.load_sii_button = QPushButton("Load SII Image", self)
        self.load_sii_button.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.load_sii_button)

        self.sii_label = QLabel("No SII image loaded.", self)
        self.sii_label.setWordWrap(True)
        left_layout.addWidget(self.sii_label)

        # **Add OSC1 Load Button and Label**
        self.load_osc1_button = QPushButton("Load OSC HaO3 Image", self)
        self.load_osc1_button.clicked.connect(lambda: self.load_image('OSC1'))
        left_layout.addWidget(self.load_osc1_button)

        self.osc1_label = QLabel("No OSC HaO3 image loaded.", self)
        self.osc1_label.setWordWrap(True)
        left_layout.addWidget(self.osc1_label)

        # **Add OSC2 Load Button and Label**
        self.load_osc2_button = QPushButton("Load OSC S2O3 Image", self)
        self.load_osc2_button.clicked.connect(lambda: self.load_image('OSC2'))
        left_layout.addWidget(self.load_osc2_button)

        self.osc2_label = QLabel("No OSC S2O3 image loaded.", self)
        self.osc2_label.setWordWrap(True)
        left_layout.addWidget(self.osc2_label)

        # "Create Palettes" button
        create_palettes_button = QPushButton("Create Palettes", self)
        create_palettes_button.clicked.connect(self.prepare_preview_palettes)
        left_layout.addWidget(create_palettes_button)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        self.push_palette_button = QPushButton("Push Final Palette for Further Processing")
        self.push_palette_button.clicked.connect(self.push_final_palette_to_image_manager)
        left_layout.addWidget(self.push_palette_button)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add a "Clear All Images" button
        self.clear_all_button = QPushButton("Clear All Images", self)
        self.clear_all_button.clicked.connect(self.clear_all_images)
        left_layout.addWidget(self.clear_all_button)


        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setFont(QFont("Helvetica", 8))
        left_layout.addWidget(footer_label)

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # Right column for previews and controls
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In", self)
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out", self)
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        fit_to_preview_button = QPushButton("Fit to Preview", self)
        fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(fit_to_preview_button)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.installEventFilter(self)
        self.image_label.setMouseTracking(True)

        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setMinimumSize(400, 250)
        right_layout.addWidget(self.scroll_area, stretch=1)


        # Preview thumbnails grid
        self.thumbs_grid = QGridLayout()
        self.palette_names = [
            "SHO", "HOO", "HSO", "HOS",
            "OSS", "OHH", "OSH", "OHS",
            "HSS", "Realistic1", "Realistic2", "Foraxx"
        ]
        self.thumbnail_buttons = []
        row = 0
        col = 0

        for palette in self.palette_names:
            button = QPushButton(palette, self)
            button.setMinimumSize(200, 100)  # Minimum size for buttons
            button.setMaximumHeight(100)  # Fixed height for buttons
            button.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)  # Expand width, fixed height
            button.setIcon(QIcon())  # Placeholder, will be set later
            button.clicked.connect(lambda checked, p=palette: self.generate_final_palette_image(p))
            button.setIconSize(QSize(200, 100))
            button.setIcon(QIcon())  # Placeholder, will be set later
            self.thumbnail_buttons.append(button)
            self.thumbs_grid.addWidget(button, row, col)
            col += 1
            if col >= 4:
                col = 0
                row += 1

        # Wrap the grid in a QWidget for better layout handling
        thumbs_widget = QWidget()
        thumbs_widget.setLayout(self.thumbs_grid)
        thumbs_widget.setSizePolicy(QSizePolicy.Policy.Preferred, QSizePolicy.Policy.Fixed)

        # Add the thumbnails widget to the layout
        right_layout.addWidget(thumbs_widget, stretch=0)


        # Status label
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        right_layout.addWidget(self.status_label)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.setWindowTitle("Perfect Palette Picker v1.0")

    def clear_all_images(self):
        """
        Clears all loaded images (Ha, OIII, SII, OSC1, OSC2).
        """
        # Clear Ha image and reset filename and label
        self.ha_image = None
        self.ha_filename = None
        self.ha_label.setText("No Ha image loaded.")

        # Clear OIII image and reset filename and label
        self.oiii_image = None
        self.oiii_filename = None
        self.oiii_label.setText("No OIII image loaded.")

        # Clear SII image and reset filename and label
        self.sii_image = None
        self.sii_filename = None
        self.sii_label.setText("No SII image loaded.")

        # Clear OSC1 image and reset filename and label
        self.osc1_image = None
        self.osc1_filename = None
        self.osc1_label.setText("No OSC HaO3 image loaded.")

        # Clear OSC2 image and reset filename and label
        self.osc2_image = None
        self.osc2_filename = None
        self.osc2_label.setText("No OSC S2O3 image loaded.")

        # Clean up preview windows
        self.cleanup_preview_windows()        

        # Update the status label
        self.status_label.setText("All images cleared.")


    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.
        
        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC1', 'OSC2').
        """
        try:
            print(f"Initiating load process for {image_type} image.")
            
            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From File", "From Slot"],
                editable=False
            )
            
            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return
            
            print(f"{image_type} image source selected: {source_choice}")
            
            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return
            
            if result is None:
                # Loading was unsuccessful or cancelled
                return
            
            image, original_header, bit_depth, is_mono, file_path = result
            
            # 🔹 **NEW: Check if grayscale is stored in 3 channels and extract the first channel**
            if image.ndim == 3 and np.all(image[:, :, 0] == image[:, :, 1]) and np.all(image[:, :, 0] == image[:, :, 2]):
                print(f"{image_type} is stored as a 3-channel grayscale image. Extracting the first channel.")
                image = image[:, :, 0]  # Convert to single-channel grayscale

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.ha_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.sii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC1':
                self.osc1_image = image
                self.osc1_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc1_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC2':
                self.osc2_image = image
                self.osc2_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc2_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return
            
            # Apply stretching if linear input is checked
            if self.linear_checkbox.isChecked():
                if is_mono:
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha':
                        self.ha_image = stretch_func(self.ha_image, target_median=0.25)
                    elif image_type == 'OIII':
                        self.oiii_image = stretch_func(self.oiii_image, target_median=0.25)
                    elif image_type == 'SII':
                        self.sii_image = stretch_func(self.sii_image, target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Assuming OSC has multiple channels; stretching would be handled during processing
                        pass
                else:
                    # For multi-channel images, apply stretching to the first channel
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha' and self.ha_image is not None and self.ha_image.ndim == 3:
                        self.ha_image[:, :, 0] = stretch_func(self.ha_image[:, :, 0], target_median=0.25)
                    elif image_type == 'OIII' and self.oiii_image is not None and self.oiii_image.ndim == 3:
                        self.oiii_image[:, :, 0] = stretch_func(self.oiii_image[:, :, 0], target_median=0.25)
                    elif image_type == 'SII' and self.sii_image is not None and self.sii_image.ndim == 3:
                        self.sii_image[:, :, 0] = stretch_func(self.sii_image[:, :, 0], target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Handle stretching for OSC images if necessary
                        pass
        
        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_slot(self, image_type):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            print("ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Build the list using the parent's slot_names dictionary.
        available_slots = []
        # Access parent's slot_names dictionary.
        slot_names = self.parent_window.slot_names if self.parent_window else {}
        for i in range(self.image_manager.max_slots):
            slot_name = slot_names.get(i, f"Slot {i+1}")
            available_slots.append(slot_name)

        slot_choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type} Image",
            "Choose a slot:",
            available_slots,
            editable=False
        )

        if not ok or not slot_choice:
            QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
            print(f"{image_type} image loading cancelled by the user.")
            return None

        # Find the slot index that matches the chosen display name.
        target_slot_num = None
        for i in range(self.image_manager.max_slots):
            current_name = slot_names.get(i, f"Slot {i+1}")
            if current_name == slot_choice:
                target_slot_num = i
                break

        if target_slot_num is None:
            QMessageBox.critical(self, "Error", f"Invalid slot selection: {slot_choice}")
            print(f"Error: Could not map slot name '{slot_choice}' to a slot number.")
            return None

        image = self.image_manager._images.get(target_slot_num, None)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{slot_choice} does not contain an image.")
            print(f"{slot_choice} is empty. Cannot load {image_type} image.")
            return None

        print(f"{image_type} image selected from {slot_choice}.")

        # Retrieve metadata.
        metadata = self.image_manager._metadata.get(target_slot_num, {})
        original_header = metadata.get('header', None)
        bit_depth = metadata.get('bit_depth', "Unknown")
        is_mono = metadata.get('is_mono', False)
        file_path = metadata.get('file_path', None)

        return image, original_header, bit_depth, is_mono, file_path




    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.
        
        Parameters:
            image_type (str): The type of image to load.
        
        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """


        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter

        )
        
        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None
        
        print(f"{image_type} image file selected: {file_path}")
        
        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None
        
        return image, original_header, bit_depth, is_mono, file_path

    def get_image_shape(self, image):
        """Returns the shape of the image or None if not set."""
        return image.shape if image is not None else None


    def prepare_preview_palettes(self):
        """
        
        Prepares the preview thumbnails for each palette based on selected images.
        """
        have_ha = self.ha_image is not None
        have_oiii = self.oiii_image is not None
        have_sii = self.sii_image is not None
        have_osc1 = self.osc1_image is not None
        have_osc2 = self.osc2_image is not None

        print(f"prepare_preview_palettes() => Ha: {have_ha} | OIII: {have_oiii} | SII: {have_sii} | OSC1: {have_osc1} | OSC2: {have_osc2}")


        # 🔹 **NEW: Check for image size mismatches**
        image_shapes = {
            'Ha': self.get_image_shape(self.ha_image),
            'OIII': self.get_image_shape(self.oiii_image),
            'SII': self.get_image_shape(self.sii_image),
            'OSC1': self.get_image_shape(self.osc1_image),
            'OSC2': self.get_image_shape(self.osc2_image),
        }

        # Filter out None values (only check actual loaded images)
        valid_shapes = {k: v for k, v in image_shapes.items() if v is not None}

        # If different shapes are found, show an error and return
        if len(set(valid_shapes.values())) > 1:
            QMessageBox.critical(
                self,
                "Image Size Mismatch",
                f"Error: The selected images have mismatched dimensions!\n\n"
                f"{valid_shapes}"
            )
            self.status_label.setText("Error: Image sizes must match.")
            print(f"[ERROR] Image size mismatch: {valid_shapes}")
            return

        # Initialize combined channels
        combined_ha = self.ha_image.copy() if self.ha_image is not None else None
        combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None
        combined_sii = self.sii_image.copy() if self.sii_image is not None else None  # Initialize combined SII

        # Process OSC1 if available
        if have_osc1:
            # Extract synthetic Ha and OIII from OSC1
            ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
            oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                ha_osc1 = stretch_mono_image(ha_osc1, target_median=0.25)
                oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=0.25)

            # Combine with existing Ha and OIII
            if combined_ha is not None:
                combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
            else:
                combined_ha = ha_osc1

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
            else:
                combined_oiii = oiii_osc1

        # Process OSC2 if available
        if have_osc2:
            # Extract synthetic SII from OSC2 red channel
            sii_osc2 = self.osc2_image[:, :, 0]  # Red channel -> SII
            oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                sii_osc2 = stretch_mono_image(sii_osc2, target_median=0.25)
                oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=0.25)

            # Combine with existing SII
            if combined_sii is not None:
                combined_sii = (combined_sii * 0.5) + (sii_osc2 * 0.5)
            else:
                combined_sii = sii_osc2

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
            else:
                combined_oiii = oiii_osc2    

        # Assign combined images back to self.ha_image, self.oiii_image, and self.sii_image
        self.ha_image = combined_ha
        self.oiii_image = combined_oiii
        self.sii_image = combined_sii  # Updated SII image

        # Ensure images are single-channel
        def ensure_single_channel(image, image_type):
            if image is not None:
                if image.ndim == 3:
                    if image.shape[2] == 1:
                        image = image[:, :, 0]
                        print(f"Converted {image_type} image to single channel: {image.shape}")
                    else:
                        # If image has multiple channels, retain the first channel
                        image = image[:, :, 0]
                        print(f"Extracted first channel from multi-channel {image_type} image: {image.shape}")
                return image
            return None

        self.ha_image = ensure_single_channel(self.ha_image, 'Ha')
        self.oiii_image = ensure_single_channel(self.oiii_image, 'OIII')
        self.sii_image = ensure_single_channel(self.sii_image, 'SII')

        print(f"Combined Ha image shape: {self.ha_image.shape if self.ha_image is not None else 'None'}")
        print(f"Combined OIII image shape: {self.oiii_image.shape if self.oiii_image is not None else 'None'}")
        print(f"Combined SII image shape: {self.sii_image.shape if self.sii_image is not None else 'None'}")

        # Validate required channels
        # Allow if (Ha and OIII) or (SII and OIII) are present
        if not ((self.ha_image is not None and self.oiii_image is not None) or
                (self.sii_image is not None and self.oiii_image is not None)):
            QMessageBox.warning(
                self,
                "Warning",
                "Please load at least Ha and OIII images or SII and OIII images to create palettes."
            )
            self.status_label.setText("Insufficient images loaded.")
            return

        # Start processing thread to generate previews
        ha_to_oii_ratio = 0.3  # Example ratio; adjust as needed
        enable_star_stretch = self.linear_checkbox.isChecked()
        stretch_factor = 0.25  # Example stretch factor; adjust as needed

        self.processing_thread = PalettePickerProcessingThread(
            ha_image=self.ha_image,
            oiii_image=self.oiii_image,
            sii_image=self.sii_image,
            osc1_image=None,  # OSC1 is already processed
            osc2_image=None,  # OSC2 is already processed
            ha_to_oii_ratio=ha_to_oii_ratio,
            enable_star_stretch=enable_star_stretch,
            stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.update_preview_thumbnails)
        self.processing_thread.start()

        self.status_label.setText("Generating preview palettes...")



    def update_preview_thumbnails(self, combined_preview):
        """
        Updates the preview thumbnails with the generated combined preview.
        Downsamples the images for efficient processing of mini-previews.
        """
        if combined_preview is None:
            # Only update the text overlays
            for i, palette in enumerate(self.palette_names):
                pixmap = self.thumbnail_buttons[i].icon().pixmap(self.thumbnail_buttons[i].iconSize())
                if pixmap.isNull():
                    print(f"Failed to retrieve pixmap for palette '{palette}'. Skipping.")
                    continue
                text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white
                painter = QPainter(pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()
                self.thumbnail_buttons[i].setIcon(QIcon(pixmap))
                QApplication.processEvents()

            return

        def downsample_image(image, factor=8):
            """
            Downsample the image by an integer factor using cv2.resize.
            """
            if image is not None:
                height, width = image.shape[:2]
                new_size = (max(1, width // factor), max(1, height // factor))  # Ensure size is at least 1x1
                return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
            return image

        # Downsample images
        ha = downsample_image(self.ha_image)
        oiii = downsample_image(self.oiii_image)
        sii = downsample_image(self.sii_image)

        # Helper function to extract single channel
        def extract_channel(image):
            return image if image is not None and image.ndim == 2 else (image[:, :, 0] if image is not None else None)

        # Helper function for channel substitution
        def get_channel(preferred, substitute):
            return preferred if preferred is not None else substitute

        for i, palette in enumerate(self.palette_names):
            text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white

            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None

            # Define substitution channels
            substituted_ha = sii if not ha_available and sii_available else ha
            substituted_sii = ha if not sii_available and ha_available else sii

            # Map channels based on palette
            if palette == "SHO":
                r = get_channel(extract_channel(sii), substituted_ha)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = extract_channel(oiii)
            elif palette == "HOO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = extract_channel(oiii)
            elif palette == "HSO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = extract_channel(oiii)
            elif palette == "HOS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OSS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OHH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OSH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OHS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "HSS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette in ["Realistic1", "Realistic2", "Foraxx"]:
                r, g, b = self.map_special_palettes(palette, ha, oiii, sii)
            else:
                # Fallback to SHO
                r, g, b = self.map_channels("SHO", ha, oiii, sii)

            # Replace NaNs and clip to [0, 1]
            r = np.clip(np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if r is not None else None
            g = np.clip(np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if g is not None else None
            b = np.clip(np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if b is not None else None

            if r is None or g is None or b is None:
                print(f"One of the channels is None for palette '{palette}'. Skipping this palette.")
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)
                continue

            combined = self.combine_channels_to_color([r, g, b], f"Preview_{palette}")
            if combined is not None:
                # Convert NumPy array to QImage
                q_image = self.numpy_to_qimage(combined)
                if q_image.isNull():
                    print(f"Failed to convert preview for palette '{palette}' to QImage.")
                    continue

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    print(f"Failed to create QPixmap for palette '{palette}'.")
                    continue

                # Scale pixmap
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.preview_scale),
                    int(pixmap.height() * self.preview_scale),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Add text overlay
                painter = QPainter(scaled_pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(scaled_pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()

                # Set pixmap to the corresponding button
                self.thumbnail_buttons[i].setIcon(QIcon(scaled_pixmap))
                self.thumbnail_buttons[i].setIconSize(scaled_pixmap.size())
                self.thumbnail_buttons[i].setToolTip(f"Palette: {palette}")
                QApplication.processEvents()
            else:
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)

        self.status_label.setText("Preview palettes generated successfully.")





    def generate_final_palette_image(self, palette_name):
        """
        Generates the final combined image for the selected palette.
        Handles substitution of SII for Ha or Ha for SII if one is missing.
        """
        try:
            print(f"Generating final palette image for: {palette_name}")
            
            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None
            
            # Define substitution
            if not ha_available and sii_available:
                # Substitute SII for Ha
                substituted_ha = self.sii_image
                substituted_sii = None
                print("Substituting SII for Ha.")
            elif not sii_available and ha_available:
                # Substitute Ha for SII
                substituted_sii = self.ha_image
                substituted_ha = None
                print("Substituting Ha for SII.")
            else:
                substituted_ha = self.ha_image
                substituted_sii = self.sii_image
            
            # Temporarily assign substituted channels
            original_ha = self.ha_image
            original_sii = self.sii_image
            
            self.ha_image = substituted_ha
            self.sii_image = substituted_sii
            
            # Combine channels
            combined_image = self.combine_channels(palette_name)
            
            # Restore original channels
            self.ha_image = original_ha
            self.sii_image = original_sii
            
            if combined_image is not None:
                # Ensure the combined image has the correct shape
                if combined_image.ndim == 4 and combined_image.shape[3] == 3:
                    combined_image = combined_image[:, :, :, 0]  # Remove the extra dimension

                # Convert to QImage
                q_image = self.numpy_to_qimage(combined_image)
                if q_image.isNull():
                    raise ValueError(f"Failed to convert combined image for palette '{palette_name}' to QImage.")

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    raise ValueError(f"Failed to create QPixmap for palette '{palette_name}'.")

                # Scale the pixmap based on zoom factor
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.zoom_factor),
                    int(pixmap.height() * self.zoom_factor),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Display the scaled pixmap in the main preview area
                self.image_label.setPixmap(scaled_pixmap)
                self.image_label.resize(scaled_pixmap.size())
                self.combined_image = combined_image
                self.status_label.setText(f"Final palette '{palette_name}' generated successfully.")

                self.selected_palette = palette_name
                self.update_preview_thumbnails(None)  # Trigger re-render with updated text colors

            else:
                raise ValueError(f"Failed to generate combined image for palette '{palette_name}'.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to generate final image: {e}")
            self.status_label.setText(f"Failed to generate palette '{palette_name}'.")
            print(f"[Error] {e}")

    def highlight_selected_button(self, palette_name):
        """
        Highlights the clicked button by changing its text color and resets others.
        """
        for button in self.thumbnail_buttons:
            if button.text() == palette_name:
                # Change text color to indicate selection
                button.setStyleSheet("color: green; font-weight: bold;")
                self.selected_palette_button = button
            else:
                # Reset text color for non-selected buttons
                button.setStyleSheet("")


    def combine_channels(self, palette_name):
        """
        Combines Ha, OIII, SII channels based on the palette name.
        Ensures that all combined channel values are within the [0, 1] range.
        """
        if palette_name in self.palette_names[:9]:  # Standard palettes
            r, g, b = self.map_channels(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        elif palette_name in self.palette_names[9:]:  # Special palettes
            r, g, b = self.map_special_palettes(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        else:
            # Fallback to SHO
            r, g, b = self.map_channels("SHO", self.ha_image, self.oiii_image, self.sii_image)

        if r is not None and g is not None and b is not None:
            # Replace NaN and Inf with 0
            r = np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0)
            g = np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0)
            b = np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0)

            # Normalize to [0,1]
            r = np.clip(r, 0, 1)
            g = np.clip(g, 0, 1)
            b = np.clip(b, 0, 1)

            # Ensure single-channel
            if r.ndim == 3:
                r = r[:, :, 0]
            if g.ndim == 3:
                g = g[:, :, 0]
            if b.ndim == 3:
                b = b[:, :, 0]

            combined = np.stack([r, g, b], axis=2)
            return combined
        else:
            return None


    def combine_channels_to_color(self, channels, output_id):
        """
        Combines three grayscale images into an RGB image.
        Ensures that all channels are consistent and have no extra dimensions.
        """
        try:
            # Validate input channels
            if len(channels) != 3:
                raise ValueError(f"Expected 3 channels, got {len(channels)}")
            
            # Ensure all channels have the same shape
            for i, channel in enumerate(channels):
                if channel is None:
                    raise ValueError(f"Channel {i} is None.")
                if channel.shape != channels[0].shape:
                    raise ValueError(f"Channel {i} has shape {channel.shape}, expected {channels[0].shape}")
            
            # Ensure all channels are 2D
            channels = [channel[:, :, 0] if channel.ndim == 3 else channel for channel in channels]
            
            # Debugging: Print channel shapes after extraction
            for idx, channel in enumerate(channels):
                print(f"Channel {idx} shape after extraction: {channel.shape}")
            
            # Stack channels along the third axis to create RGB
            rgb_image = np.stack(channels, axis=2)
            print(f"Combined RGB image shape: {rgb_image.shape}")
            return rgb_image
        except Exception as e:
            print(f"Error in combine_channels_to_color: {e}")
            return None

    def map_channels(self, palette_name, ha, oiii, sii):
        """
        Maps the Ha, OIII, SII channels based on the palette name.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        # Substitute SII for Ha if Ha is missing
        if ha is None and sii is not None:
            ha = sii
            print("Ha is missing. Substituting SII for Ha.")
        
        # Substitute Ha for SII if SII is missing
        if sii is None and ha is not None:
            sii = ha
            print("SII is missing. Substituting Ha for SII.")
        
        # Define the channel mappings
        mapping = {
            "SHO": [sii, ha, oiii],
            "HOO": [ha, oiii, oiii],
            "HSO": [ha, sii, oiii],
            "HOS": [ha, oiii, sii],
            "OSS": [oiii, sii, sii],
            "OHH": [oiii, ha, ha],
            "OSH": [oiii, sii, ha],
            "OHS": [oiii, ha, sii],
            "HSS": [ha, sii, sii],
        }
        
        # Retrieve the mapped channels based on the palette name
        mapped_channels = mapping.get(palette_name, [ha, oiii, sii])
             
        return mapped_channels


    def map_special_palettes(self, palette_name, ha, oiii, sii):
        """
        Maps channels for special palettes like Realistic1, Realistic2, Foraxx.
        Ensures all expressions produce values within the [0, 1] range.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        try:
            # Substitute SII for Ha if Ha is missing
            if ha is None and sii is not None:
                ha = sii
                print("Ha is missing in special palette. Substituting SII for Ha.")
        
            # Substitute Ha for SII if SII is missing
            if sii is None and ha is not None:
                sii = ha
                print("SII is missing in special palette. Substituting Ha for SII.")
        
            # Realistic1 mapping
            if palette_name == "Realistic1":
                expr_r = (ha + sii) / 2 if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * ha) + (0.7 * oiii) if (ha is not None and oiii is not None) else (ha if ha is not None else 0)
                expr_b = (0.9 * oiii) + (0.1 * ha) if (ha is not None and oiii is not None) else (oiii if oiii is not None else 0)
        
            # Realistic2 mapping
            elif palette_name == "Realistic2":
                expr_r = (0.7 * ha + 0.3 * sii) if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * sii + 0.7 * oiii) if (sii is not None and oiii is not None) else (oiii if oiii is not None else 0)
                expr_b = oiii if oiii is not None else 0
        
            # Foraxx mapping
            elif palette_name == "Foraxx":
                if ha is not None and oiii is not None and sii is None:
                    expr_r = ha
                    temp = ha * oiii
                    expr_g = (temp ** (1 - temp)) * ha + (1 - (temp ** (1 - temp))) * oiii
                    expr_b = oiii
                elif ha is not None and oiii is not None and sii is not None:
                    temp = oiii ** (1 - oiii)
                    expr_r = (temp * sii) + ((1 - temp) * ha)
                    temp_ha_oiii = ha * oiii
                    expr_g = (temp_ha_oiii ** (1 - temp_ha_oiii)) * ha + (1 - (temp_ha_oiii ** (1 - temp_ha_oiii))) * oiii
                    expr_b = oiii
                else:
                    # Fallback to SHO
                    return self.map_channels("SHO", ha, oiii, sii)
        
            else:
                # Fallback to SHO for any undefined palette
                return self.map_channels("SHO", ha, oiii, sii)
        
            # Replace invalid values and normalize
            expr_r = np.clip(np.nan_to_num(expr_r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_g = np.clip(np.nan_to_num(expr_g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_b = np.clip(np.nan_to_num(expr_b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
        
            return expr_r, expr_g, expr_b
        except Exception as e:
            print(f"[Error] Failed to map palette {palette_name}: {e}")
            return None, None, None


    def extract_oscc_channels(self, osc_image, base_id):
        """
        Extracts R, G, B channels from the OSC image and assigns unique postfixes.
        
        Parameters:
            osc_image (numpy.ndarray): The OSC image array.
            base_id (str): The base identifier for naming.
        
        Returns:
            list: A list containing the extracted R, G, B channels as NumPy arrays.
        """
        if osc_image is None or osc_image.shape[2] < 3:
            print(f"[!] OSC image {base_id} has fewer than 3 channels—skipping extraction.")
            return []

        # Extract channels
        R = osc_image[:, :, 0]  # Red channel
        G = osc_image[:, :, 1]  # Green channel
        B = osc_image[:, :, 2]  # Blue channel

        # Assign unique postfixes
        R_name = f"{base_id}_pppR"
        G_name = f"{base_id}_pppG"
        B_name = f"{base_id}_pppB"

        # For Seti Astro Suite, we might need to create separate image objects or handle naming differently
        # Here, we'll assume that we can manage the names via dictionaries or similar structures

        # Store the extracted channels with their names
        extracted_channels = {
            R_name: R,
            G_name: G,
            B_name: B
        }

        # Optionally, hide these images in the GUI or manage them as needed
        # For example, you might add them to an internal list for cleanup

        # For demonstration, we'll return the list of channels
        return [R, G, B]




    def numpy_to_qimage(self, image_array):
        """
        Converts a NumPy array to QImage.
        Assumes image_array is in the range [0, 1] and in RGB format.
        """
        try:
            # Validate input shape
            if image_array.ndim == 2:
                # Grayscale image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width = image_uint8.shape
                bytes_per_line = width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
                return q_image.copy()
            elif image_array.ndim == 3 and image_array.shape[2] == 3:
                # RGB image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width, channels = image_uint8.shape
                if channels != 3:
                    raise ValueError(f"Expected 3 channels for RGB, got {channels}")
                bytes_per_line = 3 * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
                return q_image.copy()
            else:
                # Invalid shape
                raise ValueError(f"Invalid image shape for QImage conversion: {image_array.shape}")
        except Exception as e:
            print(f"Error converting NumPy array to QImage: {e}")
            return QImage()



    def save_image(self):
        """
        Save the current combined image to a selected path.
        """
        if self.combined_image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                "",
                "Images (*.png *.tif *.tiff *.fits *.fit);;All Files (*)"
            )

            if save_file:
                # Prompt the user for bit depth
                bit_depth, ok = QInputDialog.getItem(
                    self,
                    "Select Bit Depth",
                    "Choose bit depth for saving:",
                    ["16-bit", "32-bit floating point"],
                    0,
                    False
                )
                if ok:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Ensure correct data ordering for FITS format
                    final_image = self.combined_image
                    if selected_format in ['fits', 'fit']:
                        if self.combined_image.ndim == 3:  # RGB image
                            # Transpose to (channels, height, width)
                            final_image = np.transpose(self.combined_image, (2, 0, 1))
                            print(f"Transposed for FITS: {final_image.shape}")
                        elif self.combined_image.ndim == 2:  # Mono image
                            print(f"Mono image, no transposition needed: {final_image.shape}")
                        else:
                            QMessageBox.critical(
                                self,
                                "Error",
                                "Unsupported image dimensions for FITS saving."
                            )
                            return

                    # Check if any loaded image file paths have the `.xisf` extension
                    loaded_file_paths = [
                        self.ha_filename, self.oiii_filename,
                        self.sii_filename, self.osc1_filename, self.osc2_filename
                    ]
                    contains_xisf = any(
                        file_path.lower().endswith('.xisf') for file_path in loaded_file_paths if file_path
                    )

                    # Create a minimal header if any loaded image is XISF
                    sanitized_header = self.original_header if not contains_xisf else self.create_minimal_fits_header(final_image)

                    # Pass the correctly ordered image to the global save_image function
                    try:
                        save_image(
                            img_array=final_image,
                            filename=save_file,
                            original_format=selected_format,
                            bit_depth=bit_depth,
                            original_header=sanitized_header,  # Pass minimal or original header
                            is_mono=self.is_mono
                        )
                        print(f"Image successfully saved to {save_file}.")
                        self.status_label.setText(f"Image saved to: {save_file}")
                    except Exception as e:
                        QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                        print(f"Error saving image: {e}")
            else:
                self.status_label.setText("Save canceled.")
        else:
            QMessageBox.warning(self, "Warning", "No combined image to save.")
            self.status_label.setText("No combined image to save.")


    def create_minimal_fits_header(self, img_array):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if self.is_mono else 3
        header['NAXIS1'] = self.combined_image.shape[1]  # Image width
        header['NAXIS2'] = self.combined_image.shape[0]  # Image height
        if not self.is_mono:
            header['NAXIS3'] = self.combined_image.shape[2]  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header['COMMENT'] = "Minimal FITS header generated by Perfect Palette Picker."

        return header

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """
        Zooms into the main preview image.
        """
        if self.zoom_factor < 5.0:  # Maximum zoom factor
            self.zoom_factor *= 1.25
            self.update_main_preview()
        else:
            print("Maximum zoom level reached.")
            self.status_label.setText("Maximum zoom level reached.")

    def zoom_out(self):
        """
        Zooms out of the main preview image.
        """
        if self.zoom_factor > 0.2:  # Minimum zoom factor
            self.zoom_factor /= 1.25
            self.update_main_preview()
        else:
            print("Minimum zoom level reached.")
            self.status_label.setText("Minimum zoom level reached.")

    def fit_to_preview(self):
        """
        Fits the main preview image to the scroll area.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            if q_image.isNull():
                QMessageBox.critical(self, "Error", "Cannot fit image to preview due to conversion error.")
                return
            pixmap = QPixmap.fromImage(q_image)
            scroll_area_width = self.scroll_area.viewport().width()
            self.zoom_factor = scroll_area_width / pixmap.width()
            self.update_main_preview()
            self.status_label.setText("Image fitted to preview area.")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")

    def update_main_preview(self):
        """
        Updates the main preview image based on the current zoom factor.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            pixmap = QPixmap.fromImage(q_image)
            if pixmap.isNull():
                QMessageBox.critical(self, "Error", "Failed to update main preview. Invalid QPixmap.")
                return

            # Ensure dimensions are integers
            scaled_width = int(pixmap.width() * self.zoom_factor)
            scaled_height = int(pixmap.height() * self.zoom_factor)

            scaled_pixmap = pixmap.scaled(
                scaled_width,
                scaled_height,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.image_label.setPixmap(scaled_pixmap)
            self.image_label.resize(scaled_pixmap.size())
        else:
            self.image_label.clear()





    def create_palette_preview(self, palette_name):
        """
        Creates a mini-preview image for the given palette.
        Returns the combined RGB image as a NumPy array.
        """
        print(f"Creating mini-preview for palette: {palette_name}")
        combined = self.combine_channels(palette_name)
        return combined

    def push_final_palette_to_image_manager(self):
        """
        Pushes the final combined image to the ImageManager for further processing.
        """
        if self.combined_image is not None:
            # Check if any of the loaded file paths have an XISF extension
            loaded_files = [self.ha_filename, self.oiii_filename, self.sii_filename, self.osc1_filename, self.osc2_filename]
            was_xisf = any(file_path and file_path.lower().endswith('.xisf') for file_path in loaded_files)

            # Generate a minimal FITS header if the original header is missing or if the format was XISF
            sanitized_header = self.original_header
            if was_xisf or sanitized_header is None:
                sanitized_header = None

            # Determine the valid file path:
            # Prioritize Ha, then OSC1, then OSC2
            file_path = None
            if self.ha_image is not None and self.ha_filename:
                file_path = self.ha_filename
                print("Using Ha filename as file_path.")
            elif self.osc1_image is not None and self.osc1_filename:
                file_path = self.osc1_filename
                print("Using OSC1 filename as file_path.")
            elif self.osc2_image is not None and self.osc2_filename:
                file_path = self.osc2_filename
                print("Using OSC2 filename as file_path.")
            else:
                # No valid source file, save combined_image to a temporary file
                try:
                    temp_dir = tempfile.gettempdir()
                    timestamp = int(time.time())
                    temp_file_path = os.path.join(temp_dir, f"combined_image_{timestamp}.tif")
                    
                    # Save the combined image using your existing save_image function
                    save_image(
                        img_array=self.combined_image,
                        filename=temp_file_path,
                        original_format='tif',
                        bit_depth=self.bit_depth,
                        original_header=self.original_header,
                        is_mono=self.is_mono
                    )
                    
                    file_path = temp_file_path
                    print(f"Combined image saved to temporary file: {file_path}")
                except Exception as e:
                    print(f"Failed to save combined image to temporary file: {e}")
                    QMessageBox.critical(
                        self, 
                        "Error", 
                        f"Failed to save combined image to temporary file:\n{e}"
                    )
                    return

            # Create metadata for the combined image
            metadata = {
                'file_path': file_path,
                'original_header': sanitized_header,  # Use the sanitized or minimal header
                'bit_depth': self.bit_depth if hasattr(self, 'bit_depth') else "Unknown",
                'is_mono': False,
                'processing_parameters': {
                    'zoom_factor': self.zoom_factor,
                    'preview_scale': self.preview_scale
                },
                'processing_timestamp': datetime.now().isoformat(),
                'source_images': {
                    'Ha': self.ha_filename if self.ha_image is not None else "Not Provided",
                    'OIII': self.oiii_filename if self.oiii_image is not None else "Not Provided",
                    'SII': self.sii_filename if self.sii_image is not None else "Not Provided",
                    'OSC1': self.osc1_filename if self.osc1_image is not None else "Not Provided",
                    'OSC2': self.osc2_filename if self.osc2_image is not None else "Not Provided"
                }
            }

            # Push the image and metadata into the ImageManager
            if self.image_manager:
                try:
                    self.image_manager.update_image(
                        updated_image=self.combined_image, metadata=metadata
                    )
                    print(f"Image pushed to ImageManager with metadata: {metadata}")
                    self.status_label.setText("Final palette image pushed for further processing.")
                except Exception as e:
                    print(f"Error updating ImageManager: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
            else:
                print("ImageManager is not initialized.")
                QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the combined image.")
        else:
            QMessageBox.warning(self, "Warning", "No final palette image to push.")
            self.status_label.setText("No final palette image to push.")



    def mousePressEvent(self, event):
        """
        Starts dragging when the left mouse button is pressed.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_mouse_position = event.pos()
            self.image_label.setCursor(Qt.CursorShape.ClosedHandCursor)

    def mouseMoveEvent(self, event):
        """
        Handles dragging by adjusting the scroll area's position.
        """
        if self.dragging and self.last_mouse_position is not None:
            # Calculate the difference in mouse movement
            delta = event.pos() - self.last_mouse_position
            self.last_mouse_position = event.pos()

            # Adjust the scroll area's scroll position
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )

    def mouseReleaseEvent(self, event):
        """
        Stops dragging when the left mouse button is released.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
            self.last_mouse_position = None
            self.image_label.setCursor(Qt.CursorShape.OpenHandCursor)


    def cleanup_preview_windows(self):
        """
        Cleans up temporary preview images by resetting image variables and clearing GUI elements.
        """
        print("Cleaning up preview windows...")
        
        # 1. Reset Temporary Image Variables
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        print("Temporary preview images (Ha, OIII, SII) have been cleared.")
        
        # 2. Clear GUI Elements Displaying Previews
        # Update the list below with the actual names of your preview labels or buttons
        preview_labels = ['ha_preview_label', 'oiii_preview_label', 'sii_preview_label']
        for label_name in preview_labels:
            if hasattr(self, label_name):
                label = getattr(self, label_name)
                label.clear()  # Removes the pixmap or any displayed content
                print(f"{label_name} has been cleared.")
        
        # 3. Clear Final Image Display (if applicable)
        # Update 'final_image_label' with your actual final image display widget name
        if hasattr(self, 'image_label'):
            self.image_label.clear()
            print("Final image label has been cleared.")
        
        # 4. Reset Thumbnail Buttons (if used for previews)
        # Ensure 'self.thumbnail_buttons' is a list of your thumbnail QPushButtons
        for button in self.thumbnail_buttons:
            button.setIcon(QIcon())    # Remove existing icon



        print("Thumbnail buttons have been reset.")
        
        # 5. Update Status Label
        self.status_label.setText("Preview windows cleaned up.")
        print("Status label updated to indicate cleanup.")
        
        # 6. Process UI Events to Reflect Changes Immediately
        QApplication.processEvents()


    def closeEvent(self, event):
        """
        Handle the close event to perform cleanup.
        """
        self.cleanup_preview_windows()
        event.accept()

class NBtoRGBstarsTab(QWidget):
    def __init__(self, image_manager=None, parent=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc_image = None
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc_filename = None        
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.dragging = False
        self.last_pos = QPoint()
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select Ha, OIII, and SII (optional) narrowband images, or an OSC stars-only image.
            2. Adjust the Ha to OIII Ratio if needed.
            3. Preview the combined result.
            4. Save the final composite image.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # Ha, OIII, SII image selections
        self.haButton = QPushButton('Select Ha Image', self)
        self.haButton.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.haButton)
        self.haLabel = QLabel('No Ha image selected', self)
        left_layout.addWidget(self.haLabel)

        self.oiiiButton = QPushButton('Select OIII Image', self)
        self.oiiiButton.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.oiiiButton)
        self.oiiiLabel = QLabel('No OIII image selected', self)
        left_layout.addWidget(self.oiiiLabel)

        self.siiButton = QPushButton('Select SII Image (Optional)', self)
        self.siiButton.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.siiButton)
        self.siiLabel = QLabel('No SII image selected', self)
        left_layout.addWidget(self.siiLabel)

        self.oscButton = QPushButton('Select OSC Stars Image (Optional)', self)
        self.oscButton.clicked.connect(lambda: self.load_image('OSC'))
        left_layout.addWidget(self.oscButton)
        self.oscLabel = QLabel('No OSC stars image selected', self)
        left_layout.addWidget(self.oscLabel)

        # Ha to OIII Ratio slider
        self.haToOiiRatioLabel, self.haToOiiRatioSlider = self.createRatioSlider("Ha to OIII Ratio", 30)
        left_layout.addWidget(self.haToOiiRatioLabel)
        left_layout.addWidget(self.haToOiiRatioSlider)

        # Star Stretch checkbox and sliders
        self.starStretchCheckBox = QCheckBox("Enable Star Stretch", self)
        self.starStretchCheckBox.setChecked(True)
        self.starStretchCheckBox.toggled.connect(self.toggleStarStretchControls)
        left_layout.addWidget(self.starStretchCheckBox)

        self.stretchSliderLabel, self.stretchSlider = self.createStretchSlider("Stretch Factor", 5.0)
        left_layout.addWidget(self.stretchSliderLabel)
        left_layout.addWidget(self.stretchSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # Preview and Save buttons
        self.previewButton = QPushButton('Preview Combined Image', self)
        self.previewButton.clicked.connect(self.previewCombine)
        left_layout.addWidget(self.previewButton)

        # File label for displaying save status
        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        self.pushButton = QPushButton('Push to Active Slot', self)
        self.pushButton.clicked.connect(self.pushToActiveSlot)
        left_layout.addWidget(self.pushButton)

        # **Remove Zoom Buttons from Left Panel (Not present)**
        # No existing zoom buttons to remove in the left panel

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return       
        if image is None:
            return         
        if slot == self.image_manager.current_slot:

            print(f"NBtoRGBstarsTab: Image updated from ImageManager slot {slot}.")

    def pushToActiveSlot(self):
        """
        Pushes the current combined image to the active slot in the ImageManager,
        along with the associated metadata.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "Warning", "No combined image available to push.")
            return

        # Check if any of the loaded file paths have an XISF extension
        loaded_files = [self.ha_filename, self.oiii_filename, self.sii_filename, self.osc_filename]
        was_xisf = any(file_path and file_path.lower().endswith('.xisf') for file_path in loaded_files)

        # Generate a minimal FITS header if the original header is missing or if the format was XISF
        sanitized_header = self.original_header
        if was_xisf or sanitized_header is None:
            sanitized_header = None  # Use None to avoid saving an empty header

        # Determine the valid file path:
        # Prioritize Ha, then OSC (if available)
        file_path = None
        if self.ha_image is not None and self.ha_filename:
            file_path = self.ha_filename
            print("Using Ha filename as file_path.")
        elif self.osc_image is not None and self.osc_filename:
            file_path = self.osc_filename
            print("Using OSC filename as file_path.")
        else:
            # No valid source file, save combined_image to a temporary file
            try:
                temp_dir = tempfile.gettempdir()
                timestamp = int(time.time())
                temp_file_path = os.path.join(temp_dir, f"combined_image_{timestamp}.tif")

                # Save the combined image using `save_image()`
                save_image(
                    img_array=self.combined_image,
                    filename=temp_file_path,
                    original_format='tif',
                    bit_depth=self.bit_depth,
                    original_header=self.original_header,
                    is_mono=self.is_mono
                )

                file_path = temp_file_path
                print(f"Combined image saved to temporary file: {file_path}")
            except Exception as e:
                print(f"Failed to save combined image to temporary file: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save combined image to temporary file:\n{e}")
                return

        # Create metadata for the combined image
        metadata = {
            'file_path': file_path,
            'original_header': sanitized_header,  # Use the sanitized or minimal header
            'bit_depth': self.bit_depth if hasattr(self, 'bit_depth') else "Unknown",
            'is_mono': False,  # Assume the combined image is color
            'processing_parameters': {
                'ha_to_oii_ratio': self.haToOiiRatioSlider.value() / 100.0,
                'enable_star_stretch': self.starStretchCheckBox.isChecked(),
                'stretch_factor': self.stretchSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Ha': self.ha_filename if self.ha_image is not None else "Not Provided",
                'OIII': self.oiii_filename if self.oiii_image is not None else "Not Provided",
                'SII': self.sii_filename if self.sii_image is not None else "Not Provided",
                'OSC': self.osc_filename if self.osc_image is not None else "Not Provided"
            }
        }

        # Push the image and metadata into the ImageManager
        if self.image_manager:
            try:
                self.image_manager.update_image(
                    updated_image=self.combined_image, metadata=metadata
                )
                print(f"Image pushed to ImageManager with metadata: {metadata}")
                QMessageBox.information(self, "Success", "Combined image pushed to active slot.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the combined image.")


    def createRatioSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value / 100:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(100)
        slider.setValue(default_value)
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def createStretchSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(800)
        slider.setValue(int(default_value * 100))  # Scale to handle float values
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def toggleStarStretchControls(self):
        enabled = self.starStretchCheckBox.isChecked()
        self.stretchSliderLabel.setVisible(enabled)
        self.stretchSlider.setVisible(enabled)

    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.

        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC').
        """
        try:
            print(f"Initiating load process for {image_type} image.")

            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From File", "From Slot"],
                editable=False
            )

            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return

            print(f"{image_type} image source selected: {source_choice}")

            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return

            if result is None:
                # Loading was unsuccessful or cancelled
                return

            image, original_header, bit_depth, is_mono, file_path = result

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.haLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiiiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.siiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC':
                self.osc_image = image
                self.osc_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oscLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return

        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.

        Parameters:
            image_type (str): The type of image to load.

        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter
        )

        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None

        print(f"{image_type} image file selected: {file_path}")

        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None

        return image, original_header, bit_depth, is_mono, file_path

    def load_image_from_slot(self, image_type):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            print("ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Build the list using the parent's slot_names dictionary.
        available_slots = []
        slot_names = self.parent_window.slot_names if self.parent_window else {}
        for i in range(self.image_manager.max_slots):
            slot_name = slot_names.get(i, f"Slot {i+1}")
            available_slots.append(slot_name)

        slot_choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type} Image",
            "Choose a slot:",
            available_slots,
            editable=False
        )

        if not ok or not slot_choice:
            QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
            print(f"{image_type} image loading cancelled by the user.")
            return None

        # Find the slot index that matches the chosen display name.
        target_slot_num = None
        for i in range(self.image_manager.max_slots):
            current_name = slot_names.get(i, f"Slot {i+1}")
            if current_name == slot_choice:
                target_slot_num = i
                break

        if target_slot_num is None:
            QMessageBox.critical(self, "Error", f"Invalid slot selection: {slot_choice}")
            print(f"Error: Could not map slot name '{slot_choice}' to a slot number.")
            return None

        image = self.image_manager._images.get(target_slot_num, None)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{slot_choice} does not contain an image.")
            print(f"{slot_choice} is empty. Cannot load {image_type} image.")
            return None

        print(f"{image_type} image selected from {slot_choice}.")

        # Retrieve metadata.
        metadata = self.image_manager._metadata.get(target_slot_num, {})
        original_header = metadata.get('header', None)
        bit_depth = metadata.get('bit_depth', "Unknown")
        is_mono = metadata.get('is_mono', False)
        file_path = metadata.get('file_path', None)

        return image, original_header, bit_depth, is_mono, file_path


    def previewCombine(self):
        # Check if required images are loaded prior to starting the processing thread
        if not ((self.ha_image is not None and self.oiii_image is not None) or (self.osc_image is not None)):
            QMessageBox.warning(self, "Missing Images", "Please Select Images Before Combining")
            return    
        ha_to_oii_ratio = self.haToOiiRatioSlider.value() / 100.0
        enable_star_stretch = self.starStretchCheckBox.isChecked()
        stretch_factor = self.stretchSlider.value() / 100.0

        # Show spinner before starting processing
        self.showSpinner()

        # Reset zoom factor when a new preview is generated
        self.zoom_factor = 1.0

        # Start background processing
        self.processing_thread = NBtoRGBProcessingThread(
            self.ha_image, self.oiii_image, self.sii_image, self.osc_image,
            ha_to_oii_ratio=ha_to_oii_ratio, enable_star_stretch=enable_star_stretch, stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.updatePreview)
        self.processing_thread.start()

    def updatePreview(self, combined_image):
        # Set the combined image for saving
        self.combined_image = combined_image

        # Convert the image to display format
        try:
            preview_image = (combined_image * 255).astype(np.uint8)
            h, w = preview_image.shape[:2]
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        except Exception as e:
            print(f"Error converting combined image for display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to prepare image for display:\n{e}")
            self.hideSpinner()
            return

        # Store original pixmap for zooming
        self.original_pixmap = QPixmap.fromImage(q_image)

        # Apply initial zoom
        scaled_pixmap = self.original_pixmap.scaled(
            self.original_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def saveImage(self):
        if self.combined_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "output"
            default_save_name = 'NBtoRGBstars.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else ""

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.combined_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.combined_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText("No combined image to save.")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        if self.zoom_factor < 20.0:  # Set a maximum zoom limit (e.g., 500%)
            self.zoom_factor *= 1.25  # Increase zoom by 25%
            self.updateImageDisplay()
        else:
            print("Maximum zoom level reached.")

    def zoom_out(self):
        if self.zoom_factor > 0.01:  # Set a minimum zoom limit (e.g., 20%)
            self.zoom_factor /= 1.25  # Decrease zoom by 20%
            self.updateImageDisplay()
        else:
            print("Minimum zoom level reached.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.combined_image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.combined_image.ndim == 3:
                image_width = self.combined_image.shape[1]
            elif self.combined_image.ndim == 2:
                image_width = self.combined_image.shape[1]
            else:
                print("Unexpected image dimensions!")

                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()  # Call without extra arguments; it will calculate dimensions based on zoom factor

    def reset_zoom(self):
        self.zoom_factor = 1.0
        self.updateImageDisplay()

    def updateImageDisplay(self):
        if self.original_pixmap:
            scaled_pixmap = self.original_pixmap.scaled(
                self.original_pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

    # Add event filter for mouse dragging in preview area
    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)

    # Placeholder methods for functionalities
    def handleImageMouseMove(self, x, y):
        # Implement handling mouse movement over the image
        pass


class NBtoRGBProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image=None, oiii_image=None, sii_image=None, osc_image=None, ha_to_oii_ratio=0.3, enable_star_stretch=True, stretch_factor=5.0):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc_image = osc_image
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        # Preprocess input images to ensure mono images are single-channel
        self.ha_image = preprocess_narrowband_image(self.ha_image)
        self.oiii_image = preprocess_narrowband_image(self.oiii_image)
        self.sii_image = preprocess_narrowband_image(self.sii_image)

        # Normalize input images to [0, 1]
        if self.ha_image is not None:
            self.ha_image = np.clip(self.ha_image, 0, 1)
        if self.oiii_image is not None:
            self.oiii_image = np.clip(self.oiii_image, 0, 1)
        if self.sii_image is not None:
            self.sii_image = np.clip(self.sii_image, 0, 1)
        if self.osc_image is not None:
            self.osc_image = np.clip(self.osc_image, 0, 1)

        # Combined RGB logic
        if self.osc_image is not None:
            r_channel = self.osc_image[..., 0]
            g_channel = self.osc_image[..., 1]
            b_channel = self.osc_image[..., 2]

            r_combined = 0.5 * r_channel + 0.5 * (self.sii_image if self.sii_image is not None else r_channel)
            g_combined = self.ha_to_oii_ratio * (self.ha_image if self.ha_image is not None else r_channel) + \
                        (1 - self.ha_to_oii_ratio) * g_channel
            b_combined = b_channel if self.oiii_image is None else self.oiii_image
        else:
            r_combined = 0.5 * self.ha_image + 0.5 * (self.sii_image if self.sii_image is not None else self.ha_image)
            g_combined = self.ha_to_oii_ratio * self.ha_image + (1 - self.ha_to_oii_ratio) * self.oiii_image
            b_combined = self.oiii_image

        # Debugging: Check shapes
        print(f"R combined shape: {r_combined.shape}")
        print(f"G combined shape: {g_combined.shape}")
        print(f"B combined shape: {b_combined.shape}")

        # Normalize combined channels to [0, 1]
        r_combined = np.clip(r_combined, 0, 1)
        g_combined = np.clip(g_combined, 0, 1)
        b_combined = np.clip(b_combined, 0, 1)

        # Stack the channels to create an RGB image
        try:
            combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)
        except ValueError as e:
            print(f"Error while stacking channels: {e}")
            print(f"R: {r_combined.shape}, G: {g_combined.shape}, B: {b_combined.shape}")
            return

        print(f"Combined image shape: {combined_image.shape}")

        # Apply star stretch if enabled
        if self.enable_star_stretch:
            combined_image = self.apply_star_stretch(combined_image)

        # Ensure combined_image is 3-channel
        if combined_image.ndim != 3 or combined_image.shape[2] != 3:
            raise ValueError("Combined image must have three channels (RGB).")

        # Apply SCNR (remove green cast)
        apply_average_neutral_scnr(combined_image)

        # Emit the processed image for preview
        self.preview_generated.emit(combined_image)


    def apply_star_stretch(self, image):
        # Ensure input image is in the range [0, 1]
        assert np.all(image >= 0) and np.all(image <= 1), "Image must be normalized to [0, 1] before star stretch."
        stretched = ((3 ** self.stretch_factor) * image) / ((3 ** self.stretch_factor - 1) * image + 1)
        return np.clip(stretched, 0, 1)

    def apply_scnr(self, image):
        green_channel = image[..., 1]
        max_rg = np.maximum(image[..., 0], image[..., 2])
        green_channel[green_channel > max_rg] = max_rg[green_channel > max_rg]
        image[..., 1] = green_channel
        return image

class HaloBGonTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager

        self.image = None  # Selected image
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.processed_image = None
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.is_mono = True
        self.last_pos = None
        self.processing_thread = None  # For background processing
        self.original_header = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
        

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fixed width for left column

        # Instructions label
        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the reduction amount as needed.
            3. Click Refresh Preview to apply the halo reduction.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Load Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Reduction amount slider
        self.reductionLabel = QLabel("Reduction Amount: Extra Low", self)
        self.reductionSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.reductionSlider.setMinimum(0)
        self.reductionSlider.setMaximum(3)
        self.reductionSlider.setValue(0)  # 0: Extra Low, 1: Low, 2: Medium, 3: High
        self.reductionSlider.setToolTip("Adjust the amount of halo reduction (Extra Low, Low, Medium, High)")
        self.reductionSlider.valueChanged.connect(self.updateReductionLabel)
        left_layout.addWidget(self.reductionLabel)
        left_layout.addWidget(self.reductionSlider)

        # Linear data checkbox
        self.linearDataCheckbox = QCheckBox("Linear Data", self)
        self.linearDataCheckbox.setToolTip("Check if the data is linear")
        left_layout.addWidget(self.linearDataCheckbox)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # **Create a horizontal layout for Refresh Preview and Undo buttons**
        action_buttons_layout = QHBoxLayout()

        # Refresh Preview button
        self.executeButton = QPushButton("Refresh Preview", self)
        self.executeButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.executeButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Comment out or remove the existing zoom buttons in the left panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton("Zoom In", self)
        # self.zoomInButton.clicked.connect(self.zoomIn)
        # zoom_layout.addWidget(self.zoomInButton)
        #
        # self.zoomOutButton = QPushButton("Zoom Out", self)
        # self.zoomOutButton.clicked.connect(self.zoomOut)
        # zoom_layout.addWidget(self.zoomOutButton)
        # left_layout.addLayout(zoom_layout)

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoomIn)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoomOut)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"Halo-B-Gon Tab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')



    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("HaloBGonTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("HaloBGonTab: No actions to undo.")

        # Update the state of the Undo button
        self.undoButton.setEnabled(self.image_manager.can_undo())

    def updateReductionLabel(self, value):
        labels = ["Extra Low", "Low", "Medium", "High"]
        if 0 <= value < len(labels):
            self.reductionLabel.setText(f"Reduction Amount: {labels[value]}")
        else:
            self.reductionLabel.setText("Reduction Amount: Unknown")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoomIn()
        else:
            self.zoomOut()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoomIn(self):
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        self.updateImageDisplay()

    def zoomOut(self):
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        self.updateImageDisplay()
    
    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.image.ndim == 3:
                image_width = self.image.shape[1]
            elif self.image.ndim == 2:
                image_width = self.image.shape[1]
            else:
                print("Unexpected image dimensions!")
                self.statusLabel.setText("Cannot fit image to preview due to unexpected dimensions.")
                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()

    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Stars Only Image", 
            "", 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                # Load the image with header information
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)  # Ensure load_image returns (image, header, bit_depth, is_mono)
                self.filename = selected_file 
                self.fileLabel.setText(os.path.basename(selected_file))
                
                # Update ImageManager with the loaded image
                if self.image_manager:
                    metadata = {
                        'file_path': selected_file,
                        'original_header': self.original_header,
                        'bit_depth': 'Unknown',  # Update if available
                        'is_mono': self.is_mono
                    }
                    self.image_manager.update_image(updated_image=self.image, metadata=metadata)
                    print(f"HaloBGonTab: Loaded image stored in ImageManager.")
                
                self.generatePreview()  # Generate preview after loading
            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                QMessageBox.critical(self, "Error", f"Failed to load image:\n{e}")
                print(f"Failed to load image: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    def applyHaloReduction(self):
        if self.image is None:
            print("No image selected.")
            return

        reduction_amount = self.reductionSlider.value()
        is_linear = self.linearDataCheckbox.isChecked()

        # Show spinner and start background processing
        self.showSpinner()
        self.processing_thread = QThread()
        self.processing_worker = self.HaloProcessingWorker(self.image, reduction_amount, is_linear)
        self.processing_worker.moveToThread(self.processing_thread)
        self.processing_worker.processing_complete.connect(self.updateImage)
        self.processing_thread.started.connect(self.processing_worker.process)
        self.processing_thread.start()

    def updatePreview(self, processed_image):
        """
        Updates the preview with the processed image and applies the active mask if available.
        """
        # Retrieve the active mask
        mask = self.get_active_mask()
        
        if mask is not None:
            print("Applying mask to the processed image.")
            # Ensure mask and image have the same number of channels
            if self.image.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)
            
            # Blend the processed image with the original image using the mask
            # Formula: blended_image = processed_image * mask + original_image * (1 - mask)
            blended_image = processed_image * mask + self.image * (1 - mask)
            blended_image = np.clip(blended_image, 0.0, 1.0)  # Ensure values are within [0,1]
        else:
            print("No mask applied. Using the processed image directly.")
            blended_image = processed_image
        
        # Create metadata for the new image
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update dynamically if available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Ensure ImageManager is initialized
        if self.image_manager:
            try:
                # Set the new image and metadata using the ImageManager
                self.image_manager.set_image(blended_image, metadata)
                print("HaloBGonTab: Processed and masked image stored in ImageManager (undoable).")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
                self.hideSpinner()
                return
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
            self.hideSpinner()
            return

        # Convert the blended image to 8-bit for display in the preview
        preview_image = (blended_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        # Update the pixmap and scale it for the preview label
        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # Store the original pixmap
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.zoom_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is complete
        self.hideSpinner()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Halo reduction applied with mask.")
        else:
            self.fileLabel.setText("Halo reduction applied without mask.")
        
        print("HaloBGonTab: Preview updated with processed image.")



    def saveImage(self):
        if self.processed_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_reduced.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                
                if ok and bit_depth:
                    # If linear data is checked, revert to linear before saving
                    if self.linearDataCheckbox.isChecked():
                        saved_image = np.clip(self.processed_image ** 5, 0, 1)  # Revert to linear state
                    else:
                        saved_image = self.processed_image  # Save as is (non-linear)

                    # Call save_image with the necessary parameters
                    save_image(saved_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
                else:
                    self.fileLabel.setText('Save canceled.')
            else:
                self.fileLabel.setText('Save canceled.')



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # Updated generatePreview method in HaloBGonTab to use HaloProcessingThread
    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing with HaloProcessingThread
            self.processing_thread = HaloProcessingThread(
                self.image, 
                self.reductionSlider.value(), 
                self.linearDataCheckbox.isChecked()
            )
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()
        else:
            QMessageBox.warning(self, "Warning", "No image loaded. Please load an image first.")
            print("HaloBGonTab: No image loaded. Cannot generate preview.")

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)


    def createLightnessMask(self, image):
        # Check if the image is already single-channel (grayscale)
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Normalize the grayscale image
            lightness_mask = image.astype(np.float32) / 255.0
        else:
            # Convert to grayscale to create a lightness mask
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0

        # Apply a Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        lightness_mask = cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)

        return lightness_mask

    def createDuplicateImage(self, original):
        return np.copy(original)

    def invert_mask(mask):
        return 1.0 - mask  # Assuming mask is normalized between 0 and 1


    def apply_mask_to_image(image, mask):
        # Ensure mask is 3-channel to match the image dimensions
        mask_rgb = np.stack([mask] * 3, axis=-1)
        return cv2.multiply(image, mask_rgb)


    def apply_curves_to_image(image, reduction_amount):
        # Define the curve based on reduction amount
        if reduction_amount == 0:
            curve = [int((i / 255.0) ** 0.575 * 255) for i in range(256)]
        else:
            curve = [int((i / 255.0) ** 0.4 * 255) for i in range(256)]
        
        lut = np.array(curve, dtype=np.uint8)
        return cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0


    def load_image(self, filename):
        original_header = None
        file_extension = filename.split('.')[-1].lower()

        # Handle different file types and normalize them to [0, 1] range
        if file_extension in ['tif', 'tiff']:
            image = tiff.imread(filename).astype(np.float32) / 65535.0  # For 16-bit TIFF images
        elif file_extension == 'png':
            image = np.array(Image.open(filename).convert('RGB')).astype(np.float32) / 255.0  # Normalize to [0, 1]
        elif file_extension in ['fits', 'fit']:
            with fits.open(filename) as hdul:
                image = hdul[0].data.astype(np.float32)
                original_header = hdul[0].header
                # Normalize if data is 16-bit or higher
                if image.max() > 1:
                    image /= np.max(image)
        else:
            raise ValueError(f"Unsupported file format: {file_extension}")

        return image, original_header

    def save_image(self, image, filename, file_format, bit_depth="16-bit", original_header=None):
        img = Image.fromarray((image * 255).astype(np.uint8))
        img.save(filename)

class HaloProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, reduction_amount, is_linear):
        super().__init__()
        self.image = image
        self.reduction_amount = reduction_amount
        self.is_linear = is_linear


    def run(self):
        processed_image = self.applyHaloReduction(self.image, self.reduction_amount, self.is_linear)
        self.preview_generated.emit(processed_image)

    def applyHaloReduction(self, image, reduction_amount, is_linear):
        # Ensure the image values are in range [0, 1]
        image = np.clip(image, 0, 1)

        # Convert linear to non-linear if the image is linear
        if is_linear:
            image = image ** (1 / 5)  # Gamma correction for linear data

        # Apply halo reduction logic
        lightness_mask = self.createLightnessMask(image)  # Single-channel mask
        inverted_mask = 1.0 - lightness_mask
        duplicated_mask = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)
        enhanced_mask = inverted_mask - duplicated_mask * reduction_amount * 0.33

        # Expand the mask to match the number of channels in the image
        if image.ndim == 3 and image.shape[2] == 3:  # Color image
            enhanced_mask = np.expand_dims(enhanced_mask, axis=-1)  # Add a channel dimension
            enhanced_mask = np.repeat(enhanced_mask, 3, axis=-1)  # Repeat for all 3 channels

        # Ensure the mask matches the data type of the image
        enhanced_mask = enhanced_mask.astype(image.dtype)

        # Verify that the image and mask dimensions match
        if image.shape != enhanced_mask.shape:
            raise ValueError(
                f"Shape mismatch between image {image.shape} and enhanced_mask {enhanced_mask.shape}"
            )

        # Apply the mask to the image
        masked_image = cv2.multiply(image, enhanced_mask)

        # Apply curves to the resulting image
        final_image = self.applyCurvesToImage(masked_image, reduction_amount)

        # Ensure the final image values are within [0, 1]
        return np.clip(final_image, 0, 1)



    def createLightnessMask(self, image):
        # Ensure the image is in a supported format (float32)
        image = image.astype(np.float32)

        # Check if the image is already grayscale
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Image is already grayscale; normalize it
            lightness_mask = image / 255.0
        else:
            # Convert RGB image to grayscale
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0

        # Apply Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        return cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)



    def createDuplicateMask(self, mask):
        # Duplicate the mask and apply additional processing (simulating MMT)
        duplicated_mask = cv2.GaussianBlur(mask, (0, 0), sigmaX=2)
        return duplicated_mask

    def applyMaskToImage(self, image, mask):
        # Blend the original image with the mask based on the reduction level
        mask_rgb = np.stack([mask] * 3, axis=-1)  # Convert to 3-channel
        return cv2.multiply(image, mask_rgb)

    def applyCurvesToImage(self, image, reduction_amount):
        # Apply a curves transformation based on reduction_amount
        if reduction_amount == 0:
            # Extra Low setting, mild curve
            curve = [int((i / 255.0) ** 1.2 * 255) for i in range(256)]
        elif reduction_amount == 1:
            # Low setting, slightly stronger darkening
            curve = [int((i / 255.0) ** 1.5 * 255) for i in range(256)]
        elif reduction_amount == 2:
            # Medium setting, moderate darkening
            curve = [int((i / 255.0) ** 1.8 * 255) for i in range(256)]
        else:
            # High setting, strong darkening effect
            curve = [int((i / 255.0) ** 2.2 * 255) for i in range(256)]

        # Apply the curve transformation as a lookup table
        lut = np.array(curve, dtype=np.uint8)
        transformed_image = cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0
        return transformed_image



class ContinuumSubtractTab(QWidget):
    def __init__(self, image_manager):
        super().__init__()
        self.image_manager = image_manager
        self.initUI()
        self.nb_image = None  # Selected NB image
        self.continuum_image = None  # Selected Continuum image
        self.filename = None  # Store the selected file path
        self.is_mono = True
        self.combined_image = None  # Store the result of the continuum subtraction
        self.zoom_factor = 1.0  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.last_pos = None
        self.processing_thread = None  # For background processing
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left side controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fixed width for left column

        # Instruction box
        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Load your NB and Continuum images.
            2. Select for optional linear only output.
            3. Click Execute to perform continuum subtraction.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File Selection Buttons
        self.nb_button = QPushButton("Load NB Image")
        self.nb_button.clicked.connect(lambda: self.selectImage("nb"))
        self.nb_label = QLabel("No NB image selected")
        left_layout.addWidget(self.nb_button)
        left_layout.addWidget(self.nb_label)

        self.continuum_button = QPushButton("Load Continuum Image")
        self.continuum_button.clicked.connect(lambda: self.selectImage("continuum"))
        self.continuum_label = QLabel("No Continuum image selected")
        left_layout.addWidget(self.continuum_button)
        left_layout.addWidget(self.continuum_label)

        # **Added: Clear Loaded Images Button**
        self.clear_button = QPushButton("Clear Loaded Images")
        self.clear_button.clicked.connect(self.clear_loaded_images)
        left_layout.addWidget(self.clear_button)        

        # Linear Output Checkbox
        self.linear_output_checkbox = QCheckBox("Output Linear Image Only")
        left_layout.addWidget(self.linear_output_checkbox)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Ensure spinner.gif is in the correct path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # Status label to show processing status
        self.statusLabel = QLabel(self)
        self.statusLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        left_layout.addWidget(self.statusLabel)

        # Execute Button
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.startContinuumSubtraction)
        left_layout.addWidget(self.execute_button)

        # **Remove Zoom Buttons from Left Panel**
        # The following code is removed to eliminate zoom buttons from the left panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton("Zoom In")
        # self.zoomInButton.clicked.connect(self.zoom_in)
        # zoom_layout.addWidget(self.zoomInButton)
        #
        # self.zoomOutButton = QPushButton("Zoom Out")
        # self.zoomOutButton.clicked.connect(self.zoom_out)
        # zoom_layout.addWidget(self.zoomOutButton)
        # left_layout.addLayout(zoom_layout)

        # Save Button
        self.save_button = QPushButton("Save Continuum Subtracted Image")
        self.save_button.clicked.connect(self.save_continuum_subtracted)
        self.save_button.setEnabled(False)  # Disable until an image is processed
        left_layout.addWidget(self.save_button)

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        # Spacer to push elements to the top
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # **Add Zoom Buttons to Right Panel**
        zoom_layout = QHBoxLayout()
        self.zoomInButton = QPushButton("Zoom In")
        self.zoomInButton.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(self.zoomInButton)

        self.zoomOutButton = QPushButton("Zoom Out")
        self.zoomOutButton.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoomOutButton)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)        

        # Add the zoom buttons layout to the right panel
        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

        # Initially disable zoom buttons until an image is loaded and previewed
        self.zoomInButton.setEnabled(False)
        self.zoomOutButton.setEnabled(False)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return     
        if image is None:
            return           
        if slot == 0:  # Assuming slot 0 is used for shared images
            # Ensure the image is a numpy array
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if needed

            # Update internal state with the new image and metadata
            self.combined_image = image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', None)

            # Update the preview
            self.update_preview()

            print(f"ContinuumSubtractTab: Image updated from ImageManager slot {slot}.")

    def clear_loaded_images(self):
        """Clear the loaded NB and Continuum images and reset the UI."""
        # Clear loaded images
        self.nb_image = None
        self.continuum_image = None
        self.filename = None
        self.combined_image = None

        # Reset labels
        self.nb_label.setText("No NB image selected")
        self.continuum_label.setText("No Continuum image selected")

        # Disable save button
        self.save_button.setEnabled(False)

        # Clear the preview image
        self.imageLabel.clear()
        self.original_pixmap = None

        # Reset zoom factor
        self.zoom_factor = 1.0
        self.apply_zoom()

        # Disable zoom buttons
        self.zoomInButton.setEnabled(False)
        self.zoomOutButton.setEnabled(False)


        # Update status label
        self.statusLabel.setText("Loaded images cleared.")

        print("Loaded images cleared.")

    def selectImage(self, image_type):
        selected_file, _ = QFileDialog.getOpenFileName(self, "Select Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *xisf)")
        if selected_file:
            try:
                image, original_header, _, _ = load_image(selected_file)  # Load image with header
                self.filename = selected_file
                if image_type == "nb":
                    self.nb_image = image
                    self.nb_label.setText(os.path.basename(selected_file))  # Updated label
                elif image_type == "continuum":
                    self.continuum_image = image
                    self.continuum_label.setText(os.path.basename(selected_file))  # Updated label
            except Exception as e:
                print(f"Failed to load {image_type} image: {e}")
                if image_type == "nb":
                    self.nb_label.setText("Error loading NB image")
                elif image_type == "continuum":
                    self.continuum_label.setText("Error loading Continuum image")

    def startContinuumSubtraction(self):
        if self.nb_image is not None and self.continuum_image is not None:
            # Show spinner and start background processing
            self.showSpinner()
            self.processing_thread = ContinuumProcessingThread(
                self.nb_image,
                self.continuum_image,
                self.linear_output_checkbox.isChecked()
            )
            self.processing_thread.processing_complete.connect(self.display_image)
            self.processing_thread.finished.connect(self.hideSpinner)
            self.processing_thread.status_update.connect(self.update_status_label)
            self.processing_thread.start()
        else:
            self.statusLabel.setText("Please select both NB and Continuum images.")
            print("Please select both NB and Continuum images.")

    def update_status_label(self, message):
        self.statusLabel.setText(message)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        if self.zoom_factor < 5.0:  # Maximum 500% zoom
            self.zoom_factor *= 1.2  # Increase zoom by 20%
            self.update_preview()
            self.statusLabel.setText(f"Zoom: {self.zoom_factor * 100:.0f}%")

        else:
            self.statusLabel.setText("Maximum zoom level reached.")

    def zoom_out(self):
        if self.zoom_factor > 0.01:  # Minimum 20% zoom
            self.zoom_factor /= 1.2  # Decrease zoom by ~17%
            self.update_preview()
            self.statusLabel.setText(f"Zoom: {self.zoom_factor * 100:.0f}%")

        else:
            self.statusLabel.setText("Minimum zoom level reached.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        # Check if the original pixmap exists
        if self.original_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the width of the original image from the original_pixmap
            image_width = self.original_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
            self.statusLabel.setText(f"Fit to Preview: {self.zoom_factor * 100:.0f}%")

        else:

            self.statusLabel.setText("No image to fit to preview.")


    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.update_preview()  # Call without extra arguments; it will calculate dimensions based on zoom factor            

    def update_preview(self):
        if self.original_pixmap is not None:
            scaled_pixmap = self.original_pixmap.scaled(
                self.original_pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
            print(f"Preview updated with zoom factor: {self.zoom_factor}")
        else:
            print("Original pixmap is not set. Cannot update preview.")

    def save_continuum_subtracted(self):
        if self.combined_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_continuumsubtracted.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(
                        self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False
                    )
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(
                            self.combined_image, 
                            save_filename, 
                            original_format, 
                            bit_depth, 
                            self.original_header, 
                            self.is_mono
                        )
                        self.statusLabel.setText(f'Image saved as: {save_filename}')
                        print(f"Image saved as: {save_filename}")
                    else:
                        self.statusLabel.setText('Save canceled.')
                        print("Save operation canceled.")
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.combined_image, save_filename, original_format)
                    self.statusLabel.setText(f'Image saved as: {save_filename}')
                    print(f"Image saved as: {save_filename}")
            else:
                self.statusLabel.setText('Save canceled.')
                print("Save operation canceled.")
        else:
            self.statusLabel.setText("No processed image to save.")
            print("No processed image to save.")

    def display_image(self, processed_image):
        if processed_image is not None:
            self.combined_image = processed_image

            # Convert the processed image to a displayable format
            preview_image = (processed_image * 255).astype(np.uint8)
            
            # Check if the image is mono or RGB
            if preview_image.ndim == 2:  # Mono image
                # Create a 3-channel RGB image by duplicating the single channel
                preview_image = np.stack([preview_image] * 3, axis=-1)  # Stack to create RGB

            h, w = preview_image.shape[:2]

            # Ensure the array is contiguous
            preview_image = np.ascontiguousarray(preview_image)

            # Change the format to RGB888 for displaying an RGB image
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)

            pixmap = QPixmap.fromImage(q_image)

            # Store the original pixmap only once
            if self.original_pixmap is None:
                self.original_pixmap = pixmap.copy()

            # Scale from original pixmap based on zoom_factor
            scaled_pixmap = self.original_pixmap.scaled(
                self.original_pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

            # Enable save and zoom buttons now that an image is processed
            self.save_button.setEnabled(True)
            self.zoomInButton.setEnabled(True)
            self.zoomOutButton.setEnabled(True)

            self.statusLabel.setText("Continuum subtraction completed.")
            # Push the processed image to ImageManager
            if self.image_manager:
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'is_mono': self.is_mono,
                    'source': 'Continuum Subtraction'
                }
                self.image_manager.update_image(self.combined_image, metadata, slot=0)

                print("ContinuumSubtractTab: Image pushed to ImageManager.")
        else:
            self.statusLabel.setText("Continuum subtraction failed.")
            print("Continuum subtraction failed.")

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def eventFilter(self, source, event):
        if source is self.scrollArea.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_pos = event.pos()
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_pos
                self.scrollArea.horizontalScrollBar().setValue(
                    self.scrollArea.horizontalScrollBar().value() - delta.x()
                )
                self.scrollArea.verticalScrollBar().setValue(
                    self.scrollArea.verticalScrollBar().value() - delta.y()
                )
                self.last_pos = event.pos()

        return super().eventFilter(source, event)


class ContinuumProcessingThread(QThread):
    processing_complete = pyqtSignal(np.ndarray)
    status_update = pyqtSignal(str)

    def __init__(self, nb_image, continuum_image, output_linear):
        super().__init__()
        self.nb_image = nb_image
        self.continuum_image = continuum_image
        self.output_linear = output_linear
        self.background_reference = None  # Store the background reference



    def run(self):
        # Ensure both images are mono
        if self.nb_image.ndim == 3 and self.nb_image.shape[2] == 3:
            self.nb_image = self.nb_image[..., 0]  # Take one channel for the NB image

        if self.continuum_image.ndim == 3 and self.continuum_image.shape[2] == 3:
            self.continuum_image = self.continuum_image[..., 0]  # Take one channel for the continuum image

        # Create RGB image
        r_combined = self.nb_image  # Use the normalized NB image as the Red channel
        g_combined = self.continuum_image # Use the normalized continuum image as the Green channel
        b_combined = self.continuum_image  # Use the normalized continuum image as the Blue channel


        # Stack the channels into a single RGB image
        combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)

        self.status_update.emit("Performing background neutralization...")
        QCoreApplication.processEvents()
            # Perform background neutralization
        self.background_neutralization(combined_image)

        # Normalize the red channel to the green channel
        combined_image[..., 0] = self.normalize_channel(combined_image[..., 0], combined_image[..., 1])

        # Perform continuum subtraction
        linear_image = combined_image[..., 0] - 0.9*(combined_image[..., 1]-np.median(combined_image[..., 1]))

            # Check if the Output Linear checkbox is checked
        if self.output_linear:
            # Emit the linear image for preview
            self.processing_complete.emit(np.clip(linear_image, 0, 1))
            return  # Exit the method if we only want to output the linear image

        self.status_update.emit("Subtraction complete.")
        QCoreApplication.processEvents()

        # Perform statistical stretch
        target_median = 0.25
        stretched_image = stretch_color_image(linear_image, target_median, True, False)

        # Final image adjustment
        final_image = stretched_image - 0.7*np.median(stretched_image)

        # Clip the final image to stay within [0, 1]
        final_image = np.clip(final_image, 0, 1)

        # Applies Curves Boost
        final_image = apply_curves_adjustment(final_image, np.median(final_image), 0.5)

        self.status_update.emit("Linear to Non-Linear Stretch complete.")
        QCoreApplication.processEvents()
        # Emit the final image for preview
        self.processing_complete.emit(final_image)

    def background_neutralization(self, rgb_image):
        height, width, _ = rgb_image.shape
        num_boxes = 200
        box_size = 25
        iterations = 25

        boxes = [(np.random.randint(0, height - box_size), np.random.randint(0, width - box_size)) for _ in range(num_boxes)]
        best_means = np.full(num_boxes, np.inf)

        for _ in range(iterations):
            for i, (y, x) in enumerate(boxes):
                if y + box_size <= height and x + box_size <= width:
                    patch = rgb_image[y:y + box_size, x:x + box_size]
                    patch_median = np.median(patch) if patch.size > 0 else np.inf

                    if patch_median < best_means[i]:
                        best_means[i] = patch_median

                    surrounding_values = []
                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            surrounding_y = y + dy * box_size
                            surrounding_x = x + dx * box_size
                            
                            if (0 <= surrounding_y < height - box_size) and (0 <= surrounding_x < width - box_size):
                                surrounding_patch = rgb_image[surrounding_y:surrounding_y + box_size, surrounding_x:surrounding_x + box_size]
                                if surrounding_patch.size > 0:
                                    surrounding_values.append(np.median(surrounding_patch))

                    if surrounding_values:
                        dimmest_index = np.argmin(surrounding_values)
                        new_y = y + (dimmest_index // 3 - 1) * box_size
                        new_x = x + (dimmest_index % 3 - 1) * box_size
                        boxes[i] = (new_y, new_x)

        # After iterations, find the darkest box median
        darkest_value = np.inf
        background_box = None

        for box in boxes:
            y, x = box
            if y + box_size <= height and x + box_size <= width:
                patch = rgb_image[y:y + box_size, x:y + box_size]
                patch_median = np.median(patch) if patch.size > 0 else np.inf

                if patch_median < darkest_value:
                    darkest_value = patch_median
                    background_box = patch

        if background_box is not None:
            self.background_reference = np.median(background_box.reshape(-1, 3), axis=0)
            
            # Adjust the channels based on the median reference
            channel_medians = np.median(rgb_image, axis=(0, 1))

            # Adjust channels based on the red channel
            for channel in range(3):
                if self.background_reference[channel] < channel_medians[channel]:
                    pedestal = channel_medians[channel] - self.background_reference[channel]
                    rgb_image[..., channel] += pedestal

            # Specifically adjust G and B to match R
            r_median = self.background_reference[0]
            for channel in [1, 2]:  # Green and Blue channels
                if self.background_reference[channel] < r_median:
                    rgb_image[..., channel] += (r_median - self.background_reference[channel])

        self.status_update.emit("Background neutralization complete.")
        QCoreApplication.processEvents()
        return rgb_image
    
    def normalize_channel(self, image_channel, reference_channel):
        mad_image = np.mean(np.abs(image_channel - np.mean(image_channel)))
        mad_ref = np.mean(np.abs(reference_channel - np.mean(reference_channel)))

        median_image = np.median(image_channel)
        median_ref = np.median(reference_channel)

        # Apply the normalization formula
        normalized_channel = (
            image_channel * mad_ref / mad_image
            - (mad_ref / mad_image) * median_image
            + median_ref
        )

        self.status_update.emit("Color calibration complete.")
        QCoreApplication.processEvents()
        return np.clip(normalized_channel, 0, 1)  



    def continuum_subtraction(self, rgb_image):
        red_channel = rgb_image[..., 0]
        green_channel = rgb_image[..., 1]
        
        # Determine Q based on the selection (modify condition based on actual UI element)
        Q = 0.9 if self.output_linear else 1.0

        # Perform the continuum subtraction
        median_green = np.median(green_channel)
        result_image = red_channel - Q * (green_channel - median_green)
        
        return np.clip(result_image, 0, 1)  # Ensure values stay within [0, 1]

def preprocess_narrowband_image(image):
    """
    Preprocess narrowband images to ensure they are single-channel.
    If the image is detected as a mono image stored in 3-channel format, the red channel is used.
    """
    if image is not None:
        if image.ndim == 3:
            if image.shape[2] == 3:
                # Use the red channel if the image is multi-channel
                print("Detected multi-channel RGB data. Using the red channel as mono.")
                image = image[..., 0]
            elif image.shape[2] == 1:
                # Squeeze single redundant channel
                print("Detected 1-channel image with extra dimension. Squeezing to single channel.")
                image = np.squeeze(image, axis=-1)
        elif image.ndim != 2:
            raise ValueError(f"Unexpected image shape: {image.shape}")
    return image



def apply_standard_white_balance(image: np.ndarray, r_gain: float = 1.0, g_gain: float = 1.0, b_gain: float = 1.0) -> np.ndarray:
    """
    Applies standard white balance by adjusting the gain of each color channel.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        r_gain (float): Gain for the Red channel.
        g_gain (float): Gain for the Green channel.
        b_gain (float): Gain for the Blue channel.

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    balanced = image.copy()
    balanced[:, :, 0] *= r_gain
    balanced[:, :, 1] *= g_gain
    balanced[:, :, 2] *= b_gain
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

def apply_auto_white_balance(image: np.ndarray) -> np.ndarray:
    """
    Applies automatic white balance using the Gray World Assumption.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    # Calculate the mean of each channel
    mean_r = np.mean(image[:, :, 0])
    mean_g = np.mean(image[:, :, 1])
    mean_b = np.mean(image[:, :, 2])
    
    # Calculate the overall mean
    mean_all = (mean_r + mean_g + mean_b) / 3
    
    # Calculate gains
    gain_r = mean_all / mean_r if mean_r != 0 else 1.0
    gain_g = mean_all / mean_g if mean_g != 0 else 1.0
    gain_b = mean_all / mean_b if mean_b != 0 else 1.0
    
    # Apply gains
    balanced = image.copy()
    balanced[:, :, 0] *= gain_r
    balanced[:, :, 1] *= gain_g
    balanced[:, :, 2] *= gain_b
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

def apply_star_based_white_balance(image: np.ndarray, threshold: int = 180) -> tuple:
    """
    Applies white balance based on detected stars in the image using thresholding and contour detection.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        threshold (int): Threshold value for binary segmentation to detect stars.

    Returns:
        tuple: (White-balanced RGB image, Number of detected stars, Image with detected stars marked)
    """
    # Convert to grayscale
    gray = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)

    # Apply Gaussian Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)

    # Apply Contrast Limited Adaptive Histogram Equalization (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(blurred)

    # Apply binary thresholding to isolate bright regions (stars)
    # Lower the threshold to detect fainter stars
    _, thresh = cv2.threshold(enhanced, threshold, 255, cv2.THRESH_BINARY)

    # Perform morphological operations to enhance star features
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel, iterations=1)

    # Find contours in the thresholded image
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    star_pixels = []
    image_with_stars = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

    for cnt in contours:
        area = cv2.contourArea(cnt)
        if 2 < area < 300:  # Adjusted area thresholds for more sensitivity
            perimeter = cv2.arcLength(cnt, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * (area / (perimeter * perimeter))
            if circularity > 0.5:  # Lowered circularity to detect less perfect circles
                # Compute the centroid
                M = cv2.moments(cnt)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    star_pixels.append(image[cY, cX, :])
                    # Draw a circle around the detected star
                    cv2.circle(image_with_stars, (cX, cY), 10, (0, 255, 0), 3)

    star_count = len(star_pixels)

    if star_count == 0:
        raise ValueError("No stars detected for Star-Based White Balance.")

    # Calculate average color of stars
    star_pixels = np.array(star_pixels)
    avg_color = np.mean(star_pixels, axis=0)  # [R, G, B]

    # Calculate scaling factors to normalize average color to neutral gray (average of R, G, B)
    avg = np.mean(avg_color)
    if avg == 0:
        raise ValueError("Average star color is zero, cannot apply White Balance.")
    scaling_factors = avg / avg_color

    # Apply scaling factors
    balanced = image.copy()
    balanced[:, :, 0] *= scaling_factors[0]  # Red channel
    balanced[:, :, 1] *= scaling_factors[1]  # Green channel
    balanced[:, :, 2] *= scaling_factors[2]  # Blue channel
    balanced = np.clip(balanced, 0.0, 1.0)

    return balanced, star_count, image_with_stars

def apply_morphology(image: np.ndarray, operation: str = 'erosion', kernel_size: int = 3, iterations: int = 1) -> np.ndarray:
    """
    Applies a morphological operation to the image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        operation (str): Morphological operation ('erosion', 'dilation', 'opening', 'closing').
        kernel_size (int): Size of the structuring element.
        iterations (int): Number of times the operation is applied.

    Returns:
        np.ndarray: Morphologically processed RGB image.
    """
    # Define the structuring element
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))

    # Convert image to uint8
    image_uint8 = (image * 255).astype(np.uint8)

    # Apply the selected operation
    if operation == 'erosion':
        processed = cv2.erode(image_uint8, kernel, iterations=iterations)
    elif operation == 'dilation':
        processed = cv2.dilate(image_uint8, kernel, iterations=iterations)
    elif operation == 'opening':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif operation == 'closing':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    else:
        raise ValueError("Unsupported morphological operation.")

    # Convert back to float [0,1]
    processed_image = processed.astype(np.float32) / 255.0
    return processed_image

def apply_clahe(image: np.ndarray, clip_limit: float = 2.0, tile_grid_size: tuple = (8, 8)) -> np.ndarray:
    """
    Applies CLAHE to the image for adaptive contrast enhancement.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        clip_limit (float): Threshold for contrast limiting.
        tile_grid_size (tuple): Size of grid for histogram equalization.

    Returns:
        np.ndarray: Contrast-enhanced RGB image.
    """
    if image.ndim == 2:
        # Grayscale image
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        enhanced = clahe.apply((image * 255).astype(np.uint8))
        return enhanced / 255.0
    elif image.ndim == 3 and image.shape[2] == 3:
        # Convert to LAB color space
        lab = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2LAB)
        # Split the channels
        l, a, b = cv2.split(lab)
        # Apply CLAHE to the L-channel
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        cl = clahe.apply(l)
        # Merge the channels back
        limg = cv2.merge((cl, a, b))
        # Convert back to RGB
        enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB) / 255.0
        return enhanced
    else:
        raise ValueError("Input image must be either grayscale or RGB.")

def apply_average_neutral_scnr(image: np.ndarray, amount: float = 1.0) -> np.ndarray:
    """
    Applies the Average Neutral SCNR method to remove green noise from an RGB image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array with shape (H, W, 3).
                            The image should be normalized to the [0, 1] range.
        amount (float): Blending factor between the original and SCNR-processed image.
                        0.0 returns the original image, 1.0 returns the fully SCNR-processed image.

    Returns:
        np.ndarray: The SCNR-processed RGB image.
    """
    if not isinstance(image, np.ndarray):
        raise TypeError("Input image must be a NumPy array.")

    if image.ndim != 3 or image.shape[2] != 3:
        print(f"apply_average_neutral_scnr received invalid image shape: {image.shape}")
        raise ValueError("Input image must have three channels (RGB).")

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("Input image must have three channels (RGB).")

    if not (0.0 <= amount <= 1.0):
        raise ValueError("Amount parameter must be between 0.0 and 1.0.")

    # Ensure the image is in float format
    image = image.astype(np.float32)

    # Separate the channels
    R, G, B = image[..., 0], image[..., 1], image[..., 2]

    # Apply the Average Neutral SCNR formula: G' = min(G, 0.5*(R + B))
    G_scnr = np.minimum(G, 0.5 * (R + B))

    # Create the SCNR image
    scnr_image = image.copy()
    scnr_image[..., 1] = G_scnr  # Replace the green channel

    # Blend the original and SCNR images based on the amount parameter
    final_image = (1.0 - amount) * image + amount * scnr_image

    # Ensure the final image is still within [0, 1]
    final_image = np.clip(final_image, 0.0, 1.0)

    return final_image


def load_image(filename, max_retries=3, wait_seconds=3):
    """
    Loads an image from the specified filename with support for various formats.
    If a "buffer is too small for requested array" error occurs, it retries loading after waiting.

    Parameters:
        filename (str): Path to the image file.
        max_retries (int): Number of times to retry on specific buffer error.
        wait_seconds (int): Seconds to wait before retrying.

    Returns:
        tuple: (image, original_header, bit_depth, is_mono) or (None, None, None, None) on failure.
    """
    attempt = 0
    while attempt <= max_retries:
        try:
            image = None  # Ensure 'image' is explicitly declared
            bit_depth = None
            is_mono = False
            original_header = None

            if filename.lower().endswith(('.fits', '.fit')):
                print(f"Loading FITS file: {filename}")
                with fits.open(filename) as hdul:
                    image_data = hdul[0].data
                    original_header = hdul[0].header  # Capture the FITS header

                    # Ensure native byte order
                    if image_data.dtype.byteorder not in ('=', '|'):
                        image_data = image_data.astype(image_data.dtype.newbyteorder('='))

                    # Determine bit depth
                    if image_data.dtype == np.uint8:
                        bit_depth = "8-bit"
                        print("Identified 8-bit FITS image.")
                        image = image_data.astype(np.float32) / 255.0
                    elif image_data.dtype == np.uint16:
                        bit_depth = "16-bit"
                        print("Identified 16-bit FITS image.")
                        image = image_data.astype(np.float32) / 65535.0
                    elif image_data.dtype == np.float32:
                        bit_depth = "32-bit floating point"
                        print("Identified 32-bit floating point FITS image.")
                    elif image_data.dtype == np.uint32:
                        bit_depth = "32-bit unsigned"
                        print("Identified 32-bit unsigned FITS image.")
                    else:
                        raise ValueError("Unsupported FITS data type!")

                    # Handle 3D FITS data (e.g., RGB or multi-layered)
                    if image_data.ndim == 3 and image_data.shape[0] == 3:
                        image = np.transpose(image_data, (1, 2, 0))  # Reorder to (height, width, channels)

                        if bit_depth == "8-bit":
                            image = image.astype(np.float32) / 255.0
                        elif bit_depth == "16-bit":
                            image = image.astype(np.float32) / 65535.0
                        elif bit_depth == "32-bit unsigned":
                            bzero = original_header.get('BZERO', 0)
                            bscale = original_header.get('BSCALE', 1)
                            image = image.astype(np.float32) * bscale + bzero

                            # Normalize based on range
                            image_min = image.min()
                            image_max = image.max()
                            image = (image - image_min) / (image_max - image_min)
                        # No normalization needed for 32-bit float
                        is_mono = False

                    # Handle 2D FITS data (grayscale)
                    elif image_data.ndim == 2:
                        if bit_depth == "8-bit":
                            image = image_data.astype(np.float32) / 255.0
                        elif bit_depth == "16-bit":
                            image = image_data.astype(np.float32) / 65535.0
                        elif bit_depth == "32-bit unsigned":
                            bzero = original_header.get('BZERO', 0)
                            bscale = original_header.get('BSCALE', 1)
                            image = image_data.astype(np.float32) * bscale + bzero

                            # Normalize based on range
                            image_min = image.min()
                            image_max = image.max()
                            image = (image - image_min) / (image_max - image_min)
                        elif bit_depth == "32-bit floating point":
                            image = image_data
                        else:
                            raise ValueError("Unsupported FITS data type!")

                        # Mono or RGB handling
                        if image_data.ndim == 2:  # Mono
                            is_mono = True
                            return image, original_header, bit_depth, is_mono
                        elif image_data.ndim == 3 and image_data.shape[0] == 3:  # RGB
                            image = np.transpose(image_data, (1, 2, 0))  # Convert to (H, W, C)
                            is_mono = False
                            return image, original_header, bit_depth, is_mono

                    else:
                        raise ValueError("Unsupported FITS format or dimensions!")

            elif filename.lower().endswith(('.tiff', '.tif')):
                print(f"Loading TIFF file: {filename}")
                image_data = tiff.imread(filename)
                print(f"Loaded TIFF image with dtype: {image_data.dtype}")

                # Determine bit depth and normalize
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    image = image_data.astype(np.float32) / 255.0
                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    image = image_data.astype(np.float32) / 65535.0
                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    image = image_data.astype(np.float32) / 4294967295.0
                elif image_data.dtype == np.float32:
                    bit_depth = "32-bit floating point"
                    image = image_data
                else:
                    raise ValueError("Unsupported TIFF format!")

                # Handle mono or RGB TIFFs
                if image_data.ndim == 2:  # Mono
                    is_mono = True
                elif image_data.ndim == 3 and image_data.shape[2] == 3:  # RGB
                    is_mono = False
                else:
                    raise ValueError("Unsupported TIFF image dimensions!")

            elif filename.lower().endswith('.xisf'):
                print(f"Loading XISF file: {filename}")
                xisf = XISF(filename)

                # Read image data (assuming the first image in the XISF file)
                image_data = xisf.read_image(0)  # Adjust the index if multiple images are present

                # Retrieve metadata
                image_meta = xisf.get_images_metadata()[0]  # Assuming single image
                file_meta = xisf.get_file_metadata()


                # Here we check the maximum pixel value to determine bit depth
                # --- Detect the bit depth by dtype ---
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    print("Debug: Detected 8-bit dtype. Normalizing by 255.")
                    image = image_data.astype(np.float32) / 255.0

                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    print("Debug: Detected 16-bit dtype. Normalizing by 65535.")
                    image = image_data.astype(np.float32) / 65535.0

                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    print("Debug: Detected 32-bit unsigned dtype. Normalizing by 4294967295.")
                    image = image_data.astype(np.float32) / 4294967295.0

                elif image_data.dtype == np.float32 or image_data.dtype == np.float64:
                    bit_depth = "32-bit floating point"
                    print("Debug: Detected float dtype. Casting to float32 (no normalization).")
                    image = image_data.astype(np.float32)

                else:
                    raise ValueError(f"Unsupported XISF data type: {image_data.dtype}")

                # Handle mono or RGB XISF
                if image_data.ndim == 2:
                    # We know it's mono. Already normalized in `image`.
                    is_mono = True
                    # If you really want to store it in an RGB shape:
                    image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 1:
                    # It's mono with shape (H, W, 1)
                    is_mono = True
                    # Squeeze the normalized image, not the original image_data
                    image = np.squeeze(image, axis=2)
                    # If you want an RGB shape, you can do:
                    image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 3:
                    is_mono = False
                    # We already stored the normalized float32 data in `image`.
                    # So no change needed if it’s already shape (H, W, 3).

                else:
                    raise ValueError("Unsupported XISF image dimensions!")

                # For XISF, you can choose what to set as original_header
                # It could be a combination of file_meta and image_meta or any other relevant information
                original_header = {
                    "file_meta": file_meta,
                    "image_meta": image_meta
                }

                print(f"Loaded XISF image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
                return image, original_header, bit_depth, is_mono

            elif filename.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print(f"Loading RAW file: {filename}")
                with rawpy.imread(filename) as raw:
                    # Get the raw Bayer data
                    bayer_image = raw.raw_image_visible.astype(np.float32)
                    print(f"Raw Bayer image dtype: {bayer_image.dtype}, min: {bayer_image.min()}, max: {bayer_image.max()}")

                    # Ensure Bayer image is normalized
                    bayer_image /= bayer_image.max()

                    if bayer_image.ndim == 2:
                        image = bayer_image  # Keep as 2D mono image
                        is_mono = True
                    elif bayer_image.ndim == 3 and bayer_image.shape[2] == 3:
                        image = bayer_image  # Already RGB
                        is_mono = False
                    else:
                        raise ValueError(f"Unexpected RAW Bayer image shape: {bayer_image.shape}")
                    bit_depth = "16-bit"  # Assuming 16-bit raw data
                    is_mono = True

                    # Populate `original_header` with RAW metadata
                    original_header_dict = {
                        'CAMERA': raw.camera_whitebalance[0] if raw.camera_whitebalance else 'Unknown',
                        'EXPTIME': raw.shutter if hasattr(raw, 'shutter') else 0.0,
                        'ISO': raw.iso_speed if hasattr(raw, 'iso_speed') else 0,
                        'FOCAL': raw.focal_len if hasattr(raw, 'focal_len') else 0.0,
                        'DATE': raw.timestamp if hasattr(raw, 'timestamp') else 'Unknown',
                    }

                    # Extract CFA pattern
                    cfa_pattern = raw.raw_colors_visible
                    cfa_mapping = {
                        0: 'R',  # Red
                        1: 'G',  # Green
                        2: 'B',  # Blue
                    }
                    cfa_description = ''.join([cfa_mapping.get(color, '?') for color in cfa_pattern.flatten()[:4]])

                    # Add CFA pattern to header
                    original_header_dict['CFA'] = (cfa_description, 'Color Filter Array pattern')

                    # Convert original_header_dict to fits.Header
                    original_header = fits.Header()
                    for key, value in original_header_dict.items():
                        original_header[key] = value

                    print(f"RAW file loaded with CFA pattern: {cfa_description}")

            elif filename.lower().endswith('.png'):
                print(f"Loading PNG file: {filename}")
                img = Image.open(filename)

                # Convert unsupported modes to RGB
                if img.mode not in ('L', 'RGB'):
                    print(f"Unsupported PNG mode: {img.mode}, converting to RGB")
                    img = img.convert("RGB")

                # Convert image to numpy array and normalize pixel values to [0, 1]
                image = np.array(img, dtype=np.float32) / 255.0
                bit_depth = "8-bit"

                # Determine if the image is grayscale or RGB
                if len(image.shape) == 2:  # Grayscale image
                    is_mono = True
                elif len(image.shape) == 3 and image.shape[2] == 3:  # RGB image
                    is_mono = False
                else:
                    raise ValueError(f"Unsupported PNG dimensions: {image.shape}")

                print(f"Loaded PNG image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")

            elif filename.lower().endswith(('.jpg', '.jpeg')):
                print(f"Loading JPG file: {filename}")
                img = Image.open(filename)
                if img.mode == 'L':  # Grayscale
                    is_mono = True
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                elif img.mode == 'RGB':  # RGB
                    is_mono = False
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                else:
                    raise ValueError("Unsupported JPG format!")            

            else:
                raise ValueError("Unsupported file format!")

            print(f"Loaded image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
            return image, original_header, bit_depth, is_mono

        except Exception as e:
            error_message = str(e)
            if "buffer is too small for requested array" in error_message.lower():
                if attempt < max_retries:
                    attempt += 1
                    print(f"Error reading image {filename}: {e}")
                    print(f"Retrying in {wait_seconds} seconds... (Attempt {attempt}/{max_retries})")
                    time.sleep(wait_seconds)
                    continue  # Retry loading the image
                else:
                    print(f"Error reading image {filename} after {max_retries} retries: {e}")
            else:
                print(f"Error reading image {filename}: {e}")
            return None, None, None, None








def save_image(img_array, filename, original_format, bit_depth=None, original_header=None, is_mono=False, image_meta=None, file_meta=None):
    """
    Save an image array to a file in the specified format and bit depth.
    """
    img_array = ensure_native_byte_order(img_array)  # Ensure correct byte order
    is_xisf = False  # Flag to determine if the original file was XISF

    # **🔹 Detect If Original File Was XISF**
    if original_header:
        for key in original_header.keys():
            if key.startswith("XISF:"):
                is_xisf = True
                break

    if image_meta and "XISFProperties" in image_meta:
        is_xisf = True  # Confirm XISF metadata exists

    try:
        if original_format == 'png':
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit PNG image to: {filename}")
        elif original_format in ['jpg', 'jpeg']:
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit JPG image to: {filename}")        
        elif original_format in ['tiff', 'tif']:
            # Save TIFF files based on bit depth
            if bit_depth == "8-bit":
                tiff.imwrite(filename, (img_array * 255).astype(np.uint8))  # Save as 8-bit TIFF
            elif bit_depth == "16-bit":
                tiff.imwrite(filename, (img_array * 65535).astype(np.uint16))  # Save as 16-bit TIFF
            elif bit_depth == "32-bit unsigned":
                tiff.imwrite(filename, (img_array * 4294967295).astype(np.uint32))  # Save as 32-bit unsigned TIFF
            elif bit_depth == "32-bit floating point":
                tiff.imwrite(filename, img_array.astype(np.float32))  # Save as 32-bit floating point TIFF
            else:
                raise ValueError("Unsupported bit depth for TIFF!")
            print(f"Saved {bit_depth} TIFF image to: {filename}")

        elif original_format in ['fits', 'fit']:
            # Preserve the original extension
            if not filename.lower().endswith(f".{original_format}"):
                filename = filename.rsplit('.', 1)[0] + f".{original_format}"

            # **📌 CASE 1: ORIGINAL FILE WAS XISF → CONVERT TO FITS HEADER**
            if is_xisf:
                print("Detected XISF metadata. Converting to FITS header...")
                fits_header = fits.Header()

                if 'XISFProperties' in image_meta:
                    xisf_props = image_meta['XISFProperties']

                    # Extract WCS parameters
                    if 'PCL:AstrometricSolution:ReferenceCoordinates' in xisf_props:
                        ref_coords = xisf_props['PCL:AstrometricSolution:ReferenceCoordinates']['value']
                        fits_header['CRVAL1'] = ref_coords[0]
                        fits_header['CRVAL2'] = ref_coords[1]

                    if 'PCL:AstrometricSolution:ReferenceLocation' in xisf_props:
                        ref_pixel = xisf_props['PCL:AstrometricSolution:ReferenceLocation']['value']
                        fits_header['CRPIX1'] = ref_pixel[0]
                        fits_header['CRPIX2'] = ref_pixel[1]

                    if 'PCL:AstrometricSolution:PixelSize' in xisf_props:
                        pixel_size = xisf_props['PCL:AstrometricSolution:PixelSize']['value']
                        fits_header['CDELT1'] = -pixel_size / 3600.0
                        fits_header['CDELT2'] = pixel_size / 3600.0

                    if 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_props:
                        linear_transform = xisf_props['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        fits_header['CD1_1'] = linear_transform[0][0]
                        fits_header['CD1_2'] = linear_transform[0][1]
                        fits_header['CD2_1'] = linear_transform[1][0]
                        fits_header['CD2_2'] = linear_transform[1][1]

                # Ensure essential WCS headers exist
                fits_header.setdefault('CTYPE1', 'RA---TAN')
                fits_header.setdefault('CTYPE2', 'DEC--TAN')

                print("Converted XISF metadata to FITS header.")

            # **📌 CASE 2: ORIGINAL FILE WAS FITS → PRESERVE HEADER**
            elif original_header is not None:
                print("Detected FITS format. Preserving original FITS header.")
                fits_header = fits.Header()
                for key, value in original_header.items():
                    if key.startswith("XISF:"):
                        continue  # Skip XISF metadata

                    if key in ["RANGE_LOW", "RANGE_HIGH"]:
                        print(f"Removing {key} from header to prevent overflow.")
                        continue  # Skip adding RANGE_LOW and RANGE_HIGH

                    if isinstance(value, dict) and 'value' in value:
                        value = value['value']

                    try:
                        fits_header[key] = value
                    except Exception as e:
                        print(f"Skipping problematic key {key} due to error: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

            # **📌 Image Processing for FITS**
            fits_header['BSCALE'] = 1.0
            fits_header['BZERO'] = 0.0

            if is_mono or img_array.ndim == 2:
                img_array_fits = img_array[:, :, 0] if len(img_array.shape) == 3 else img_array
                fits_header['NAXIS'] = 2
            else:
                img_array_fits = np.transpose(img_array, (2, 0, 1))
                fits_header['NAXIS'] = 3
                fits_header['NAXIS3'] = 3

            fits_header['NAXIS1'] = img_array.shape[1]
            fits_header['NAXIS2'] = img_array.shape[0]

            # **💾 Save the FITS File**
            hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
            hdu.writeto(filename, overwrite=True)
            print(f"Saved FITS image to: {filename}")
            return



        elif original_format in ['.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef']:
            # Save as FITS file with metadata
            print("RAW formats are not writable. Saving as FITS instead.")
            filename = filename.rsplit('.', 1)[0] + ".fits"

            if original_header is not None:
                # Convert original_header (dictionary) to astropy Header object
                fits_header = fits.Header()
                for key, value in original_header.items():
                    fits_header[key] = value
                fits_header['BSCALE'] = 1.0  # Scaling factor
                fits_header['BZERO'] = 0.0   # Offset for brightness    

                if is_mono:  # Grayscale FITS
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array[:, :, 0] * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = (img_array[:, :, 0].astype(np.float32) * bscale + bzero).astype(np.uint32)
                    else:  # 32-bit float
                        img_array_fits = img_array[:, :, 0].astype(np.float32)

                    # Update header for a 2D (grayscale) image
                    fits_header['NAXIS'] = 2
                    fits_header['NAXIS1'] = img_array.shape[1]  # Width
                    fits_header['NAXIS2'] = img_array.shape[0]  # Height
                    fits_header.pop('NAXIS3', None)  # Remove if present

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
                else:  # RGB FITS
                    img_array_transposed = np.transpose(img_array, (2, 0, 1))  # Channels, Height, Width
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array_transposed * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = img_array_transposed.astype(np.float32) * bscale + bzero
                        fits_header['BITPIX'] = -32
                    else:  # Default to 32-bit float
                        img_array_fits = img_array_transposed.astype(np.float32)

                    # Update header for a 3D (RGB) image
                    fits_header['NAXIS'] = 3
                    fits_header['NAXIS1'] = img_array_transposed.shape[2]  # Width
                    fits_header['NAXIS2'] = img_array_transposed.shape[1]  # Height
                    fits_header['NAXIS3'] = img_array_transposed.shape[0]  # Channels

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)

                # Write the FITS file
                try:
                    hdu.writeto(filename, overwrite=True)
                    print(f"RAW processed and saved as FITS to: {filename}")
                except Exception as e:
                    print(f"Error saving FITS file: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

        elif original_format == 'xisf':
            try:
                print(f"Original image shape: {img_array.shape}, dtype: {img_array.dtype}")
                print(f"Bit depth: {bit_depth}")

                # Adjust bit depth for saving
                if bit_depth == "16-bit":
                    processed_image = (img_array * 65535).astype(np.uint16)
                elif bit_depth == "32-bit unsigned":
                    processed_image = (img_array * 4294967295).astype(np.uint32)
                else:  # Default to 32-bit float
                    processed_image = img_array.astype(np.float32)

                # Handle mono images explicitly
                if is_mono:
                    print("Detected mono image. Preparing for XISF...")
                    if processed_image.ndim == 3 and processed_image.shape[2] > 1:
                        processed_image = processed_image[:, :, 0]  # Extract single channel
                    processed_image = processed_image[:, :, np.newaxis]  # Add back channel dimension

                    # Update metadata for mono images
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], 1)
                        image_meta[0]['colorSpace'] = 'Gray'
                    else:
                        # Create default metadata for mono images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], 1),
                            'colorSpace': 'Gray'
                        }]

                # Handle RGB images
                else:
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2])
                        image_meta[0]['colorSpace'] = 'RGB'
                    else:
                        # Create default metadata for RGB images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2]),
                            'colorSpace': 'RGB'
                        }]

                # Ensure fallback for `image_meta` and `file_meta`
                if image_meta is None or not isinstance(image_meta, list):
                    image_meta = [{
                        'geometry': (processed_image.shape[1], processed_image.shape[0], 1 if is_mono else 3),
                        'colorSpace': 'Gray' if is_mono else 'RGB'
                    }]
                if file_meta is None:
                    file_meta = {}

                # Debug: Print processed image details and metadata
                print(f"Processed image shape for XISF: {processed_image.shape}, dtype: {processed_image.dtype}")

                # Save the image using XISF.write
                XISF.write(
                    filename,                    # Output path
                    processed_image,             # Final processed image
                    creator_app="Seti Astro Cosmic Clarity",
                    image_metadata=image_meta[0],  # First block of image metadata
                    xisf_metadata=file_meta,       # File-level metadata
                    shuffle=True
                )

                print(f"Saved {bit_depth} XISF image to: {filename}")

            except Exception as e:
                print(f"Error saving XISF file: {e}")
                raise


        else:
            raise ValueError("Unsupported file format!")

    except Exception as e:
        print(f"Error saving image to {filename}: {e}")
        raise




def stretch_mono_image(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Stretches a single-channel (2D) image so that its median ends up near `target_median`.
    Uses the old formula, but with the final math done in a Numba function.
    """
    # 1) Compute black_point from old logic
    black_point = max(np.min(image), np.median(image) - 2.7 * np.std(image))

    # 2) Rescale in Python
    #    r = (val - black_point) / (1 - black_point)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Compute median of *this* rescaled data
    median_rescaled = np.median(rescaled_image)

    # 4) Final stretch in Numba
    stretched_image = numba_mono_final_formula(rescaled_image, median_rescaled, target_median)

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    # 7) Clip result [0..1]
    return np.clip(stretched_image, 0, 1)

def stretch_color_image(image, target_median, linked=True,
                        normalize=False, apply_curves=False, curves_boost=0.0):
    # If image is mono or single-channel, treat as mono
    if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
        mono = image.squeeze()
        mono_stretched = stretch_mono_image(mono, target_median,
                                            normalize=normalize,
                                            apply_curves=apply_curves,
                                            curves_boost=curves_boost)
        # Replicate into 3 channels if you want a 3-channel result
        return np.stack([mono_stretched] * 3, axis=-1)

    # If it's actually color (H, W, 3):
    if linked:
        stretched_image = stretch_color_image_linked(image, target_median,
                                                     normalize=normalize,
                                                     apply_curves=apply_curves,
                                                     curves_boost=curves_boost)
    else:
        stretched_image = stretch_color_image_unlinked(image, target_median,
                                                       normalize=normalize,
                                                       apply_curves=apply_curves,
                                                       curves_boost=curves_boost)
    return stretched_image

def stretch_color_image_linked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Linked color stretch: uses one black_point and one median for all channels.
    """
    # 1) Compute black_point from the combined median, std
    combined_median = np.median(image)
    combined_std = np.std(image)
    black_point = max(np.min(image), combined_median - 2.7 * combined_std)

    # 2) Rescale
    #    (H, W, 3)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Median of the entire rescaled array
    median_rescaled = np.median(rescaled_image)

    # 4) Final formula in Numba
    stretched_image = numba_color_final_formula_linked(
        rescaled_image, 
        median_rescaled, 
        target_median
    )

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)

def stretch_color_image_unlinked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Unlinked color stretch: each channel has its own black_point, own median.
    """
    H, W, _ = image.shape
    rescaled_image = np.zeros_like(image, dtype=np.float32)
    black_points = np.zeros(3, dtype=np.float32)
    medians_rescaled = np.zeros(3, dtype=np.float32)

    # 1) For each channel, compute black point, rescale, find median
    for c in range(3):
        channel = image[..., c]
        channel_median = np.median(channel)
        channel_std = np.std(channel)
        bp = max(channel.min(), channel_median - 2.7 * channel_std)

        # Store black point
        black_points[c] = bp

        # Rescale that channel
        denom_bp = 1.0 - bp
        rescaled_image[..., c] = (channel - bp) / denom_bp

    # 2) For each channel, compute median of the rescaled version
    for c in range(3):
        medians_rescaled[c] = np.median(rescaled_image[..., c])

    # 3) Final formula in Numba
    stretched_image = numba_color_final_formula_unlinked(
        rescaled_image,
        medians_rescaled,
        target_median
    )

    # 4) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 5) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)



def apply_curves_adjustment(image, target_median, curves_boost):
    """
    Original signature unchanged, but now uses a Numba helper
    to do the pixel-by-pixel interpolation.

    'image' can be 2D (H,W) or 3D (H,W,3).
    """
    # Build the curve array as before
    curve = [
        [0.0, 0.0],
        [0.5 * target_median, 0.5 * target_median],
        [target_median, target_median],
        [
            (1/4 * (1 - target_median) + target_median),
            np.power((1/4 * (1 - target_median) + target_median), (1 - curves_boost))
        ],
        [
            (3/4 * (1 - target_median) + target_median),
            np.power(np.power((3/4 * (1 - target_median) + target_median), (1 - curves_boost)), (1 - curves_boost))
        ],
        [1.0, 1.0]
    ]
    # Convert to arrays
    xvals = np.array([p[0] for p in curve], dtype=np.float32)
    yvals = np.array([p[1] for p in curve], dtype=np.float32)

    # Ensure 'image' is float32
    image_32 = image.astype(np.float32, copy=False)

    # Now apply the piecewise linear function in Numba
    adjusted_image = apply_curves_numba(image_32, xvals, yvals)
    return adjusted_image

def resource_path(relative_path):
    """ Get the absolute path to the resource, works for dev and for PyInstaller """
    try:
        # PyInstaller creates a temporary folder and stores path in _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)

def ensure_native_byte_order(array):
    """
    Ensures that the array is in the native byte order.
    If the array is in a non-native byte order, it will convert it.
    """
    if array.dtype.byteorder == '=':  # Already in native byte order
        return array
    elif array.dtype.byteorder in ('<', '>'):  # Non-native byte order
        return array.byteswap().view(array.dtype.newbyteorder('='))
    return array



# Determine if running inside a PyInstaller bundle
if hasattr(sys, '_MEIPASS'):
    # Set path for PyInstaller bundle
    data_path = os.path.join(sys._MEIPASS, "astroquery", "simbad", "data")
else:
    # Set path for regular Python environment
    data_path = "/home/setiastroadmin/Desktop/cosmicclarity/env/lib/python3.8/site-packages/astroquery/simbad/data"

# Ensure the final path doesn't contain 'data/data' duplication
if 'data/data' in data_path:
    data_path = data_path.replace('data/data', 'data')

conf.dataurl = f'file://{data_path}/'

# Access wrench_icon.png, adjusting for PyInstaller executable
if hasattr(sys, '_MEIPASS'):
    wrench_path = os.path.join(sys._MEIPASS, 'wrench_icon.png')
    eye_icon_path = os.path.join(sys._MEIPASS, 'eye.png')
    disk_icon_path = os.path.join(sys._MEIPASS, 'disk.png')
    nuke_path = os.path.join(sys._MEIPASS, 'nuke.png')  
    hubble_path = os.path.join(sys._MEIPASS, 'hubble.png') 
    collage_path = os.path.join(sys._MEIPASS, 'collage.png') 
    annotated_path = os.path.join(sys._MEIPASS, 'annotated.png') 
    colorwheel_path = os.path.join(sys._MEIPASS, 'colorwheel.png')
    font_path = os.path.join(sys._MEIPASS, 'font.png')
    csv_icon_path = os.path.join(sys._MEIPASS, 'cvs.png')
else:
    wrench_path = 'wrench_icon.png'  # Path for running as a script
    eye_icon_path = 'eye.png'  # Path for running as a script
    disk_icon_path = 'disk.png'   
    nuke_path = 'nuke.png' 
    hubble_path = 'hubble.png'
    collage_path = 'collage.png'
    annotated_path = 'annotated.png'
    colorwheel_path = 'colorwheel.png'
    font_path = 'font.png'
    csv_icon_path = 'cvs.png'

# Constants for comoving radial distance calculation
H0 = 69.6  # Hubble constant in km/s/Mpc
WM = 0.286  # Omega(matter)
WV = 0.714  # Omega(vacuum)
c = 299792.458  # speed of light in km/s
Tyr = 977.8  # coefficient to convert 1/H into Gyr
Mpc_to_Gly = 3.262e-3  # Conversion from Mpc to Gly

otype_long_name_lookup = {
    "ev": "transient event",
    "Rad": "Radio-source",
    "mR": "metric Radio-source",
    "cm": "centimetric Radio-source",
    "mm": "millimetric Radio-source",
    "smm": "sub-millimetric source",
    "HI": "HI (21cm) source",
    "rB": "radio Burst",
    "Mas": "Maser",
    "IR": "Infra-Red source",
    "FIR": "Far-Infrared source",
    "MIR": "Mid-Infrared source",
    "NIR": "Near-Infrared source",
    "blu": "Blue object",
    "UV": "UV-emission source",
    "X": "X-ray source",
    "UX?": "Ultra-luminous X-ray candidate",
    "ULX": "Ultra-luminous X-ray source",
    "gam": "gamma-ray source",
    "gB": "gamma-ray Burst",
    "err": "Not an object (error, artefact, ...)",
    "grv": "Gravitational Source",
    "Lev": "(Micro)Lensing Event",
    "LS?": "Possible gravitational lens System",
    "Le?": "Possible gravitational lens",
    "LI?": "Possible gravitationally lensed image",
    "gLe": "Gravitational Lens",
    "gLS": "Gravitational Lens System (lens+images)",
    "GWE": "Gravitational Wave Event",
    "..?": "Candidate objects",
    "G?": "Possible Galaxy",
    "SC?": "Possible Supercluster of Galaxies",
    "C?G": "Possible Cluster of Galaxies",
    "Gr?": "Possible Group of Galaxies",
    "**?": "Physical Binary Candidate",
    "EB?": "Eclipsing Binary Candidate",
    "Sy?": "Symbiotic Star Candidate",
    "CV?": "Cataclysmic Binary Candidate",
    "No?": "Nova Candidate",
    "XB?": "X-ray binary Candidate",
    "LX?": "Low-Mass X-ray binary Candidate",
    "HX?": "High-Mass X-ray binary Candidate",
    "Pec?": "Possible Peculiar Star",
    "Y*?": "Young Stellar Object Candidate",
    "TT?": "T Tau star Candidate",
    "C*?": "Possible Carbon Star",
    "S*?": "Possible S Star",
    "OH?": "Possible Star with envelope of OH/IR type",
    "WR?": "Possible Wolf-Rayet Star",
    "Be?": "Possible Be Star",
    "Ae?": "Possible Herbig Ae/Be Star",
    "HB?": "Possible Horizontal Branch Star",
    "RR?": "Possible Star of RR Lyr type",
    "Ce?": "Possible Cepheid",
    "WV?": "Possible Variable Star of W Vir type",
    "RB?": "Possible Red Giant Branch star",
    "sg?": "Possible Supergiant star",
    "s?r": "Possible Red supergiant star",
    "s?y": "Possible Yellow supergiant star",
    "s?b": "Possible Blue supergiant star",
    "AB?": "Asymptotic Giant Branch Star candidate",
    "LP?": "Long Period Variable candidate",
    "Mi?": "Mira candidate",
    "pA?": "Post-AGB Star Candidate",
    "BS?": "Candidate blue Straggler Star",
    "HS?": "Hot subdwarf candidate",
    "WD?": "White Dwarf Candidate",
    "N*?": "Neutron Star Candidate",
    "BH?": "Black Hole Candidate",
    "SN?": "SuperNova Candidate",
    "LM?": "Low-mass star candidate",
    "BD?": "Brown Dwarf Candidate",
    "mul": "Composite object",
    "reg": "Region defined in the sky",
    "vid": "Underdense region of the Universe",
    "SCG": "Supercluster of Galaxies",
    "ClG": "Cluster of Galaxies",
    "GrG": "Group of Galaxies",
    "CGG": "Compact Group of Galaxies",
    "PaG": "Pair of Galaxies",
    "IG": "Interacting Galaxies",
    "C?*": "Possible (open) star cluster",
    "Gl?": "Possible Globular Cluster",
    "Cl*": "Cluster of Stars",
    "GlC": "Globular Cluster",
    "OpC": "Open (galactic) Cluster",
    "As*": "Association of Stars",
    "St*": "Stellar Stream",
    "MGr": "Moving Group",
    "**": "Double or multiple star",
    "EB*": "Eclipsing binary",
    "Al*": "Eclipsing binary of Algol type",
    "bL*": "Eclipsing binary of beta Lyr type",
    "WU*": "Eclipsing binary of W UMa type",
    "SB*": "Spectroscopic binary",
    "El*": "Ellipsoidal variable Star",
    "Sy*": "Symbiotic Star",
    "CV*": "Cataclysmic Variable Star",
    "DQ*": "CV DQ Her type (intermediate polar)",
    "AM*": "CV of AM Her type (polar)",
    "NL*": "Nova-like Star",
    "No*": "Nova",
    "DN*": "Dwarf Nova",
    "XB*": "X-ray Binary",
    "LXB": "Low Mass X-ray Binary",
    "HXB": "High Mass X-ray Binary",
    "ISM": "Interstellar matter",
    "PoC": "Part of Cloud",
    "PN?": "Possible Planetary Nebula",
    "CGb": "Cometary Globule",
    "bub": "Bubble",
    "EmO": "Emission Object",
    "Cld": "Cloud",
    "GNe": "Galactic Nebula",
    "DNe": "Dark Cloud (nebula)",
    "RNe": "Reflection Nebula",
    "MoC": "Molecular Cloud",
    "glb": "Globule (low-mass dark cloud)",
    "cor": "Dense core",
    "SFR": "Star forming region",
    "HVC": "High-velocity Cloud",
    "HII": "HII (ionized) region",
    "PN": "Planetary Nebula",
    "sh": "HI shell",
    "SR?": "SuperNova Remnant Candidate",
    "SNR": "SuperNova Remnant",
    "of?": "Outflow candidate",
    "out": "Outflow",
    "HH": "Herbig-Haro Object",
    "*": "Star",
    "V*?": "Star suspected of Variability",
    "Pe*": "Peculiar Star",
    "HB*": "Horizontal Branch Star",
    "Y*O": "Young Stellar Object",
    "Ae*": "Herbig Ae/Be star",
    "Em*": "Emission-line Star",
    "Be*": "Be Star",
    "BS*": "Blue Straggler Star",
    "RG*": "Red Giant Branch star",
    "AB*": "Asymptotic Giant Branch Star (He-burning)",
    "C*": "Carbon Star",
    "S*": "S Star",
    "sg*": "Evolved supergiant star",
    "s*r": "Red supergiant star",
    "s*y": "Yellow supergiant star",
    "s*b": "Blue supergiant star",
    "HS*": "Hot subdwarf",
    "pA*": "Post-AGB Star (proto-PN)",
    "WD*": "White Dwarf",
    "LM*": "Low-mass star (M<1solMass)",
    "BD*": "Brown Dwarf (M<0.08solMass)",
    "N*": "Confirmed Neutron Star",
    "OH*": "OH/IR star",
    "TT*": "T Tau-type Star",
    "WR*": "Wolf-Rayet Star",
    "PM*": "High proper-motion Star",
    "HV*": "High-velocity Star",
    "V*": "Variable Star",
    "Ir*": "Variable Star of irregular type",
    "Or*": "Variable Star of Orion Type",
    "Er*": "Eruptive variable Star",
    "RC*": "Variable Star of R CrB type",
    "RC?": "Variable Star of R CrB type candidate",
    "Ro*": "Rotationally variable Star",
    "a2*": "Variable Star of alpha2 CVn type",
    "Psr": "Pulsar",
    "BY*": "Variable of BY Dra type",
    "RS*": "Variable of RS CVn type",
    "Pu*": "Pulsating variable Star",
    "RR*": "Variable Star of RR Lyr type",
    "Ce*": "Cepheid variable Star",
    "dS*": "Variable Star of delta Sct type",
    "RV*": "Variable Star of RV Tau type",
    "WV*": "Variable Star of W Vir type",
    "bC*": "Variable Star of beta Cep type",
    "cC*": "Classical Cepheid (delta Cep type)",
    "gD*": "Variable Star of gamma Dor type",
    "SX*": "Variable Star of SX Phe type (subdwarf)",
    "LP*": "Long-period variable star",
    "Mi*": "Variable Star of Mira Cet type",
    "SN*": "SuperNova",
    "su*": "Sub-stellar object",
    "Pl?": "Extra-solar Planet Candidate",
    "Pl": "Extra-solar Confirmed Planet",
    "G": "Galaxy",
    "PoG": "Part of a Galaxy",
    "GiC": "Galaxy in Cluster of Galaxies",
    "BiC": "Brightest galaxy in a Cluster (BCG)",
    "GiG": "Galaxy in Group of Galaxies",
    "GiP": "Galaxy in Pair of Galaxies",
    "rG": "Radio Galaxy",
    "H2G": "HII Galaxy",
    "LSB": "Low Surface Brightness Galaxy",
    "AG?": "Possible Active Galaxy Nucleus",
    "Q?": "Possible Quasar",
    "Bz?": "Possible Blazar",
    "BL?": "Possible BL Lac",
    "EmG": "Emission-line galaxy",
    "SBG": "Starburst Galaxy",
    "bCG": "Blue compact Galaxy",
    "LeI": "Gravitationally Lensed Image",
    "LeG": "Gravitationally Lensed Image of a Galaxy",
    "LeQ": "Gravitationally Lensed Image of a Quasar",
    "AGN": "Active Galaxy Nucleus",
    "LIN": "LINER-type Active Galaxy Nucleus",
    "SyG": "Seyfert Galaxy",
    "Sy1": "Seyfert 1 Galaxy",
    "Sy2": "Seyfert 2 Galaxy",
    "Bla": "Blazar",
    "BLL": "BL Lac - type object",
    "OVV": "Optically Violently Variable object",
    "QSO": "Quasar"
}


# Configure Simbad to include the necessary fields, including redshift
Simbad.add_votable_fields('otype', 'otypes', 'diameter', 'z_value')
Simbad.ROW_LIMIT = 0  # Remove row limit for full results
Simbad.TIMEOUT = 60  # Increase timeout for long queries

# Astrometry.net API constants
ASTROMETRY_API_URL = "http://nova.astrometry.net/api/"
ASTROMETRY_API_KEY_FILE = "astrometry_api_key.txt"


settings = QSettings("Seti Astro", "Seti Astro Suite")

def save_api_key(api_key):
    settings.setValue("astrometry_api_key", api_key)  # Save to QSettings
    print("API key saved.")

def load_api_key():
    api_key = settings.value("astrometry_api_key", "")  # Load from QSettings
    if api_key:
        print("API key loaded.")
    return api_key




class CustomGraphicsView(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.setMouseTracking(True)  # Enable mouse tracking
        self.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable default drag mode to avoid hand cursor
        self.setCursor(Qt.CursorShape.ArrowCursor)  # Set default cursor to arrow
        self.drawing_item = None
        self.start_pos = None     
        self.annotation_items = []  # Store annotation items  
        self.drawing_measurement = False
        self.measurement_start = QPointF()    
         

        self.selected_object = None  # Initialize selected_object to None
        self.show_names = False 

        # Variables for drawing the circle
        self.circle_center = None
        self.circle_radius = 0
        self.drawing_circle = False  # Flag to check if we're currently drawing a circle
        self.dragging = False  # Flag to manage manual dragging


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            if event.modifiers() == Qt.KeyboardModifier.ControlModifier:
                # Start annotation mode with the current tool
                self.start_pos = self.mapToScene(event.pos())

                # Check which tool is currently selected
                if self.parent.current_tool == "Ellipse":
                    self.drawing_item = QGraphicsEllipseItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Rectangle":
                    self.drawing_item = QGraphicsRectItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Arrow":
                    self.drawing_item = QGraphicsLineItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Freehand":
                    self.drawing_item = QGraphicsPathItem()
                    path = QPainterPath(self.start_pos)
                    self.drawing_item.setPath(path)
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Text":
                    text, ok = QInputDialog.getText(self, "Add Text", "Enter text:")
                    if ok and text:
                        text_item = QGraphicsTextItem(text)
                        text_item.setPos(self.start_pos)
                        text_item.setDefaultTextColor(self.parent.selected_color)  # Use selected color
                        text_item.setFont(self.parent.selected_font)  # Use selected font
                        self.parent.main_scene.addItem(text_item)
                        
                        # Store as ('text', text, position, color)
                        self.annotation_items.append(('text', text, self.start_pos, self.parent.selected_color))


                elif self.parent.current_tool == "Compass":
                    self.place_celestial_compass(self.start_pos)

            elif event.modifiers() == Qt.KeyboardModifier.ShiftModifier:
                # Start drawing a circle for Shift+Click
                self.drawing_circle = True
                self.circle_center = self.mapToScene(event.pos())
                self.circle_radius = 0
                self.parent.status_label.setText("Drawing circle: Shift + Drag")
                self.update_circle()

            elif event.modifiers() == Qt.KeyboardModifier.AltModifier:
                # Start celestial measurement for Alt+Click
                self.measurement_start = self.mapToScene(event.pos())
                self.drawing_measurement = True
                self.drawing_item = None  # Clear any active annotation item
    

            else:
                # Detect if an object circle was clicked without Shift or Ctrl
                scene_pos = self.mapToScene(event.pos())
                clicked_object = self.get_object_at_position(scene_pos)
                
                if clicked_object:
                    # Select the clicked object and redraw
                    self.parent.selected_object = clicked_object
                    self.select_object(clicked_object)
                    self.draw_query_results()
                    self.update_mini_preview()
                    
                    # Highlight the corresponding row in the TreeWidget
                    for i in range(self.parent.results_tree.topLevelItemCount()):
                        item = self.parent.results_tree.topLevelItem(i)
                        if item.text(2) == clicked_object["name"]:  # Assuming third element is 'Name'
                            self.parent.results_tree.setCurrentItem(item)
                            break
                else:
                    # Start manual dragging if no modifier is held
                    self.dragging = True
                    self.setCursor(Qt.CursorShape.ClosedHandCursor)  # Use closed hand cursor to indicate dragging
                    self.drag_start_pos = event.pos()  # Store starting position

        super().mousePressEvent(event)


    def mouseDoubleClickEvent(self, event):
        """Handle double-click event on an object in the main image to open SIMBAD or NED URL based on source."""
        scene_pos = self.mapToScene(event.pos())
        clicked_object = self.get_object_at_position(scene_pos)

        if clicked_object:
            object_name = clicked_object.get("name")  # Access 'name' key from the dictionary
            ra = float(clicked_object.get("ra"))  # Ensure RA is a float for precision
            dec = float(clicked_object.get("dec"))  # Ensure Dec is a float for precision
            source = clicked_object.get("source", "Simbad")  # Default to "Simbad" if source not specified

            if source == "Simbad" and object_name:
                # Open Simbad URL with encoded object name
                encoded_name = quote(object_name)
                url = f"https://simbad.cds.unistra.fr/simbad/sim-basic?Ident={encoded_name}&submit=SIMBAD+search"
                webbrowser.open(url)
            elif source == "Vizier":
                # Format the NED search URL with proper RA, Dec, and radius
                radius = 5 / 60  # Radius in arcminutes (5 arcseconds)
                dec_sign = "%2B" if dec >= 0 else "-"  # Determine sign for declination
                ned_url = (
                    f"http://ned.ipac.caltech.edu/conesearch?search_type=Near%20Position%20Search"
                    f"&ra={ra:.6f}d&dec={dec_sign}{abs(dec):.6f}d&radius={radius:.3f}"
                    "&in_csys=Equatorial&in_equinox=J2000.0"
                )
                webbrowser.open(ned_url)
            elif source == "Mast":
                # Open MAST URL using RA and Dec with a small radius for object lookup
                mast_url = f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
                webbrowser.open(mast_url)                
        else:
            super().mouseDoubleClickEvent(event)

    def mouseMoveEvent(self, event):
        scene_pos = self.mapToScene(event.pos())

        if self.drawing_circle:
            # Update the circle radius as the mouse moves
            self.circle_radius = np.sqrt(
                (scene_pos.x() - self.circle_center.x()) ** 2 +
                (scene_pos.y() - self.circle_center.y()) ** 2
            )
            self.update_circle()

        elif self.drawing_measurement:
            # Update the measurement line dynamically as the mouse moves
            if self.drawing_item:
                self.parent.main_scene.removeItem(self.drawing_item)  # Remove previous line if exists
            self.drawing_item = QGraphicsLineItem(QLineF(self.measurement_start, scene_pos))
            self.drawing_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))  # Use green dashed line for measurement
            self.parent.main_scene.addItem(self.drawing_item)

        elif self.drawing_item:
            # Update the current drawing item based on the selected tool and mouse position
            if isinstance(self.drawing_item, QGraphicsEllipseItem) and self.parent.current_tool == "Ellipse":
                # For Ellipse tool, update the ellipse dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsRectItem) and self.parent.current_tool == "Rectangle":
                # For Rectangle tool, update the rectangle dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsLineItem) and self.parent.current_tool == "Arrow":
                # For Arrow tool, set the line from start_pos to current mouse position
                line = QLineF(self.start_pos, scene_pos)
                self.drawing_item.setLine(line)

            elif isinstance(self.drawing_item, QGraphicsPathItem) and self.parent.current_tool == "Freehand":
                # For Freehand tool, add a line to the path to follow the mouse movement
                path = self.drawing_item.path()
                path.lineTo(scene_pos)
                self.drawing_item.setPath(path)

        elif self.dragging:
            # Handle manual dragging by scrolling the view
            delta = event.pos() - self.drag_start_pos
            self.horizontalScrollBar().setValue(self.horizontalScrollBar().value() - delta.x())
            self.verticalScrollBar().setValue(self.verticalScrollBar().value() - delta.y())
            self.drag_start_pos = event.pos()
        else:
            # Update RA/Dec display as the cursor moves
            self.parent.update_ra_dec_from_mouse(event)
            
        super().mouseMoveEvent(event)
                

    def mouseReleaseEvent(self, event):
        if self.drawing_circle and event.button() == Qt.MouseButton.LeftButton:
            # Stop drawing the circle
            self.drawing_circle = False
            self.parent.circle_center = self.circle_center
            self.parent.circle_radius = self.circle_radius

            # Calculate RA/Dec for the circle center
            ra, dec = self.parent.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            if ra is not None and dec is not None:
                self.parent.ra_label.setText(f"RA: {self.parent.convert_ra_to_hms(ra)}")
                self.parent.dec_label.setText(f"Dec: {self.parent.convert_dec_to_dms(dec)}")

                if self.parent.pixscale:
                    radius_arcmin = self.circle_radius * self.parent.pixscale / 60.0
                    self.parent.status_label.setText(
                        f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
                    )
                else:
                    self.parent.status_label.setText("Pixscale not available for radius calculation.")
            else:
                self.parent.status_label.setText("Unable to determine RA/Dec due to missing WCS.")

            # Update circle data and redraw
            self.parent.update_circle_data()
            self.update_circle()

        elif self.drawing_measurement and event.button() == Qt.MouseButton.LeftButton:
            # Complete the measurement when the mouse is released
            self.drawing_measurement = False
            measurement_end = self.mapToScene(event.pos())

            # Calculate celestial distance between start and end points
            ra1, dec1 = self.parent.calculate_ra_dec_from_pixel(self.measurement_start.x(), self.measurement_start.y())
            ra2, dec2 = self.parent.calculate_ra_dec_from_pixel(measurement_end.x(), measurement_end.y())
            
            if ra1 is not None and dec1 is not None and ra2 is not None and dec2 is not None:
                # Compute the angular distance
                angular_distance = self.parent.calculate_angular_distance(ra1, dec1, ra2, dec2)
                distance_text = self.parent.format_distance_as_dms(angular_distance)

                # Create and add the line item for display
                measurement_line_item = QGraphicsLineItem(QLineF(self.measurement_start, measurement_end))
                measurement_line_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))
                self.parent.main_scene.addItem(measurement_line_item)

                # Create a midpoint position for the distance text
                midpoint = QPointF(
                    (self.measurement_start.x() + measurement_end.x()) / 2,
                    (self.measurement_start.y() + measurement_end.y()) / 2
                )

                # Create and add the text item at the midpoint
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(midpoint)
                text_item.setDefaultTextColor(Qt.GlobalColor.green)
                text_item.setFont(self.parent.selected_font)  # Use the selected font
                self.parent.main_scene.addItem(text_item)

                # Store the line and text in annotation items for future reference
                measurement_line = QLineF(self.measurement_start, measurement_end)
                self.annotation_items.append(('line', measurement_line))  # Store QLineF, not QGraphicsLineItem
                self.annotation_items.append(('text', distance_text, midpoint, Qt.GlobalColor.green))

            # Clear the temporary measurement line item without removing the final line
            self.drawing_item = None



        elif self.drawing_item and event.button() == Qt.MouseButton.LeftButton:
            # Finalize the shape drawing and add its properties to annotation_items
            if isinstance(self.drawing_item, QGraphicsEllipseItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('ellipse', rect, color))
            elif isinstance(self.drawing_item, QGraphicsRectItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('rect', rect, color))
            elif isinstance(self.drawing_item, QGraphicsLineItem):
                line = self.drawing_item.line()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('line', line, color))
            elif isinstance(self.drawing_item, QGraphicsTextItem):
                pos = self.drawing_item.pos()
                text = self.drawing_item.toPlainText()
                color = self.drawing_item.defaultTextColor()
                self.annotation_items.append(('text', pos, text, color))
            elif isinstance(self.drawing_item, QGraphicsPathItem):  # Handle Freehand
                path = self.drawing_item.path()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('freehand', path, color))        

            # Clear the temporary drawing item
            self.drawing_item = None

        # Stop manual dragging and reset cursor to arrow
        self.dragging = False
        self.setCursor(Qt.CursorShape.ArrowCursor)
        
        # Update the mini preview to reflect any changes
        self.update_mini_preview()

        super().mouseReleaseEvent(event)


    def draw_measurement_line_and_label(self, distance_ddmmss):
        """Draw the measurement line and label with the celestial distance."""
        # Draw line
        line_item = QGraphicsLineItem(
            QLineF(self.measurement_start, self.measurement_end)
        )
        line_item.setPen(QPen(QColor(0, 255, 255), 2))  # Cyan color for measurement
        self.parent.main_scene.addItem(line_item)

        # Place distance text at the midpoint of the line
        midpoint = QPointF(
            (self.measurement_start.x() + self.measurement_end.x()) / 2,
            (self.measurement_start.y() + self.measurement_end.y()) / 2
        )
        text_item = QGraphicsTextItem(distance_ddmmss)
        text_item.setDefaultTextColor(QColor(0, 255, 255))  # Same color as line
        text_item.setPos(midpoint)
        self.parent.main_scene.addItem(text_item)
        
        # Append both line and text to annotation_items
        self.annotation_items.append(('line', line_item))
        self.annotation_items.append(('text', midpoint, distance_ddmmss, QColor(0, 255, 255)))


    
    def wheelEvent(self, event):
        """Handle zoom in and out with the mouse wheel."""
        if event.angleDelta().y() > 0:
            self.parent.zoom_in()
        else:
            self.parent.zoom_out()        

    def update_circle(self):
        """Draws the search circle on the main scene if circle_center and circle_radius are set."""
        if self.parent.main_image and self.circle_center is not None and self.circle_radius > 0:
            # Clear the main scene and add the main image back
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)        

                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)

                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)                                
                        
            
            # Draw the search circle
            pen_circle = QPen(QColor(255, 0, 0), 2)
            self.parent.main_scene.addEllipse(
                int(self.circle_center.x() - self.circle_radius),
                int(self.circle_center.y() - self.circle_radius),
                int(self.circle_radius * 2),
                int(self.circle_radius * 2),
                pen_circle
            )
            self.update_mini_preview()
        else:
            # If circle is disabled (e.g., during save), clear without drawing
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

    def delete_selected_object(self):
        if self.selected_object is None:
            self.parent.status_label.setText("No object selected to delete.")
            return

        # Remove the selected object from the results list
        self.parent.results = [obj for obj in self.parent.results if obj != self.selected_object]

        # Remove the corresponding row from the TreeBox
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == self.selected_object["name"]:  # Match the name in the third column
                self.parent.results_tree.takeTopLevelItem(i)
                break

        # Clear the selection
        self.selected_object = None
        self.parent.results_tree.clearSelection()

        # Redraw the main and mini previews without the deleted marker
        self.draw_query_results()
        self.update_mini_preview()

        # Update the status label
        self.parent.status_label.setText("Selected object and marker removed.")



    def scrollContentsBy(self, dx, dy):
        """Called whenever the main preview scrolls, ensuring the green box updates in the mini preview."""
        super().scrollContentsBy(dx, dy)
        self.parent.update_green_box()

    def update_mini_preview(self):
        """Update the mini preview with the current view rectangle and any additional mirrored elements."""
        if self.parent.main_image:
            # Scale the main image to fit in the mini preview
            mini_pixmap = self.parent.main_image.scaled(
                self.parent.mini_preview.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            mini_painter = QPainter(mini_pixmap)

            try:
                # Define scale factors based on main image dimensions
                if self.parent.main_image.width() > 0 and self.parent.main_image.height() > 0:
                    scale_factor_x = mini_pixmap.width() / self.parent.main_image.width()
                    scale_factor_y = mini_pixmap.height() / self.parent.main_image.height()

                    # Draw the search circle if it's defined
                    if self.circle_center is not None and self.circle_radius > 0:
                        pen_circle = QPen(QColor(255, 0, 0), 2)
                        mini_painter.setPen(pen_circle)
                        mini_painter.drawEllipse(
                            int(self.circle_center.x() * scale_factor_x - self.circle_radius * scale_factor_x),
                            int(self.circle_center.y() * scale_factor_y - self.circle_radius * scale_factor_y),
                            int(self.circle_radius * 2 * scale_factor_x),
                            int(self.circle_radius * 2 * scale_factor_y)
                        )

                    # Draw the green box representing the current view
                    mini_painter.setPen(QPen(QColor(0, 255, 0), 2))
                    view_rect = self.parent.main_preview.mapToScene(
                        self.parent.main_preview.viewport().rect()
                    ).boundingRect()
                    mini_painter.drawRect(
                        int(view_rect.x() * scale_factor_x),
                        int(view_rect.y() * scale_factor_y),
                        int(view_rect.width() * scale_factor_x),
                        int(view_rect.height() * scale_factor_y)
                    )


                    # Draw dots for each result with a color based on selection status
                    for obj in self.parent.results:
                        ra, dec = obj['ra'], obj['dec']
                        x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                        if x is not None and y is not None:
                            # Change color to green if this is the selected object
                            dot_color = QColor(0, 255, 0) if obj == getattr(self.parent, 'selected_object', None) else QColor(255, 0, 0)
                            mini_painter.setPen(QPen(dot_color, 4))
                            mini_painter.drawPoint(
                                int(x * scale_factor_x),
                                int(y * scale_factor_y)
                            )

                    # Redraw annotation items on the mini preview
                    for item in self.annotation_items:
                        pen = QPen(self.parent.selected_color, 1)  # Use a thinner pen for mini preview
                        mini_painter.setPen(pen)

                        # Interpret item type and draw accordingly
                        if item[0] == 'ellipse':
                            rect = item[1]
                            mini_painter.drawEllipse(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'rect':
                            rect = item[1]
                            mini_painter.drawRect(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'line':
                            line = item[1]
                            mini_painter.drawLine(
                                int(line.x1() * scale_factor_x), int(line.y1() * scale_factor_y),
                                int(line.x2() * scale_factor_x), int(line.y2() * scale_factor_y)
                            )
                        elif item[0] == 'text':
                            text = item[1]            # The text string
                            pos = item[2]             # A QPointF for the position
                            color = item[3]           # The color for the text

                            # Create a smaller font for the mini preview
                            mini_font = QFont(self.parent.selected_font)
                            mini_font.setPointSize(int(self.parent.selected_font.pointSize() * 0.2))  # Scale down font size

                            mini_painter.setFont(mini_font)
                            mini_painter.setPen(color)  # Set the color for the text
                            mini_painter.drawText(
                                int(pos.x() * scale_factor_x), int(pos.y() * scale_factor_y),
                                text
                            )

                        elif item[0] == 'freehand':
                            # Scale the freehand path and draw it
                            path = item[1]
                            scaled_path = QPainterPath()
                            
                            # Scale each point in the path to fit the mini preview
                            for i in range(path.elementCount()):
                                point = path.elementAt(i)
                                if i == 0:
                                    scaled_path.moveTo(point.x * scale_factor_x, point.y * scale_factor_y)
                                else:
                                    scaled_path.lineTo(point.x * scale_factor_x, point.y * scale_factor_y)

                            mini_painter.drawPath(scaled_path)

                        elif item[0] == 'compass':
                            compass = item[1]
                            # Draw the North line
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_line = compass["north_line"]
                            mini_painter.drawLine(
                                int(north_line[0] * scale_factor_x), int(north_line[1] * scale_factor_y),
                                int(north_line[2] * scale_factor_x), int(north_line[3] * scale_factor_y)
                            )

                            # Draw the East line
                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_line = compass["east_line"]
                            mini_painter.drawLine(
                                int(east_line[0] * scale_factor_x), int(east_line[1] * scale_factor_y),
                                int(east_line[2] * scale_factor_x), int(east_line[3] * scale_factor_y)
                            )

                            # Draw North and East labels
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_label = compass["north_label"]
                            mini_painter.drawText(
                                int(north_label[0] * scale_factor_x), int(north_label[1] * scale_factor_y), north_label[2]
                            )

                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_label = compass["east_label"]
                            mini_painter.drawText(
                                int(east_label[0] * scale_factor_x), int(east_label[1] * scale_factor_y), east_label[2]
                            )                            

            finally:
                mini_painter.end()  # Ensure QPainter is properly ended

            self.parent.mini_preview.setPixmap(mini_pixmap)

    def place_celestial_compass(self, center):
        """Draw a celestial compass at a given point aligned with celestial North and East."""
        compass_radius = 50  # Length of the compass lines

        # Get the orientation in radians (assuming `self.parent.orientation` is in degrees)
        orientation_radians = math.radians(self.parent.orientation)

        # Calculate North vector (upwards, adjusted for orientation)
        north_dx = math.sin(orientation_radians) * compass_radius
        north_dy = -math.cos(orientation_radians) * compass_radius

        # Calculate East vector (rightwards, adjusted for orientation)
        east_dx = math.cos(orientation_radians) * -compass_radius
        east_dy = math.sin(orientation_radians) * -compass_radius

        # Draw North line
        north_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + north_dx, center.y() + north_dy
        )
        north_line.setPen(QPen(Qt.GlobalColor.red, 2))
        self.parent.main_scene.addItem(north_line)

        # Draw East line
        east_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + east_dx, center.y() + east_dy
        )
        east_line.setPen(QPen(Qt.GlobalColor.blue, 2))
        self.parent.main_scene.addItem(east_line)

        # Add labels for North and East
        text_north = QGraphicsTextItem("N")
        text_north.setDefaultTextColor(Qt.GlobalColor.red)
        text_north.setPos(center.x() + north_dx - 10, center.y() + north_dy - 10)
        self.parent.main_scene.addItem(text_north)

        text_east = QGraphicsTextItem("E")
        text_east.setDefaultTextColor(Qt.GlobalColor.blue)
        text_east.setPos(center.x() + east_dx - 15, center.y() + east_dy - 10)
        self.parent.main_scene.addItem(text_east)

        # Append all compass components as a tuple to annotation_items for later redrawing
        self.annotation_items.append((
            "compass", {
                "center": center,
                "north_line": (center.x(), center.y(), center.x() + north_dx, center.y() + north_dy),
                "east_line": (center.x(), center.y(), center.x() + east_dx, center.y() + east_dy),
                "north_label": (center.x() + north_dx - 10, center.y() + north_dy - 10, "N"),
                "east_label": (center.x() + east_dx - 15, center.y() + east_dy - 10, "E"),
                "orientation": self.parent.orientation
            }
        ))

    def zoom_to_coordinates(self, ra, dec):
        """Zoom to the specified RA/Dec coordinates and center the view on that position."""
        # Calculate the pixel position from RA and Dec
        pixel_x, pixel_y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
        
        if pixel_x is not None and pixel_y is not None:
            # Center the view on the calculated pixel position
            self.centerOn(pixel_x, pixel_y)
            
            # Reset the zoom level to 1.0 by adjusting the transformation matrix
            self.resetTransform()
            self.scale(1.0, 1.0)

            # Optionally, update the mini preview to reflect the new zoom and center
            self.update_mini_preview()

    def draw_query_results(self):
        """Draw query results with or without names based on the show_names setting."""
        if self.parent.main_image:
            # Clear the main scene and re-add the main image
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)                      
                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)        
                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)                               
            # Ensure the search circle is drawn if circle data is available
            #if self.circle_center is not None and self.circle_radius > 0:
            #    self.update_circle()

            # Draw object markers (circle or crosshair)
            for obj in self.parent.results:
                ra, dec, name = obj["ra"], obj["dec"], obj["name"]
                x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                if x is not None and y is not None:
                    # Determine color: green if selected, red otherwise
                    pen_color = QColor(0, 255, 0) if obj == self.selected_object else QColor(255, 0, 0)
                    pen = QPen(pen_color, 2)

                    if self.parent.marker_style == "Circle":
                        # Draw a circle around the object
                        self.parent.main_scene.addEllipse(int(x - 5), int(y - 5), 10, 10, pen)
                    elif self.parent.marker_style == "Crosshair":
                        # Draw crosshair with a 5-pixel gap in the middle
                        crosshair_size = 10
                        gap = 5
                        line1 = QLineF(x - crosshair_size, y, x - gap, y)
                        line2 = QLineF(x + gap, y, x + crosshair_size, y)
                        line3 = QLineF(x, y - crosshair_size, x, y - gap)
                        line4 = QLineF(x, y + gap, x, y + crosshair_size)
                        for line in [line1, line2, line3, line4]:
                            crosshair_item = QGraphicsLineItem(line)
                            crosshair_item.setPen(pen)
                            self.parent.main_scene.addItem(crosshair_item)
                    if self.parent.show_names:
                        #print(f"Drawing name: {name} at ({x}, {y})")  # Debugging statement
                        text_color = obj.get("color", QColor(Qt.GlobalColor.white))
                        text_item = QGraphicsTextItem(name)
                        text_item.setPos(x + 10, y + 10)  # Offset to avoid overlapping the marker
                        text_item.setDefaultTextColor(text_color)
                        text_item.setFont(self.parent.selected_font)
                        self.parent.main_scene.addItem(text_item)                            
    

    def clear_query_results(self):
        """Clear query markers from the main image without removing annotations."""
        # Clear the main scene and add the main image back
        self.parent.main_scene.clear()
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)
        
        # Redraw the stored annotation items
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item)  
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)       
            elif item[0] == 'compass':
                compass = item[1]
                # North line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                # East line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                # North label
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                # East label
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)
        
        # Update the circle data, if any
        self.parent.update_circle_data()
                        

    def set_query_results(self, results):
        """Set the query results and redraw."""
        self.parent.results = results  # Store results as dictionaries
        self.draw_query_results()

    def get_object_at_position(self, pos):
        """Find the object at the given position in the main preview."""
        for obj in self.parent.results:
            ra, dec = obj["ra"], obj["dec"]
            x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
            if x is not None and y is not None:
                if abs(pos.x() - x) <= 5 and abs(pos.y() - y) <= 5:
                    return obj
        return None


    def select_object(self, selected_obj):
        """Select or deselect the specified object and update visuals."""
        self.selected_object = selected_obj if self.selected_object != selected_obj else None
        self.draw_query_results()  # Redraw to reflect selection

        # Update the TreeWidget selection in MainWindow
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == selected_obj["name"]:  # Assuming 'name' is the unique identifier
                self.parent.results_tree.setCurrentItem(item if self.selected_object else None)
                break

    def undo_annotation(self):
        """Remove the last annotation item from the scene and annotation_items list."""
        if self.annotation_items:
            # Remove the last item from annotation_items
            self.annotation_items.pop()

            # Clear the scene and redraw all annotations except the last one
            self.parent.main_scene.clear()
            if self.parent.main_image:
                self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw remaining annotations
            self.redraw_annotations()

            # Optionally, update the mini preview to reflect changes
            self.update_mini_preview()

    def clear_annotations(self):
        """Clear all annotation items from the scene and annotation_items list."""
        # Clear all items in annotation_items and update the scene
        self.annotation_items.clear()
        self.parent.main_scene.clear()
        
        # Redraw only the main image
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)

        # Optionally, update the mini preview to reflect changes
        self.update_mini_preview()

    def redraw_annotations(self):
        """Helper function to redraw all annotations from annotation_items."""
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item) 
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)                                        
            elif item[0] == 'compass':
                compass = item[1]
                # Redraw north line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                
                # Redraw east line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                
                # Redraw labels
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)        


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("What's In My Image")
        self.setGeometry(100, 100, 800, 600)
        # Track the theme status
        self.is_dark_mode = True
        self.metadata = {}
        self.circle_center = None
        self.circle_radius = 0    
        self.show_names = False  # Boolean to toggle showing names on the main image
        self.max_results = 100  # Default maximum number of query results     
        self.current_tool = None  # Track the active annotation tool
        self.header = Header()
        self.marker_style = "Circle" 
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")
            

        main_layout = QHBoxLayout()

        # Left Column Layout
        left_panel = QVBoxLayout()

        # Load the image using the resource_path function
        wimilogo_path = resource_path("wimilogo.png")

        # Create a QLabel to display the logo
        self.logo_label = QLabel()

        # Set the logo image to the label
        logo_pixmap = QPixmap(wimilogo_path)

        # Scale the pixmap to fit within a desired size, maintaining the aspect ratio
        scaled_pixmap = logo_pixmap.scaled(200, 100, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Set the scaled pixmap to the label
        self.logo_label.setPixmap(scaled_pixmap)

        # Set alignment to center the logo horizontally
        self.logo_label.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Optionally, you can set a fixed size for the label (this is for layout purposes)
        self.logo_label.setFixedSize(200, 100)  # Adjust the size as needed

        # Add the logo_label to your layout
        left_panel.addWidget(self.logo_label)
       
        button_layout = QHBoxLayout()
        
        # Load button
        self.load_button = QPushButton("Load Image")
        self.load_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogStart))
        self.load_button.clicked.connect(self.open_image)

        # AutoStretch button
        self.auto_stretch_button = QPushButton("AutoStretch")
        self.auto_stretch_button.clicked.connect(self.toggle_autostretch)

        # Add both buttons to the horizontal layout
        button_layout.addWidget(self.load_button)
        button_layout.addWidget(self.auto_stretch_button)

        # Add the button layout to the left panel
        left_panel.addLayout(button_layout)

        # Create the instruction QLabel for search region
        search_region_instruction_label = QLabel("Shift+Click to define a search region")
        search_region_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        search_region_instruction_label.setStyleSheet("font-size: 15px; color: gray;")

        # Add this QLabel to your layout at the appropriate position above RA/Dec
        left_panel.addWidget(search_region_instruction_label)  



        # Query Simbad button
        self.query_button = QPushButton("Query Simbad")
        self.query_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        left_panel.addWidget(self.query_button)
        self.query_button.clicked.connect(lambda: self.query_simbad(self.get_defined_radius()))


        # Create a horizontal layout for the show names checkbox and clear results button
        show_clear_layout = QHBoxLayout()

        # Create the Show Object Names checkbox
        self.show_names_checkbox = QCheckBox("Show Object Names")
        self.show_names_checkbox.stateChanged.connect(self.toggle_object_names)  # Connect to a function to toggle names
        show_clear_layout.addWidget(self.show_names_checkbox)

        # Create the Clear Results button
        self.clear_results_button = QPushButton("Clear Results")
        self.clear_results_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))
        self.clear_results_button.clicked.connect(self.clear_search_results)  # Connect to a function to clear results
        show_clear_layout.addWidget(self.clear_results_button)

        # Add this horizontal layout to the left panel layout (or wherever you want it to appear)
        left_panel.addLayout(show_clear_layout)   

        # Create a horizontal layout for the two buttons
        button_layout = QHBoxLayout()

        # Show Visible Objects Only button
        self.toggle_visible_objects_button = QPushButton("Show Visible Objects Only")
        self.toggle_visible_objects_button.setCheckable(True)  # Toggle button state
        self.toggle_visible_objects_button.setIcon(QIcon(eye_icon_path))
        self.toggle_visible_objects_button.clicked.connect(self.filter_visible_objects)
        self.toggle_visible_objects_button.setToolTip("Toggle the visibility of objects based on brightness.")
        button_layout.addWidget(self.toggle_visible_objects_button)

        # Save CSV button
        self.save_csv_button = QPushButton("Save CSV")
        self.save_csv_button.setIcon(QIcon(csv_icon_path))
        self.save_csv_button.clicked.connect(self.save_results_as_csv)
        button_layout.addWidget(self.save_csv_button)

        # Add the button layout to the left panel or main layout
        left_panel.addLayout(button_layout)  

        # Advanced Search Button
        self.advanced_search_button = QPushButton("Advanced Search")
        self.advanced_search_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogDetailedView))
        self.advanced_search_button.setCheckable(True)
        self.advanced_search_button.clicked.connect(self.toggle_advanced_search)
        left_panel.addWidget(self.advanced_search_button)

        # Advanced Search Panel (initially hidden)
        self.advanced_search_panel = QVBoxLayout()
        self.advanced_search_panel_widget = QWidget()
        self.advanced_search_panel_widget.setLayout(self.advanced_search_panel)
        self.advanced_search_panel_widget.setFixedWidth(300)
        self.advanced_search_panel_widget.setVisible(False)  # Hide initially        

        # Status label
        self.status_label = QLabel("Status: Ready")
        left_panel.addWidget(self.status_label)

        # Create a horizontal layout
        button_layout = QHBoxLayout()

        # Copy RA/Dec to Clipboard button
        self.copy_button = QPushButton("Copy RA/Dec to Clipboard", self)
        self.copy_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_CommandLink))
        self.copy_button.clicked.connect(self.copy_ra_dec_to_clipboard)
        button_layout.addWidget(self.copy_button)

        # Settings button (wrench icon)
        self.settings_button = QPushButton()
        self.settings_button.setIcon(QIcon(wrench_path))  # Adjust icon path as needed
        self.settings_button.clicked.connect(self.open_settings_dialog)
        button_layout.addWidget(self.settings_button)

        # Add the horizontal layout to the main layout or the desired parent layout
        left_panel.addLayout(button_layout)
        
         # Save Plate Solved Fits Button
        self.save_plate_solved_button = QPushButton("Save Plate Solved Fits")
        self.save_plate_solved_button.setIcon(QIcon(disk_icon_path))
        self.save_plate_solved_button.clicked.connect(self.save_plate_solved_fits)
        left_panel.addWidget(self.save_plate_solved_button)       

        # RA/Dec Labels
        ra_dec_layout = QHBoxLayout()
        self.ra_label = QLabel("RA: N/A")
        self.dec_label = QLabel("Dec: N/A")
        self.orientation_label = QLabel("Orientation: N/A°")
        ra_dec_layout.addWidget(self.ra_label)
        ra_dec_layout.addWidget(self.dec_label)
        ra_dec_layout.addWidget(self.orientation_label)
        left_panel.addLayout(ra_dec_layout)

        # Mini Preview
        self.mini_preview = QLabel("Mini Preview")
        self.mini_preview.setFixedSize(300, 300)
        self.mini_preview.mousePressEvent = self.on_mini_preview_press
        self.mini_preview.mouseMoveEvent = self.on_mini_preview_drag
        self.mini_preview.mouseReleaseEvent = self.on_mini_preview_release
        left_panel.addWidget(self.mini_preview)

  

        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_panel.addWidget(footer_label)

        # Right Column Layout
        right_panel = QVBoxLayout()

        # Zoom buttons above the main preview
        zoom_controls_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_in_button)
        zoom_controls_layout.addWidget(self.zoom_out_button)
        right_panel.addLayout(zoom_controls_layout)        

        # Main Preview
        self.main_preview = CustomGraphicsView(self)
        self.main_scene = QGraphicsScene(self.main_preview)
        self.main_preview.setScene(self.main_scene)
        self.main_preview.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.main_preview.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        right_panel.addWidget(self.main_preview)

        # Save Annotated Image and Save Collage of Objects Buttons in a Horizontal Layout between main image and treebox
        save_buttons_layout = QHBoxLayout()

        # Button to toggle annotation tools section
        self.show_annotations_button = QPushButton("Show Annotation Tools")
        self.show_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogResetButton))
        self.show_annotations_button.clicked.connect(self.toggle_annotation_tools)
        save_buttons_layout.addWidget(self.show_annotations_button)
        
        self.save_annotated_button = QPushButton("Save Annotated Image")
        self.save_annotated_button.setIcon(QIcon(annotated_path))
        self.save_annotated_button.clicked.connect(self.save_annotated_image)
        save_buttons_layout.addWidget(self.save_annotated_button)
        
        self.save_collage_button = QPushButton("Save Collage of Objects")
        self.save_collage_button.setIcon(QIcon(collage_path))
        self.save_collage_button.clicked.connect(self.save_collage_of_objects)
        save_buttons_layout.addWidget(self.save_collage_button)

        right_panel.addLayout(save_buttons_layout)        

        # Connect scroll events to update the green box in the mini preview
        self.main_preview.verticalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)
        self.main_preview.horizontalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)

        # Create a horizontal layout for the labels
        label_layout = QHBoxLayout()

        # Create the label to display the count of objects
        self.object_count_label = QLabel("Objects Found: 0")

        # Create the label with instructions
        self.instructions_label = QLabel("Right Click a Row for More Options")

        # Add both labels to the horizontal layout
        label_layout.addWidget(self.object_count_label)
        label_layout.addWidget(self.instructions_label)

        # Add the horizontal layout to the main panel layout
        right_panel.addLayout(label_layout)

        self.results_tree = QTreeWidget()
        self.results_tree.setHeaderLabels(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])
        self.results_tree.setFixedHeight(150)
        self.results_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.results_tree.customContextMenuRequested.connect(self.open_context_menu)
        self.results_tree.itemClicked.connect(self.on_tree_item_clicked)
        self.results_tree.itemDoubleClicked.connect(self.on_tree_item_double_clicked)
        self.results_tree.setSortingEnabled(True)
        right_panel.addWidget(self.results_tree)

        self.annotation_buttons = []

        # Annotation Tools Section (initially hidden)
        self.annotation_tools_section = QWidget()
        annotation_tools_layout = QGridLayout(self.annotation_tools_section)

        annotation_instruction_label = QLabel("Ctrl+Click to add items, Alt+Click to measure distance")
        annotation_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        annotation_instruction_label.setStyleSheet("font-size: 10px; color: gray;")        

        self.draw_ellipse_button = QPushButton("Draw Ellipse")
        self.draw_ellipse_button.tool_name = "Ellipse"
        self.draw_ellipse_button.clicked.connect(lambda: self.set_tool("Ellipse"))
        self.annotation_buttons.append(self.draw_ellipse_button)

        self.freehand_button = QPushButton("Freehand (Lasso)")
        self.freehand_button.tool_name = "Freehand"
        self.freehand_button.clicked.connect(lambda: self.set_tool("Freehand"))
        self.annotation_buttons.append(self.freehand_button)

        self.draw_rectangle_button = QPushButton("Draw Rectangle")
        self.draw_rectangle_button.tool_name = "Rectangle"
        self.draw_rectangle_button.clicked.connect(lambda: self.set_tool("Rectangle"))
        self.annotation_buttons.append(self.draw_rectangle_button)

        self.draw_arrow_button = QPushButton("Draw Arrow")
        self.draw_arrow_button.tool_name = "Arrow"
        self.draw_arrow_button.clicked.connect(lambda: self.set_tool("Arrow"))
        self.annotation_buttons.append(self.draw_arrow_button)

        self.place_compass_button = QPushButton("Place Celestial Compass")
        self.place_compass_button.tool_name = "Compass"
        self.place_compass_button.clicked.connect(lambda: self.set_tool("Compass"))
        self.annotation_buttons.append(self.place_compass_button)

        self.add_text_button = QPushButton("Add Text")
        self.add_text_button.tool_name = "Text"
        self.add_text_button.clicked.connect(lambda: self.set_tool("Text"))
        self.annotation_buttons.append(self.add_text_button)

        # Add Color and Font buttons
        self.color_button = QPushButton("Select Color")
        self.color_button.setIcon(QIcon(colorwheel_path))
        self.color_button.clicked.connect(self.select_color)

        self.font_button = QPushButton("Select Font")
        self.font_button.setIcon(QIcon(font_path))
        self.font_button.clicked.connect(self.select_font)

        # Undo button
        self.undo_button = QPushButton("Undo")
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))  # Left arrow icon for undo
        self.undo_button.clicked.connect(self.main_preview.undo_annotation)  # Connect to undo_annotation in CustomGraphicsView

        # Clear Annotations button
        self.clear_annotations_button = QPushButton("Clear Annotations")
        self.clear_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_TrashIcon))  # Trash icon
        self.clear_annotations_button.clicked.connect(self.main_preview.clear_annotations)  # Connect to clear_annotations in CustomGraphicsView

        # Delete Selected Object button
        self.delete_selected_object_button = QPushButton("Delete Selected Object")
        self.delete_selected_object_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))  # Trash icon
        self.delete_selected_object_button.clicked.connect(self.main_preview.delete_selected_object)  # Connect to delete_selected_object in CustomGraphicsView

        # Add the instruction label to the top of the grid layout (row 0, spanning multiple columns)
        annotation_tools_layout.addWidget(annotation_instruction_label, 0, 0, 1, 4)  # Span 5 columns to center it

        # Shift all other widgets down by one row
        annotation_tools_layout.addWidget(self.draw_ellipse_button, 1, 0)
        annotation_tools_layout.addWidget(self.freehand_button, 1, 1)
        annotation_tools_layout.addWidget(self.draw_rectangle_button, 2, 0)
        annotation_tools_layout.addWidget(self.draw_arrow_button, 2, 1)
        annotation_tools_layout.addWidget(self.place_compass_button, 3, 0)
        annotation_tools_layout.addWidget(self.add_text_button, 3, 1)
        annotation_tools_layout.addWidget(self.color_button, 4, 0)
        annotation_tools_layout.addWidget(self.font_button, 4, 1)
        annotation_tools_layout.addWidget(self.undo_button, 1, 4)
        annotation_tools_layout.addWidget(self.clear_annotations_button, 2, 4)
        annotation_tools_layout.addWidget(self.delete_selected_object_button, 3, 4)

        self.annotation_tools_section.setVisible(False)  # Initially hidden
        right_panel.addWidget(self.annotation_tools_section)

        # Advanced Search Panel
        self.advanced_param_label = QLabel("Advanced Search Parameters")
        self.advanced_search_panel.addWidget(self.advanced_param_label)

        # TreeWidget for object types
        self.object_tree = QTreeWidget()
        self.object_tree.setHeaderLabels(["Object Type", "Description"])
        self.object_tree.setColumnWidth(0, 150)
        self.object_tree.setSortingEnabled(True)

        # Populate the TreeWidget with object types from otype_long_name_lookup
        for obj_type, description in otype_long_name_lookup.items():
            item = QTreeWidgetItem([obj_type, description])
            item.setCheckState(0, Qt.CheckState.Checked)  # Start with all items unchecked
            self.object_tree.addTopLevelItem(item)

        self.advanced_search_panel.addWidget(self.object_tree)

        # Buttons for toggling selections
        toggle_buttons_layout = QHBoxLayout()

        # Toggle All Button
        self.toggle_all_button = QPushButton("Toggle All")
        self.toggle_all_button.clicked.connect(self.toggle_all_items)
        toggle_buttons_layout.addWidget(self.toggle_all_button)

        # Toggle Stars Button
        self.toggle_stars_button = QPushButton("Toggle Stars")
        self.toggle_stars_button.clicked.connect(self.toggle_star_items)
        toggle_buttons_layout.addWidget(self.toggle_stars_button)

        # Toggle Galaxies Button
        self.toggle_galaxies_button = QPushButton("Toggle Galaxies")
        self.toggle_galaxies_button.clicked.connect(self.toggle_galaxy_items)
        toggle_buttons_layout.addWidget(self.toggle_galaxies_button)

        # Add toggle buttons to the advanced search layout
        self.advanced_search_panel.addLayout(toggle_buttons_layout)    

        # Add Simbad Search buttons below the toggle buttons
        search_button_layout = QHBoxLayout()

        self.simbad_defined_region_button = QPushButton("Search Defined Region")
        self.simbad_defined_region_button.clicked.connect(self.search_defined_region)
        search_button_layout.addWidget(self.simbad_defined_region_button)

        self.simbad_entire_image_button = QPushButton("Search Entire Image")
        self.simbad_entire_image_button.clicked.connect(self.search_entire_image)
        search_button_layout.addWidget(self.simbad_entire_image_button)

        self.advanced_search_panel.addLayout(search_button_layout)

        # Adding the "Deep Vizier Search" button below the other search buttons
        self.deep_vizier_button = QPushButton("Caution - Deep Vizier Search")
        self.deep_vizier_button.setIcon(QIcon(nuke_path))  # Assuming `nuke_path` is the correct path for the icon
        self.deep_vizier_button.setToolTip("Perform a deep search with Vizier. Caution: May return large datasets.")

        # Connect the button to a placeholder method for the deep Vizier search
        self.deep_vizier_button.clicked.connect(self.perform_deep_vizier_search)

        # Add the Deep Vizier button to the advanced search layout
        self.advanced_search_panel.addWidget(self.deep_vizier_button)

        self.mast_search_button = QPushButton("Search M.A.S.T Database")
        self.mast_search_button.setIcon(QIcon(hubble_path))
        self.mast_search_button.clicked.connect(self.perform_mast_search)
        self.mast_search_button.setToolTip("Search Hubble, JWST, Spitzer, TESS and More.")
        self.advanced_search_panel.addWidget(self.mast_search_button)                        

        # Combine left and right panels
        main_layout.addLayout(left_panel)
        main_layout.addLayout(right_panel)
        main_layout.addWidget(self.advanced_search_panel_widget)
        
        container = QWidget()
        container.setLayout(main_layout)
        self.setCentralWidget(container)

        self.image_path = None
        self.zoom_level = 1.0
        self.main_image = None
        self.green_box = None
        self.dragging = False
        self.center_ra = None
        self.center_dec = None
        self.pixscale = None
        self.orientation = None
        self.parity = None  
        self.circle_center = None
        self.circle_radius = 0  
        self.results = []
        self.wcs = None  # Initialize WCS to None
        # Initialize selected color and font with default values
        self.selected_color = QColor(Qt.GlobalColor.red)  # Default annotation color
        self.selected_font = QFont("Arial", 12)  # Default font for text annotations        

    def update_object_count(self):
        count = self.results_tree.topLevelItemCount()
        self.object_count_label.setText(f"Objects Found: {count}")

    def open_context_menu(self, position):
        
        # Get the item at the mouse position
        item = self.results_tree.itemAt(position)
        if not item:
            return  # If no item is clicked, do nothing
        
        self.on_tree_item_clicked(item)

        # Create the context menu
        menu = QMenu(self)

        # Define actions
        open_website_action = QAction("Open Website", self)
        open_website_action.triggered.connect(lambda: self.results_tree.itemDoubleClicked.emit(item, 0))
        menu.addAction(open_website_action)

        zoom_to_object_action = QAction("Zoom to Object", self)
        zoom_to_object_action.triggered.connect(lambda: self.zoom_to_object(item))
        menu.addAction(zoom_to_object_action)

        copy_info_action = QAction("Copy Object Information", self)
        copy_info_action.triggered.connect(lambda: self.copy_object_information(item))
        menu.addAction(copy_info_action)

        # Display the context menu at the cursor position
        menu.exec(self.results_tree.viewport().mapToGlobal(position))

    def toggle_autostretch(self):
        if not hasattr(self, 'original_image'):
            # Store the original image the first time AutoStretch is applied
            self.original_image = self.image_data.copy()
        
        # Determine if the image is mono or color based on the number of dimensions
        if self.image_data.ndim == 2:
            # Call stretch_mono_image if the image is mono

            stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:
            # Call stretch_color_image if the image is color

            stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=True, normalize=True)
        
        # If the AutoStretch is toggled off (using the same button), restore the original image
        if self.auto_stretch_button.text() == "AutoStretch":
            # Store the stretched image and update the button text to indicate it's on
            self.stretched_image = stretched_image
            self.auto_stretch_button.setText("Turn Off AutoStretch")
        else:
            # Revert to the original image and update the button text to indicate it's off
            stretched_image = self.original_image
            self.auto_stretch_button.setText("AutoStretch")
        

        stretched_image = (stretched_image * 255).astype(np.uint8)


        # Update the display with the stretched image (or original if toggled off)

        height, width = stretched_image.shape[:2]
        bytes_per_line = 3 * width

        # Ensure the image has 3 channels (RGB)
        if stretched_image.ndim == 2:
            stretched_image = np.stack((stretched_image,) * 3, axis=-1)
        elif stretched_image.shape[2] == 1:
            stretched_image = np.repeat(stretched_image, 3, axis=2)



        qimg = QImage(stretched_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        if qimg.isNull():
            print("Failed to create QImage")
            return

        pixmap = QPixmap.fromImage(qimg)
        if pixmap.isNull():
            print("Failed to create QPixmap")
            return

        self.main_image = pixmap
        scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.mini_preview.setPixmap(scaled_pixmap)

        self.main_scene.clear()
        self.main_scene.addPixmap(pixmap)
        self.main_preview.setSceneRect(QRectF(pixmap.rect()))
        self.zoom_level = 1.0
        self.main_preview.resetTransform()
        self.main_preview.centerOn(self.main_scene.sceneRect().center())
        self.update_green_box()

        # Optionally, you can also update any other parts of the UI after stretching the image
        print(f"AutoStretch {'applied to' if self.auto_stretch_button.text() == 'Turn Off AutoStretch' else 'removed from'} the image.")


    def zoom_to_object(self, item):
        """Zoom to the object in the main preview."""
        ra = float(item.text(0))  # Assuming RA is in the first column
        dec = float(item.text(1))  # Assuming Dec is in the second column
        self.main_preview.zoom_to_coordinates(ra, dec)
        

    def copy_object_information(self, item):
        """Copy object information to the clipboard."""
        info = f"RA: {item.text(0)}, Dec: {item.text(1)}, Name: {item.text(2)}, Diameter: {item.text(3)}, Type: {item.text(4)}"
        clipboard = QApplication.clipboard()
        clipboard.setText(info)

    def set_tool(self, tool_name):
        """Sets the current tool and updates button states."""
        self.current_tool = tool_name

        # Reset button styles and highlight the selected button
        for button in self.annotation_buttons:
            if button.tool_name == tool_name:
                button.setStyleSheet("background-color: lightblue;")  # Highlight selected button
            else:
                button.setStyleSheet("")  # Reset other buttons


    def select_color(self):
        """Opens a color dialog to choose annotation color."""
        color = QColorDialog.getColor(self.selected_color, self, "Select Annotation Color")
        if color.isValid():
            self.selected_color = color

    def select_font(self):
        """Opens a font dialog to choose text annotation font."""
        font, ok = QFontDialog.getFont(self.selected_font, self, "Select Annotation Font")
        if ok:
            self.selected_font = font                

    def toggle_annotation_tools(self):
        """Toggle the visibility of the annotation tools section."""
        is_visible = self.annotation_tools_section.isVisible()
        self.annotation_tools_section.setVisible(not is_visible)
        self.show_annotations_button.setText("Hide Annotation Tools" if not is_visible else "Show Annotation Tools")

    def save_plate_solved_fits(self):
        """Save the plate-solved FITS file with WCS header data and the desired bit depth."""
        # Prompt user to select bit depth
        bit_depth, ok = QInputDialog.getItem(
            self, 
            "Select Bit Depth", 
            "Choose the bit depth for the FITS file:",
            ["8-bit", "16-bit", "32-bit"], 
            0, False
        )

        if not ok:
            return  # User cancelled the selection

        # Open file dialog to select where to save the FITS file
        output_image_path, _ = QFileDialog.getSaveFileName(
            self, "Save Plate Solved FITS", "", "FITS Files (*.fits *.fit)"
        )

        if not output_image_path:
            return  # User cancelled save file dialog

        # Verify WCS header data is available
        if not hasattr(self, 'wcs') or self.wcs is None:
            QMessageBox.warning(self, "WCS Data Missing", "WCS header data is not available.")
            return

        # Retrieve image data and WCS header
        image_data = self.image_data  # Raw image data
        wcs_header = self.wcs.to_header(relax=True)  # WCS header, including non-standard keywords
        combined_header = self.original_header.copy() if self.original_header else fits.Header()
        combined_header.update(wcs_header)  # Combine original header with WCS data

        # Convert image data based on selected bit depth
        if self.is_mono:
            # Grayscale (2D) image
            if bit_depth == "8-bit":
                scaled_image = (image_data[:, :, 0] / np.max(image_data) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (image_data[:, :, 0] * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = image_data[:, :, 0].astype(np.float32)
                combined_header['BITPIX'] = -32
        else:
            # RGB (3D) image: Transpose to FITS format (channels, height, width)
            transformed_image = np.transpose(image_data, (2, 0, 1))
            if bit_depth == "8-bit":
                scaled_image = (transformed_image / np.max(transformed_image) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (transformed_image * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = transformed_image.astype(np.float32)
                combined_header['BITPIX'] = -32

            # Update header to reflect 3D structure
            combined_header['NAXIS'] = 3
            combined_header['NAXIS1'] = transformed_image.shape[2]
            combined_header['NAXIS2'] = transformed_image.shape[1]
            combined_header['NAXIS3'] = transformed_image.shape[0]

        # Save the image with combined header (including WCS and original data)
        hdu = fits.PrimaryHDU(scaled_image, header=combined_header)
        try:
            hdu.writeto(output_image_path, overwrite=True)
            QMessageBox.information(self, "File Saved", f"FITS file saved as {output_image_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save FITS file: {str(e)}")



    def save_annotated_image(self):
        """Save the annotated image as a full or cropped view, excluding the search circle."""
        # Create a custom message box
        msg_box = QMessageBox(self)
        msg_box.setWindowTitle("Save Annotated Image")
        msg_box.setText("Do you want to save the Full Image or Cropped Only?")
        
        # Add custom buttons
        full_image_button = msg_box.addButton("Save Full", QMessageBox.ButtonRole.AcceptRole)
        cropped_image_button = msg_box.addButton("Save Cropped", QMessageBox.ButtonRole.DestructiveRole)
        msg_box.addButton(QMessageBox.StandardButton.Cancel)

        # Show the message box and get the user's response
        msg_box.exec()

        # Determine the save type based on the selected button
        if msg_box.clickedButton() == full_image_button:
            save_full_image = True
        elif msg_box.clickedButton() == cropped_image_button:
            save_full_image = False
        else:
            return  # User cancelled

        # Open a file dialog to select the file name and format
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Annotated Image",
            "",
            "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )
        
        if not file_path:
            return  # User cancelled the save dialog

        # Temporarily disable the search circle in the custom graphics view
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.main_preview.circle_center = None  # Hide the circle temporarily
        self.main_preview.circle_radius = 0

        # Redraw annotations without the search circle
        self.main_preview.draw_query_results()

        # Create a QPixmap to render the annotations
        if save_full_image:
            # Save the entire main image with annotations
            pixmap = QPixmap(self.main_image.size())
            pixmap.fill(Qt.GlobalColor.Transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter)  # Render the entire scene without the search circle
        else:
            # Save only the currently visible area (cropped view)
            rect = self.main_preview.viewport().rect()
            scene_rect = self.main_preview.mapToScene(rect).boundingRect()
            pixmap = QPixmap(int(scene_rect.width()), int(scene_rect.height()))
            pixmap.fill(Qt.GlobalColor.Transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter, QRectF(0, 0, pixmap.width(), pixmap.height()), scene_rect)

        painter.end()  # End QPainter to finalize drawing

        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle

        # Save the QPixmap as an image file in the selected format
        try:
            if pixmap.save(file_path, file_path.split('.')[-1].upper()):
                QMessageBox.information(self, "Save Successful", f"Annotated image saved as {file_path}")
            else:
                raise Exception("Failed to save image due to format or file path issues.")
        except Exception as e:
            QMessageBox.critical(self, "Save Failed", f"An error occurred while saving the image: {str(e)}")


    def save_collage_of_objects(self):
        """Save a collage of 128x128 pixel patches centered around each object, with dynamically spaced text below."""
        # Options for display
        options = ["Name", "RA", "Dec", "Short Type", "Long Type", "Redshift", "Comoving Distance"]

        # Create a custom dialog to select information to display
        dialog = QDialog(self)
        dialog.setWindowTitle("Select Information to Display")
        layout = QVBoxLayout(dialog)
        
        # Add checkboxes for each option
        checkboxes = {}
        for option in options:
            checkbox = QCheckBox(option)
            checkbox.setChecked(True)  # Default to checked
            layout.addWidget(checkbox)
            checkboxes[option] = checkbox

        # Add OK and Cancel buttons
        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        layout.addWidget(button_box)
        button_box.accepted.connect(dialog.accept)
        button_box.rejected.connect(dialog.reject)

        # Show the dialog and get the user's response
        if dialog.exec() == QDialog.DialogCode.Rejected:
            return  # User cancelled

        # Determine which fields to display based on user selection
        selected_fields = [key for key, checkbox in checkboxes.items() if checkbox.isChecked()]

        # Calculate required vertical space for text based on number of selected fields
        text_row_height = 15
        text_block_height = len(selected_fields) * text_row_height
        patch_size = 128
        space_between_patches = max(64, text_block_height + 20)  # Ensure enough space for text between patches

        # Set parameters for collage layout
        number_of_objects = len(self.results)

        if number_of_objects == 0:
            QMessageBox.warning(self, "No Objects", "No objects available to create a collage.")
            return

        # Determine grid size for the collage
        grid_size = math.ceil(math.sqrt(number_of_objects))
        collage_width = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128
        collage_height = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128

        # Create an empty black RGB image for the collage
        collage_image = Image.new("RGB", (collage_width, collage_height), (0, 0, 0))

        # Temporarily disable annotations
        original_show_names = self.show_names
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.show_names = False
        self.main_preview.circle_center = None
        self.main_preview.circle_radius = 0

        try:
            for i, obj in enumerate(self.results):
                # Calculate position in the grid
                row = i // grid_size
                col = i % grid_size
                offset_x = 64 + col * (patch_size + space_between_patches)
                offset_y = 64 + row * (patch_size + space_between_patches)

                # Calculate pixel coordinates around the object
                ra, dec = obj["ra"], obj["dec"]
                x, y = self.calculate_pixel_from_ra_dec(ra, dec)

                # Render the main image without annotations onto a QPixmap
                patch = QPixmap(self.main_image.size())
                patch.fill(Qt.GlobalColor.black)
                painter = QPainter(patch)
                self.main_scene.clear()  # Clear any previous drawings on the scene
                self.main_scene.addPixmap(self.main_image)  # Add only the main image without annotations
                self.main_scene.render(painter)  # Render the scene onto the patch

                # End the painter early to prevent QPaintDevice errors
                painter.end()

                # Crop the relevant area for the object
                rect = QRectF(x - patch_size // 2, y - patch_size // 2, patch_size, patch_size)
                cropped_patch = patch.copy(rect.toRect())
                cropped_image = cropped_patch.toImage().scaled(patch_size, patch_size).convertToFormat(QImage.Format.Format_RGB888)

                # Convert QImage to PIL format for adding to the collage
                bytes_img = cropped_image.bits().asstring(cropped_image.width() * cropped_image.height() * 3)
                pil_patch = Image.frombytes("RGB", (patch_size, patch_size), bytes_img)

                # Paste the patch in the correct location on the collage
                collage_image.paste(pil_patch, (offset_x, offset_y))

                # Draw the selected information below the patch
                draw = ImageDraw.Draw(collage_image)
                font = ImageFont.truetype("arial.ttf", 12)  # Adjust font path as needed
                text_y = offset_y + patch_size + 5

                for field in selected_fields:
                    # Retrieve data and only display if not "N/A"
                    if field == "Name" and obj.get("name") != "N/A":
                        text = obj["name"]
                    elif field == "RA" and obj.get("ra") is not None:
                        text = f"RA: {obj['ra']:.6f}"
                    elif field == "Dec" and obj.get("dec") is not None:
                        text = f"Dec: {obj['dec']:.6f}"
                    elif field == "Short Type" and obj.get("short_type") != "N/A":
                        text = f"Type: {obj['short_type']}"
                    elif field == "Long Type" and obj.get("long_type") != "N/A":
                        text = f"{obj['long_type']}"
                    elif field == "Redshift" and obj.get("redshift") != "N/A":
                        text = f"Redshift: {float(obj['redshift']):.5f}"  # Limit redshift to 5 decimal places
                    elif field == "Comoving Distance" and obj.get("comoving_distance") != "N/A":
                        text = f"Distance: {obj['comoving_distance']} GLy"
                    else:
                        continue  # Skip if field is not available or set to "N/A"

                    # Draw the text and increment the Y position
                    draw.text((offset_x + 10, text_y), text, (255, 255, 255), font=font)
                    text_y += text_row_height  # Space between lines

        finally:
            # Restore the original annotation and search circle settings
            self.show_names = original_show_names
            self.main_preview.circle_center = original_circle_center
            self.main_preview.circle_radius = original_circle_radius

        # Save the collage
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save Collage of Objects", "", "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )

        if file_path:
            collage_image.save(file_path)
            QMessageBox.information(self, "Save Successful", f"Collage saved as {file_path}")


        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle


    def get_selected_object_types(self):
        """Return a list of selected object types from the tree widget."""
        selected_types = []
        for i in range(self.object_tree.topLevelItemCount()):
            item = self.object_tree.topLevelItem(i)
            if item.checkState(0) == Qt.CheckState.Checked:
                selected_types.append(item.text(0))  # Add the object type
        return selected_types
    
    def search_defined_region(self):
        """Perform a Simbad search for the defined region and filter by selected object types."""
        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate the radius in degrees for the defined region (circle radius)
        radius_deg = self.get_defined_radius()

        # Perform the Simbad search in the defined region with the calculated radius
        self.query_simbad(radius_deg)


    def search_entire_image(self):
        """Search the entire image using Simbad with selected object types."""
        selected_types = self.get_selected_object_types()  # Get selected types from the advanced search panel
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate radius as the distance from the image center to a corner
        width, height = self.main_image.width(), self.main_image.height()
        center_x, center_y = width / 2, height / 2
        corner_x, corner_y = width, height  # Bottom-right corner
        # Calculate distance in pixels from center to corner
        radius_px = np.sqrt((corner_x - center_x) ** 2 + (corner_y - center_y) ** 2)
        # Convert radius from pixels to degrees
        radius_deg = float((radius_px * self.pixscale) / 3600.0)

        # Automatically set circle_center and circle_radius for the entire image
        self.circle_center = QPointF(center_x, center_y)  # Assuming QPointF is used
        self.circle_radius = radius_px  # Set this to allow the check in `query_simbad`

        # Perform the query with the calculated radius
        self.query_simbad(radius_deg, max_results=100000)




    def toggle_advanced_search(self):
        """Toggle visibility of the advanced search panel."""
        self.advanced_search_panel.setVisible(not self.advanced_search_panel.isVisible())

    def toggle_all_items(self):
        """Toggle selection for all items in the object tree."""
        # Check if all items are currently selected
        all_checked = all(
            self.object_tree.topLevelItem(i).checkState(0) == Qt.CheckState.Checked
            for i in range(self.object_tree.topLevelItemCount())
        )

        # Determine the new state: Uncheck if all are checked, otherwise check all
        new_state = Qt.CheckState.Unchecked if all_checked else Qt.CheckState.Checked

        # Apply the new state to all items
        for i in range(self.object_tree.topLevelItemCount()):
            item = self.object_tree.topLevelItem(i)
            item.setCheckState(0, new_state)


    def toggle_star_items(self):
        """Toggle selection for items related to stars."""
        star_keywords = ["star", "Eclipsing binary of W UMa type", "Spectroscopic binary",
                         "Variable of RS CVn type", "Mira candidate", "Long Period Variable candidate",
                         "Hot subdwarf", "Eclipsing Binary Candidate", "Eclipsing binary", 
                         "Cataclysmic Binary Candidate", "Possible Cepheid", "White Dwarf", 
                         "White Dwarf Candidate"]
        for i in range(self.object_tree.topLevelItemCount()):
            item = self.object_tree.topLevelItem(i)
            description = item.text(1).lower()
            object_type = item.text(0)
            if any(keyword.lower() in description for keyword in star_keywords) or "*" in object_type:
                new_state = Qt.CheckState.Checked if item.checkState(0) == Qt.CheckState.Unchecked else Qt.CheckState.Unchecked
                item.setCheckState(0, new_state)

    def toggle_galaxy_items(self):
        """Toggle selection for items related to galaxies."""
        for i in range(self.object_tree.topLevelItemCount()):
            item = self.object_tree.topLevelItem(i)
            description = item.text(1).lower()
            if "galaxy" in description or "galaxies" in description:
                new_state = Qt.CheckState.Checked if item.checkState(0) == Qt.CheckState.Unchecked else Qt.CheckState.Unchecked
                item.setCheckState(0, new_state)


    def toggle_advanced_search(self):
        """Toggle the visibility of the advanced search panel."""
        is_visible = self.advanced_search_panel_widget.isVisible()
        self.advanced_search_panel_widget.setVisible(not is_visible)

    def save_results_as_csv(self):
        """Save the results from the TreeWidget as a CSV file."""
        path, _ = QFileDialog.getSaveFileName(self, "Save CSV", "", "CSV Files (*.csv)")
        if path:
            with open(path, mode='w', newline='') as file:
                writer = csv.writer(file)
                # Write header
                writer.writerow(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])

                # Write data from TreeWidget
                for i in range(self.results_tree.topLevelItemCount()):
                    item = self.results_tree.topLevelItem(i)
                    row_data = [item.text(column) for column in range(self.results_tree.columnCount())]
                    writer.writerow(row_data)

            QMessageBox.information(self, "CSV Saved", f"Results successfully saved to {path}")        

    def filter_visible_objects(self):
        """Filter objects based on visibility threshold."""
        if not self.main_image:  # Ensure there's an image loaded
            QMessageBox.warning(self, "No Image", "Please load an image first.")
            return

        n = 0.2  # Threshold multiplier, adjust as needed
        median, std_dev = self.calculate_image_statistics(self.main_image)

        # Remove objects below threshold from results
        filtered_results = []
        for obj in self.results:
            if self.is_marker_visible(obj, median, std_dev, n):
                filtered_results.append(obj)

        # Update the results and redraw the markers
        self.results = filtered_results
        self.update_results_tree()
        self.main_preview.draw_query_results()

    def calculate_image_statistics(self, image):
        """Calculate median and standard deviation for a grayscale image efficiently using OpenCV."""
        
        # Convert QPixmap to QImage if necessary
        qimage = image.toImage()

        # Convert QImage to a format compatible with OpenCV
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 4)  # 4 channels (RGBA)
        img_array = np.array(ptr).reshape(height, width, 4)  # Convert to RGBA array

        # Convert to grayscale for analysis
        gray_image = cv2.cvtColor(img_array, cv2.COLOR_RGBA2GRAY)

        # Calculate median and standard deviation
        median = np.median(gray_image)
        _, std_dev = cv2.meanStdDev(gray_image)

        return median, std_dev[0][0]  # std_dev returns a 2D array, so we extract the single value
    
    def is_marker_visible(self, marker, median, std_dev, n):
        """Check if the marker's brightness is above the threshold."""
        threshold = median + n * std_dev
        check_size = 8  # Define a 4x4 region around the marker

        # Convert QPixmap to QImage to access pixel colors
        image = self.main_image.toImage()

        # Get marker coordinates in pixel space
        ra, dec = marker.get('ra'), marker.get('dec')
        if ra is not None and dec is not None:
            x, y = self.calculate_pixel_from_ra_dec(ra, dec)
            if x is None or y is None:
                return False  # Skip marker if it can't be converted to pixels
        else:
            return False

        # Calculate brightness in a 4x4 region around marker coordinates
        brightness_values = []
        for dx in range(-check_size // 2, check_size // 2):
            for dy in range(-check_size // 2, check_size // 2):
                px = x + dx
                py = y + dy
                if 0 <= px < image.width() and 0 <= py < image.height():
                    color = image.pixelColor(px, py)  # Get color from QImage
                    brightness = color.value() if color.isValid() else 0  # Adjust for grayscale
                    brightness_values.append(brightness)

        if brightness_values:
            average_brightness = sum(brightness_values) / len(brightness_values)
            return average_brightness > threshold
        else:
            return False



    def update_results_tree(self):
        """Refresh the TreeWidget to reflect current results."""
        self.results_tree.clear()
        for obj in self.results:
            item = QTreeWidgetItem([
                str(obj['ra']),
                str(obj['dec']),
                obj['name'],
                str(obj['diameter']),
                obj['short_type'],
                obj['long_type'],
                str(obj['redshift']),
                str(obj['comoving_distance'])
            ])
            self.results_tree.addTopLevelItem(item)

    def toggle_object_names(self, state):
        """Toggle the visibility of object names based on the checkbox state."""
        self.show_names = state == Qt.CheckState.Checked
        self.show_names = bool(state)        
        self.main_preview.draw_query_results()  # Redraw to apply the change


    # Function to clear search results and remove markers
    def clear_search_results(self):
        """Clear the search results and remove all markers."""
        self.results_tree.clear()        # Clear the results from the tree
        self.results = []                # Clear the results list
        self.main_preview.results = []   # Clear results from the main preview
        self.main_preview.selected_object = None
        self.main_preview.draw_query_results()  # Redraw the main image without markers
        self.status_label.setText("Results cleared.")

    def on_tree_item_clicked(self, item):
        """Handle item click in the TreeWidget to highlight the associated object."""
        object_name = item.text(2)

        # Find the object in results
        selected_object = next(
            (obj for obj in self.results if obj.get("name") == object_name), None
        )

        if selected_object:
            # Set the selected object in MainWindow and update views
            self.selected_object = selected_object
            self.main_preview.select_object(selected_object)
            self.main_preview.draw_query_results()
            self.main_preview.update_mini_preview() 
            
            

    def on_tree_item_double_clicked(self, item):
        """Handle double-click event on a TreeWidget item to open SIMBAD or NED URL based on source."""
        object_name = item.text(2)  # Assuming 'Name' is in the third column
        ra = float(item.text(0).strip())  # Assuming RA is in the first column
        dec = float(item.text(1).strip())  # Assuming Dec is in the second column
        
        # Retrieve the entry directly from self.query_results
        entry = next((result for result in self.query_results if float(result['ra']) == ra and float(result['dec']) == dec), None)
        source = entry.get('source', 'Simbad') if entry else 'Simbad'  # Default to "Simbad" if entry not found

        if source == "Simbad" and object_name:
            # Open Simbad URL with encoded object name
            encoded_name = quote(object_name)
            simbad_url = f"https://simbad.cds.unistra.fr/simbad/sim-basic?Ident={encoded_name}&submit=SIMBAD+search"
            webbrowser.open(simbad_url)
        elif source == "Vizier":
            # Format the NED search URL with proper RA, Dec, and radius
            radius = 5 / 60  # Radius in arcminutes (5 arcseconds)
            dec_sign = "%2B" if dec >= 0 else "-"  # Determine sign for declination
            ned_url = f"http://ned.ipac.caltech.edu/conesearch?search_type=Near%20Position%20Search&ra={ra:.6f}d&dec={dec_sign}{abs(dec):.6f}d&radius={radius:.3f}&in_csys=Equatorial&in_equinox=J2000.0"
            webbrowser.open(ned_url)
        elif source == "Mast":
            # Open MAST URL using RA and Dec with a small radius for object lookup
            mast_url = f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
            webbrowser.open(mast_url)            

    def copy_ra_dec_to_clipboard(self):
        """Copy the currently displayed RA and Dec to the clipboard."""
        # Access the RA and Dec labels directly
        ra_text = self.ra_label.text()
        dec_text = self.dec_label.text()
        
        # Combine RA and Dec text for clipboard
        clipboard_text = f"{ra_text}, {dec_text}"
        
        clipboard = QApplication.instance().clipboard()
        clipboard.setText(clipboard_text)
        
        QMessageBox.information(self, "Copied", "Current RA/Dec copied to clipboard!")
    

    def open_image(self):
        self.image_path, _ = QFileDialog.getOpenFileName(self, "Open Image", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fit *.fits *.xisf)")
        if self.image_path:
            img_array, original_header, bit_depth, is_mono = load_image(self.image_path)
            if img_array is not None:

                self.image_data = img_array
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono

                # Prepare image for display
                if img_array.ndim == 2:  # Single-channel image
                    img_array = np.stack([img_array] * 3, axis=-1)  # Expand to 3 channels


                # Prepare image for display
                img = (img_array * 255).astype(np.uint8)
                height, width, _ = img.shape
                bytes_per_line = 3 * width
                qimg = QImage(img.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
                pixmap = QPixmap.fromImage(qimg)

                self.main_image = pixmap
                scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                self.mini_preview.setPixmap(scaled_pixmap)

                self.main_scene.clear()
                self.main_scene.addPixmap(pixmap)
                self.main_preview.setSceneRect(QRectF(pixmap.rect()))
                self.zoom_level = 1.0
                self.main_preview.resetTransform()
                self.main_preview.centerOn(self.main_scene.sceneRect().center())
                self.update_green_box()

                # Initialize WCS from FITS header if it is a FITS file
                if self.image_path.lower().endswith(('.fits', '.fit')):
                    with fits.open(self.image_path) as hdul:
                        self.header = hdul[0].header
                        
                        try:
                            # Use only the first two dimensions for WCS
                            self.wcs = WCS(self.header, naxis=2, relax=True)
                            
                            # Calculate and set pixel scale
                            pixel_scale_matrix = self.wcs.pixel_scale_matrix
                            self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
                            self.center_ra, self.center_dec = self.wcs.wcs.crval
                            self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
                            self.print_corner_coordinates()
                            
                            print(f"Header CROTA2 Value: {self.header.get('CROTA2', 'Not Found')}")

                            # Display WCS information
                            # Set orientation based on WCS data if available
                            if 'CROTA2' in self.header:
                                try:
                                    self.orientation = float(self.header['CROTA2'])  # Convert to float
                                except (ValueError, TypeError):
                                    self.orientation = None
                                    print("CROTA2 found, but could not convert to float.")
                            else:
                                # Use calculate_orientation if CROTA2 is not present
                                self.orientation = calculate_orientation(self.header)
                                if self.orientation is None:
                                    print("Orientation: CD matrix elements not found in WCS header.")

                            # --- ✅ Ensure `self.orientation` is a float before using it ---
                            if self.orientation is not None:
                                try:
                                    self.orientation = float(self.orientation)  # Final conversion check
                                    print(f"Orientation: {self.orientation:.2f}°")
                                    self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                                except (ValueError, TypeError):
                                    print(f"Failed to format orientation: {self.orientation}")
                                    self.orientation_label.setText("Orientation: N/A")
                            else:
                                self.orientation_label.setText("Orientation: N/A")


                            print(f"WCS data loaded from FITS header: RA={self.center_ra}, Dec={self.center_dec}, "
                                f"Pixel Scale={self.pixscale} arcsec/px")
                            
                            
                        except ValueError as e:
                            print("Error initializing WCS:", e)
                            QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from FITS header.")
                elif self.image_path.lower().endswith('.xisf'):
                    # Load WCS from XISF properties
                    xisf_meta = self.extract_xisf_metadata(self.image_path)
                    self.metadata = xisf_meta  # Ensure metadata is stored in self.metadata for later use

                    # Construct WCS header from XISF properties
                    header = self.construct_fits_header_from_xisf(xisf_meta)
                    if header:
                        try:
                            self.initialize_wcs_from_header(header)
                        except ValueError as e:
                            print("Error initializing WCS from XISF:", e)
                            QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from XISF properties.")
                else:
                    # For non-FITS images (e.g., JPEG, PNG), prompt directly for a blind solve
                    self.prompt_blind_solve()

    def extract_xisf_metadata(self, xisf_path):
        """
        Extract metadata from a .xisf file, focusing on WCS and essential image properties.
        """
        try:
            # Load the XISF file
            xisf = XISF(xisf_path)
            
            # Extract file and image metadata
            self.file_meta = xisf.get_file_metadata()
            self.image_meta = xisf.get_images_metadata()[0]  # Get metadata for the first image
            return self.image_meta
        except Exception as e:
            print(f"Error reading XISF metadata: {e}")
            return None

    def initialize_wcs_from_header(self, header):
        """ Initialize WCS data from a FITS header or constructed XISF header """
        try:
            # Use only the first two dimensions for WCS
            self.wcs = WCS(header, naxis=2, relax=True)
            
            # Calculate and set pixel scale
            pixel_scale_matrix = self.wcs.pixel_scale_matrix
            self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
            self.center_ra, self.center_dec = self.wcs.wcs.crval
            self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
            self.print_corner_coordinates()

            # --- 🔍 Debugging Output ---
            print(f"Header CROTA2 Value: {header.get('CROTA2', 'Not Found')}")

            # Display WCS information
            if 'CROTA2' in header:
                try:
                    self.orientation = float(header['CROTA2'])  # Convert to float
                except (ValueError, TypeError):
                    self.orientation = None
                    print("CROTA2 found, but could not convert to float.")
            else:
                self.orientation = calculate_orientation(header)
                if self.orientation is None:
                    print("Orientation: CD matrix elements not found in WCS header.")

            # --- ✅ Ensure `self.orientation` is a float before using it ---
            if self.orientation is not None:
                try:
                    self.orientation = float(self.orientation)  # Final conversion check
                    print(f"Orientation: {self.orientation:.2f}°")
                    self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                except (ValueError, TypeError):
                    print("Final conversion failed. Orientation is not a float.")
                    self.orientation_label.setText("Orientation: N/A")
            else:
                print("Orientation is None.")
                self.orientation_label.setText("Orientation: N/A")

            print(f"WCS data loaded: RA={self.center_ra}, Dec={self.center_dec}, Pixel Scale={self.pixscale} arcsec/px")

        except ValueError as e:
            raise ValueError(f"WCS initialization error: {e}")

    def construct_fits_header_from_xisf(self, xisf_meta):
        """ Convert XISF metadata to a FITS header compatible with WCS """
        header = fits.Header()

        # Define WCS keywords to populate
        wcs_keywords = ["CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", 
                        "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]

        # Populate WCS and FITS keywords
        if 'FITSKeywords' in xisf_meta:
            for keyword, values in xisf_meta['FITSKeywords'].items():
                for entry in values:
                    if 'value' in entry:
                        value = entry['value']
                        if keyword in wcs_keywords:
                            try:
                                value = int(value)
                            except ValueError:
                                value = float(value)
                        header[keyword] = value

        # Manually add WCS information if missing
        header.setdefault('CTYPE1', 'RA---TAN')
        header.setdefault('CTYPE2', 'DEC--TAN')

        # Add SIP distortion suffix if SIP coefficients are present
        if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
            header['CTYPE1'] = 'RA---TAN-SIP'
            header['CTYPE2'] = 'DEC--TAN-SIP'

        # Set default reference pixel to the center of the image
        header.setdefault('CRPIX1', self.image_data.shape[1] / 2)
        header.setdefault('CRPIX2', self.image_data.shape[0] / 2)

        # Retrieve RA and DEC values if available
        if 'RA' in xisf_meta['FITSKeywords']:
            header['CRVAL1'] = float(xisf_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
        if 'DEC' in xisf_meta['FITSKeywords']:
            header['CRVAL2'] = float(xisf_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

        # Calculate pixel scale if focal length and pixel size are available
        if 'FOCALLEN' in xisf_meta['FITSKeywords'] and 'XPIXSZ' in xisf_meta['FITSKeywords']:
            focal_length = float(xisf_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
            pixel_size = float(xisf_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
            pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
            header['CDELT1'] = -pixel_scale / 3600.0
            header['CDELT2'] = pixel_scale / 3600.0
        else:
            header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
            header['CDELT2'] = 2.77778e-4

        # Populate CD matrix using the XISF LinearTransformationMatrix if available
        if 'XISFProperties' in xisf_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_meta['XISFProperties']:
            linear_transform = xisf_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
            header['CD1_1'] = linear_transform[0][0]
            header['CD1_2'] = linear_transform[0][1]
            header['CD2_1'] = linear_transform[1][0]
            header['CD2_2'] = linear_transform[1][1]
        else:
            # Use pixel scale for CD matrix if no linear transformation is defined
            header['CD1_1'] = header['CDELT1']
            header['CD1_2'] = 0.0
            header['CD2_1'] = 0.0
            header['CD2_2'] = header['CDELT2']

        # Ensure numeric types for SIP distortion keywords if present
        sip_keywords = ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
        for sip_key in sip_keywords:
            if sip_key in xisf_meta['XISFProperties']:
                try:
                    value = xisf_meta['XISFProperties'][sip_key]['value']
                    header[sip_key] = int(value) if isinstance(value, str) and value.isdigit() else float(value)
                except ValueError:
                    pass  # Ignore any invalid conversion

        return header

    def print_corner_coordinates(self):
        """Print the RA/Dec coordinates of the four corners of the image for debugging purposes."""
        if not hasattr(self, 'wcs'):
            print("WCS data is incomplete, cannot calculate corner coordinates.")
            return

        width = self.main_image.width()
        height = self.main_image.height()

        # Define the corner coordinates
        corners = {
            "Top-Left": (0, 0),
            "Top-Right": (width, 0),
            "Bottom-Left": (0, height),
            "Bottom-Right": (width, height)
        }

        print("Corner RA/Dec coordinates:")
        for corner_name, (x, y) in corners.items():
            ra, dec = self.calculate_ra_dec_from_pixel(x, y)
            ra_hms = self.convert_ra_to_hms(ra)
            dec_dms = self.convert_dec_to_dms(dec)
            print(f"{corner_name}: RA={ra_hms}, Dec={dec_dms}")

    def calculate_ra_dec_from_pixel(self, x, y):
        """Convert pixel coordinates (x, y) to RA/Dec using Astropy WCS."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert pixel coordinates to sky coordinates
        ra, dec = self.wcs.all_pix2world(x, y, 0)

        return ra, dec
                        


    def update_ra_dec_from_mouse(self, event):
        """Update RA and Dec based on mouse position over the main preview."""
        if self.main_image and self.wcs:
            pos = self.main_preview.mapToScene(event.pos())
            x, y = int(pos.x()), int(pos.y())

            if 0 <= x < self.main_image.width() and 0 <= y < self.main_image.height():
                ra, dec = self.calculate_ra_dec_from_pixel(x, y)
                ra_hms = self.convert_ra_to_hms(ra)
                dec_dms = self.convert_dec_to_dms(dec)

                # Update RA/Dec labels
                self.ra_label.setText(f"RA: {ra_hms}")
                self.dec_label.setText(f"Dec: {dec_dms}")

                # --- 🔍 Debugging Output ---
                #print(f"Current Orientation Type: {type(self.orientation)}, Value: {self.orientation}")

                # ✅ Ensure `self.orientation` is a float before formatting
                if self.orientation is not None:
                    try:
                        self.orientation = float(self.orientation)  # Final safeguard conversion
                        self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                    except (ValueError, TypeError):
                        print(f"Failed to format orientation: {self.orientation}")
                        self.orientation_label.setText("Orientation: N/A")
                else:
                    self.orientation_label.setText("Orientation: N/A")
        else:
            self.ra_label.setText("RA: N/A")
            self.dec_label.setText("Dec: N/A")
            self.orientation_label.setText("Orientation: N/A")



    def convert_ra_to_hms(self, ra_deg):
        """Convert Right Ascension in degrees to Hours:Minutes:Seconds format."""
        ra_hours = ra_deg / 15.0  # Convert degrees to hours
        hours = int(ra_hours)
        minutes = int((ra_hours - hours) * 60)
        seconds = (ra_hours - hours - minutes / 60.0) * 3600
        return f"{hours:02d}h{minutes:02d}m{seconds:05.2f}s"

    def convert_dec_to_dms(self, dec_deg):
        """Convert Declination in degrees to Degrees:Minutes:Seconds format."""
        sign = "-" if dec_deg < 0 else "+"
        dec_deg = abs(dec_deg)
        degrees = int(dec_deg)
        minutes = int((dec_deg - degrees) * 60)
        seconds = (dec_deg - degrees - minutes / 60.0) * 3600
        degree_symbol = "\u00B0"
        return f"{sign}{degrees:02d}{degree_symbol}{minutes:02d}m{seconds:05.2f}s"                 

    def check_astrometry_data(self, header):
        return "CTYPE1" in header and "CTYPE2" in header

    def prompt_blind_solve(self):
        reply = QMessageBox.question(
            self, "Astrometry Data Missing",
            "No astrometry data found in the image. Would you like to perform a blind solve?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.perform_blind_solve()

    def perform_blind_solve(self):
        """
        First attempts to plate-solve the loaded image using ASTAP.
        If that fails, falls back to performing a blind solve via Astrometry.net.
        Updates the WCS (self.wcs) and header (self.header) accordingly.
        """
        # --- First, try ASTAP plate solve ---
        self.status_label.setText("Status: Attempting ASTAP plate solve...")
        QApplication.processEvents()
        solved_header = self.plate_solve_image()  # This method should try to solve via ASTAP and return a header (or None).
        if solved_header is not None:
            self.status_label.setText("ASTAP plate solve succeeded.")
            try:
                # Update self.header with the solved header data.
                self.header.update(solved_header)
                # Reinitialize the WCS from the new header.
                self.wcs = WCS(self.header, naxis=2, relax=True)
                QMessageBox.information(self, "Plate Solve", "ASTAP plate solve succeeded. WCS updated.")
            except Exception as e:
                QMessageBox.critical(self, "Plate Solve", f"Error initializing WCS from ASTAP solution: {e}")
            return

        # --- If ASTAP plate solve failed, fall back to blind solve via Astrometry.net ---
        self.status_label.setText("Status: ASTAP failed. Proceeding with blind solve via Astrometry.net...")
        QApplication.processEvents()

        # Load or prompt for API key
        api_key = load_api_key()
        if not api_key:
            api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
            if ok and api_key:
                save_api_key(api_key)
            else:
                QMessageBox.warning(self, "API Key Required", "Blind solve cannot proceed without an API key.")
                return

        try:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()

            # Step 1: Login to Astrometry.net
            session_key = self.login_to_astrometry(api_key)

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()
            
            # Step 2: Upload the image and get submission ID
            subid = self.upload_image_to_astrometry(self.image_path, session_key)

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            
            # Step 3: Poll for the job ID until it's available
            job_id = self.poll_submission_status(subid)
            if not job_id:
                raise TimeoutError("Failed to retrieve job ID from Astrometry.net after multiple attempts.")
            
            self.status_label.setText("Status: Job ID found, processing image...")
            QApplication.processEvents()

            # Step 4a: Poll for the calibration data, ensuring RA/Dec are available
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                raise TimeoutError("Calibration data did not complete in the expected timeframe.")
            
            # Set pixscale and other necessary attributes from calibration data
            self.pixscale = calibration_data.get('pixscale')

            self.status_label.setText("Status: Calibration complete, downloading WCS file...")
            QApplication.processEvents()

            # Step 4b: Download the WCS FITS file for complete calibration data
            wcs_header = self.retrieve_and_apply_wcs(job_id)
            if not wcs_header:
                raise TimeoutError("Failed to retrieve WCS FITS file from Astrometry.net.")

            self.status_label.setText("Status: Applying astrometric solution to the image...")
            QApplication.processEvents()

            # Apply calibration data to the WCS
            self.apply_wcs_header(wcs_header)
            self.status_label.setText("Status: Blind Solve Complete.")
            QMessageBox.information(self, "Blind Solve Complete", "Astrometric solution applied successfully.")
        except Exception as e:
            self.status_label.setText("Status: Blind Solve Failed.")
            QMessageBox.critical(self, "Blind Solve Failed", f"An error occurred: {str(e)}")

    def plate_solve_image(self):
        """
        Attempts to plate-solve the loaded image using ASTAP.
        If no ASTAP executable is set (or the user cancels its selection),
        it falls back to blind solving via Astrometry.net.
        On success, the method updates self.header and initializes self.wcs.
        """
        if not hasattr(self, 'image_path') or not self.image_path:
            QMessageBox.warning(self, "Plate Solve", "No image loaded.")
            return

        # Check if the ASTAP executable is set in settings.
        astap_exe = self.settings.value("astap/exe_path", "", type=str)
        if not astap_exe or not os.path.exists(astap_exe):
            import sys
            if sys.platform.startswith("win"):
                executable_filter = "Executables (*.exe);;All Files (*)"
            else:
                executable_filter = "Executables (astap);;All Files (*)"
            new_path, _ = QFileDialog.getOpenFileName(
                self, "Select ASTAP Executable", "", executable_filter
            )
            if new_path:
                astap_exe = new_path
                self.settings.setValue("astap/exe_path", astap_exe)
                QMessageBox.information(self, "Plate Solve", "ASTAP path updated successfully.")
            else:
                QMessageBox.information(self, "Plate Solve", "No ASTAP executable provided. Falling back to blind solve.")
                return None

        # Normalize the loaded image.
        normalized = self.stretch_image(self.image_data)
        
        # Save the normalized image to a temporary FITS file.
        try:
            tmp_path = self.save_temp_fits_image(normalized, self.image_path)
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error saving temporary FITS: {e}")
            return

        # Run ASTAP on the temporary file.
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(astap_exe, args)
        if not process.waitForStarted(5000):
            QMessageBox.critical(self, "Plate Solve", "Failed to start ASTAP process.")
            os.remove(tmp_path)
            self.blind_solve_image()
            return
        if not process.waitForFinished(300000):
            QMessageBox.critical(self, "Plate Solve", "ASTAP process timed out.")
            os.remove(tmp_path)
            self.blind_solve_image()
            return

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)
        
        if exit_code != 0:
            os.remove(tmp_path)
            QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Falling back to blind solve.")
            self.blind_solve_image()
            return

        # --- Retrieve the initial solved header from the temporary FITS file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error reading solved header: {e}")
            os.remove(tmp_path)
            self.blind_solve_image()
            return

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                import re
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Matches a FITS header keyword and its value (with an optional comment).
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        # --- Add any missing required WCS keywords ---
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2 are ideally provided by ASTAP.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Convert keys that are expected to be numeric from strings to numbers ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # For keys that should be integers, you can use int(float(...)) if necessary.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Ensure integer keywords are stored as integers ---
        for key in ["WCSAXES", "NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to int.")


        os.remove(tmp_path)
        print("ASTAP plate solving successful. Final solved header:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        # Update the main image header and reinitialize WCS.
        self.header.update(solved_header)
        try:
            self.wcs = WCS(self.header, naxis=2, relax=True)
            QMessageBox.information(self, "Plate Solve", "ASTAP plate solve succeeded. WCS updated.")
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error initializing WCS from solved header: {e}")
            return

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def retrieve_and_apply_wcs(self, job_id):
        """Download the wcs.fits file from Astrometry.net, extract WCS header data, and apply it."""
        try:
            wcs_url = f"https://nova.astrometry.net/wcs_file/{job_id}"
            wcs_filepath = "wcs.fits"
            max_retries = 10
            delay = 10  # seconds
            
            for attempt in range(max_retries):
                # Attempt to download the file
                response = requests.get(wcs_url, stream=True)
                response.raise_for_status()

                # Save the WCS file locally
                with open(wcs_filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                # Check if the downloaded file is a valid FITS file
                try:
                    with fits.open(wcs_filepath, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
                        # If it opens correctly, return the header
                        wcs_header = hdul[0].header
                        print("WCS header successfully retrieved.")
                        self.wcs = WCS(wcs_header)
                        return wcs_header
                except Exception as e:
                    print(f"Attempt {attempt + 1}: Failed to process WCS file - possibly HTML instead of FITS. Retrying in {delay} seconds...")
                    print(f"Error: {e}")
                    time.sleep(delay)  # Wait and retry
            
            print("Failed to download a valid WCS FITS file after multiple attempts.")
            return None

        except requests.exceptions.RequestException as e:
            print(f"Error downloading WCS file: {e}")
        except Exception as e:
            print(f"Error processing WCS file: {e}")
            
        return None



    def apply_wcs_header(self, wcs_header):
        """Apply WCS header to create a WCS object and set orientation."""
        self.wcs = WCS(wcs_header)  # Initialize WCS with header directly
        
        # Set orientation based on WCS data if available
        if 'CROTA2' in wcs_header:
            self.orientation = wcs_header['CROTA2']
        else:
            # Use calculate_orientation if CROTA2 is not present
            self.orientation = calculate_orientation(wcs_header)
            if self.orientation is None:
                print("Orientation: CD matrix elements not found in WCS header.")

        # Update orientation label
        if self.orientation is not None:
            self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
        else:
            self.orientation_label.setText("Orientation: N/A")

        print("WCS applied successfully from header data.")


    def calculate_pixel_from_ra_dec(self, ra, dec):
        """Convert RA/Dec to pixel coordinates using the WCS data."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert RA and Dec to pixel coordinates using the WCS object
        sky_coord = SkyCoord(ra, dec, unit=(u.deg, u.deg), frame='icrs')
        x, y = self.wcs.world_to_pixel(sky_coord)
        
        return int(x), int(y)

    def login_to_astrometry(self, api_key):
        try:
            response = requests.post(
                ASTROMETRY_API_URL + "login",
                data={'request-json': json.dumps({"apikey": api_key})}
            )
            response_data = response.json()
            if response_data.get("status") == "success":
                return response_data["session"]
            else:
                raise ValueError("Login failed: " + response_data.get("error", "Unknown error"))
        except Exception as e:
            raise Exception("Login to Astrometry.net failed: " + str(e))


    def upload_image_to_astrometry(self, image_path, session_key):
        try:
            # Check if the file is XISF format
            file_extension = os.path.splitext(image_path)[-1].lower()
            if file_extension == ".xisf":
                # Load the XISF image
                xisf = XISF(image_path)
                im_data = xisf.read_image(0)
                
                # Convert to a temporary TIFF file for upload
                temp_image_path = os.path.splitext(image_path)[0] + "_converted.tif"
                if im_data.dtype == np.float32 or im_data.dtype == np.float64:
                    im_data = np.clip(im_data, 0, 1) * 65535
                im_data = im_data.astype(np.uint16)

                # Save as TIFF
                if im_data.shape[-1] == 1:  # Grayscale
                    tiff.imwrite(temp_image_path, np.squeeze(im_data, axis=-1))
                else:  # RGB
                    tiff.imwrite(temp_image_path, im_data)

                print(f"Converted XISF file to TIFF at {temp_image_path} for upload.")
                image_path = temp_image_path  # Use the converted file for upload

            # Upload the image file
            with open(image_path, 'rb') as image_file:
                files = {'file': image_file}
                data = {
                    'request-json': json.dumps({
                        "publicly_visible": "y",
                        "allow_modifications": "d",
                        "session": session_key,
                        "allow_commercial_use": "d"
                    })
                }
                response = requests.post(ASTROMETRY_API_URL + "upload", files=files, data=data)
                response_data = response.json()
                if response_data.get("status") == "success":
                    return response_data["subid"]
                else:
                    raise ValueError("Image upload failed: " + response_data.get("error", "Unknown error"))

        except Exception as e:
            raise Exception("Image upload to Astrometry.net failed: " + str(e))

        finally:
            # Clean up temporary file if created
            if file_extension == ".xisf" and os.path.exists(temp_image_path):
                os.remove(temp_image_path)
                print(f"Temporary TIFF file {temp_image_path} deleted after upload.")



    def poll_submission_status(self, subid):
        """Poll Astrometry.net to retrieve the job ID once the submission is processed."""
        max_retries = 90  # Adjust as necessary
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"submissions/{subid}")
                response_data = response.json()
                jobs = response_data.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
                else:
                    print(f"Polling attempt {retries + 1}: Job not ready yet.")
            except Exception as e:
                print(f"Error while polling submission status: {e}")
            
            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries
        
        return None

    def poll_calibration_data(self, job_id):
        """Poll Astrometry.net to retrieve the calibration data once it's available."""
        max_retries = 90  # Retry for up to 15 minutes (90 * 10 seconds)
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/")
                response_data = response.json()
                if response_data and 'ra' in response_data and 'dec' in response_data:
                    print("Calibration data retrieved:", response_data)
                    return response_data  # Calibration data is complete
                else:
                    print(f"Calibration data not available yet (Attempt {retries + 1})")
            except Exception as e:
                print(f"Error retrieving calibration data: {e}")

            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries

        return None


    #If originally a fits file update the header
    def update_fits_with_wcs(self, filepath, calibration_data):
        if not filepath.lower().endswith(('.fits', '.fit')):
            print("File is not a FITS file. Skipping WCS header update.")
            return

        print("Updating image with calibration data:", calibration_data)
        with fits.open(filepath, mode='update') as hdul:
            header = hdul[0].header
            header['CTYPE1'] = 'RA---TAN'
            header['CTYPE2'] = 'DEC--TAN'
            header['CRVAL1'] = calibration_data['ra']
            header['CRVAL2'] = calibration_data['dec']
            header['CRPIX1'] = hdul[0].data.shape[1] / 2
            header['CRPIX2'] = hdul[0].data.shape[0] / 2
            scale = calibration_data['pixscale'] / 3600
            orientation = np.radians(calibration_data['orientation'])
            header['CD1_1'] = -scale * np.cos(orientation)
            header['CD1_2'] = scale * np.sin(orientation)
            header['CD2_1'] = -scale * np.sin(orientation)
            header['CD2_2'] = -scale * np.cos(orientation)
            header['RADECSYS'] = 'ICRS'

    def on_mini_preview_press(self, event):
        # Set dragging flag and scroll the main preview to the position in the mini preview.
        self.dragging = True
        self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_drag(self, event):
        # Scroll to the new position while dragging in the mini preview.
        if self.dragging:
            self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_release(self, event):
        # Stop dragging
        self.dragging = False

    def scroll_main_preview_to_mini_position(self, event):
        """Scrolls the main preview to the corresponding position based on the mini preview click."""
        if self.main_image:
            # Get the click position in the mini preview
            click_x = event.pos().x()
            click_y = event.pos().y()
            
            # Calculate scale factors based on the difference in dimensions between main image and mini preview
            scale_factor_x = self.main_scene.sceneRect().width() / self.mini_preview.width()
            scale_factor_y = self.main_scene.sceneRect().height() / self.mini_preview.height()
            
            # Scale the click position to the main preview coordinates
            scaled_x = click_x * scale_factor_x
            scaled_y = click_y * scale_factor_y
            
            # Center the main preview on the calculated position
            self.main_preview.centerOn(scaled_x, scaled_y)
            
            # Update the green box after scrolling
            self.main_preview.update_mini_preview()

    def update_green_box(self):
        if self.main_image:
            factor_x = self.mini_preview.width() / self.main_image.width()
            factor_y = self.mini_preview.height() / self.main_image.height()
            
            # Get the current view rectangle in the main preview (in scene coordinates)
            view_rect = self.main_preview.mapToScene(self.main_preview.viewport().rect()).boundingRect()
            
            # Calculate the green box rectangle, shifted upward by half its height to center it
            green_box_rect = QRectF(
                view_rect.x() * factor_x,
                view_rect.y() * factor_y,
                view_rect.width() * factor_x,
                view_rect.height() * factor_y
            )
            
            # Scale the main image for the mini preview and draw the green box on it
            pixmap = self.main_image.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            painter = QPainter(pixmap)
            pen = QPen(QColor(0, 255, 0), 2)
            painter.setPen(pen)
            painter.drawRect(green_box_rect)
            painter.end()
            self.mini_preview.setPixmap(pixmap)

    @staticmethod
    def calculate_angular_distance(ra1, dec1, ra2, dec2):
        # Convert degrees to radians
        ra1, dec1, ra2, dec2 = map(math.radians, [ra1, dec1, ra2, dec2])

        # Haversine formula for angular distance
        delta_ra = ra2 - ra1
        delta_dec = dec2 - dec1
        a = (math.sin(delta_dec / 2) ** 2 +
            math.cos(dec1) * math.cos(dec2) * math.sin(delta_ra / 2) ** 2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        angular_distance = math.degrees(c)
        return angular_distance
    
    @staticmethod
    def format_distance_as_dms(angle):
        degrees = int(angle)
        minutes = int((angle - degrees) * 60)
        seconds = (angle - degrees - minutes / 60) * 3600
        return f"{degrees}° {minutes}' {seconds:.2f}\""


    def wheel_zoom(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()

    def zoom_in(self):
        self.zoom_level *= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()
        
    def zoom_out(self):
        self.zoom_level /= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.update_green_box()


    def compute_pixscale(self):
        """
        Computes the pixel scale (arcsec/pixel) from the header's CD keywords.
        """
        try:
            cd1_1 = float(self.header.get('CD1_1', 0))
            cd1_2 = float(self.header.get('CD1_2', 0))
            # Calculate scale in degrees per pixel and convert to arcsec.
            pixscale = math.sqrt(cd1_1**2 + cd1_2**2) * 3600.0
            print("Calculated pixscale from header:", pixscale)
            return pixscale
        except Exception as e:
            print("Error calculating pixscale:", e)
            return None

    def get_defined_radius(self):
        """
        Returns the radius (in arcminutes) for the current circle.
        If self.pixscale is None, attempt to calculate it manually.
        """
        if self.pixscale is None:
            self.pixscale = self.compute_pixscale()
            if self.pixscale is None:
                print("Warning: Could not compute pixscale from header.")
                return None

        # The circle_radius is in pixels; convert to arcminutes.
        return float((self.circle_radius * self.pixscale) / 3600.0)

    def update_circle_data(self):
        """Updates the status based on the circle's center and radius."""
        if self.circle_center and self.circle_radius > 0:
            # Make sure we have a valid pixscale.
            if self.pixscale is None:
                self.pixscale = self.compute_pixscale()
                if self.pixscale is None:
                    self.status_label.setText("No pixscale available for radius calculation.")
                    print("Warning: Pixscale is None. Cannot calculate radius in arcminutes.")
                    return

            # Convert circle center to RA/Dec and radius to arcminutes.
            ra, dec = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            radius_arcmin = self.circle_radius * self.pixscale / 60.0  # from arcsec to arcmin
            self.status_label.setText(
                f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
            )
        else:
            self.status_label.setText("No search area defined.")



    def get_defined_radius(self):
        """Calculate radius in degrees for the defined region (circle radius)."""
        if self.circle_radius <= 0:
            return 0
        return float((self.circle_radius * self.pixscale) / 3600.0)


    def query_simbad(self, radius_deg, max_results=None):
        """Query Simbad based on the defined search circle using a single ADQL query, with filtering by selected types."""
            # If max_results is not provided, use the value from settings
        max_results = max_results if max_results is not None else self.max_results
        # Check if the circle center and radius are defined
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area", "Please define a search circle by Shift-clicking and dragging.")
            return

        # Calculate RA, Dec, and radius in degrees from pixel coordinates
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates", "Could not determine the RA/Dec of the circle center.")
            return

        # Convert radius from arcseconds to degrees
        radius_deg = radius_deg

        # Get selected types from the tree widget
        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Build ADQL query
        query = f"""
            SELECT TOP {max_results} ra, dec, main_id, rvz_redshift, otype, galdim_majaxis
            FROM basic
            WHERE CONTAINS(POINT('ICRS', basic.ra, basic.dec), CIRCLE('ICRS', {ra_center}, {dec_center}, {radius_deg})) = 1
        """

        try:
            # Execute the query using Simbad's TAP service
            result = Simbad.query_tap(query)

            # Clear previous results in the tree
            self.results_tree.clear()
            query_results = []

            if result is None or len(result) == 0:
                QMessageBox.information(self, "No Results", "No objects found in the specified area.")
                return

            # Process and display results, filtering by selected types
            for row in result:
                short_type = row["otype"]
                if short_type not in selected_types:
                    continue  # Skip items not in selected types

                # Retrieve other data fields
                ra = row["ra"]
                dec = row["dec"]
                main_id = row["main_id"]
                redshift = row["rvz_redshift"] if row["rvz_redshift"] is not None else "--"
                diameter = row.get("galdim_majaxis", "N/A")
                comoving_distance = calculate_comoving_distance(float(redshift)) if redshift != "--" else "N/A"

                # Map short type to long type
                long_type = otype_long_name_lookup.get(short_type, short_type)

                # Add to TreeWidget
                item = QTreeWidgetItem([
                    f"{ra:.6f}", f"{dec:.6f}", main_id, str(diameter), short_type, long_type, str(redshift), str(comoving_distance)
                ])
                self.results_tree.addTopLevelItem(item)

                # Append full details as a dictionary to query_results
                query_results.append({
                    'ra': ra,
                    'dec': dec,
                    'name': main_id,
                    'diameter': diameter,
                    'short_type': short_type,
                    'long_type': long_type,
                    'redshift': redshift,
                    'comoving_distance': comoving_distance,
                    'source' : "Simbad"
                })

            # Set query results in the CustomGraphicsView for display
            self.main_preview.set_query_results(query_results)
            self.query_results = query_results  # Keep a reference to results in MainWindow
            self.update_object_count()

        except Exception as e:
            # Fallback to legacy region query if TAP fails
            try:
                QMessageBox.warning(self, "Query Failed", f"TAP service failed, falling back to legacy region query. Error: {str(e)}")
                
                # Legacy region query fallback
                coord = SkyCoord(ra_center, dec_center, unit="deg")
                legacy_result = Simbad.query_region(coord, radius=radius_deg * u.deg)

                if legacy_result is None or len(legacy_result) == 0:
                    QMessageBox.information(self, "No Results", "No objects found in the specified area (fallback query).")
                    return

                # Process legacy query results
                query_results = []
                self.results_tree.clear()

                for row in legacy_result:
                    try:
                        # Convert RA/Dec to degrees
                        coord = SkyCoord(row["RA"], row["DEC"], unit=(u.hourangle, u.deg))
                        ra = coord.ra.deg  # RA in degrees
                        dec = coord.dec.deg  # Dec in degrees
                    except Exception as coord_error:
                        print(f"Failed to convert RA/Dec for {row['MAIN_ID']}: {coord_error}")
                        continue  # Skip this object if conversion fails

                    # Retrieve other data fields
                    main_id = row["MAIN_ID"]
                    short_type = row["OTYPE"]
                    long_type = otype_long_name_lookup.get(short_type, short_type)

                    # Fallback does not provide some fields, so we use placeholders
                    diameter = "N/A"
                    redshift = "N/A"
                    comoving_distance = "N/A"

                    # Add to TreeWidget for display
                    item = QTreeWidgetItem([
                        f"{ra:.6f}", f"{dec:.6f}", main_id, diameter, short_type, long_type, redshift, comoving_distance
                    ])
                    self.results_tree.addTopLevelItem(item)

                    # Append full details to query_results
                    query_results.append({
                        'ra': ra,  # Ensure degrees format
                        'dec': dec,  # Ensure degrees format
                        'name': main_id,
                        'diameter': diameter,
                        'short_type': short_type,
                        'long_type': long_type,
                        'redshift': redshift,
                        'comoving_distance': comoving_distance,
                        'source': "Simbad (Legacy)"
                    })

                # Pass fallback results to graphics and updates
                self.main_preview.set_query_results(query_results)
                self.query_results = query_results  # Keep a reference to results in MainWindow
                self.update_object_count()

            except Exception as fallback_error:
                QMessageBox.critical(self, "Query Failed", f"Both TAP and fallback queries failed: {str(fallback_error)}")

    def perform_deep_vizier_search(self):
        """Perform a Vizier catalog search and parse results based on catalog-specific fields, with duplicate handling."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area", "Please define a search circle by Shift-clicking and dragging.")
            return

        # Convert the center coordinates to RA/Dec
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates", "Could not determine the RA/Dec of the circle center.")
            return

        # Convert radius from arcseconds to arcminutes
        radius_arcmin = float((self.circle_radius * self.pixscale) / 60.0)

        # List of Vizier catalogs
        catalog_ids = ["II/246", "I/350/gaiaedr3", "V/147/sdss12", "I/322A", "V/154"]

        coord = SkyCoord(ra_center, dec_center, unit="deg")
        all_results = []  # Collect all results for display in the main preview
        unique_entries = {}  # Dictionary to track unique entries by (RA, Dec) tuple

        try:
            for catalog_id in catalog_ids:
                # Query each catalog
                result = Vizier.query_region(coord, radius=radius_arcmin * u.arcmin, catalog=catalog_id)
                if result:
                    catalog_results = result[0]
                    for row in catalog_results:
                        # Map data to the columns in your tree view structure

                        # RA and Dec
                        ra = str(row.get("RAJ2000", row.get("RA_ICRS", "")))
                        dec = str(row.get("DEJ2000", row.get("DE_ICRS", "")))
                        if not ra or not dec:
                            
                            continue  # Skip this entry if RA or Dec is empty

                        # Create a unique key based on RA and Dec to track duplicates
                        unique_key = (ra, dec)

                        # Name (different columns based on catalog)
                        name = str(
                            row.get("_2MASS", "")
                            or row.get("Source", "")
                            or row.get("SDSS12", "")
                            or row.get("UCAC4", "")
                            or row.get("SDSS16", "")
                        )

                        # Diameter - store catalog ID as the diameter field to help with tracking
                        diameter = catalog_id

                        # Type (e.g., otype)
                        type_short = str(row.get("otype", "N/A"))

                        # Long Type (e.g., SpType)
                        long_type = str(row.get("SpType", "N/A"))

                        # Redshift or Parallax (zph for redshift or Plx for parallax)
                        redshift = row.get("zph", row.get("Plx", ""))
                        if redshift:
                            if "Plx" in row.colnames:
                                redshift = f"{redshift} (Parallax in mas)"
                                # Calculate the distance in light-years from parallax
                                try:
                                    parallax_value = float(row["Plx"])
                                    comoving_distance = f"{1000 / parallax_value * 3.2615637769:.2f} Ly"
                                except (ValueError, ZeroDivisionError):
                                    comoving_distance = "N/A"  # Handle invalid parallax values
                            else:
                                redshift = str(redshift)
                                # Calculate comoving distance for redshift if it's from zph
                                if "zph" in row.colnames and isinstance(row["zph"], (float, int)):
                                    comoving_distance = str(calculate_comoving_distance(float(row["zph"])))
                        else:
                            redshift = "N/A"
                            comoving_distance = "N/A"

                        # Handle duplicates: prioritize V/147/sdss12 over V/154 and only add unique entries
                        if unique_key not in unique_entries:
                            unique_entries[unique_key] = {
                                'ra': ra,
                                'dec': dec,
                                'name': name,
                                'diameter': diameter,
                                'short_type': type_short,
                                'long_type': long_type,
                                'redshift': redshift,
                                'comoving_distance': comoving_distance,
                                'source' : "Vizier"
                            }
                        else:
                            # Check if we should replace the existing entry
                            existing_entry = unique_entries[unique_key]
                            if (existing_entry['diameter'] == "V/154" and diameter == "V/147/sdss12"):
                                unique_entries[unique_key] = {
                                    'ra': ra,
                                    'dec': dec,
                                    'name': name,
                                    'diameter': diameter,
                                    'short_type': type_short,
                                    'long_type': long_type,
                                    'redshift': redshift,
                                    'comoving_distance': comoving_distance,
                                    'source' : "Vizier"
                                }

            # Convert unique entries to the main preview display
            for entry in unique_entries.values():
                item = QTreeWidgetItem([
                    entry['ra'], entry['dec'], entry['name'], entry['diameter'], entry['short_type'], entry['long_type'],
                    entry['redshift'], entry['comoving_distance']
                ])
                self.results_tree.addTopLevelItem(item)
                all_results.append(entry)

            # Update the main preview with the query results
            self.main_preview.set_query_results(all_results)
            self.query_results = all_results  # Keep a reference to results in MainWindow
            self.update_object_count()
            
        except Exception as e:
            QMessageBox.critical(self, "Vizier Search Failed", f"Failed to query Vizier: {str(e)}")

    def perform_mast_search(self):
        """Perform a MAST cone search in the user-defined region using astroquery."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area", "Please define a search circle by Shift-clicking and dragging.")
            return

        # Calculate RA and Dec for the center point
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates", "Could not determine the RA/Dec of the circle center.")
            return

        # Convert radius from arcseconds to degrees (MAST uses degrees)
        search_radius_deg = float((self.circle_radius * self.pixscale) / 3600.0)  # Convert to degrees
        ra_center = float(ra_center)  # Ensure it's a regular float
        dec_center = float(dec_center)  # Ensure it's a regular float

        try:
            # Perform the MAST cone search using Mast.mast_query for the 'Mast.Caom.Cone' service
            observations = Mast.mast_query(
                'Mast.Caom.Cone',
                ra=ra_center,
                dec=dec_center,
                radius=search_radius_deg
            )

            # Limit the results to the first 100 rows
            limited_observations = observations[:100]

            if len(observations) == 0:
                QMessageBox.information(self, "No Results", "No objects found in the specified area on MAST.")
                return

            # Clear previous results
            self.results_tree.clear()
            query_results = []

            # Process each observation in the results
            for obj in limited_observations:

                def safe_get(value):
                    return "N/A" if np.ma.is_masked(value) else str(value)


                ra = safe_get(obj.get("s_ra", "N/A"))
                dec = safe_get(obj.get("s_dec", "N/A"))
                target_name = safe_get(obj.get("target_name", "N/A"))
                instrument = safe_get(obj.get("instrument_name", "N/A"))
                jpeg_url = safe_get(obj.get("dataURL", "N/A"))  # Adjust URL field as needed

                # Add to TreeWidget
                item = QTreeWidgetItem([
                    ra,
                    dec,
                    target_name,
                    instrument,
                    "N/A",  # Placeholder for observation date if needed
                    "N/A",  # Other placeholder
                    jpeg_url,  # URL in place of long type
                    "MAST"  # Source
                ])
                self.results_tree.addTopLevelItem(item)

                # Append full details as a dictionary to query_results
                query_results.append({
                    'ra': ra,
                    'dec': dec,
                    'name': target_name,
                    'diameter': instrument,
                    'short_type': "N/A",
                    'long_type': jpeg_url,
                    'redshift': "N/A",
                    'comoving_distance': "N/A",
                    'source': "Mast"
                })

            # Set query results in the CustomGraphicsView for display
            self.main_preview.set_query_results(query_results)
            self.query_results = query_results  # Keep a reference to results in MainWindow
            self.update_object_count()

        except Exception as e:
            QMessageBox.critical(self, "MAST Query Failed", f"Failed to query MAST: {str(e)}")

    def toggle_show_names(self, state):
        """Toggle showing/hiding names on the main image."""
        self.show_names = state == Qt.CheckState.Checked
        self.main_preview.draw_query_results()  # Redraw with or without names

    def clear_results(self):
        """Clear the search results and remove markers from the main image."""
        self.results_tree.clear()
        self.main_preview.clear_query_results()
        self.status_label.setText("Results cleared.")

    def open_settings_dialog(self):
        """Open settings dialog to adjust max results and marker type."""
        dialog = QDialog(self)
        dialog.setWindowTitle("Settings")
        
        layout = QFormLayout(dialog)
        

        # Max Results setting using CustomSpinBox
        max_results_spinbox = CustomSpinBox(minimum=1, maximum=100000, initial=self.max_results, step=1)
        layout.addRow("Max Results:", max_results_spinbox)

        
        # Marker Style selection
        marker_style_combo = QComboBox()
        marker_style_combo.addItems(["Circle", "Crosshair"])
        marker_style_combo.setCurrentText(self.marker_style)
        layout.addRow("Marker Style:", marker_style_combo)

        # Force Blind Solve button
        force_blind_solve_button = QPushButton("Force Blind Solve")
        force_blind_solve_button.clicked.connect(lambda: self.force_blind_solve(dialog))
        layout.addWidget(force_blind_solve_button)
        
        # OK and Cancel buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(lambda: self.update_settings(max_results_spinbox.value(), marker_style_combo.currentText(), dialog))
        buttons.rejected.connect(dialog.reject)
        layout.addWidget(buttons)
        
        dialog.setLayout(layout)
        dialog.exec()

    def update_settings(self, max_results, marker_style, dialog):
        """Update settings based on dialog input."""
        self.max_results = max_results
        self.marker_style = marker_style  # Store the selected marker style
        self.main_preview.draw_query_results()
        dialog.accept()

    def force_blind_solve(self, dialog):
        """Force a blind solve on the currently loaded image."""
        dialog.accept()  # Close the settings dialog
        self.prompt_blind_solve()  # Call the blind solve function


def extract_wcs_data(file_path):
    try:
        # Open the FITS file with minimal validation to ignore potential errors in non-essential parts
        with fits.open(file_path, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
            header = hdul[0].header

            # Extract essential WCS parameters
            wcs_params = {}
            keys_to_extract = [
                'WCSAXES', 'CTYPE1', 'CTYPE2', 'EQUINOX', 'LONPOLE', 'LATPOLE',
                'CRVAL1', 'CRVAL2', 'CRPIX1', 'CRPIX2', 'CUNIT1', 'CUNIT2',
                'CD1_1', 'CD1_2', 'CD2_1', 'CD2_2', 'A_ORDER', 'A_0_0', 'A_0_1', 
                'A_0_2', 'A_1_0', 'A_1_1', 'A_2_0', 'B_ORDER', 'B_0_0', 'B_0_1', 
                'B_0_2', 'B_1_0', 'B_1_1', 'B_2_0', 'AP_ORDER', 'AP_0_0', 'AP_0_1', 
                'AP_0_2', 'AP_1_0', 'AP_1_1', 'AP_2_0', 'BP_ORDER', 'BP_0_0', 
                'BP_0_1', 'BP_0_2', 'BP_1_0', 'BP_1_1', 'BP_2_0'
            ]
            for key in keys_to_extract:
                if key in header:
                    wcs_params[key] = header[key]

            # Manually create a minimal header with WCS information
            wcs_header = fits.Header()
            for key, value in wcs_params.items():
                wcs_header[key] = value

            # Initialize WCS with this custom header
            wcs = WCS(wcs_header)
            print("WCS successfully initialized with minimal header.")
            return wcs

    except Exception as e:
        print(f"Error processing WCS file: {e}")
        return None

# Function to calculate comoving radial distance (in Gly)
def calculate_comoving_distance(z):
    z = abs(z)
    # Initialize variables
    WR = 4.165E-5 / ((H0 / 100) ** 2)  # Omega radiation
    WK = 1 - WM - WV - WR  # Omega curvature
    az = 1.0 / (1 + z)
    n = 1000  # number of points in integration

    # Comoving radial distance
    DCMR = 0.0
    for i in range(n):
        a = az + (1 - az) * (i + 0.5) / n
        adot = sqrt(WK + (WM / a) + (WR / (a ** 2)) + (WV * a ** 2))
        DCMR += 1 / (a * adot)
    
    DCMR = (1 - az) * DCMR / n
    DCMR_Gly = (c / H0) * DCMR * Mpc_to_Gly

    return round(DCMR_Gly, 3)  # Round to three decimal places for display

def calculate_orientation(header):
    """Calculate the orientation angle from the CD matrix if available."""
    # Extract CD matrix elements
    cd1_1 = header.get('CD1_1')
    cd1_2 = header.get('CD1_2')
    cd2_1 = header.get('CD2_1')
    cd2_2 = header.get('CD2_2')

    if cd1_1 is not None and cd1_2 is not None and cd2_1 is not None and cd2_2 is not None:
        # Calculate the orientation angle in degrees and adjust by adding 180 degrees
        orientation = (np.degrees(np.arctan2(cd1_2, cd1_1)) + 180) % 360
        return orientation
    else:
        print("CD matrix elements not found in the header.")
        return None



# Set the directory for the images in the /imgs folder
if getattr(sys, 'frozen', False):  # Check if running as a PyInstaller bundle
    phase_folder = os.path.join(sys._MEIPASS, "imgs")  # Use PyInstaller's temporary directory with /imgs
else:
    phase_folder = os.path.join(os.path.dirname(__file__), "imgs")  # Use the directory of the script file with /imgs


# Set precision for Decimal operations
getcontext().prec = 24

# Suppress warnings
warnings.filterwarnings("ignore")


class CalculationThread(QThread):
    calculation_complete = pyqtSignal(pd.DataFrame, str)
    lunar_phase_calculated = pyqtSignal(int, str)  # phase_percentage, phase_image_name
    lst_calculated = pyqtSignal(str)
    status_update = pyqtSignal(str)

    def __init__(self, latitude, longitude, date, time, timezone, min_altitude, catalog_filters, object_limit):
        super().__init__()
        self.latitude = latitude
        self.longitude = longitude
        self.date = date
        self.time = time
        self.timezone = timezone
        self.min_altitude = min_altitude
        self.catalog_filters = catalog_filters
        self.object_limit = object_limit

    def get_catalog_file_path(self):
        # Define a user-writable location for the catalog (e.g., in the user's home directory)
        user_catalog_path = os.path.join(os.path.expanduser("~"), "celestial_catalog.csv")

        # Check if we are running in a PyInstaller bundle
        if not os.path.exists(user_catalog_path):
            bundled_catalog = os.path.join(getattr(sys, '_MEIPASS', os.path.dirname(__file__)), "celestial_catalog.csv")
            if os.path.exists(bundled_catalog):
                # Copy the bundled catalog to a writable location
                shutil.copyfile(bundled_catalog, user_catalog_path)

        return user_catalog_path  # Return the path to the user-writable catalog

    def run(self):
        try:
            # Convert date and time to astropy Time
            datetime_str = f"{self.date} {self.time}"
            local = pytz.timezone(self.timezone)
            naive_datetime = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M")
            local_datetime = local.localize(naive_datetime)
            astropy_time = Time(local_datetime)

            # Define observer's location
            location = EarthLocation(lat=self.latitude * u.deg, lon=self.longitude * u.deg, height=0 * u.m)

            # Calculate Local Sidereal Time (LST)
            lst = astropy_time.sidereal_time('apparent', self.longitude * u.deg)
            self.lst_calculated.emit(f"Local Sidereal Time: {lst.to_string(unit=u.hour, precision=3)}")

            # Calculate lunar phase
            phase_percentage, phase_image_name = self.calculate_lunar_phase(astropy_time, location)
            self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)

            # Load celestial catalog
            catalog_file = self.get_catalog_file_path()
            if not os.path.exists(catalog_file):
                self.calculation_complete.emit(pd.DataFrame(), "Catalog file not found.")
                return

            df = pd.read_csv(catalog_file, encoding='ISO-8859-1')

            # Apply catalog filters **AFTER reading to avoid index mismatch**
            df = df[df['Catalog'].isin(self.catalog_filters)]
            df.dropna(subset=['RA', 'Dec'], inplace=True)

            # Ensure DataFrame is contiguous
            df.reset_index(drop=True, inplace=True)

            # Convert RA/Dec into SkyCoord objects **vectorized**
            sky_coords = SkyCoord(ra=df['RA'].values * u.deg, dec=df['Dec'].values * u.deg, frame='icrs')

            # Create an AltAz frame for observer location
            altaz_frame = AltAz(obstime=astropy_time, location=location)

            # **Vectorized altitude and azimuth calculation**
            altaz = sky_coords.transform_to(altaz_frame)
            df['Altitude'] = np.round(altaz.alt.deg, 1)
            df['Azimuth'] = np.round(altaz.az.deg, 1)

            # **Vectorized Moon Separation Calculation**
            moon = get_body("moon", astropy_time, location).transform_to(altaz_frame)
            df['Degrees from Moon'] = np.round(sky_coords.separation(moon).deg, 2)

            # **Apply altitude filter after calculations**
            df = df[df['Altitude'] >= self.min_altitude]

            # **Vectorized calculation of "Minutes to Transit"**
            ra_hours = df['RA'].values * (24 / 360.0)  # Convert degrees to hours
            time_diff = ((ra_hours - lst.hour) * u.hour) % (24 * u.hour)  # Hour difference
            df['Minutes to Transit'] = np.round(time_diff.value * 60, 1)

            # Correct Before/After Transit flags efficiently
            df['Before/After Transit'] = np.where(df['Minutes to Transit'] > 720, "After", "Before")
            df['Minutes to Transit'] = np.where(df['Minutes to Transit'] > 720, 1440 - df['Minutes to Transit'], df['Minutes to Transit'])

            # **Optimized Sorting & Selection**
            df = df.nsmallest(self.object_limit, 'Minutes to Transit')  # Faster than full sort

            self.calculation_complete.emit(df, "Calculation complete.")
        except Exception as e:
            self.calculation_complete.emit(pd.DataFrame(), f"Error: {str(e)}")




    def calculate_lunar_phase(self, astropy_time, location):
        moon = get_body("moon", astropy_time, location)
        sun = get_sun(astropy_time)
        elongation = moon.separation(sun).deg

        # Determine lunar phase percentage
        phase_percentage = (1 - np.cos(np.radians(elongation))) / 2 * 100
        phase_percentage = round(phase_percentage)

        # Determine if it is waxing or waning
        future_time = astropy_time + (6 * u.hour)
        future_moon = get_body("moon", future_time, location)
        future_sun = get_sun(future_time)
        future_elongation = future_moon.separation(future_sun).deg
        is_waxing = future_elongation > elongation

        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")


        # Select appropriate lunar phase image based on phase angle
        phase_image_name = "new_moon.png"  # Default

        if 0 <= elongation < 9:
            phase_image_name = "new_moon.png"
        elif 9 <= elongation < 18:
            phase_image_name = "waxing_crescent_1.png" if is_waxing else "waning_crescent_5.png"
        elif 18 <= elongation < 27:
            phase_image_name = "waxing_crescent_2.png" if is_waxing else "waning_crescent_4.png"
        elif 27 <= elongation < 36:
            phase_image_name = "waxing_crescent_3.png" if is_waxing else "waning_crescent_3.png"
        elif 36 <= elongation < 45:
            phase_image_name = "waxing_crescent_4.png" if is_waxing else "waning_crescent_2.png"
        elif 45 <= elongation < 54:
            phase_image_name = "waxing_crescent_5.png" if is_waxing else "waning_crescent_1.png"
        elif 54 <= elongation < 90:
            phase_image_name = "first_quarter.png"
        elif 90 <= elongation < 108:
            phase_image_name = "waxing_gibbous_1.png" if is_waxing else "waning_gibbous_4.png"
        elif 108 <= elongation < 126:
            phase_image_name = "waxing_gibbous_2.png" if is_waxing else "waning_gibbous_3.png"
        elif 126 <= elongation < 144:
            phase_image_name = "waxing_gibbous_3.png" if is_waxing else "waning_gibbous_2.png"
        elif 144 <= elongation < 162:
            phase_image_name = "waxing_gibbous_4.png" if is_waxing else "waning_gibbous_1.png"
        elif 162 <= elongation <= 180:
            phase_image_name = "full_moon.png"


        self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)
        return phase_percentage, phase_image_name



class WhatsInMySky(QWidget):
    def __init__(self):
        super().__init__()
        self.settings_file = os.path.join(os.path.expanduser("~"), "sky_settings.json")
        self.settings = QSettings("Seti Astro", "Seti Astro Suite")
        self.initUI()  # Build the UI
        self.load_settings()  # Load settings after UI is built
        self.object_limit = self.settings.value("object_limit", 100, type=int)

    def initUI(self):
        layout = QGridLayout()
        fixed_width = 150

        # Latitude, Longitude, Date, Time, Time Zone
        self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo = self.setup_basic_info_fields(layout, fixed_width)

        # Minimum Altitude, Catalog Filters, RA/Dec format
        self.min_altitude_entry, self.catalog_vars, self.ra_dec_format = self.setup_filters(layout, fixed_width)

        # Calculate Button, Status Label, Sidereal Time, Treeview for Results, Custom Object and Save Buttons
        self.setup_controls(layout, fixed_width)

        self.setLayout(layout)
        self.setMinimumWidth(1000)  # Ensures a wide enough starting window

    def setup_basic_info_fields(self, layout, fixed_width):
        self.latitude_entry = QLineEdit()
        self.latitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Latitude:"), 0, 0)
        layout.addWidget(self.latitude_entry, 0, 1)

        self.longitude_entry = QLineEdit()
        self.longitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Longitude:"), 1, 0)
        layout.addWidget(self.longitude_entry, 1, 1)

        self.date_entry = QLineEdit()
        self.date_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Date (YYYY-MM-DD):"), 2, 0)
        layout.addWidget(self.date_entry, 2, 1)

        self.time_entry = QLineEdit()
        self.time_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time (HH:MM):"), 3, 0)
        layout.addWidget(self.time_entry, 3, 1)

        self.timezone_combo = QComboBox()
        self.timezone_combo.addItems(pytz.all_timezones)
        self.timezone_combo.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time Zone:"), 4, 0)
        layout.addWidget(self.timezone_combo, 4, 1)

        return self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo

    def setup_filters(self, layout, fixed_width):
        self.min_altitude_entry = QLineEdit()
        self.min_altitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Min Altitude (0-90 degrees):"), 5, 0)
        layout.addWidget(self.min_altitude_entry, 5, 1)

        catalog_frame = QScrollArea()
        catalog_widget = QWidget()
        catalog_layout = QGridLayout()
        self.catalog_vars = {}
        for i, catalog in enumerate(["Messier", "NGC", "IC", "Caldwell", "Abell", "Sharpless", "LBN", "LDN", "PNG", "User"]):
            chk = QCheckBox(catalog)
            chk.setChecked(False)
            catalog_layout.addWidget(chk, i // 5, i % 5)
            self.catalog_vars[catalog] = chk
        catalog_widget.setLayout(catalog_layout)
        catalog_frame.setWidget(catalog_widget)
        catalog_frame.setFixedWidth(fixed_width + 250)
        layout.addWidget(QLabel("Catalog Filters:"), 6, 0)
        layout.addWidget(catalog_frame, 6, 1)

        # RA/Dec format setup
        self.ra_dec_degrees = QRadioButton("Degrees")
        self.ra_dec_hms = QRadioButton("H:M:S / D:M:S")
        ra_dec_group = QButtonGroup()
        ra_dec_group.addButton(self.ra_dec_degrees)
        ra_dec_group.addButton(self.ra_dec_hms)
        self.ra_dec_degrees.setChecked(True)  # Default to Degrees format
        ra_dec_layout = QHBoxLayout()
        ra_dec_layout.addWidget(self.ra_dec_degrees)
        ra_dec_layout.addWidget(self.ra_dec_hms)
        layout.addWidget(QLabel("RA/Dec Format:"), 7, 0)
        layout.addLayout(ra_dec_layout, 7, 1)

        # Connect the radio buttons to the update function
        self.ra_dec_degrees.toggled.connect(self.update_ra_dec_format)
        self.ra_dec_hms.toggled.connect(self.update_ra_dec_format)

        return self.min_altitude_entry, self.catalog_vars, self.ra_dec_degrees

    def setup_controls(self, layout, fixed_width):
        # Calculate button
        calculate_button = QPushButton("Calculate")
        calculate_button.setFixedWidth(fixed_width)
        layout.addWidget(calculate_button, 8, 0)
        calculate_button.clicked.connect(self.start_calculation)

        # Status label
        self.status_label = QLabel("Status: Idle")
        layout.addWidget(self.status_label, 9, 0, 1, 2)

        # Sidereal time label
        self.lst_label = QLabel("Local Sidereal Time: {:.3f}".format(0.0))
        layout.addWidget(self.lst_label, 10, 0, 1, 2)

        # Lunar phase image and label
        self.lunar_phase_image_label = QLabel()
        layout.addWidget(self.lunar_phase_image_label, 0, 2, 4, 1)  # Position it appropriately

        self.lunar_phase_label = QLabel("Lunar Phase: N/A")
        layout.addWidget(self.lunar_phase_label, 4, 2)

        # Treeview for results (expand dynamically)
        self.tree = QTreeWidget()
        self.tree.setHeaderLabels([
            "Name", "RA", "Dec", "Altitude", "Azimuth", "Minutes to Transit", "Before/After Transit",
            "Degrees from Moon", "Alt Name", "Type", "Magnitude", "Size (arcmin)"
        ])
        self.tree.setSortingEnabled(True)
        header = self.tree.header()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # Allow users to resize columns
        header.setStretchLastSection(False)  # Ensure last column is not stretched automatically

        self.tree.sortByColumn(5, Qt.SortOrder.AscendingOrder)
        layout.addWidget(self.tree, 11, 0, 1, 3)
        self.tree.itemDoubleClicked.connect(self.on_row_double_click)

        # Buttons at the bottom
        add_object_button = QPushButton("Add Custom Object")
        add_object_button.setFixedWidth(fixed_width)
        layout.addWidget(add_object_button, 12, 0)
        add_object_button.clicked.connect(self.add_custom_object)

        save_button = QPushButton("Save to CSV")
        save_button.setFixedWidth(fixed_width)
        layout.addWidget(save_button, 12, 1)
        save_button.clicked.connect(self.save_to_csv)

        # Settings button to change the number of objects displayed
        settings_button = QPushButton()
        settings_button.setIcon(QIcon(wrench_path))  # Use icon_path for the button's icon
        settings_button.setFixedWidth(fixed_width)
        layout.addWidget(settings_button, 12, 2)
        settings_button.clicked.connect(self.open_settings)        

        # Allow the main window to expand
        layout.setColumnStretch(2, 1)  # Makes the right column (with tree widget) expand as the window grows


    def start_calculation(self):
        # Gather the inputs
        latitude = float(self.latitude_entry.text())
        longitude = float(self.longitude_entry.text())
        date_str = self.date_entry.text()
        time_str = self.time_entry.text()
        timezone_str = self.timezone_combo.currentText()
        min_altitude = float(self.min_altitude_entry.text())

        # Validate inputs
        try:
            latitude = float(latitude)
            longitude = float(longitude)
            min_altitude = float(min_altitude)
        except ValueError:
            self.update_status("Invalid input: Latitude, Longitude, and Min Altitude must be numeric.")
            return

        # Save the settings
        self.save_settings(latitude, longitude, date_str, time_str, timezone_str, min_altitude)


        catalog_filters = [catalog for catalog, var in self.catalog_vars.items() if var.isChecked()]
        object_limit = self.object_limit

        # Set up and start the calculation thread
        self.calc_thread = CalculationThread(
            latitude, longitude, date_str, time_str, timezone_str,
            min_altitude, catalog_filters, object_limit
        )
        self.calc_thread.calculation_complete.connect(self.on_calculation_complete)
        self.calc_thread.lunar_phase_calculated.connect(self.update_lunar_phase)
        self.calc_thread.lst_calculated.connect(self.update_lst) 
        self.calc_thread.status_update.connect(self.update_status)
        self.update_status("Calculating...")
        self.calc_thread.start()


    def update_lunar_phase(self, phase_percentage, phase_image_name):
        # Update the lunar phase label
        self.lunar_phase_label.setText(f"Lunar Phase: {phase_percentage}% illuminated")

        # Define the path to the image
        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")
        phase_image_path = os.path.join(phase_folder, phase_image_name)

        # Load and display the lunar phase image if it exists
        if os.path.exists(phase_image_path):
            pixmap = QPixmap(phase_image_path).scaled(100, 100, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            self.lunar_phase_image_label.setPixmap(pixmap)
        else:
            print(f"Image not found: {phase_image_path}")     

    def on_calculation_complete(self, df, message):
        # Handle the data received from the calculation thread
        self.update_status(message)
        if not df.empty:
            self.tree.clear()
            for _, row in df.iterrows():
                # Prepare RA and Dec display based on selected format
                ra_display = row['RA']
                dec_display = row['Dec']

                if self.ra_dec_hms.isChecked():
                    # Convert degrees to H:M:S format
                    sky_coord = SkyCoord(ra=row['RA'] * u.deg, dec=row['Dec'] * u.deg)
                    ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                    dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')

                # Calculate Before/After Transit string
                before_after = row['Before/After Transit']

                # Ensure Size (arcmin) displays correctly as a string
                size_arcmin = row.get('Info', '')
                if pd.notna(size_arcmin):
                    size_arcmin = str(size_arcmin)  # Ensure it's treated as a string

                # Populate each row with the calculated data
                values = [
                    str(row['Name']) if pd.notna(row['Name']) else '',  # Ensure Name is a string or empty
                    str(ra_display),  # RA in either H:M:S or degrees format
                    str(dec_display),  # Dec in either H:M:S or degrees format
                    str(row['Altitude']) if pd.notna(row['Altitude']) else '',  # Altitude as string or empty
                    str(row['Azimuth']) if pd.notna(row['Azimuth']) else '',  # Azimuth as string or empty
                    str(int(row['Minutes to Transit'])) if pd.notna(row['Minutes to Transit']) else '',  # Minutes to Transit as integer string
                    before_after,  # Before/After Transit (already a string)
                    str(round(row['Degrees from Moon'], 2)) if pd.notna(row['Degrees from Moon']) else '',  # Degrees from Moon as rounded string or empty
                    row.get('Alt Name', '') if pd.notna(row.get('Alt Name', '')) else '',  # Alt Name as string or empty
                    row.get('Type', '') if pd.notna(row.get('Type', '')) else '',  # Type as string or empty
                    str(row.get('Magnitude', '')) if pd.notna(row.get('Magnitude', '')) else '',  # Magnitude as string or empty
                    str(size_arcmin) if pd.notna(size_arcmin) else ''  # Size in arcmin as string or empty
                ]

                # Use SortableTreeWidgetItem instead of QTreeWidgetItem
                item = SortableTreeWidgetItem(values)
                self.tree.addTopLevelItem(item)


    def update_status(self, message):
        self.status_label.setText(f"Status: {message}")

    def update_lst(self, message):
        self.lst_label.setText(message)


    def save_settings(self, latitude, longitude, date, time, timezone, min_altitude):
        self.settings.setValue("latitude", latitude)
        self.settings.setValue("longitude", longitude)
        self.settings.setValue("date", date)
        self.settings.setValue("time", time)
        self.settings.setValue("timezone", timezone)
        self.settings.setValue("min_altitude", min_altitude)
        print("Settings saved.")

    def load_settings(self):
        """Load settings from QSettings and populate UI fields."""
        def safe_cast(value, default, cast_type):
            """Safely cast a value to a specific type."""
            try:
                return cast_type(value)
            except (ValueError, TypeError):
                return default

        # Load and cast settings with fallbacks
        self.latitude = safe_cast(self.settings.value("latitude", 0.0), 0.0, float)
        self.longitude = safe_cast(self.settings.value("longitude", 0.0), 0.0, float)
        self.date = self.settings.value("date", datetime.now().strftime("%Y-%m-%d"))
        self.time = self.settings.value("time", "00:00:00")
        self.timezone = self.settings.value("timezone", "UTC")
        self.min_altitude = safe_cast(self.settings.value("min_altitude", 0.0), 0.0, float)
        self.object_limit = safe_cast(self.settings.value("object_limit", 100), 100, int)

        # Populate fields in the UI
        self.latitude_entry.setText(str(self.latitude))
        self.longitude_entry.setText(str(self.longitude))
        self.date_entry.setText(self.date)
        self.time_entry.setText(self.time)
        self.timezone_combo.setCurrentText(self.timezone)
        self.min_altitude_entry.setText(str(self.min_altitude))

        print("Settings loaded:", {
            "latitude": self.latitude,
            "longitude": self.longitude,
            "date": self.date,
            "time": self.time,
            "timezone": self.timezone,
            "min_altitude": self.min_altitude,
            "object_limit": self.object_limit,
        })




    def open_settings(self):
        object_limit, ok = QInputDialog.getInt(self, "Settings", "Enter number of objects to display:", value=self.object_limit, min=1, max=1000)
        if ok:
            self.object_limit = object_limit

    def treeview_sort_column(self, tv, col, reverse):
        l = [(tv.set(k, col), k) for k in tv.get_children('')]
        try:
            l.sort(key=lambda t: float(t[0]) if t[0] else float('inf'), reverse=reverse)
        except ValueError:
            l.sort(reverse=reverse)

        for index, (val, k) in enumerate(l):
            tv.move(k, '', index)

        tv.heading(col, command=lambda: self.treeview_sort_column(tv, col, not reverse))

    def on_row_double_click(self, item: QTreeWidgetItem, column: int):
        """Handle double-clicking an item in the tree view."""
        object_name = item.text(0).replace(" ", "")  # Assuming the name is in the first column
        search_url = f"https://www.astrobin.com/search/?q={object_name}"
        print(f"Opening URL: {search_url}")  # Debugging output
        webbrowser.open(search_url)

    def add_custom_object(self):
        # Gather information for the custom object
        name, ok_name = QInputDialog.getText(self, "Add Custom Object", "Enter object name:")
        if not ok_name or not name:
            return

        ra, ok_ra = QInputDialog.getDouble(self, "Add Custom Object", "Enter RA (in degrees):", decimals=3)
        if not ok_ra:
            return

        dec, ok_dec = QInputDialog.getDouble(self, "Add Custom Object", "Enter Dec (in degrees):", decimals=3)
        if not ok_dec:
            return

        # Create the custom object entry
        new_object = {
            "Name": name,
            "RA": ra,
            "Dec": dec,
            "Catalog": "User Defined",
            "Alt Name": "User Defined",
            "Type": "Custom",
            "Magnitude": "",
            "Info": ""
        }

        # Load the catalog, add the custom object, and save it back
        df = pd.read_csv(self.calc_thread.catalog_file, encoding='ISO-8859-1')
        df = pd.concat([df, pd.DataFrame([new_object])], ignore_index=True)
        df.to_csv(self.calc_thread.catalog_file, index=False, encoding='ISO-8859-1')
        self.update_status(f"Added custom object: {name}")

    def update_ra_dec_format(self):
        """Update the RA/Dec format in the tree based on the selected radio button."""
        is_degrees_format = self.ra_dec_degrees.isChecked()  # Check if degrees format is selected

        for i in range(self.tree.topLevelItemCount()):
            item = self.tree.topLevelItem(i)
            ra_value = item.text(1)  # RA is in the second column
            dec_value = item.text(2)  # Dec is in the third column

            try:
                if is_degrees_format:
                    # Convert H:M:S to degrees only if in H:M:S format
                    if ":" in ra_value:
                        # Conversion from H:M:S format to degrees
                        sky_coord = SkyCoord(ra=ra_value, dec=dec_value, unit=(u.hourangle, u.deg))
                        ra_display = str(round(sky_coord.ra.deg, 3))
                        dec_display = str(round(sky_coord.dec.deg, 3))
                    else:
                        # Already in degrees format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value
                else:
                    # Convert degrees to H:M:S only if in degrees format
                    if ":" not in ra_value:
                        # Conversion from degrees to H:M:S format
                        ra_deg = float(ra_value)
                        dec_deg = float(dec_value)
                        sky_coord = SkyCoord(ra=ra_deg * u.deg, dec=dec_deg * u.deg)
                        ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                        dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')
                    else:
                        # Already in H:M:S format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value

            except ValueError as e:
                print(f"Conversion error: {e}")
                ra_display = ra_value
                dec_display = dec_value
            except Exception as e:
                print(f"Unexpected error: {e}")
                ra_display = ra_value
                dec_display = dec_value

            # Update item with the new RA/Dec display format
            item.setText(1, ra_display)
            item.setText(2, dec_display)



    def save_to_csv(self):
        # Ask user where to save the CSV file
        file_path, _ = QFileDialog.getSaveFileName(self, "Save CSV File", "", "CSV files (*.csv);;All Files (*)")
        if file_path:
            # Extract data from QTreeWidget
            columns = [self.tree.headerItem().text(i) for i in range(self.tree.columnCount())]
            data = [columns]
            for i in range(self.tree.topLevelItemCount()):
                item = self.tree.topLevelItem(i)
                row = [item.text(j) for j in range(self.tree.columnCount())]
                data.append(row)

            # Convert data to DataFrame and save as CSV
            df = pd.DataFrame(data[1:], columns=data[0])
            df.to_csv(file_path, index=False)
            self.update_status(f"Data saved to {file_path}")

class SortableTreeWidgetItem(QTreeWidgetItem):
    def __lt__(self, other):
        # Get the column index being sorted
        column = self.treeWidget().sortColumn()

        # Columns with numeric data for custom sorting (adjust column indices as needed)
        numeric_columns = [3, 4, 5, 7, 10]  # Altitude, Azimuth, Minutes to Transit, Degrees from Moon, Magnitude

        # Check if the column is in numeric_columns for numeric sorting
        if column in numeric_columns:
            try:
                # Attempt to compare as floats
                return float(self.text(column)) < float(other.text(column))
            except ValueError:
                # If conversion fails, fall back to string comparison
                return self.text(column) < other.text(column)
        else:
            # Default string comparison for other columns
            return self.text(column) < other.text(column)


if __name__ == '__main__':
    # Configure logging to capture errors for debugging
    logging.basicConfig(
        filename="astro_editing_suite.log",
        level=logging.ERROR,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    app = QApplication(sys.argv)
    app.setWindowIcon(QIcon(icon_path))
    
    try:
        # Create and show the main window
        window = AstroEditingSuite()
        window.show()
        sys.exit(app.exec())
    except Exception as e:
        # Log the error
        logging.error("Unhandled exception occurred", exc_info=True)
        
        # Display a critical error message to the user
        QMessageBox.critical(
            None,
            "Application Error",
            f"An unexpected error occurred:\n{str(e)}\n\n"
            "Please check the log file for more details."
        )
        sys.exit(1)
