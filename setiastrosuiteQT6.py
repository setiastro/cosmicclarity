import sys
import urllib

# Standard library imports
import pickle
import os
import tempfile
import time
import json
import logging
import math
from datetime import datetime
from decimal import getcontext
from urllib.parse import quote
from urllib.parse import quote_plus
import webbrowser
import warnings
import shutil
import subprocess
from xisf import XISF
import requests
import csv
import lz4.block
import zstandard
import base64
import ast
import platform
import glob
import time
from datetime import datetime
import pywt
from io import BytesIO
import re
from collections import defaultdict
from scipy.spatial import Delaunay, KDTree
from scipy.ndimage import gaussian_filter
import scipy.ndimage as ndi
import plotly.graph_objects as go
from scipy.ndimage import zoom
import multiprocessing
import matplotlib
matplotlib.use("QtAgg") 
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Circle
from matplotlib.ticker import MaxNLocator

import random
if sys.stdout is not None:
    sys.stdout.reconfigure(encoding='utf-8')

from astropy.stats import sigma_clipped_stats
from astropy.io.votable import parse_single_table
from photutils.detection import DAOStarFinder
from scipy.spatial import ConvexHull
from astropy.table import Table, vstack
from numba import njit, prange
from scipy.optimize import curve_fit
import exifread
from numba_utils import *
import astroalign
import gzip
import traceback
import sep

from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed

from astropy.wcs.utils import skycoord_to_pixel
from astropy.coordinates import SkyCoord
from astropy import units as u
import itertools
from astropy.io.fits import Header

# Reproject for WCS-based alignment
try:
    from reproject import reproject_interp
except ImportError:
    reproject_interp = None  # fallback if not installed

# OpenCV for transform estimation & warping
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False


# Third-party library imports
import requests
import numpy as np
import pandas as pd
import cv2
from PIL import Image, ImageDraw, ImageFont

# Astropy and Astroquery imports
from astropy.io import fits
from astropy.time import Time
from astropy.coordinates import SkyCoord, EarthLocation, AltAz, get_body, get_sun
import astropy.units as u
from astropy.wcs import WCS
from astroquery.simbad import Simbad
from astroquery.mast import Mast
from astroquery.vizier import Vizier
import tifffile as tiff
import pytz
from astropy.utils.data import conf

from scipy.interpolate import PchipInterpolator
from scipy.interpolate import Rbf
from scipy.ndimage import median_filter
from scipy.ndimage import convolve


import rawpy
import numpy.ma as ma

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from matplotlib.patches import Circle

#################################
# PyQt6 Imports
#################################
from collections import defaultdict
import fnmatch
import pyqtgraph as pg
import psutil
# ----- QtWidgets -----
from PyQt6.QtWidgets import (
    QApplication,
    QMainWindow,
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QLabel,
    QPushButton,
    QFileDialog,
    QGraphicsView,
    QGraphicsScene,
    QMessageBox,
    QInputDialog,
    QTreeWidget,
    QTreeWidgetItem,
    QToolTip,
    QCheckBox,
    QDialog,
    QFormLayout,
    QSpinBox,
    QDialogButtonBox,
    QGridLayout,
    QGraphicsEllipseItem,
    QGraphicsLineItem,
    QGraphicsRectItem,
    QGraphicsPathItem,
    QDoubleSpinBox,
    QColorDialog,
    QFontDialog,
    QStyle,
    QSlider,
    QTabWidget,
    QScrollArea,
    QSizePolicy,
    QSpacerItem,
    QAbstractItemView,
    QToolBar,
    QGraphicsPixmapItem,
    QRubberBand,
    QGroupBox,
    QGraphicsTextItem,
    QComboBox,
    QLineEdit,
    QRadioButton,
    QButtonGroup,
    QHeaderView,
    QStackedWidget,
    QSplitter,
    QMenuBar,
    QTextEdit,
    QPlainTextEdit,      
    QProgressBar,
    QGraphicsItem,
    QToolButton,
    QStatusBar,
    QMenu,
    QTableWidget,
    QTableWidgetItem,
    QListWidget,
    QListWidgetItem,
    QSplashScreen,
    QProgressDialog, 
    QDockWidget
)

# ----- QtGui -----
from PyQt6.QtGui import (
    QPixmap,
    QImage,
    QPainter,
    QPen,
    QColor,
    QTransform,
    QIcon,
    QPainterPath,
    QKeySequence,
    QFont,
    QMovie,
    QCursor,
    QBrush,
    QShortcut,
    QPolygon,
    QPolygonF,
    QPalette, 
    QWheelEvent, 
    QDoubleValidator,
    QAction  # NOTE: In PyQt6, QAction is in QtGui (moved from QtWidgets)
)

# ----- QtCore -----
from PyQt6.QtCore import (
    Qt,
    QRectF,
    QLineF,
    QPointF,
    QThread,
    pyqtSignal,
    QCoreApplication,
    QPoint,
    QTimer,
    QRect,
    QFileSystemWatcher,
    QEvent,
    pyqtSlot,
    QProcess,
    QSize,
    QObject,
    QSettings,
    QRunnable,
    QThreadPool,
    QSignalBlocker
)


# Math functions
from math import sqrt
import math
from copy import deepcopy


VERSION = "2.15.12"


if hasattr(sys, '_MEIPASS'):
    # PyInstaller path
    icon_path = os.path.join(sys._MEIPASS, 'astrosuite.png')
    windowslogo_path = os.path.join(sys._MEIPASS, 'astrosuite.ico')
    green_path = os.path.join(sys._MEIPASS, 'green.png')
    neutral_path = os.path.join(sys._MEIPASS, 'neutral.png')
    whitebalance_path = os.path.join(sys._MEIPASS, 'whitebalance.png')
    morpho_path = os.path.join(sys._MEIPASS, 'morpho.png')
    clahe_path = os.path.join(sys._MEIPASS, 'clahe.png')
    starnet_path = os.path.join(sys._MEIPASS, 'starnet.png')
    staradd_path = os.path.join(sys._MEIPASS, 'staradd.png')
    LExtract_path = os.path.join(sys._MEIPASS, 'LExtract.png')
    LInsert_path = os.path.join(sys._MEIPASS, 'LInsert.png')
    slot0_path = os.path.join(sys._MEIPASS, 'slot0.png')
    slot1_path = os.path.join(sys._MEIPASS, 'slot1.png')
    slot2_path = os.path.join(sys._MEIPASS, 'slot2.png')
    slot3_path = os.path.join(sys._MEIPASS, 'slot3.png')
    slot4_path = os.path.join(sys._MEIPASS, 'slot4.png')
    rgbcombo_path = os.path.join(sys._MEIPASS, 'rgbcombo.png')
    rgbextract_path = os.path.join(sys._MEIPASS, 'rgbextract.png')
    copyslot_path = os.path.join(sys._MEIPASS, 'copyslot.png')
    graxperticon_path = os.path.join(sys._MEIPASS, 'graxpert.png')
    cropicon_path = os.path.join(sys._MEIPASS, 'cropicon.png')
    openfile_path = os.path.join(sys._MEIPASS, 'openfile.png')
    abeicon_path = os.path.join(sys._MEIPASS, 'abeicon.png')    
    undoicon_path = os.path.join(sys._MEIPASS, 'undoicon.png')  
    redoicon_path = os.path.join(sys._MEIPASS, 'redoicon.png')  
    blastericon_path = os.path.join(sys._MEIPASS, 'blaster.png')
    hdr_path = os.path.join(sys._MEIPASS, 'hdr.png')  
    invert_path = os.path.join(sys._MEIPASS, 'invert.png')  
    fliphorizontal_path = os.path.join(sys._MEIPASS, 'fliphorizontal.png')
    flipvertical_path = os.path.join(sys._MEIPASS, 'flipvertical.png')
    rotateclockwise_path = os.path.join(sys._MEIPASS, 'rotateclockwise.png')
    rotatecounterclockwise_path = os.path.join(sys._MEIPASS, 'rotatecounterclockwise.png')
    maskcreate_path = os.path.join(sys._MEIPASS, 'maskcreate.png')
    maskapply_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    maskremove_path = os.path.join(sys._MEIPASS, 'maskremove.png')
    slot5_path = os.path.join(sys._MEIPASS, 'slot5.png')
    slot6_path = os.path.join(sys._MEIPASS, 'slot6.png')
    slot7_path = os.path.join(sys._MEIPASS, 'slot7.png')
    slot8_path = os.path.join(sys._MEIPASS, 'slot8.png')
    slot9_path = os.path.join(sys._MEIPASS, 'slot9.png') 
    pixelmath_path = os.path.join(sys._MEIPASS, 'pixelmath.png')   
    histogram_path = os.path.join(sys._MEIPASS, 'histogram.png') 
    mosaic_path = os.path.join(sys._MEIPASS, 'mosaic.png')
    rescale_path = os.path.join(sys._MEIPASS, 'rescale.png')
    staralign_path = os.path.join(sys._MEIPASS, 'staralign.png')
    mask_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    platesolve_path = os.path.join(sys._MEIPASS, 'platesolve.png')
    psf_path = os.path.join(sys._MEIPASS, 'psf.png')
    supernova_path = os.path.join(sys._MEIPASS, 'supernova.png')
    starregistration_path = os.path.join(sys._MEIPASS, 'starregistration.png')
    stacking_path = os.path.join(sys._MEIPASS, 'stacking.png')
    pedestal_icon_path = os.path.join(sys._MEIPASS, 'pedestal.png')
    starspike_path = os.path.join(sys._MEIPASS, 'starspike.png')
    aperture_path = os.path.join(sys._MEIPASS, 'aperture.png')
    jwstpupil_path = os.path.join(sys._MEIPASS, 'jwstpupil.png')
    signature_icon_path = os.path.join(sys._MEIPASS, 'pen.png')
else:
    # Development path
    icon_path = 'astrosuite.png'
    windowslogo_path = 'astrosuite.ico'
    green_path = 'green.png'
    neutral_path = 'neutral.png'
    whitebalance_path = 'whitebalance.png'
    morpho_path = 'morpho.png'
    clahe_path = 'clahe.png'
    starnet_path = 'starnet.png'
    staradd_path = 'staradd.png'
    LExtract_path = 'LExtract.png'
    LInsert_path = 'LInsert.png'
    slot1_path = 'slot1.png'
    slot0_path = 'slot0.png'
    slot2_path = 'slot2.png'
    slot3_path  = 'slot3.png'
    slot4_path  = 'slot4.png'
    rgbcombo_path = 'rgbcombo.png'
    rgbextract_path = 'rgbextract.png'
    copyslot_path = 'copyslot.png'
    graxperticon_path = 'graxpert.png'
    cropicon_path = 'cropicon.png'
    openfile_path = 'openfile.png'
    abeicon_path = 'abeicon.png'
    undoicon_path = 'undoicon.png'
    redoicon_path = 'redoicon.png'
    blastericon_path = 'blaster.png'
    hdr_path = 'hdr.png'
    invert_path = 'invert.png'
    fliphorizontal_path = 'fliphorizontal.png'
    flipvertical_path = 'flipvertical.png'
    rotateclockwise_path = 'rotateclockwise.png'
    rotatecounterclockwise_path = 'rotatecounterclockwise.png'
    maskcreate_path = 'maskcreate.png'
    maskapply_path = 'maskapply.png'
    maskremove_path = 'maskremove.png'
    slot5_path = 'slot5.png'
    slot6_path = 'slot6.png'
    slot7_path = 'slot7.png'
    slot8_path  = 'slot8.png'
    slot9_path  = 'slot9.png'
    pixelmath_path = 'pixelmath.png'
    histogram_path = 'histogram.png'
    mosaic_path = 'mosaic.png'
    rescale_path = 'rescale.png'
    staralign_path = 'staralign.png'
    mask_path = 'maskapply.png'
    platesolve_path = 'platesolve.png'
    psf_path = 'psf.png'
    supernova_path = 'supernova.png'
    starregistration_path = 'starregistration.png'
    stacking_path = 'stacking.png'
    pedestal_icon_path = 'pedestal.png'
    starspike_path = 'starspike.png'
    aperture_path = 'aperture.png'
    jwstpupil_path = 'jwstpupil.png'
    signature_icon_path = 'pen.png'

def announce_zoom(method):
    def wrapper(self, *args, **kwargs):
        # try calling with whatever was passed, but if that fails,
        # call the zero-arg version
        try:
            result = method(self, *args, **kwargs)
        except TypeError:
            result = method(self)

        # now announce
        try:
            pct = self.zoom_factor * 100
            print(f"Zoom now {pct:.0f}%")
            vp = self.scroll_area.viewport()
            center_local = vp.rect().center()                    # QPoint in viewport coords
            center_global = vp.mapToGlobal(center_local)         # map to screen coords

            QToolTip.showText(center_global, f"{pct}%")
        except Exception:
            pass

        return result

    return wrapper

class AstroEditingSuite(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowIcon(QIcon(icon_path))
        self.setDockNestingEnabled(True)
        self.current_theme = "dark"  # Default theme
        self.image_manager = ImageManager(max_slots=10, parent=self)  # Initialize ImageManager
        self.mask_manager = self.image_manager.mask_manager
        self.image_manager.image_changed.connect(self.update_file_name)
        self.settings = QSettings()   # Replace "Seti Astro" with your actual organization name
        self.starnet_exe_path = self.settings.value("starnet/exe_path", type=str)  # Load saved path if available
        self.preview_windows = {}

        # NEW: Dictionary to store custom slot names (default names)
        self.slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
        self.slot_actions = {}

        # NEW: Dictionary to store custom mask slot names (default names)
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}
        self.mask_slot_actions = {}

        # Initialize the mask banner
        self.mask_banner = QLabel()  # Initialize QLabel
        self.mask_banner.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.mask_banner.setText("Mask Applied: None")  # Default text
        self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
        self.mask_banner.setVisible(False)  # Hidden by default        

        # Initialize UI
        self.current_theme = self.settings.value("theme", "dark")  # Fallback to dark
        self.initUI()
        self.connect_mask_manager_signals()        

    def initUI(self):
        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Enable drag and drop
        self.setAcceptDrops(True)

        # Create a menu bar
        menubar = self.menuBar()  # Use the menu bar directly from QMainWindow

        # --------------------
        # File Menu
        # --------------------
        file_menu = menubar.addMenu("File")
        
        # Create File Menu Actions
        open_action = QAction("Open Image", self)
        open_action.setShortcut('Ctrl+O')
        open_action.setStatusTip('Open an image file')
        open_action.triggered.connect(self.open_image)
        
        save_action = QAction("Save As", self)
        save_action.setShortcut('Ctrl+S')
        save_action.setStatusTip('Save the image to disk')
        save_action.triggered.connect(self.save_image)
        
        undo_action = QAction("Undo", self)
        undo_action.setShortcut('Ctrl+Z')
        undo_action.setStatusTip('Undo the last action')
        undo_action.triggered.connect(self.undo_image)
        
        redo_action = QAction("Redo", self)
        redo_action.setShortcut('Ctrl+Y')
        redo_action.setStatusTip('Redo the last undone action')
        redo_action.triggered.connect(self.redo_image)
        
        exit_action = QAction("Exit", self)
        exit_action.setShortcut('Ctrl+Q')  # Common shortcut for Exit
        exit_action.setStatusTip('Exit the application')
        exit_action.triggered.connect(self.close)  # Close the application

        # --- New Project Actions ---
        save_project_action = QAction("Save Project", self)
        save_project_action.setStatusTip("Save the entire project (images, metadata, masks, etc.)")
        save_project_action.triggered.connect(self.save_project)
        
        open_project_action = QAction("Open Project", self)
        open_project_action.setStatusTip("Open a saved project")
        open_project_action.triggered.connect(self.open_project)   

        new_project_action = QAction("New Project", self)
        new_project_action.setStatusTip("Clear the current project and start a new project (this will erase all data)")
        new_project_action.triggered.connect(self.new_project)     

        # Add actions to the File menu
        file_menu.addAction(open_action)
        file_menu.addAction(save_action)
        file_menu.addSeparator()
        file_menu.addAction(undo_action)
        file_menu.addAction(redo_action)
        file_menu.addSeparator()
        file_menu.addAction(save_project_action)   # New action
        file_menu.addAction(open_project_action)   # New action
        file_menu.addAction(new_project_action) 
        file_menu.addSeparator()
        file_menu.addAction(exit_action)

        # --------------------
        # Themes Menu
        # --------------------
        theme_menu = menubar.addMenu("Themes")
        light_theme_action = QAction("Light Theme", self)
        dark_theme_action = QAction("Dark Theme", self)

        custom_theme_menu = QMenu("Custom Theme", self)
        create_custom_action = QAction("Create New", self)
        apply_custom_action = QAction("Apply Saved", self)
        reset_custom_action = QAction("Reset", self)

        # Connect all actions
        light_theme_action.triggered.connect(lambda: self.apply_theme("light"))
        dark_theme_action.triggered.connect(lambda: self.apply_theme("dark"))
        create_custom_action.triggered.connect(self.open_custom_theme_dialog)
        apply_custom_action.triggered.connect(lambda: self.apply_theme("custom"))
        reset_custom_action.triggered.connect(self.reset_custom_theme)

        # Add actions to submenu
        custom_theme_menu.addAction(create_custom_action)
        custom_theme_menu.addAction(apply_custom_action)
        custom_theme_menu.addSeparator()
        custom_theme_menu.addAction(reset_custom_action)

        # Add to top-level menu
        theme_menu.addAction(light_theme_action)
        theme_menu.addAction(dark_theme_action)
        theme_menu.addMenu(custom_theme_menu)

        # --------------------
        # Functions Menu
        # --------------------
        functions_menu = menubar.addMenu("Functions")

        # Add Histogram Action
        histogram_action = QAction(QIcon(histogram_path), "Histogram", self)
        histogram_action.setStatusTip("Show histogram of Slot 0")
        histogram_action.triggered.connect(self.open_histogram)
        functions_menu.addAction(histogram_action)

        gradient_removal_icon = QIcon(abeicon_path)  # Replace with the actual path variable
        gradient_removal_action = QAction(gradient_removal_icon, "Remove Gradient with SetiAstro ABE", self)
        gradient_removal_action.setShortcut('Ctrl+Shift+G')  # Assign a keyboard shortcut
        gradient_removal_action.setStatusTip('Remove gradient from the current image')
        gradient_removal_action.triggered.connect(self.remove_gradient)

        # Add the new action to the Functions menu
        functions_menu.addAction(gradient_removal_action)

        remove_gradient_action = QAction(QIcon(graxperticon_path), "Remove Gradient with GraXpert", self)
        remove_gradient_action.triggered.connect(self.remove_gradient_with_graxpert)
        functions_menu.addAction(remove_gradient_action)        
        
        # Add Crop to Functions menu
        crop_action = QAction(QIcon(cropicon_path), "Crop Image", self)
        crop_action.setShortcut('Ctrl+K')
        crop_action.setStatusTip('Crop the current image')
        crop_action.triggered.connect(self.open_crop_tool)
        functions_menu.addAction(crop_action)

        pedestal_icon = QIcon(pedestal_icon_path)  # Define pedestal_icon_path appropriately.
        pedestal_action = QAction(pedestal_icon, "Pedestal Remover", self)
        pedestal_action.setShortcut('Ctrl+P')  # Example shortcut
        pedestal_action.setStatusTip("Subtract the minimum value from the active image")
        pedestal_action.triggered.connect(self.remove_pedestal)

        functions_menu.addAction(pedestal_action)

        # Create Remove Green QAction
        remove_green_action = QAction("Remove Green", self)
        remove_green_action.setShortcut('Ctrl+G')  # Assign a keyboard shortcut
        remove_green_action.setStatusTip('Remove green noise from the image')
        remove_green_action.triggered.connect(self.open_remove_green_dialog)
        
        # Add Remove Green to Functions menu
        functions_menu.addAction(remove_green_action)

        background_neutralization_action = QAction("Background Neutralization", self)
        background_neutralization_action.setShortcut('Ctrl+N')  # Assign a keyboard shortcut
        background_neutralization_action.setStatusTip('Neutralize background colors based on a sample region')
        background_neutralization_action.triggered.connect(self.open_background_neutralization_dialog)
        
        # Add to Functions menu
        functions_menu.addAction(background_neutralization_action)        

        # White Balance Action
        whitebalance_action = QAction("White Balance", self)
        whitebalance_action.setShortcut('Ctrl+Shift+W')  # Assign a keyboard shortcut
        whitebalance_action.setStatusTip('Adjust white balance of the image')
        whitebalance_action.triggered.connect(self.open_whitebalance_dialog)
        
        # Add White Balance to Functions menu
        functions_menu.addAction(whitebalance_action)   

        # Extract Luminance Action with Icon
        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.setShortcut('Ctrl+Shift+E')  # Assign a keyboard shortcut
        extract_luminance_action.setStatusTip('Extract luminance from the current image')
        extract_luminance_action.triggered.connect(self.extract_luminance)

        # Add Extract Luminance to Functions menu
        functions_menu.addAction(extract_luminance_action)

        # Recombine Luminance Action with Icon
        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.setShortcut('Ctrl+Shift+R')  # Assign a keyboard shortcut
        recombine_luminance_action.setStatusTip('Recombine luminance into the RGB image in slot 1')
        recombine_luminance_action.triggered.connect(self.recombine_luminance)

        # Add Recombine Luminance to Functions menu
        functions_menu.addAction(recombine_luminance_action)

        # RGB Combination Action
        rgb_combination_icon = QIcon(rgbcombo_path)
        rgb_combination_action = QAction(rgb_combination_icon, "RGB Combination", self)
        rgb_combination_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        rgb_combination_action.setStatusTip('Combine separate R, G, B images into an RGB image')
        rgb_combination_action.triggered.connect(self.rgb_combination)
        # Add RGB Combination to Functions menu
        functions_menu.addAction(rgb_combination_action)
        
        # RGB Extract Action
        rgb_extract_icon = QIcon(rgbextract_path)
        rgb_extract_action = QAction(rgb_extract_icon, "RGB Extract", self)
        rgb_extract_action.setShortcut('Ctrl+Shift+X')  # Assign a keyboard shortcut
        rgb_extract_action.setStatusTip('Extract R, G, B channels from an RGB image')
        rgb_extract_action.triggered.connect(self.rgb_extract)
        # Add RGB Extract to Functions menu
        functions_menu.addAction(rgb_extract_action)

        blemish_blaster_icon = QIcon(blastericon_path)  # Ensure 'blastericon_path' is correctly defined
        blemish_blaster_action = QAction(blemish_blaster_icon, "Blemish Blaster", self)
        blemish_blaster_action.setShortcut('Ctrl+B')  # Assign a keyboard shortcut (e.g., Ctrl+B)
        blemish_blaster_action.setStatusTip('Remove blemishes from the current image')
        blemish_blaster_action.triggered.connect(self.open_blemish_blaster)  # Connect to handler method

        # Add the Blemish Blaster action to the Functions menu
        functions_menu.addAction(blemish_blaster_action)

        hdr_icon = QIcon(hdr_path)
        hdr_action = QAction(hdr_icon, "WaveScale HDR", self)
        hdr_action.setShortcut('Ctrl+H')
        hdr_action.setStatusTip('Apply WaveScale HDR to the current image')
        hdr_action.triggered.connect(self.open_hdr_dialog)
        functions_menu.addAction(hdr_action)

        clahe_action = QAction("CLAHE", self)
        clahe_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        clahe_action.setStatusTip('Apply Contrast Limited Adaptive Histogram Equalization')
        clahe_action.triggered.connect(self.open_clahe_dialog)
        
        # Add CLAHE to Functions menu
        functions_menu.addAction(clahe_action)


        # Morphological Operations Action
        morpho_action = QAction("Morphological Operations", self)
        morpho_action.setShortcut('Ctrl+Shift+M')  # Assign a keyboard shortcut
        morpho_action.setStatusTip('Apply morphological operations to the image')
        morpho_action.triggered.connect(self.open_morpho_dialog)
        
        # Add Morphological Operations to Functions menu
        functions_menu.addAction(morpho_action)        

        remove_stars_action = QAction("Remove Stars", self)
        remove_stars_action.setShortcut('Ctrl+R')  # Assign a keyboard shortcut
        remove_stars_action.setStatusTip('Remove stars from the image using StarNet')
        remove_stars_action.triggered.connect(self.remove_stars)

        # Add Remove Stars to Functions menu
        functions_menu.addAction(remove_stars_action)

        add_stars_action = QAction("Add Stars", self)
        add_stars_action.setShortcut('Ctrl+A')  # Assign a keyboard shortcut
        add_stars_action.setStatusTip('Add stars back to the current image')
        add_stars_action.triggered.connect(self.add_stars)

        # Add Add Stars to Functions menu
        functions_menu.addAction(add_stars_action)   

        # Pixel Math Action
        pixel_math_action = QAction(QIcon(pixelmath_path), "Pixel Math", self)
        pixel_math_action.setStatusTip("Perform pixel math operations on the current image")
        pixel_math_action.triggered.connect(self.open_pixel_math_dialog)
        functions_menu.addAction(pixel_math_action)         

        self.signature_insert_action = QAction(QIcon(signature_icon_path), "Signature/Insert", self)
        self.signature_insert_action.setStatusTip("Open Signature/Insert tool")
        self.signature_insert_action.triggered.connect(self.open_signature_insert_window)
        functions_menu.addAction(self.signature_insert_action)
        

        # --------------------
        # Geometry Menu
        # --------------------
        geometry_menu = menubar.addMenu("Geometry")

        invert_icon = QIcon(invert_path)  # Ensure 'invert_path' is correctly defined
        invert_action = QAction(invert_icon, "Invert Image", self)
        invert_action.setShortcut("Ctrl+I")
        invert_action.setStatusTip("Invert the colors of the current image")
        invert_action.triggered.connect(self.invert_image)

        # Add the Invert action to the Functions menu
        geometry_menu.addAction(invert_action)


        # Flip Horizontal Action
        flip_horizontal_icon = QIcon(fliphorizontal_path)
        flip_horizontal_action = QAction(flip_horizontal_icon, "Flip Horizontal", self)
        flip_horizontal_action.setShortcut("Ctrl+Shift+H")
        flip_horizontal_action.setStatusTip("Flip the current image horizontally")
        flip_horizontal_action.triggered.connect(self.flip_horizontal)

        # Add to Functions menu
        geometry_menu.addAction(flip_horizontal_action)



        # Flip Vertical Action
        flip_vertical_icon = QIcon(flipvertical_path)
        flip_vertical_action = QAction(flip_vertical_icon, "Flip Vertical", self)
        flip_vertical_action.setShortcut("Ctrl+Shift+V")
        flip_vertical_action.setStatusTip("Flip the current image vertically")
        flip_vertical_action.triggered.connect(self.flip_vertical)

        # Add to Functions menu
        geometry_menu.addAction(flip_vertical_action)



        # Rotate Clockwise Action
        rotate_clockwise_icon = QIcon(rotateclockwise_path)
        rotate_clockwise_action = QAction(rotate_clockwise_icon, "Rotate Clockwise", self)
        rotate_clockwise_action.setShortcut("Ctrl+Shift+R")
        rotate_clockwise_action.setStatusTip("Rotate the current image 90° clockwise")
        rotate_clockwise_action.triggered.connect(self.rotate_clockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_clockwise_action)


        # Rotate Counterclockwise Action
        rotate_counterclockwise_icon = QIcon(rotatecounterclockwise_path)
        rotate_counterclockwise_action = QAction(rotate_counterclockwise_icon, "Rotate Counterclockwise", self)
        rotate_counterclockwise_action.setShortcut("Ctrl+Shift+L")
        rotate_counterclockwise_action.setStatusTip("Rotate the current image 90° counterclockwise")
        rotate_counterclockwise_action.triggered.connect(self.rotate_counterclockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_counterclockwise_action)

        #rescale
        rescale_action = QAction("Rescale", self)
        rescale_action.setIcon(QIcon(rescale_path))
        rescale_action.setStatusTip("Rescale the current image by a custom factor")
        rescale_action.triggered.connect(self.rescale_image)
        geometry_menu.addAction(rescale_action)

        # --------------------
        # Slot Menu
        # --------------------
        slot_menu = menubar.addMenu("Slots")

        # Dictionary to store menubar slot actions
        self.menubar_slot_actions = {}

        num_slots = self.image_manager.max_slots

        for slot in range(num_slots):
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            slot_icon = QIcon(slot_icon_path)
            
            slot_name = self.slot_names.get(slot, f"Slot {slot}")

            # Create QAction for the menubar slot
            slot_action = QAction(slot_icon, slot_name, self)
            slot_action.setStatusTip(f"Open preview for {slot_name}")
            slot_action.triggered.connect(lambda checked, s=slot: self.open_preview_window(s))
            
            # Store menubar slot actions for later updates
            self.menubar_slot_actions[slot] = slot_action

            # Add to menu
            slot_menu.addAction(slot_action)

        # Separator & Rename Slot Action
        slot_menu.addSeparator()
        rename_slot_action = QAction("Rename Slot", self)
        rename_slot_action.setStatusTip("Rename a slot with a custom name")
        rename_slot_action.triggered.connect(self.rename_slot)
        slot_menu.addAction(rename_slot_action)


        # --------------------
        # Mask Menu
        # --------------------
        masks_menu = menubar.addMenu("&Masks")

        maskcreate_path = resource_path('maskcreate.png')
        maskapply_path = resource_path('maskapply.png')
        maskremove_path = resource_path('maskremove.png')

        maskcreate_icon = QIcon(maskcreate_path)
        maskapply_icon = QIcon(maskapply_path)
        maskremove_icon = QIcon(maskremove_path)

        # Create Mask Actions
        create_mask_action = QAction(maskcreate_icon, "Create Mask", self)
        create_mask_action.setStatusTip("Create a new mask for the current image")
        create_mask_action.triggered.connect(self.create_mask)

        apply_mask_action = QAction(maskapply_icon, "Apply Mask", self)
        apply_mask_action.setStatusTip("Apply the selected mask to the image")
        apply_mask_action.triggered.connect(self.apply_mask)

        remove_mask_action = QAction(maskremove_icon, "Remove Mask", self)
        remove_mask_action.setStatusTip("Remove the currently applied mask")
        remove_mask_action.triggered.connect(self.remove_mask)

        # Add Mask Actions to Masks Menu
        masks_menu.addAction(create_mask_action)
        masks_menu.addAction(apply_mask_action)
        masks_menu.addAction(remove_mask_action)

        # Add Load Mask action
        load_mask_action = QAction("Load Mask", self)
        load_mask_action.triggered.connect(self.load_mask)
        masks_menu.addAction(load_mask_action)

        # Add Save Mask action
        save_mask_action = QAction("Save Mask", self)
        save_mask_action.triggered.connect(self.save_mask)
        masks_menu.addAction(save_mask_action)

        # Mask Slots Submenu
        mask_slots_menu = masks_menu.addMenu("Mask Slots")


        for slot in range(5):  # Five mask slots (0-4)
            # Use the custom name from the dictionary
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            slot_action = QAction(mask_slot_name, self)
            slot_action.triggered.connect(lambda checked, s=slot: self.preview_mask_slot(s))
            mask_slots_menu.addAction(slot_action)
            self.mask_slot_actions[slot] = slot_action

        # Add a separator and a "Rename Mask Slot" action
        mask_slots_menu.addSeparator()
        rename_mask_slot_action = QAction("Rename Mask Slot", self)
        rename_mask_slot_action.setStatusTip("Rename a mask slot with a custom name")
        rename_mask_slot_action.triggered.connect(self.rename_mask_slot)
        mask_slots_menu.addAction(rename_mask_slot_action)

        # --------------------
        # Star Stuff Menu
        # --------------------
        mosaic_menu = menubar.addMenu("Star Stuff")

        # Stacking Suite Action (New!)
        stacking_suite_action = QAction(QIcon(stacking_path), "Stacking Suite", self)
        stacking_suite_action.setStatusTip("Calibrate and stack images with advanced methods")
        stacking_suite_action.triggered.connect(self.stacking_suite_action)
        mosaic_menu.addAction(stacking_suite_action)

        mosaic_master_action = QAction(QIcon(mosaic_path), "Mosaic Master", self)
        mosaic_master_action.setStatusTip("Create a mosaic from multiple images.")
        mosaic_master_action.triggered.connect(self.open_mosaic_master)

        mosaic_menu.addAction(mosaic_master_action)

        # Stellar Alignment Action (added to Mosaic menu and toolbar)
        stellar_align_action = QAction(QIcon(staralign_path), "Stellar Alignment", self)
        stellar_align_action.setStatusTip("Align the target image to the source image using star alignment")
        stellar_align_action.triggered.connect(self.stellar_alignment)
        mosaic_menu.addAction(stellar_align_action)

        star_registration_action = QAction(QIcon(starregistration_path), "Star Registration", self)
        star_registration_action.setStatusTip("Register multiple images based on star alignment")
        star_registration_action.triggered.connect(self.star_registration)
        mosaic_menu.addAction(star_registration_action)        

        plate_solver_action = QAction(QIcon(platesolve_path), "Plate Solver", self)
        plate_solver_action.setStatusTip("Perform plate solving on an image")
        plate_solver_action.triggered.connect(self.launch_plate_solver)
        mosaic_menu.addAction(plate_solver_action)      

        # PSF Viewer Action (New!)
        psf_viewer_action = QAction(QIcon(psf_path), "PSF Viewer", self)
        psf_viewer_action.setStatusTip("View PSF histograms and star statistics")
        psf_viewer_action.triggered.connect(self.psf_viewer)
        mosaic_menu.addAction(psf_viewer_action)        

        # Supernova Action (New!)
        supernova_action = QAction(QIcon(supernova_path), "SuperNova Asteroid Hunter", self)
        supernova_action.setStatusTip("Hunt for anomalies in your images")
        supernova_action.triggered.connect(self.open_supernova_hunter)
        mosaic_menu.addAction(supernova_action)    

        star_spike_icon = QIcon(starspike_path)  # the path to your star spike icon
        star_spike_action = QAction(star_spike_icon, "Star Spike Tool", self)
        star_spike_action.setStatusTip("Add diffraction spikes to stars in the active image")
        star_spike_action.triggered.connect(self.starspiketool)  # connects to the method below
        mosaic_menu.addAction(star_spike_action)

        # --------------------
        # Toolbar
        # --------------------
        filebar = QToolBar("File Toolbar")
        filebar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(filebar)

        # Add Open File icon and action
        open_icon = QIcon(openfile_path)  # Replace with the actual path to your "Open File" icon
        open_action = QAction(open_icon, "Open File", self)
        open_action.setStatusTip("Open an image file")
        open_action.triggered.connect(self.open_image)  # Connect to the existing open_image method
        filebar.addAction(open_action)

        # Add Save As disk icon and action
        save_as_icon = QIcon(disk_icon_path)  # Replace with the actual path to your "Save As" icon
        save_as_action = QAction(save_as_icon, "Save As", self)
        save_as_action.setStatusTip("Save the current image")
        save_as_action.triggered.connect(self.save_image)  # Connect to the existing save_image method
        filebar.addAction(save_as_action)

        # Add Undo icon and action
        undo_icon = QIcon(undoicon_path)
        self.undo_action_toolbar = QAction(undo_icon, "Undo", self)
        self.undo_action_toolbar.setStatusTip("Undo the last action")
        self.undo_action_toolbar.triggered.connect(self.undo_image)
        filebar.addAction(self.undo_action_toolbar)

        # Add Redo icon and action
        redo_icon = QIcon(redoicon_path)
        self.redo_action_toolbar = QAction(redo_icon, "Redo", self)
        self.redo_action_toolbar.setStatusTip("Redo the last undone action")
        self.redo_action_toolbar.triggered.connect(self.redo_image)
        filebar.addAction(self.redo_action_toolbar)

        toolbar = QToolBar("Main Toolbar")
        toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(toolbar)

        # Add "Copy Slot" Button to Toolbar with Icon
        copy_slot_icon = QIcon(copyslot_path)  # Ensure 'copyslot.png' is the correct path
        copy_slot_action = QAction(copy_slot_icon, "Copy Slot", self)
        copy_slot_action.setStatusTip("Copy the current image in Slot 0 to another slot")
        copy_slot_action.triggered.connect(self.copy_slot_to_target)
        toolbar.addAction(copy_slot_action)

        toolbar.addAction(histogram_action)

        crop_icon = QIcon(cropicon_path)
        crop_action.setIcon(crop_icon)
        toolbar.addAction(crop_action)

        toolbar.addAction(gradient_removal_action)

        remove_gradient_icon = QIcon(graxperticon_path)
        remove_gradient_action.setIcon(remove_gradient_icon)
        remove_gradient_action.setStatusTip("Remove Gradient with GraXpert AI")
        toolbar.addAction(remove_gradient_action)

        # Add Remove Stars Button to Toolbar with Icon
        remove_stars_icon = QIcon(starnet_path)
        remove_stars_action.setIcon(remove_stars_icon)  # Set the icon to the QAction
        remove_stars_action.setToolTip("Remove Stars using StarNet")
        toolbar.addAction(remove_stars_action)  # Add the same QAction to the toolbar

        # Add Add Stars Button to Toolbar with Icon
        add_stars_icon = QIcon(staradd_path)
        add_stars_action.setIcon(add_stars_icon)  # Set the icon to the QAction
        add_stars_action.setToolTip("Add Stars back to the image")
        toolbar.addAction(add_stars_action)  # Add the same QAction to the toolbar

        pedestal_icon = QIcon(pedestal_icon_path)  # Define pedestal_icon_path appropriately.
        pedestal_action = QAction(pedestal_icon, "Pedestal Remover", self)
        pedestal_action.setShortcut('Ctrl+P')  # Example shortcut
        pedestal_action.setStatusTip("Subtract the minimum value from the active image")
        pedestal_action.triggered.connect(self.remove_pedestal)
        toolbar.addAction(pedestal_action)

        # Add "Remove Green" Button to Toolbar with Icon
        remove_green_icon = QIcon(green_path)
        remove_green_action.setIcon(remove_green_icon)  # Set the icon to the QAction
        toolbar.addAction(remove_green_action)  # Add the same QAction to the toolbar

        # Add "Background Neutralization" Button to Toolbar with Icon
        background_neutralization_icon = QIcon(neutral_path)
        background_neutralization_action.setIcon(background_neutralization_icon)  # Set the icon
        background_neutralization_action.setToolTip("Neutralize background colors based on a sample region.")
        toolbar.addAction(background_neutralization_action)  # Add the QAction to the toolbar

        # Add White Balance Button to Toolbar with Icon
        whitebalance_icon = QIcon(whitebalance_path)
        whitebalance_action.setIcon(whitebalance_icon)
        whitebalance_action.setToolTip("Adjust white balance of the image.")
        toolbar.addAction(whitebalance_action)

        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.triggered.connect(self.extract_luminance)
        toolbar.addAction(extract_luminance_action)

        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.triggered.connect(self.recombine_luminance)
        toolbar.addAction(recombine_luminance_action)

        # Add RGB Combination Button to Toolbar
        toolbar.addAction(rgb_combination_action)

        # Add RGB Extract Button to Toolbar
        toolbar.addAction(rgb_extract_action)

        toolbar.addAction(blemish_blaster_action)

        toolbar.addAction(hdr_action)

        # Add CLAHE Button to Toolbar with Icon
        clahe_icon = QIcon(clahe_path)
        clahe_action.setIcon(clahe_icon)
        clahe_action.setToolTip("Apply Contrast Limited Adaptive Histogram Equalization.")
        toolbar.addAction(clahe_action)      

        # Add Morphological Operations Button to Toolbar with Icon
        morpho_icon = QIcon(morpho_path)
        morpho_action.setIcon(morpho_icon)
        morpho_action.setToolTip("Apply morphological operations to the image.")
        toolbar.addAction(morpho_action)    

        toolbar.addAction(pixel_math_action)

        toolbar.addAction(self.signature_insert_action)        

        geometrybar = QToolBar("Geometry Toolbar")

        geometrybar.addAction(invert_action)
        self.addToolBar(geometrybar)

        geometrybar.addAction(flip_horizontal_action)
        geometrybar.addAction(flip_vertical_action)        
        geometrybar.addAction(rotate_clockwise_action)
        geometrybar.addAction(rotate_counterclockwise_action)    
        geometrybar.addAction(rescale_action)

        # --------------------
        # Star Stuff Toolbar
        # --------------------        
        mosaictoolbar = QToolBar("Star Stuff Toolbar")
        mosaictoolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mosaictoolbar)  
        mosaictoolbar.addAction(stacking_suite_action)      
        mosaictoolbar.addAction(mosaic_master_action)    
        mosaictoolbar.addAction(stellar_align_action)
        mosaictoolbar.addAction(star_registration_action)
        mosaictoolbar.addAction(plate_solver_action)
        mosaictoolbar.addAction(psf_viewer_action)     
        mosaictoolbar.addAction(supernova_action)   
        mosaictoolbar.addAction(star_spike_action)
        
        # --------------------
        # Mask Toolbar
        # --------------------
        mask_toolbar = QToolBar("Mask Toolbar")
        mask_toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mask_toolbar)

        # Add Mask Actions to Mask Toolbar
        mask_toolbar.addAction(create_mask_action)
        mask_toolbar.addAction(apply_mask_action)
        mask_toolbar.addAction(remove_mask_action)
        
        # Create a toolbar for slots and dock it on the left side.
        self.slot_toolbar = QToolBar("Slot Toolbar", self)
        self.slot_toolbar.setAllowedAreas(Qt.ToolBarArea.LeftToolBarArea)
        self.slot_toolbar.setOrientation(Qt.Orientation.Vertical)  # Vertical layout
        self.addToolBar(Qt.ToolBarArea.LeftToolBarArea, self.slot_toolbar)

        # Create a button for each slot
        for slot in range(self.image_manager.max_slots):
            # Create a QToolButton for this slot.
            button = QToolButton()
            
            # Retrieve the icon path using getattr. This will look for an attribute
            # like 'slot0_path', 'slot1_path', etc., in your module, defaulting to 'slot0.png'
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            
            # Set the icon and optionally an icon size
            button.setIcon(QIcon(slot_icon_path))
            button.setIconSize(QSize(32, 32))  # Adjust the size as needed
            
            # Set the slot text and style (text below the icon)
            button.setText(self.slot_names[slot])
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Connect the normal (left-click) signal.
            button.clicked.connect(lambda checked, s=slot: self.set_active_slot(s))
            
            # Enable the custom context menu.
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_slot_context_menu(pos, s))
            
            # Add the button to the toolbar and store a reference.
            self.slot_toolbar.addWidget(button)
            self.slot_actions[slot] = button


        # --- Add a dummy separator button with the mask icon ---

        separator_button = QToolButton()
        separator_button.setIcon(QIcon(mask_path))
        separator_button.setIconSize(QSize(64, 64))
        separator_button.setEnabled(False)  # Disable so it doesn't respond to clicks.
        separator_button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonIconOnly)
        self.slot_toolbar.addWidget(separator_button)

        # --- Create mask slot buttons ---
        for slot in range(5):  # Assuming 5 mask slots (0-4)
            button = QToolButton()
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            button.setText(mask_slot_name)
            # Optionally, set an icon for mask slots:
            # button.setIcon(QIcon("mask_icon.png"))
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Left-click: apply the mask in that slot.
            button.clicked.connect(lambda checked, s=slot: self.apply_mask_from_slot(s))
            
            # Right-click: open a context menu with "Preview Mask Slot" and "Rename Mask Slot".
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_mask_slot_context_menu(pos, s))
            
            self.slot_toolbar.addWidget(button)
            self.mask_slot_actions[slot] = button            

        # Highlight the default active slot.
        self.update_slot_toolbar_highlight()

        # --------------------
        # Status Bar
        # --------------------
        self.statusBar = QStatusBar(self)
        self.setStatusBar(self.statusBar)

        # File label (left side)
        self.file_name_label = QLabel("No file selected")
        self.statusBar.addWidget(self.file_name_label)  # Adds on the left

        # Create a container widget for the active slot label in the center.
        middleWidget = QWidget()
        middleLayout = QHBoxLayout(middleWidget)
        middleLayout.setContentsMargins(0, 0, 0, 0)  # Remove extra margins
        # Add stretch before and after the active slot label to center it.
        middleLayout.addStretch(1)
        self.active_slot_label = QLabel("Active Slot: 0")
        middleLayout.addWidget(self.active_slot_label)
        middleLayout.addStretch(1)
        # Add the middle widget with an expanding stretch factor (here using 1)
        self.statusBar.addWidget(middleWidget, 1)

        # Dimension label (right side)
        self.dim_label = QLabel("0 x 0")
        self.statusBar.addPermanentWidget(self.dim_label)  # Adds on the right

        # Connect the image_manager's signal to update the active slot label.
        self.image_manager.current_slot_changed.connect(self.update_active_slot_label)

        # --------------------
        # Tab Widget
        # --------------------
        self.tabs = QTabWidget()
        # Add individual tabs for each tool
        self.tabs.addTab(XISFViewer(image_manager=self.image_manager), "Image Viewer")
        self.tabs.addTab(BlinkTab(image_manager=self.image_manager), "Blink Comparator")
        self.tabs.addTab(CosmicClarityTab(image_manager=self.image_manager), "Cosmic Clarity")
        self.tabs.addTab(CosmicClaritySatelliteTab(), "Cosmic Clarity Satellite")
        self.tabs.addTab(StatisticalStretchTab(image_manager=self.image_manager), "Statistical Stretch")
        self.tabs.addTab(FullCurvesTab(image_manager=self.image_manager), "Curves Utility")
        self.tabs.addTab(PerfectPalettePickerTab(image_manager=self.image_manager, parent=self), "Perfect Palette Picker")
        self.tabs.addTab(NBtoRGBstarsTab(image_manager=self.image_manager, parent=self), "NB to RGB Stars")
        self.tabs.addTab(StarStretchTab(image_manager=self.image_manager), "Star Stretch")
        self.tabs.addTab(FrequencySeperationTab(image_manager=self.image_manager), "Frequency Separation")
        self.tabs.addTab(HaloBGonTab(image_manager=self.image_manager), "Halo-B-Gon")
        self.tabs.addTab(ContinuumSubtractTab(image_manager=self.image_manager), "Continuum Subtraction")
        self.tabs.addTab(MainWindow(), "What's In My Image")
        self.tabs.addTab(WhatsInMySky(), "What's In My Sky")
        self.tabs.currentChanged.connect(self.on_tab_changed)

        # Set the layout for the main window
        central_widget = QWidget(self)  # Create a central widget
        layout = QVBoxLayout(central_widget)

        layout.addWidget(self.mask_banner)  # Add banner to the layout        
        layout.addWidget(self.tabs)  # Add tabs to the central widget

        # Set the central widget of the main window
        self.setCentralWidget(central_widget)

        # --------------------
        # Quick Navigation Menu
        # --------------------
        quicknav_menu = menubar.addMenu("Quick Navigation")
        for i in range(self.tabs.count()):
            tab_title = self.tabs.tabText(i)
            action = QAction(tab_title, self)
            # Use lambda with default argument to capture the current value of i
            action.triggered.connect(lambda checked, index=i: self.tabs.setCurrentIndex(index))
            quicknav_menu.addAction(action)

        # --------------------
        # History Menu
        # --------------------
        history_menu = menubar.addMenu("History")
        view_history_action = QAction("View Undo History", self)
        view_history_action.setStatusTip("View all previous steps for the current slot")
        view_history_action.triggered.connect(self.show_history_dialog)
        history_menu.addAction(view_history_action)

        # --------------------
        # Preferences Menu
        # --------------------
        preferences_menu = menubar.addMenu("Preferences")
        preferences_action = QAction("Open Preferences", self)
        preferences_action.setStatusTip('Modify application settings')
        preferences_action.triggered.connect(self.open_preferences_dialog)
        preferences_menu.addAction(preferences_action)

        update_menu = menubar.addMenu("Update")
        check_update_action = QAction("Check for Updates", self)
        check_update_action.triggered.connect(self.check_for_updates)
        update_menu.addAction(check_update_action)

        # Help Menu with About action
        help_menu = menubar.addMenu("About")
        about_action = QAction("About", self)
        about_action.setStatusTip("About AstroEditingSuite")
        about_action.triggered.connect(self.show_about_dialog)
        help_menu.addAction(about_action)

        # --------------------
        # Apply Default Theme
        # --------------------
        self.apply_theme(self.current_theme)

        # --------------------
        # Window Properties
        # --------------------
        self.setWindowTitle(f'Seti Astro\'s Suite V{VERSION} QT6')
        self.setGeometry(100, 100, 800, 600)  # Set window size as needed

        self.check_for_updatesstartup()  # Call this in your app's init
        self.update_slot_toolbar_highlight()

    def show_history_dialog(self):
        slot = self.image_manager.current_slot
        self.history_dialog = HistoryExplorerDialog(self.image_manager, slot=self.image_manager.current_slot, parent=self)
        self.history_dialog.show()



    def starspiketool(self):
        dialog = StarSpikeTool(self.image_manager, self.mask_manager, parent=self)
        dialog.exec()

    def remove_pedestal(self):
        # 1) Prompt the user
        dlg = QMessageBox(self)
        dlg.setWindowTitle("Pedestal Removal")
        dlg.setText("Apply pedestal removal to:")
        btn_current = dlg.addButton(
            "Current Slot", QMessageBox.ButtonRole.YesRole
        )
        btn_all     = dlg.addButton(
            "All Slots",    QMessageBox.ButtonRole.NoRole
        )
        dlg.addButton(QMessageBox.StandardButton.Cancel)
        dlg.exec()

        # 2) Pick slots based on exactly which button got clicked
        if dlg.clickedButton() is btn_current:
            slots = [ self.image_manager.current_slot ]
        elif dlg.clickedButton() is btn_all:
            slots = list(range(self.image_manager.max_slots))
        else:
            return  # canceled

        # 3) Do the pedestal subtraction on each slot you chose
        for slot in slots:
            img = self.image_manager._images.get(slot)
            meta = self.image_manager._metadata.get(slot, {})
            if img is None:
                continue

            if img.ndim == 2:
                new_img = img - img.min()
            else:
                new_img = np.empty_like(img)
                for ch in range(img.shape[2]):
                    new_img[..., ch] = img[..., ch] - img[..., ch].min()

            # 4) Use set_image_for_slot so each slot gets its own undo entry
            self.image_manager.set_image_for_slot(
                slot,
                new_img,
                meta,
                step_name="Pedestal Removal"
            )

        # 5) Let them know
        QMessageBox.information(self, "Pedestal Removal", "Done!")


    def open_signature_insert_window(self):
        self.signature_insert_window = SignatureInsertWindow(self.image_manager, parent=self)
        self.signature_insert_window.show()



    def star_registration(self):
        self.star_registration_window = StarRegistrationWindow(self.image_manager)
        self.star_registration_window.show()

    def show_about_dialog(self):
        dialog = AboutDialog(self)
        dialog.show()

    def open_supernova_hunter(self):
        # Instantiate the SuperNova/Asteroid Hunter widget
        self.supernova_hunter_tab = SupernovaAsteroidHunterTab()
        # Show the new window (or tab)
        self.supernova_hunter_tab.show()

    def stacking_suite_action(self):
        self.stackingsuitewindow = StackingSuiteDialog()
        self.stackingsuitewindow.show()



    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified image slot."""
        # Validate slot range and image availability.
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview is already open.
        if slot in self.preview_windows:
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            return

        # Create and show a new preview window.
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)
        self.preview_windows[slot] = preview
        preview.closed.connect(self.on_preview_closed)
        preview.show()

    def update_mask_slot_toolbar_highlight(self):
        """
        Loops through the mask slot buttons and applies a blue border to any slot that contains a mask.
        """
        for slot, button in self.mask_slot_actions.items():
            mask = self.mask_manager.get_mask(slot)
            if mask is not None:
                # Blue border indicates a mask is saved in this slot.
                button.setStyleSheet("border: 2px solid blue;")
            else:
                # Clear any border if the slot is empty.
                button.setStyleSheet("")


    def connect_mask_manager_signals(self):
        self.mask_manager.mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())
        self.mask_manager.applied_mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())

    def show_mask_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for a mask slot button with options to preview or rename.
        """
        button = self.mask_slot_actions.get(slot)
        if not button:
            return

        menu = QMenu(button)
        action_preview = menu.addAction("Preview Mask Slot")
        action_rename = menu.addAction("Rename Mask Slot")
        global_pos = button.mapToGlobal(pos)
        selected_action = menu.exec(global_pos)
        if selected_action == action_preview:
            self.preview_mask_slot(slot)
        elif selected_action == action_rename:
            self.rename_mask_slot_by_context(slot)

    def rename_mask_slot_by_context(self, slot):
        """
        Prompts the user to rename a mask slot (given by slot number) and updates the UI.
        """
        new_name, ok = QInputDialog.getText(
            self, "Rename Mask Slot", f"Enter new name for mask slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        self.mask_slot_names[slot] = new_name
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Apply or preview mask for {new_name}")
        QMessageBox.information(self, "Rename Mask Slot", f"Mask slot {slot} renamed to '{new_name}'.")


    def show_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for the slot button, with options to show the slot preview, rename the slot, or clear its contents.
        """
        # Retrieve the corresponding button
        button = self.slot_actions.get(slot)
        if not button:
            return

        # Create a QMenu for this button
        menu = QMenu(self)  # In Qt6, pass self as the parent
        
        # Add actions
        action_show_preview = menu.addAction("Show Slot Preview")
        action_rename = menu.addAction("Rename")
        action_clear = menu.addAction("Clear Slot")  # New clear slot option

        # Execute the menu at the global position
        selected_action = menu.exec(button.mapToGlobal(pos))
        
        # Perform actions based on selection
        if selected_action == action_show_preview:
            self.open_preview_window(slot)
        elif selected_action == action_rename:
            self.rename_slot_by_context(slot)
        elif selected_action == action_clear:
            self.clear_slot_contents(slot)  # Call the new clear function


    def rename_slot_by_context(self, slot):
        """
        Prompts the user to enter a new name for the specified slot and updates the UI.
        """
        # Prompt for the new name for this slot.
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", f"Enter new name for slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces.
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary.
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()

        QMessageBox.information(self, "Rename Successful", f"Slot {slot} renamed to {new_name}.")

    def clear_slot_contents(self, slot):
        """
        Completely clears the contents of the specified slot and resets the UI in Qt6.
        """
        # Confirm with the user before clearing
        reply = QMessageBox.question(
            self,
            "Clear Slot",
            f"Are you sure you want to clear slot {slot}?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.No:
            return  # User canceled

        # Ensure the ImageManager exists
        if not hasattr(self, 'image_manager'):
            QMessageBox.warning(self, "Error", "ImageManager is not available.")
            return

        # Remove image and metadata from ImageManager
        self.image_manager._images[slot] = None  # Remove image
        self.image_manager._metadata[slot] = {}  # Clear metadata
        self.image_manager._undo_stacks[slot] = []  # Clear undo history
        self.image_manager._redo_stacks[slot] = []  # Clear redo history


        # Close preview window if it exists
        if slot in self.preview_windows:
            self.preview_windows[slot].close()
            del self.preview_windows[slot]

        # Reset slot button UI
        if slot in self.slot_actions:
            button = self.slot_actions[slot]
            button.setText(f"Slot {slot}")  # Reset text
            button.setToolTip("No content available")  # Reset tooltip

        # Emit signal to update the UI and trigger the image refresh
        self.image_manager.image_changed.emit(slot, np.zeros((1, 1), dtype=np.uint8), {})

        # Notify user that the slot was cleared
        QMessageBox.information(self, "Slot Cleared", f"Slot {slot} has been completely cleared.")



    def stellar_alignment(self):
        dialog = StellarAlignmentDialog(self, self.settings, self.image_manager)
        dialog.show()

    def launch_plate_solver(self):
        # Instantiate and run the PlateSolver dialog.
        solver = PlateSolver(self.settings, self)
        solver.show()  # The PlateSolver dialog handles the full process

    def psf_viewer(self):
        """
        Create and show the PSFViewer dialog using the current image from the image manager.
        """
        # Check if a PSFViewer dialog is already open; if so, bring it to the front.
        if (hasattr(self, 'psf_viewer_dialog') and 
                self.psf_viewer_dialog is not None and 
                self.psf_viewer_dialog.isVisible()):
            self.psf_viewer_dialog.raise_()
            self.psf_viewer_dialog.activateWindow()
            return

        # Get the image from slot 0.
        img = self.image_manager._images.get(0, None)
        if img is None:
            QMessageBox.warning(self, "No Image", "Slot 0 does not contain an image.")
            return

        # If the image is grayscale, replicate to 3 channels.
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)

        # Create the PSFViewer dialog.
        self.psf_viewer_dialog = PSFViewer(img, self)

        # Define a helper function to update the PSFViewer when slot 0 changes.
        def update_psf(slot, image, metadata):
            if slot == 0:
                if image is None:
                    return
                if image.ndim == 2:
                    image = np.stack([image] * 3, axis=-1)
                self.psf_viewer_dialog.updateImage(image)

        # Connect the image_changed signal.
        #self.image_manager.image_changed.connect(update_psf)

        self.psf_viewer_dialog.show()


    def update_slot_toolbar_highlight(self):
        """
        Update the slot toolbar so that:
        - The active slot gets a distinct border (e.g., blue) regardless of occupancy.
        - Non-active slots that are occupied get a green border.
        - Unoccupied non-active slots have no border.
        """
        active_slot = self.image_manager.current_slot
        for slot, button in self.slot_actions.items():
            if button is not None:
                if slot == active_slot:
                    # Active slot: highlight with blue border.
                    button.setStyleSheet("border: 2px solid green; background-color: yellow; color: black;")
                else:
                    # For non-active slots:
                    if self.image_manager._images.get(slot) is not None:
                        # Occupied slot: green border.
                        button.setStyleSheet("border: 2px solid blue;")
                    else:
                        # Unoccupied: clear style.
                        button.setStyleSheet("")


    def set_active_slot(self, slot):
        """Set the specified slot as active and update the slot toolbar highlight."""
        self.image_manager.set_current_slot(slot)
        # Optionally, update other UI elements (such as an "Active Slot" label)
        self.update_slot_toolbar_highlight()


    def on_tab_changed(self, index):
        current_tab = self.tabs.widget(index)
        # Check if the tab has a 'refresh' method.
        if hasattr(current_tab, "refresh"):
            current_tab.refresh()

    def update_active_slot_label(self, slot):
        # Look up the custom name for this slot; if none exists, fall back to "Slot {slot}"
        slot_name = self.slot_names.get(slot, f"Slot {slot}")
        self.active_slot_label.setText(f"Active Slot: {slot_name}")


    def open_mosaic_master(self):
        """
        Opens a new MosaicMasterDialog (or QMainWindow) where the user can
        add multiple images, star-align them, and create a large mosaic.
        """
        # Create the mosaic master window if not already created, or just each time:
        mosaic_window = MosaicMasterDialog(self.settings, parent=self, image_manager=self.image_manager)

        mosaic_window.show()

    def save_project(self):
        """Save all project data to a single file."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getSaveFileName(
            self,
            "Save Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        # Assemble project data into one dictionary.
        project_data = {
            # ImageManager data: images and metadata
            "images": self.image_manager._images,       # dictionary {slot: image array}
            "metadata": self.image_manager._metadata,   # dictionary {slot: metadata dict}
            # Save custom slot names
            "slot_names": self.slot_names,
            # Undo/Redo stacks
            "undo_stacks": self.image_manager._undo_stacks,
            "redo_stacks": self.image_manager._redo_stacks,            
            # MaskManager data
            "masks": self.mask_manager._masks,          # dictionary {slot: mask array}
            "applied_mask_slot": self.mask_manager.applied_mask_slot,
            "applied_mask": self.mask_manager.applied_mask,
            # Save custom mask slot names
            "mask_slot_names": self.mask_slot_names,
            
            # Additional settings
            "current_slot": self.image_manager.current_slot,
            "theme": self.current_theme,
        }

        try:
            with open(fileName, "wb") as f:
                pickle.dump(project_data, f)
            print("Project saved successfully to:", fileName)
        except Exception as e:
            QMessageBox.critical(self, "Save Project Error", f"Error saving project: {str(e)}")


    def open_project(self):
        """Open a project file and repopulate all managers and UI elements."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getOpenFileName(
            self,
            "Open Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        try:
            with open(fileName, "rb") as f:
                project_data = pickle.load(f)
        except Exception as e:
            QMessageBox.critical(self, "Open Project Error", f"Error opening project: {str(e)}")
            return

        # Restore ImageManager data
        if "images" in project_data and "metadata" in project_data:
            self.image_manager._images = project_data["images"]
            self.image_manager._metadata = project_data["metadata"]
            self.image_manager.current_slot = project_data.get("current_slot", 0)
            # Restore undo/redo stacks if available
            self.image_manager._undo_stacks = project_data.get(
                "undo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )
            self.image_manager._redo_stacks = project_data.get(
                "redo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )            
        else:
            QMessageBox.warning(self, "Project Data", "No image data found in project file.")

        # Restore slot names if available
        if "slot_names" in project_data:
            self.slot_names = project_data["slot_names"]

        # Restore MaskManager data
        if "masks" in project_data:
            self.mask_manager._masks = project_data["masks"]
            self.mask_manager.applied_mask_slot = project_data.get("applied_mask_slot")
            self.mask_manager.applied_mask = project_data.get("applied_mask")
        
        # Restore custom mask slot names
        if "mask_slot_names" in project_data:
            self.mask_slot_names = project_data["mask_slot_names"]

        # Restore additional settings, e.g., theme
        if "theme" in project_data:
            self.current_theme = project_data["theme"]

        # Emit a signal to update the UI for the current slot if needed
        self.image_manager.image_changed.emit(
            self.image_manager.current_slot,
            self.image_manager._images[self.image_manager.current_slot],
            self.image_manager._metadata[self.image_manager.current_slot]
        )

        # **Update the slot menu actions to reflect the new custom slot names**
        for slot, action in self.slot_actions.items():
            new_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")
        
        # (Optionally, update mask slot actions similarly if needed.)
        for slot, action in self.mask_slot_actions.items():
            new_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")        

        print("Project loaded successfully from:", fileName)

    def new_project(self):
        """
        Clears all current project data (images, masks, undo/redo stacks, etc.)
        after warning the user that this operation is destructive.
        """
        reply = QMessageBox.question(
            self,
            "New Project",
            "This will erase all data in current slots and undo/redo stacks. Are you sure you want to create a new project?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply != QMessageBox.StandardButton.Yes:
            print("New project canceled by user.")
            return

        # Clear ImageManager data
        self.image_manager._images = {i: None for i in range(self.image_manager.max_slots)}
        self.image_manager._metadata = {i: {} for i in range(self.image_manager.max_slots)}
        self.image_manager._undo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager._redo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager.current_slot = 0

        # Clear MaskManager data
        self.mask_manager._masks = {}
        self.mask_manager.applied_mask = None
        self.mask_manager.applied_mask_slot = None

        # Clear preview windows if any
        self.preview_windows = {}

        # Reset custom slot names to defaults
        self.slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}

        # Update UI elements for slot names (e.g., QToolButtons)
        for slot, action in self.slot_actions.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(default_name)
            action.setStatusTip(f"Open preview for {default_name}")

        # Update any open preview windows
        for slot, window in self.preview_windows.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            window.setWindowTitle(f"Preview - {default_name}")

        # Update UI elements that are managed outside of ImageManager
        # For instance, update file name label or other status indicators.
        # Here we call update_file_name with default parameters.
        self.update_file_name(0, None, {})

        # Clear all tabs that display images.
        self.clear_all_tabs()

        print("New project created: All image, mask, and undo/redo data have been cleared.")


    def clear_all_tabs(self):
        """
        Simulate a tab click by switching to a different tab and back.
        This forces the tab's update logic to clear the image.
        """
        if self.tabs.count() < 2:
            # Only one tab—try calling clear_image() if available.
            current_tab = self.tabs.currentWidget()
            if hasattr(current_tab, "clear_image"):
                current_tab.clear_image()
            return

        # Save the current index.
        current_index = self.tabs.currentIndex()
        # Choose a different tab index.
        new_index = 1 if current_index == 0 else 0
        # Switch to the new index.
        self.tabs.setCurrentIndex(new_index)
        # Immediately switch back.
        self.tabs.setCurrentIndex(current_index)
        print("Simulated tab click to clear image.")

    def open_histogram(self):
        # Check if a histogram dialog is already open; if so, bring it to front.
        if hasattr(self, 'hist_dialog') and self.hist_dialog is not None and self.hist_dialog.isVisible():
            self.hist_dialog.raise_()
            self.hist_dialog.activateWindow()
            return

        # Get the image from the active slot instead of slot 0.
        current_slot = self.image_manager.current_slot
        img = self.image_manager._images.get(current_slot, None)
        if img is None:
            QMessageBox.warning(self, "No Image", f"Slot {current_slot} does not contain an image.")
            return
        # If grayscale, replicate to 3 channels.
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)
        # Create the histogram dialog using the active slot's image.
        self.hist_dialog = HistogramDialog(self.image_manager, self)
        
        # Define a helper function to update the histogram when the active slot changes.
        def update_hist(slot, image, metadata):
            # Update only if the changed slot is the current active slot.
            if slot == self.image_manager.current_slot:
                if image is None:
                    return
                if image.ndim == 2:
                    image = np.stack([image]*3, axis=-1)
                self.hist_dialog.updateHistogram(image)
        
        # Connect the image_changed signal.
        self.image_manager.image_changed.connect(update_hist)
        
        self.hist_dialog.show()


    def rename_slot(self):
        """
        Prompts the user to select a slot and enter a new name (with no spaces).
        The new name is then applied to the slot and updates the UI.
        """
        # Ask the user which slot to rename (0 to max_slots-1)
        slot, ok = QInputDialog.getInt(
            self, "Rename Slot", "Enter slot number to rename:",
            0, 0, self.image_manager.max_slots - 1
        )
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", "Enter new name (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()

        QMessageBox.information(self, "Rename Successful", f"Slot {slot} renamed to {new_name}.")

    def rename_mask_slot(self):
        """
        Prompts the user to select a mask slot (0-4) and enter a new name (without spaces),
        then updates the mask slot name in the dictionary and the corresponding QAction.
        """
        # Ask for the mask slot number
        slot, ok = QInputDialog.getInt(self, "Rename Mask Slot", "Enter mask slot number (0-4):", 0, 0, 4)
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(self, "Rename Mask Slot", "Enter new name (no spaces):")
        if not ok or not new_name:
            return

        # Validate that the new name has no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom mask slot names dictionary
        self.mask_slot_names[slot] = new_name

        # Update the corresponding QAction text and tooltip
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # Optionally, if you keep track of open mask preview dialogs, update their titles as well.
        # For example, if you maintain a dictionary self.mask_preview_windows:
        # if slot in self.mask_preview_windows:
        #     self.mask_preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        QMessageBox.information(self, "Rename Mask Slot", f"Mask slot {slot} renamed to '{new_name}'.")


    def open_pixel_math_dialog(self):
        """Opens the Pixel Math dialog."""
        dialog = PixelMathDialog(self, self.image_manager)
        dialog.exec()  # Using exec() to open as a modal dialog

    def connect_mask_manager_signals(self):
        """
        Connect signals from MaskManager to update the banner dynamically.
        """
        self.mask_manager.applied_mask_changed.connect(self.update_mask_banner)

    def update_mask_banner(self, slot, mask):
        """
        Updates the mask banner to indicate whether a mask is applied,
        using the custom name for the mask slot if available.
        """
        if mask is not None:
            # Check if a custom name exists for this mask slot
            if hasattr(self, 'mask_slot_names'):
                custom_name = self.mask_slot_names.get(slot, f"Slot {slot}")
            else:
                custom_name = f"Slot {slot}"
            self.mask_banner.setText(f"Mask Applied: {custom_name}")
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(True)
        else:
            self.mask_banner.setText("Mask Applied: None")
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(False)


    def preview_mask_slot(self, slot):
        """
        Opens a preview window for the selected mask slot.
        """
        mask = self.mask_manager.get_mask(slot)
        
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask saved in slot {slot}.")
            return

        # Create the mask slot preview dialog
        preview_dialog = MaskSlotPreviewDialog(mask, slot, self)
        preview_dialog.show()


    def create_mask(self):
        """Open the Mask Creation dialog."""
        current_image = self.image_manager.image
        if current_image is None:
            QMessageBox.warning(self, "No Image", "No image available to create a mask.")
            return

        # Open the Mask Creation Dialog
        dialog = MaskCreationDialog(current_image, parent=self)
        dialog.exec()  # Execute the dialog as a modal window


    def apply_mask(self):
        """Prompt user for a mask slot and flag it in MaskManager for application."""
        # Check available mask slots
        available_slots = [slot for slot in range(self.mask_manager.max_slots) if self.mask_manager.get_mask(slot) is not None]

        if not available_slots:
            QMessageBox.warning(self, "No Masks Available", "There are no masks to apply.")
            return

        # Prompt user to select a mask slot
        slot, ok = QInputDialog.getItem(
            self,
            "Select Mask Slot",
            "Choose a mask slot to apply:",
            [f"Slot {s}" for s in available_slots],
            0,  # Default selection
            False  # Do not allow user input outside the options
        )

        if not ok:
            return  # User canceled

        # Extract selected slot number
        selected_slot = int(slot.split()[-1])

        # Flag the mask in MaskManager
        self.mask_manager.apply_mask_from_slot(selected_slot)

        # Update the UI banner to indicate an active mask
        self.update_mask_banner(selected_slot, self.mask_manager.get_applied_mask())

        print(f"Mask from Slot {selected_slot} flagged for application.")

    def apply_mask_from_slot(self, slot):
        """
        Applies the mask stored in the given mask slot.
        Updates the UI (e.g. mask banner) to reflect the applied mask.
        """
        mask = self.mask_manager.get_mask(slot)
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask is saved in slot {slot}.")
            return

        # Apply the mask from the specified slot.
        self.mask_manager.apply_mask_from_slot(slot)
        # Optionally, update any UI elements (for example, a banner) to show the applied mask.
        self.update_mask_banner(slot, self.mask_manager.get_applied_mask())
        print(f"Mask from Slot {slot} flagged for application.")


    def remove_mask(self):
        """Remove the active mask and update the UI."""
        # Check if a mask is currently applied
        if self.mask_manager.get_applied_mask() is None:
            QMessageBox.warning(self, "No Mask", "No mask is currently applied.")
            return

        # Clear the applied mask
        self.mask_manager.clear_applied_mask()


        # Update the UI banner to reflect no active mask
        self.update_mask_banner(-1, None)

        print("Mask removed successfully, banner updated.")


    def load_mask(self):
        """Load a mask from a file."""
        default_dir = self.settings.value("working_directory", "")
        # Open a file dialog to select the mask file
        filename, _ = QFileDialog.getOpenFileName(
            self, 
            "Load Mask", 
            default_dir, 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if not filename:
            return  # User canceled the dialog

        try:
            # Load the mask using the global load_image method
            loaded_image, _, _, _ = load_image(filename)  # Ensure load_image returns (image, header, bit_depth, is_mono)

            # Convert the loaded image to grayscale if it's not already
            if loaded_image.ndim == 3:
                # Assuming RGB; convert to grayscale using OpenCV
                mask = cv2.cvtColor(loaded_image, cv2.COLOR_RGB2GRAY)
            else:
                mask = loaded_image.copy()  # Already single-channel

            # Normalize the mask to [0, 1] if it's not already
            mask = mask.astype(np.float32)
            if mask.max() > 1.0:
                mask /= 255.0
            mask = np.clip(mask, 0.0, 1.0)

            # Prompt the user to select the mask slot
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot", 
                f"Enter mask slot number (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if ok:
                # Set the mask in the selected slot using MaskManager
                self.mask_manager.set_mask(slot_number, mask)
                QMessageBox.information(
                    self, 
                    "Mask Loaded", 
                    f"Mask loaded from {filename} into slot {slot_number}."
                )
                print(f"AstroEditingSuite: Mask loaded from {filename} into slot {slot_number}.")
            else:
                QMessageBox.information(self, "Load Mask", "Mask loading canceled.")
                print("AstroEditingSuite: Mask loading canceled by the user.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load mask:\n{e}")
            print(f"AstroEditingSuite: Failed to load mask: {e}")

    def save_mask(self):
        """Save the active mask to a file."""
        default_dir = self.settings.value("working_directory", "")
        try:
            # Prompt the user to select the mask slot to save
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot to Save", 
                f"Enter mask slot number to save (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if not ok:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Retrieve the mask from the selected slot using MaskManager
            mask = self.mask_manager.get_mask(slot_number)
            if mask is None:
                QMessageBox.warning(
                    self, 
                    "No Mask", 
                    f"No mask available in slot {slot_number} to save."
                )
                print(f"AstroEditingSuite: No mask available in slot {slot_number} to save.")
                return

            # Open a save file dialog to specify the destination file
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save Mask", 
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
            )
            if not filename:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Determine the file format based on the file extension
            file_format = os.path.splitext(filename)[1][1:].lower()  # Extract extension without dot

            # Set bit_depth based on file format
            # For PNG and JPEG, bit_depth is not required as they typically use 8-bit
            # For TIFF and FITS, we'll specify 8-bit
            if file_format in ['tif', 'tiff']:
                bit_depth = "8-bit"
            else:
                bit_depth = None  # Not required for formats like PNG

            # Convert mask to appropriate format for saving
            # Assuming mask is single-channel and normalized between 0 and 1
            mask_to_save = (mask * 255).astype(np.uint8)
            if mask_to_save.ndim == 2:
                # Convert to RGB if the save format expects multi-channel
                mask_to_save = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2RGB)

            # Save the mask using the global save_image method
            save_image(
                img_array=mask_to_save, 
                filename=filename, 
                original_format=file_format, 
                bit_depth=bit_depth, 
                original_header=None,  # Masks typically don't have headers
                is_mono=False,         # Masks are RGB after conversion
                image_meta=None,       # Optional metadata
                file_meta=None         # Optional file metadata
            )
            QMessageBox.information(
                self, 
                "Mask Saved", 
                f"Mask from slot {slot_number} saved to {filename}."
            )
            print(f"AstroEditingSuite: Mask from slot {slot_number} saved to {filename}.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save mask:\n{e}")
            print(f"AstroEditingSuite: Failed to save mask: {e}")

    def rescale_image(self):
        """
        Rescales the current image by a user-defined scaling factor using OpenCV.
        The image is expected to be stored as a 32-bit floating point numpy array.
        For example, a factor of 0.5 scales down the image to 50% of its original size,
        while 2 scales it up to 200%.
        """
        try:
            # Ensure that an image is loaded.
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rescaling.")
                return

            # Prompt the user for a scaling factor.
            factor, ok = QInputDialog.getDouble(
                self,
                "Rescale Image",
                "Enter scaling factor (e.g., 0.5 for 50%, 2 for 200%):",
                1.0,    # default value
                0.1,    # minimum value
                10.0,   # maximum value
                2       # number of decimals
            )
            if not ok:
                return

            # Retrieve a copy of the current image.
            current_image = self.image_manager.image.copy()

            # Determine new dimensions based on the scaling factor.
            # current_image.shape is assumed to be (height, width) for grayscale or (height, width, channels) for RGB.
            height, width = current_image.shape[:2]
            new_width = int(width * factor)
            new_height = int(height * factor)

            # Import cv2 and use cv2.resize with the LANCZOS4 interpolation method.
            resized_image = rescale_image_numba(current_image, factor)

            # Prepare metadata (append a description note about rescaling).
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + f" | Rescaled by factor {factor}"

            # Update the ImageManager with the rescaled image.
            self.image_manager.set_image(new_image=resized_image, metadata=metadata, step_name="Rescale Image")
            self.image_manager.image_changed.emit(
                self.image_manager.current_slot,
                resized_image,
                metadata
            )

            QMessageBox.information(
                self,
                "Image Rescaled",
                f"The image has been successfully rescaled by a factor of {factor}."
            )

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rescale image:\n{e}")
            print(f"Error in rescale_image: {e}")

            
    def flip_horizontal(self):
        """
        Flips the current image horizontally.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the horizontal flip using numpy
            flipped_image = flip_horizontal_numba(current_image)  # Flip horizontally

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Horizontally Flipped"


            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata, step_name="Flip Horizontal")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Flipped", "The image has been successfully flipped horizontally.")

            print(f"Image in Slot {self.image_manager.current_slot} flipped horizontally successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image horizontally:\n{e}")
            print(f"Error in flip_horizontal: {e}")

    def flip_vertical(self):
        """
        Flips the current image vertically.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the vertical flip using numpy
            flipped_image = flip_vertical_numba(current_image)  # Flip vertically

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Vertically Flipped"

            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata, step_name="Flip Vertically")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Flipped", "The image has been successfully flipped vertically.")

            print(f"Image in Slot {self.image_manager.current_slot} flipped vertically successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image vertically:\n{e}")
            print(f"Error in flip_vertical: {e}")

    def rotate_clockwise(self):
        """
        Rotates the current image 90 degrees clockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_clockwise_numba(current_image)  # Rotate clockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Clockwise"

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata, step_name="Rotate 90° Clockwise")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Rotated", "The image has been successfully rotated 90° clockwise.")

            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° clockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image clockwise:\n{e}")
            print(f"Error in rotate_clockwise: {e}")

    def rotate_counterclockwise(self):
        """
        Rotates the current image 90 degrees counterclockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_counterclockwise_numba(current_image)  # Rotate counterclockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Counterclockwise"

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata, step_name="Rotate Counterclockwise")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Rotated", "The image has been successfully rotated 90° counterclockwise.")

            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° counterclockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image counterclockwise:\n{e}")
            print(f"Error in rotate_counterclockwise: {e}")

    def invert_image(self):
        """
        Inverts the colors of the current image.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before inverting.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Check if the image is in a compatible format (e.g., float32 in [0,1])
            if current_image.dtype not in [np.float32, np.float64]:
                QMessageBox.warning(self, "Unsupported Format", "Image inversion supports floating point images.")
                return

            # Perform the inversion
            inverted_image = invert_image_numba(current_image)

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Inverted Image"

            # Update the ImageManager with the inverted image
            self.image_manager.set_image(new_image=inverted_image, metadata=metadata, step_name="Image Inversion")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, inverted_image, metadata)

            # Notify the user
            QMessageBox.information(self, "Image Inverted", "The image has been successfully inverted.")

            print(f"Image in Slot {self.image_manager.current_slot} inverted successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to invert image:\n{e}")
            print(f"Error in invert_image: {e}")

    def open_hdr_dialog(self):
        """Open the WaveScale HDR dialog."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before using WaveScale HDR.")
            return

        dialog = WaveScaleHDRDialog(self.image_manager, self)
        dialog.exec()


    def open_blemish_blaster(self):
        """Handler method to open the Blemish Blaster tool."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image Loaded", "Please load an image before using Blemish Blaster.")
            return

        # Initialize and show the Blemish Blaster dialog, passing the ImageManager
        self.blemish_dialog = BlemishBlasterDialog(self.image_manager, self)

        self.blemish_dialog.exec()


    def remove_gradient(self):
        """Handle the Remove Gradient action."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Initialize the GradientRemovalDialog with the current image
        gradient_dialog = GradientRemovalDialog(image=self.image_manager.image.copy(), parent=self)
        gradient_dialog.processing_completed.connect(self.handle_gradient_removal)
        gradient_dialog.exec()


    def handle_gradient_removal(self, corrected_image, gradient_background, save_to_slot_1, selected_slot):
        """
        Handle the processed image after gradient removal.

        Args:
            corrected_image (np.ndarray): The image after gradient removal.
            gradient_background (np.ndarray): The extracted gradient.
            save_to_slot_1 (bool): Whether the user wants to save the gradient background.
            selected_slot (str): The slot number selected (e.g., "Slot 1").
        """
        try:
            # Store the corrected image in the current slot
            current_slot = self.image_manager.current_slot
            metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            metadata['description'] = "Gradient removed"
            self.image_manager.set_image(new_image=corrected_image, metadata=metadata, step_name="Gradient Removal")

            # **Save gradient background only if requested**
            if save_to_slot_1:
                slot_number = int(selected_slot.split(" ")[1])  # Convert "Slot 1" -> 1

                metadata_slot = {
                    'file_path': f"Gradient Background ({selected_slot})",
                    'description': "Extracted Gradient Background",
                    'bit_depth': "32-bit floating point",
                    'is_mono': len(gradient_background.shape) < 3,
                    'gradient_background': gradient_background
                }

                # Save gradient background in the selected slot
                self.image_manager._images[slot_number] = gradient_background
                self.image_manager._metadata[slot_number] = metadata_slot

                print(f"[INFO] Gradient background stored in {selected_slot}.")

                # --- Update slot UI Labels ---
                if hasattr(self, 'slot_names'):
                    self.slot_names[slot_number] = f"Extracted Gradient ({selected_slot})"
                if hasattr(self, 'slot_actions') and slot_number in self.slot_actions:
                    self.slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")
                # --- Update Menubar Slot Name (FIX) ---
                if hasattr(self, 'menubar_slot_actions') and slot_number in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.menubar_slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")

                if hasattr(self, 'preview_windows') and slot_number in self.preview_windows:
                    self.preview_windows[slot_number].setWindowTitle(f"Preview - Extracted Gradient ({selected_slot})")

                self.menuBar().update()
                print(f"[INFO] Gradient removal completed and saved to {selected_slot}.")
            else:
                print("[INFO] User chose not to save the extracted gradient.")

            # Notify the user
            QMessageBox.information(self, "Success", "Gradient removal completed successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply gradient removal:\n{e}")
            print(f"Error in handle_gradient_removal: {e}")




    def check_for_updates(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/refs/heads/main/updates.json"

            # Fetch the JSON data
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()
            update_data = response.json()

            # Convert version strings to tuples for proper comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                msg_box.setDetailedText("\n".join([f"{k}: {v}" for k, v in downloads.items()]))

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    import webbrowser
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        webbrowser.open(downloads.get("Windows", ""))
                    elif platform.startswith("darwin"):
                        webbrowser.open(downloads.get("macOS", ""))
                    elif platform.startswith("linux"):
                        webbrowser.open(downloads.get("Linux", ""))
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
            else:
                QMessageBox.information(self, "No Updates", "You are already running the latest version.")

        except requests.RequestException as e:
            QMessageBox.critical(self, "Error", f"Failed to check for updates:\n{e}")


    def check_for_updatesstartup(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/main/updates.json"

            # Fetch the JSON data with a timeout to prevent hanging
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()  # Raise an exception for HTTP errors
            update_data = response.json()

            # Convert version strings to tuples for accurate comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            if not latest_version_str:
                print("Update check: 'version' key not found in update data.")
                return  # Exit silently

            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                detailed_text = "\n".join([f"{k}: {v}" for k, v in downloads.items()])
                msg_box.setDetailedText(detailed_text)

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    import webbrowser
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        download_link = downloads.get("Windows", "")
                    elif platform.startswith("darwin"):
                        download_link = downloads.get("macOS", "")
                    elif platform.startswith("linux"):
                        download_link = downloads.get("Linux", "")
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
                        download_link = ""

                    if download_link:
                        webbrowser.open(download_link)
                    else:
                        QMessageBox.warning(self, "Error", "Download link not available.")
                else:
                    # If the user declines the update, you might want to log it or simply do nothing.
                    pass
            else:
                # No update available; you might opt to notify the user at startup,
                # but typically it's best to remain silent.
                pass

        except requests.RequestException as e:
            # Log the error and optionally show a non-intrusive warning.
            print(f"Update check failed: {e}")
            msg_box = QMessageBox(self)
            msg_box.setIcon(QMessageBox.Icon.Warning)
            msg_box.setWindowTitle("Update Check Failed")
            msg_box.setText("Unable to check for updates at this time.")
            msg_box.setInformativeText("Please check your internet connection and try again later.")
            msg_box.setStandardButtons(QMessageBox.StandardButton.Ok)
            msg_box.exec()
        
    def version_str_to_tuple(self, version_str):
        """
        Convert a version string into a tuple of integers for comparison.
        Example: "1.10.2" -> (1, 10, 2)
        """
        return tuple(int(part) for part in version_str.split('.') if part.isdigit())

    def open_preferences_dialog(self):
        dialog = QDialog(self)
        dialog.setWindowTitle("Preferences")
        layout = QVBoxLayout(dialog)

        # Display stored settings using a form layout.
        settings_form = QFormLayout()

        # Define settings fields with appropriate selection methods.
        settings_fields = {
            "GraXpert Path": ("graxpert/path", self.settings.value("graxpert/path", "")),  # Needs FILE selection
            "StarNet Executable Path": ("starnet/exe_path", self.settings.value("starnet/exe_path", "")),  # FILE
            "ASTAP Executable Path": ("astap/exe_path", self.settings.value("astap/exe_path", "")),  # FILE
            "Cosmic Clarity Folder": ("cosmic_clarity_folder", self.settings.value("cosmic_clarity_folder", "")),  # FOLDER
            "Working Directory": ("working_directory", self.settings.value("working_directory", ""))  # FOLDER
        }

        # Create input fields dynamically with file/folder selection buttons.
        input_fields = {}
        for label, (key, value) in settings_fields.items():
            field_widget = QWidget()
            field_layout = QHBoxLayout(field_widget)
            field_layout.setContentsMargins(0, 0, 0, 0)

            # Create the QLineEdit with the stored value.
            field = QLineEdit(str(value))
            input_fields[key] = field
            field_layout.addWidget(field)

            # Create selection button.
            select_button = QPushButton("...")
            select_button.setFixedWidth(30)

            # **Use file selection for executable paths, folder selection for directories**
            if label in ["GraXpert Path", "StarNet Executable Path", "ASTAP Executable Path"]:
                select_button.setToolTip(f"Select file for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_file(f))
            else:
                select_button.setToolTip(f"Select folder for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_folder(f))

            field_layout.addWidget(select_button)
            settings_form.addRow(label, field_widget)

        # Additional settings fields (without selection buttons).
        additional_fields = {
            "Astrometry API Key": ("astrometry_api_key", self.settings.value("astrometry_api_key", "")),
            "Latitude": ("latitude", self.settings.value("latitude", "")),
            "Longitude": ("longitude", self.settings.value("longitude", "")),
            "Date": ("date", self.settings.value("date", "")),
            "Time": ("time", self.settings.value("time", "")),
            "Timezone": ("timezone", self.settings.value("timezone", "")),
            "Minimum Altitude": ("min_altitude", self.settings.value("min_altitude", ""))
        }

        for label, (key, value) in additional_fields.items():
            field = QLineEdit(str(value))
            settings_form.addRow(label, field)
            input_fields[key] = field

        layout.addLayout(settings_form)

        # **Add Save, Reset, and Cancel buttons**
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Save |
                                QDialogButtonBox.StandardButton.Reset |
                                QDialogButtonBox.StandardButton.Cancel)

        # Save button: Save preferences
        buttons.accepted.connect(lambda: self.save_preferences(input_fields, dialog))

        # Reset button: Clear preferences
        buttons.button(QDialogButtonBox.StandardButton.Reset).clicked.connect(lambda: self.clear_preferences(input_fields))

        # Cancel button: Close the dialog
        buttons.rejected.connect(dialog.reject)

        layout.addWidget(buttons)
        dialog.exec()

    def select_file(self, field):
        """Open file selection dialog for executable files."""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select Executable File",
            "",
            "Executables (*.exe *.AppImage *.sh *.bin *.run);;All Files (*)"
        )
        if file_path:
            field.setText(file_path)

    def select_folder(self, field):
        """Open folder selection dialog."""
        folder_path = QFileDialog.getExistingDirectory(self, "Select Folder")
        if folder_path:
            field.setText(folder_path)

    def save_preferences(self, input_fields, dialog):
        for key, field in input_fields.items():
            self.settings.setValue(key, field.text())
        dialog.accept()
        QMessageBox.information(self, "Preferences Saved", "Settings have been updated successfully.")

    def clear_preferences(self, input_fields):
        reply = QMessageBox.question(self, "Clear Preferences", "Are you sure you want to clear all preferences?", QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
        if reply == QMessageBox.StandardButton.Yes:
            for key in input_fields.keys():
                self.settings.remove(key)
                input_fields[key].clear()
            QMessageBox.information(self, "Preferences Cleared", "All settings have been reset.")


    def open_crop_tool(self):
        """Open the crop tool to crop the current image."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before cropping.")
            return

        # Open the Crop Tool with correct parameters
        crop_tool = CropTool(self.image_manager, self.image_manager.image, self)
        crop_tool.crop_applied.connect(self.apply_cropped_image)
        crop_tool.exec()

    def apply_cropped_image(self, cropped_image):
        """Apply the cropped image to the current slot."""
        current_slot = self.image_manager.current_slot
        metadata = self.image_manager._metadata.get(current_slot, {}).copy()
        metadata['file_path'] = "Cropped Image"

        # Use the proper undo-enabled, step-name-aware method
        self.image_manager.set_image_with_step_name(
            cropped_image,
            metadata,
            step_name="Crop"
        )

        QMessageBox.information(self, "Success", "Cropped image applied.")



    def rgb_combination(self):
        """Handle the RGB Combination action."""
        dialog = RGBCombinationDialog(self, image_manager=self.image_manager)
        if dialog.exec() == QDialog.DialogCode.Accepted:
            # The RGBCombinationDialog calls image_manager.set_image() to store the image in the active slot.
            active_slot = self.image_manager.current_slot
            slot_name = self.image_manager.get_slot_name(active_slot)
            print(f"RGB image stored in {slot_name}.")
            QMessageBox.information(self, "Success", f"RGB image combined and stored in {slot_name}.")
        else:
            print("RGB Combination cancelled by the user.")

    def rgb_extract(self):
        """Handle the RGB Extract action."""
        # 1. Determine which slot to extract from — use the current slot
        slot_to_extract = self.image_manager.current_slot
        image = self.image_manager._images.get(slot_to_extract, None)

        if image is None:
            QMessageBox.warning(self, "No Image", 
                f"Slot {slot_to_extract} does not contain an image to extract from.")
            print(f"Slot {slot_to_extract} is empty. Cannot perform RGB Extract.")
            return

        if image.ndim != 3 or image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", 
                "The selected image is not a valid 3-channel RGB image.")
            print("Invalid image format for RGB Extract. Expected a 3-channel RGB image.")
            return

        # 2. Helper to find the next free slot
        def find_next_free_slot(start=0):
            for s in range(start, self.image_manager.max_slots):
                if self.image_manager._images[s] is None:
                    return s
            return -1

        # 3. Check if we have enough free slots for R, G, B
        r_slot = find_next_free_slot(0)
        if r_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Red channel.")
            return

        g_slot = find_next_free_slot(r_slot + 1)  # or start=0 if you want them anywhere
        if g_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Green channel.")
            return

        b_slot = find_next_free_slot(g_slot + 1)
        if b_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Blue channel.")
            return

        try:
            # 4. Split the RGB channels
            r_channel = image[..., 0].copy()
            g_channel = image[..., 1].copy()
            b_channel = image[..., 2].copy()

            # 5. Define metadata for each channel
            metadata_r = {
                'file_path': f"RGB Extract - Red Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_g = {
                'file_path': f"RGB Extract - Green Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_b = {
                'file_path': f"RGB Extract - Blue Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }

            # 6. Store each channel in the free slots found
            self.image_manager._images[r_slot] = r_channel
            self.image_manager._metadata[r_slot] = metadata_r

            self.image_manager._images[g_slot] = g_channel
            self.image_manager._metadata[g_slot] = metadata_g

            self.image_manager._images[b_slot] = b_channel
            self.image_manager._metadata[b_slot] = metadata_b

            # 7. Update your local slot_names / slot_actions, etc.
            #    (Make sure these exist or adapt for your code.)
            #    For example:
            self.slot_names[r_slot] = "Red"
            self.slot_names[g_slot] = "Green"
            self.slot_names[b_slot] = "Blue"

            for slot_id, name in zip([r_slot, g_slot, b_slot], ["Red", "Green", "Blue"]):
                if slot_id in self.slot_actions:
                    self.slot_actions[slot_id].setText(name)
                    self.slot_actions[slot_id].setStatusTip(f"Open preview for {name}")

                if slot_id in self.preview_windows:
                    self.preview_windows[slot_id].setWindowTitle(f"Preview - {name}")

                # Menubar slot names, if used:
                if hasattr(self, 'menubar_slot_actions') and slot_id in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot_id].setText(name)
                    self.menubar_slot_actions[slot_id].setStatusTip(f"Open preview for {name}")

            self.menuBar().update()

            print(f"Extracted R, G, B channels from Slot {slot_to_extract} "
                f"and stored in Slots {r_slot}, {g_slot}, {b_slot} as Red, Green, Blue.")

            QMessageBox.information(
                self, "Success",
                f"RGB channels extracted and stored in slots {r_slot} (Red), {g_slot} (Green), {b_slot} (Blue)."
            )

            # 8. Optionally open preview windows
            self.open_preview_window(slot=r_slot)
            self.open_preview_window(slot=g_slot)
            self.open_preview_window(slot=b_slot)

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to extract RGB channels: {e}")
            print(f"Error during RGB Extract: {e}")

    def extract_luminance(self):
        # Rec.709 linear luma weights
        _LUMA_WEIGHTS = np.array([0.2126, 0.7152, 0.0722], dtype=np.float32)
        """Extracts linear Y' luminance from the active RGB image and stores it in a user-selected slot."""
        # 1) Source checks
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before extracting luminance.")
            return
        current_image = self.image_manager.image
        if current_image.ndim != 3 or current_image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", "Luminance extraction requires an RGB image.")
            return

        # 2) Clip to [0,1] (you said you’re already 0–1, but just in case)
        img = np.clip(current_image, 0.0, 1.0).astype(np.float32)

        # 3) Compute Y' = 0.2126 R + 0.7152 G + 0.0722 B
        luminance = img[..., 0]*_LUMA_WEIGHTS[0] + \
                    img[..., 1]*_LUMA_WEIGHTS[1] + \
                    img[..., 2]*_LUMA_WEIGHTS[2]

        # 4) Build slot list & names
        max_slots = getattr(self.image_manager, "max_slots", 10)
        slots = list(range(max_slots))
        if hasattr(self, "slot_names"):
            display_names = [self.slot_names.get(i, f"Slot {i+1}") for i in slots]
        else:
            display_names = [f"Slot {i+1}" for i in slots]

        # 5) Ask user which slot to store luminance
        item, ok = QInputDialog.getItem(
            self, "Select Target Slot",
            "Select the slot to store the luminance image:",
            display_names, editable=False
        )
        if not ok:
            QMessageBox.information(self, "Operation Cancelled", "Luminance extraction was cancelled.")
            return
        target_slot = display_names.index(item)

        # 6) Store luminance
        luminance_metadata = {
            'file_path': "Luminance Extracted",
            'is_mono': True,
            'bit_depth': "32-bit floating point",
        }
        self.image_manager._images[target_slot]   = luminance
        self.image_manager._metadata[target_slot] = luminance_metadata
        print(f"Luminance image updated in slot {target_slot}.")
        self.image_manager.image_changed.emit(target_slot, luminance, luminance_metadata)

        # 7) Update UI names/actions
        if hasattr(self, "slot_names"):
            self.slot_names[target_slot] = "Luminance"
        if hasattr(self, 'slot_actions') and target_slot in self.slot_actions:
            self.slot_actions[target_slot].setText("Luminance")
            self.slot_actions[target_slot].setStatusTip("Open preview for Luminance")
        if hasattr(self, 'menubar_slot_actions') and target_slot in self.menubar_slot_actions:
            self.menubar_slot_actions[target_slot].setText("Luminance")
            self.menubar_slot_actions[target_slot].setStatusTip("Open preview for Luminance")
        self.menuBar().update()

        # 8) Open preview
        self.open_preview_window(slot=target_slot)


    def recombine_luminance(self):
        # Rec.709 linear luma weights
        _LUMA_WEIGHTS = np.array([0.2126, 0.7152, 0.0722], dtype=np.float32)
        """Recombines linear Y' luminance with an RGB image by preserving chroma ratios."""
        # 1) Select slots
        max_slots = getattr(self.image_manager, "max_slots", 10)
        available_slots = list(range(max_slots))
        dialog = RecombineDialog(available_slots, self)
        if dialog.exec() != QDialog.DialogCode.Accepted:
            QMessageBox.information(self, "Operation Cancelled", "Recombination operation was cancelled.")
            return
        luminance_slot, rgb_slot = dialog.getSelections()

        # 2) Retrieve data
        Y = self.image_manager._images[luminance_slot]
        RGB = self.image_manager._images[rgb_slot]

        # 3) Validate inputs
        if RGB is None or RGB.ndim != 3 or RGB.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image",
                                f"Slot {rgb_slot} must contain an RGB image for recombination.")
            return
        if Y is None or Y.ndim < 2:
            QMessageBox.warning(self, "Invalid Luminance Image",
                                f"Slot {luminance_slot} must contain a 2D luminance image.")
            return
        # if 3-channel luminance, take first channel
        if Y.ndim == 3 and Y.shape[2] > 1:
            QMessageBox.information(
                self, "Multiple Channels Detected",
                f"Luminance image in slot {luminance_slot} has multiple channels. Only the first channel will be used."
            )
            Y = Y[..., 0]

        # 4) Prepare arrays
        Y = np.clip(Y, 0.0, 1.0).astype(np.float32)
        rgb = np.clip(RGB, 0.0, 1.0).astype(np.float32)

        # 5) Compute original luma for chroma ratios
        orig_Y = rgb[...,0]*_LUMA_WEIGHTS[0] + \
                rgb[...,1]*_LUMA_WEIGHTS[1] + \
                rgb[...,2]*_LUMA_WEIGHTS[2]
        eps = 1e-6
        chroma = rgb / (orig_Y[..., None] + eps)

        # 6) Rebuild RGB = chroma × new Y'
        new_rgb = chroma * Y[..., None]
        new_rgb = np.clip(new_rgb, 0.0, 1.0)

        # 7) Push back into manager
        metadata = self.image_manager._metadata[rgb_slot].copy()
        metadata['file_path'] = f"Luminance Recombined (Lum Slot: {luminance_slot}, RGB Slot: {rgb_slot})"
        self.image_manager.set_image(new_rgb, metadata, step_name="Recombine Luminance")
        print(f"Recombined image updated in slot {rgb_slot} with luminance from slot {luminance_slot}.")

    def remove_gradient_with_graxpert(self):
        """Integrate GraXpert for gradient removal."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Prompt user for smoothing value
        smoothing, ok = QInputDialog.getDouble(
            self,
            "GraXpert Smoothing Amount",
            "Enter smoothing amount (0.0 to 1.0):",
            decimals=2,
            min=0.0,
            max=1.0,
            value=0.1
        )
        if not ok:
            return  # User cancelled

        # Save the current image as a TIFF file
        input_basename = "input_image"
        input_path = os.path.join(os.getcwd(), f"{input_basename}.tif")
        save_image(self.image_manager.image, input_path, "tiff", "16-bit", None, is_mono=False)

        # Output will have the same base name with `_GraXpert` suffix
        output_basename = f"{input_basename}_GraXpert"
        output_directory = os.getcwd()

        # Determine the platform-specific GraXpert command
        current_os = platform.system()
        if current_os == "Windows":
            graxpert_cmd = "GraXpert.exe"
        elif current_os == "Darwin":  # macOS
            graxpert_cmd = "/Applications/GraXpert.app/Contents/MacOS/GraXpert"
        elif current_os == "Linux":
            graxpert_cmd = self.get_graxpert_path()
            if not graxpert_cmd:
                return  # User cancelled
        else:
            QMessageBox.critical(self, "Unsupported OS", f"Unsupported operating system: {current_os}")
            return

        # Build the command
        command = [
            graxpert_cmd,
            "-cmd", "background-extraction",
            input_path,
            "-cli",
            "-smoothing", str(smoothing),
            "-gpu", "true"
        ]

        # Run the command
        self.run_graxpert_command(command, output_basename, output_directory)

    def get_graxpert_path(self):
        """Prompt user to select the GraXpert path on Linux and save it."""
        graxpert_path = self.settings.value("graxpert/path", type=str)

        if not graxpert_path or not os.path.exists(graxpert_path):
            QMessageBox.information(self, "GraXpert Path", "Please select the GraXpert executable.")

            graxpert_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select GraXpert Executable",
                "",
                "Executable Files (*)"

            )
            if not graxpert_path:
                QMessageBox.warning(self, "Cancelled", "GraXpert path selection was cancelled.")
                return None  # User cancelled
            if not os.access(graxpert_path, os.X_OK):
                try:
                    os.chmod(graxpert_path, 0o755)  # Add execute permissions
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                    return None

            # Save the path for future use
            self.settings.setValue("graxpert/path", graxpert_path)

        return graxpert_path



    def run_graxpert_command(self, command, output_basename, output_directory):
        """Execute GraXpert asynchronously."""
        dialog = QDialog(self)
        dialog.setWindowTitle("GraXpert Progress")
        dialog.setMinimumSize(600, 400)
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        layout.addWidget(text_edit)
        cancel_button = QPushButton("Cancel")
        layout.addWidget(cancel_button)

        thread = GraXpertThread(command)
        thread.stdout_signal.connect(text_edit.append)
        thread.stderr_signal.connect(text_edit.append)
        thread.finished_signal.connect(lambda code: self.on_graxpert_finished(code, output_basename, output_directory, dialog))
        cancel_button.clicked.connect(thread.terminate)

        thread.start()
        dialog.exec()

    def on_graxpert_finished(self, return_code, output_basename, output_directory, dialog):
        """Handle GraXpert process completion."""
        dialog.close()
        if return_code != 0:
            QMessageBox.critical(self, "Error", "GraXpert process failed.")
            return

        # Locate the output file with any extension
        output_file = None
        for ext in ["fits", "tif", "tiff", "png"]:
            candidate = os.path.join(output_directory, f"{output_basename}.{ext}")
            if os.path.exists(candidate):
                output_file = candidate
                break

        if not output_file:
            QMessageBox.critical(self, "Error", "GraXpert output file not found.")
            return

        # Load the processed image back
        processed_image, _, _, _ = load_image(output_file)

        # Check the number of dimensions to determine if the image is mono
        if processed_image.ndim == 2:
            print("GraXpert output is a mono image. Converting to RGB...")
            processed_image = np.stack([processed_image] * 3, axis=-1)

        # Set the processed image in the image manager
        self.image_manager.set_image(
            processed_image,
            {'file_path': output_file, 'description': "GraXpert Gradient Removed"}, step_name="GraXpert Gradient Removal"
        )

        QMessageBox.information(self, "Success", "Gradient removed successfully.")


    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)


    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def swap_slots(self, slot_a, slot_b):
        """
        Swap images and metadata between two slots.
        
        :param slot_a: The first slot number.
        :param slot_b: The second slot number.
        """
        try:
            # Retrieve images and metadata from both slots
            image_a = self.image_manager._images.get(slot_a, None)
            metadata_a = self.image_manager._metadata.get(slot_a, {}).copy()
            
            image_b = self.image_manager._images.get(slot_b, None)
            metadata_b = self.image_manager._metadata.get(slot_b, {}).copy()
            
            # Swap the images and metadata
            self.image_manager._images[slot_a] = image_b
            self.image_manager._metadata[slot_a] = metadata_b
            
            self.image_manager._images[slot_b] = image_a
            self.image_manager._metadata[slot_b] = metadata_a
            
            # Emit image_changed signals for both slots
            self.image_manager.image_changed.emit(slot_a, image_b, metadata_b)
            self.image_manager.image_changed.emit(slot_b, image_a, metadata_a)
            
            print(f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            QMessageBox.information(self, "Success", f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to swap images between Slot {slot_a} and Slot {slot_b}: {e}")
            print(f"Error during swapping slots {slot_a} and {slot_b}: {e}")

    def copy_slot_to_target(self):
        """Copy from any source slot (Image or Mask) to any target slot (Image or Mask)."""
        # Open the enhanced CopySlotDialog
        dialog = CopySlotDialog(self, self.image_manager, self.mask_manager)
        result = dialog.exec()
        
        if result == QDialog.DialogCode.Accepted:
            # Retrieve selected source and target
            source_type, source_slot_num = dialog.get_selected_source()
            target_type, target_slot_num = dialog.get_selected_target()
            
            print(f"User selected to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            # Validate that source and target are not the same
            if source_type == target_type and source_slot_num == target_slot_num:
                QMessageBox.warning(self, "Invalid Operation", "Source and target slots are the same.")
                print("Source and target slots are identical. Operation aborted.")
                return
            
            # Retrieve source data
            try:
                if source_type == "Image":
                    source_image = self.image_manager._images.get(source_slot_num, None)
                    source_metadata = self.image_manager._metadata.get(source_slot_num, {}).copy()
                    if source_image is None:
                        QMessageBox.warning(self, "No Image", f"No image found in Image Slot {source_slot_num}.")
                        print(f"No image found in Image Slot {source_slot_num}.")
                        return
                elif source_type == "Mask":
                    source_image = self.mask_manager.get_mask(source_slot_num)
                    if source_image is None:
                        QMessageBox.warning(self, "No Mask", f"No mask found in Mask Slot {source_slot_num}.")
                        print(f"No mask found in Mask Slot {source_slot_num}.")
                        return
                    # Convert mask to grayscale if it's multi-channel
                    if source_image.ndim == 3:
                        source_image = cv2.cvtColor(source_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted multi-channel Mask Slot {source_slot_num} to grayscale.")
                    # Normalize mask to [0,1] if necessary
                    if source_image.max() > 1.0:
                        source_image = source_image.astype(np.float32) / 255.0
                        print(f"Normalized Mask Slot {source_slot_num} to [0,1].")
                    else:
                        source_image = source_image.astype(np.float32)
                        print(f"Mask Slot {source_slot_num} is already normalized.")
                    source_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Source Type", "Selected source type is invalid.")
                    print("Selected source type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve source data:\n{e}")
                print(f"Failed to retrieve source data: {e}")
                return
            
            # Retrieve target data
            try:
                if target_type == "Image":
                    target_image = self.image_manager._images.get(target_slot_num, None)
                    target_metadata = self.image_manager._metadata.get(target_slot_num, {}).copy()
                elif target_type == "Mask":
                    target_image = self.mask_manager.get_mask(target_slot_num)
                    target_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Target Type", "Selected target type is invalid.")
                    print("Selected target type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve target data:\n{e}")
                print(f"Failed to retrieve target data: {e}")
                return
            
            # Check if target slot is occupied
            try:
                if target_type == "Image":
                    is_occupied = self.image_manager._images.get(target_slot_num, None) is not None
                elif target_type == "Mask":
                    is_occupied = self.mask_manager.get_mask(target_slot_num) is not None
                else:
                    is_occupied = False
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to check target slot:\n{e}")
                print(f"Failed to check target slot: {e}")
                return
            
            if is_occupied:
                overwrite = QMessageBox.question(
                    self,
                    "Overwrite Confirmation",
                    f"{target_type} Slot {target_slot_num} already contains data. Do you want to overwrite it?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                    QMessageBox.StandardButton.No
                )
                if overwrite != QMessageBox.StandardButton.Yes:
                    QMessageBox.information(self, "Operation Cancelled", "Copy operation cancelled.")
                    print("User chose not to overwrite the target slot.")
                    return
            
            # Proceed with the copy operation
            try:
                # Save current state of the target slot to undo stack (only for images)
                if is_occupied:
                    if target_type == "Image":
                        self.image_manager._undo_stacks[target_slot_num].append(
                            (self.image_manager._images[target_slot_num].copy(),
                            self.image_manager._metadata[target_slot_num].copy())
                        )
                        print(f"Image Slot {target_slot_num} state saved to undo stack.")
                    # For masks, skip saving to an undo stack.

            
            
                # Deep copy to prevent unintended modifications
                copied_image = source_image.copy()
                copied_metadata = source_metadata.copy()
            
                # If copying from a mask to an image slot, ensure grayscale and normalization
                if source_type == "Mask" and target_type == "Image":
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied mask to single-channel grayscale for Image Slot {target_slot_num}.")
                    # Ensure normalization to [0,1]
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied mask to [0,1] for Image Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied mask is already normalized for Image Slot {target_slot_num}.")
            
                # Assign to target slot
                if target_type == "Image":
                    # Ensure image is float32 normalized to [0,1]
                    if copied_image.dtype != np.float32 and copied_image.dtype != np.float64:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Converted copied image to float32 normalized [0,1] for Image Slot {target_slot_num}.")
                    self.image_manager._images[target_slot_num] = copied_image
                    self.image_manager._metadata[target_slot_num] = copied_metadata
                    # Emit image_changed signal
                    self.image_manager.image_changed.emit(target_slot_num, copied_image, copied_metadata)
                    print(f"Copied data assigned to Image Slot {target_slot_num}.")
                    self.update_slot_toolbar_highlight()
                elif target_type == "Mask":
                    # Ensure mask is single-channel and normalized
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied image to single-channel grayscale for Mask Slot {target_slot_num}.")
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied image to [0,1] for Mask Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied image is already normalized for Mask Slot {target_slot_num}.")
                    self.mask_manager.set_mask(target_slot_num, copied_image)
                    # Emit mask_changed signal if available
                    # Assuming MaskManager has a signal similar to image_changed
                    # self.mask_manager.mask_changed.emit(target_slot_num, copied_image)
                    print(f"Copied data assigned to Mask Slot {target_slot_num}.")
            
                QMessageBox.information(
                    self, 
                    "Copy Successful", 
                    f"{source_type} Slot {source_slot_num} successfully copied to {target_type} Slot {target_slot_num}."
                )
                print(f"Copy successful: {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            except Exception as e:
                QMessageBox.critical(
                    self, 
                    "Copy Failed", 
                    f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.\nError: {e}"
                )
                print(f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}. Error: {e}")
        else:
            print("Copy Slot operation cancelled by the user.")

    # --------------------
    # Slot Preview Methods
    # --------------------
    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified slot."""
        print(f"Attempting to open preview window for Slot {slot}. Current preview_windows: {self.preview_windows}")
        # Check if the slot index is valid
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        # Check if the slot has an image
        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview window for this slot already exists
        if slot in self.preview_windows:
            # If the window is already open, bring it to the front
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            print(f"Preview window for Slot {slot} is already open.")
            return

        # Create a new ImagePreview window with a copy of the image data
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)  # Pass parent=self


        # Store the reference to prevent garbage collection
        self.preview_windows[slot] = preview
        print(f"Stored preview window for Slot {slot} in preview_windows.")

        # Connect the custom closed signal to the on_preview_closed method
        preview.closed.connect(self.on_preview_closed)

        # Show the preview window
        preview.show()
        print(f"Opened preview window for Slot {slot}.")

    def on_preview_closed(self, slot):
        """Handles the cleanup when a preview window is closed."""
        if slot in self.preview_windows:
            del self.preview_windows[slot]
            print(f"Preview window for Slot {slot} has been closed and removed from tracking.")
        else:
            print(f"No preview window found for Slot {slot} to remove.")

    def on_image_changed(self, slot, image, metadata):
        """Update the file name in the status bar and refresh preview if open."""
        file_path = metadata.get('file_path', None)
        if file_path:
            self.file_name_label.setText(os.path.basename(file_path))  # Update the label with file name
            self.update_slot_toolbar_highlight()
        else:
            self.file_name_label.setText("No file selected")

        # If a preview window for this slot is open, update its image
        if slot in self.preview_windows:
            preview_window = self.preview_windows[slot]
            preview_window.update_image_data(image.copy())
            self.update_slot_toolbar_highlight()
            print(f"Preview window for Slot {slot} updated with new image.")

     

    def add_stars(self):
        """
        Opens the AddStarsDialog to configure and preview star additions.
        """
        try:
            print("Opening AddStarsDialog...")
            add_stars_dialog = AddStarsDialog(self.image_manager, parent=self)
            add_stars_dialog.stars_added.connect(self.receive_blended_image)
            add_stars_dialog.exec()  # Modal dialog
            print("AddStarsDialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to open AddStarsDialog:\n{e}")
            print(f"Failed to open AddStarsDialog: {e}")

    def receive_blended_image(self, blended_image):
        """
        Receives the blended image from AddStarsDialog and updates the current slot.
        """
        if blended_image is not None:
            current_slot = self.image_manager.current_slot

            # Prepare metadata
            current_metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            addition_note = "Stars added using AddStarsDialog."
            if 'notes' in current_metadata and isinstance(current_metadata['notes'], list):
                current_metadata['notes'].append(addition_note)
            else:
                current_metadata['notes'] = [addition_note]

            # Assign the blended image and metadata to the current slot
            self.image_manager.set_image(blended_image, current_metadata, step_name="Star Addition")

            # Emit the image_changed signal with all required arguments
            self.image_manager.image_changed.emit(current_slot, blended_image, current_metadata)

            QMessageBox.information(self, "Success", "Stars added successfully.")
            print("Stars added successfully.")


    def remove_stars(self):
        """
        Prompts the user to select a star removal tool and then removes stars from the current image
        using either StarNet or CosmicClarityDarkStar and generates a stars-only image.
        Supports Windows, macOS, and Linux platforms.
        """
        # Prompt the user to select which tool to use.
        tool, ok = QInputDialog.getItem(
            self,
            "Select Star Removal Tool",
            "Choose a tool:",
            ["StarNet", "CosmicClarityDarkStar"],
            0,
            False
        )
        if not ok:
            print("User cancelled star removal tool selection.")
            return

        if tool == "CosmicClarityDarkStar":
            self.remove_stars_darkstar()
            return

        # --- StarNet branch (existing code) ---
        self.starnet_exe_path = self.settings.value("starnet/exe_path", "")

        print("Starting star removal process using StarNet...")

        # Step 1: Verify StarNet Executable Path
        if not self.starnet_exe_path:
            print("StarNet executable path not set. Prompting user to select executable.")
            self.select_starnet_exe()
            if not self.starnet_exe_path:
                print("User cancelled StarNet executable selection.")
                return  # User cancelled the selection
            else:
                print(f"StarNet executable selected: {self.starnet_exe_path}")
        else:
            print(f"Using existing StarNet executable path: {self.starnet_exe_path}")

        # Step 1.5: Check if the executable exists
        if not os.path.exists(self.starnet_exe_path):
            QMessageBox.critical(self, "StarNet Not Found",
                                f"StarNet executable not found at {self.starnet_exe_path}. Aborting star removal process.")
            print(f"StarNet executable not found: {self.starnet_exe_path}")
            return

        # Step 2: Ensure current image is loaded
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing stars.")
            print("No image loaded. Exiting star removal process.")
            return

        print("Image is loaded. Proceeding with star removal.")

        # Step 3: Determine the Operating System
        current_os = platform.system()
        print(f"Operating System detected: {current_os}")
        if current_os not in ["Windows", "Darwin", "Linux"]:
            QMessageBox.critical(self, "Unsupported OS",
                                f"The current operating system '{current_os}' is not supported.")
            print(f"Unsupported operating system: {current_os}")
            return

        # Step 4: Ask if the image is linear
        reply = QMessageBox.question(
            self,
            "Image Linearity",
            "Is the current image linear?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        
        if self.image_manager.image.ndim == 2 or (self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 1):
            print("Converting single-channel image to 3-channel RGB...")
            processing_image = np.stack([self.image_manager.image] * 3, axis=-1)
        else:
            processing_image = self.image_manager.image

        if reply == QMessageBox.StandardButton.Yes:
            print("Image is linear. Applying stretch.")

            # Apply stretch
            stretched_image = self.stretch_image(processing_image)
            processing_image = stretched_image
            print("Image stretched successfully.")
            self.image_was_stretched = True
        else:
            print("Image is not linear. Proceeding without stretching.")
            self.image_was_stretched = False

        # Step 4: Set Command Parameters Based on OS
        self.starnet_dir = os.path.dirname(self.starnet_exe_path)
        self.input_image_path = os.path.join(self.starnet_dir, "imagetoremovestars.tif")
        self.output_image_path = os.path.join(self.starnet_dir, "starless.tif")
        original_image = processing_image

        print(f"StarNet directory: {self.starnet_dir}")
        print(f"Input image path: {self.input_image_path}")
        print(f"Output image path: {self.output_image_path}")

        # Convert image from [0,1] to [0, 65535] for 16-bit TIFF
        image_16bit = (original_image * 65535).astype(np.uint16)
        image_bgr_16bit = cv2.cvtColor(image_16bit, cv2.COLOR_RGB2BGR)
        cv2.imwrite(self.input_image_path, image_bgr_16bit)
        print(f"Input image saved at {self.input_image_path}")

        # Prepare the command based on the OS
        if current_os == "Windows":
            chunk_size = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(chunk_size)
            ]
            print("Preparing command for Windows.")
        elif current_os == "Linux":
            chunk_size = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(chunk_size)
            ]
            print("Preparing command for Linux.")
        elif current_os == "Darwin":
            executable_name = os.path.basename(self.starnet_exe_path).lower()
            if "starnet2" in executable_name:
                command = [
                    self.starnet_exe_path,
                    "--input", self.input_image_path,
                    "--output", self.output_image_path
                ]
                print("Preparing command for macOS using StarNet2 arguments.")
            else:
                command = [
                    self.starnet_exe_path,
                    self.input_image_path,
                    self.output_image_path
                ]
                print("Preparing command for macOS using StarNet++ arguments.")

        print(f"StarNet command: {' '.join(command)}")

        # Step 5: Ensure the StarNet Executable has Execute Permissions (for macOS and Linux)
        if current_os in ["Darwin", "Linux"]:
            if not os.access(self.starnet_exe_path, os.X_OK):
                print(f"StarNet executable not executable. Setting execute permissions for {self.starnet_exe_path}")
                try:
                    os.chmod(self.starnet_exe_path, 0o755)
                    print("Execute permissions set.")
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error",
                                        f"Failed to set execute permissions for StarNet executable: {e}")
                    print(f"Failed to set execute permissions for {self.starnet_exe_path}: {e}")
                    return
            else:
                print("StarNet executable already has execute permissions.")
        else:
            print("No need to set execute permissions for Windows.")

        # Step 6: Initialize and Show StarNetDialog
        starnet_dialog = StarNetDialog()
        starnet_dialog.show()

        # Step 7: Initialize StarNetThread
        self.starnet_thread = StarNetThread(command, self.starnet_dir)
        self.starnet_thread.stdout_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.stderr_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.finished_signal.connect(lambda return_code: self.on_starnet_finished(return_code, starnet_dialog, self.output_image_path))
        starnet_dialog.cancel_button.clicked.connect(self.starnet_thread.stop)
        self.starnet_thread.start()


    def on_starnet_finished(self, return_code, dialog, output_image_path):
        """
        Handles the completion of the StarNet process.
        """
        dialog.append_text(f"\nProcess finished with return code {return_code}.\n")
        if return_code != 0:
            QMessageBox.critical(self, "StarNet Error", f"StarNet failed with return code {return_code}.")
            print(f"StarNet failed with return code {return_code}.")
            dialog.close()
            return

        # Step 8: Load the starless image
        if not os.path.exists(output_image_path):
            QMessageBox.critical(self, "StarNet Error", "Starless image was not created.")
            print(f"Starless image was not created at {output_image_path}.")
            dialog.close()
            return

        dialog.append_text(f"Starless image found at {output_image_path}. Loading image...\n")
        starless_bgr = cv2.imread(output_image_path, cv2.IMREAD_UNCHANGED)
        if starless_bgr is None:
            QMessageBox.critical(self, "StarNet Error", "Failed to load starless image.")
            dialog.close()
            return

        dialog.append_text("Starless image loaded successfully.\n")
        starless_rgb = cv2.cvtColor(starless_bgr, cv2.COLOR_BGR2RGB).astype('float32') / 65535.0

        # Unstretch if needed
        if getattr(self, 'image_was_stretched', False):
            dialog.append_text("Unstretching the starless image...\n")
            starless_rgb = self.unstretch_image(starless_rgb)
            dialog.append_text("Starless image unstretched successfully.\n")
        else:
            dialog.append_text("Image was not stretched. Proceeding without unstretching.\n")

        # Ensure 3-channel
        if starless_rgb.ndim == 2 or (starless_rgb.ndim == 3 and starless_rgb.shape[2] == 1):
            starless_rgb = np.stack([starless_rgb]*3, axis=-1)

        orig = self.image_manager.image
        if orig.ndim == 2 or (orig.ndim == 3 and orig.shape[2] == 1):
            original_rgb = np.stack([orig]*3, axis=-1)
        else:
            original_rgb = orig

        # Step 9: Generate Stars-Only image
        dialog.append_text("Generating stars-only image...\n")
        with np.errstate(divide='ignore', invalid='ignore'):
            stars_only = (original_rgb - starless_rgb) / (1.0 - starless_rgb)
            stars_only = np.nan_to_num(stars_only, nan=0.0, posinf=0.0, neginf=0.0)
        stars_only = np.clip(stars_only, 0.0, 1.0)
        dialog.append_text("Stars-only image generated.\n")

        # ─── Apply mask to Stars-Only ─────────────────────────────────────
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = stars_only.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32')/255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    mask3 = mask[:, :, None]
                    mask3 = np.repeat(mask3, 3, axis=2)
                    mask3 = np.clip(mask3, 0.0, 1.0)
                    stars_only = stars_only * mask3
                    dialog.append_text("✅ Applied active mask to the stars-only image.\n")
                else:
                    dialog.append_text("⚠️ Stars-only mask size mismatch; skipping mask on stars-only.\n")
        else:
            dialog.append_text("ℹ️ No active mask for stars-only; skipping.\n")

        # Step 10: Push Stars-Only to next slot
        available_slot = None
        for slot in range(self.image_manager.max_slots):
            img = self.image_manager._images.get(slot)
            if img is None or (isinstance(img, np.ndarray) and img.shape[:2] <= (10,10)):
                available_slot = slot
                break

        if available_slot is not None:
            meta = {'slot_name': 'Stars_Only'}
            self.image_manager.update_image(stars_only, metadata=meta, slot=available_slot)
            self.image_manager._metadata[available_slot]['slot_name'] = "Stars_Only"
            self.slot_names[available_slot] = "Stars_Only"
            if available_slot in self.slot_actions:
                self.slot_actions[available_slot].setText("Stars_Only")
            if available_slot in self.preview_windows:
                self.preview_windows[available_slot].setWindowTitle("Preview - Stars_Only")
            if hasattr(self, 'menubar_slot_actions') and available_slot in self.menubar_slot_actions:
                self.menubar_slot_actions[available_slot].setText("Stars_Only")
            self.menuBar().update()
            self.open_preview_window(slot=available_slot)
            dialog.append_text(f"Stars-only image pushed to slot {available_slot}.\n")
        else:
            dialog.append_text("⚠️ No available slot for stars-only image.\n")

        # ─── Mask-blend Starless and update ─────────────────────────────────
        dialog.append_text("Preparing to update ImageManager with starless (mask-blend)...\n")
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = starless_rgb.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32')/255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    mask3 = mask[:, :, None]
                    mask3 = np.repeat(mask3, 3, axis=2)
                    mask3 = np.clip(mask3, 0.0, 1.0)
                    final_starless = starless_rgb * mask3 + original_rgb * (1.0 - mask3)
                    dialog.append_text("✅ Applied active mask to the starless image.\n")
                else:
                    dialog.append_text("⚠️ Starless mask size mismatch; skipping mask on starless.\n")
                    final_starless = starless_rgb
            else:
                dialog.append_text("⚠️ No active mask found; using raw starless.\n")
                final_starless = starless_rgb
        else:
            dialog.append_text("ℹ️ Mask not active; using raw starless.\n")
            final_starless = starless_rgb

        # Step 11: Update ImageManager with starless
        self.image_manager.set_image(
            final_starless,
            metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}),
            step_name="Stars Removed"
        )
        QMessageBox.information(self, "Success", "Starless image updated successfully.")
        dialog.append_text("ImageManager updated with starless image.\n")

        # Cleanup
        try:
            if os.path.exists(self.input_image_path):
                os.remove(self.input_image_path)
            if os.path.exists(self.output_image_path):
                os.remove(self.output_image_path)
        except Exception as e:
            dialog.append_text(f"Cleanup error: {e}\n")

        dialog.close()




    def remove_stars_darkstar(self):
        """
        Removes stars from the current image using CosmicClarityDarkStar headless mode
        and generates a stars-only image. In this branch no linearity or conversion is needed –
        the input image is assumed to be a 32-bit, 0-1 normalized array.
        """
        print("Starting star removal process using CosmicClarityDarkStar...")

        # Retrieve the parent Cosmic Clarity folder from settings.
        cosmic_clarity_folder = self.settings.value("cosmic_clarity_folder", "")
        if not cosmic_clarity_folder:
            QMessageBox.critical(self, "Cosmic Clarity Folder Error",
                                "Cosmic Clarity folder not set in preferences.")
            print("Cosmic Clarity folder not set in preferences.")
            return

        # Determine the CosmicClarityDarkStar executable based on OS.
        current_os = platform.system()
        if current_os == "Windows":
            executable_name = "setiastrocosmicclarity_darkstar.exe"
        else:
            executable_name = "setiastrocosmicclarity_darkstar"
        darkstar_exe_path = os.path.join(cosmic_clarity_folder, executable_name)
        print(f"Using CosmicClarityDarkStar executable: {darkstar_exe_path}")

        if not os.path.exists(darkstar_exe_path):
            QMessageBox.critical(self, "CosmicClarityDarkStar Not Found",
                                f"CosmicClarityDarkStar executable not found at {darkstar_exe_path}. Aborting star removal process.")
            print(f"CosmicClarityDarkStar executable not found: {darkstar_exe_path}")
            return

        # Step 2: Ensure current image is loaded
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing stars.")
            print("No image loaded. Exiting star removal process.")
            return

        print("Image is loaded. Proceeding with star removal using CosmicClarityDarkStar.")

        # Prompt the user for Dark Star parameters:
        # Show parameter dialog
        config_dialog = DarkStarConfigDialog(self)
        if not config_dialog.exec():
            print("User cancelled Dark Star settings dialog.")
            return
        params = config_dialog.get_values()
        disable_gpu = params["disable_gpu"]
        mode = params["mode"]
        show_extracted_stars = params["show_extracted_stars"]
        chunk_size_value = params["chunk_size"]

        # Set up input/output folders (which Dark Star will use automatically)
        input_dir = os.path.join(cosmic_clarity_folder, "input")
        output_dir = os.path.join(cosmic_clarity_folder, "output")
        os.makedirs(input_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True)

        # Save the current image in the input folder as a 32-bit TIFF.
        base_filename = "imagetoremovestars.tif"
        self.input_image_path = os.path.join(input_dir, base_filename)
        print(f"Saving input image as 32-bit float TIFF to {self.input_image_path} ...")
        save_image(
            self.image_manager.image,
            self.input_image_path,
            original_format="tif",
            bit_depth="32-bit floating point",
            original_header=None,
            is_mono=False,
            image_meta=None,
            file_meta=None
        )
        print(f"Input image saved at {self.input_image_path}")

        # Build command arguments based on user choices.
        args_list = []
        if disable_gpu:
            args_list.append("--disable_gpu")
        args_list.extend(["--star_removal_mode", mode])
        if show_extracted_stars:
            args_list.append("--show_extracted_stars")
        args_list.extend(["--chunk_size", str(chunk_size_value)])

        # Final command to launch Dark Star
        command = [darkstar_exe_path] + args_list
        print(f"CosmicClarityDarkStar command: {' '.join(command)}")

        # Ensure executable permissions if needed
        if current_os in ["Darwin", "Linux"]:
            if not os.access(darkstar_exe_path, os.X_OK):
                print(f"Setting execute permissions for: {darkstar_exe_path}")
                try:
                    os.chmod(darkstar_exe_path, 0o755)
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error",
                                        f"Failed to set execute permissions for DarkStar executable: {e}")
                    print(f"Permission error: {e}")
                    return
            else:
                print("Executable permission already set.")
        else:
            print("Windows platform — execute permission check skipped.")

        # Show progress dialog
        darkstar_dialog = StarNetDialog()
        darkstar_dialog.show()

        # Run Dark Star in background thread
        self.darkstar_thread = StarNetThread(command, output_dir)
        self.darkstar_thread.stdout_signal.connect(darkstar_dialog.append_text)
        self.darkstar_thread.stderr_signal.connect(darkstar_dialog.append_text)
        self.darkstar_thread.finished_signal.connect(
            lambda return_code: self.on_darkstar_finished(return_code, darkstar_dialog, output_dir)
        )
        darkstar_dialog.cancel_button.clicked.connect(self.darkstar_thread.stop)
        self.darkstar_thread.start()



    def on_darkstar_finished(self, return_code, dialog, output_dir):
        """
        Handles the completion of the CosmicClarityDarkStar process.
        Loads the starless image (with _starless suffix) and, if generated, the stars-only image (with _stars_only suffix).
        Updates the ImageManager and cleans up temporary files.
        """
        dialog.append_text(f"\nProcess finished with return code {return_code}.\n")
        if return_code != 0:
            QMessageBox.critical(self, "CosmicClarityDarkStar Error",
                                f"CosmicClarityDarkStar failed with return code {return_code}.")
            dialog.close()
            return

        # ─── Load starless ───────────────────────────────────────────
        starless_path = os.path.join(output_dir, "imagetoremovestars_starless.tif")
        if not os.path.exists(starless_path):
            QMessageBox.critical(self, "CosmicClarityDarkStar Error", "Starless image was not created.")
            dialog.close()
            return

        dialog.append_text(f"Loading starless image from {starless_path}...\n")
        starless = cv2.imread(starless_path, cv2.IMREAD_UNCHANGED)
        if starless is None:
            QMessageBox.critical(self, "CosmicClarityDarkStar Error", "Failed to load starless image.")
            dialog.close()
            return

        dialog.append_text("Starless image loaded successfully.\n")
        starless_rgb = cv2.cvtColor(starless, cv2.COLOR_BGR2RGB).astype('float32')

        # Ensure 3-channel
        if starless_rgb.ndim == 2 or (starless_rgb.ndim == 3 and starless_rgb.shape[2] == 1):
            starless_rgb = np.stack([starless_rgb]*3, axis=-1)

        orig = self.image_manager.image
        if orig.ndim == 2 or (orig.ndim == 3 and orig.shape[2] == 1):
            original_rgb = np.stack([orig]*3, axis=-1)
        else:
            original_rgb = orig

        # ─── Load & mask-push stars-only ─────────────────────────────
        stars_path = os.path.join(output_dir, "imagetoremovestars_stars_only.tif")
        if os.path.exists(stars_path):
            dialog.append_text(f"Loading stars-only image from {stars_path}...\n")
            stars_only = cv2.imread(stars_path, cv2.IMREAD_UNCHANGED)
            if stars_only is not None:
                stars_only_rgb = cv2.cvtColor(stars_only, cv2.COLOR_BGR2RGB).astype('float32')

                # Apply active mask to stars-only if present
                mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
                if mask_slot == self.image_manager.current_slot:
                    mask = self.image_manager.mask_manager.get_applied_mask()
                    if mask is not None:
                        h, w = stars_only_rgb.shape[:2]
                        if mask.shape == (h, w):
                            if mask.dtype != np.float32:
                                mask = mask.astype('float32') / 255.0
                            if mask.ndim == 3:
                                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                            m3 = mask[:, :, None]
                            m3 = np.repeat(m3, 3, axis=2)
                            stars_only_rgb *= np.clip(m3, 0.0, 1.0)
                            dialog.append_text("✅ Applied active mask to stars-only image.\n")
                        else:
                            dialog.append_text("⚠️ Stars-only mask size mismatch; skipping mask.\n")
                    else:
                        dialog.append_text("⚠️ No active mask for stars-only; skipping.\n")
                else:
                    dialog.append_text("ℹ️ Mask not active for stars-only; skipping.\n")

                # push into next free slot
                available_slot = None
                for slot in range(self.image_manager.max_slots):
                    img = self.image_manager._images.get(slot)
                    if img is None or (isinstance(img, np.ndarray) and img.shape[:2] <= (10,10)):
                        available_slot = slot
                        break
                if available_slot is not None:
                    meta = {'slot_name': 'Stars_Only'}
                    self.image_manager.update_image(stars_only_rgb, metadata=meta, slot=available_slot)
                    self.image_manager._metadata[available_slot]['slot_name'] = "Stars_Only"
                    self.slot_names[available_slot] = "Stars_Only"
                    if available_slot in self.slot_actions:
                        self.slot_actions[available_slot].setText("Stars_Only")
                    if available_slot in self.preview_windows:
                        self.preview_windows[available_slot].setWindowTitle("Preview - Stars_Only")
                    if hasattr(self, 'menubar_slot_actions') and available_slot in self.menubar_slot_actions:
                        self.menubar_slot_actions[available_slot].setText("Stars_Only")
                    self.menuBar().update()
                    self.open_preview_window(slot=available_slot)
                    dialog.append_text(f"Stars-only image pushed to slot {available_slot}.\n")
                else:
                    dialog.append_text("⚠️ No available slot for stars-only image.\n")
            else:
                dialog.append_text("Failed to load stars-only image.\n")
        else:
            dialog.append_text("No stars-only image generated.\n")

        # ─── Mask-blend starless & update ──────────────────────────────
        dialog.append_text("Mask-blending starless image before update...\n")
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = starless_rgb.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32') / 255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    m3 = mask[:, :, None]
                    m3 = np.repeat(m3, 3, axis=2)
                    final_starless = starless_rgb * m3 + original_rgb * (1.0 - m3)
                    dialog.append_text("✅ Applied active mask to starless image.\n")
                else:
                    dialog.append_text("⚠️ Starless mask size mismatch; skipping mask.\n")
                    final_starless = starless_rgb
            else:
                dialog.append_text("⚠️ No active mask found; using raw starless.\n")
                final_starless = starless_rgb
        else:
            dialog.append_text("ℹ️ Mask not active; using raw starless.\n")
            final_starless = starless_rgb

        # ─── Final update ───────────────────────────────────────────────
        self.image_manager.set_image(
            final_starless,
            metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}),
            step_name="Stars Removed"
        )
        QMessageBox.information(self, "Success",
                                "Starless image updated successfully via CosmicClarityDarkStar.")
        dialog.append_text("ImageManager updated with starless image.\n")

        # ─── Cleanup ───────────────────────────────────────────────────
        try:
            for p in (self.input_image_path, starless_path, stars_path):
                if os.path.exists(p):
                    os.remove(p)
            dialog.append_text("Temporary files cleaned up.\n")
        except Exception as e:
            dialog.append_text(f"Cleanup error: {e}\n")

        dialog.close()



    
    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.15

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def select_starnet_exe(self):
        """
        Prompts the user to select the StarNet executable based on the operating system.
        Saves the path using QSettings for future use.
        """


        current_os = platform.system()

        if current_os == "Windows":
            filter_str = "Executable Files (*.exe)"
        elif current_os in ["Linux", "Darwin"]:
            # For Unix-based systems, executables may not have extensions
            filter_str = "All Executable Files (*)"
        else:
            QMessageBox.critical(self, "Unsupported OS", f"The current operating system '{current_os}' is not supported.")
            return

        exe_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select StarNet Executable",
            "",
            filter_str

        )
        if exe_path:
            # For Windows, ensure the file has .exe extension
            if current_os == "Windows" and not exe_path.lower().endswith('.exe'):
                QMessageBox.warning(self, "Invalid File", "Please select a valid .exe file for StarNet.")
                return
            # For Unix-based systems, optionally check if it's executable
            elif current_os in ["Linux", "Darwin"]:
                if not os.access(exe_path, os.X_OK):
                    reply = QMessageBox.question(
                        self,
                        "Set Execute Permissions",
                        "The selected file does not have execute permissions. Would you like to add them?",
                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                        QMessageBox.StandardButton.Yes
                    )
                    if reply == QMessageBox.StandardButton.Yes:
                        try:
                            os.chmod(exe_path, 0o755)
                        except Exception as e:
                            QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                            return
                    else:
                        QMessageBox.information(self, "Cancelled", "Execute permissions not set. Cannot proceed.")
                        return
            self.starnet_exe_path = exe_path
            # Save the path using QSettings
            self.settings.setValue("starnet/exe_path", self.starnet_exe_path)
            QMessageBox.information(self, "StarNet Executable Set", f"StarNet executable set to:\n{exe_path}")
        else:
            QMessageBox.information(self, "Cancelled", "StarNet executable selection was cancelled.")



    def open_clahe_dialog(self):
        """Opens the CLAHE dialog window."""
        dialog = CLAHEDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_morpho_dialog(self):
        """Opens the Morphological Operations dialog window."""
        dialog = MorphologyDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_whitebalance_dialog(self):
        """Opens the White Balance dialog window."""
        dialog = WhiteBalanceDialog(self.image_manager, self)
        dialog.exec()

    def open_background_neutralization_dialog(self):
        """Opens the Background Neutralization dialog window."""
        dialog = BackgroundNeutralizationDialog(self.image_manager, self)
        dialog.exec()

    def open_remove_green_dialog(self):
        """
        Opens the RemoveGreenDialog.
        """
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "No image loaded in the current slot.")
            return

        dialog = RemoveGreenDialog(
            image_manager=self.image_manager,
            mask_manager=self.mask_manager,
            parent=self
        )
        dialog.exec()


    def dragEnterEvent(self, event):
        """Handle the drag enter event."""
        # Check if the dragged content is a file
        if event.mimeData().hasUrls():
            event.accept()
        else:
            event.ignore()

    def dropEvent(self, event):
        """Handle the drop event."""
        # Get the file path from the dropped file
        file_path = event.mimeData().urls()[0].toLocalFile()
        
        # Check if the file is an image (you can customize this check as needed)
        if file_path.lower().endswith(('.png', '.tif', '.tiff', '.fits', '.xisf', '.fit', '.fit.gz', '.fits.gz', '.jpg', '.jpeg', '.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            try:
                # Load the image into ImageManager
                image, header, bit_depth, is_mono = load_image(file_path)
                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }
                self.image_manager.add_image(self.image_manager.current_slot, image, metadata)  # Make sure to specify the slot here
                print(f"Image {file_path} loaded successfully via drag and drop.")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {e}")
        else:
            QMessageBox.warning(self, "Invalid File", "Only image files are supported.")

    def update_file_name(self, slot, image, metadata):
        """Update the file name in the status bar."""
        file_path = metadata.get('file_path', None)
        
        if file_path:
            # Debugging: Print type and value of file_path
            print(f"DEBUG: file_path type: {type(file_path)}, value: {file_path}")
            
            # Check if file_path is a QLabel
            if isinstance(file_path, QLabel):
                # Extract text from QLabel
                file_path_str = file_path.text()
                print("WARNING: 'file_path' was a QLabel. Extracted text.")
            elif isinstance(file_path, (str, bytes, os.PathLike)):
                # Correct type
                file_path_str = file_path
            else:
                # Unsupported type
                file_path_str = "Invalid file path"
                QMessageBox.warning(
                    self,
                    "Invalid File Path",
                    f"The provided file path is invalid (type: {type(file_path)})."
                )
                print(f"WARNING: 'file_path' is of unsupported type: {type(file_path)}")
                self.file_name_label.setText(file_path_str)
                return  # Exit early since the path is invalid
            
            # Safely set the file name label
            try:
                base_name = os.path.basename(file_path_str)
                self.file_name_label.setText(base_name)
                print(f"File name updated to: {base_name}")
            except Exception as e:
                QMessageBox.critical(
                    self,
                    "Error Updating File Name",
                    f"An error occurred while updating the file name:\n{str(e)}"
                )
                print(f"ERROR: Failed to set file name label: {e}")
        else:
            self.file_name_label.setText("No file selected")
            print("No file path provided in metadata.")
        
        # If slot == 0 and we have a valid image, update dimensions
        if image is not None:
            # Check the number of dimensions in the image array.
            if image.ndim == 2:
                # 2D image (height, width)
                h, w = image.shape
                self.dim_label.setText(f"{w} x {h}")
                print(f"Image dimensions updated to: {w} x {h}")
            elif image.ndim == 3:
                # 3D image (height, width, channels)
                h, w, c = image.shape
                self.dim_label.setText(f"{w} x {h} x {c}")
                print(f"Image dimensions updated to: {w} x {h} x {c}")
            else:
                self.dim_label.setText("Unknown dimensions")
                print("Image dimensions not updated due to unrecognized shape.")
        else:
            # No image available
            self.dim_label.setText("—")
            print("Image dimensions not updated.")   

    def apply_theme(self, theme):
        """Apply the selected theme to the application and persist it."""
        self.current_theme = theme
        self.settings.setValue("theme", theme)

        if theme == "light":
            light_stylesheet = """ 
            QWidget {
                background-color: #f0f0f0;
                color: #000000;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 2px;
            }
            QPushButton {
                background-color: #e0e0e0;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #d0d0d0;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #ffffff;
            }
            QTreeWidget {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
            }
            QHeaderView::section {
                background-color: #f0f0f0;
                color: #000000;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #cccccc; 
                background-color: #f0f0f0;
            }
            QTabBar::tab {
                background: #e0e0e0;
                color: #000000;
                padding: 5px;
                border: 1px solid #cccccc;
                border-bottom: none;
            }
            QTabBar::tab:selected {
                background: #d0d0d0;
                border-color: #000000;
            }
            QTabBar::tab:hover {
                background: #c0c0c0;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;
            }
            QMenu {
                background-color: #f0f0f0;
                color: #000000;
            }
            QMenu::item:selected {
                background-color: #d0d0d0; 
                color: #000000;
            }
            """
            self.setStyleSheet(light_stylesheet)

        elif theme == "dark":
            dark_stylesheet = """
            QWidget {
                background-color: #2b2b2b;
                color: #dcdcdc;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 2px;
            }
            QPushButton {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #4a4a4a;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #3c3f41;
            }
            QTreeWidget {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
            }
            QHeaderView::section {
                background-color: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #5c5c5c; 
                background-color: #2b2b2b;
            }
            QTabBar::tab {
                background: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
                border: 1px solid #5c5c5c;
                border-bottom: none;
            }
            QTabBar::tab:selected {
                background: #4a4a4a;
                border-color: #dcdcdc;
            }
            QTabBar::tab:hover {
                background: #505050;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;
            }
            QMenu {
                background-color: #2b2b2b;
                color: #dcdcdc;
            }
            QMenu::item:selected {
                background-color: #3a75c4;
                color: #ffffff;
            }       
            """
            self.setStyleSheet(dark_stylesheet)

        elif theme == "custom":
            custom_stylesheet = self.settings.value("custom_stylesheet", "")
            if custom_stylesheet:
                self.setStyleSheet(custom_stylesheet)
            else:
                print("⚠️ No custom stylesheet found in settings.")

        # Update mask banner styling
        if self.mask_manager.get_applied_mask() is not None:
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
        else:
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")


    def open_custom_theme_dialog(self):
        # Ask user for a background color
        bg_color = QColorDialog.getColor(title="Select Background Color", parent=self)
        if not bg_color.isValid():
            return

        # Ask user for a text color
        text_color = QColorDialog.getColor(title="Select Text Color", parent=self)
        if not text_color.isValid():
            return

        # Ask user for a font
        font, ok = QFontDialog.getFont(self)
        if not ok:
            return

        self.current_theme = "custom"

        # Generate a stylesheet using user choices
        lighter_bg = bg_color.lighter(300)
        darker_bg = bg_color.darker(120)

        custom_stylesheet = f"""
        QWidget {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
            font-family: {font.family()};
            font-size: {font.pointSize()}pt;
        }}

        QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {{
            background-color: {bg_color.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
            padding: 2px;
        }}

        QLabel {{
            background-color: {darker_bg.name()};
            color: {text_color.name()};
        }}

        QPushButton {{
            background-color: {lighter_bg.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
            padding: 5px;
        }}

        QPushButton:hover {{
            background-color: {text_color.name()};
            color: {bg_color.name()};
        }}

        QScrollBar:vertical, QScrollBar:horizontal {{
            background: {darker_bg.name()};
        }}

        QTreeWidget {{
            background-color: {darker_bg.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
        }}

        QHeaderView::section {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
            padding: 5px;
        }}

        QTabWidget::pane {{ 
            border: 1px solid {text_color.name()}; 
            background-color: {bg_color.name()};
        }}

        QTabBar::tab {{
            background: {lighter_bg.name()};
            color: {text_color.name()};
            padding: 5px;
            border: 1px solid {text_color.name()};
            border-bottom: none;
        }}

        QTabBar::tab:selected {{
            background: {text_color.name()};
            color: {bg_color.name()};
            border-color: {text_color.name()};
        }}

        QTabBar::tab:hover {{
            background: {text_color.name()};
            color: {bg_color.name()};
        }}

        QTabBar::tab:!selected {{
            margin-top: 2px;
        }}

        QMenu {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
        }}

        QMenu::item:selected {{
            background-color: {text_color.name()};
            color: {bg_color.name()};
        }}
        """
        self.setStyleSheet(custom_stylesheet)

        # Adjust banner style accordingly
        if self.mask_manager.get_applied_mask() is not None:
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
        else:
            self.mask_banner.setStyleSheet(f"background-color: transparent; color: {text_color.name()}; font-size: 14px; padding: 5px;")

        self.settings.setValue("custom_stylesheet", custom_stylesheet)
        self.settings.setValue("theme", "custom")
        self.current_theme = "custom"            

    def reset_custom_theme(self):
        confirm = QMessageBox.question(
            self,
            "Reset Custom Theme",
            "Are you sure you want to reset the custom theme to default?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if confirm == QMessageBox.StandardButton.Yes:
            self.settings.remove("custom_stylesheet")
            self.settings.setValue("theme", "dark")
            self.apply_theme("dark")
            QMessageBox.information(self, "Custom Theme Reset", "Custom theme has been reset to dark mode.")



    def open_image(self):
        default_dir = self.settings.value("working_directory", "")

        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Open Images",
            default_dir,
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.fits.gz *.fit.gz *.fz *.xisf *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )

        if not file_paths:
            return

        # Save last folder location
        self.settings.setValue("working_directory", os.path.dirname(file_paths[0]))

        slot = self.image_manager.current_slot  # Start at current slot

        for file_path in file_paths:
            try:
                image, header, bit_depth, is_mono = load_image(file_path)
                if image is None:
                    raise ValueError("Loaded image is None")

                # Find the next empty or <10x10 slot
                while slot < self.image_manager.max_slots:
                    existing_img = self.image_manager._images.get(slot)
                    if existing_img is None or existing_img.size == 0 or existing_img.shape[0] < 10 or existing_img.shape[1] < 10:
                        break
                    slot += 1

                if slot >= self.image_manager.max_slots:
                    QMessageBox.warning(self, "No Slots Available", "Ran out of image slots.")
                    break

                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }

                self.image_manager.add_image(slot, image, metadata)
                self.image_manager.set_current_slot(slot)
                self.update_slot_toolbar_highlight()
                print(f"Image loaded to slot {slot}: {file_path}")
                slot += 1

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {file_path}\n{e}")




    def save_image(self):
        """Save the current image to a selected path."""
        default_dir = self.settings.value("working_directory", "")
        if self.image_manager.image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
            )
            
            if save_file:
                self.settings.setValue("working_directory", os.path.dirname(save_file))
                try:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit', 'xisf', 'jpg', 'jpeg']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Define formats that do not require bit depth selection
                    no_bit_depth_formats = ['png', 'jpg', 'jpeg']

                    # Initialize bit_depth variable
                    bit_depth = None

                    if selected_format in no_bit_depth_formats:
                        # For PNG, JPG, JPEG, set bit depth to '8-bit' automatically
                        bit_depth = '8-bit'
                        print(f"Selected format '{selected_format}' does not require bit depth selection. Using bit depth: {bit_depth}.")
                    else:
                        # Prompt the user for bit depth selection for other formats
                        bit_depth, ok = QInputDialog.getItem(
                            self,
                            "Select Bit Depth",
                            "Choose bit depth for saving:",
                            ["32-bit floating point", "16-bit"],
                            0,
                            False
                        )
                        if not ok or not bit_depth:
                            QMessageBox.information(self, "Cancelled", "Save operation cancelled.")
                            print("Save operation cancelled by the user during bit depth selection.")
                            return

                    # Retrieve the image and metadata
                    image_data = self.image_manager.image
                    metadata = self.image_manager._metadata[self.image_manager.current_slot]
                    original_header = metadata.get('original_header', None)
                    is_mono = metadata.get('is_mono', False)

                    # Create a minimal header if the original header is missing and format is FITS
                    if original_header is None and selected_format in ['fits', 'fit']:
                        print("Creating a minimal FITS header for the data...")
                        original_header = self.create_minimal_fits_header(image_data, is_mono)

                    # Pass the image to the global save_image function
                    save_image(
                        img_array=image_data,
                        filename=save_file,
                        original_format=selected_format,
                        bit_depth=bit_depth,
                        original_header=original_header,
                        is_mono=is_mono
                    )
                    print(f"Image successfully saved to {save_file}.")

                    # Correctly access the status bar using the statusBar() method
                    self.statusBar.showMessage(f"Image saved to: {save_file}", 5000)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                    print(f"Error saving image: {e}")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded.")




    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def undo_image(self):
        if self.image_manager.can_undo():
            step = self.image_manager.undo()
            self.statusBar.showMessage(f"Undo: {step or 'Unnamed'}", 4000)
            self.update_undo_redo_action_labels()
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def redo_image(self):
        if self.image_manager.can_redo():
            step = self.image_manager.redo()
            self.statusBar.showMessage(f"Redo: {step or 'Unnamed'}", 4000)
            self.update_undo_redo_action_labels()
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")      


    def update_undo_redo_action_labels(self):
        slot = self.image_manager.current_slot

        # ---- Undo Label + Tip ----
        if self.image_manager.can_undo(slot):
            _, _, step_name = self.image_manager._undo_stacks[slot][-1]
            self.undo_action_toolbar.setText("Undo")
            self.undo_action_toolbar.setToolTip(f"Undo {step_name}")
            self.undo_action_toolbar.setStatusTip(f"Undo: {step_name}")
        else:
            self.undo_action_toolbar.setToolTip("Undo (no actions)")
            self.undo_action_toolbar.setStatusTip("Undo the last action")

        # ---- Redo Label + Tip ----
        if self.image_manager.can_redo(slot):
            _, _, step_name = self.image_manager._redo_stacks[slot][-1]
            self.redo_action_toolbar.setText("Redo")
            self.redo_action_toolbar.setToolTip(f"Redo {step_name}")
            self.redo_action_toolbar.setStatusTip(f"Redo: {step_name}")
        else:
            self.redo_action_toolbar.setToolTip("Redo (no actions)")
            self.redo_action_toolbar.setStatusTip("Redo the last undone action")




    def closeEvent(self, event):
        """Prompt the user before exiting the application."""
        reply = QMessageBox.question(
            self,
            "Exit Confirmation",
            "Are you sure you want to exit?\nDon't forget to save your work.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            event.accept()
        else:
            event.ignore()


class AboutDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("About Seti Astro Suite")
        layout = QVBoxLayout()

        # Create a QLabel with rich text (HTML) for clickable links
        about_text = (
            f"<h2>Seti Astro's Suite {VERSION}</h2>"
            "<p>Written by Franklin Marek</p>"
            "<p>Website: <a href='http://www.setiastro.com'>www.setiastro.com</a></p>"
            "<p>Donations: <a href='https://www.setiastro.com/checkout/donate?donatePageId=65ae7e7bac20370d8c04c1ab'>Click here to donate</a></p>"
        )
        label = QLabel(about_text)
        label.setTextFormat(Qt.TextFormat.RichText)
        label.setTextInteractionFlags(Qt.TextInteractionFlag.TextBrowserInteraction)
        label.setOpenExternalLinks(True)
        
        layout.addWidget(label)
        self.setLayout(layout)

class RecombineDialog(QDialog):
    def __init__(self, available_slots, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Recombine Luminance and RGB Images")
        self.selected_lum_slot = None
        self.selected_rgb_slot = None
        self.initUI(available_slots)
    
    def initUI(self, available_slots):
        layout = QVBoxLayout()
        
        # Instruction Label
        instruction_label = QLabel("Select the slots for Luminance and RGB images:")
        layout.addWidget(instruction_label)
        
        # Luminance Slot Selection
        lum_layout = QHBoxLayout()
        lum_label = QLabel("Luminance Slot:")
        self.lum_combo = QComboBox()
        self.lum_combo.addItems([f"Slot {slot}" for slot in available_slots])
        lum_layout.addWidget(lum_label)
        lum_layout.addWidget(self.lum_combo)
        layout.addLayout(lum_layout)
        
        # RGB Slot Selection
        rgb_layout = QHBoxLayout()
        rgb_label = QLabel("RGB Slot:")
        self.rgb_combo = QComboBox()
        self.rgb_combo.addItems([f"Slot {slot}" for slot in available_slots])
        rgb_layout.addWidget(rgb_label)
        rgb_layout.addWidget(self.rgb_combo)
        layout.addLayout(rgb_layout)
        
        # Buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK")
        cancel_button = QPushButton("Cancel")
        ok_button.clicked.connect(self.validate_and_accept)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(ok_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)
        
        self.setLayout(layout)
    
    def validate_and_accept(self):
        """Ensure that the selected slots are different before accepting."""
        lum_slot = self.lum_combo.currentIndex()
        rgb_slot = self.rgb_combo.currentIndex()
        
        if lum_slot == rgb_slot:
            QMessageBox.warning(
                self,
                "Invalid Selection",
                "Luminance and RGB slots must be different. Please select distinct slots."
            )
            return
        self.selected_lum_slot = lum_slot
        self.selected_rgb_slot = rgb_slot
        self.accept()
    
    def getSelections(self):
        """Return the selected luminance and RGB slot numbers."""
        return self.selected_lum_slot, self.selected_rgb_slot


class CopySlotDialog(QDialog):
    def __init__(self, parent, image_manager, mask_manager):
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Copy Slot")
        self.initUI()
    
    def initUI(self):
        layout = QVBoxLayout()
        
        # Source Type Selection
        source_type_layout = QHBoxLayout()
        source_type_label = QLabel("Source Type:")
        self.source_type_combo = QComboBox()
        self.source_type_combo.addItems(["Image", "Mask"])
        self.source_type_combo.currentTextChanged.connect(self.update_source_slots)
        source_type_layout.addWidget(source_type_label)
        source_type_layout.addWidget(self.source_type_combo)
        layout.addLayout(source_type_layout)
        
        # Source Slot Selection
        source_slot_layout = QHBoxLayout()
        source_slot_label = QLabel("Source Slot:")
        self.source_slot_combo = QComboBox()
        source_slot_layout.addWidget(source_slot_label)
        source_slot_layout.addWidget(self.source_slot_combo)
        layout.addLayout(source_slot_layout)
        
        # Target Type Selection
        target_type_layout = QHBoxLayout()
        target_type_label = QLabel("Target Type:")
        self.target_type_combo = QComboBox()
        self.target_type_combo.addItems(["Image", "Mask"])
        self.target_type_combo.currentTextChanged.connect(self.update_target_slots)
        target_type_layout.addWidget(target_type_label)
        target_type_layout.addWidget(self.target_type_combo)
        layout.addLayout(target_type_layout)
        
        # Target Slot Selection
        target_slot_layout = QHBoxLayout()
        target_slot_label = QLabel("Target Slot:")
        self.target_slot_combo = QComboBox()
        target_slot_layout.addWidget(target_slot_label)
        target_slot_layout.addWidget(self.target_slot_combo)
        layout.addLayout(target_slot_layout)
        
        # Initialize slot selections
        self.update_source_slots(self.source_type_combo.currentText())
        self.update_target_slots(self.target_type_combo.currentText())
        
        # Dialog buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)
        
        self.setLayout(layout)
    
    def update_source_slots(self, source_type):
        self.source_slot_combo.clear()
        if source_type == "Image":
            # Use parent's custom names if available; fall back to default text if not.
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif source_type == "Mask":
            # For masks, we use default text (or you could create a similar renaming mechanism)
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.source_slot_combo.addItem(text, slot_number)
    
    def update_target_slots(self, target_type):
        self.target_slot_combo.clear()
        if target_type == "Image":
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif target_type == "Mask":
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.target_slot_combo.addItem(text, slot_number)
    
    def get_selected_source(self):
        source_type = self.source_type_combo.currentText()
        # Retrieve the slot number from the combo box item data.
        source_slot_num = self.source_slot_combo.currentData()
        return (source_type, source_slot_num)
    
    def get_selected_target(self):
        target_type = self.target_type_combo.currentText()
        target_slot_num = self.target_slot_combo.currentData()
        return (target_type, target_slot_num)

def siril_style_autostretch(image, sigma=3.0):
    """
    Perform a 'Siril-style histogram stretch' using MAD for robust contrast enhancement.
    
    Parameters:
        image (np.ndarray): Input image, assumed to be normalized to [0, 1] range.
        sigma (float): How many MADs to stretch from the median.
    
    Returns:
        np.ndarray: Stretched image in [0, 1] range.
    """
    def stretch_channel(channel):
        median = np.median(channel)
        mad = np.median(np.abs(channel - median))
        min_val = np.min(channel)
        max_val = np.max(channel)

        # Convert MAD to an equivalent of std (optional, keep raw MAD if preferred)
        mad_std_equiv = mad * 1.4826

        black_point = max(min_val, median - sigma * mad_std_equiv)
        white_point = min(max_val, median + sigma * mad_std_equiv)

        if white_point - black_point <= 1e-6:
            return np.zeros_like(channel)  # Avoid divide-by-zero

        stretched = (channel - black_point) / (white_point - black_point)
        return np.clip(stretched, 0, 1)

    if image.ndim == 2:
        return stretch_channel(image)
    elif image.ndim == 3 and image.shape[2] == 3:
        return np.stack([stretch_channel(image[..., c]) for c in range(3)], axis=-1)
    else:
        raise ValueError("Unsupported image format for histogram stretch.")

HANDLE_SIZE = 20

class ResizableRotatableRectItem(QGraphicsRectItem):
    """
    A rectangle item with 4 corner handles for resizing and
    alt+drag to rotate.
    """
    def __init__(self, rect: QRectF, parent=None):
        super().__init__(rect, parent)
        self.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges
        )
        self.setAcceptHoverEvents(True)
        self._handles = {}
        self._active_handle = None
        self._rotating = False
        self._rotation_start = 0.0
        self._pivot_scene = QPointF()
        self._initHandles()
        # only set origin _once_ here
        self.setTransformOriginPoint(self.rect().center())

    def _initHandles(self):
        pen = QPen(Qt.GlobalColor.black)
        brush = QBrush(Qt.GlobalColor.white)
        for pos in ("tl","tr","br","bl"):
            h = QGraphicsEllipseItem(0,0, HANDLE_SIZE, HANDLE_SIZE, self)
            h.setPen(pen)
            h.setBrush(brush)
            h.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIsMovable, False)
            self._handles[pos] = h
        self._updateHandlePositions()

    def _updateHandlePositions(self):
        r = self.rect()
        s = HANDLE_SIZE
        corners = {
            "tl": QPointF(r.left()-s/2,  r.top()-s/2),
            "tr": QPointF(r.right()-s/2, r.top()-s/2),
            "br": QPointF(r.right()-s/2, r.bottom()-s/2),
            "bl": QPointF(r.left()-s/2,  r.bottom()-s/2),
        }
        for pos, item in self._handles.items():
            item.setPos(corners[pos])

        # reset the transform‐origin to the box’s true center
        scene_ctr = self.mapToScene(self.boundingRect().center())


    def hoverMoveEvent(self, ev):
        for pos, h in self._handles.items():
            if h.contains(h.mapFromScene(ev.scenePos())):
                self._setCursorForHandle(pos)
                return
        self.setCursor(Qt.CursorShape.SizeAllCursor)
        super().hoverMoveEvent(ev)

    def mousePressEvent(self, ev):
        if ev.modifiers() == Qt.KeyboardModifier.ShiftModifier:
            # start rotating
            self._rotating = True
            # store where we began, in degrees
            pivot = self.mapToScene(self.rect().center())
            self._pivot_scene = pivot
            v0 = ev.scenePos() - pivot
            self._angle_ref = math.degrees(math.atan2(v0.y(), v0.x()))
            # and the item’s starting rotation
            self._rotation_start = self.rotation()
            ev.accept()
            return

        # check for handle‐resize
        for pos, h in self._handles.items():
            if h.contains(h.mapFromScene(ev.scenePos())):
                self._active_handle = pos
                ev.accept()
                return

        # fallback to move
        super().mousePressEvent(ev)

    def mouseMoveEvent(self, ev):
        if self._rotating:
            # compute new absolute angle
            v_new = ev.scenePos() - self._pivot_scene
            a_new = math.degrees(math.atan2(v_new.y(), v_new.x()))
            delta = a_new - self._angle_ref
            # apply full delta from the very start
            self.setRotation(self._rotation_start + delta)
            ev.accept()
            return

        if self._active_handle:
            self._resizeViaHandle(ev.scenePos())
            ev.accept()
            return

        super().mouseMoveEvent(ev)


    def mouseReleaseEvent(self, ev):
        if self._rotating:
            self._rotating = False
            ev.accept()
            return
        super().mouseReleaseEvent(ev)

    def _refreshPivot(self):
        scene_ctr = self.mapToScene(self.boundingRect().center())
        self.setTransformOriginPoint(self.mapFromScene(scene_ctr))

    def _resizeViaHandle(self, scene_pt: QPointF):
        r = self.rect()
        p = self.mapFromScene(scene_pt)
        # adjust rect based on which handle
        if self._active_handle == "tl":
            r.setTopLeft(p)
        elif self._active_handle == "tr":
            r.setTopRight(p)
        elif self._active_handle == "br":
            r.setBottomRight(p)
        elif self._active_handle == "bl":
            r.setBottomLeft(p)
        # normalize and apply
        r = r.normalized()
        self.setRect(r)
        self._updateHandlePositions()

    def _setCursorForHandle(self, handle_name):
        cursors = {
            "tl": Qt.CursorShape.SizeFDiagCursor,
            "br": Qt.CursorShape.SizeFDiagCursor,
            "tr": Qt.CursorShape.SizeBDiagCursor,
            "bl": Qt.CursorShape.SizeBDiagCursor,
        }
        self.setCursor(cursors.get(handle_name, Qt.CursorShape.ArrowCursor))

class CropTool(QDialog):
    """A cropping tool with a resizable, rotatable rectangle."""
    crop_applied = pyqtSignal(object)
    # before: previous_crop_rect = None
    previous_crop_rect = (None, 0.0, QPointF(0, 0))

    def __init__(self, image_manager, image_data, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Crop Tool")
        self.setGeometry(100,100,800,600)
        self.image_manager = image_manager
        self.original_image_data = image_data.copy()
        self.image_data = image_data
        self.scene = QGraphicsScene(self)
        self.view  = QGraphicsView(self.scene)
        self._rect_item = None
        self.selection_rect_item = None
        self.drawing = False
        self.origin = QPointF()
        instr = QLabel(
            "• Click-and-drag to draw crop rectangle\n"
            "• Drag any corner handle to resize\n"
            "• Shift + drag a corner handle to rotate"
        )
        layout = QVBoxLayout(self)

        instr.setAlignment(Qt.AlignmentFlag.AlignCenter)
        instr.setStyleSheet("font-style: italic; color: gray;")
        layout.addWidget(instr)
        # install filter after view is created:
        self.view.viewport().installEventFilter(self)
        # Layout & buttons

        layout.addWidget(self.view)

        btns = [
            ("Toggle Autostretch", self.toggle_autostretch),
            ("Load Previous Crop", self.load_previous_crop),
            ("Apply Crop",         self.apply_crop),
            ("Batch Crop All Slots", self.batch_crop_all_slots),
        ]
        for txt, slot in btns:
            b = QPushButton(txt);  b.clicked.connect(slot)
            layout.addWidget(b)

        self.setLayout(layout)
        self._loadImage()
        self.view.viewport().installEventFilter(self)

    def _loadImage(self):
        img = self.image_data
        if img.ndim==3 and img.shape[2]==1:
            img = img.squeeze(2)
        if img.ndim==3:
            h,w,_ = img.shape
            q = QImage((img*255).astype(np.uint8).tobytes(), w,h,3*w,QImage.Format.Format_RGB888)
        else:
            h,w = img.shape
            q = QImage((img*255).astype(np.uint8).tobytes(), w,h,w,QImage.Format.Format_Grayscale8)
        pix = QPixmap.fromImage(q)
        self.scene.clear()
        self.scene.addItem(QGraphicsPixmapItem(pix))
        self.view.fitInView(self.scene.itemsBoundingRect(), Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, ev):
        super().resizeEvent(ev)
        if self.scene.items():
            self.view.fitInView(self.scene.itemsBoundingRect(), Qt.AspectRatioMode.KeepAspectRatio)

    def eventFilter(self, source, ev):
        if source is self.view.viewport():
            # translate to scene coords when needed
            if ev.type() in (
                QEvent.Type.MouseButtonPress,
                QEvent.Type.MouseMove,
                QEvent.Type.MouseButtonRelease
            ):
                scene_pt = self.view.mapToScene(ev.pos())

            # if we haven't yet created our rotatable rect, intercept
            if self._rect_item is None:
                if ev.type() == QEvent.Type.MouseButtonPress and ev.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin  = scene_pt
                    return True
                if ev.type() == QEvent.Type.MouseMove and getattr(self, "drawing", False):
                    r = QRectF(self.origin, scene_pt).normalized()
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                    pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
                    self.selection_rect_item = self.scene.addRect(r, pen)
                    return True
                if ev.type() == QEvent.Type.MouseButtonRelease and ev.button() == Qt.MouseButton.LeftButton and getattr(self, "drawing", False):
                    self.drawing = False
                    final_r = QRectF(self.origin, scene_pt).normalized()
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                    self._rect_item = ResizableRotatableRectItem(final_r)
                    pos   = self._rect_item.pos()
                    angle = self._rect_item.rotation()
                    CropTool.previous_crop_rect = (final_r, angle, pos)
                    self.scene.addItem(self._rect_item)
                    return True

            # 2) If a rect already exists, don’t intercept—let the QGraphicsItem handle it!
            return False

        return super().eventFilter(source, ev)



    def _getCurrentRect(self):
        """Return QRectF in image‐pixel coords (ignoring rotation)."""
        if not self._rect_item:
            return None
        r = self._rect_item.rect()
        # Use itemsBoundingRect() to cover the entire pixmap
        sb = self.scene.itemsBoundingRect()
        if sb.isEmpty():
            return None
        scale_x = self.original_image_data.shape[1] / sb.width()
        scale_y = self.original_image_data.shape[0] / sb.height()
        return QRectF(
            r.left()   * scale_x,
            r.top()    * scale_y,
            r.width()  * scale_x,
            r.height() * scale_y
        )


    def toggle_autostretch(self):
        stretched = siril_style_autostretch(self.original_image_data, sigma=3.0)
        if stretched is None:
            return
        # grab and clear
        saved = self._getCurrentRect()
        self.image_data = stretched
        self._loadImage()
        if saved and not saved.isNull():
            # restore size/angle/position triple
            rect, old_angle, old_pos = CropTool.previous_crop_rect
            self._rect_item = ResizableRotatableRectItem(rect)
            self._rect_item.setPos(old_pos)
            self._rect_item.setRotation(old_angle)
            self._rect_item.setTransformOriginPoint(rect.center())
            self.scene.addItem(self._rect_item)

    def load_previous_crop(self):
        rect, angle, pos = CropTool.previous_crop_rect
        if rect is None:
            QMessageBox.information(self, "No Previous", "No previous crop stored.")
            return

        # remove old
        if self._rect_item:
            self.scene.removeItem(self._rect_item)

        # create, then re‐position & rotate
        self._rect_item = ResizableRotatableRectItem(rect)
        self._rect_item.setPos(pos)
        self._rect_item.setRotation(angle)
        self._rect_item.setTransformOriginPoint(rect.center())
        self.scene.addItem(self._rect_item)

    def apply_crop(self):
        """Crop out exactly the rotated rectangle, then derotate so the result is upright."""
        rc = self._getCurrentRect()
        if not rc or rc.isNull():
            QMessageBox.warning(self, "No Selection", "Draw (and finalize) a crop first.")
            return

        # 1) Figure out the rotation angle of the rect item
        angle = self._rect_item.rotation()  # degrees, CCW positive

        # 2) Prepare the original image and rotation matrix
        img = self.original_image_data  # numpy array HxW(xC)
        h_img, w_img = img.shape[:2]
        center = (w_img/2.0, h_img/2.0)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)

        # 3) Rotate the entire image
        #    keep same size to make cropping simpler
        rotated = cv2.warpAffine(
            img,
            M,
            (w_img, h_img),
            flags=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=0
        )

        # 4) Extract integer crop coords from rc (these are in un‐rotated image pixels)
        x, y, w, h = int(rc.x()), int(rc.y()), int(rc.width()), int(rc.height())

        # clamp just in case
        x = max(0, min(x, w_img-1))
        y = max(0, min(y, h_img-1))
        w = max(1, min(w, w_img - x))
        h = max(1, min(h, h_img - y))

        # 5) Crop from the rotated image
        cropped = rotated[y:y+h, x:x+w].copy()

        # 6) Notify caller
        self.crop_applied.emit(cropped)

        # save size, rotation and position for next time
        rect = self._getCurrentRect()
        angle = self._rect_item.rotation()
        pos   = self._rect_item.pos()
        CropTool.previous_crop_rect = (rect, angle, pos)
        self.accept()

    def batch_crop_all_slots(self):
        """
        Same logic as apply_crop, but loop through every slot in image_manager.
        Each gets rotated + cropped by the same rectangle/angle.
        """
        rc = self._getCurrentRect()
        if not rc or rc.isNull():
            QMessageBox.warning(self, "No Selection", "Draw & finalize a crop first.")
            return

        angle = self._rect_item.rotation()
        img0 = self.original_image_data
        h0, w0 = img0.shape[:2]
        center = (w0/2.0, h0/2.0)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)

        # integer coords
        x, y, w, h = int(rc.x()), int(rc.y()), int(rc.width()), int(rc.height())

        num_slots = sum(1 for im in self.image_manager._images.values() if im is not None)
        if num_slots == 0:
            QMessageBox.information(self, "No Images", "There are no images to crop.")
            return

        reply = QMessageBox.question(
            self, "Confirm Batch Crop",
            f"Apply this same rotated crop to all {num_slots} images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if reply != QMessageBox.StandardButton.Yes:
            return

        any_cropped = False
        for slot, img in self.image_manager._images.items():
            if img is None:
                continue

            # rotate this slot’s image
            rot = cv2.warpAffine(
                img, M, (w0, h0),
                flags=cv2.INTER_LINEAR,
                borderMode=cv2.BORDER_CONSTANT, borderValue=0
            )

            # bounds‐clamp
            x1 = max(0, min(x, w0-1))
            y1 = max(0, min(y, h0-1))
            w1 = max(1, min(w, w0 - x1))
            h1 = max(1, min(h, h0 - y1))

            cropped = rot[y1:y1+h1, x1:x1+w1].copy()

            # push undo / clear redo
            self.image_manager._undo_stacks[slot].append(
                (self.image_manager._images[slot].copy(),
                 self.image_manager._metadata[slot].copy())
            )
            self.image_manager._redo_stacks[slot].clear()

            # save & emit
            self.image_manager._images[slot] = cropped
            self.image_manager.image_changed.emit(
                slot, cropped, self.image_manager._metadata[slot]
            )
            any_cropped = True

        if any_cropped:
            QMessageBox.information(self, "Batch Crop Completed",
                                    f"Successfully cropped {num_slots} images.")
            self.accept()
        else:
            QMessageBox.information(self, "Batch Crop", "No images were cropped.")



class ImageManager(QObject):
    """
    Manages multiple image slots with associated metadata and supports undo/redo operations for each slot.
    Emits a signal whenever an image or its metadata changes.
    """
    
    # Signal emitted when an image or its metadata changes.
    # Parameters:
    # - slot (int): The slot number.
    # - image (np.ndarray): The new image data.
    # - metadata (dict): Associated metadata for the image.
    image_changed = pyqtSignal(int, np.ndarray, dict)
    current_slot_changed = pyqtSignal(int)    

    def __init__(self, max_slots=5, parent=None):
        """
        Initializes the ImageManager with a specified number of slots.
        
        :param max_slots: Maximum number of image slots to manage.
        """
        super().__init__()
        self.parent = parent
        self.max_slots = max_slots
        self._images = {i: None for i in range(max_slots)}
        self._metadata = {i: {} for i in range(max_slots)}
        self._undo_stacks = {i: [] for i in range(max_slots)}
        self._redo_stacks = {i: [] for i in range(max_slots)}
        self.current_slot = 0  # Default to the first slot
        self.active_previews = {}  # Track active preview windows by slot
        self.mask_manager = MaskManager(max_slots)  # Add a MaskManager


    def get_current_image_and_metadata(self):
        slot = self.current_slot
        return self._images[slot], self._metadata[slot]

    def get_mask(self, slot=None):
        """
        Retrieves the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        :return: Mask as numpy array or None.
        """
        if slot is None:
            slot = self.current_slot
        return self.mask_manager.get_mask(slot)

    def set_mask(self, mask, slot=None):
        """
        Sets a mask for the current or specified slot.
        :param mask: Numpy array representing the mask.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.set_mask(slot, mask)

    def clear_mask(self, slot=None):
        """
        Clears the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.clear_mask(slot)        

    def set_current_slot(self, slot):
        if 0 <= slot < self.max_slots:
            self.current_slot = slot
            self.current_slot_changed.emit(slot)
            # Use a non-empty placeholder if the slot is empty
            image_to_emit = self._images[slot] if self._images[slot] is not None and self._images[slot].size > 0 else np.zeros((1, 1), dtype=np.uint8)
            self.image_changed.emit(slot, image_to_emit, self._metadata[slot])
            print(f"ImageManager: Current slot set to {slot}.")
        else:
            print(f"ImageManager: Slot {slot} is out of range.")


    def add_image(self, slot, image, metadata):
        """
        Adds an image and its metadata to a specified slot.
        
        :param slot: The slot number where the image will be added.
        :param image: The image data (numpy array).
        :param metadata: A dictionary containing metadata for the image.
        """
        if 0 <= slot < self.max_slots:
            self._images[slot] = image
            self._metadata[slot] = metadata
            # Clear undo/redo stacks when a new image is added
            self._undo_stacks[slot].clear()
            self._redo_stacks[slot].clear()
            self.current_slot = slot
            self.image_changed.emit(slot, image, metadata)
            print(f"ImageManager: Image added to slot {slot} with metadata.")
        else:
            print(f"ImageManager: Slot {slot} is out of range. Max slots: {self.max_slots}")

    def set_image(self, new_image, metadata, step_name=None):
        slot = self.current_slot
        if self._images[slot] is not None:
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy(), step_name or "Unnamed Step"))
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")
        self._images[slot] = new_image
        self._metadata[slot] = metadata
        self.image_changed.emit(slot, new_image, metadata)
        print(f"ImageManager: Image set for slot {slot} with new metadata.")

        # ⬇ Update undo/redo labels
        if self.parent and hasattr(self.parent, "update_undo_redo_action_labels"):
            self.parent.update_undo_redo_action_labels()


    def set_image_for_slot(self, slot, new_image, metadata, step_name=None):
        """
        Similar to set_image, but allows specifying which slot to update,
        and pushes the previous image to the undo stack.
        """
        if slot < 0 or slot >= self.max_slots:
            print(f"ImageManager: Slot {slot} is out of range. Max slots={self.max_slots}")
            return

        # If there's an existing image in that slot, push it to undo
        if self._images[slot] is not None:
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy(), step_name or "Unnamed Step"))
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")

        # Update the slot with the new image + metadata
        self._images[slot] = new_image
        self._metadata[slot] = metadata

        # Optionally set this slot as current
        self.current_slot = slot

        # Emit the change
        self.image_changed.emit(slot, new_image, metadata)
        print(f"ImageManager: Image set for slot {slot} with new metadata.")

        # Update undo/redo tooltip text if the parent supports it
        if self.parent and hasattr(self.parent, "update_undo_redo_action_labels"):
            self.parent.update_undo_redo_action_labels()


    @property
    def image(self):
        return self._images[self.current_slot]

    @image.setter
    def image(self, new_image):
        """
        Default image setter that stores undo as an unnamed step.
        """
        self.set_image_with_step_name(new_image, self._metadata[self.current_slot], step_name="Unnamed Step")

    def set_image_with_step_name(self, new_image, metadata, step_name="Unnamed Step"):
        """
        Set a new image and metadata for the current slot and push the previous state to the undo stack with a step name.
        
        :param new_image: New image (np.ndarray)
        :param metadata: Metadata dictionary
        :param step_name: Description of the operation
        """
        slot = self.current_slot
        if self._images[slot] is not None:
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), step_name)
            )
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack (step: {step_name})")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")

        self._images[slot] = new_image
        self._metadata[slot] = metadata
        self.image_changed.emit(slot, new_image, metadata)
        print(f"ImageManager: Image set for slot {slot} via set_image_with_step_name.")

        # Update tooltips for undo/redo actions
        if self.parent and hasattr(self.parent, "update_undo_redo_action_labels"):
            self.parent.update_undo_redo_action_labels()


    def get_slot_name(self, slot):
        """
        Returns the display name for a given slot.
        If a slot has been renamed (stored under "slot_name" in metadata), that name is returned.
        Otherwise, it returns "Slot X" (using 1-indexed numbering for display).
        """
        metadata = self._metadata.get(slot, {})
        if 'slot_name' in metadata:
            return metadata['slot_name']
        else:
            return f"Slot {slot + 1}"


    def set_metadata(self, metadata):
        """
        Sets new metadata for the current slot, adding the previous state to the undo stack.
        
        :param metadata: A dictionary containing new metadata.
        """
        slot = self.current_slot
        if self._images[slot] is not None:
            # Save current state to undo stack
            self._undo_stacks[slot].append((self._images[slot].copy(), self._metadata[slot].copy()))
            # Clear redo stack since new action invalidates the redo history
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous metadata in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to set metadata.")
        self._metadata[slot] = metadata
        self.image_changed.emit(slot, self._images[slot], metadata)
        print(f"ImageManager: Metadata set for slot {slot}.")

    def update_image(self, updated_image, metadata=None, slot=None):
        if slot is None:
            slot = self.current_slot


        self._images[slot] = updated_image
        if metadata:
            self._metadata[slot] = metadata
        self.image_changed.emit(slot, updated_image, metadata)

    def can_undo(self, slot=None):
        """
        Determines if there are actions available to undo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if undo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._undo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_undo.")
            return False

    def can_redo(self, slot=None):
        """
        Determines if there are actions available to redo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if redo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._redo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_redo.")
            return False

    def undo(self, slot=None):
        if slot is None:
            slot = self.current_slot

        if 0 <= slot < self.max_slots and self.can_undo(slot):
            self._redo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), "Redo of Previous Step")
            )

            popped = self._undo_stacks[slot].pop()
            if len(popped) == 3:
                prev_img, prev_meta, step_name = popped
            else:
                prev_img, prev_meta = popped
                step_name = "Unnamed Undo Step"

            self._images[slot] = prev_img
            self._metadata[slot] = prev_meta
            self.image_changed.emit(slot, prev_img, prev_meta)

            print(f"ImageManager: Undo performed on slot {slot}: {step_name}")
            return step_name
        else:
            print(f"ImageManager: Cannot perform undo on slot {slot}.")
            return None



    def redo(self, slot=None):
        if slot is None:
            slot = self.current_slot

        if 0 <= slot < self.max_slots and self.can_redo(slot):
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), "Undo of Redone Step")
            )

            popped = self._redo_stacks[slot].pop()
            if len(popped) == 3:
                redo_img, redo_meta, step_name = popped
            else:
                redo_img, redo_meta = popped
                step_name = "Unnamed Redo Step"

            self._images[slot] = redo_img
            self._metadata[slot] = redo_meta
            self.image_changed.emit(slot, redo_img, redo_meta)

            print(f"ImageManager: Redo performed on slot {slot}: {step_name}")
            return step_name
        else:
            print(f"ImageManager: Cannot perform redo on slot {slot}.")
            return None

    def get_history_image(self, slot: int, index: int):
        """
        Get a specific image from the undo stack (not applied, just for preview).
        :param slot: Slot number.
        :param index: Index from the bottom (0 = oldest).
        """
        if 0 <= slot < self.max_slots:
            stack = self._undo_stacks[slot]
            if 0 <= index < len(stack):
                img, meta, _ = stack[index] if len(stack[index]) == 3 else (*stack[index], "Unnamed")
                return img.copy(), meta.copy()
        return None, None

class HistoryExplorerDialog(QDialog):
    def __init__(self, image_manager, slot, parent=None):
        super().__init__(parent)
        self.setWindowTitle(f"History Explorer - Slot {slot}")
        self.image_manager = image_manager
        self.slot = slot

        self.setMinimumSize(600, 400)
        layout = QVBoxLayout(self)

        self.history_list = QListWidget()
        undo_stack = self.image_manager._undo_stacks.get(slot, [])
        self.history_images = []

        # Step history based on undo_stack
        for i in range(len(undo_stack)):
            img, meta = undo_stack[i][:2]

            # Step name is derived from the *next* entry in the stack
            if i == 0:
                label = "1. Original Image"
            else:
                if len(undo_stack[i - 1]) == 3:
                    label = f"{i + 1}. {undo_stack[i - 1][2]}"
                else:
                    label = f"{i + 1}. Unnamed"

            self.history_list.addItem(label)
            self.history_images.append((img, meta))

        # Add the current image as the final step
        current_img = image_manager._images.get(slot)
        current_meta = image_manager._metadata.get(slot, {})
        final_step_name = (
            undo_stack[-1][2] if len(undo_stack) > 0 and len(undo_stack[-1]) == 3 else "Current Image"
        )
        self.history_list.addItem(f"{len(undo_stack)+1}. {final_step_name} (Current)")
        self.history_images.append((current_img, current_meta))

        # Connect interaction
        self.history_list.itemDoubleClicked.connect(self.preview_selected_history_step)
        layout.addWidget(self.history_list)

        # Close button
        self.close_button = QPushButton("Close")
        self.close_button.clicked.connect(self.close)
        layout.addWidget(self.close_button)

    def preview_selected_history_step(self, item):
        row = self.history_list.row(item)

        if 0 <= row < len(self.history_images):
            img, meta = self.history_images[row]
            if img is not None:
                preview = HistoryImagePreview(img, meta, self.slot, image_manager=self.image_manager)
                preview.setWindowTitle(item.text())
                preview.show()
                return

        QMessageBox.warning(self, "Preview Failed", "Could not retrieve image for this step.")

class HistoryImagePreview(QWidget):
    def __init__(self, image_data, metadata, slot, image_manager=None, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        self.setWindowTitle("History Preview")
        self.image_data = image_data
        self.image_manager = image_manager
        self.metadata = metadata
        self.slot = slot
        self.parent_ref = parent
        self.zoom_factor = 1.0
        self.is_autostretched = False
        self.stretched_image_data = None
        self._panning = False
        self._pan_start = QPointF()
        

        # QLabel setup
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.viewport().installEventFilter(self)

        # Zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)
        self.zoom_slider.setValue(100)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        zoom_in = QPushButton("Zoom In")
        zoom_in.clicked.connect(lambda: self.adjust_zoom(10))
        zoom_out = QPushButton("Zoom Out")
        zoom_out.clicked.connect(lambda: self.adjust_zoom(-10))
        fit = QPushButton("Fit to Preview")
        fit.clicked.connect(self.fit_to_preview)

        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.clicked.connect(self.apply_autostretch)

        compare_btn = QPushButton("Compare to Current")
        compare_btn.clicked.connect(self.launch_comparison_slider)

        # Restore Button
        restore_btn = QPushButton("Restore This Version")
        restore_btn.clicked.connect(self.restore_version)

        # Layout
        zoom_layout = QHBoxLayout()
        zoom_layout.addWidget(zoom_out)
        zoom_layout.addWidget(self.zoom_slider)
        zoom_layout.addWidget(zoom_in)
        zoom_layout.addWidget(fit)
        zoom_layout.addWidget(self.autostretch_button)

        main_layout = QVBoxLayout(self)
        main_layout.addWidget(self.scroll_area)
        main_layout.addLayout(zoom_layout)
        main_layout.addWidget(compare_btn)
        main_layout.addWidget(restore_btn)
        self.setLayout(main_layout)

        self.update_image_display()

    def eventFilter(self, source, event):
        if source == self.scroll_area.viewport():
            if (event.type() == QEvent.Type.Wheel and
                    event.modifiers() & Qt.KeyboardModifier.ControlModifier):
                # Ctrl + wheel for zooming
                step = 1.25 if event.angleDelta().y() > 0 else 0.8
                new_zoom = self.zoom_factor * step
                self.zoom_slider.setValue(
                    max(1, min(400, int(new_zoom * 100)))
                )
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseButtonPress and \
                    event.button() == Qt.MouseButton.LeftButton:
                # Start panning
                self._panning = True
                self._pan_start = event.position()
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseMove and self._panning:
                # Pan scrollbars
                delta = event.position() - self._pan_start
                hbar = self.scroll_area.horizontalScrollBar()
                vbar = self.scroll_area.verticalScrollBar()
                hbar.setValue(hbar.value() - int(delta.x()))
                vbar.setValue(vbar.value() - int(delta.y()))
                self._pan_start = event.position()
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseButtonRelease and \
                    event.button() == Qt.MouseButton.LeftButton:
                # End panning
                self._panning = False
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                event.accept()
                return True

        return super().eventFilter(source, event)


    def launch_comparison_slider(self):
        """Open the before/after slider in its own pop‑up."""
        current_img = self.image_manager.image
        if current_img is None:
            QMessageBox.warning(self, "Unavailable",
                                "No current image available.")
            return

        slider_window = QWidget(self, Qt.WindowType.Window)
        slider_window.setWindowTitle("Compare with Current")
        slider_window.resize(900, 700)

        win_layout = QVBoxLayout(slider_window)

        # ---- the slider widget itself ----
        self.slider_widget = ComparisonSlider(self.image_data,
                                            current_img,
                                            slider_window)
        win_layout.addWidget(self.slider_widget)

        # ---- control‑bar (zoom + autostretch) ----
        ctrl_bar = QHBoxLayout()

        zoom_in_btn  = QPushButton("Zoom In")
        zoom_in_btn.clicked.connect(self.slider_widget.zoom_in)
        ctrl_bar.addWidget(zoom_in_btn)

        zoom_out_btn = QPushButton("Zoom Out")
        zoom_out_btn.clicked.connect(self.slider_widget.zoom_out)
        ctrl_bar.addWidget(zoom_out_btn)

        stretch_btn  = QPushButton("Toggle AutoStretch")
        stretch_btn.clicked.connect(self.slider_widget.toggle_autostretch)
        ctrl_bar.addWidget(stretch_btn)

        # (optional) add more buttons later – e.g. blink‑mode toggle
        # blink_btn = QPushButton("Toggle Blink")
        # blink_btn.clicked.connect(self.slider_widget.toggle_blink_mode)
        # ctrl_bar.addWidget(blink_btn)

        # push the buttons to the left and leave the rest empty
        ctrl_bar.addStretch(1)

        win_layout.addLayout(ctrl_bar)

        slider_window.show()


    def restore_version(self):
        """Push this image into the active slot via image manager."""
        if self.image_manager:
            self.image_manager.set_image(
                self.image_data.copy(),
                self.metadata.copy(),
                step_name="Restored from History"
            )
            self.close()
        else:
            QMessageBox.critical(self, "Error", "Parent does not have an image manager.")

    def stretch_image(self, image):
        target_median = 0.25
        if image.ndim == 2:
            return stretch_mono_image(image, target_median)
        elif image.ndim == 3:
            return stretch_color_image(image, target_median, linked=False)
        return image

    def apply_autostretch(self):
        self.is_autostretched = not self.is_autostretched
        if self.is_autostretched:
            self.stretched_image_data = self.stretch_image(self.image_data)
        self.update_image_display()

    def update_image_display(self):
        display_image = self.stretched_image_data if self.is_autostretched else self.image_data
        display_image = np.clip(display_image * 255, 0, 255).astype(np.uint8)

        if display_image.ndim == 2:
            h, w = display_image.shape
            qimg = QImage(display_image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            h, w, _ = display_image.shape
            qimg = QImage(display_image.data, w, h, w * 3, QImage.Format.Format_RGB888)

        pixmap = QPixmap.fromImage(qimg)
        scaled = pixmap.scaled(
            pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled)

    def on_zoom_changed(self, value):
        self.zoom_factor = value / 100.0
        self.update_image_display()

    def adjust_zoom(self, delta):
        self.zoom_slider.setValue(max(1, min(400, self.zoom_slider.value() + delta)))

    def fit_to_preview(self):
        if self.image_label.pixmap() is None:
            return
        available = self.scroll_area.viewport().size()
        pixmap = self.image_label.pixmap()
        if pixmap:
            factor = min(available.width() / pixmap.width(), available.height() / pixmap.height())
            self.zoom_factor = factor
            self.zoom_slider.setValue(int(factor * 100))
            self.update_image_display()

class ComparisonSlider(QWidget):
    def __init__(self, before_image: np.ndarray, after_image: np.ndarray, parent=None):
        super().__init__(parent)
        self.before_image = before_image
        self.after_image = after_image
        self.slider_position = 0.5
        self.zoom_factor = 1.0
        self.autostretch = False
        self.setMouseTracking(True)
        self.setMinimumSize(400, 300)

    def set_zoom_factor(self, zoom):
        self.zoom_factor = max(0.1, min(zoom, 5.0))  # Clamp zoom
        self.update()

    def zoom_in(self):
        self.set_zoom_factor(self.zoom_factor * 1.25)

    @announce_zoom
    def zoom_out(self):
        self.set_zoom_factor(self.zoom_factor / 1.25)

    def toggle_autostretch(self):
        self.autostretch = not self.autostretch
        self.update()

    def paintEvent(self, _ev):
        painter   = QPainter(self)
        W, H      = self.width(), self.height()

        before_q  = self.prepare_image(self.before_image)
        after_q   = self.prepare_image(self.after_image)

        # centre the zoomed image inside the widget
        ox = (W - before_q.width())  // 2
        oy = (H - before_q.height()) // 2

        divider_x = int(W * self.slider_position)

        # ---- LEFT half : BEFORE ------------------------------------
        painter.save()
        painter.setClipRect(0, 0, divider_x, H)
        painter.drawImage(ox, oy, before_q)
        painter.restore()

        # ---- RIGHT half : AFTER ------------------------------------
        painter.save()
        painter.setClipRect(divider_x, 0, W - divider_x, H)
        painter.drawImage(ox, oy, after_q)
        painter.restore()

        # ---- Divider line ------------------------------------------
        painter.setPen(Qt.GlobalColor.red)
        painter.drawLine(divider_x, 0, divider_x, H)

    def mousePressEvent(self, event):
        self.update_slider(event.position().x())

    def mouseMoveEvent(self, event):
        if event.buttons() & Qt.MouseButton.LeftButton:
            self.update_slider(event.position().x())

    def update_slider(self, x):
        self.slider_position = min(max(x / self.width(), 0.0), 1.0)
        self.update()

    def prepare_image(self, image):
        if self.autostretch:
            image = self.stretch_image(image)

        image = np.clip(image * 255, 0, 255).astype(np.uint8)

        if image.ndim == 2:
            h, w = image.shape
            qimg = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            h, w, _ = image.shape
            qimg = QImage(image.data, w, h, w * 3, QImage.Format.Format_RGB888)

        # Apply zoom and scale to widget size
        target_size = QSize(int(self.width() * self.zoom_factor), int(self.height() * self.zoom_factor))
        return qimg.scaled(target_size, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

    def stretch_image(self, image):
        p = np.percentile(image, 99.5)
        return np.clip(image / p, 0, 1)



class MaskManager(QObject):
    """
    Manages masks and tracks whether a mask is applied to the image.
    """
    mask_changed = pyqtSignal(int, np.ndarray)  # Signal to notify mask changes (slot, mask)
    applied_mask_changed = pyqtSignal(int, np.ndarray)  # Signal for applied mask updates

    def __init__(self, max_slots=5):
        super().__init__()
        self.max_slots = max_slots
        self._masks = {i: None for i in range(max_slots)}  # Store masks for each slot
        self.applied_mask_slot = None  # Slot from which the mask is applied
        self.applied_mask = None  # Currently applied mask (numpy array)

    def set_mask(self, slot, mask):
        """
        Sets the mask for a specific slot.
        """
        if 0 <= slot < self.max_slots:
            self._masks[slot] = mask
            self.mask_changed.emit(slot, mask)

    def get_mask(self, slot):
        """
        Retrieves the mask from a specific slot.
        """
        return self._masks.get(slot, None)

    def clear_applied_mask(self):
        """
        Clears the currently applied mask and emits an empty mask.
        """
        self.applied_mask_slot = None
        self.applied_mask = None

        # Emit an empty mask instead of None
        empty_mask = np.zeros((1, 1), dtype=np.uint8)  
        self.applied_mask_changed.emit(-1, empty_mask)  # Signal that no mask is applied

        print("Applied mask cleared.")



    def apply_mask_from_slot(self, slot):
        """
        Applies the mask from the specified slot.
        """
        if slot in self._masks and self._masks[slot] is not None:
            self.applied_mask_slot = slot
            self.applied_mask = self._masks[slot]
            self.applied_mask_changed.emit(slot, self.applied_mask)
            print(f"Mask from slot {slot} applied.")
        else:
            print(f"Mask from slot {slot} cannot be applied (empty).")

    def get_applied_mask(self):
        """
        Retrieves the currently applied mask.
        """
        return self.applied_mask

    def get_applied_mask_slot(self):
        """
        Retrieves the slot from which the currently applied mask originated.
        """
        return self.applied_mask_slot


class MaskSlotPreviewDialog(QDialog):
    """
    Dialog for displaying, zooming, inverting, and applying a mask from a specific slot with scroll bars.
    Automatically closes after saving the mask.
    """
    # Define a custom signal if needed (e.g., to notify the main window)
    mask_applied = pyqtSignal(int, np.ndarray)  # (slot, mask)

    def __init__(self, mask, slot, parent=None):
        super().__init__(parent)
        # If the parent has a 'mask_slot_names' dictionary, use it
        if parent is not None and hasattr(parent, 'mask_slot_names'):
            custom_name = parent.mask_slot_names.get(slot, f"Mask Slot {slot}")
        else:
            custom_name = f"Mask Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.mask = mask.copy()  # The mask to display (ensure a copy is made)
        self.slot = slot  # Mask slot number
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Store reference to the main window
        self.parent_window = parent

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)

        # Action buttons
        action_layout = QHBoxLayout()
        invert_button = QPushButton("Invert Mask")
        invert_button.clicked.connect(self.invert_mask)
        apply_button = QPushButton(f"Apply Mask from Slot {self.slot}")
        apply_button.clicked.connect(self.apply_mask)

        action_layout.addWidget(invert_button)
        action_layout.addWidget(apply_button)

        # Add action buttons to main layout
        main_layout.addLayout(action_layout)

        # Set the layout
        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods
    @announce_zoom
    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def invert_mask(self):
        """
        Inverts the current mask and updates the display and mask slot,
        while preserving the current zoom and scroll positions.
        """
        reply = QMessageBox.question(
            self, 
            "Confirm Inversion", 
            "Are you sure you want to invert the mask?", 
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, 
            QMessageBox.StandardButton.No
        )
        if reply != QMessageBox.StandardButton.Yes:
            return

        try:
            # Invert the mask (assuming the mask is normalized between 0 and 1)
            inverted_mask = 1.0 - self.mask
            print("Mask inversion performed.")
            
            # Update the internal mask and create a new pixmap
            self.mask = inverted_mask.copy()
            self.pixmap = self.convert_to_pixmap(self.mask)
            
            # Call update_image() to rescale and reposition the image, preserving zoom/scroll.
            self.update_image()
            print("Mask display updated with inverted mask while preserving zoom and scroll positions.")
            
            QMessageBox.information(self, "Mask Inverted", "The mask has been successfully inverted.")
            
        except Exception as e:
            QMessageBox.critical(self, "Inversion Failed", f"Failed to invert the mask:\n{e}")
            print(f"Failed to invert the mask: {e}")


    def apply_mask(self):
        """
        Applies the current mask to the parent through the MaskManager.
        Automatically closes the dialog after successful application.
        """
        if not self.parent_window or not hasattr(self.parent_window, "mask_manager"):
            QMessageBox.warning(self, "Error", "Unable to apply mask: Mask Manager not found.")
            return

        # Apply mask from the given slot using apply_mask_from_slot to emit the correct signal
        try:
            self.parent_window.mask_manager.set_mask(self.slot, self.mask)
            self.parent_window.mask_manager.apply_mask_from_slot(self.slot)
            QMessageBox.information(self, "Mask Applied", f"Mask from Slot {self.slot} has been applied successfully.")
            # Emit the custom signal if connected
            self.mask_applied.emit(self.slot, self.mask.copy())
            self.accept()  # Close the dialog
            print(f"Mask from Slot {self.slot} applied and dialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Application Failed", f"Failed to apply mask:\n{e}")
            print(f"Failed to apply mask from Slot {self.slot}: {e}")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            # Schedule fit_to_window to be called after the dialog is fully shown
            QTimer.singleShot(0, self.fit_to_window)
            self.fitted = True

class MaskCreationDialog(QDialog):
    """
    Dialog for creating masks with various types and customizations.
    """

    def __init__(self, image, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Creation")
        self.image = image.copy()  # Original image
        self.mask = None
        self.drawing = False
        self.current_polygon = []
        self.exclusion_polygons = []  # List of drawn polygons
        self.scale_factor = 1.0

        # Initialize parameters
        self.mask_type = "Binary"
        self.blur_amount = 0

        # UI Components
        self.init_ui()

    def init_ui(self):
        # Main Layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Align with XISFViewer
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Image Preview within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.image_pixmap = self.convert_to_pixmap(self.image)
        self.image_label.setPixmap(self.image_pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Enable mouse event handling
        self.image_label.mousePressEvent = self.mouse_press_event
        self.image_label.mouseMoveEvent = self.mouse_move_event
        self.image_label.mouseReleaseEvent = self.mouse_release_event

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)



        # Zoom and Fit-to-Preview Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_preview_button = QPushButton("Fit to Preview")
        fit_to_preview_button.clicked.connect(self.fit_to_preview)
        select_entire_image_button = QPushButton("Select Entire Image")
        select_entire_image_button.clicked.connect(self.select_entire_image)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_preview_button)
        zoom_layout.addWidget(select_entire_image_button)

        # Mask Type Selection
        mask_type_label = QLabel("Select Mask Type:")
        self.mask_type_dropdown = QComboBox()
        self.mask_type_dropdown.addItems([
            "Binary", "Lightness", "Chrominance", "Star Mask",
            "Color: Red", "Color: Orange", "Color: Yellow",
            "Color: Green", "Color: Cyan", "Color: Blue",
            "Color: Magenta"
        ])
        self.mask_type_dropdown.currentTextChanged.connect(self.update_mask_type)

        # Convolution Blur Slider
        blur_layout = QHBoxLayout()
        blur_label = QLabel("Convolution Blur Amount:")
        self.blur_slider = QSlider(Qt.Orientation.Horizontal)
        self.blur_slider.setRange(0, 150)
        self.blur_slider.setValue(0)
        self.blur_slider.valueChanged.connect(self.update_blur_amount)

        # Display the current blur amount
        self.blur_value_label = QLabel("0")  # Initialize with the default value
        self.blur_slider.valueChanged.connect(
            lambda value: self.blur_value_label.setText(str(value))
        )

        blur_layout.addWidget(blur_label)
        blur_layout.addWidget(self.blur_slider)
        blur_layout.addWidget(self.blur_value_label)

        # Buttons
        buttons_layout = QHBoxLayout()
        preview_button = QPushButton("Preview Mask")
        preview_button.clicked.connect(self.preview_mask)

        clear_button = QPushButton("Clear Drawings")
        clear_button.clicked.connect(self.clear_exclusion_areas)

        buttons_layout.addWidget(preview_button)

        buttons_layout.addWidget(clear_button)

        # Add Components to Layout
        controls_layout = QVBoxLayout()
        controls_layout.addWidget(mask_type_label)
        controls_layout.addWidget(self.mask_type_dropdown)
        controls_layout.addLayout(blur_layout)
        controls_layout.addWidget(self.blur_slider)
        controls_layout.addLayout(buttons_layout)

        main_layout.addLayout(zoom_layout)
        main_layout.addLayout(controls_layout)

        self.setLayout(main_layout)
        self.setMinimumSize(800, 500)

    def convert_to_pixmap(self, image):
        """
        Converts a numpy array to QPixmap for display.
        """
        if image.ndim == 3:  # RGB
            h, w, c = image.shape
            image = (image * 255).astype(np.uint8)
            q_image = QImage(image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:  # Grayscale
            h, w = image.shape
            image = (image * 255).astype(np.uint8)
            q_image = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        return QPixmap.fromImage(q_image)

    # Mouse Events for Drawing
    def mouse_press_event(self, event):
        """
        Handles the mouse press event to initiate drawing.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.drawing = True
            adjusted_pos = self.get_adjusted_position(event.position())
            self.current_polygon = [adjusted_pos]
            self.update_selection()

    def mouse_move_event(self, event):
        """
        Handles the mouse move event to update the current polygon being drawn.
        """
        if self.drawing:
            adjusted_pos = self.get_adjusted_position(event.position())
            self.current_polygon.append(adjusted_pos)
            self.update_selection()

    def mouse_release_event(self, event):
        """
        Handles the mouse release event to finalize the polygon.
        """
        if event.button() == Qt.MouseButton.LeftButton and self.drawing:
            self.drawing = False
            adjusted_polygon = QPolygon(self.current_polygon)
            self.exclusion_polygons.append(adjusted_polygon)
            self.current_polygon = []
            self.update_selection()

    def select_entire_image(self):
        """
        Selects the entire image as the mask region.
        """
        self.clear_exclusion_areas()  # Clear existing exclusion areas
        height, width = self.image.shape[:2]
        self.exclusion_polygons.append(
            QPolygon([
                QPoint(0, 0),
                QPoint(width - 1, 0),
                QPoint(width - 1, height - 1),
                QPoint(0, height - 1)
            ])
        )
        self.update_selection()

    def update_selection(self):
        """
        Updates the pixmap with all finalized polygons and the current polygon being drawn,
        preserving the current zoom level.
        """
        # Start with the original pixmap scaled by the current zoom level
        scaled_pixmap = self.image_pixmap.scaled(
            self.image_pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.pixmap = scaled_pixmap.copy()

        painter = QPainter(self.pixmap)

        # Draw all finalized exclusion polygons in semi-transparent green
        pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.SolidLine)
        brush = QColor(0, 255, 0, 50)  # Semi-transparent green
        painter.setPen(pen)
        painter.setBrush(brush)
        for polygon in self.exclusion_polygons:
            # Scale polygon points according to zoom
            scaled_polygon = QPolygon(
                [QPoint(int(point.x() * self.scale_factor), int(point.y() * self.scale_factor)) for point in polygon]
            )
            painter.drawPolygon(scaled_polygon)

        # If currently drawing, draw the current polygon outline in red
        if self.drawing and len(self.current_polygon) > 1:
            pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.setBrush(Qt.BrushStyle.NoBrush)
            scaled_current_polygon = QPolygon(
                [QPoint(int(point.x() * self.scale_factor), int(point.y() * self.scale_factor)) for point in self.current_polygon]
            )
            painter.drawPolyline(scaled_current_polygon)

        painter.end()
        self.image_label.setPixmap(self.pixmap)


    def clear_exclusion_areas(self):
        """
        Clears all drawn exclusion polygons and updates the preview.
        """
        self.exclusion_polygons = []
        self.current_polygon = []
        self.update_selection()

    def update_mask_type(self, mask_type):
        """
        Updates the selected mask type.
        """
        self.mask_type = mask_type

    def update_blur_amount(self, value):
        """
        Updates the blur amount.
        """
        self.blur_amount = value


    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to File", "Save to Mask Slot"],
            0,
            False
        )

        if not ok:  # User canceled the dialog
            return

        if choice == "Save to File":
            # Save to a file
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                save_image(self.mask, filename)
        elif choice == "Save to Mask Slot":
            # Save to a mask slot
            slot, ok = QInputDialog.getInt(
                self,
                "Save to Mask Slot",
                f"Enter slot number (0-{self.parent().mask_manager.max_slots - 1}):",
                0,
                0,
                self.parent().mask_manager.max_slots - 1,
            )
            if ok:
                self.parent().mask_manager.set_mask(slot, self.mask)

    def apply_mask(self):
        """
        Applies the current mask to the parent.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to apply.")
            return
        self.parent().mask_manager.set_mask(0, self.mask)

    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        # Convert the mask to an 8-bit image for display
        mask_8bit = (mask * 255).astype(np.uint8)
        q_image = QImage(
            mask_8bit.data,
            mask_8bit.shape[1],
            mask_8bit.shape[0],
            mask_8bit.strides[0],
            QImage.Format_Grayscale8
        )
        mask_pixmap = QPixmap.fromImage(q_image)
        self.image_label.setPixmap(mask_pixmap)

    # Mask Generation and Preview
    def generate_mask(self):
        """
        Generates a mask based on the current settings and exclusion areas.
        """
        height, width = self.image.shape[:2]
        mask = np.zeros((height, width), dtype=np.float32)  # Start with an empty mask

        # Create the exclusion mask
        exclusion_mask = self.create_exclusion_mask(self.image.shape, self.exclusion_polygons)

        # Apply mask type
        if self.mask_type == "Binary":
            mask[exclusion_mask] = 1.0  # Binary mask for exclusion areas
        elif self.mask_type == "Lightness":
            lightness_mask = self.generate_lightness_mask()
            mask[exclusion_mask] = lightness_mask[exclusion_mask]
        elif self.mask_type == "Chrominance":
            chrominance_mask = self.generate_chrominance_mask()
            mask[exclusion_mask] = chrominance_mask[exclusion_mask]
        elif self.mask_type == "Star Mask":
            # Build a star‐based mask
            # 1) Detect *all* stars over the full image
            full_star_mask = self.create_star_mask(self.image, None)

            # 2) Turn your drawn polygons into an *inclusion* mask
            inclusion_mask = exclusion_mask

            # 3) Only keep stars falling inside the polygons:
            mask[:] = 0.0
            mask[inclusion_mask] = full_star_mask[inclusion_mask]           
        elif self.mask_type.startswith("Color:"):
            color = self.mask_type.split(":")[1].strip()
            color_mask = self.generate_color_mask(color)
            mask[exclusion_mask] = color_mask[exclusion_mask]

        # Apply convolution blur if specified
        if self.blur_amount > 0:
            kernel_size = self.blur_amount * 2 + 1  # Ensure kernel size is odd
            mask = cv2.GaussianBlur(mask, (kernel_size, kernel_size), 0)

        # Normalize the mask to [0, 1] for visualization
        mask = np.clip(mask, 0, 1)
        return mask
    
    def preview_mask(self):
        """
        Previews the mask with the current settings in a new window.
        """
        if not self.exclusion_polygons:
            QMessageBox.warning(self, "No Exclusions", "No exclusion areas have been drawn.")
            return

        # Generate the mask
        mask = self.generate_mask()
        if mask is not None:
            self.mask = mask
            # Open the mask in a new preview dialog
            preview_dialog = MaskPreviewDialog(self.mask, self)
            preview_dialog.exec()
        else:
            QMessageBox.warning(self, "Mask Generation Failed", "Failed to generate the mask.")


    # Mask Creation and Generation Helpers
    def get_adjusted_position(self, event_pos):
        """
        Adjusts the mouse position based on the current zoom level.

        Args:
            event_pos: The position of the mouse event (QPointF).

        Returns:
            QPoint: Adjusted position.
        """
        # Calculate the position relative to the pixmap without adding scroll offsets
        adjusted_x = event_pos.x() / self.scale_factor
        adjusted_y = event_pos.y() / self.scale_factor

        return QPoint(int(adjusted_x), int(adjusted_y))


    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with True in exclusion areas and False elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                x_original = point.x()
                y_original = point.y()
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Fill polygons
        cv2.fillPoly(mask, polygons, 1)  # Fill the polygons with 1
        return mask.astype(bool)
    
    def generate_lightness_mask(self):
        """
        Generates a lightness mask based on the luminance of the image.
        """
        if self.image.ndim == 3:  # RGB image
            luminance = np.dot(self.image[..., :3], [0.2989, 0.5870, 0.1140])
            return luminance
        else:
            return self.image  # Grayscale image

    def generate_color_mask(self, color):
        """
        Generates a mask for a specific color range using the HSL color model.

        Args:
            color: The name of the color (e.g., "Red", "Orange", "Yellow", etc.).
        
        Returns:
            A mask for the selected color range.
        """
        # Define color ranges in HSL (Hue in degrees)
        color_ranges = {
            "Red": [(0, 10), (350, 360)],  # Red spans from 0-10 and 350-360 degrees
            "Orange": [(10, 40)],
            "Yellow": [(40, 70)],
            "Green": [(70, 170)],
            "Cyan": [(170, 200)],
            "Blue": [(200, 270)],
            "Magenta": [(270, 350)],
        }

        if color not in color_ranges:
            QMessageBox.warning(self, "Invalid Color", f"Color '{color}' is not supported.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

        if self.image.ndim == 3:  # RGB image
            # Convert RGB to HSL
            rgb_image = (self.image * 255).astype(np.uint8)
            hsl_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HLS)

            # Extract the Hue channel
            hue = hsl_image[:, :, 0].astype(np.float32)  # Hue is the first channel in OpenCV HLS

            # Normalize hue to [0, 360] for calculations
            hue = (hue / 180) * 360

            # Create the mask for the selected color range
            mask = np.zeros_like(hue, dtype=np.float32)
            for hue_range in color_ranges[color]:
                lower, upper = hue_range
                if lower < upper:
                    mask = np.maximum(mask, ((hue >= lower) & (hue <= upper)).astype(np.float32))
                else:  # Handle wraparound for red (e.g., 350-360 and 0-10)
                    mask = np.maximum(mask, ((hue >= lower) | (hue <= upper)).astype(np.float32))

            return mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Color mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

    def generate_chrominance_mask(self):
        """
        Generates a chrominance mask based on the chroma components of the image.
        """
        if self.image.ndim == 3:  # RGB image
            # Convert RGB to YCbCr color space
            rgb_image = (self.image * 255).astype(np.uint8)
            ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)

            # Extract the Cb and Cr channels
            cb = ycbcr_image[:, :, 1].astype(np.float32) / 255.0
            cr = ycbcr_image[:, :, 2].astype(np.float32) / 255.0

            # Compute the chrominance mask as the sum of the absolute differences from the mean
            cb_mean = np.mean(cb)
            cr_mean = np.mean(cr)
            chrominance_mask = np.sqrt((cb - cb_mean) ** 2 + (cr - cr_mean) ** 2)

            # Normalize the mask to [0, 1] range
            chrominance_mask = (chrominance_mask - np.min(chrominance_mask)) / (
                np.max(chrominance_mask) - np.min(chrominance_mask)
            )
            return chrominance_mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Chrominance mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

    def create_star_mask(self, image, exclusion_mask=None):
        import sep

        # 1) Build a grayscale detection image
        if image.ndim == 3:
            data = (0.2126*image[...,0] + 0.7152*image[...,1] + 0.0722*image[...,2]).astype(np.float32)
        else:
            data = image.astype(np.float32)

        # 2) Background subtraction
        bkg = sep.Background(data)
        data_sub = data - bkg.back()

        # 3) Extract objects
        objects = sep.extract(data_sub, thresh=self.blur_amount or 3.0, err=bkg.globalrms)

        h, w = image.shape[:2]
        star_mask = np.zeros((h, w), dtype=np.float32)

        # define a maximum “true star” radius in pixels
        MAX_RADIUS = 10

        for obj in objects:
            x, y = int(obj['x']), int(obj['y'])
            # use 1.5× the half‐light radius as your mask radius
            raw_radius = max(obj['a'], obj['b']) * 1.5
            radius = int(raw_radius)

            # skip anything that’s too big to be a star
            if radius > MAX_RADIUS:
                continue

            # if we have an exclusion_mask, only accept stars inside it
            if exclusion_mask is not None and not exclusion_mask[y, x]:
                continue

            # draw a filled circle
            cv2.circle(star_mask,
                    center=(x, y),
                    radius=radius,
                    color=1.0,
                    thickness=-1)

        return star_mask


    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        mask_pixmap = self.convert_to_pixmap(mask)
        self.image_label.setPixmap(mask_pixmap)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    # Zoom Methods
    @announce_zoom
    def zoom_in(self):
        """Zoom in on the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_preview(self):
        """Fit the image to the preview area."""
        # Calculate the required scale factor to fit the image within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        img_width = self.image_pixmap.width()
        img_height = self.image_pixmap.height()

        scale_w = viewport_size.width() / img_width
        scale_h = viewport_size.height() / img_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.convert_to_pixmap(self.image).scaled(
            self.image_pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

        # Redraw polygons with the new scale
        self.update_selection()



class MaskPreviewDialog(QDialog):
    """
    Dialog for displaying and zooming the mask with scroll bars.
    """
    
    def __init__(self, mask, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Preview")
        self.mask = mask.copy()  # Ensure a copy is made to prevent unintended side effects
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)
        save_mask_button = QPushButton("Save Mask")
        save_mask_button.clicked.connect(self.save_mask)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)
        main_layout.addWidget(save_mask_button)

        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods
    @announce_zoom
    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to Mask Slot", "Save to File"],
            0,
            False
        )
        if not ok:
            return

        if choice == "Save to File":
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                self.save_image(self.mask, filename)
                QMessageBox.information(self, "Mask Saved", f"Mask saved to {filename}.")
                self.accept()
        elif choice == "Save to Mask Slot":
            # Traverse parent hierarchy until we find the main window with a mask_manager.
            parent = self.parent()
            while parent and not hasattr(parent, 'mask_manager'):
                parent = parent.parent()
            if parent and hasattr(parent, 'mask_manager'):
                slot, ok = QInputDialog.getInt(
                    self,
                    "Save to Mask Slot",
                    f"Enter slot number (0-{parent.mask_manager.max_slots - 1}):",
                    0,
                    0,
                    parent.mask_manager.max_slots - 1,
                )
                if ok:
                    parent.mask_manager.set_mask(slot, self.mask)
                    # ** Update the mask slot toolbar so that the button for this slot shows a blue border **
                    if hasattr(parent, 'update_mask_slot_toolbar_highlight'):
                        parent.update_mask_slot_toolbar_highlight()
                    QMessageBox.information(self, "Mask Saved", f"Mask saved to Slot {slot}.")
                    self.accept()
            else:
                QMessageBox.warning(self, "No Mask Manager", "Parent does not have a mask_manager.")


    def save_image(self, mask, filename):
        """
        Saves the mask to a file.
        """
        # Convert mask to 8-bit for saving
        mask_8bit = (mask * 255).astype(np.uint8)
        # Save using QPixmap
        pixmap = self.convert_to_pixmap(mask)
        pixmap.save(filename)
        print(f"Mask saved to {filename}.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            self.fit_to_window()
            self.fitted = True

class MaskDisplayWindow(QDialog):
    """
    A separate window to display the luminance mask for debugging purposes.
    Includes Zoom In, Zoom Out, and Fit to Preview controls.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Luminance Mask")
        self.setMinimumSize(300, 300)

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the mask display area (QGraphicsView in a scrollable region)
        self._create_mask_display_area()

        # 2) Create the zoom controls
        self._create_zoom_controls()

    # -------------------------------------------------------------------------
    # 1) MASK DISPLAY AREA
    # -------------------------------------------------------------------------
    def _create_mask_display_area(self):
        """Create a QGraphicsView & QGraphicsScene for the mask display."""
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        # Add the graphics view to the main layout
        self.main_layout.addWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) ZOOM CONTROLS
    # -------------------------------------------------------------------------
    def _create_zoom_controls(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_controls_group = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_controls_group.setLayout(zoom_layout)

        # Add the zoom controls to the main layout
        self.main_layout.addWidget(self.zoom_controls_group)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def _zoom_in(self):
        """Zoom in the mask display."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed in to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")
            print("MaskDisplayWindow: Maximum zoom level reached.")

    def _zoom_out(self):
        """Zoom out the mask display."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed out to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")
            print("MaskDisplayWindow: Minimum zoom level reached.")

    def _fit_to_preview(self):
        """Fit the entire mask within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No mask to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0
        print("MaskDisplayWindow: Fitted mask to preview and reset zoom factor to 1.0.")

    def _apply_zoom(self):
        """Apply the current zoom factor to the graphics view."""
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)
        print(f"MaskDisplayWindow: Applied zoom factor of {self.zoom_factor}x.")

    # -------------------------------------------------------------------------
    # MASK UPDATE METHOD
    # -------------------------------------------------------------------------
    def update_mask(self, mask_array):
        """
        Update the mask display with the given mask array.
        
        Args:
            mask_array (np.ndarray): 2D array with values in [0, 1].
        """
        try:
            # Convert mask array to grayscale image [0..255]
            mask_uint8 = (np.clip(mask_array, 0, 1) * 255).astype(np.uint8)

            # Ensure it's single-channel
            if mask_uint8.ndim == 3 and mask_uint8.shape[2] == 3:
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)
            elif mask_uint8.ndim == 2:
                pass  # Already single-channel
            else:
                # Handle unexpected formats
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)

            # Convert to QImage
            h, w = mask_uint8.shape[:2]
            qimage = QImage(
                mask_uint8.data, w, h, w, QImage.Format.Format_Grayscale8
            )
            pixmap = QPixmap.fromImage(qimage)

            # Update the pixmap item
            self.pixmap_item.setPixmap(pixmap)
            self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

            # Reset zoom to fit the new mask
            self._fit_to_preview()

            print("MaskDisplayWindow: Mask updated and fitted to preview.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")
            print(f"MaskDisplayWindow: Error updating mask - {e}")

class HistogramDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        """
        Initialize the histogram dialog.

        Args:
            image_manager (ImageManager): The manager providing the current image.
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Histogram")
        self.image_manager = image_manager
        # Start with the active slot’s image:
        self.image = image_manager.image  # image_manager.image returns the current slot's image.
        self.zoom_factor = 1.0  # 1.0 means 100%
        self.log_scale = False  # Default: linear x-axis
        self.initUI()
        # Connect to the image_changed signal so that the histogram updates when the active slot changes.
        self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Create a horizontal layout to hold the histogram and statistics table.
        top_layout = QHBoxLayout()
        
        # Create a scroll area for the histogram.
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        
        # Create the histogram label.
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)
        
        # Create the statistics table.
        self.stats_table = QTableWidget(self)
        self.stats_table.setRowCount(4)  # Min, Max, Median, StdDev
        self.stats_table.setColumnCount(1)  # Default for mono; updated later if RGB.
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)
        
        main_layout.addLayout(top_layout)
        
        # Controls for zoom and log toggle.
        controls_layout = QHBoxLayout()
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)  # 50% to 1000%
        self.zoom_slider.setValue(100)
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(QLabel("Zoom:"))
        controls_layout.addWidget(self.zoom_slider)
        
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis scaling.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)
        
        main_layout.addLayout(controls_layout)
        
        # Close button.
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        self.drawHistogram()

    def on_image_changed(self, slot, image, metadata):
        # Update the histogram only if the changed slot is the active one.
        if slot == self.image_manager.current_slot:
            self.image = image
            self.drawHistogram()

    def updateHistogram(self, new_image):
        """ Update the histogram with a new image. """
        self.image = new_image
        self.drawHistogram()

    def updateZoom(self, value):
        self.zoom_factor = value / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked):
        self.log_scale = checked
        self.drawHistogram()

    def drawHistogram(self):
        """
        Computes and draws the histogram.
        In linear mode, it uses equally spaced bins.
        In log mode, it uses logarithmically spaced bins (with a small epsilon to avoid log(0)).
        Also draws an x-axis with tick marks and labels.
        """
        # Base dimensions.
        base_width = 512
        height = 300
        width = int(base_width * self.zoom_factor)
        
        # Create a pixmap with the computed dimensions.
        pixmap = QPixmap(width, height)
        pixmap.fill(Qt.GlobalColor.white)
        painter = QPainter(pixmap)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        bin_count = 512
        
        # Choose bin edges based on the log_scale toggle.
        if self.log_scale:
            raw_min = float(np.min(self.image))
            eps     = max(raw_min, 1e-4)   # Cannot start at 0 for log scale.
            self._hist_eps     = eps
            self._hist_log_min = np.log10(eps)
            self._hist_log_max = 0.0  # since log10(1)==0            
            bin_edges = np.logspace(np.log10(eps), 0, bin_count + 1)
            log_min = np.log10(eps)
            log_max = 0  # log10(1)=0
            def x_pos(edge):
                return int((np.log10(edge) - log_min) / (log_max - log_min) * width)
        else:
            bin_edges = np.linspace(0, 1, bin_count + 1)
            def x_pos(edge):
                return int(edge * width)
        
        # Draw histogram bars.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # For RGB images, draw each channel histogram.
            channel_colors = [
                QColor(255, 0, 0, 120),
                QColor(0, 255, 0, 120),
                QColor(0, 0, 255, 120)
            ]
            for ch in range(3):
                hist, _ = np.histogram(self.image[..., ch].ravel(), bins=bin_edges)
                if hist.max() > 0:
                    hist = hist.astype(np.float32) / hist.max()
                else:
                    hist = hist.astype(np.float32)
                painter.setPen(QPen(channel_colors[ch]))
                for i in range(bin_count):
                    x0 = x_pos(bin_edges[i])
                    x1 = x_pos(bin_edges[i+1])
                    bar_width = x1 - x0
                    bar_height = hist[i] * height
                    painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        else:
            # Mono: if image is 3D with one channel, squeeze.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                gray = self.image.squeeze()
            else:
                gray = self.image
            hist, _ = np.histogram(gray.ravel(), bins=bin_edges)
            if hist.max() > 0:
                hist = hist.astype(np.float32) / hist.max()
            else:
                hist = hist.astype(np.float32)
            painter.setPen(QPen(QColor(0, 0, 0)))
            for i in range(bin_count):
                x0 = x_pos(bin_edges[i])
                x1 = x_pos(bin_edges[i+1])
                bar_width = x1 - x0
                bar_height = hist[i] * height
                painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        
        # Draw x-axis.
        painter.setPen(QPen(QColor(0, 0, 0), 2))
        painter.drawLine(0, height - 1, width, height - 1)
        
        # Draw tick marks and labels.
        painter.setFont(QFont("Arial", 10))
        if self.log_scale:
            tick_values = np.logspace(np.log10(eps), 0, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.3f}")
        else:
            tick_values = np.linspace(0, 1, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.1f}")
        
        painter.end()
        self.hist_label.setPixmap(pixmap)
        self.hist_label.resize(pixmap.size())
        
        # Update the statistics table.
        self.updateStatistics()

    def updateStatistics(self):
        """
        Computes statistics for the current image and updates the table.
        For an RGB image, computes per-channel min, max, median, and standard deviation.
        For a mono image, computes statistics for the first channel.
        """
        # Determine if the image is color or mono.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # Color image: 3 columns.
            self.stats_table.setColumnCount(3)
            self.stats_table.setHorizontalHeaderLabels(["R", "G", "B"])
            channels = [self.image[..., i] for i in range(3)]
        else:
            # Mono: 1 column.
            self.stats_table.setColumnCount(1)
            self.stats_table.setHorizontalHeaderLabels(["Gray"])
            # If the image is 3D with 1 channel, squeeze it.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                channels = [self.image.squeeze()]
            else:
                channels = [self.image]
        
        # Compute statistics for each channel.
        stats = {"Min": [], "Max": [], "Median": [], "StdDev": []}
        for ch in channels:
            stats["Min"].append(np.min(ch))
            stats["Max"].append(np.max(ch))
            stats["Median"].append(np.median(ch))
            stats["StdDev"].append(np.std(ch))
        
        # Update the table cells.
        row_labels = ["Min", "Max", "Median", "StdDev"]
        for row, label in enumerate(row_labels):
            for col in range(self.stats_table.columnCount()):
                val = stats[label][col]
                item = QTableWidgetItem(f"{val:.3f}")
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(row, col, item)

# --------------------------------------------------
# Stacking Suite
# --------------------------------------------------
class BatchSettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Set Type, Exposure, and Filter for All Files")

        layout = QVBoxLayout(self)

        # 1) IMAGETYP Combo
        type_layout = QHBoxLayout()
        type_layout.addWidget(QLabel("Image Type (IMAGETYP):"))
        self.type_combo = QComboBox()
        self.type_combo.addItems(["LIGHT", "DARK", "FLAT", "BIAS", "UNKNOWN"])
        type_layout.addWidget(self.type_combo)
        layout.addLayout(type_layout)

        # 2) Exposure Time
        exp_layout = QHBoxLayout()
        exp_layout.addWidget(QLabel("Exposure Time (seconds):"))
        self.exptime_edit = QLineEdit()
        self.exptime_edit.setText("Unknown")  # default
        exp_layout.addWidget(self.exptime_edit)
        layout.addLayout(exp_layout)

        # 3) Filter
        filt_layout = QHBoxLayout()
        filt_layout.addWidget(QLabel("Filter:"))
        self.filter_edit = QLineEdit()
        self.filter_edit.setText("None")  # default
        filt_layout.addWidget(self.filter_edit)
        layout.addLayout(filt_layout)

        # Buttons
        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("OK")
        cancel_btn = QPushButton("Cancel")
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)
        layout.addLayout(btn_layout)

        ok_btn.clicked.connect(self.accept)
        cancel_btn.clicked.connect(self.reject)

        # Final layout
        self.setLayout(layout)

    def get_values(self):
        """
        Returns (imagetyp, exptime_str, filter_str)
        after the dialog is accepted.
        """
        return (
            self.type_combo.currentText(),
            self.exptime_edit.text(),
            self.filter_edit.text()
        )

class ReferenceFrameReviewDialog(QDialog):
    def __init__(self, ref_frame_path, stats, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Reference Frame Review")
        self.ref_frame_path = ref_frame_path
        self.stats = stats  # e.g., {"star_count": 250, "eccentricity": 0.12, "mean": 0.45}
        self.autostretch_enabled = False
        self.original_image = None  # Will store the loaded image array
        self.target_median = self.stats.get("mean", 0.25)
        self.user_choice = None  # Will be set to 'use' or 'select_other'
        self.zoom_factor = 1.0
        self.current_preview_image = None  # Store the image array currently shown in preview

        # For panning functionality
        self._panning = False
        self._last_mouse_pos = QPoint()

        self.initUI()
        self.loadImageArray()  # Load the image into self.original_image
        if self.original_image is not None:
            self.updatePreview(self.original_image)  # Ensure the first image is shown
        if self.original_image is not None:
            QTimer.singleShot(0, self.zoomIn)            


    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Create a scroll area for the preview image
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setMinimumSize(QSize(600, 400))
        self.previewLabel = QLabel("Reference Preview", self)
        self.previewLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.previewLabel)
        main_layout.addWidget(self.scrollArea)
        self.scrollArea.viewport().installEventFilter(self)
        
        # Zoom control buttons
        zoom_layout = QHBoxLayout()
        self.zoomInButton = QPushButton("Zoom In", self)
        self.zoomInButton.clicked.connect(self.zoomIn)
        zoom_layout.addWidget(self.zoomInButton)
        self.zoomOutButton = QPushButton("Zoom Out", self)
        self.zoomOutButton.clicked.connect(self.zoomOut)
        zoom_layout.addWidget(self.zoomOutButton)
        main_layout.addLayout(zoom_layout)
        
        # Stats display
        stats_text = (
            f"Star Count: {self.stats.get('star_count', 'N/A')}\n"
            f"Eccentricity: {self.stats.get('eccentricity', 'N/A'):.4f}\n"
            f"Mean: {self.stats.get('mean', 'N/A'):.4f}"
        )
        self.statsLabel = QLabel(stats_text, self)
        main_layout.addWidget(self.statsLabel)
        
        # Buttons layout for reference selection and autostretch toggle
        button_layout = QHBoxLayout()
        self.toggleAutoStretchButton = QPushButton("Enable Autostretch", self)
        self.toggleAutoStretchButton.clicked.connect(self.toggleAutostretch)
        button_layout.addWidget(self.toggleAutoStretchButton)
        
        # New button to let the user select a new reference frame file
        self.selectNewRefButton = QPushButton("Select New Reference Frame", self)
        self.selectNewRefButton.clicked.connect(self.selectNewReferenceFrame)
        button_layout.addWidget(self.selectNewRefButton)
        
        self.useRefButton = QPushButton("Use This Reference Frame", self)
        self.useRefButton.clicked.connect(self.useReference)
        button_layout.addWidget(self.useRefButton)
        
        self.selectOtherButton = QPushButton("Cancel", self)
        self.selectOtherButton.clicked.connect(self.reject)
        button_layout.addWidget(self.selectOtherButton)
        
        main_layout.addLayout(button_layout)
        self.setLayout(main_layout)
        self.zoomIn()
    
    def fitToPreview(self):
        """Calculate and set the zoom factor so that the image fills the preview area."""
        if self.original_image is None:
            return
        # Get the available size from the scroll area's viewport.
        available_size = self.scrollArea.viewport().size()
        # Determine the original image dimensions.
        if self.original_image.ndim == 2:
            orig_height, orig_width = self.original_image.shape
        elif self.original_image.ndim == 3:
            orig_height, orig_width = self.original_image.shape[:2]
        else:
            return
        # Calculate the zoom factor that will allow the image to fit.
        factor = min(available_size.width() / orig_width,
                    available_size.height() / orig_height)
        self.zoom_factor = factor
        # Choose the current preview image if available, otherwise use the original image.
        if self.current_preview_image is not None:
            image = self.current_preview_image
        else:
            image = self.original_image
        self.updatePreview(image)



    def loadImageArray(self):
        """
        Load the image from the reference frame file using the global load_image function.
        """
        image_data, header, _, _ = load_image(self.ref_frame_path)
        if image_data is not None:
            if image_data.ndim == 3 and image_data.shape[-1] == 1:
                image_data = np.squeeze(image_data, axis=-1)
            self.original_image = image_data
        else:
            QMessageBox.critical(self, "Error", "Failed to load the reference image.")
    
    def updatePreview(self, image):
        """
        Convert a given image array to a QPixmap and update the preview label.
        """
        self.current_preview_image = image
        pixmap = self.convertArrayToPixmap(image)
        if pixmap is None or pixmap.isNull():
            self.previewLabel.setText("Unable to load preview.")
        else:
            available_size = self.scrollArea.viewport().size()
            new_size = QSize(int(available_size.width() * self.zoom_factor),
                             int(available_size.height() * self.zoom_factor))
            scaled_pixmap = pixmap.scaled(new_size, Qt.AspectRatioMode.KeepAspectRatio,
                                          Qt.TransformationMode.SmoothTransformation)
            self.previewLabel.setPixmap(scaled_pixmap)
    
    def convertArrayToPixmap(self, image):
        if image is None:
            return None
        display_image = (image * 255).clip(0, 255).astype(np.uint8)
        if display_image.ndim == 2:
            h, w = display_image.shape
            bytes_per_line = w
            q_image = QImage(display_image.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)
        elif display_image.ndim == 3 and display_image.shape[2] == 3:
            h, w, _ = display_image.shape
            bytes_per_line = 3 * w
            q_image = QImage(display_image.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            return None
        return QPixmap.fromImage(q_image)
    
    def toggleAutostretch(self):
        if self.original_image is None:
            QMessageBox.warning(self, "Error", "Reference image not loaded.")
            return
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            if self.original_image.ndim == 2:
                new_image = stretch_mono_image(self.original_image, target_median=0.3,
                                               normalize=True, apply_curves=False)
            elif self.original_image.ndim == 3 and self.original_image.shape[2] == 3:
                new_image = stretch_color_image(self.original_image, target_median=0.3,
                                                linked=False, normalize=True, apply_curves=False)
            else:
                new_image = self.original_image
            self.toggleAutoStretchButton.setText("Disable Autostretch")
        else:
            new_image = self.original_image
            self.toggleAutoStretchButton.setText("Enable Autostretch")
        self.updatePreview(new_image)
    
    def zoomIn(self):
        self.zoom_factor *= 1.2
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
    
    def zoomOut(self):
        self.zoom_factor /= 1.2
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
    
    def eventFilter(self, source, event):
        if source is self.scrollArea.viewport():
            if event.type() == QEvent.Type.Wheel:
                if event.angleDelta().y() > 0:
                    self.zoomIn()
                else:
                    self.zoomOut()
                return True
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = True
                    self._last_mouse_pos = event.pos()
                    self.scrollArea.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                    return True
            if event.type() == QEvent.Type.MouseMove:
                if self._panning:
                    delta = event.pos() - self._last_mouse_pos
                    self._last_mouse_pos = event.pos()
                    h_bar = self.scrollArea.horizontalScrollBar()
                    v_bar = self.scrollArea.verticalScrollBar()
                    h_bar.setValue(h_bar.value() - delta.x())
                    v_bar.setValue(v_bar.value() - delta.y())
                    return True
            if event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = False
                    self.scrollArea.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                    return True
        return super().eventFilter(source, event)
    
    def resizeEvent(self, event):
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
        super().resizeEvent(event)
    
    def selectNewReferenceFrame(self):
        """Open a file dialog to select a new reference frame, update preview accordingly."""
        new_file, _ = QFileDialog.getOpenFileName(
            self,
            "Select New Reference Frame",
            "",
            "FITS Files (*.fits *.fit);;All Files (*)"
        )
        if new_file:
            self.ref_frame_path = new_file
            self.loadImageArray()          # Reload the new image
            self.updatePreview(self.original_image)  # Update the preview
            # Optionally, you could also update stats if needed.
    
    def useReference(self):
        self.user_choice = "use"
        self.accept()
    
    def selectOtherReference(self):
        self.user_choice = "select_other"
        self.reject()
    
    def getUserChoice(self):
        return self.user_choice

class StackingSuiteDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Stacking Suite")
        self.setGeometry(300, 200, 800, 600)
        self.per_group_drizzle = {}
        self.manual_dark_overrides = {}  
        self.manual_flat_overrides = {}
        self.conversion_output_directory = None
        self.reg_files = {}
        self.session_tags = {}  # 🔑 file_path => session_tag (e.g., "Session1", "Blue Flats", etc.)
        self.deleted_calibrated_files = []

        # QSettings for your app
        self.settings = QSettings() 
        

        # Load or default these
        self.stacking_directory = self.settings.value("stacking/dir", "", type=str)
        self.sigma_high = self.settings.value("stacking/sigma_high", 3.0, type=float)
        self.sigma_low = self.settings.value("stacking/sigma_low", 3.0, type=float)
        self.rejection_algorithm = self.settings.value(
            "stacking/rejection_algorithm",
            "Weighted Windsorized Sigma Clipping",
            type=str
        )
        self.kappa = self.settings.value("stacking/kappa", 2.5, type=float)
        self.iterations = self.settings.value("stacking/iterations", 3, type=int)
        self.esd_threshold = self.settings.value("stacking/esd_threshold", 3.0, type=float)
        self.biweight_constant = self.settings.value("stacking/biweight_constant", 6.0, type=float)
        self.trim_fraction = self.settings.value("stacking/trim_fraction", 0.1, type=float)
        self.modz_threshold = self.settings.value("stacking/modz_threshold", 3.5, type=float)
        self.chunk_height = self.settings.value("stacking/chunk_height", 2048, type=int)
        self.chunk_width = self.settings.value("stacking/chunk_width", 2048, type=int)        

        # Dictionaries to store file paths
        self.conversion_files = {}
        self.dark_files = {}
        self.flat_files = {}
        self.light_files = {}
        self.master_files = {}
        self.master_sizes = {}

        layout = QVBoxLayout(self)
        self.tabs = QTabWidget()
        layout.addWidget(self.tabs)
        self.dir_path_edit = QLineEdit(self.stacking_directory)  # Add this here
        # Create the new Conversion tab.
        self.conversion_tab = self.create_conversion_tab()
        # Existing tabs...
        self.dark_tab = self.create_dark_tab()
        self.flat_tab = self.create_flat_tab()
        self.light_tab = self.create_light_tab()
        self.image_integration_tab = self.create_image_registration_tab()

        # Add the tabs in desired order. (Conversion first)
        self.tabs.addTab(self.conversion_tab, "Convert Non-FITS Formats")
        self.tabs.addTab(self.dark_tab, "Darks")
        self.tabs.addTab(self.flat_tab, "Flats")
        self.tabs.addTab(self.light_tab, "Lights")
        self.tabs.addTab(self.image_integration_tab, "Image Integration")
        self.tabs.setCurrentIndex(1)  # Default to Darks tab

        # Wrench button, status bar, etc.
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))
        self.wrench_button.setToolTip("Set Stacking Directory & Sigma Clipping")
        self.wrench_button.clicked.connect(self.open_stacking_settings)
        self.wrench_button.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        layout.addWidget(self.wrench_button, alignment=Qt.AlignmentFlag.AlignLeft)
        self.setup_status_bar(layout)
        self.tabs.currentChanged.connect(self.on_tab_changed)

    def create_conversion_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.addWidget(QLabel("Batch Convert Files to Debayered FITS (.fit)"))

        # 1) Create the tree
        self.conversion_tree = QTreeWidget()
        self.conversion_tree.setColumnCount(2)
        self.conversion_tree.setHeaderLabels(["File", "Status"])

        # 2) Make columns user-resizable (Interactive)
        header = self.conversion_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After populating the tree, do an initial auto-resize
        self.conversion_tree.resizeColumnToContents(0)
        self.conversion_tree.resizeColumnToContents(1)
        layout.addWidget(self.conversion_tree)

        # Buttons for adding files, adding a directory,
        # selecting an output directory, and clearing the list.
        btn_layout = QHBoxLayout()
        self.add_conversion_files_btn = QPushButton("Add Conversion Files")
        self.add_conversion_files_btn.clicked.connect(self.add_conversion_files)
        self.add_conversion_dir_btn = QPushButton("Add Conversion Directory")
        self.add_conversion_dir_btn.clicked.connect(self.add_conversion_directory)
        self.select_conversion_output_btn = QPushButton("Select Output Directory")
        self.select_conversion_output_btn.clicked.connect(self.select_conversion_output_dir)
        self.clear_conversion_btn = QPushButton("Clear List")
        self.clear_conversion_btn.clicked.connect(self.clear_conversion_list)
        btn_layout.addWidget(self.add_conversion_files_btn)
        btn_layout.addWidget(self.add_conversion_dir_btn)
        btn_layout.addWidget(self.select_conversion_output_btn)
        btn_layout.addWidget(self.clear_conversion_btn)
        layout.addLayout(btn_layout)

        # Convert All button (converts all files in the tree).
        self.convert_btn = QPushButton("Convert All Files to FITS")
        self.convert_btn.clicked.connect(self.convert_all_files)
        layout.addWidget(self.convert_btn)

        return tab

    def add_conversion_files(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files for Conversion", last_dir,
                                                "Supported Files (*.fits *.fit *.fz *.fz *.fits.gz *.fit.gz *.tiff *.tif *.png *.jpg *.jpeg *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef *.xisf)")
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            for file in files:
                item = QTreeWidgetItem([os.path.basename(file), "Pending"])
                item.setData(0, 1000, file)  # store full path in role 1000
                self.conversion_tree.addTopLevelItem(item)

    def add_conversion_directory(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, "Select Directory for Conversion", last_dir)
        if directory:
            self.settings.setValue("last_opened_folder", directory)
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit", ".fz", ".fz", ".fit.gz", ".fits.gz", ".tiff", ".tif", ".png", ".jpg", ".jpeg", 
                                           ".cr2", ".cr3", ".nef", ".arw", ".dng", ".orf", ".rw2", ".pef", ".xisf")):
                    full_path = os.path.join(directory, file)
                    item = QTreeWidgetItem([file, "Pending"])
                    item.setData(0, 1000, full_path)
                    self.conversion_tree.addTopLevelItem(item)

    def select_conversion_output_dir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Conversion Output Directory")
        if directory:
            self.conversion_output_directory = directory
            self.update_status(f"Conversion output directory set to: {directory}")

    def clear_conversion_list(self):
        self.conversion_tree.clear()
        self.update_status("Conversion list cleared.")

    def convert_all_files(self):
        # If no output directory is set, ask the user if they want to set it now.
        if not self.conversion_output_directory:
            reply = QMessageBox.question(
                self,
                "No Output Directory",
                "No output directory is set. Do you want to select one now?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if reply == QMessageBox.StandardButton.Yes:
                self.select_conversion_output_dir()  # Let them pick a folder
            else:
                # They chose 'No' → just stop
                return

            # If it's still empty after that, bail out
            if not self.conversion_output_directory:
                QMessageBox.warning(self, "No Output Directory", "Please select a conversion output directory first.")
                return

        count = self.conversion_tree.topLevelItemCount()
        if count == 0:
            QMessageBox.information(self, "No Files", "There are no files to convert.")
            return

        # 1) Show the batch settings dialog
        dialog = BatchSettingsDialog(self)
        result = dialog.exec()
        if result == int(QDialog.DialogCode.Rejected):
            # user canceled
            return
        # user pressed OK => get the values
        imagetyp_user, exptime_user, filter_user = dialog.get_values()

        for i in range(count):
            item = self.conversion_tree.topLevelItem(i)
            file_path = item.data(0, 1000)
            result = load_image(file_path)
            if result[0] is None:
                item.setText(1, "Failed to load")
                self.update_status(f"Failed to load {os.path.basename(file_path)}")
                continue

            image, header, bit_depth, is_mono = result

            if image is None:
                item.setText(1, "Failed to load")
                self.update_status(f"Failed to load {os.path.basename(file_path)}")
                continue

            # 🔹 If the file has no header (TIFF, PNG, JPG, etc.), create a minimal one
            if header is None:
                header = fits.Header()
                header["SIMPLE"]   = True
                header["BITPIX"]   = 16  # Or 16, depending on your preference
                header["CREATOR"]  = "SetiAstroSuite"
                header["IMAGETYP"] = "UNKNOWN"  # We'll set it properly below
                header["EXPTIME"]  = "Unknown"  # Just a placeholder
                # You can add more default keywords as needed

            # Debayer if needed:
            image = self.debayer_image(image, file_path, header)
            if image.ndim == 3:
                is_mono = False

            # If it's a RAW format, definitely treat as color
            if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                is_mono = False

                # Try extracting EXIF metadata
                try:
                    import exifread
                    with open(file_path, 'rb') as f:
                        tags = exifread.process_file(f, details=False)

                    exptime_tag = tags.get("EXIF ExposureTime")  # e.g. "1/125"
                    iso_tag = tags.get("EXIF ISOSpeedRatings")
                    date_obs_tag = tags.get("EXIF DateTimeOriginal")

                    # Create or replace with a fresh header, but keep some existing fields if desired
                    new_header = fits.Header()
                    new_header['SIMPLE'] = True
                    new_header['BITPIX'] = 16
                    new_header['IMAGETYP'] = header.get('IMAGETYP', "UNKNOWN")

                    # Attempt to parse exptime. If fraction or numeric fails, store 'Unknown'.
                    if exptime_tag:
                        exptime_str = str(exptime_tag.values)  # or exptime_tag.printable
                        # Attempt fraction or float
                        try:
                            if '/' in exptime_str:  
                                # e.g. "1/125"
                                top, bot = exptime_str.split('/', 1)
                                fexp = float(top) / float(bot)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                            else:
                                # e.g. "0.008" or "8"
                                fexp = float(exptime_str)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                        except (ValueError, ZeroDivisionError):
                            new_header['EXPTIME'] = 'Unknown'
                    # If no exptime_tag, set Unknown
                    else:
                        new_header['EXPTIME'] = 'Unknown'

                    if iso_tag:
                        new_header['ISO'] = str(iso_tag.values)
                    if date_obs_tag:
                        new_header['DATE-OBS'] = str(date_obs_tag.values)

                    # Replace old header with new
                    header = new_header

                except Exception as e:
                    # If exif extraction fails for any reason, we just keep the existing header
                    # but ensure we set EXPTIME if missing
                    self.update_status(f"Warning: Failed to extract RAW header from {os.path.basename(file_path)}: {e}")

            header['IMAGETYP'] = imagetyp_user
            header['FILTER'] = filter_user

            # For exptime_user, try to parse float or fraction
            try:
                if '/' in exptime_user:
                    top, bot = exptime_user.split('/', 1)
                    exptime_val = float(top) / float(bot)
                    header['EXPTIME'] = (exptime_val, "User-specified exposure (s)")
                else:
                    exptime_val = float(exptime_user)
                    header['EXPTIME'] = (exptime_val, "User-specified exposure (s)")
            except (ValueError, ZeroDivisionError):
                # If user typed "Unknown" or something non-numeric
                header['EXPTIME'] = exptime_user

            # Remove any existing NAXIS keywords
            for key in ["NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
                header.pop(key, None)

            if image.ndim == 2:
                header['NAXIS'] = 2
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
            elif image.ndim == 3:
                header['NAXIS'] = 3
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
                header['NAXIS3'] = image.shape[2]

            # -- Ensure EXPTIME is defined --
            if 'EXPTIME' not in header:
                # If the camera or exif didn't provide it, we set it to 'Unknown'
                header['EXPTIME'] = 'Unknown'

            # Build output filename and save
            base = os.path.basename(file_path)
            name, _ = os.path.splitext(base)
            output_filename = os.path.join(self.conversion_output_directory, f"{name}.fit")
            image=image/np.max(image)

            try:
                save_image(
                    img_array=image,
                    filename=output_filename,
                    original_format="fit",
                    bit_depth="16-bit",
                    original_header=header,
                    is_mono=is_mono
                )
                item.setText(1, "Converted")
                self.update_status(
                    f"Converted {os.path.basename(file_path)} to FITS with "
                    f"IMAGETYP={header['IMAGETYP']}, EXPTIME={header['EXPTIME']}."
                )
            except Exception as e:
                item.setText(1, f"Error: {e}")
                self.update_status(f"Error converting {os.path.basename(file_path)}: {e}")

            QApplication.processEvents()

        self.update_status("Conversion complete.")



    def debayer_image(self, image, file_path, header):
        if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            print(f"Debayering RAW image: {file_path}")
            return debayer_raw_fast(image)
        elif file_path.lower().endswith(('.fits', '.fit', '.fz')):
            bayer_pattern = header.get('BAYERPAT')
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                return debayer_fits_fast(image, bayer_pattern)
        return image

    def setup_status_bar(self, layout):
        """ Sets up a scrollable status log at the bottom of the UI. """
        self.status_text = QTextEdit()
        self.status_text.setReadOnly(True)
        self.status_text.setMaximumHeight(100)  # Limits visible lines (~5 lines)
        self.status_text.setStyleSheet("background-color: black; color: white; font-family: Monospace; padding: 4px;")
        
        # Wrap in a scroll area for scrolling
        self.status_scroll = QScrollArea()
        self.status_scroll.setWidgetResizable(True)
        self.status_scroll.setWidget(self.status_text)
        
        # Add to the main layout
        layout.addWidget(self.status_scroll)

    def update_status(self, message):
        old_state = self.status_text.blockSignals(True)
        self.status_text.append(message)
        self.status_text.verticalScrollBar().setValue(
            self.status_text.verticalScrollBar().maximum()
        )
        self.status_text.blockSignals(old_state)


    def open_stacking_settings(self):
        """ Opens a dialog to set the stacking directory, sigma values, rejection algorithm, and algorithm parameters. """
        dialog = QDialog(self)
        dialog.setWindowTitle("Stacking Settings")
        layout = QVBoxLayout(dialog)

        # Stacking directory selection
        dir_layout = QHBoxLayout()
        dir_label = QLabel("Stacking Directory:")
        self.dir_path_edit = QLineEdit(self.stacking_directory)
        dir_button = QPushButton("Browse")
        dir_button.clicked.connect(self.select_stacking_directory)
        dir_layout.addWidget(dir_label)
        dir_layout.addWidget(self.dir_path_edit)
        dir_layout.addWidget(dir_button)
        layout.addLayout(dir_layout)

        # Sigma High & Low settings
        sigma_layout = QHBoxLayout()
        sigma_layout.addWidget(QLabel("Sigma High:"))
        self.sigma_high_spinbox = QDoubleSpinBox()
        self.sigma_high_spinbox.setRange(0.1, 10.0)
        self.sigma_high_spinbox.setDecimals(2)
        self.sigma_high_spinbox.setValue(self.sigma_high)
        sigma_layout.addWidget(self.sigma_high_spinbox)
        sigma_layout.addWidget(QLabel("Sigma Low:"))
        self.sigma_low_spinbox = QDoubleSpinBox()
        self.sigma_low_spinbox.setRange(0.1, 10.0)
        self.sigma_low_spinbox.setDecimals(2)
        self.sigma_low_spinbox.setValue(self.sigma_low)
        sigma_layout.addWidget(self.sigma_low_spinbox)
        layout.addLayout(sigma_layout)

        chunk_layout = QHBoxLayout()
        chunk_layout.addWidget(QLabel("Chunk Height:"))
        self.chunkHeightSpinBox = QSpinBox()
        self.chunkHeightSpinBox.setRange(128, 8192)  # or whatever range you want
        self.chunkHeightSpinBox.setValue(self.settings.value("stacking/chunk_height", 2048, type=int))
        chunk_layout.addWidget(self.chunkHeightSpinBox)

        chunk_layout.addWidget(QLabel("Chunk Width:"))
        self.chunkWidthSpinBox = QSpinBox()
        self.chunkWidthSpinBox.setRange(128, 8192)
        self.chunkWidthSpinBox.setValue(self.settings.value("stacking/chunk_width", 2048, type=int))
        chunk_layout.addWidget(self.chunkWidthSpinBox)

        layout.addLayout(chunk_layout)

        # Rejection algorithm selection
        algo_layout = QHBoxLayout()
        algo_label = QLabel("Rejection Algorithm:")
        self.rejection_algo_combo = QComboBox()
        self.rejection_algo_combo.addItems([
            "Weighted Windsorized Sigma Clipping",
            "Kappa-Sigma Clipping",
            "Simple Average (No Rejection)",
            "Simple Median (No Rejection)",
            "Trimmed Mean",
            "Extreme Studentized Deviate (ESD)",
            "Biweight Estimator",
            "Modified Z-Score Clipping"
        ])
        saved_algo = self.settings.value("stacking/rejection_algorithm", "Weighted Windsorized Sigma Clipping")
        index = self.rejection_algo_combo.findText(saved_algo)
        if index >= 0:
            self.rejection_algo_combo.setCurrentIndex(index)
        algo_layout.addWidget(algo_label)
        algo_layout.addWidget(self.rejection_algo_combo)
        layout.addLayout(algo_layout)

        # --- Additional Parameters ---

        # Kappa-Sigma Clipping: Kappa Value
        kappa_layout = QHBoxLayout()
        kappa_label = QLabel("Kappa Value:")
        self.kappa_spinbox = QDoubleSpinBox()
        self.kappa_spinbox.setRange(0.1, 10.0)
        self.kappa_spinbox.setDecimals(2)
        self.kappa_spinbox.setValue(self.settings.value("stacking/kappa", 2.5, type=float))
        kappa_help = QPushButton("?")
        kappa_help.setFixedSize(20, 20)
        kappa_help.clicked.connect(lambda: QMessageBox.information(self, "Kappa Value", 
            "Kappa determines how many standard deviations away from the median are considered outliers. Higher values are more lenient."))
        kappa_layout.addWidget(kappa_label)
        kappa_layout.addWidget(self.kappa_spinbox)
        kappa_layout.addWidget(kappa_help)
        layout.addLayout(kappa_layout)

        # Kappa-Sigma Clipping: Iterations
        iterations_layout = QHBoxLayout()
        iterations_label = QLabel("Iterations:")
        self.iterations_spinbox = QSpinBox()
        self.iterations_spinbox.setRange(1, 10)
        self.iterations_spinbox.setValue(self.settings.value("stacking/iterations", 3, type=int))
        iterations_help = QPushButton("?")
        iterations_help.setFixedSize(20, 20)
        iterations_help.clicked.connect(lambda: QMessageBox.information(self, "Iterations", 
            "The number of iterations to perform kappa-sigma clipping. More iterations may remove more outliers."))
        iterations_layout.addWidget(iterations_label)
        iterations_layout.addWidget(self.iterations_spinbox)
        iterations_layout.addWidget(iterations_help)
        layout.addLayout(iterations_layout)

        # ESD: ESD Threshold
        esd_layout = QHBoxLayout()
        esd_label = QLabel("ESD Threshold:")
        self.esd_spinbox = QDoubleSpinBox()
        self.esd_spinbox.setRange(0.1, 10.0)
        self.esd_spinbox.setDecimals(2)
        self.esd_spinbox.setValue(self.settings.value("stacking/esd_threshold", 3.0, type=float))
        esd_help = QPushButton("?")
        esd_help.setFixedSize(20, 20)
        esd_help.clicked.connect(lambda: QMessageBox.information(self, "ESD Threshold", 
            "Threshold for the Extreme Studentized Deviate test. Lower values are more aggressive in rejecting outliers."))
        esd_layout.addWidget(esd_label)
        esd_layout.addWidget(self.esd_spinbox)
        esd_layout.addWidget(esd_help)
        layout.addLayout(esd_layout)

        # Biweight Estimator: Tuning Constant
        biweight_layout = QHBoxLayout()
        biweight_label = QLabel("Biweight Tuning Constant:")
        self.biweight_spinbox = QDoubleSpinBox()
        self.biweight_spinbox.setRange(1.0, 10.0)
        self.biweight_spinbox.setDecimals(2)
        self.biweight_spinbox.setValue(self.settings.value("stacking/biweight_constant", 6.0, type=float))
        biweight_help = QPushButton("?")
        biweight_help.setFixedSize(20, 20)
        biweight_help.clicked.connect(lambda: QMessageBox.information(self, "Biweight Tuning Constant", 
            "Tuning constant for the biweight estimator; it controls the aggressiveness of down-weighting outliers."))
        biweight_layout.addWidget(biweight_label)
        biweight_layout.addWidget(self.biweight_spinbox)
        biweight_layout.addWidget(biweight_help)
        layout.addLayout(biweight_layout)

        # Trimmed Mean: Trim Fraction
        trim_layout = QHBoxLayout()
        trim_label = QLabel("Trim Fraction:")
        self.trim_spinbox = QDoubleSpinBox()
        self.trim_spinbox.setRange(0.0, 0.5)
        self.trim_spinbox.setDecimals(2)
        self.trim_spinbox.setValue(self.settings.value("stacking/trim_fraction", 0.1, type=float))
        trim_help = QPushButton("?")
        trim_help.setFixedSize(20, 20)
        trim_help.clicked.connect(lambda: QMessageBox.information(self, "Trim Fraction", 
            "Fraction of values to trim from each end before averaging. For example, 0.1 will trim 10% from each end."))
        trim_layout.addWidget(trim_label)
        trim_layout.addWidget(self.trim_spinbox)
        trim_layout.addWidget(trim_help)
        layout.addLayout(trim_layout)

        # Modified Z-Score Clipping: Threshold
        modz_layout = QHBoxLayout()
        modz_label = QLabel("Modified Z-Score Threshold:")
        self.modz_spinbox = QDoubleSpinBox()
        self.modz_spinbox.setRange(0.1, 10.0)
        self.modz_spinbox.setDecimals(2)
        self.modz_spinbox.setValue(self.settings.value("stacking/modz_threshold", 3.5, type=float))
        modz_help = QPushButton("?")
        modz_help.setFixedSize(20, 20)
        modz_help.clicked.connect(lambda: QMessageBox.information(self, "Modified Z-Score Threshold", 
            "Threshold for the modified z-score clipping using the median absolute deviation. Lower values are more aggressive."))
        modz_layout.addWidget(modz_label)
        modz_layout.addWidget(self.modz_spinbox)
        modz_layout.addWidget(modz_help)
        layout.addLayout(modz_layout)

        # Save button
        save_button = QPushButton("Save Settings")
        save_button.clicked.connect(lambda: self.save_stacking_settings(dialog))
        layout.addWidget(save_button)

        dialog.exec()

    def save_stacking_settings(self, dialog):
        """ Saves stacking directory, sigma values, rejection algorithm, and algorithm parameters to QSettings. """
        self.stacking_directory = self.dir_path_edit.text()
        self.sigma_high = self.sigma_high_spinbox.value()
        self.sigma_low = self.sigma_low_spinbox.value()
        self.rejection_algorithm = self.rejection_algo_combo.currentText()
        self.kappa = self.kappa_spinbox.value()
        self.iterations = self.iterations_spinbox.value()
        self.esd_threshold = self.esd_spinbox.value()
        self.biweight_constant = self.biweight_spinbox.value()
        self.trim_fraction = self.trim_spinbox.value()
        self.modz_threshold = self.modz_spinbox.value()
        self.chunk_height = self.chunkHeightSpinBox.value()
        self.chunk_width = self.chunkWidthSpinBox.value()

        # Store in QSettings
        self.settings.setValue("stacking/dir", self.stacking_directory)
        self.settings.setValue("stacking/sigma_high", self.sigma_high)
        self.settings.setValue("stacking/sigma_low", self.sigma_low)
        self.settings.setValue("stacking/rejection_algorithm", self.rejection_algorithm)
        self.settings.setValue("stacking/kappa", self.kappa)
        self.settings.setValue("stacking/iterations", self.iterations)
        self.settings.setValue("stacking/esd_threshold", self.esd_threshold)
        self.settings.setValue("stacking/biweight_constant", self.biweight_constant)
        self.settings.setValue("stacking/trim_fraction", self.trim_fraction)
        self.settings.setValue("stacking/modz_threshold", self.modz_threshold)
        self.settings.setValue("stacking/chunk_height", self.chunk_height)
        self.settings.setValue("stacking/chunk_width", self.chunk_width)

        print(f"✅ Saved settings - Directory: {self.stacking_directory}, Sigma High: {self.sigma_high}, Sigma Low: {self.sigma_low}, Algorithm: {self.rejection_algorithm}")
        print(f"    Kappa: {self.kappa}, Iterations: {self.iterations}, ESD Threshold: {self.esd_threshold}, Biweight Constant: {self.biweight_constant}, Trim Fraction: {self.trim_fraction}, Modified Z-Score Threshold: {self.modz_threshold}")
        self.update_status("✅ Saved stacking settings.")
        dialog.accept()

    def select_stacking_directory(self):
        """ Opens a dialog to choose a stacking directory. """
        directory = QFileDialog.getExistingDirectory(self, "Select Stacking Directory")
        if directory:
            self.stacking_directory = directory
            self.dir_path_edit.setText(directory)  # No more AttributeError
            self.settings.setValue("stacking/dir", directory)  # Save the new directory


    def create_dark_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Vertical layout to separate sections

        # --- DARK FRAMES TREEBOX (TOP) ---
        darks_layout = QHBoxLayout()  # Left = Dark Tree, Right = Controls

        # Left Side - Dark Frames
        dark_frames_layout = QVBoxLayout()
        dark_frames_layout.addWidget(QLabel("Dark Frames"))
        # 1) Create the tree
        self.dark_tree = QTreeWidget()
        self.dark_tree.setColumnCount(2)
        self.dark_tree.setHeaderLabels(["Exposure Time", "Metadata"])
        self.dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # 2) Make columns user-resizable
        header = self.dark_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After you fill the tree with items, auto-resize
        self.dark_tree.resizeColumnToContents(0)
        self.dark_tree.resizeColumnToContents(1)

        # Then add it to the layout
        dark_frames_layout.addWidget(self.dark_tree)

        # Buttons to Add Dark Files & Directories
        btn_layout = QHBoxLayout()
        self.add_dark_files_btn = QPushButton("Add Dark Files")
        self.add_dark_files_btn.clicked.connect(self.add_dark_files)
        self.add_dark_dir_btn = QPushButton("Add Dark Directory")
        self.add_dark_dir_btn.clicked.connect(self.add_dark_directory)
        btn_layout.addWidget(self.add_dark_files_btn)
        btn_layout.addWidget(self.add_dark_dir_btn)
        dark_frames_layout.addLayout(btn_layout)

        self.clear_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_dark_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.dark_tree, self.dark_files))
        dark_frames_layout.addWidget(self.clear_dark_selection_btn)

        darks_layout.addLayout(dark_frames_layout, 2)  # Dark Frames Tree takes more space


        # --- RIGHT SIDE: Exposure Tolerance & Master Darks Button ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.exposure_tolerance_spinbox = QSpinBox()
        self.exposure_tolerance_spinbox.setRange(0, 30)  # Acceptable range
        self.exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)

        # --- "Turn Those Darks Into Master Darks" Button ---
        self.create_master_dark_btn = QPushButton("Turn Those Darks Into Master Darks")
        self.create_master_dark_btn.clicked.connect(self.create_master_dark)

        # Apply a bold font, padding, and a highlighted effect
        self.create_master_dark_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)

        right_controls_layout.addWidget(self.create_master_dark_btn)


        darks_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(darks_layout)

        # --- MASTER DARKS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Darks"))
        self.master_dark_tree = QTreeWidget()
        self.master_dark_tree.setColumnCount(2)
        self.master_dark_tree.setHeaderLabels(["Exposure Time", "Master File"])
        self.master_dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        main_layout.addWidget(self.master_dark_tree)

        # Master Dark Selection Button
        self.master_dark_btn = QPushButton("Load Master Dark")
        self.master_dark_btn.clicked.connect(self.load_master_dark)
        main_layout.addWidget(self.master_dark_btn)

        # Add "Clear Selection" button for Master Darks
        self.clear_master_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_master_dark_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.master_dark_tree))
        main_layout.addWidget(self.clear_master_dark_selection_btn)

        return tab



    def create_flat_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Main layout to organize sections

        # --- FLAT FRAMES TREEBOX (TOP) ---
        flats_layout = QHBoxLayout()  # Left = Flat Tree, Right = Controls

        # Left Side - Flat Frames
        flat_frames_layout = QVBoxLayout()
        flat_frames_layout.addWidget(QLabel("Flat Frames"))

        self.flat_tree = QTreeWidget()
        self.flat_tree.setColumnCount(3)  # Added 3rd column for Master Dark Used
        self.flat_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark Used"])
        self.flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.flat_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.flat_tree.customContextMenuRequested.connect(self.flat_tree_context_menu)
        flat_frames_layout.addWidget(self.flat_tree)

        # Buttons to Add Flat Files & Directories
        btn_layout = QHBoxLayout()
        self.add_flat_files_btn = QPushButton("Add Flat Files")
        self.add_flat_files_btn.clicked.connect(self.add_flat_files)
        self.add_flat_dir_btn = QPushButton("Add Flat Directory")
        self.add_flat_dir_btn.clicked.connect(self.add_flat_directory)
        btn_layout.addWidget(self.add_flat_files_btn)
        btn_layout.addWidget(self.add_flat_dir_btn)
        flat_frames_layout.addLayout(btn_layout)
        # 🔧 Session Tag Hint
        session_hint_label = QLabel("Right Click to Assign Session Keys if desired")
        session_hint_label.setStyleSheet("color: #888; font-style: italic; font-size: 11px; margin-left: 4px;")
        flat_frames_layout.addWidget(session_hint_label)

        # Add "Clear Selection" button for Flat Frames
        self.clear_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_flat_selection_btn.clicked.connect(lambda: self.clear_tree_selection_flat(self.flat_tree, self.flat_files))
        flat_frames_layout.addWidget(self.clear_flat_selection_btn)

        flats_layout.addLayout(flat_frames_layout, 2)  # Left side takes more space

        # --- RIGHT SIDE: Exposure Tolerance & Master Dark Selection ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.flat_exposure_tolerance_spinbox = QSpinBox()
        self.flat_exposure_tolerance_spinbox.setRange(0, 30)  # Allow ±0 to 30 seconds
        self.flat_exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.flat_exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)
        self.flat_exposure_tolerance_spinbox.valueChanged.connect(self.rebuild_flat_tree)


        # Auto-Select Master Dark
        self.auto_select_dark_checkbox = QCheckBox("Auto-Select Closest Master Dark")
        self.auto_select_dark_checkbox.setChecked(True)  # Default enabled
        right_controls_layout.addWidget(self.auto_select_dark_checkbox)

        # Manual Override: Select a Master Dark
        self.override_dark_combo = QComboBox()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.currentIndexChanged.connect(self.override_selected_master_dark)
        right_controls_layout.addWidget(QLabel("Override Master Dark Selection"))
        right_controls_layout.addWidget(self.override_dark_combo)

        self.create_master_flat_btn = QPushButton("Turn Those Flats Into Master Flats")
        self.create_master_flat_btn.clicked.connect(self.create_master_flat)

        # Apply a bold font, padding, and a glowing effect
        self.create_master_flat_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)


        right_controls_layout.addWidget(self.create_master_flat_btn)

        flats_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(flats_layout)

        # --- MASTER FLATS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Flats"))
        self.master_flat_tree = QTreeWidget()
        self.master_flat_tree.setColumnCount(2)
        self.master_flat_tree.setHeaderLabels(["Filter", "Master File"])
        self.master_flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        
        main_layout.addWidget(self.master_flat_tree)

        # Master Flat Selection Button
        self.master_flat_btn = QPushButton("Load Master Flat")
        self.master_flat_btn.clicked.connect(self.load_master_flat)
        main_layout.addWidget(self.master_flat_btn)

        self.clear_master_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_master_flat_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.master_flat_tree))
        main_layout.addWidget(self.clear_master_flat_selection_btn)
        return tab

    def flat_tree_context_menu(self, position):
        item = self.flat_tree.itemAt(position)
        if item:
            menu = QMenu()
            set_session_action = menu.addAction("Set Session Tag")
            action = menu.exec(self.flat_tree.viewport().mapToGlobal(position))
            if action == set_session_action:
                self.prompt_set_session(item, "flat")

    def create_light_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # Tree widget for light frames
        self.light_tree = QTreeWidget()
        self.light_tree.setColumnCount(5)  # Added columns for Master Dark and Flat
        self.light_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark", "Master Flat", "Corrections"])
        self.light_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        layout.addWidget(QLabel("Light Frames"))
        layout.addWidget(self.light_tree)

        # Buttons for adding files and directories
        btn_layout = QHBoxLayout()
        self.add_light_files_btn = QPushButton("Add Light Files")
        self.add_light_files_btn.clicked.connect(self.add_light_files)
        self.add_light_dir_btn = QPushButton("Add Light Directory")
        self.add_light_dir_btn.clicked.connect(self.add_light_directory)
        btn_layout.addWidget(self.add_light_files_btn)
        btn_layout.addWidget(self.add_light_dir_btn)
        layout.addLayout(btn_layout)
        session_hint_label = QLabel("Right Click to Assign Session Keys if desired")
        session_hint_label.setStyleSheet("color: #888; font-style: italic; font-size: 11px; margin-left: 4px;")
        layout.addWidget(session_hint_label)

        clear_selection_btn = QPushButton("Remove Selected")
        clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection_light(self.light_tree))
        layout.addWidget(clear_selection_btn)

        # Cosmetic Correction & Pedestal Controls
        correction_layout = QHBoxLayout()

        self.cosmetic_checkbox = QCheckBox("Enable Cosmetic Correction")
        self.pedestal_checkbox = QCheckBox("Apply Pedestal")
        self.bias_checkbox = QCheckBox("Apply Bias Subtraction (For CCD Users)")

        # Pedestal Value (0-1000, converted to 0-1)
        pedestal_layout = QHBoxLayout()
        self.pedestal_spinbox = QSpinBox()
        self.pedestal_spinbox.setRange(0, 1000)
        self.pedestal_spinbox.setValue(50)  # Default pedestal
        pedestal_layout.addWidget(QLabel("Pedestal (0-1000):"))
        pedestal_layout.addWidget(self.pedestal_spinbox)
        layout.addLayout(pedestal_layout)        

        # Tooltip for Bias Checkbox
        self.bias_checkbox.setToolTip(
            "CMOS users: Bias Subtraction is not needed.\n"
            "Modern CMOS cameras use Correlated Double Sampling (CDS),\n"
            "meaning bias is already subtracted at the sensor level."
        )

        # Connect checkboxes to update function
        self.cosmetic_checkbox.stateChanged.connect(self.update_light_corrections)
        self.pedestal_checkbox.stateChanged.connect(self.update_light_corrections)
        self.bias_checkbox.stateChanged.connect(self.update_light_corrections)

        # Add checkboxes to layout
        correction_layout.addWidget(self.cosmetic_checkbox)
        correction_layout.addWidget(self.pedestal_checkbox)
        correction_layout.addWidget(self.bias_checkbox)

        layout.addLayout(correction_layout)        

        # --- RIGHT SIDE CONTROLS: Override Dark & Flat ---
        override_layout = QHBoxLayout()

        self.override_dark_btn = QPushButton("Override Dark Frame")
        self.override_dark_btn.clicked.connect(self.override_selected_master_dark)
        override_layout.addWidget(self.override_dark_btn)

        self.override_flat_btn = QPushButton("Override Flat Frame")
        self.override_flat_btn.clicked.connect(self.override_selected_master_flat)
        override_layout.addWidget(self.override_flat_btn)

        layout.addLayout(override_layout)

        # Calibrate Lights Button
        self.calibrate_lights_btn = QPushButton("🚀 Calibrate Light Frames 🚀")
        self.calibrate_lights_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        self.calibrate_lights_btn.clicked.connect(self.calibrate_lights)
        layout.addWidget(self.calibrate_lights_btn)

        # Enable Context Menu
        self.light_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.light_tree.customContextMenuRequested.connect(self.light_tree_context_menu)

        return tab



    def prompt_set_session(self, item, frame_type):
        text, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session name:")
        if not (ok and text.strip()):
            return

        session_name = text.strip()
        is_flat = frame_type.upper() == "FLAT"
        tree = self.flat_tree if is_flat else self.light_tree
        target_dict = self.flat_files if is_flat else self.light_files

        selected_items = tree.selectedItems()

        def update_file_session(filename, widget_item):
            for key in list(target_dict.keys()):
                if isinstance(key, tuple) and len(key) == 2:
                    group_key, old_session = key
                else:
                    continue  # Skip malformed keys

                files = target_dict.get(key, [])
                for f in list(files):
                    if os.path.basename(f) == filename:
                        if old_session != session_name:
                            new_key = (group_key, session_name)
                            if new_key not in target_dict:
                                target_dict[new_key] = []
                            target_dict[new_key].append(f)
                            target_dict[key].remove(f)
                            if not target_dict[key]:
                                del target_dict[key]

                        # Update internal session tag
                        self.session_tags[f] = session_name

                        # Update leaf's metadata column
                        old_meta = widget_item.text(1)
                        if "Session:" in old_meta:
                            new_meta = re.sub(r"Session: [^|]*", f"Session: {session_name}", old_meta)
                        else:
                            new_meta = f"{old_meta} | Session: {session_name}"
                        widget_item.setText(1, new_meta)
                        return

        def recurse_all_leaf_items(parent_item):
            for i in range(parent_item.childCount()):
                child = parent_item.child(i)
                if child.childCount() == 0:
                    update_file_session(child.text(0), child)
                else:
                    recurse_all_leaf_items(child)

        # Case 1: Multi-leaf selection (e.g. Shift/Ctrl-click)
        if selected_items and any(i.childCount() == 0 for i in selected_items):
            for leaf in selected_items:
                if leaf.childCount() == 0:
                    update_file_session(leaf.text(0), leaf)

        # Case 2: Right-clicked on a group (e.g. filter+exposure node)
        elif item and item.childCount() > 0:
            recurse_all_leaf_items(item)

        # ✅ Reassign matching master flats/darks per leaf
        self.assign_best_master_files()


    def create_image_registration_tab(self):
        """
        Creates an Image Registration tab that mimics how the Light tab handles
        cosmetic corrections—i.e., we have global Drizzle controls (checkbox, combo, spin),
        and we update a text column in the QTreeWidget to show each group's drizzle state.
        """
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # ─────────────────────────────────────────
        # 1) QTreeWidget
        # ─────────────────────────────────────────
        self.reg_tree = QTreeWidget()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels([
            "Filter - Exposure - Size",
            "Metadata",
            "Drizzle"  # We'll display "Drizzle: True, Scale: 2x, Drop:0.65" here
        ])
        self.reg_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Optional: make columns resize nicely
        header = self.reg_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(2, QHeaderView.ResizeMode.Stretch)

        layout.addWidget(QLabel("Calibrated Light Frames"))
        layout.addWidget(self.reg_tree)

        tol_layout = QHBoxLayout()
        tol_layout.addWidget(QLabel("Exposure Tolerance (sec):"))
        self.exposure_tolerance_spin = QSpinBox()
        self.exposure_tolerance_spin.setRange(0, 900)
        self.exposure_tolerance_spin.setValue(0)
        self.exposure_tolerance_spin.setSingleStep(5)
        tol_layout.addWidget(self.exposure_tolerance_spin)
        layout.addLayout(tol_layout)
        self.exposure_tolerance_spin.valueChanged.connect(lambda _: self.populate_calibrated_lights())

        # Populate the tree from your calibrated folder
        self.populate_calibrated_lights()


        # ─────────────────────────────────────────
        # 2) Buttons for Managing Files
        # ─────────────────────────────────────────
        btn_layout = QHBoxLayout()
        self.add_reg_files_btn = QPushButton("Add Light Files")
        self.add_reg_files_btn.clicked.connect(self.add_light_files_to_registration)
        btn_layout.addWidget(self.add_reg_files_btn)

        self.clear_selection_btn = QPushButton("Remove Selected")
        self.clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection_registration(self.reg_tree))

        btn_layout.addWidget(self.clear_selection_btn)

        layout.addLayout(btn_layout)

        # ─────────────────────────────────────────
        # 3) Global Drizzle Controls
        # ─────────────────────────────────────────
        drizzle_layout = QHBoxLayout()

        self.drizzle_checkbox = QCheckBox("Enable Drizzle (beta)")
        self.drizzle_checkbox.stateChanged.connect(self.update_drizzle_settings)  # <─ connect signal
        drizzle_layout.addWidget(self.drizzle_checkbox)

        drizzle_layout.addWidget(QLabel("Scale:"))
        self.drizzle_scale_combo = QComboBox()
        self.drizzle_scale_combo.addItems(["1x", "2x", "3x"])
        self.drizzle_scale_combo.currentIndexChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_scale_combo)

        drizzle_layout.addWidget(QLabel("Drop Shrink:"))
        self.drizzle_drop_shrink_spin = QDoubleSpinBox()
        self.drizzle_drop_shrink_spin.setRange(0.0, 1.0)
        self.drizzle_drop_shrink_spin.setSingleStep(0.05)
        self.drizzle_drop_shrink_spin.setValue(0.65)
        self.drizzle_drop_shrink_spin.valueChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_drop_shrink_spin)

        layout.addLayout(drizzle_layout)

        # ─────────────────────────────────────────
        # 4) Reference Frame Selection
        # ─────────────────────────────────────────
        self.ref_frame_label = QLabel("Select Reference Frame:")
        self.ref_frame_path = QLabel("No file selected")
        self.ref_frame_path.setWordWrap(True)
        self.select_ref_frame_btn = QPushButton("Select Reference Frame")
        self.select_ref_frame_btn.clicked.connect(self.select_reference_frame)

        ref_layout = QHBoxLayout()
        ref_layout.addWidget(self.ref_frame_label)
        ref_layout.addWidget(self.ref_frame_path)
        ref_layout.addWidget(self.select_ref_frame_btn)
        layout.addLayout(ref_layout)

        # ─────────────────────────────────────────
        # 5) Register & Integrate Buttons
        # ─────────────────────────────────────────
        self.register_images_btn = QPushButton("🔥🚀Register and Integrate Images🔥🚀")
        self.register_images_btn.clicked.connect(self.register_images)
        self.register_images_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        layout.addWidget(self.register_images_btn)

        self.integrate_registered_btn = QPushButton("Integrate Previously Registered Images")
        self.integrate_registered_btn.clicked.connect(self.integrate_registered_images)
        self.integrate_registered_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;
            }
            QPushButton:hover {
                border: 2px solid #FFD700;
            }
            QPushButton:pressed {
                background-color: #222;
                border: 2px solid #FFA500;
            }
        """)
        layout.addWidget(self.integrate_registered_btn)

        tab.setLayout(layout)
        return tab

    def select_reference_frame(self):
        """ Opens a file dialog to select the reference frame. """
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Frame", "", 
                                                "FITS Images (*.fits *.fit);;All Files (*)")
        if file_path:
            self.reference_frame = file_path
            self.ref_frame_path.setText(os.path.basename(file_path))

    def clear_tree_selection(self, tree, file_dict):
        """Clears selected items from a simple (non-tuple-keyed) tree like Master Darks or Darks tab."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()
            if parent is None:
                # Top-level group item
                key = item.text(0)
                if key in file_dict:
                    del file_dict[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))
            else:
                # Child item
                key = parent.text(0)
                filename = item.text(0)
                if key in file_dict:
                    file_dict[key] = [f for f in file_dict[key] if os.path.basename(f) != filename]
                    if not file_dict[key]:
                        del file_dict[key]
                parent.removeChild(item)


    def clear_tree_selection_light(self, tree):
        """Clears the selection in the light tree and updates self.light_files accordingly."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()
            if parent is None:
                # Top-level filter node selected
                filter_name = item.text(0)
                # Remove all composite keys whose group_key starts with filter_name
                keys_to_remove = [key for key in list(self.light_files.keys())
                                if isinstance(key, tuple) and key[0].startswith(f"{filter_name} - ")]
                for key in keys_to_remove:
                    del self.light_files[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))
            else:
                if parent.parent() is None:
                    # Exposure node selected (child)
                    filter_name = parent.text(0)
                    exposure_text = item.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                    keys_to_remove = [key for key in list(self.light_files.keys())
                                    if isinstance(key, tuple) and key[0] == group_key]
                    for key in keys_to_remove:
                        del self.light_files[key]
                    parent.removeChild(item)
                else:
                    # Grandchild file node selected
                    filter_name = parent.parent().text(0)
                    exposure_text = parent.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                    filename = item.text(0)

                    keys_to_check = [key for key in list(self.light_files.keys())
                                    if isinstance(key, tuple) and key[0] == group_key]

                    for key in keys_to_check:
                        self.light_files[key] = [
                            f for f in self.light_files[key] if os.path.basename(f) != filename
                        ]
                        if not self.light_files[key]:
                            del self.light_files[key]
                    parent.removeChild(item)

    def clear_tree_selection_flat(self, tree, file_dict):
        """Clears the selection in the given tree widget and removes items from the corresponding dictionary."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()

            if parent:
                # Grandchild level (actual file)
                if parent.parent() is not None:
                    filter_name = parent.parent().text(0)
                    exposure_text = parent.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                else:
                    # Exposure level
                    filter_name = parent.text(0)
                    exposure_text = item.text(0)
                    group_key = f"{filter_name} - {exposure_text}"

                filename = item.text(0)

                # Remove from all matching (group_key, session) tuples
                keys_to_check = [key for key in list(file_dict.keys())
                                if isinstance(key, tuple) and key[0] == group_key]

                for key in keys_to_check:
                    file_dict[key] = [f for f in file_dict[key] if os.path.basename(f) != filename]
                    if not file_dict[key]:
                        del file_dict[key]

                parent.removeChild(item)
            else:
                # Top-level (filter group) selected
                filter_name = item.text(0)
                keys_to_remove = [key for key in list(file_dict.keys())
                                if isinstance(key, tuple) and key[0].startswith(f"{filter_name} - ")]
                for key in keys_to_remove:
                    del file_dict[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))

    def clear_tree_selection_registration(self, tree):
        """Clears the selection in the registration tree and updates self.reg_files accordingly."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()

            if parent is None:
                # Top-level group
                group_key = item.text(0)

                # ✅ Delete all calibrated files inside this group
                full_file_paths = item.data(0, Qt.ItemDataRole.UserRole)
                if full_file_paths:
                    for full_path in full_file_paths:
                        if not hasattr(self, "deleted_calibrated_files"):
                            self.deleted_calibrated_files = []
                        if full_path not in self.deleted_calibrated_files:
                            self.deleted_calibrated_files.append(full_path)

                if group_key in self.reg_files:
                    del self.reg_files[group_key]

                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))

            else:
                # Child file under a group
                group_key = parent.text(0)
                filename = item.text(0)

                if group_key in self.reg_files:
                    self.reg_files[group_key] = [
                        f for f in self.reg_files[group_key]
                        if os.path.basename(f) != filename
                    ]
                    if not self.reg_files[group_key]:
                        del self.reg_files[group_key]

                # ✅ Delete calibrated child file
                full_file_paths = parent.data(0, Qt.ItemDataRole.UserRole)
                if full_file_paths:
                    for full_path in full_file_paths:
                        if os.path.basename(full_path) == filename:
                            if not hasattr(self, "deleted_calibrated_files"):
                                self.deleted_calibrated_files = []
                            if full_path not in self.deleted_calibrated_files:
                                self.deleted_calibrated_files.append(full_path)

                parent.removeChild(item)

    def rebuild_flat_tree(self):
        """Regroup flat frames in the flat_tree based on the exposure tolerance."""
        self.flat_tree.clear()

        if not self.flat_files:
            return

        tolerance = self.flat_exposure_tolerance_spinbox.value()

        # Flatten all flats into a list
        all_flats = []
        for (filter_exp_size, session_tag), files in self.flat_files.items():
            for file in files:
                all_flats.append((filter_exp_size, session_tag, file))

        # Group the flats
        grouped = {}

        for (filter_exp_size, session_tag, file_path) in all_flats:
            try:
                header = fits.getheader(file_path, ext=0)
                filter_name = header.get("FILTER", "Unknown")
                exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))
                width = header.get("NAXIS1", 0)
                height = header.get("NAXIS2", 0)
                image_size = f"{width}x{height}" if width and height else "Unknown"
                exposure = float(exposure)

                found_group = None
                for group_key in grouped.keys():
                    g_filter, g_min_exp, g_max_exp, g_size = group_key
                    if (
                        filter_name == g_filter and
                        image_size == g_size and
                        g_min_exp - tolerance <= exposure <= g_max_exp + tolerance
                    ):
                        found_group = group_key
                        break

                if found_group:
                    grouped[found_group].append((file_path, exposure))
                else:
                    new_key = (filter_name, exposure, exposure, image_size)
                    grouped[new_key] = [(file_path, exposure)]

            except Exception as e:
                print(f"⚠️ Failed reading {file_path}: {e}")

        # Now create the tree
        for (filter_name, min_exp, max_exp, image_size), files in grouped.items():
            top_item = QTreeWidgetItem()
            expmin = np.floor(min_exp)
            tolerance = self.flat_exposure_tolerance_spinbox.value()

            if len(files) > 1:
                exposure_str = f"{expmin:.1f}s–{(expmin + tolerance):.1f}s"
            else:
                exposure_str = f"{min_exp:.1f}s"

            top_item.setText(0, f"{filter_name} - {exposure_str} ({image_size})")
            top_item.setText(1, f"{len(files)} files")
            top_item.setText(2, "Auto-Selected Dark" if self.auto_select_dark_checkbox.isChecked() else "None")

            self.flat_tree.addTopLevelItem(top_item)

            for file_path, _ in files:
                session_tag = self.session_tags.get(file_path, "Default")
                leaf_item = QTreeWidgetItem([
                    os.path.basename(file_path),
                    f"Size: {image_size} | Session: {session_tag}"
                ])
                top_item.addChild(leaf_item)


    def exposures_within_tolerance(self, exp1, exp2, tolerance):
        try:
            return abs(float(exp1) - float(exp2)) <= tolerance
            
        except Exception:
            return False

    def parse_group_key(self, group_key):
        """
        Parses a group key string like 'Luminance - 90s (3000x2000)'
        into filter_name, exposure (float), and image_size (str).
        """
        try:
            parts = group_key.split(' - ')
            filter_name = parts[0]
            exp_size_part = parts[1] if len(parts) > 1 else ""

            # Separate exposure and size correctly
            if '(' in exp_size_part and ')' in exp_size_part:
                exposure_str, size_part = exp_size_part.split('(', 1)
                exposure = exposure_str.replace('s', '').strip()
                size = size_part.strip(') ').strip()
            else:
                exposure = exp_size_part.replace('s', '').strip()
                size = "Unknown"

            
            return filter_name, float(exposure), size

        except Exception as e:
            
            return "Unknown", 0.0, "Unknown"



    def populate_calibrated_lights(self):
        """
        Reads both the Calibrated folder and any manually-added files,
        groups them by FILTER, EXPOSURE±tol, SIZE, and fills self.reg_tree.
        """
        # 1) clear out the tree
        self.reg_tree.clear()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels(["Filter - Exposure - Size", "Metadata", "Drizzle"])
        hdr = self.reg_tree.header()
        hdr.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        hdr.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)
        hdr.setSectionResizeMode(2, QHeaderView.ResizeMode.Interactive)

        # 2) gather all files
        calibrated_folder = os.path.join(self.stacking_directory or "", "Calibrated")
        files = []
        if os.path.isdir(calibrated_folder):
            for fn in os.listdir(calibrated_folder):
                if fn.lower().endswith((".fits", ".fit")):
                    files.append(os.path.join(calibrated_folder, fn))
        # append any manual additions
        files += getattr(self, "manual_light_files", [])

        # nothing to do?
        if not files:
            return

        # 3) group by header
        grouped = {}  # key -> list of (path, exposure_float)
        tol = self.exposure_tolerance_spin.value()
        for fp in files:
            try:
                hdr0 = fits.getheader(fp, ext=0)
                filt = hdr0.get("FILTER", "Unknown")
                exp  = hdr0.get("EXPOSURE", hdr0.get("EXPTIME", 0.0))
                exp  = float(exp)
                data0 = fits.getdata(fp, ext=0)
                h, w = data0.shape[-2:]
                size = f"{w}x{h}"
            except Exception as e:
                print(f"⚠️ Skipping {fp}: {e}")
                continue

            # find existing group
            match = None
            for key in grouped:
                f2,e2,s2 = self.parse_group_key(key)
                if filt==f2 and s2==size and abs(exp-e2)<=tol:
                    match = key
                    break
            if match is None:
                key = f"{filt} - {exp:.1f}s ({size})"
                grouped[key] = []
            else:
                key = match

            grouped[key].append((fp, exp))

        # 4) populate the tree & store in self.light_files
        self.light_files = {}
        for key, lst in grouped.items():
            paths = [p for p,_ in lst]
            exps  = [e for _,e in lst]

            top = QTreeWidgetItem()
            top.setText(0, key)
            # metadata: "N files, min–max s"
            if len(exps)>1:
                mn, mx = min(exps), max(exps)
                top.setText(1, f"{len(paths)} files, {mn:.0f}s–{mx:.0f}s")
            else:
                top.setText(1, f"{len(paths)} file")
            top.setText(2, "Drizzle: False")
            # store full list for gather_drizzle & extractor
            top.setData(0, Qt.ItemDataRole.UserRole, paths)
            self.reg_tree.addTopLevelItem(top)

            for fp,_ in lst:
                # leaf row
                data0 = fits.getdata(fp, ext=0)
                h, w = data0.shape[-2:]
                leaf = QTreeWidgetItem([os.path.basename(fp), f"Size: {w}x{h}"])
                # store absolute path
                leaf.setData(0, Qt.ItemDataRole.UserRole, fp)
                top.addChild(leaf)

            top.setExpanded(True)
            self.light_files[key] = paths


    def update_drizzle_settings(self):
        """
        Called whenever the user toggles the 'Enable Drizzle' checkbox,
        changes the scale combo, or changes the drop shrink spinbox.
        Applies to all *selected* top-level items in the reg_tree.
        """
        # Current states from global controls
        drizzle_enabled = self.drizzle_checkbox.isChecked()
        scale_str = self.drizzle_scale_combo.currentText()  # e.g. "1x","2x","3x"
        drop_val = self.drizzle_drop_shrink_spin.value()    # e.g. 0.65

        # Gather selected items
        selected_items = self.reg_tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            # If the user selected a child row, go up to its parent group
            if item.parent() is not None:
                item = item.parent()

            group_key = item.text(0)

            if drizzle_enabled:
                # Show scale + drop shrink
                drizzle_text = (f"Drizzle: True, "
                                f"Scale: {scale_str}, "
                                f"Drop: {drop_val:.2f}")
            else:
                # Just show "Drizzle: False"
                drizzle_text = "Drizzle: False"

            # Update column 2 with the new text
            item.setText(2, drizzle_text)

            # If you also store it in a dictionary:
            self.per_group_drizzle[group_key] = {
                "enabled": drizzle_enabled,
                "scale": float(scale_str.replace("x","", 1)),
                "drop": drop_val
            }


    def gather_drizzle_settings_from_tree(self):
        """
        Returns: { group_key: {files:[...], drizzle_enabled:bool,
                            scale_factor:float, drop_shrink:float} }
        """
        dd = {}
        for i in range(self.reg_tree.topLevelItemCount()):
            item = self.reg_tree.topLevelItem(i)
            key  = item.text(0)
            files= item.data(0, Qt.ItemDataRole.UserRole) or []
            txt  = item.text(2).lower()

            ena = txt.startswith("drizzle: true")
            sf  = 1.0
            ds  = 0.65
            if ena:
                import re
                m = re.search(r"scale\s*:\s*([\d\.]+)x?", txt)
                if m: sf = float(m.group(1))
                m = re.search(r"drop\s*:\s*([\d\.]+)", txt)
                if m: ds = float(m.group(1))

            dd[key] = {
                "files": files,
                "drizzle_enabled": ena,
                "scale_factor": sf,
                "drop_shrink": ds
            }

        # backfill any group that lived only in self.light_files
        for key, fl in self.light_files.items():
            if key not in dd:
                dd[key] = {
                    "files": fl,
                    "drizzle_enabled": False,
                    "scale_factor": 1.0,
                    "drop_shrink": 0.65
                }

        return dd



    def add_light_files_to_registration(self):
        """
        Let the user pick some new LIGHT frames, then
        immediately re-populate the tree so they show up
        in the same Filter–Exposure–Size groups as everything else.
        """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(
            self,
            "Select Light Frames",
            last_dir,
            "FITS Files (*.fits *.fit *.fz *.fz)"
        )
        if not files:
            return

        # remember for next time
        self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))

        # store these in a manual list, then rebuild the tree
        if not hasattr(self, "manual_light_files"):
            self.manual_light_files = []
        self.manual_light_files.extend(files)

        # rebuild the registration tree (it reads manual_light_files + calibrated folder)
        self.populate_calibrated_lights()





    def on_tab_changed(self, index):
        """ Detects when user switches to the Flats tab and triggers auto-assign. """
        if self.tabs.tabText(index) == "Flats":
            print("🔄 Auto-checking best Master Darks for Flats...")
            self.assign_best_master_dark()


    def add_dark_files(self):
        self.add_files(self.dark_tree, "Select Dark Files", "DARK")
    
    def add_dark_directory(self):
        self.add_directory(self.dark_tree, "Select Dark Directory", "DARK")

    def add_flat_files(self):
        self.prompt_session_before_adding("FLAT")


    def add_flat_directory(self):
        self.prompt_session_before_adding("FLAT", directory_mode=True)


    
    def add_light_files(self):
        self.prompt_session_before_adding("LIGHT")

    
    def add_light_directory(self):
        self.prompt_session_before_adding("LIGHT", directory_mode=True)


    def prompt_session_before_adding(self, frame_type, directory_mode=False):
        # 🔥 Prompt user first
        text, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session name:", text="Default")
        if not (ok and text.strip()):
            return

        session_name = text.strip()

        # 🔥 Set it globally before adding
        self.current_session_tag = session_name

        # 🔥 Then add files or directory
        if frame_type.upper() == "FLAT":
            if directory_mode:
                self.add_directory(self.flat_tree, "Select Flat Directory", "FLAT")
            else:
                self.add_files(self.flat_tree, "Select Flat Files", "FLAT")
            self.assign_best_master_dark()
            self.rebuild_flat_tree()

        elif frame_type.upper() == "LIGHT":
            if directory_mode:
                self.add_directory(self.light_tree, "Select Light Directory", "LIGHT")
            else:
                self.add_files(self.light_tree, "Select Light Files", "LIGHT")
            self.assign_best_master_files()

    def load_master_dark(self):
        """ Loads a Master Dark and updates the UI. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)  # Get last folder
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Dark", last_dir, "FITS Files (*.fits *.fit)")
        
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last used folder
            self.add_master_files(self.master_dark_tree, "DARK", files)

        self.update_override_dark_combo()
        self.assign_best_master_dark()
        self.assign_best_master_files()
        print("DEBUG: Loaded Master Darks and updated assignments.")


    def load_master_flat(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Flat", last_dir, "FITS Files (*.fits *.fit)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            self.add_master_files(self.master_flat_tree, "FLAT", files)


    def add_files(self, tree, title, expected_type):
        """ Adds FITS files and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, title, last_dir, "FITS Files (*.fits *.fit *.fz *.fz)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last opened folder
            for file in files:
                self.process_fits_header(file, tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()



    def add_directory(self, tree, title, expected_type):
        """ Adds all FITS files from a directory and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, title, last_dir)

        if directory:
            self.settings.setValue("last_opened_folder", directory)  # Save last opened folder
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit", ".fz", ".fz")):
                    self.process_fits_header(os.path.join(directory, file), tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()


    
    def process_fits_header(self, file_path, tree, expected_type):
        try:
            # Read only the FITS header (fast)
            header, _ = get_valid_header(file_path)

            try:
                width = int(header.get("NAXIS1"))
                height = int(header.get("NAXIS2"))
            except Exception as e:
                self.update_status(f"Warning: Could not convert dimensions to int for {file_path}: {e}")
                width, height = None, None

            if width is not None and height is not None:
                image_size = f"{width}x{height}"
            else:
                image_size = "Unknown"

            # Retrieve IMAGETYP (default to "UNKNOWN" if not present)
            imagetyp = header.get("IMAGETYP", "UNKNOWN").lower()

            # Retrieve exposure from either EXPOSURE or EXPTIME
            exposure_val = header.get("EXPOSURE")
            if not exposure_val:
                exposure_val = header.get("EXPTIME")
            if not exposure_val:
                exposure_val = "Unknown"  # fallback if neither keyword is present

            # Define forbidden keywords per expected type.
            if expected_type.upper() == "DARK":
                forbidden = ["light", "flat"]
            elif expected_type.upper() == "FLAT":
                forbidden = ["dark", "light"]
            elif expected_type.upper() == "LIGHT":
                forbidden = ["dark", "flat"]
            else:
                forbidden = []

            # Determine attribute name for auto-confirm decision (per expected type)
            decision_attr = f"auto_confirm_{expected_type.lower()}"
            # If a decision has already been made, use it.
            if hasattr(self, decision_attr):
                decision = getattr(self, decision_attr)
                if decision is False:
                    # Skip this file automatically.
                    return
                # If decision is True, then add without prompting.
            elif any(word in imagetyp for word in forbidden):
                # Prompt the user with Yes, Yes to All, No, and No to All options.
                msgBox = QMessageBox(self)
                msgBox.setWindowTitle("Mismatched Image Type")
                msgBox.setText(
                    f"The file:\n{os.path.basename(file_path)}\n"
                    f"has IMAGETYP = {header.get('IMAGETYP')} "
                    f"which does not match the expected type ({expected_type}).\n\n"
                    f"Do you want to add it anyway?"
                )
                yesButton = msgBox.addButton("Yes", QMessageBox.ButtonRole.YesRole)
                yesToAllButton = msgBox.addButton("Yes to All", QMessageBox.ButtonRole.YesRole)
                noButton = msgBox.addButton("No", QMessageBox.ButtonRole.NoRole)
                noToAllButton = msgBox.addButton("No to All", QMessageBox.ButtonRole.NoRole)
                msgBox.exec()
                clicked = msgBox.clickedButton()
                if clicked == yesToAllButton:
                    setattr(self, decision_attr, True)
                elif clicked == noToAllButton:
                    setattr(self, decision_attr, False)
                    return
                elif clicked == noButton:
                    return

            # Now handle each expected type
            if expected_type.upper() == "DARK":
                key = f"{exposure_val} ({image_size})"
                if key not in self.dark_files:
                    self.dark_files[key] = []
                self.dark_files[key].append(file_path)

                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    exposure_item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(exposure_item)
                else:
                    exposure_item = items[0]
                metadata = f"Size: {image_size}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

            elif expected_type.upper() == "FLAT":
                filter_name = header.get("FILTER", "Unknown")
                flat_key = f"{filter_name} - {exposure_val} ({image_size})"
                session_tag = getattr(self, "current_session_tag", "Default")
                composite_key = (flat_key, session_tag)

                if composite_key not in self.flat_files:
                    self.flat_files[composite_key] = []
                self.flat_files[composite_key].append(file_path)

                # ✅ Also store session tag internally
                self.session_tags[file_path] = session_tag

                # Tree UI update
                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]

                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)

                metadata = f"Size: {image_size} | Session: {session_tag}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))


            elif expected_type.upper() == "LIGHT":
                filter_name = header.get("FILTER", "Unknown")
                session_tag = getattr(self, "current_session_tag", "Default")  # ⭐️ Step 1: Get session label

                light_key = f"{filter_name} - {exposure_val} ({image_size})"
                composite_key = (light_key, session_tag)

                if composite_key not in self.light_files:
                    self.light_files[composite_key] = []
                self.light_files[composite_key].append(file_path)

                # Update Tree UI
                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]

                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)

                leaf_item = QTreeWidgetItem([os.path.basename(file_path), f"Size: {image_size} | Session: {session_tag}"])
                exposure_item.addChild(leaf_item)
                self.session_tags[file_path] = session_tag  # ✅ Store per-file session tag here


            self.update_status(f"✅ Added {os.path.basename(file_path)} as {expected_type}")
            QApplication.processEvents()

        except Exception as e:
            self.update_status(f"❌ ERROR: Could not read FITS header for {file_path} - {e}")
            QApplication.processEvents()


    def add_master_files(self, tree, file_type, files):
        """ 
        Adds multiple master calibration files to the correct treebox with metadata including image dimensions.
        This version only reads the FITS header to extract image dimensions, making it much faster.
        """
        for file_path in files:
            try:
                # Read only the FITS header (fast)
                header = fits.getheader(file_path)
                
                # Check for both EXPOSURE and EXPTIME
                exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))
                filter_name = header.get("FILTER", "Unknown")
                
                # Extract image dimensions from header keywords NAXIS1 and NAXIS2
                width = header.get("NAXIS1")
                height = header.get("NAXIS2")
                if width is not None and height is not None:
                    image_size = f"{width}x{height}"
                else:
                    image_size = "Unknown"
                
                # Construct key based on file type
                if file_type.upper() == "DARK":
                    key = f"{exposure}s ({image_size})"
                    self.master_files[key] = file_path  # Store master dark
                    self.master_sizes[file_path] = image_size  # Store size
                elif file_type.upper() == "FLAT":
                    # Attempt to extract session name from filename
                    session_name = "Default"
                    filename = os.path.basename(file_path)
                    if filename.lower().startswith("masterflat_"):
                        parts = filename.split("_")
                        if len(parts) > 1:
                            session_name = parts[1]

                    key = f"{filter_name} ({image_size}) [{session_name}]"
                    self.master_files[key] = file_path
                    self.master_sizes[file_path] = image_size

                # Extract additional metadata from header.
                sensor_temp = header.get("CCD-TEMP", "N/A")
                date_obs = header.get("DATE-OBS", "Unknown")
                metadata = f"Size: {image_size}, Temp: {sensor_temp}°C, Date: {date_obs}"

                # Check if category item already exists in the tree.
                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(item)
                else:
                    item = items[0]

                # Add the master file as a child node with metadata.
                item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

                print(f"✅ DEBUG: Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                self.update_status(f"✅ Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                print(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                self.update_status(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                QApplication.processEvents()
                self.assign_best_master_files()

            except Exception as e:
                print(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                self.update_status(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                QApplication.processEvents()



    def create_master_dark(self):
        """ Creates master darks with minimal RAM usage by loading frames in small tiles. """

        if not self.stacking_directory:
            self.select_stacking_directory()
            if not self.stacking_directory:
                QMessageBox.warning(self, "Error", "Output directory is not set.")
                return

        exposure_tolerance = self.exposure_tolerance_spinbox.value()
        dark_files_by_group = {}

        # 1) Group dark files by exposure time & image size within tolerance
        for exposure_key, file_list in self.dark_files.items():
            exposure_time_str, image_size = exposure_key.split(" (")
            image_size = image_size.rstrip(")")
            exposure_time = float(exposure_time_str.replace("s", "")) if "Unknown" not in exposure_time_str else 0

            matched_group = None
            for (existing_exposure, existing_size) in dark_files_by_group.keys():
                if abs(existing_exposure - exposure_time) <= exposure_tolerance and existing_size == image_size:
                    matched_group = (existing_exposure, existing_size)
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size)
                dark_files_by_group[matched_group] = []

            dark_files_by_group[matched_group].extend(file_list)

        # 2) Create Master Calibration Directory
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # 3) Stack Each Group in a Chunked Manner
        chunk_height = self.chunk_height
        chunk_width  = self.chunk_width

        for (exposure_time, image_size), file_list in dark_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) - Not enough frames to stack.")
                QApplication.processEvents()
                continue

            self.update_status(f"🟢 Processing {len(file_list)} darks for {exposure_time}s ({image_size}) exposure...")
            QApplication.processEvents()

            # (A) Identify reference shape from the first file
            ref_file = file_list[0]
            ref_data, ref_header, bit_depth, is_mono = load_image(ref_file)
            if ref_data is None:
                self.update_status(f"❌ Failed to load reference {os.path.basename(ref_file)}")
                continue

            height, width = ref_data.shape[:2]
            channels = 1 if (ref_data.ndim == 2) else 3

            # (B) Create a memmap for the final stacked result
            # shape=(height, width, channels)
            memmap_path = os.path.join(master_dir, f"temp_dark_{exposure_time}_{image_size}.dat")
            final_stacked = np.memmap(
                memmap_path,
                dtype=np.float32,
                mode='w+',
                shape=(height, width, channels)
            )

            # (C) For each tile, load that tile from all frames, do outlier rejection, store in final_stacked
            num_frames = len(file_list)

            for y_start in range(0, height, chunk_height):
                y_end = min(y_start + chunk_height, height)
                tile_h = y_end - y_start

                for x_start in range(0, width, chunk_width):
                    x_end = min(x_start + chunk_width, width)
                    tile_w = x_end - x_start

                    # tile_stack shape => (num_frames, tile_h, tile_w, channels)
                    tile_stack = np.zeros((num_frames, tile_h, tile_w, channels), dtype=np.float32)


                    num_cores = os.cpu_count() or 4
                    with ThreadPoolExecutor(max_workers=num_cores) as executor:
                        future_to_index = {}
                        # 1) Submit each file’s tile load in parallel
                        for i, fpath in enumerate(file_list):
                            future = executor.submit(load_fits_tile, fpath, y_start, y_end, x_start, x_end)
                            future_to_index[future] = i

                        # 2) Collect results as they complete
                        for future in as_completed(future_to_index):
                            i = future_to_index[future]
                            sub_img = future.result()
                            if sub_img is None:
                                continue

                            # --- shape handling (same as before) ---
                            # If sub_img is (H,W) & channels=3 => expand
                            if sub_img.ndim == 2 and channels == 3:
                                sub_img = np.repeat(sub_img[:, :, np.newaxis], 3, axis=2)
                            elif sub_img.ndim == 2 and channels == 1:
                                sub_img = sub_img[:, :, np.newaxis]

                            # If sub_img is (3,H,W) but we want (H,W,3), transpose
                            if sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                                sub_img = sub_img.transpose(1, 2, 0)

                            sub_img = sub_img.astype(np.float32, copy=False)
                            tile_stack[i] = sub_img

                    # (D) Outlier rejection => tile_result
                    # Use your existing 3D or 4D Windsorized Sigma Clip depending on channels
                    if channels == 3:
                        # tile_stack => shape (F,H,W,3)
                        tile_result = windsorized_sigma_clip_4d(
                            tile_stack,
                            lower=self.sigma_low,
                            upper=self.sigma_high
                        )
                        # If the function returns a tuple, extract the first element.
                        if isinstance(tile_result, tuple):
                            tile_result = tile_result[0]
                    else:
                        # tile_stack => shape (F,H,W,1) or (F,H,W)
                        # If shape=(F,H,W,1), we can squeeze or just call 3D version
                        tile_stack_3d = tile_stack[..., 0] if tile_stack.ndim == 4 else tile_stack
                        tile_result_3d = windsorized_sigma_clip_3d(tile_stack_3d, lower=self.sigma_low, upper=self.sigma_high)
                        # If the function returns a tuple, extract the first element.
                        if isinstance(tile_result_3d, tuple):
                            tile_result_3d = tile_result_3d[0]
                        # Now, ensure the result has shape (H, W, 1)
                        tile_result = tile_result_3d[..., np.newaxis]

                    # (E) Store tile_result in final_stacked
                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

            # Convert final_stacked to a normal array
            master_dark_data = np.array(final_stacked)
            del final_stacked

            # (F) Save Master Dark
            master_dark_path = os.path.join(master_dir, f"MasterDark_{int(exposure_time)}s_{image_size}.fit")

            # Build a minimal header
            # Possibly store EXPTIME, IMAGETYP="DARK", etc.
            master_header = fits.Header()
            master_header["IMAGETYP"] = "DARK"
            master_header["EXPTIME"]  = (exposure_time, "User-specified or from grouping")
            # plus any other fields you want

            # Remove NAXIS from the old ref_header if you want
            # or define them fresh
            master_header["NAXIS"] = 3 if channels==3 else 2
            master_header["NAXIS1"] = master_dark_data.shape[1]
            master_header["NAXIS2"] = master_dark_data.shape[0]
            if channels==3:
                master_header["NAXIS3"] = 3

            save_image(
                img_array=master_dark_data,
                filename=master_dark_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=master_header,
                is_mono=(channels==1)
            )

            # (G) Add to tree, status, etc.
            self.add_master_dark_to_tree(f"{exposure_time}s ({image_size})", master_dark_path)
            self.update_status(f"✅ Master Dark saved: {master_dark_path}")
            self.assign_best_master_files()

        # Finally, assign best master dark, etc.
        self.assign_best_master_dark()
        self.update_override_dark_combo()
        self.assign_best_master_files()



    def save_master_dark(self, master_dark, output_path, exposure_time, is_mono):
        """Saves the master dark as 32-bit floating point FITS while maintaining OSC structure."""
        if is_mono:
            # Mono => shape (H, W)
            h, w = master_dark.shape
            # Wrap in an HDU
            hdu_data = master_dark.astype(np.float32)
            hdu = fits.PrimaryHDU(hdu_data)
            image_size = f"{w}x{h}"  # Width x Height
        else:
            # Color => shape (H, W, C)
            h, w, c = master_dark.shape
            # Transpose to (C, H, W)
            hdu_data = master_dark.transpose(2, 0, 1).astype(np.float32)
            hdu = fits.PrimaryHDU(hdu_data)
            image_size = f"{w}x{h}"

        # Now 'hdu' is a fits.PrimaryHDU in both branches
        hdr = hdu.header
        hdr["SIMPLE"]   = True
        hdr["BITPIX"]   = -32
        hdr["NAXIS"]    = 3 if not is_mono else 2
        hdr["NAXIS1"]   = w  # Width
        hdr["NAXIS2"]   = h  # Height
        if not is_mono:
            hdr["NAXIS3"] = c
        hdr["BSCALE"]   = 1.0
        hdr["BZERO"]    = 0.0
        hdr["IMAGETYP"] = "MASTER DARK"
        hdr["EXPOSURE"] = exposure_time
        hdr["DATE-OBS"] = datetime.utcnow().isoformat()
        hdr["CREATOR"]  = "SetiAstroSuite"

        # Write the FITS file
        hdu.writeto(output_path, overwrite=True)

        # Store Master Dark path with correct key
        key = f"{exposure_time}s ({image_size})"
        self.master_files[key] = output_path
        self.master_sizes[output_path] = image_size

        print(f"✅ Master Dark FITS saved: {output_path}")
        self.update_status(f"✅ Stored Master Dark -> {key}: {output_path}")



            
    def add_master_dark_to_tree(self, exposure_time, master_dark_path):
        """ Adds the newly created Master Dark to the Master Dark TreeBox and updates the dropdown. """

        exposure_key = f"{exposure_time}s"

        # ✅ Store in the dictionary
        self.master_files[exposure_key] = master_dark_path  # Store master dark
        print(f"📝 DEBUG: Stored Master Dark -> {exposure_key}: {master_dark_path}")

        # ✅ Update UI Tree
        existing_items = self.master_dark_tree.findItems(exposure_key, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            exposure_item = existing_items[0]
        else:
            exposure_item = QTreeWidgetItem([exposure_key])
            self.master_dark_tree.addTopLevelItem(exposure_item)

        master_item = QTreeWidgetItem([os.path.basename(master_dark_path)])
        exposure_item.addChild(master_item)

        # ✅ Refresh the override dropdown
        self.update_override_dark_combo()
        self.assign_best_master_dark()  # 🔥 Ensure auto-selection works

        self.update_status(f"✅ Master Dark saved and added to UI: {master_dark_path}")



    def assign_best_master_dark(self):
        """ Assigns the closest matching master dark based on exposure & image size. """
        print("\n🔍 DEBUG: Assigning best master darks to flats...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Darks available.")
            self.update_status("⚠️ WARNING: No Master Darks available.")
            return  # Exit early if there are no master darks

        print(f"📂 Loaded Master Darks ({len(self.master_files)} total):")
        for key, value in self.master_files.items():
            print(f"   📌 {key} -> {value}")

        # Iterate through all flat filters
        for i in range(self.flat_tree.topLevelItemCount()):
            filter_item = self.flat_tree.topLevelItem(i)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)  # Example: "0.0007s (8288x5644)"

                # Extract exposure time
                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue  # Skip if exposure is invalid

                exposure_time = float(match.group(1))  # Extracted number
                print(f"🟢 Checking Flat Group: {exposure_text} (Parsed: {exposure_time}s)")

                # Extract image size from metadata
                if exposure_item.childCount() > 0:
                    metadata_text = exposure_item.child(0).text(1)  # Metadata column
                    size_match = re.search(r"Size: (\d+x\d+)", metadata_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                else:
                    image_size = "Unknown"

                print(f"✅ Parsed Flat Size: {image_size}")

                # Find the best matching master dark
                best_match = None
                best_diff = float("inf")

                for master_dark_exposure, master_dark_path in self.master_files.items():
                    master_dark_exposure_match = re.match(r"([\d.]+)s?", master_dark_exposure)
                    if not master_dark_exposure_match:
                        continue  # Skip if master dark exposure is invalid

                    master_dark_exposure_time = float(master_dark_exposure_match.group(1))
                    master_dark_size = self.master_sizes.get(master_dark_path, "Unknown")
                    if master_dark_size == "Unknown":
                        with fits.open(master_dark_path) as hdul:
                            master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                            self.master_sizes[master_dark_path] = master_dark_size  # ✅ Store it

                    print(f"🔎 Comparing with Master Dark: {master_dark_exposure_time}s ({master_dark_size})")

                    # Match both image size and exposure time
                    if image_size == master_dark_size:
                        diff = abs(master_dark_exposure_time - exposure_time)
                        if diff < best_diff:
                            best_match = master_dark_path
                            best_diff = diff

                # Assign best match in column 3
                if best_match:
                    exposure_item.setText(2, os.path.basename(best_match))
                    print(f"🔵 Assigned Master Dark: {os.path.basename(best_match)}")
                else:
                    exposure_item.setText(2, "None")
                    print(f"⚠️ No matching Master Dark found for {exposure_text}")

        # 🔥 Force UI update to reflect changes
        self.flat_tree.viewport().update()

        print("\n✅ DEBUG: Finished assigning best matching Master Darks to Flats.\n")



    def update_override_dark_combo(self):
        """ Populates the dropdown with available Master Darks and prevents duplicate entries. """
        self.override_dark_combo.clear()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.addItem("None (Use no Dark to Calibrate)")

        seen_files = set()
        for exposure, path in self.master_files.items():
            file_name = os.path.basename(path)
            if file_name not in seen_files:
                self.override_dark_combo.addItem(f"{file_name} ({exposure})")
                seen_files.add(file_name)

        print("✅ DEBUG: Updated Override Master Dark dropdown with unique entries.")


    def override_selected_master_dark(self):
        """ Overrides the selected master dark for the currently highlighted flat group. """
        selected_items = self.flat_tree.selectedItems()
        if not selected_items:
            return

        new_dark = self.override_dark_combo.currentText()

        # ✅ Handle "None (Use no Dark to Calibrate)" explicitly
        if new_dark == "None (Use no Dark to Calibrate)":
            new_dark = "No Calibration"  # Show "No Calibration" in the UI
        elif new_dark == "None (Use Auto-Select)":
            new_dark = None  # Auto-select behavior

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, new_dark if new_dark else "Auto")

        print(f"✅ DEBUG: Override Master Dark set to: {new_dark}")

    def create_master_flat(self):
        """ Creates master flats using per-frame dark subtraction before stacking. """

        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first using the wrench button.")
            return

        exposure_tolerance = self.flat_exposure_tolerance_spinbox.value()
        flat_files_by_group = {}  # Group by (Exposure, Image Size, Filter, Session)

        # Group Flats by Filter, Exposure & Size within Tolerance
        for (filter_exposure, session), file_list in self.flat_files.items():
            try:
                filter_name, exposure_size = filter_exposure.split(" - ")
                exposure_time_str, image_size = exposure_size.split(" (")
                image_size = image_size.rstrip(")")
            except ValueError:
                self.update_status(f"⚠️ ERROR: Could not parse {filter_exposure}")
                continue

            match = re.match(r"([\d.]+)s?", exposure_time_str)
            exposure_time = float(match.group(1)) if match else -10.0

            matched_group = None
            for key in flat_files_by_group:
                existing_exposure, existing_size, existing_filter, existing_session = key
                if (
                    abs(existing_exposure - exposure_time) <= exposure_tolerance
                    and existing_size == image_size
                    and existing_filter == filter_name
                    and existing_session == session
                ):
                    matched_group = key
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size, filter_name, session)
                flat_files_by_group[matched_group] = []

            flat_files_by_group[matched_group].extend(file_list)

        # Create output folder
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # Stack each grouped flat set
        for (exposure_time, image_size, filter_name, session), file_list in flat_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) [{filter_name}] [{session}] - Not enough frames to stack.")
                continue

            self.update_status(f"🟢 Processing {len(file_list)} flats for {exposure_time}s ({image_size}) [{filter_name}] in session '{session}'...")

            # Load master dark
            best_diff = float("inf")
            selected_master_dark = None
            for key, path in self.master_files.items():
                match = re.match(r"([\d.]+)s", key)
                if not match:
                    continue
                dark_exposure = float(match.group(1))
                dark_size = self.master_sizes.get(path, "Unknown")
                if dark_size == image_size:
                    diff = abs(dark_exposure - exposure_time)
                    if diff < best_diff:
                        best_diff = diff
                        selected_master_dark = path

            if selected_master_dark:
                dark_data, _, _, _ = load_image(selected_master_dark)
            else:
                dark_data = None
                self.update_status("DEBUG: No matching Master Dark found.")

            # Load reference image
            ref_data, _, _, _ = load_image(file_list[0])
            if ref_data is None:
                self.update_status(f"❌ Failed to load reference {os.path.basename(file_list[0])}")
                continue

            height, width = ref_data.shape[:2]
            channels = 1 if ref_data.ndim == 2 else 3
            memmap_path = os.path.join(master_dir, f"temp_flat_{session}_{exposure_time}_{image_size}_{filter_name}.dat")
            final_stacked = np.memmap(memmap_path, dtype=np.float32, mode="w+", shape=(height, width, channels))
            num_frames = len(file_list)

            for y_start in range(0, height, self.chunk_height):
                y_end = min(y_start + self.chunk_height, height)
                tile_h = y_end - y_start
                for x_start in range(0, width, self.chunk_width):
                    x_end = min(x_start + self.chunk_width, width)
                    tile_w = x_end - x_start
                    tile_stack = np.zeros((num_frames, tile_h, tile_w, channels), dtype=np.float32)

                    with ThreadPoolExecutor() as executor:
                        
                        futures = {
                            executor.submit(load_fits_tile, f, y_start, y_end, x_start, x_end): idx
                            for idx, f in enumerate(file_list)
                        }

                        for future in as_completed(futures):
                            i = futures[future]
                            sub_img = future.result()
                            if sub_img is None:
                                self.update_status(f"⚠️ Skipping tile {i} due to load failure.")
                                continue

                            # Ensure correct shape
                            if sub_img.ndim == 2:
                                sub_img = sub_img[:, :, np.newaxis]
                                if channels == 3:
                                    sub_img = np.repeat(sub_img, 3, axis=2)
                            elif sub_img.shape[0] == 3:
                                sub_img = sub_img.transpose(1, 2, 0)

                            tile_stack[i] = sub_img


                    if dark_data is not None:
                        dark_tile = dark_data[y_start:y_end, x_start:x_end]
                        if dark_tile.ndim == 2:
                            dark_tile = dark_tile[..., np.newaxis]
                            if channels == 3:
                                dark_tile = np.repeat(dark_tile, 3, axis=2)
                        elif dark_tile.shape[0] == 3:
                            dark_tile = dark_tile.transpose(1, 2, 0)

                        if dark_tile.shape == (tile_h, tile_w, channels):
                            tile_stack = subtract_dark(tile_stack, dark_tile)

                    if channels == 3:
                        tile_result = windsorized_sigma_clip_4d(tile_stack, lower=self.sigma_low, upper=self.sigma_high)[0]
                    else:
                        stack_3d = tile_stack[..., 0]
                        tile_result = windsorized_sigma_clip_3d(stack_3d, lower=self.sigma_low, upper=self.sigma_high)[0]
                        tile_result = tile_result[..., np.newaxis]

                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

            master_flat_data = np.array(final_stacked)
            del final_stacked

            master_flat_path = os.path.join(
                master_dir,
                f"MasterFlat_{session}_{int(exposure_time)}s_{image_size}_{filter_name}.fit"
            )

            header = fits.Header()
            header["IMAGETYP"] = "FLAT"
            header["EXPTIME"] = (exposure_time, "grouped exposure")
            header["FILTER"] = filter_name
            header["NAXIS"] = 3 if channels == 3 else 2
            header["NAXIS1"] = width
            header["NAXIS2"] = height
            if channels == 3:
                header["NAXIS3"] = 3

            save_image(
                img_array=master_flat_data,
                filename=master_flat_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=header,
                is_mono=(channels == 1)
            )

            key = f"{filter_name} ({image_size}) [{session}]"
            self.master_files[key] = master_flat_path
            self.master_sizes[master_flat_path] = image_size
            self.add_master_flat_to_tree(filter_name, master_flat_path)
            self.update_status(f"✅ Master Flat saved: {master_flat_path}")

        self.assign_best_master_dark()
        self.assign_best_master_files()



    def save_master_flat(self, master_flat, output_path, exposure_time, filter_name):
        """ Saves master flat as both a 32-bit floating point FITS and TIFF while ensuring no unintended normalization. """

        # ✅ Retrieve FITS header from a sample flat (to check if it's mono or color)
        original_header = None
        is_mono = True  # Default to mono

        if self.flat_files:
            sample_flat = next(iter(self.flat_files.values()))[0]  # Get the first flat file
            try:
                with fits.open(sample_flat) as hdul:
                    original_header = hdul[0].header

                    # **🔍 Detect if the flat is color by checking NAXIS3**
                    if original_header.get("NAXIS", 2) == 3 and original_header.get("NAXIS3", 1) == 3:
                        is_mono = False  # ✅ It's a color flat

            except Exception as e:
                print(f"⚠️ Warning: Could not retrieve FITS header from {sample_flat}: {e}")

        # ✅ Explicitly ensure we are saving raw values (NO normalization)
        fits_header = original_header if original_header else fits.Header()
        fits_header["BSCALE"] = 1.0  # 🔹 Prevent rescaling
        fits_header["BZERO"] = 0.0   # 🔹 Prevent offset

        # ✅ Save as FITS
        save_image(
            img_array=master_flat,
            filename=output_path,
            original_format="fit",
            bit_depth="32-bit floating point",
            original_header=fits_header,
            is_mono=is_mono
        )

        print(f"✅ Master Flat FITS saved: {output_path}")




    def add_master_flat_to_tree(self, filter_name, master_flat_path):
        """ Adds the newly created Master Flat to the Master Flat TreeBox and stores it. """

        key = f"{filter_name} ({self.master_sizes[master_flat_path]})"
        self.master_files[key] = master_flat_path  # ✅ Store the flat file for future use
        print(f"📝 DEBUG: Stored Master Flat -> {key}: {master_flat_path}")

        existing_items = self.master_flat_tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            filter_item = existing_items[0]
        else:
            filter_item = QTreeWidgetItem([filter_name])
            self.master_flat_tree.addTopLevelItem(filter_item)

        master_item = QTreeWidgetItem([os.path.basename(master_flat_path)])
        filter_item.addChild(master_item)

    def assign_best_master_files(self):
        """ Assign best matching Master Dark and Flat to each Light Frame (per leaf). """
        print("\n🔍 DEBUG: Assigning best Master Darks & Flats to Lights...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Calibration Files available.")
            self.update_status("⚠️ WARNING: No Master Calibration Files available.")
            return

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            filter_name = filter_item.text(0)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)

                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue

                exposure_time = float(match.group(1))

                for k in range(exposure_item.childCount()):
                    leaf_item = exposure_item.child(k)
                    meta_text = leaf_item.text(1)

                    size_match = re.search(r"Size: (\d+x\d+)", meta_text)
                    session_match = re.search(r"Session: ([^|]+)", meta_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                    session_name = session_match.group(1).strip() if session_match else "Default"

                    print(f"🧠 Leaf: {leaf_item.text(0)} | Size: {image_size} | Session: {session_name}")

                    # 🔍 Match Dark
                    best_dark_match = None
                    best_dark_diff = float("inf")

                    for master_key, master_path in self.master_files.items():
                        # ✅ Only consider keys that start with an exposure (i.e. darks)
                        dark_match = re.match(r"^([\d.]+)s\b", master_key)
                        if not dark_match:
                            continue
                        master_dark_exposure_time = float(dark_match.group(1))

                        # Ensure we know the dark’s size
                        master_dark_size = self.master_sizes.get(master_path, "Unknown")
                        if master_dark_size == "Unknown":
                            with fits.open(master_path) as hdul:
                                master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                                self.master_sizes[master_path] = master_dark_size

                        # Only compare if sizes match
                        if master_dark_size == image_size:
                            diff = abs(master_dark_exposure_time - exposure_time)
                            if diff < best_dark_diff:
                                best_dark_match = master_path
                                best_dark_diff = diff

                    # 🔍 Match Flat
                    best_flat_match = None
                    for flat_key, flat_path in self.master_files.items():
                        if filter_name not in flat_key or f"({image_size})" not in flat_key:
                            continue
                        if session_name in flat_key:
                            best_flat_match = flat_path
                            break
                    if not best_flat_match:
                        fallback_key = f"{filter_name} ({image_size})"
                        best_flat_match = self.master_files.get(fallback_key)

                    # 🔄 Assign to leaf
                    leaf_item.setText(2, os.path.basename(best_dark_match) if best_dark_match else "None")
                    leaf_item.setText(3, os.path.basename(best_flat_match) if best_flat_match else "None")

                    print(f"📌 Assigned to {leaf_item.text(0)} -> Dark: {leaf_item.text(2)}, Flat: {leaf_item.text(3)}")

        self.light_tree.viewport().update()
        print("\n✅ DEBUG: Finished assigning Master Files per leaf.\n")

    def update_light_corrections(self):
        """ Updates the light frame corrections when checkboxes change. """
        corrections = []
        if self.cosmetic_checkbox.isChecked():
            corrections.append("Cosmetic: True")
        else:
            corrections.append("Cosmetic: False")

        if self.pedestal_checkbox.isChecked():
            corrections.append("Pedestal: True")
        else:
            corrections.append("Pedestal: False")

        if self.bias_checkbox.isChecked():
            # Show file dialog to select a Master Bias
            bias_file, _ = QFileDialog.getOpenFileName(self, "Select Master Bias Frame", "", "FITS Files (*.fits *.fit)")
            if bias_file:
                self.master_files["Bias"] = bias_file  # ✅ Store bias path
                corrections.append(f"Bias: {os.path.basename(bias_file)}")
            else:
                self.bias_checkbox.setChecked(False)  # If no file selected, uncheck
                return

        # Update all rows
        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_item.setText(4, ", ".join(corrections))

    def light_tree_context_menu(self, pos):
        item = self.light_tree.itemAt(pos)
        if not item:
            return

        menu = QMenu(self.light_tree)
        override_dark_action = menu.addAction("Override Dark Frame")
        override_flat_action = menu.addAction("Override Flat Frame")
        set_session_action = menu.addAction("Set Session Tag...")

        action = menu.exec(self.light_tree.viewport().mapToGlobal(pos))

        if action == override_dark_action:
            self.override_selected_master_dark()
        elif action == override_flat_action:
            self.override_selected_master_flat()
        elif action == set_session_action:
            self.prompt_set_session(item, "LIGHT")


    def set_session_tag_for_group(self, item):
        """
        Prompt the user to assign a session tag to all frames in this group.
        """
        session_name, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session label (e.g., Night1, RedFilterSet2):")
        if not ok or not session_name.strip():
            return

        session_name = session_name.strip()
        filter_name = item.text(0)

        for i in range(item.childCount()):
            exposure_item = item.child(i)
            exposure_label = exposure_item.text(0)

            # Update metadata text
            if exposure_item.childCount() > 0:
                metadata_item = exposure_item.child(0)
                metadata_text = metadata_item.text(1)
                metadata_text = re.sub(r"Session: [^|]+", f"Session: {session_name}", metadata_text)
                if "Session:" not in metadata_text:
                    metadata_text += f" | Session: {session_name}"
                metadata_item.setText(1, metadata_text)

            # Update internal session tag mapping
            composite_key = (f"{filter_name} - {exposure_label}", session_name)
            original_key = f"{filter_name} - {exposure_label}"

            if original_key in self.light_files:
                self.light_files[composite_key] = self.light_files.pop(original_key)

                for path in self.light_files[composite_key]:
                    self.session_tags[path] = session_name

        self.update_status(f"🟢 Assigned session '{session_name}' to group '{filter_name}'")


    def override_selected_master_dark(self):
        """ Opens a file dialog to manually select a Master Dark for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for dark frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Dark", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, os.path.basename(file_path))  # Update tree UI
                self.manual_dark_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Dark for {item.text(0)} with {file_path}")



    def override_selected_master_flat(self):
        """ Opens a file dialog to manually select a Master Flat for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for flat frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Flat", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(3, os.path.basename(file_path))  # Update tree UI
                self.manual_flat_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Flat for {item.text(0)} with {file_path}")


    def toggle_group_correction(self, group_item, which):
        """
        group_item: a top-level item in the light_tree
        which: either "cosmetic" or "pedestal"
        """
        old_text = group_item.text(4)  # e.g. "Cosmetic: True, Pedestal: False"
        # If there's nothing, default them to False
        if not old_text:
            old_text = "Cosmetic: False, Pedestal: False"

        # Parse
        # old_text might be "Cosmetic: True, Pedestal: False"
        # split by comma
        # part[0] => "Cosmetic: True"
        # part[1] => " Pedestal: False"
        parts = old_text.split(",")
        cosmetic_str = "False"
        pedestal_str = "False"
        if len(parts) == 2:
            # parse cosmetic
            cos_part = parts[0].split(":")[-1].strip()  # "True" or "False"
            cosmetic_str = cos_part
            # parse pedestal
            ped_part = parts[1].split(":")[-1].strip()
            pedestal_str = ped_part

        # Convert to bool
        cosmetic_bool = (cosmetic_str.lower() == "true")
        pedestal_bool = (pedestal_str.lower() == "true")

        # Toggle whichever was requested
        if which == "cosmetic":
            cosmetic_bool = not cosmetic_bool
        elif which == "pedestal":
            pedestal_bool = not pedestal_bool

        # Rebuild the new text
        new_text = f"Cosmetic: {str(cosmetic_bool)}, Pedestal: {str(pedestal_bool)}"
        group_item.setText(4, new_text)


    def calibrate_lights(self):
        """Performs calibration on selected light frames using Master Darks and Flats, considering overrides."""
        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first.")
            return

        calibrated_dir = os.path.join(self.stacking_directory, "Calibrated")
        os.makedirs(calibrated_dir, exist_ok=True)

        total_files = sum(len(files) for files in self.light_files.values())
        processed_files = 0

        master_bias_path = self.master_files.get("Bias", None)
        master_bias = None
        if master_bias_path:
            with fits.open(master_bias_path) as bias_hdul:
                master_bias = bias_hdul[0].data.astype(np.float32)
            self.update_status(f"Using Master Bias: {os.path.basename(master_bias_path)}")

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            filter_name = filter_item.text(0)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)

                # Get default corrections
                correction_text = exposure_item.text(4)
                apply_cosmetic = False
                apply_pedestal = False
                if correction_text:
                    parts = correction_text.split(",")
                    if len(parts) == 2:
                        apply_cosmetic = parts[0].split(":")[-1].strip().lower() == "true"
                        apply_pedestal = parts[1].split(":")[-1].strip().lower() == "true"

                pedestal_value = self.pedestal_spinbox.value() / 65535 if apply_pedestal else 0

                for k in range(exposure_item.childCount()):
                    leaf = exposure_item.child(k)
                    filename = leaf.text(0)
                    meta = leaf.text(1)

                    # Get session from metadata
                    session_name = "Default"
                    match = re.search(r"Session: ([^|]+)", meta)
                    if match:
                        session_name = match.group(1).strip()

                    # Look up the light file from session-specific group
                    composite_key = (f"{filter_name} - {exposure_text}", session_name)
                    light_file_list = self.light_files.get(composite_key, [])
                    light_file = next((f for f in light_file_list if os.path.basename(f) == filename), None)
                    if not light_file:
                        continue

                    # Determine size from header
                    header, _ = get_valid_header(light_file)
                    width = int(header.get("NAXIS1", 0))
                    height = int(header.get("NAXIS2", 0))
                    image_size = f"{width}x{height}"

                    # Determine Master Dark (manual override or best match)
                    manual_dark_key = f"{filter_name} - {exposure_text}"
                    master_dark_path = self.manual_dark_overrides.get(manual_dark_key)
                    if not master_dark_path:
                        for key, path in self.master_files.items():
                            if os.path.basename(path) == exposure_item.text(2):
                                master_dark_path = path
                                break

                    # Determine Master Flat (manual override or best session match)
                    manual_flat_key = f"{filter_name} - {exposure_text}"
                    master_flat_path = self.manual_flat_overrides.get(manual_flat_key)
                    if not master_flat_path:
                        flat_key = f"{filter_name} ({image_size}) [{session_name}]"
                        master_flat_path = self.master_files.get(flat_key)

                    self.update_status(f"Processing: {os.path.basename(light_file)}")
                    QApplication.processEvents()

                    light_data, hdr, bit_depth, is_mono = load_image(light_file)
                    if light_data is None or hdr is None:
                        self.update_status(f"❌ ERROR: Failed to load {os.path.basename(light_file)}")
                        continue

                    if not is_mono and light_data.shape[-1] == 3:
                        light_data = light_data.transpose(2, 0, 1)

                    if master_bias is not None:
                        if is_mono:
                            light_data -= master_bias
                        else:
                            light_data -= master_bias[np.newaxis, :, :]
                        self.update_status("Bias Subtracted")
                        QApplication.processEvents()

                    if master_dark_path:
                        dark_data, _, _, dark_is_mono = load_image(master_dark_path)
                        if dark_data is not None:
                            if not dark_is_mono and dark_data.shape[-1] == 3:
                                dark_data = dark_data.transpose(2, 0, 1)
                            light_data = subtract_dark_with_pedestal(
                                light_data[np.newaxis, :, :], dark_data, pedestal_value
                            )[0]
                            self.update_status(f"Dark Subtracted: {os.path.basename(master_dark_path)}")
                            QApplication.processEvents()

                    if master_flat_path:
                        flat_data, _, _, flat_is_mono = load_image(master_flat_path)
                        if flat_data is not None:
                            if not flat_is_mono and flat_data.shape[-1] == 3:
                                flat_data = flat_data.transpose(2, 0, 1)
                            flat_data[flat_data == 0] = 1.0
                            light_data = apply_flat_division_numba(light_data, flat_data)
                            self.update_status(f"Flat Applied: {os.path.basename(master_flat_path)}")
                            QApplication.processEvents()

                    if apply_cosmetic:
                        if hdr.get("BAYERPAT"):
                            light_data = bulk_cosmetic_correction_bayer(light_data)
                            self.update_status("Cosmetic Correction Applied for Bayer Pattern")
                        else:
                            light_data = bulk_cosmetic_correction_numba(light_data)
                            self.update_status("Cosmetic Correction Applied")
                        QApplication.processEvents()

                    if not is_mono and light_data.shape[0] == 3:
                        light_data = light_data.transpose(1, 2, 0)

                    min_val = light_data.min()
                    max_val = light_data.max()
                    self.update_status(f"Before saving: min = {min_val:.4f}, max = {max_val:.4f}")
                    print(f"Before saving: min = {min_val:.4f}, max = {max_val:.4f}")
                    QApplication.processEvents()

                    calibrated_filename = os.path.join(
                        calibrated_dir, os.path.basename(light_file).replace(".fit", "_c.fit")
                    )

                    save_image(
                        img_array=light_data,
                        filename=calibrated_filename,
                        original_format="fit",
                        bit_depth=bit_depth,
                        original_header=hdr,
                        is_mono=is_mono
                    )

                    processed_files += 1
                    self.update_status(f"Saved: {os.path.basename(calibrated_filename)} ({processed_files}/{total_files})")
                    QApplication.processEvents()

        self.update_status("✅ Calibration Complete!")
        QApplication.processEvents()
        self.populate_calibrated_lights()

    def extract_light_files_from_tree(self):
        """
        Walks self.reg_tree and rebuilds self.light_files as
        { group_key: [abs_path1, abs_path2, ...], ... }
        """
        new = {}
        for i in range(self.reg_tree.topLevelItemCount()):
            group = self.reg_tree.topLevelItem(i)
            key   = group.text(0)
            files = []

            # dive into exposure → leaf or direct leaf
            for j in range(group.childCount()):
                sub = group.child(j)
                leaves = []
                if sub.childCount()>0:
                    for k in range(sub.childCount()):
                        leaves.append(sub.child(k))
                else:
                    leaves.append(sub)

                for leaf in leaves:
                    fp = leaf.data(0, Qt.ItemDataRole.UserRole)
                    if fp and os.path.exists(fp):
                        files.append(fp)
                    else:
                        self.update_status(f"⚠️ WARNING: File not found: {fp}")
            if files:
                new[key] = files

        self.light_files = new
        total = sum(len(v) for v in new.values())
        self.update_status(f"✅ Extracted Light Files: {total} total")


    def select_reference_frame_robust(self, frame_weights, sigma_threshold=1.0):
        """
        Instead of sigma filtering, pick the frame at the 75th percentile of frame weights.
        This assumes that higher weights are better and that the 75th percentile represents
        a good-quality frame.
        
        Parameters
        ----------
        frame_weights : dict
            Mapping { file_path: weight_value } for each frame.
        
        Returns
        -------
        best_frame : str or None
            The file path of the chosen reference frame, or None if no frames are available.
        """
        items = list(frame_weights.items())  # List of (file_path, weight) pairs
        if not items:
            return None

        # Sort frames by weight in ascending order.
        items.sort(key=lambda x: x[1])
        n = len(items)
        # Get the index corresponding to the 75th percentile.
        index = int(0.75 * (n - 1))
        best_frame = items[index][0]
        return best_frame

    def prompt_for_reference_frame(self):
        new_ref, _ = QFileDialog.getOpenFileName(
            self,
            "Select New Reference Frame",
            "",  # default directory
            "FITS Files (*.fit *.fits);;All Files (*)"
        )
        return new_ref if new_ref else None

    def register_images(self):
        """ 
        Measures all frames in small batches (to find a reference frame and weights),
        then normalizes each entire frame (again in small batches) using the Numba
        normalize_images function, saves them with a '_n.fit' suffix, and finally
        starts the alignment thread on those normalized files.
        """
        self.update_status("🔄 Image Registration Started...")

        # ── 0) if the user added files “by hand”, use them
        self.extract_light_files_from_tree()
        if not self.light_files:
            self.update_status("⚠️ No light files to register!")
            return

        # ── 1) bail if still nothing
        if not self.light_files:
            self.update

        # Flatten to get all files
        all_files = [f for file_list in self.light_files.values() for f in file_list]
        self.update_status(f"📊 Found {len(all_files)} total frames. Now measuring in parallel batches...")

        self.frame_weights = {}
        mean_values = {}
        star_counts = {}
        measured_frames = []

        max_workers = os.cpu_count() or 4
        chunk_size = max_workers  # or bigger if you prefer

        def chunk_list(lst, size):
            for i in range(0, len(lst), size):
                yield lst[i : i + size]

        chunked_files = list(chunk_list(all_files, chunk_size))
        total_chunks = len(chunked_files)

        # ---------------------------------------------------------------------
        # PHASE 1: Load & Measure Each Chunk (to pick reference frame & weights)
        # ---------------------------------------------------------------------
        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"📦 Measuring chunk {chunk_index}/{total_chunks} ({len(chunk)} frames)")

            chunk_images = []
            chunk_valid_files = []

            # -------------------------------
            # Multi-threaded loading of chunk
            # -------------------------------
            self.update_status(f"🌍 Loading {len(chunk)} images in parallel (up to {max_workers} threads)...")

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Build the dictionary mapping futures to file names
                future_to_file = {}
                for file in chunk:
                    future = executor.submit(load_image, file)
                    future_to_file[future] = file

                for future in as_completed(future_to_file):
                    file = future_to_file[future]
                    try:
                        image_data, header, _, _ = future.result()
                        if image_data is not None:
                            # First check for Bayer pattern in the header
                            if header and header.get('BAYERPAT'):
                                image_data = self.debayer_image(image_data, file, header)
                                self.update_status("📦 Bayer pattern detected, Debayering")
                                QApplication.processEvents()
                            else:
                                # If the image is 3D but has only one channel (e.g. HxWx1), squeeze it to 2D
                                if image_data.ndim == 3 and image_data.shape[-1] == 1:
                                    image_data = np.squeeze(image_data, axis=-1)
                            chunk_images.append(image_data)
                            chunk_valid_files.append(file)
                            self.update_status(f"  Loaded {file}")
                            QApplication.processEvents()
                    except Exception as e:
                        self.update_status(f"⚠️ Error loading {file}: {e}")
                        QApplication.processEvents()



            if not chunk_images:
                self.update_status("⚠️ No valid images in this chunk.")
                continue

            # measure means in parallel
            self.update_status("🌍 Measuring global means in parallel...")
            means = parallel_measure_frames(chunk_images)

            # star counts
            for i, file in enumerate(chunk_valid_files):
                mean_val = means[i]
                mean_values[file] = mean_val

                c, ecc = compute_star_count(chunk_images[i])
                star_counts[file] = {"count": c, "eccentricity": ecc}

                measured_frames.append(file)

            del chunk_images

        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status(f"✅ All chunks complete! Measured {len(measured_frames)} frames total.")

        # ------------------------------------------------
        # 2) Compute Weights & Pick Reference
        # ------------------------------------------------
        self.update_status("⚖️ Computing frame weights...")
        debug_log = "\n📊 **Frame Weights Debug Log:**\n"
        for file in measured_frames:
            c = star_counts[file]["count"]
            ecc = star_counts[file]["eccentricity"]
            m = mean_values[file]

            c = max(c, 1)
            m = max(m, 1e-6)
            raw_w = (c * min(1, max(1.0 - ecc, 0.0))) / m
            self.frame_weights[file] = raw_w

            debug_log += (
                f"📂 {os.path.basename(file)} → "
                f"StarCount={c}, Ecc={ecc:.4f}, Mean={m:.4f}, Weight={raw_w:.4f}\n"
            )

        self.update_status(debug_log)

        max_w = max(self.frame_weights.values()) if self.frame_weights else 0
        if max_w > 0:
            for k in self.frame_weights:
                self.frame_weights[k] /= max_w

        # Choose reference
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference: {self.reference_frame}")
        else:
            self.reference_frame = self.select_reference_frame_robust(self.frame_weights, sigma_threshold=2.0)
            self.update_status(f"📌 Auto-selected robust reference frame: {self.reference_frame}")

        # ------------------------------------------------
        # 3) Load the reference, get ref_median
        # ------------------------------------------------
        ref_data, _, _, _ = load_image(self.reference_frame)
        if ref_data is None:
            self.update_status(f"🚨 Could not load reference {self.reference_frame}. Aborting.")
            return
        ref_median = np.median(ref_data)
        self.update_status(f"📊 Reference median: {ref_median:.4f}")

        stats = {
            "star_count": c,         # Replace with the actual star count
            "eccentricity": ecc,        # Replace with the computed eccentricity
            "mean": ref_median
        }


        # Show the review dialog (pausing further processing until user responds)
        dialog = ReferenceFrameReviewDialog(self.reference_frame, stats, parent=self)
        result = dialog.exec()
        user_choice = dialog.getUserChoice()  # This returns "use", "select_other", or None

        if result == QDialog.DialogCode.Accepted:
            # User chose to use the auto-selected reference via the "Use This Reference Frame" button.
            self.update_status("User accepted the auto-selected reference frame.")
        elif user_choice == "select_other":
            # User actively clicked "Select Other Reference Frame"
            new_ref = self.prompt_for_reference_frame()  # Open a file dialog or list of frames
            if new_ref:
                self.reference_frame = new_ref
                self.update_status(f"User selected a new reference frame: {new_ref}")
            else:
                self.update_status("No new reference frame selected. Using auto-selected frame.")
        else:
            # The dialog was closed (e.g. via the window’s close button) without an active selection.
            self.update_status("Dialog closed without selection. Using auto-selected frame.")

        # ------------------------------------------------
        # 4) Normalize Each Frame to ref_median in Batches
        # ------------------------------------------------
        norm_dir = os.path.join(self.stacking_directory, "Normalized_Images")
        os.makedirs(norm_dir, exist_ok=True)

        chunked_files = list(chunk_list(measured_frames, chunk_size))
        total_chunks = len(chunked_files)
        normalized_files = []

        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"🌀 Normalizing chunk {chunk_index}/{total_chunks} ({len(chunk)} frames)...")
            QApplication.processEvents()

            # --------------
            # Multi-threaded loading again
            # --------------
            loaded_images = []
            valid_paths = []

            self.update_status(f"🌍 Loading {len(chunk)} images in parallel for normalization (up to {max_workers} threads)...")

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_file = {}
                for file in chunk:
                    future = executor.submit(load_image, file)
                    future_to_file[future] = file

                for future in as_completed(future_to_file):
                    file = future_to_file[future]
                    try:
                        img, hdr, _, _ = future.result()
                        if img is not None:
                            # Check for Bayer pattern first – debayer if needed
                            if hdr and hdr.get('BAYERPAT'):
                                img = self.debayer_image(img, file, hdr)
                            else:
                                # Only squeeze if the image has an extra singleton dimension
                                if img.ndim == 3 and img.shape[-1] == 1:
                                    img = np.squeeze(img, axis=-1)
                            loaded_images.append(img)
                            valid_paths.append(file)
                        else:
                            self.update_status(f"⚠️ No data for {file}")
                    except Exception as e:
                        self.update_status(f"⚠️ Error loading {file} for normalization: {e}")
                    QApplication.processEvents()


            if not loaded_images:
                continue

            # shape=(F,H,W) or (F,H,W,C)
            stack = np.array(loaded_images, dtype=np.float32)
            normalized_stack = normalize_images(stack, ref_median)

            # Save each with "_n.fit"
            for i, orig_file in enumerate(valid_paths):
                base = os.path.basename(orig_file)
                if base.endswith("_n.fit"):
                    base = base.replace("_n.fit", ".fit")
                out_name = base.replace(".fit", "_n.fit")
                out_path = os.path.join(norm_dir, out_name)

                frame_data = normalized_stack[i]
                is_mono = (frame_data.ndim == 2)

                # Reuse original header but don't load image data again
                try:
                    orig_header = fits.getheader(orig_file, ext=0)
                except:
                    orig_header = fits.Header()

                hdu = fits.PrimaryHDU(data=frame_data.astype(np.float32), header=orig_header)
                hdu.writeto(out_path, overwrite=True)
                normalized_files.append(out_path)

            del loaded_images, stack, normalized_stack

        # ---------------------------------------------------------
        # 5) ***Update self.light_files to reference *_n.fit***
        # ---------------------------------------------------------
        for group, file_list in self.light_files.items():
            new_list = []
            for old_path in file_list:
                base = os.path.basename(old_path)
                if base.endswith("_n.fit"):
                    # It's already _n
                    new_list.append(os.path.join(norm_dir, base))
                else:
                    n_name = base.replace(".fit", "_n.fit")
                    new_path = os.path.join(norm_dir, n_name)
                    new_list.append(new_path)

            self.light_files[group] = new_list

        self.update_status("✅ Updated self.light_files to use _n.fit paths for all frames.")

        # ------------------------------------------------
        # 6) Start Alignment on the normalized files
        # ------------------------------------------------
        align_dir = os.path.join(self.stacking_directory, "Aligned_Images")
        os.makedirs(align_dir, exist_ok=True)

        self.alignment_thread = StarRegistrationThread(
            self.reference_frame,
            normalized_files,  # the entire list of _n.fit files
            align_dir
        )
        self.alignment_thread.progress_update.connect(self.update_status)
        self.alignment_thread.registration_complete.connect(self.on_registration_complete)
        self.alignment_thread.start()

    def save_alignment_matrices_sasd(self, transforms_dict):
        out_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        try:
            with open(out_path, "w") as f:
                for norm_path, matrix in transforms_dict.items():
                    # Use the original normalized input path (e.g., *_n.fit)
                    orig_path = os.path.normpath(norm_path)

                    a, b, tx = matrix[0]
                    c, d, ty = matrix[1]

                    f.write(f"FILE: {orig_path}\n")
                    f.write("MATRIX:\n")
                    f.write(f"{a:.4f}, {b:.4f}, {tx:.4f}\n")
                    f.write(f"{c:.4f}, {d:.4f}, {ty:.4f}\n")
                    f.write("\n")  # blank line
            self.update_status(f"✅ Transform file saved as {os.path.basename(out_path)}")
        except Exception as e:
            self.update_status(f"⚠️ Failed to save transform file: {e}")



    def load_alignment_matrices_custom(self, file_path):

        transforms = {}
        with open(file_path, "r") as f:
            content = f.read()

        blocks = re.split(r"\n\s*\n", content.strip())

        for block in blocks:
            lines = [line.strip() for line in block.splitlines() if line.strip()]
            if not lines:
                continue
            if lines[0].startswith("FILE:"):
                raw_file_path = lines[0].replace("FILE:", "").strip()
                # *** KEY FIX: normalize here
                curr_file = os.path.normpath(raw_file_path)
            else:
                continue
            
            if len(lines) < 4 or not lines[1].startswith("MATRIX:"):
                continue

            row0 = lines[2].split(",")
            row1 = lines[3].split(",")
            a, b, tx = [float(x) for x in row0]
            c, d, ty = [float(x) for x in row1]

            transforms[curr_file] = np.array([[a, b, tx],
                                            [c, d, ty]], dtype=np.float32)
        return transforms

    def on_registration_complete(self, success, msg):
        self.update_status(msg)

        alignment_thread = self.alignment_thread
        if alignment_thread is None:
            self.update_status("⚠️ Error: No alignment data available.")
            return

        # Copy the final transforms
        all_transforms = alignment_thread.alignment_matrices.copy()

        # Get final shift values
        if not alignment_thread.transform_deltas:
            self.update_status("⚠️ No shift data available. Skipping filtering.")
            final_shifts = [0.0] * len(all_transforms)
        else:
            final_shifts = alignment_thread.transform_deltas[-1]

        # Pair filenames with shift values
        file_shift_pairs = list(zip(all_transforms.keys(), final_shifts))

        # 1) Build numeric transforms for valid frames
        valid_matrices = {
            orig_path: all_transforms[orig_path]
            for orig_path, shift in zip(all_transforms.keys(), final_shifts)
            if all_transforms[orig_path] is not None and shift <= 2.0
        }

        # 2) Build dictionary from the normalized `_n.fit` or `_n.fits` → final aligned `_n_r.fit`
        self.valid_transforms = {}
        for norm_path, shift in file_shift_pairs:
            transform = all_transforms[norm_path]
            if transform is not None and shift <= 2.0:
                base = os.path.basename(norm_path)
                # Check for both .fits and .fit extensions for normalized files.
                if base.endswith("_n.fits"):
                    aligned_name = base.replace("_n.fits", "_n_r.fit")
                elif base.endswith("_n.fit"):
                    aligned_name = base.replace("_n.fit", "_n_r.fit")
                elif base.endswith(".fits"):
                    aligned_name = base.replace(".fits", "_r.fit")
                elif base.endswith(".fit"):
                    aligned_name = base.replace(".fit", "_r.fit")
                else:
                    # Fallback if unexpected extension
                    aligned_name = base + "_r"

                aligned_path = os.path.join(
                    self.stacking_directory, "Aligned_Images", aligned_name
                )
                # Key the dictionary by the *same* normalized path used by the alignment
                self.valid_transforms[os.path.normpath(norm_path)] = aligned_path

        # Identify rejected
        rejected_files = [path for path, shift in file_shift_pairs if shift > 2.0]
        self.alignment_thread = None  # done with the thread

        # Status
        n_valid = len(self.valid_transforms)
        n_total = len(all_transforms)
        self.update_status(f"Alignment summary: {n_valid} succeeded, {n_total - n_valid} rejected.")

        if n_valid == 0:
            self.update_status("⚠️ No frames to stack; aborting.")
            return

        if rejected_files:
            self.update_status(f"🚨 Rejected {len(rejected_files)} frames due to shift > 2px.")
            for rf in rejected_files:
                self.update_status(f"  ❌ {os.path.basename(rf)}")

        # 3) Save numeric transforms
        self.save_alignment_matrices_sasd(valid_matrices)

        # Gather drizzle settings
        drizzle_dict = self.gather_drizzle_settings_from_tree()

        # ===========================
        # DEBUG PRINTS BEFORE FILTER
        # ===========================

        # 4) Filter `light_files`
        filtered_light_files = {}
        for group, file_list in self.light_files.items():
            filtered_light_files[group] = [
                f for f in file_list if os.path.normpath(f) in self.valid_transforms
            ]
            self.update_status(
                f"Group '{group}' has {len(filtered_light_files[group])} file(s) after filtering."
            )

        # 5) **Build a second dict** that replaces each normalized file with its aligned counterpart.
        aligned_light_files = {}
        for group, file_list in filtered_light_files.items():
            
            new_list = []
            for f in file_list:
                normed_f = os.path.normpath(f)
                aligned_f = self.valid_transforms.get(normed_f, None)
                
                if aligned_f and os.path.exists(aligned_f):
                    new_list.append(aligned_f)
                else:
                    self.update_status(f"DEBUG: File '{aligned_f}' does not exist on disk.")
            aligned_light_files[group] = new_list

        # Finally, pass the aligned_light_files to stacking
        self.stack_images_mixed_drizzle(
            grouped_files=aligned_light_files,  # Now we pass the aligned _r.fit paths
            frame_weights=self.frame_weights,
            transforms_dict=self.valid_transforms,
            drizzle_dict=drizzle_dict
        )

    def save_rejection_map_sasr(self, rejection_map, out_file):
        """
        Writes the per-file rejection map to a custom text file.
        Format:
            FILE: path/to/file1
            x1, y1
            x2, y2

            FILE: path/to/file2
            ...
        """
        with open(out_file, "w") as f:
            for fpath, coords_list in rejection_map.items():
                f.write(f"FILE: {fpath}\n")
                for (x, y) in coords_list:
                    # Convert to Python int in case they're NumPy int64
                    f.write(f"{int(x)}, {int(y)}\n")
                f.write("\n")  # blank line to separate blocks

    def load_rejection_map_sasr(self, in_file):
        """
        Reads a .sasr text file and rebuilds the rejection map dictionary.
        Returns a dict { fpath: [(x, y), (x, y), ...], ... }
        """
        rejections = {}
        with open(in_file, "r") as f:
            content = f.read().strip()

        # Split on blank lines
        blocks = re.split(r"\n\s*\n", content)
        for block in blocks:
            lines = [line.strip() for line in block.splitlines() if line.strip()]
            if not lines:
                continue

            # First line should be 'FILE: <path>'
            if lines[0].startswith("FILE:"):
                raw_path = lines[0].replace("FILE:", "").strip()
                coords = []
                for line in lines[1:]:
                    # Each subsequent line is "x, y"
                    parts = line.split(",")
                    if len(parts) == 2:
                        x_str, y_str = parts
                        x = int(x_str.strip())
                        y = int(y_str.strip())
                        coords.append((x, y))
                rejections[raw_path] = coords
        return rejections

    def stack_images_mixed_drizzle(self, grouped_files, frame_weights, transforms_dict, drizzle_dict):
        self.update_status("🔄 Running normal integration to record rejected pixel positions...")
        QApplication.processEvents()
        group_integration_data = {}
        summary_lines = []

        for group_key, file_list in grouped_files.items():
            self.update_status(f"Integration for group '{group_key}' with {len(file_list)} file(s): {file_list}")
            integrated_image, rejection_map, ref_header = self.normal_integration_with_rejection(
                group_key, file_list, frame_weights
            )

            if integrated_image is None:
                continue

            if ref_header is None:
                ref_header = fits.Header()

            ref_header["IMAGETYP"] = "MASTER STACK"
            ref_header["BITPIX"] = -32
            ref_header["STACKED"] = (True, "Stacked using normal_integration_with_rejection")
            ref_header["CREATOR"] = "SetiAstroSuite"
            ref_header["DATE-OBS"] = datetime.utcnow().isoformat()

            is_mono = (integrated_image.ndim == 2)
            if is_mono:
                ref_header["NAXIS"] = 2
                ref_header["NAXIS1"] = integrated_image.shape[1]
                ref_header["NAXIS2"] = integrated_image.shape[0]
            else:
                ref_header["NAXIS"] = 3
                ref_header["NAXIS1"] = integrated_image.shape[1]
                ref_header["NAXIS2"] = integrated_image.shape[0]
                ref_header["NAXIS3"] = 3

            n_frames = len(file_list)
            out_path = os.path.join(self.stacking_directory, f"MasterLight_{group_key}_{n_frames}stacked.fit")
            save_image(
                img_array=integrated_image,
                filename=out_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=ref_header,
                is_mono=is_mono
            )
            self.update_status(f"✅ Saved integrated image for '{group_key}' using {n_frames} frame(s): {out_path}")
            QApplication.processEvents()

            dconf = drizzle_dict.get(group_key, {})
            if dconf.get("drizzle_enabled", False):
                sasr_path = os.path.join(self.stacking_directory, f"{group_key}_rejections.sasr")
                self.save_rejection_map_sasr(rejection_map, sasr_path)
                self.update_status(f"✅ Saved rejection map to {sasr_path}")
                group_integration_data[group_key] = {
                    "integrated_image": integrated_image,
                    "rejection_map": rejection_map,
                    "n_frames": n_frames,
                    "drizzled": True
                }
            else:
                group_integration_data[group_key] = {
                    "integrated_image": integrated_image,
                    "rejection_map": None,
                    "n_frames": n_frames,
                    "drizzled": False
                }
                self.update_status(f"ℹ️ Skipping rejection map save for '{group_key}' (drizzle disabled).")

        for group_key, file_list in grouped_files.items():
            dconf = drizzle_dict.get(group_key, None)
            if dconf and dconf.get("drizzle_enabled", False):
                scale_factor = dconf["scale_factor"]
                drop_shrink = dconf["drop_shrink"]
                rejections_for_group = group_integration_data[group_key]["rejection_map"]
                n_frames = group_integration_data[group_key]["n_frames"]

                self.update_status(f"📐 Drizzle for '{group_key}' at {scale_factor}× (drop={drop_shrink}) using {n_frames} frame(s).")
                QApplication.processEvents()

                self.drizzle_stack_one_group(
                    group_key=group_key,
                    file_list=file_list,
                    transforms_dict=transforms_dict,
                    frame_weights=frame_weights,
                    scale_factor=scale_factor,
                    drop_shrink=drop_shrink,
                    rejection_map=rejections_for_group
                )
            else:
                self.update_status(f"✅ Group '{group_key}' not set for drizzle. Integrated image already saved.")
                QApplication.processEvents()

        # 🧾 Summary message box
        for group_key, info in group_integration_data.items():
            n_frames = info["n_frames"]
            drizzled = info["drizzled"]
            summary_lines.append(f"• {group_key}: {n_frames} stacked{' + drizzle' if drizzled else ''}")

        summary_text = "\n".join(summary_lines)
        QMessageBox.information(
            self,
            "Integration Summary",
            f"The following groups were successfully integrated:\n\n{summary_text}"
        )

    def save_registered_images(self, success, msg, frame_weights):
        if not success:
            self.update_status(f"⚠️ Image registration failed: {msg}")
            return

        self.update_status("✅ All frames registered successfully!")
        
        # Use the grouped files already stored from the tree view.
        if not self.light_files:
            self.update_status("⚠️ No light frames available for stacking!")
            return
        
        self.update_status(f"📂 Preparing to stack {sum(len(v) for v in self.light_files.values())} frames in {len(self.light_files)} groups.")
        
        # Pass the dictionary (grouped by filter, exposure, dimensions) to the stacking function.
        self.stack_registered_images(self.light_files, frame_weights)


    def stack_registered_images_chunked(
        self,
        grouped_files,           # dict of { group_key: [list_of_aligned_and_already_normalized_file_paths] }
        frame_weights,           # dict of { file_path: weight }
        chunk_height=2048,
        chunk_width=2048
    ):
        """
        Chunked stacking of already-aligned and pre-normalized FITS images.
        Reads small tiles from each image, applies outlier rejection (using the new rejection-map output),
        writes the result into a memory-mapped array, and saves a final stacked FITS.
        """
        self.update_status(f"✅ Chunked stacking {len(grouped_files)} group(s)...")

        # We'll also accumulate a list of rejected pixel positions (global coordinates)
        all_rejection_coords = []

        for group_key, file_list in grouped_files.items():
            num_files = len(file_list)
            self.update_status(f"📊 Group '{group_key}' has {num_files} aligned file(s).")
            QApplication.processEvents()

            if num_files < 2:
                self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to stack.")
                continue

            # 1) Identify the reference file to get shape and header
            ref_file = file_list[0]
            if not os.path.exists(ref_file):
                self.update_status(f"⚠️ Reference file '{ref_file}' not found, skipping group.")
                continue

            ref_data, ref_header, _, _ = load_image(ref_file)
            if ref_data is None:
                self.update_status(f"⚠️ Could not load reference '{ref_file}', skipping group.")
                continue

            is_color = (ref_data.ndim == 3 and ref_data.shape[2] == 3)
            height, width = ref_data.shape[:2]
            channels = 3 if is_color else 1

            # 2) Prepare a memmap for the final stacked image.
            memmap_path = os.path.join(self.stacking_directory, f"chunked_{group_key}.dat")
            final_stacked = np.memmap(
                memmap_path,
                dtype=np.float32,
                mode='w+',
                shape=(height, width, channels)
            )

            # Build list of valid files and corresponding weights.
            aligned_paths = []
            weights_list = []
            for fpath in file_list:
                if os.path.exists(fpath):
                    aligned_paths.append(fpath)
                    w = frame_weights.get(fpath, 1.0)
                    weights_list.append(w)
                else:
                    self.update_status(f"⚠️ File not found: {fpath}, skipping.")

            if len(aligned_paths) < 2:
                self.update_status(f"⚠️ Not enough valid frames in group '{group_key}' to stack.")
                continue

            weights_list = np.array(weights_list, dtype=np.float32)
            self.update_status(f"📊 Stacking group '{group_key}' with {self.rejection_algorithm}")
            QApplication.processEvents()

            # Initialize a list to collect rejected pixel coordinates for this group.
            rejection_coords = []

            # 3) Loop over tiles
            from concurrent.futures import ThreadPoolExecutor, as_completed
            for y_start in range(0, height, chunk_height):
                y_end = min(y_start + chunk_height, height)
                tile_h = y_end - y_start

                for x_start in range(0, width, chunk_width):
                    x_end = min(x_start + chunk_width, width)
                    tile_w = x_end - x_start

                    # Build tile stack: shape (N, tile_h, tile_w, channels)
                    N = len(aligned_paths)
                    tile_stack = np.zeros((N, tile_h, tile_w, channels), dtype=np.float32)
                    num_cores = os.cpu_count() or 4
                    with ThreadPoolExecutor(max_workers=num_cores) as executor:
                        future_to_index = {}
                        for i, path in enumerate(aligned_paths):
                            future = executor.submit(load_fits_tile, path, y_start, y_end, x_start, x_end)
                            future_to_index[future] = i

                        for future in as_completed(future_to_index):
                            i = future_to_index[future]
                            sub_img = future.result()
                            if sub_img is None:
                                continue
                            # Ensure sub_img is shaped (tile_h, tile_w, channels)
                            if sub_img.ndim == 2:
                                sub_img = sub_img[:, :, np.newaxis]
                                if channels == 3:
                                    sub_img = np.repeat(sub_img, 3, axis=2)
                            elif sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                                sub_img = sub_img.transpose(1, 2, 0)
                            sub_img = sub_img.astype(np.float32, copy=False)
                            tile_stack[i] = sub_img

                    # 4) Apply the chosen rejection algorithm and get the rejection map.
                    algo = self.rejection_algorithm
                    if algo == "Simple Median (No Rejection)":
                        tile_result = np.median(tile_stack, axis=0)
                        tile_rej_map = np.zeros(tile_stack.shape[1:], dtype=np.bool_)
                    elif algo == "Simple Average (No Rejection)":
                        tile_result = np.average(tile_stack, axis=0, weights=weights_list)
                        tile_rej_map = np.zeros(tile_stack.shape[1:], dtype=np.bool_)
                    elif algo == "Weighted Windsorized Sigma Clipping":
                        tile_result, tile_rej_map = windsorized_sigma_clip_weighted(tile_stack, weights_list,
                            lower=self.sigma_low, upper=self.sigma_high)
                    elif algo == "Kappa-Sigma Clipping":
                        tile_result, tile_rej_map = kappa_sigma_clip_weighted(tile_stack, weights_list,
                            kappa=self.kappa, iterations=self.iterations)
                    elif algo == "Trimmed Mean":
                        tile_result, tile_rej_map = trimmed_mean_weighted(tile_stack, weights_list,
                            trim_fraction=self.trim_fraction)
                    elif algo == "Extreme Studentized Deviate (ESD)":
                        tile_result, tile_rej_map = esd_clip_weighted(tile_stack, weights_list,
                            threshold=self.esd_threshold)
                    elif algo == "Biweight Estimator":
                        tile_result, tile_rej_map = biweight_location_weighted(tile_stack, weights_list,
                            tuning_constant=self.biweight_constant)
                    elif algo == "Modified Z-Score Clipping":
                        tile_result, tile_rej_map = modified_zscore_clip_weighted(tile_stack, weights_list,
                            threshold=self.modz_threshold)
                    else:
                        tile_result, tile_rej_map = windsorized_sigma_clip_weighted(tile_stack, weights_list,
                            lower=self.sigma_low, upper=self.sigma_high)

                    # 5) Insert integrated tile into final image.
                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

                    # 6) Use the returned tile_rej_map to record rejected pixel positions.
                    # For rejection maps with per-frame output, combine along the frame axis.
                    if tile_rej_map.ndim == 3:  # mono: (N, tile_h, tile_w)
                        combined_rej = np.any(tile_rej_map, axis=0)  # shape: (tile_h, tile_w)
                    elif tile_rej_map.ndim == 4:  # color: (N, tile_h, tile_w, channels)
                        # First combine along the frame axis, then across channels.
                        combined_rej = np.any(tile_rej_map, axis=0)  # shape: (tile_h, tile_w, channels)
                        combined_rej = np.any(combined_rej, axis=-1)  # shape: (tile_h, tile_w)
                    else:
                        combined_rej = np.zeros(tile_stack.shape[1:3], dtype=np.bool_)

                    ys_tile, xs_tile = np.where(combined_rej)
                    for dx, dy in zip(xs_tile, ys_tile):
                        global_x = x_start + dx
                        global_y = y_start + dy
                        rejection_coords.append((global_x, global_y))

            # 7) After processing all tiles, finish up the integrated image.
            final_array = np.array(final_stacked)
            del final_stacked

            # Apply a black-point offset and scale if needed.
            flat_array = final_array.ravel()
            nonzero_indices = np.where(flat_array > 0)[0]
            if nonzero_indices.size > 0:
                first_nonzero = flat_array[nonzero_indices[0]]
                final_array -= first_nonzero

            new_max = final_array.max()
            if new_max > 1.0:
                new_min = final_array.min()
                range_val = new_max - new_min
                if range_val != 0:
                    final_array = (final_array - new_min) / range_val
                else:
                    final_array = np.zeros_like(final_array, dtype=np.float32)

            if final_array.ndim == 3 and final_array.shape[-1] == 1:
                final_array = final_array[..., 0]
            is_mono = (final_array.ndim == 2)

            # 8) Save the final stacked image.
            if ref_header is None:
                ref_header = fits.Header()

            ref_header["IMAGETYP"] = "MASTER STACK"
            ref_header["BITPIX"] = -32
            ref_header["STACKED"] = (True, "Stacked using chunked approach")
            ref_header["CREATOR"] = "SetiAstroSuite"
            ref_header["DATE-OBS"] = datetime.utcnow().isoformat()

            if is_mono:
                ref_header["NAXIS"] = 2
                ref_header["NAXIS1"] = final_array.shape[1]
                ref_header["NAXIS2"] = final_array.shape[0]
            else:
                ref_header["NAXIS"] = 3
                ref_header["NAXIS1"] = final_array.shape[1]
                ref_header["NAXIS2"] = final_array.shape[0]
                ref_header["NAXIS3"] = 3

            output_filename = f"MasterLight_{group_key}_{len(aligned_paths)}stacked.fit"
            output_path = os.path.join(self.stacking_directory, output_filename)
            save_image(
                img_array=final_array,
                filename=output_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=ref_header,
                is_mono=is_mono
            )

            self.update_status(f"✅ Group '{group_key}' stacked {len(aligned_paths)} frame(s)! Saved: {output_path}")

            print(f"✅ Master Light saved for group '{group_key}': {output_path}")

            # Optionally, you might want to store or log 'rejection_coords' (here appended to all_rejection_coords)
            all_rejection_coords.extend(rejection_coords)

            # Clean up memmap file
            try:
                os.remove(memmap_path)
            except OSError:
                pass

        # Optionally, you could return the global rejection coordinate list.
        return all_rejection_coords

        QMessageBox.information(
            self,
            "Stacking Complete",
            f"All stacking finished successfully.\n"
            f"Frames per group:\n" +
            "\n".join([f"{group_key}: {len(files)} frame(s)" for group_key, files in grouped_files.items()])
        )



    def integrate_registered_images(self):
        """ 
        Integrates previously registered images (already aligned) without re-aligning them,
        but uses a chunked measurement approach so we don't load all frames at once.
        """
        self.update_status("🔄 Integrating Previously Registered Images...")

        # 1) Extract files from the registration tree
        self.extract_light_files_from_tree()
        if not self.light_files:
            self.update_status("⚠️ No registered images found!")
            return

        # Flatten the dictionary to get all registered files
        all_files = [f for file_list in self.light_files.values() for f in file_list]
        if not all_files:
            self.update_status("⚠️ No frames found in the registration tree!")
            return

        # 2) We'll measure means + star counts in chunks, so we don't load everything at once
        self.update_status(f"📊 Found {len(all_files)} total aligned frames. Measuring in parallel batches...")

        self.frame_weights = {}
        mean_values = {}
        star_counts = {}
        measured_frames = []

        # Decide how many images to load at once. Typically # of CPU cores:
        import os
        max_workers = os.cpu_count() or 4
        chunk_size = max_workers  # or a custom formula if you prefer

        def chunk_list(lst, size):
            for i in range(0, len(lst), size):
                yield lst[i : i + size]

        chunked_files = list(chunk_list(all_files, chunk_size))
        total_chunks = len(chunked_files)

        # 3) Process each chunk
        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"📦 Loading and measuring chunk {chunk_index}/{total_chunks} with {len(chunk)} frames...")
            QApplication.processEvents()

            # Load this chunk of images
            images = []
            valid_files_for_this_chunk = []
            for file in chunk:
                image_data, _, _, _ = load_image(file)
                if image_data is not None:
                    images.append(image_data)
                    valid_files_for_this_chunk.append(file)
                else:
                    self.update_status(f"⚠️ Could not load {file}, skipping.")

            if not images:
                self.update_status("⚠️ No valid images in this chunk.")
                continue

            # Parallel measure the mean pixel value
            self.update_status("🌍 Measuring global statistics (mean) in parallel...")
            QApplication.processEvents()
            means = parallel_measure_frames(images)

            # Now measure star counts
            for i, file in enumerate(valid_files_for_this_chunk):
                mean_signal = means[i]
                mean_values[file] = mean_signal
                measured_frames.append(file)

                self.update_status(f"⭐ Measuring star stats for {file}...")
                QApplication.processEvents()
                count, ecc = compute_star_count(images[i])
                star_counts[file] = {"count": count, "eccentricity": ecc}

            # Clear the images from memory before moving on
            del images

        # If we never measured any frames at all
        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status(f"✅ All chunks complete! Measured {len(measured_frames)} frames total.")
        QApplication.processEvents()

        # 4) Compute Weights
        self.update_status("⚖️ Computing frame weights...")

        debug_weight_log = "\n📊 **Frame Weights Debug Log:**\n"
        QApplication.processEvents()
        for file in measured_frames:
            c = star_counts[file]["count"]
            ecc = star_counts[file]["eccentricity"]
            mean_val = mean_values[file]

            star_weight = max(c, 1e-6)
            mean_weight = max(mean_val, 1e-6)

            # Basic ratio-based weight: star_count / mean
            raw_weight = star_weight / mean_weight
            self.frame_weights[file] = raw_weight

            debug_weight_log += (
                f"📂 {os.path.basename(file)} → "
                f"Star Count: {c}, Mean: {mean_val:.4f}, Final Weight: {raw_weight:.4f}\n"
            )
            QApplication.processEvents()

        self.update_status(debug_weight_log)
        self.update_status("✅ Frame weights computed!")
        QApplication.processEvents()

        # 5) Pick the best reference frame if not user-specified
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference frame: {self.reference_frame}")
            QApplication.processEvents()
        else:
            self.reference_frame = max(self.frame_weights, key=self.frame_weights.get)
            self.update_status(f"📌 Auto-selected reference frame: {self.reference_frame} (Best Weight)")
            
        chunk_h = self.chunk_height  # or self.settings.value("stacking/chunk_height", 1024, type=int)
        chunk_w = self.chunk_width   # or self.settings.value("stacking/chunk_width", 1024, type=int)

        # 6) Finally, call the chunked stacking method using the already registered images
        self.stack_registered_images_chunked(self.light_files, self.frame_weights, chunk_height=chunk_h, chunk_width=chunk_w)

    @staticmethod
    def invert_affine_transform(matrix):
        """
        Inverts a 2x3 affine transformation matrix.
        Given matrix = [[a, b, tx],
                        [c, d, ty]],
        returns the inverse matrix.
        """
        A = matrix[:, :2]
        t = matrix[:, 2]
        A_inv = np.linalg.inv(A)
        t_inv = -A_inv @ t
        inv = np.hstack([A_inv, t_inv.reshape(2, 1)])
        return inv

    @staticmethod
    def apply_affine_transform_point(matrix, x, y):
        """
        Applies a 2x3 affine transformation to a point (x, y).
        Returns the transformed (x, y) coordinates.
        """
        point = np.array([x, y])
        result = matrix[:, :2] @ point + matrix[:, 2]
        return result[0], result[1]

    def drizzle_stack_one_group(
        self,
        group_key,
        file_list,
        transforms_dict,
        frame_weights,
        scale_factor=2.0,
        drop_shrink=0.65,
        rejection_map=None
    ):
        """
        Drizzle a single group. Now, we only skip the pixels that are actually rejected for
        each file (based on the per-file rejection_map).
        
        'rejection_map' is a dict: { file_path: [(x_r, y_r), (x_r, y_r), ...], ... }
        where (x_r, y_r) are coordinates in the aligned (_n_r) space that were rejected
        for THAT particular file.
        """
        # Count how many total rejections across all files (for debug)
        total_rej = 0
        if rejection_map is not None:
            total_rej = sum(len(v) for v in rejection_map.values())
        self.update_status(
            f"🔭 Drizzle stacking for group '{group_key}' with {total_rej} total rejected pixels across files."
        )
        QApplication.processEvents()

        # 1) Check we have enough frames
        if len(file_list) < 2:
            self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to drizzle.")
            return

        # 2) Load transforms from disk
        transforms_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        if not os.path.exists(transforms_path):
            self.update_status(f"⚠️ No alignment_transforms.sasd found at {transforms_path}!")
            return

        new_transforms_dict = self.load_alignment_matrices_custom(transforms_path)
        self.update_status(f"✅ Loaded {len(new_transforms_dict)} transforms from disk for drizzle.")
        QApplication.processEvents()

        # 3) Load the first file to determine shape + color/mono
        first_file = file_list[0]
        first_img, hdr, _, _ = load_image(first_file)
        if first_img is None:
            self.update_status(f"⚠️ Could not load {first_file} to determine drizzle shape!")
            return

        if first_img.ndim == 2:
            is_mono = True
            h, w = first_img.shape
        else:
            is_mono = False
            h, w, c = first_img.shape

        # 4) Decide deposit function (naive vs footprint)
        if drop_shrink >= 0.99:
            if is_mono:
                deposit_func = drizzle_deposit_numba_naive
                self.update_status("Using naive drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_naive
                self.update_status("Using naive drizzle deposit (color).")
        else:
            if is_mono:
                deposit_func = drizzle_deposit_numba_footprint
                self.update_status("Using footprint drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_footprint
                self.update_status("Using footprint drizzle deposit (color).")
        QApplication.processEvents()

        # 5) Prepare drizzle buffers
        out_h = int(h * scale_factor)
        out_w = int(w * scale_factor)
        if is_mono:
            drizzle_buffer = np.zeros((out_h, out_w), dtype=np.float32)
            coverage_buffer = np.zeros((out_h, out_w), dtype=np.float32)
            finalize_func = finalize_drizzle_2d
        else:
            drizzle_buffer = np.zeros((out_h, out_w, c), dtype=np.float32)
            coverage_buffer = np.zeros((out_h, out_w, c), dtype=np.float32)
            finalize_func = finalize_drizzle_3d

        # 6) For each aligned file, deposit raw pixels—skipping only that file's rejections
        for aligned_file in file_list:
            aligned_base = os.path.basename(aligned_file)
            if aligned_base.endswith("_n_r.fit"):
                raw_base = aligned_base.replace("_n_r.fit", "_n.fit")
            else:
                raw_base = aligned_base

            raw_file = os.path.join(self.stacking_directory, "Normalized_Images", raw_base)
            raw_img_data, _, _, _ = load_image(raw_file)
            if raw_img_data is None:
                self.update_status(f"⚠️ Could not load raw file '{raw_file}' for drizzle!")
                continue

            # Look up transform
            raw_key = os.path.normpath(raw_file)
            transform = new_transforms_dict.get(raw_key, None)
            if transform is None:
                self.update_status(f"⚠️ No transform found for raw '{raw_base}'! Skipping drizzle.")
                continue

            self.update_status(f"🧩 Drizzling (raw): {raw_base}")
            self.update_status(
                f"    Matrix: [[{transform[0,0]:.4f}, {transform[0,1]:.4f}, {transform[0,2]:.4f}], "
                f"[{transform[1,0]:.4f}, {transform[1,1]:.4f}, {transform[1,2]:.4f}]]"
            )
            QApplication.processEvents()

            weight = frame_weights.get(aligned_file, 1.0)
            if transform.dtype != np.float32:
                transform = transform.astype(np.float32)

            # Only skip rejections for THIS file
            coords_for_this_file = []
            if rejection_map is not None:
                coords_for_this_file = rejection_map.get(aligned_file, [])

            # Mask out those pixels in the raw image
            if coords_for_this_file:
                inv_transform = self.invert_affine_transform(transform)
                for (x_r, y_r) in coords_for_this_file:
                    x_raw, y_raw = self.apply_affine_transform_point(inv_transform, x_r, y_r)
                    x_raw = int(round(x_raw))
                    y_raw = int(round(y_raw))
                    if 0 <= x_raw < raw_img_data.shape[1] and 0 <= y_raw < raw_img_data.shape[0]:
                        raw_img_data[y_raw, x_raw] = 0.0

            # Deposit raw pixels using the transform
            drizzle_buffer, coverage_buffer = deposit_func(
                raw_img_data,
                transform,
                drizzle_buffer,
                coverage_buffer,
                scale_factor,
                drop_shrink,
                weight
            )

        # 7) Finalize drizzle
        final_drizzle = np.zeros_like(drizzle_buffer, dtype=np.float32)
        final_drizzle = finalize_func(drizzle_buffer, coverage_buffer, final_drizzle)

        # 8) Save final drizzle image
        out_filename = f"MasterLight_{group_key}_{len(file_list)}stacked_drizzle.fit"

        out_path = os.path.join(self.stacking_directory, out_filename)
        if hdr is None:
            hdr = fits.Header()
        hdr["IMAGETYP"]  = "MASTER STACK - DRIZZLE"
        hdr["DRIZFACTOR"] = (scale_factor, "Drizzle scale factor")
        hdr["DROPFRAC"]   = (drop_shrink, "Drizzle drop shrink/pixfrac")
        hdr["CREATOR"]    = "SetiAstroSuite"
        hdr["DATE-OBS"]   = datetime.utcnow().isoformat()

        if final_drizzle.ndim == 3 and final_drizzle.shape[-1] == 3:
            is_mono = False
        else:
            is_mono = True

        if is_mono:
            hdr["NAXIS"] = 2
            hdr["NAXIS1"] = final_drizzle.shape[1]
            hdr["NAXIS2"] = final_drizzle.shape[0]
        else:
            hdr["NAXIS"] = 3
            hdr["NAXIS1"] = final_drizzle.shape[1]
            hdr["NAXIS2"] = final_drizzle.shape[0]
            hdr["NAXIS3"] = 3

        save_image(
            img_array=final_drizzle,
            filename=out_path,
            original_format="fit",
            bit_depth="32-bit floating point",
            original_header=hdr,
            is_mono=is_mono
        )

        self.update_status(f"✅ Drizzle group '{group_key}' done! Stacked {len(file_list)} frame(s). Saved: {out_path}")



    def normal_integration_with_rejection(self, group_key, file_list, frame_weights):
        """
        Performs chunked stacking integration of aligned (_n_r) images using the current
        rejection algorithm. Returns:
        integrated_image: Final integrated (stacked) image as a NumPy array.
        per_file_rejections: dict mapping each file in 'file_list' to a list of (x,y) 
                            coordinates that were rejected for THAT file only.
        ref_header: the header from the reference file (or a new one if missing)
        """
        import os
        from concurrent.futures import ThreadPoolExecutor, as_completed
        self.update_status(f"Starting integration for group '{group_key}' with {len(file_list)} files.")
        if not file_list:
            self.update_status(f"DEBUG: Empty file_list for group '{group_key}'.")
            return None, {}, None
        # 1) Load a reference image to determine dimensions and channels
        ref_file = file_list[0]
        if not os.path.exists(ref_file):
            self.update_status(f"⚠️ Reference file '{ref_file}' not found for group '{group_key}'.")
            return None, {}, None
        ref_data, ref_header, _, _ = load_image(ref_file)
        if ref_data is None:
            self.update_status(f"⚠️ Could not load reference '{ref_file}' for group '{group_key}'.")
            return None, {}, None

        if ref_header is None:
            ref_header = fits.Header()  # fallback if no header was present

        is_color = (ref_data.ndim == 3 and ref_data.shape[2] == 3)
        height, width = ref_data.shape[:2]
        channels = 3 if is_color else 1
        self.update_status(f"📊 Stacking group '{group_key}' with {self.rejection_algorithm}")
        QApplication.processEvents()
        # 2) Allocate final integrated image and set up a dictionary for rejections
        integrated_image = np.zeros((height, width, channels), dtype=np.float32)
        per_file_rejections = {f: [] for f in file_list}

        # 3) Define tile dimensions
        chunk_h = self.chunk_height
        chunk_w = self.chunk_width

        # 4) Process the image tile by tile
        for y_start in range(0, height, chunk_h):
            y_end = min(y_start + chunk_h, height)
            tile_h = y_end - y_start

            for x_start in range(0, width, chunk_w):
                x_end = min(x_start + chunk_w, width)
                tile_w = x_end - x_start

                # Build a tile stack: shape (N, tile_h, tile_w, channels)
                N = len(file_list)
                tile_stack = np.zeros((N, tile_h, tile_w, channels), dtype=np.float32)
                weights_list = []
                num_cores = os.cpu_count() or 4

                with ThreadPoolExecutor(max_workers=num_cores) as executor:
                    future_to_index = {}
                    for i, fpath in enumerate(file_list):
                        
                        future = executor.submit(load_fits_tile, fpath, y_start, y_end, x_start, x_end)
                        future_to_index[future] = i
                        weights_list.append(frame_weights.get(fpath, 1.0))

                    for future in as_completed(future_to_index):
                        i = future_to_index[future]
                        sub_img = future.result()
                        if sub_img is None:
                            self.update_status(f"DEBUG: Tile load returned None for file: {file_list[i]}")
                            continue
                        # Ensure shape => (tile_h, tile_w, channels)
                        if sub_img.ndim == 2:
                            sub_img = sub_img[:, :, np.newaxis]
                            if channels == 3:
                                sub_img = np.repeat(sub_img, 3, axis=2)
                        elif sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                            sub_img = sub_img.transpose(1, 2, 0)
                        sub_img = sub_img.astype(np.float32, copy=False)
                        tile_stack[i] = sub_img

                weights_array = np.array(weights_list, dtype=np.float32)

                # 5) Run your chosen rejection algorithm => (tile_result, tile_rej_map)
                algo = self.rejection_algorithm
                if algo == "Simple Median (No Rejection)":
                    tile_result = np.median(tile_stack, axis=0)
                    tile_rej_map = np.zeros((N, tile_h, tile_w), dtype=np.bool_)
                elif algo == "Simple Average (No Rejection)":
                    tile_result = np.average(tile_stack, axis=0, weights=weights_array)
                    tile_rej_map = np.zeros((N, tile_h, tile_w), dtype=np.bool_)
                elif algo == "Weighted Windsorized Sigma Clipping":
                    tile_result, tile_rej_map = windsorized_sigma_clip_weighted(
                        tile_stack, weights_array,
                        lower=self.sigma_low, upper=self.sigma_high
                    )
                elif algo == "Kappa-Sigma Clipping":
                    tile_result, tile_rej_map = kappa_sigma_clip_weighted(
                        tile_stack, weights_array,
                        kappa=self.kappa, iterations=self.iterations
                    )
                elif algo == "Trimmed Mean":
                    tile_result, tile_rej_map = trimmed_mean_weighted(
                        tile_stack, weights_array,
                        trim_fraction=self.trim_fraction
                    )
                elif algo == "Extreme Studentized Deviate (ESD)":
                    tile_result, tile_rej_map = esd_clip_weighted(
                        tile_stack, weights_array,
                        threshold=self.esd_threshold
                    )
                elif algo == "Biweight Estimator":
                    tile_result, tile_rej_map = biweight_location_weighted(
                        tile_stack, weights_array,
                        tuning_constant=self.biweight_constant
                    )
                elif algo == "Modified Z-Score Clipping":
                    tile_result, tile_rej_map = modified_zscore_clip_weighted(
                        tile_stack, weights_array,
                        threshold=self.modz_threshold
                    )
                else:
                    tile_result, tile_rej_map = windsorized_sigma_clip_weighted(
                        tile_stack, weights_array,
                        lower=self.sigma_low, upper=self.sigma_high
                    )

                # 6) Place the integrated tile into the final image
                integrated_image[y_start:y_end, x_start:x_end, :] = tile_result

                # 7) For color, tile_rej_map is shape (N, tile_h, tile_w, C). Combine channels if needed.
                if tile_rej_map.ndim == 4:
                    # shape => (N, tile_h, tile_w, channels)
                    # reduce across channels => (N, tile_h, tile_w)
                    tile_rej_map = np.any(tile_rej_map, axis=-1)

                # 8) Now tile_rej_map is shape (N, tile_h, tile_w). Record the rejections per file
                for i, fpath in enumerate(file_list):
                    frame_mask = tile_rej_map[i]  # shape (tile_h, tile_w)
                    ys_tile, xs_tile = np.where(frame_mask)
                    for dx, dy in zip(xs_tile, ys_tile):
                        global_x = x_start + dx
                        global_y = y_start + dy
                        per_file_rejections[fpath].append((global_x, global_y))

        # 9) Squeeze if mono
        if channels == 1:
            integrated_image = integrated_image[..., 0]

        # Return integrated_image, the per-file rejection dictionary, and the reference header
        return integrated_image, per_file_rejections, ref_header


    def outlier_rejection_with_mask(self, tile_stack, weights_array):
        """
        Example outlier rejection routine that computes the weighted median of the tile stack
        and returns both the integrated tile and a rejection mask.
        
        Parameters:
        tile_stack: numpy array of shape (N, H, W, C)
        weights_array: numpy array of shape (N,)
        
        Returns:
        tile_result: numpy array of shape (H, W, C)
        rejection_mask: boolean numpy array of shape (H, W) where True indicates a rejected pixel.
        
        This is a simple example. Replace this logic with your actual rejection algorithm.
        """
        # Compute the weighted median along axis 0.
        # For simplicity, we'll use the unweighted median here.
        tile_result = np.median(tile_stack, axis=0)
        
        # Compute the absolute deviation for each frame and take the median deviation.
        # Then mark as rejected any pixel in any frame that deviates by more than a threshold.
        # Here we define a threshold factor (this value may need tuning).
        threshold_factor = 1.5
        abs_deviation = np.abs(tile_stack - tile_result)
        # Compute the median deviation per pixel over the frames.
        median_deviation = np.median(abs_deviation, axis=0)
        # Define a rejection mask: True if the median deviation exceeds a threshold.
        # (For demonstration, assume threshold = threshold_factor * some constant; here we choose 0.05.)
        rejection_mask = median_deviation[..., 0] > (threshold_factor * 0.05)
        # If color, you might combine channels or process each channel separately.
        
        return tile_result, rejection_mask


def load_fits_tile(filepath, y_start, y_end, x_start, x_end):
    """
    Loads a sub-region from a FITS file, detecting which axes are spatial vs. color.
    
    * If the data is 2D, it might be (height, width) or (width, height).
    * If the data is 3D, it might be:
        - (height, width, 3)
        - (3, height, width)
        - (width, height, 3)
        - (3, width, height)
      We only slice the two spatial dimensions; the color axis remains intact.
    
    The returned tile will always have the shape:
      - (tile_height, tile_width) for mono
      - (tile_height, tile_width, 3) for color
    (though the color dimension may still be first if it was first in the file).
    It's up to the caller to reorder if needed.
    """
    with fits.open(filepath, memmap=False) as hdul:
        data = hdul[0].data
        if data is None:
            return None

        # Save the original data type for normalization later.
        orig_dtype = data.dtype

        shape = data.shape
        ndim = data.ndim

        if ndim == 2:
            # Data is 2D; shape could be (height, width) or (width, height)
            dim0, dim1 = shape
            if (y_end <= dim0) and (x_end <= dim1):
                tile_data = data[y_start:y_end, x_start:x_end]
            else:
                tile_data = data[x_start:x_end, y_start:y_end]
        elif ndim == 3:
            # Data is 3D; could be (height, width, 3) or (3, height, width), etc.
            dim0, dim1, dim2 = shape

            def do_slice_spatial(data3d, spat0, spat1, color_axis):
                slicer = [slice(None)] * 3
                slicer[spat0] = slice(y_start, y_end)
                slicer[spat1] = slice(x_start, x_end)
                tile = data3d[tuple(slicer)]
                return tile

            # Identify the color axis (assumed to have size 3)
            color_axis = None
            spat_axes = []
            for idx, d in enumerate((dim0, dim1, dim2)):
                if d == 3:
                    color_axis = idx
                else:
                    spat_axes.append(idx)

            if color_axis is None:
                # No axis with size 3; assume the image is mono and use the first two dims.
                tile_data = data[y_start:y_end, x_start:x_end]
            else:
                # Ensure we have two spatial axes.
                if len(spat_axes) != 2:
                    spat_axes = [0, 1]
                spat0, spat1 = spat_axes
                d0 = shape[spat0]
                d1 = shape[spat1]
                if (y_end <= d0) and (x_end <= d1):
                    tile_data = do_slice_spatial(data, spat0, spat1, color_axis)
                else:
                    tile_data = do_slice_spatial(data, spat1, spat0, color_axis)
        else:
            return None

        # Normalize based on the original data type.
        if orig_dtype == np.uint8:
            tile_data = tile_data.astype(np.float32) / 255.0
        elif orig_dtype == np.uint16:
            tile_data = tile_data.astype(np.float32) / 65535.0
        elif orig_dtype == np.uint32:
            # 32-bit data: convert to float32 but leave values as is.
            tile_data = tile_data.astype(np.float32)
        elif orig_dtype == np.float32:
            # Already 32-bit float; assume it's in the desired range.
            tile_data = tile_data
        else:
            tile_data = tile_data.astype(np.float32)

    return tile_data



# --------------------------------------------------
# MosaicMasterDialog with blending/normalization integrated
# --------------------------------------------------
def get_wcs_from_header(header):
    """Attempt to create a WCS from a FITS header."""
    if not header:
        return None
    try:
        # First, try normally:
        wcs = WCS(header)
        if wcs.is_celestial:
            return wcs
        # If not celestial and header has more than 2 axes, force naxis=2.
        if header.get('NAXIS', 0) > 2:
            wcs = WCS(header, naxis=2)
            if wcs.is_celestial:
                return wcs
        return None
    except Exception:
        return None
    
def robust_api_request(method, url, data=None, files=None, prompt_on_failure=False):
    """
    Sends an API request without automatic retries. If the request fails (network error or invalid JSON response),
    prompts the user if they want to start completely over. If the user chooses to try again,
    the function calls itself recursively.
    """
    try:
        if method == "GET":
            response = requests.get(url, timeout=600)
        elif method == "POST":
            response = requests.post(url, data=data, files=files, timeout=600)
        else:
            raise ValueError("Unsupported request method: " + method)

        response.raise_for_status()  # Raise HTTP errors (e.g., 500, 404)

        try:
            return response.json()  # Attempt to parse JSON
        except json.JSONDecodeError:
            error_message = f"Invalid JSON response from {url}."
            print(error_message)
            if prompt_on_failure:
                user_choice = QMessageBox.question(
                    None,
                    "Invalid Response",
                    f"{error_message}\nDo you want to start over?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
                )
                if user_choice == QMessageBox.StandardButton.Yes:
                    return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
                else:
                    return None
            else:
                return None

    except requests.exceptions.RequestException as e:
        error_message = f"Network error when contacting {url}: {e}."
        print(error_message)
        if prompt_on_failure:
            user_choice = QMessageBox.question(
                None,
                "Network Error",
                f"{error_message}\nDo you want to start over?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if user_choice == QMessageBox.StandardButton.Yes:
                return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
            else:
                return None
        else:
            return None


def scale_image_for_display(image):
    """
    Scales a floating point image (0-1) to 8-bit (0-255) for display.
    """
    if np.max(image) == np.min(image):
        return np.zeros_like(image, dtype=np.uint8)  # Prevent division by zero
    scaled = (255 * (image - np.min(image)) / (np.max(image) - np.min(image))).astype(np.uint8)
    return scaled

def generate_minimal_fits_header(image):
    header = Header()
    header['SIMPLE'] = True
    # Set BITPIX according to the image’s data type.
    if np.issubdtype(image.dtype, np.integer):
        header['BITPIX'] = 16  # For 16-bit integer data.
    elif np.issubdtype(image.dtype, np.floating):
        header['BITPIX'] = -32  # For 32-bit float data.
    else:
        raise ValueError("Unsupported image data type for FITS header generation.")
    header['NAXIS'] = 2
    header['NAXIS1'] = image.shape[1]  # width
    header['NAXIS2'] = image.shape[0]  # height
    header['COMMENT'] = "Minimal header generated for blind solve"
    return header


class MosaicPreviewWindow(QDialog):
    def __init__(self, image_array, title="", parent=None):
        super().__init__(parent)
        self.setWindowTitle(title if title else "Preview")

        # Keep the original array around for re-stretch or reset
        self.original_array = image_array.copy()
        # Current displayed array (8-bit or whatever you want)
        self.image_array = image_array.copy()

        # Zoom state
        self.zoom_factor = 1.0

        # Variables for panning (dragging)
        self.dragging = False
        self.last_mouse_pos = QPoint()
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # 1) QScrollArea to enable scrollbars for large images
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # 2) Label inside the scroll area
        self.preview_label = QLabel("No image yet.")
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)
        self.scroll_area.viewport().installEventFilter(self)

        # 3) Auto-Stretch Toggle
        self.stretch_toggle = QCheckBox("Auto-Stretch for Display")
        self.stretch_toggle.setChecked(True)
        self.stretch_toggle.stateChanged.connect(self.update_display)
        layout.addWidget(self.stretch_toggle)

        # 4) Button row (Zoom, Fit, etc.)
        button_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        self.fit_button = QPushButton("Fit to Preview")
        self.fit_button.clicked.connect(self.fit_to_preview)
        button_layout.addWidget(self.fit_button)

        self.autostretch_button = QPushButton("Reapply Stretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        button_layout.addWidget(self.autostretch_button)

        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.close)
        button_layout.addWidget(close_btn)

        layout.addLayout(button_layout)

        self.setLayout(layout)
        # Finally, display the initial image
        self.display_image(self.image_array)

    def display_image(self, arr):
        """
        Convert array to QPixmap and display in preview_label.
        We'll respect self.zoom_factor to scale the pixmap.
        """
        if arr is None or arr.size == 0:
            print("WARNING: Trying to display an empty image.")
            return

        # Possibly apply auto-stretch
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr)
        else:
            # If it's already 8-bit or float, just convert to 8-bit safely
            arr_display = self.to_8bit(arr)
        
        # Convert single-channel => 3 channels if needed
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        # Make QImage => QPixmap
        h, w, c = arr_3ch.shape
        bytes_per_line = w * c
        qimg = QImage(arr_3ch.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(qimg)

        # Apply zoom factor
        new_w = int(w * self.zoom_factor)
        new_h = int(h * self.zoom_factor)
        if new_w < 1: new_w = 1
        if new_h < 1: new_h = 1

        scaled_pixmap = pixmap.scaled(
            new_w, new_h,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # Set the label to the scaled pixmap
        self.preview_label.setPixmap(scaled_pixmap)
        # Important: set the label size so the scroll area can scroll if it's bigger
        self.preview_label.resize(scaled_pixmap.size())

    def stretch_for_display(self, arr):
        """
        Applies an auto-stretch to improve visualization:
          1) Compute 0.5 and 99.5 percentiles
          2) Rescale to [0..255]
        """
        arr = arr.astype(np.float32, copy=False)
        mn, mx = np.percentile(arr, (0.5, 99.5))
        if mx > mn:
            arr = (arr - mn) / (mx - mn)
        else:
            arr = np.zeros_like(arr)
        arr = (arr * 255).clip(0, 255).astype(np.uint8)
        return arr

    def eventFilter(self, source, event):
        """
        Capture mouse events on the scroll_area.viewport():
          - Left-button press => start dragging
          - Mouse move => if dragging, pan
          - Left-button release => stop dragging
          - Wheel => zoom in/out
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = True
                    self.last_mouse_pos = event.pos()
                    return True  # We handled it
            elif event.type() == QEvent.Type.MouseMove:
                if self.dragging:
                    # Compute how far we moved
                    delta = event.pos() - self.last_mouse_pos
                    self.last_mouse_pos = event.pos()

                    # Adjust scrollbars
                    h_bar = self.scroll_area.horizontalScrollBar()
                    v_bar = self.scroll_area.verticalScrollBar()
                    h_bar.setValue(h_bar.value() - delta.x())
                    v_bar.setValue(v_bar.value() - delta.y())

                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = False
                    return True
            elif event.type() == QEvent.Type.Wheel:
                # Zoom in or out
                if event.angleDelta().y() > 0:
                    self.zoom_in()
                else:
                    self.zoom_out()
                event.accept()
                return True
        return super().eventFilter(source, event)

    def to_8bit(self, arr):
        """
        Simple fallback if not using auto-stretch:
        - If float in [0..1], multiply by 255
        - If already 8-bit, do nothing
        """
        if arr.dtype == np.uint8:
            return arr
        # else assume float [0..1]
        return (arr*255).clip(0,255).astype(np.uint8)

    def update_display(self):
        """
        Called when toggling the stretch checkbox. Re-display the image.
        """
        self.display_image(self.image_array)

    def autostretch_image(self):
        """
        Auto-stretch the original image and update preview.
        If the image has multiple channels, we do the same approach as stretch_for_display
        but typically you'd do something more advanced for color.
        """
        arr = self.original_array.copy()
        # e.g., if color, you might do a channel-by-channel approach
        # For simplicity, let's do a grayscale approach using the mean:
        if arr.ndim == 3:
            # we create a single channel for stretch
            g = np.mean(arr, axis=-1)
            arr_stretched = self.stretch_for_display(g)
            # Then broadcast back to 3 channels
            arr_stretched = np.stack([arr_stretched]*3, axis=-1)
        else:
            arr_stretched = self.stretch_for_display(arr)
        self.image_array = arr_stretched
        self.display_image(self.image_array)

    # ---------------------
    # ZOOM Methods
    # ---------------------
    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.display_image(self.image_array)

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        if self.zoom_factor < 0.05:
            self.zoom_factor = 0.05
        self.display_image(self.image_array)

    def fit_to_preview(self):
        """
        Scale the image so it fits inside the scroll_area's viewport.
        We'll measure the image's actual size, compare to the viewport,
        and adjust zoom_factor accordingly.
        """
        if self.image_array is None or self.image_array.size == 0:
            return

        # We'll figure out the image's *unzoomed* dimensions
        arr_display = self.image_array
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr_display)
        else:
            arr_display = self.to_8bit(arr_display)

        # Convert single-channel => 3 channels if needed, to find w,h
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        h, w, c = arr_3ch.shape

        # The scroll area viewport size
        viewport_size = self.scroll_area.viewport().size()
        vw, vh = viewport_size.width(), viewport_size.height()

        # Compute the scale factor to fit image inside viewport
        scale_w = vw / w if w else 1.0
        scale_h = vh / h if h else 1.0
        new_zoom = min(scale_w, scale_h)
        if new_zoom <= 0:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.display_image(self.image_array)

    def resizeEvent(self, event):
        """
        Refresh displayed pixmap when window is resized,
        only if we want the displayed image to keep fitting automatically.
        But typically, we won't auto-fit on window resize if user is controlling zoom.
        """
        super().resizeEvent(event)
        # Optionally do:
        # self.fit_to_preview()
        # or if you want to keep the user-chosen zoom, just re-display:
        self.display_image(self.image_array)

class MosaicSettingsDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Mosaic Master Settings")
        self.initUI()

    def initUI(self):
        layout = QFormLayout(self)

        # Number of Stars to Attempt to Use
        self.starCountSpin = CustomSpinBox(minimum=1, maximum=1000,
                                        initial=self.settings.value("mosaic/num_stars", 150, type=int),
                                        step=1)
        layout.addRow("Number of Stars:", self.starCountSpin)

        # Translation Max Tolerance
        self.transTolSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/translation_max_tolerance", 3.0, type=float),
                                                step=0.1)
        layout.addRow("Translation Max Tolerance:", self.transTolSpin)

        # Scale Min Tolerance
        self.scaleMinSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_min_tolerance", 0.8, type=float),
                                                step=0.1)
        layout.addRow("Scale Min Tolerance:", self.scaleMinSpin)

        # Scale Max Tolerance
        self.scaleMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_max_tolerance", 1.25, type=float),
                                                step=0.1)
        layout.addRow("Scale Max Tolerance:", self.scaleMaxSpin)

        # Rotation Max Tolerance
        self.rotationMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=180.0,
                                                initial=self.settings.value("mosaic/rotation_max_tolerance", 45.0, type=float),
                                                step=0.1)
        # Force two decimals in display
        self.rotationMaxSpin.lineEdit.setText(f"{self.rotationMaxSpin.value():.2f}")
        layout.addRow("Rotation Max Tolerance (°):", self.rotationMaxSpin)

        # Skew Max Tolerance
        self.skewMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=1.0,
                                            initial=self.settings.value("mosaic/skew_max_tolerance", 0.1, type=float),
                                            step=0.01)
        layout.addRow("Skew Max Tolerance:", self.skewMaxSpin)

        # FWHM for Star Detection
        self.fwhmSpin = CustomDoubleSpinBox(minimum=0.0, maximum=20.0,
                                            initial=self.settings.value("mosaic/star_fwhm", 3.0, type=float),
                                            step=0.1)
        self.fwhmSpin.lineEdit.setText(f"{self.fwhmSpin.value():.2f}")
        layout.addRow("FWHM for Star Detection:", self.fwhmSpin)

        # Sigma for Star Detection
        self.sigmaSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                            initial=self.settings.value("mosaic/star_sigma", 3.0, type=float),
                                            step=0.1)
        self.sigmaSpin.lineEdit.setText(f"{self.sigmaSpin.value():.2f}")
        layout.addRow("Sigma for Star Detection:", self.sigmaSpin)

        # Polynomial Degree
        self.polyDegreeSpin = CustomSpinBox(minimum=1, maximum=6,
                                            initial=self.settings.value("mosaic/poly_degree", 3, type=int),
                                            step=1)
        layout.addRow("Polynomial Degree:", self.polyDegreeSpin)

        buttons = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel,
            parent=self
        )
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addRow(buttons)

    def accept(self):
        # Save the values to QSettings
        self.settings.setValue("mosaic/num_stars", self.starCountSpin.value)
        self.settings.setValue("mosaic/translation_max_tolerance", self.transTolSpin.value())
        self.settings.setValue("mosaic/scale_min_tolerance", self.scaleMinSpin.value())
        self.settings.setValue("mosaic/scale_max_tolerance", self.scaleMaxSpin.value())
        self.settings.setValue("mosaic/rotation_max_tolerance", self.rotationMaxSpin.value())
        self.settings.setValue("mosaic/skew_max_tolerance", self.skewMaxSpin.value())
        self.settings.setValue("mosaic/star_fwhm", self.fwhmSpin.value())
        self.settings.setValue("mosaic/star_sigma", self.sigmaSpin.value())
        self.settings.setValue("mosaic/poly_degree", self.polyDegreeSpin.value)
        super().accept()


class MosaicMasterDialog(QDialog):
    def __init__(self, settings: QSettings, parent=None, image_manager=None):
        super().__init__(parent)
        self.settings = settings
        self.image_manager = image_manager
        self.setWindowTitle("Mosaic Master")
        self.resize(600, 400)
        self.loaded_images = []  
        self.final_mosaic = None
        self.weight_mosaic = None
        self.wcs_metadata = None  # To store mosaic WCS header
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        # Variables to store stretching parameters:
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        instructions = QLabel(
            "Mosaic Master:\n"
            "1) Add images - Highly Recommend Images be Linear FITS\n"
            "2) Choose Transformation Type:\n"
            "....Partial Affine - Great for Images with Translation, Rotation, and Scaling Needs\n"
            "....Affine - Great for Images that also have skew distortions\n"
            "....Homography - Great for Images that also have lens or perspective distortion\n"
            "....Polynomial Warp - Useful in large mosaics to bend the images together\n"
            "3) Align & Create Mosaic\n"
            "4) Save to Image Manager"
        )
        instructions.setWordWrap(True)
        layout.addWidget(instructions)

        btn_layout = QHBoxLayout()
        # Button to add image from disk
        add_btn = QPushButton("Add Image")
        add_btn.clicked.connect(self.add_image)
        btn_layout.addWidget(add_btn)

        # New button to add an image from one of the ImageManager slots
        add_from_slot_btn = QPushButton("Add from Slot")
        add_from_slot_btn.clicked.connect(self.add_image_from_slot)
        btn_layout.addWidget(add_from_slot_btn)

        remove_btn = QPushButton("Remove Selected")
        remove_btn.clicked.connect(self.remove_selected)
        btn_layout.addWidget(remove_btn)

        preview_btn = QPushButton("Preview Selected")
        preview_btn.clicked.connect(self.preview_selected)
        btn_layout.addWidget(preview_btn)

        align_btn = QPushButton("Align and Create Mosaic")
        align_btn.clicked.connect(self.align_images)
        btn_layout.addWidget(align_btn)

        save_btn = QPushButton("Save to Image Manager")
        save_btn.clicked.connect(self.create_mosaic)
        btn_layout.addWidget(save_btn)

        layout.addLayout(btn_layout)

        # Add the wrench button for settings.
        wrench_btn = QPushButton()
        wrench_btn.setIcon(QIcon(wrench_path))
        wrench_btn.setToolTip("Mosaic Settings")
        wrench_btn.clicked.connect(self.openSettings)
        btn_layout.addWidget(wrench_btn)

        layout.addLayout(btn_layout)

        # Horizontal sizer for checkboxes.
        checkbox_layout = QHBoxLayout()
        self.forceBlindCheckBox = QCheckBox("Force Blind Solve (ignore existing WCS)")
        checkbox_layout.addWidget(self.forceBlindCheckBox)
        # New Seestar Mode checkbox:
        self.seestarCheckBox = QCheckBox("Seestar Mode")
        self.seestarCheckBox.setToolTip("When enabled, images are aligned iteratively using astroalign without plate solving.")
        checkbox_layout.addWidget(self.seestarCheckBox)
        layout.addLayout(checkbox_layout)

        self.transform_combo = QComboBox()
        self.transform_combo.addItems([
            "Partial Affine Transform",
            "Affine Transform",
            "Homography Transform",
            "Polynomial Warp Based Transform"
        ])
        # Set the default selection to "Affine Transform" (index 1)
        self.transform_combo.setCurrentIndex(1)
        layout.addWidget(QLabel("Select Transformation Method:"))
        layout.addWidget(self.transform_combo)

        self.images_list = QListWidget()
        self.images_list.setSelectionMode(self.images_list.SelectionMode.SingleSelection)
        layout.addWidget(self.images_list)

        self.status_label = QLabel("Status: no images")
        layout.addWidget(self.status_label)

        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide() 
        layout.addWidget(self.spinnerLabel)

        self.setLayout(layout)

    def openSettings(self):
        dlg = MosaicSettingsDialog(self.settings, self)
        if dlg.exec():
            self.status_label.setText("Mosaic settings updated.")

    # ---------- Add / Remove ----------
    def add_image(self):
        paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Add Image(s)",
            "",
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.fz *.fz *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if paths:
            for path in paths:
                arr, header, bitdepth, ismono = load_image(path)
                wcs_obj = get_wcs_from_header(header) if header else None
                d = {
                    "path": path,
                    "image": arr,
                    "header": header,
                    "wcs": wcs_obj,
                    "bit_depth": bitdepth,
                    "is_mono": ismono,
                    "transform": None
                }
                self.loaded_images.append(d)

                text = os.path.basename(path)
                if wcs_obj is not None:
                    text += " [WCS]"
                item = QListWidgetItem(text)
                item.setToolTip(path)
                self.images_list.addItem(item)
            self.update_status()


    # ---------- New Method: Add Image From a Slot ----------
    def add_image_from_slot(self):
        """
        Allow the user to add an image from one of the ImageManager’s slots.
        The dropdown will list only slots that contain an image, showing the renamed name
        (if available via metadata['display_name']), or else falling back to the file basename.
        """
        available_slots = []
        # Iterate through all slots managed by ImageManager
        for slot, img in self.image_manager._images.items():
            if img is not None:
                metadata = self.image_manager._metadata[slot]
                # Use a renamed name if available, otherwise use the file path basename or a default
                display_name = metadata.get("display_name")
                if not display_name:
                    file_path = metadata.get("file_path")
                    display_name = os.path.basename(file_path) if file_path else f"Slot {slot}"
                available_slots.append((slot, display_name))
        
        if not available_slots:
            QMessageBox.information(self, "Add Image", "No images available in slots.")
            return

        # Create a list of strings for the dropdown, e.g., "Slot 0: MyRenamedImage"
        items = [f"Slot {slot}: {name}" for slot, name in available_slots]

        # Let the user choose from the available slots
        item, ok = QInputDialog.getItem(self, "Select Image", "Select an image from slots:", items, 0, False)
        if not ok or not item:
            return

        # Parse the selected slot number. We assume the string format "Slot X: <name>"
        selected_slot = int(item.split(":")[0].split()[1])
        metadata = self.image_manager._metadata[selected_slot]
        image = self.image_manager._images[selected_slot]
        wcs_obj = get_wcs_from_header(metadata.get("original_header", None)) if metadata.get("original_header") else None

        # Create a dictionary similar to that used for loaded images
        d = {
            "path": metadata.get("file_path", f"Slot {selected_slot} image"),
            "image": image,
            "header": metadata.get("original_header"),
            "wcs": wcs_obj,
            "bit_depth": metadata.get("bit_depth"),
            "is_mono": metadata.get("is_mono", False),
            "transform": None
        }
        self.loaded_images.append(d)

        # Determine the text to display. Use the renamed name if available.
        text = metadata.get("display_name")
        if not text:
            file_path = metadata.get("file_path")
            text = os.path.basename(file_path) if file_path else f"Slot {selected_slot} image"
        if wcs_obj is not None:
            text += " [WCS]"
        list_item = QListWidgetItem(text)
        list_item.setToolTip(metadata.get("file_path", ""))
        self.images_list.addItem(list_item)
        self.update_status()

    def remove_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Remove", "No item selected.")
            return
        for itm in s:
            row = self.images_list.row(itm)
            self.images_list.takeItem(row)
            p = itm.toolTip()
            self.loaded_images = [x for x in self.loaded_images if x["path"] != p]
        self.update_status()

    def update_status(self):
        c = len(self.loaded_images)
        self.status_label.setText(f"{c} images loaded.")

    # ---------- Preview ----------
    def preview_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Preview", "No item selected.")
            return
        path = s[0].toolTip()
        for d in self.loaded_images:
            if d["path"] == path:
                preview_image = d["image"]
                if np.all(preview_image == 0):
                    print(f"WARNING: Preview for {path} is completely black!")
                print(f"Previewing {path}, shape={preview_image.shape}, max={np.max(preview_image)}")
                win = MosaicPreviewWindow(preview_image, title=f"Preview - {os.path.basename(path)}", parent=self)
                win.show()
                break

    # ---------- Align (Entry Point) ----------
    def align_images(self):
        if self.seestarCheckBox.isChecked():
            self.align_images_seestar_mode()
        else:
            if len(self.loaded_images) == 0:
                QMessageBox.warning(self, "Align", "No images to align.")
                return

            # Show spinner and start animation.
            self.spinnerLabel.show()
            self.spinnerMovie.start()
            QApplication.processEvents()

            # Step 1: Force blind solve if requested.
            force_blind = self.forceBlindCheckBox.isChecked()
            images_to_process = (self.loaded_images if force_blind 
                                else [item for item in self.loaded_images if item.get("wcs") is None])

            # Process each image for plate solving.
            for item in images_to_process:
                # Check if ASTAP is set.
                if not self.astap_exe or not os.path.exists(self.astap_exe):
                    executable_filter = "Executables (*.exe);;All Files (*)" if sys.platform.startswith("win") else "Executables (astap);;All Files (*)"
                    new_path, _ = QFileDialog.getOpenFileName(self, "Select ASTAP Executable", "", executable_filter)
                    if new_path:
                        self.astap_exe = new_path
                        self.settings.setValue("astap/exe_path", self.astap_exe)
                        QMessageBox.information(self, "Mosaic Master", "ASTAP path updated successfully.")
                    else:
                        QMessageBox.warning(self, "Mosaic Master", "ASTAP path not provided. Falling back to blind solve.")
                        solved_header = self.perform_blind_solve(item)
                        if solved_header:
                            item["wcs"] = WCS(solved_header)
                        continue  # Move to next image

                # Attempt ASTAP solve.
                self.status_label.setText(f"Attempting ASTAP solve for {item['path']}...")
                QApplication.processEvents()
                solved_header = self.attempt_astap_solve(item)

                if solved_header is None:
                    self.status_label.setText(f"ASTAP failed for {item['path']}. Falling back to blind solve...")
                    QApplication.processEvents()
                    solved_header = self.perform_blind_solve(item)
                else:
                    self.status_label.setText(f"Plate solve successful using ASTAP for {item['path']}.")

                if solved_header:
                    # Remove unnecessary 3D-related keywords.
                    for k in list(solved_header.keys()):
                        if (k.startswith("NAXIS3") or k.startswith("CTYPE3") or k.startswith("CUNIT3") or
                            k.startswith("CRVAL3") or k.startswith("CRPIX3") or k.startswith("CDELT3") or
                            k.startswith("CD3_") or k.startswith("PC3_") or k.startswith("PC_3")):
                            del solved_header[k]
                    # Ensure mandatory WCS keys are present.
                    solved_header.setdefault("CTYPE1", "RA---TAN")
                    solved_header.setdefault("CTYPE2", "DEC--TAN")
                    solved_header.setdefault("RADECSYS", "ICRS")
                    solved_header.setdefault("WCSAXES", 2)
                    item["wcs"] = WCS(solved_header)
                else:
                    print(f"Plate solving failed for {item['path']}.")

            # After processing, get all images with valid WCS.
            wcs_items = [x for x in self.loaded_images if x.get("wcs") is not None]
            if not wcs_items:
                print("No images have WCS, skipping WCS alignment.")
                self.spinnerMovie.stop()
                self.spinnerLabel.hide()
                return

            # Use the first image's WCS as reference and compute the mosaic bounding box.
            reference_wcs = wcs_items[0]["wcs"].deepcopy()
            min_x, min_y, max_x, max_y = self.compute_mosaic_bounding_box(wcs_items, reference_wcs)
            mosaic_width = int(max_x - min_x)
            mosaic_height = int(max_y - min_y)

            if mosaic_width < 1 or mosaic_height < 1:
                print("ERROR: Computed mosaic size is invalid. Check WCS or inputs.")
                return

            # Adjust the reference WCS so that (min_x, min_y) becomes (0,0).
            mosaic_wcs = reference_wcs.deepcopy()
            mosaic_wcs.wcs.crpix[0] -= min_x
            mosaic_wcs.wcs.crpix[1] -= min_y
            self.wcs_metadata = mosaic_wcs.to_header()

            # Set up accumulators.
            is_color = any(not item["is_mono"] for item in wcs_items)
            if is_color:
                self.final_mosaic = np.zeros((mosaic_height, mosaic_width, 3), dtype=np.float32)
            else:
                self.final_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)
            self.weight_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)

            first_image = True
            for idx, itm in enumerate(wcs_items):
                arr = itm["image"]
                self.status_label.setText(f"Projecting {itm['path']} onto the celestial sphere...")
                QApplication.processEvents()

                # Pre-stretch the image.
                stretched_arr = self.stretch_image(arr)
                # Use the first channel for alignment.
                if not itm["is_mono"]:
                    red_stretched = stretched_arr[..., 0]
                else:
                    red_stretched = stretched_arr[..., 0] if stretched_arr.ndim == 3 else stretched_arr

                # Reproject the image.
                if not itm["is_mono"]:
                    channels = []
                    for c in range(3):
                        channel = stretched_arr[..., c]
                        reproj, _ = reproject_interp((channel, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                        reproj = np.nan_to_num(reproj, nan=0.0).astype(np.float32)
                        channels.append(reproj)
                    reprojected = np.stack(channels, axis=-1)
                    reproj_red = reprojected[..., 0]
                else:
                    reproj_red, _ = reproject_interp((red_stretched, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                    reproj_red = np.nan_to_num(reproj_red, nan=0.0).astype(np.float32)
                    reprojected = np.stack([reproj_red, reproj_red, reproj_red], axis=-1)

                self.status_label.setText(f"WCS Reproject: {itm['path']} processed.")
                QApplication.processEvents()

                # --- Stellar Alignment ---
                num_stars = self.settings.value("mosaic/num_stars", 150, type=int)
                if not first_image:
                    transform_method = self.transform_combo.currentText()
                    # Use the current mosaic as reference.
                    mosaic_gray = (self.final_mosaic if self.final_mosaic.ndim == 2 
                                else np.mean(self.final_mosaic, axis=-1))
                    print("Mosaic gray shape:", mosaic_gray.shape)
                        
                    self.status_label.setText("Detecting stars in overlap region...")
                    QApplication.processEvents()
                        
                    overlap_mask = (mosaic_gray > 0) & (reproj_red > 0)
                        
                    # (Optional: You can still detect stars if needed, but here we opt to use astroalign directly.)
                    try:
                        import astroalign
                        # reproj_red is already a grayscale version from the reprojected image.
                        reproj_gray = reproj_red  
                        self.status_label.setText("Computing affine transform with astroalign...")
                        QApplication.processEvents()
                            
                        # Use astroalign to find a transform that maps reproj_gray (target) to mosaic_gray (reference).
                        transform_obj, (src_pts, dst_pts) = astroalign.find_transform(reproj_gray, mosaic_gray)
                        # Extract a 2x3 affine matrix and ensure its type.
                        transform_matrix = transform_obj.params[0:2, :].astype(np.float32)
                        self.status_label.setText("Astroalign computed transform successfully.")
                    except Exception as e:
                        self.status_label.setText(f"Astroalign failed: {e}. Using identity transform.")
                        transform_matrix = np.eye(2, 3, dtype=np.float32)
                        
                    print("Computed affine transform matrix:\n", transform_matrix)
                    # Compute the effective scales.
                    A = transform_matrix[:, :2]
                    scale1 = np.linalg.norm(A[:, 0])
                    scale2 = np.linalg.norm(A[:, 1])
                    print("Computed scales: {:.6f}, {:.6f}".format(scale1, scale2))
                                            
                    self.status_label.setText("Affine alignment computed. Warping image...")
                    QApplication.processEvents()
                    # Warp the reprojected image with the computed 2x3 transform.
                    affine_aligned = cv2.warpAffine(reprojected, transform_matrix, (mosaic_width, mosaic_height), flags=cv2.INTER_LANCZOS4)
                    print("Affine aligned image shape:", affine_aligned.shape)
                    print("Affine aligned image mean:", np.mean(affine_aligned))
                    aligned = affine_aligned

                    # If a refined method is selected, further refine the alignment.
                    if transform_method in ["Homography Transform", "Polynomial Warp Based Transform"]:
                        self.status_label.setText(f"Starting refined alignment using {transform_method}...")
                        print("Refined alignment using method:", transform_method)
                        QApplication.processEvents()                    
                        refined_result = self.refined_alignment(affine_aligned, mosaic_gray, method=transform_method)
                        if refined_result is not None:
                            aligned, best_inliers2 = refined_result
                            self.status_label.setText(f"Refined alignment succeeded with {best_inliers2} inliers.")
                            print("Refined alignment inliers:", best_inliers2)
                        else:
                            self.status_label.setText("Refined alignment failed; falling back to affine alignment.")
                            print("Refined alignment failed; using affine alignment.")
                            aligned = affine_aligned
                    else:
                        aligned = affine_aligned

                    gray_aligned = aligned[..., 0] if aligned.ndim == 3 else aligned
                    print("Final aligned image shape:", aligned.shape)
                else:
                    # For the first image, use the reprojected image as is.
                    aligned = reprojected
                    gray_aligned = (np.mean(aligned, axis=-1) if not itm["is_mono"] else aligned[..., 0])
                    first_image = False

                # Compute weight mask from the grayscale aligned image.
                binary_mask = (gray_aligned > 0).astype(np.uint8)
                smooth_mask = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 5)
                if np.max(smooth_mask) > 0:
                    smooth_mask = smooth_mask / np.max(smooth_mask)
                else:
                    smooth_mask = binary_mask.astype(np.float32)
                smooth_mask = cv2.GaussianBlur(smooth_mask, (15, 15), 0)

                # Accumulate the aligned image.
                if is_color:
                    self.final_mosaic += aligned * smooth_mask[..., np.newaxis]
                else:
                    self.final_mosaic += aligned[..., 0] * smooth_mask
                self.weight_mosaic += smooth_mask

                self.status_label.setText(f"Processed: {itm['path']}")
                QApplication.processEvents()

            # Final blending.
            nonzero_mask = (self.weight_mosaic > 0)
            if is_color:
                self.final_mosaic = np.where(self.weight_mosaic[..., None] > 0,
                                            self.final_mosaic / self.weight_mosaic[..., None],
                                            self.final_mosaic)
            else:
                self.final_mosaic[nonzero_mask] = self.final_mosaic[nonzero_mask] / self.weight_mosaic[nonzero_mask]

            print("WCS + Star Alignment Complete.")
            self.status_label.setText("WCS + Star Alignment Complete. De-Normalizing Mosaic...")
            self.final_mosaic = self.unstretch_image(self.final_mosaic)
            self.status_label.setText("Final Mosaic Ready.")
            QApplication.processEvents()

            if self.final_mosaic.ndim == 2:
                display_image = np.stack([self.final_mosaic] * 3, axis=-1)
            else:
                display_image = self.stretch_for_display(self.final_mosaic)
            mosaic_win = MosaicPreviewWindow(display_image, title="Incremental Mosaic", parent=self)
            mosaic_win.show()

            self.spinnerMovie.stop()
            self.spinnerLabel.hide()
            QApplication.processEvents()
            pass        

    def debayer_image(self, image, file_path, header):
        if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            print(f"Debayering RAW image: {file_path}")
            return debayer_raw_fast(image)
        elif file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
            bayer_pattern = header.get('BAYERPAT')
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                return debayer_fits_fast(image, bayer_pattern)
        return image

    def refine_via_overlap(self, new_gray, mosaic_gray, rough_matrix):
        """
        1) Warp new_gray into mosaic coords using rough_matrix.
        2) Compute overlap region by checking where both warped_new_gray and mosaic_gray > 0.
        3) Restrict astroalign.find_transform() to that overlap only.
        4) Combine the refinement transform with rough_matrix so you have a single final 2×3 matrix
        mapping the original new_gray -> mosaic_gray coordinates.

        Returns the final 2×3 transform matrix for cv2.warpAffine, or None if no overlap or alignment fails.
        """

        # ------------------------------------------
        # A) Warp new_gray with rough_matrix
        # ------------------------------------------
        h_m, w_m = mosaic_gray.shape
        warped_new_gray = cv2.warpAffine(
            new_gray,
            rough_matrix,
            (w_m, h_m),   # (width, height)
            flags=cv2.INTER_LANCZOS4
        )

        # ------------------------------------------
        # B) Determine overlap region (both > 0)
        # ------------------------------------------
        mask_warped = (warped_new_gray > 0)
        mask_mosaic = (mosaic_gray > 0)
        overlap_mask = mask_warped & mask_mosaic

        overlap_pixels = np.count_nonzero(overlap_mask)
        print(f"[DEBUG] Overlap region has {overlap_pixels} pixels.")

        # If there’s not enough overlap, bail out
        if overlap_pixels < 50:
            # Not enough area for star matching
            return None

        # ------------------------------------------
        # C) Mask out everything except the overlap
        # ------------------------------------------
        # We'll use numpy.ma arrays so astroalign sees "valid" data only in overlap region
        warped_new_ma = ma.array(warped_new_gray, mask=~overlap_mask)
        mosaic_ma = ma.array(mosaic_gray, mask=~overlap_mask)

        # ------------------------------------------
        # D) Attempt astroalign on that overlap
        #    Note: the transform we get is from warped_new_gray -> mosaic_gray,
        #    i.e., in "mosaic coordinate space." So it should be *almost* identity
        #    if the rough transform was close, but with some tweak for rotation/translation.
        # ------------------------------------------
        try:
            refine_obj, (src_pts, dst_pts) = astroalign.find_transform(
                warped_new_ma, mosaic_ma,
                max_control_points=50,
                detection_sigma=2
            )
            print(f"[DEBUG] Overlap-limited astroalign success with {len(src_pts)} stars.")
        except Exception as e:
            print(f"[DEBUG] Overlap-limited astroalign failed: {e}")
            return None

        # ------------------------------------------
        # E) Combine refine_obj with the original rough_matrix
        # ------------------------------------------
        # refine_obj.params is typically a 3×3 (similarity).
        # rough_matrix is 2×3 for warpAffine.
        # We'll promote rough_matrix to 3×3, multiply, then convert back.
        refine_mat_3x3 = refine_obj.params  # e.g. a 3×3
        rough_mat_3x3 = np.eye(3, dtype=np.float32)
        rough_mat_3x3[:2, :] = rough_matrix

        # The final transform is refine_mat_3x3 * rough_mat_3x3
        #   (in linear-algebra order, the right-hand transform applies first)
        combined_3x3 = refine_mat_3x3 @ rough_mat_3x3

        # Convert that back to 2×3 for cv2
        final_transform = combined_3x3[:2, :].astype(np.float32)
        return final_transform

    def align_images_seestar_mode(self):
        """ 
        Align images in Seestar Mode by first selecting the center-most image (based on WCS centers)
        as the initial mosaic. Then, sort and add images by increasing distance from the mosaic center.
        If WCS information is present in the header, a rough pre-alignment is computed before refining
        with astroalign.find_transform. After processing all images, failed images are reattempted.

        Final image is produced by summing all warped images and dividing by the pixel counts 
        (sum-then-divide approach).
        """

        if len(self.loaded_images) == 0:
            QMessageBox.warning(self, "Align", "No images to align.")
            return

        self.status_label.setText("🔄 Image Registration Started...")
        self.spinnerLabel.show()
        self.spinnerMovie.start()
        QApplication.processEvents()

        total_files = len(self.loaded_images)  # how many images in total
        if total_files == 0:
            QMessageBox.warning(self, "Align", "No images to align.")
            return

        # Create a QProgressDialog
        progress = QProgressDialog("Aligning images...", "Cancel", 0, total_files, self)
        progress.setWindowTitle("Seestar Alignment")
        progress.setWindowModality(Qt.WindowModality.WindowModal)
        progress.setAutoClose(False)
        progress.setAutoReset(False)
        progress.setMinimumDuration(0)
        progress.show()

        # We define how many pixels to zero out on each edge AFTER warp
        POST_WARP_BORDER = 10
        THRESHOLD_RATIO = 0.9  # if new pixel < 0.5 * mosaic pixel, skip it

        # -----------------------------------------------------
        # Helper: Extract the world-coordinate center from an image header
        # -----------------------------------------------------
        def get_wcs_center(item):
            header = item.get("header", None)
            if header is None:
                print(f"[DEBUG] No header for {item.get('path','')}")
                return None
            try:
                wcs = WCS(header)
                naxis1 = int(header.get("NAXIS1", 0))
                naxis2 = int(header.get("NAXIS2", 0))
                center_pix = np.array([naxis1 / 2.0, naxis2 / 2.0])
                center_world = wcs.all_pix2world(center_pix[None, :], 1)[0]
                print(f"[DEBUG] {item.get('path','')} center_world: {center_world}")
                return center_world
            except Exception as e:
                print(f"[DEBUG] Failed to get WCS center for {item.get('path','')}: {e}")
                return None

        # -----------------------------------------------------
        # Helper: Count how many stars appear in an image (2D or 3D)
        # -----------------------------------------------------
        def count_stars_in_image(image):
            """
            Use DAOStarFinder to return number of detected stars.
            Expects a 2D image; if 3D, we average over channels.
            You might need to tweak fwhm/threshold for your data.
            """
            if image.ndim == 3:
                image = np.mean(image, axis=2)

            mean_val, median_val, std_val = sigma_clipped_stats(image, sigma=3.0)
            daofind = DAOStarFinder(fwhm=3.0, threshold=5.0 * std_val)
            sources = daofind(image - median_val)

            if sources is None:
                return 0
            else:
                return len(sources)

        # -----------------------------------------------------
        # 1) Gather all images with valid WCS and compute average center
        # -----------------------------------------------------
        centers = []
        valid_items = []
        for item in self.loaded_images:
            center = get_wcs_center(item)
            if center is not None:
                centers.append(center)
                valid_items.append(item)

        if not centers:
            QMessageBox.warning(self, "Align", "No images with valid WCS found.")
            return

        centers = np.array(centers)
        avg_center = np.mean(centers, axis=0)  # or np.median if you prefer

        # -----------------------------------------------------
        # Sort valid items by distance from average center
        # -----------------------------------------------------
        def distance_from_avg(item):
            center = get_wcs_center(item)
            dist = np.linalg.norm(center - avg_center) if center is not None else np.inf
            print(f"[DEBUG] {item['path']} distance from avg: {dist}")
            return dist

        valid_items.sort(key=distance_from_avg)
        for item in valid_items:
            print(f"[DEBUG] Sorted valid item: {item['path']}")

        # -----------------------------------------------------
        # Select from the top few “closest to center,” pick the one with the most stars as the base.
        # -----------------------------------------------------
        top_n = 5
        candidate_subset = valid_items[:top_n]

        best_item = None
        best_star_count = 0
        for candidate in candidate_subset:
            star_count = count_stars_in_image(candidate["image"])
            print(f"[DEBUG] {candidate['path']} star count: {star_count}")
            if star_count > best_star_count:
                best_star_count = star_count
                best_item = candidate

        if best_item is None:
            best_item = valid_items[0]

        base_item = best_item
        print(f"[DEBUG] Selected base image: {base_item['path']} with star count = {best_star_count}")

        # -----------------------------------------------------
        # Reorder loaded_images so that valid (WCS) items come first
        # -----------------------------------------------------
        remaining_items = []
        valid_paths = {v["path"] for v in valid_items}  # set of valid item paths

        for item in self.loaded_images:
            if item["path"] not in valid_paths:
                remaining_items.append(item)

        self.loaded_images = valid_items + remaining_items


        # -----------------------------------------------------
        # Helper: Crop a 5-pixel border from each edge
        # -----------------------------------------------------
        def crop_5px_border(img):
            if img.ndim == 3:
                h, w, c = img.shape
                if h <= 10 or w <= 10:
                    return np.empty((0, 0, c), dtype=img.dtype)
                return img[10:-10, 10:-10, :]
            else:
                h, w = img.shape
                if h <= 10 or w <= 10:
                    return np.empty((0, 0), dtype=img.dtype)
                return img[10:-10, 10:-10]

        # -----------------------------------------------------
        # Helper: Convert image to float32 and normalize if needed
        # -----------------------------------------------------
        def ensure_float32_in_01(img):
            img = img.astype(np.float32, copy=False)
            mx = np.max(img)
            if mx <= 1.0:
                return img
            elif mx <= 255.0:
                return img / 255.0
            elif mx <= 65535.0:
                return img / 65535.0
            else:
                return img / mx if mx > 0 else img

        # -----------------------------------------------------
        # Helper: Compute a rough transform (rotation+translation) using WCS
        # -----------------------------------------------------
        def compute_rough_transform(new_header, ref_header):
            """Compute a rough transformation (rotation and translation) using WCS."""
            try:
                new_wcs = WCS(new_header)
                ref_wcs = WCS(ref_header)
                ref_naxis1 = int(ref_header.get('NAXIS1', 0))
                ref_naxis2 = int(ref_header.get('NAXIS2', 0))
                ref_center = np.array([ref_naxis1 / 2.0, ref_naxis2 / 2.0])
                world_center = ref_wcs.all_pix2world(ref_center[None, :], 1)
                new_center = new_wcs.all_world2pix(world_center, 1)[0]
                ref_offset = ref_center + np.array([1, 0])
                world_offset = ref_wcs.all_pix2world(ref_offset[None, :], 1)[0]
                new_offset = new_wcs.all_world2pix(world_offset[None, :], 1)[0]
                vector = new_offset - new_center
                angle = np.arctan2(vector[1], vector[0])
                cos_a = np.cos(angle)
                sin_a = np.sin(angle)
                R = np.array([[cos_a, -sin_a],
                            [sin_a,  cos_a]])
                t = ref_center - R @ new_center
                rough = np.hstack([R, t.reshape(2, 1)]).astype(np.float32)
                return rough
            except Exception as e:
                print(f"Rough transform skipped: {e}")
                return None

        def compute_rough_transform_seestar(new_header, ref_header):
            """
            Builds a 2×3 transform matrix (rotation + translation) that
            roughly aligns an image with RA/DEC, pixel scale, and focal length
            to a reference image with the same kind of data.

            Required header fields (example):
            new_header["RA"]       (degrees)
            new_header["DEC"]      (degrees)
            new_header["XPIXSZ"]   (microns)
            new_header["YPIXSZ"]   (microns)
            new_header["FOCALLEN"] (mm)
            Similarly for ref_header.

            Returns:
            A 2×3 np.float32 array suitable for cv2.warpAffine,
            or None if missing data or something fails.
            """

            # 1) Parse required fields from new_header
            try:
                ra_new_deg = float(new_header["RA"])       # degrees
                dec_new_deg = float(new_header["DEC"])     # degrees
                xpixsz_new = float(new_header["XPIXSZ"])   # microns
                ypixsz_new = float(new_header["YPIXSZ"])   # microns
                flen_new   = float(new_header["FOCALLEN"]) # mm
            except KeyError as e:
                print(f"[DEBUG] new_header missing key {e}. No rough transform.")
                return None
            except Exception as e:
                print(f"[DEBUG] parse error in new_header => {e}")
                return None

            # 2) Parse required fields from ref_header
            try:
                ra_ref_deg = float(ref_header["RA"])
                dec_ref_deg = float(ref_header["DEC"])
                xpixsz_ref = float(ref_header["XPIXSZ"])
                ypixsz_ref = float(ref_header["YPIXSZ"])
                flen_ref   = float(ref_header["FOCALLEN"])
            except KeyError as e:
                print(f"[DEBUG] ref_header missing key {e}. No rough transform.")
                return None
            except Exception as e:
                print(f"[DEBUG] parse error in ref_header => {e}")
                return None

            # 3) Compute average arcsec/pixel for each image
            #    arcsec_per_pix = 206265 * (XPIXSZ [um]) / (FOCALLEN [mm])
            #    (assuming 1 mm = 1000 um)
            #    If you want to be more precise, you might average XPIXSZ and YPIXSZ,
            #    or handle them separately if the camera has rectangular pixels.
            def arcsec_per_pixel(xpixsz, flen):
                return 206265.0 * (xpixsz / 1000.0) / flen

            scale_new = arcsec_per_pixel(xpixsz_new, flen_new)
            scale_ref = arcsec_per_pixel(xpixsz_ref, flen_ref)

            # For simplicity, let's assume the "reference" image defines the final scale.
            # If the images have different scales, we can do a ratio of scales => ~some "zoom."
            # Here we assume they are close enough, or you can do scale = scale_ref / scale_new
            # to get a small difference in pixel scale if needed.
            scale_ratio = scale_ref / scale_new  # how many ref pixels = 1 new pixel

            # 4) Compute difference in RA/DEC in arcseconds
            #    RA/DEC difference in degrees => multiply by 3600 to get arcseconds
            #    Then convert to pixel shift in reference coordinates.
            d_ra_deg  = (ra_new_deg  - ra_ref_deg)
            d_dec_deg = (dec_new_deg - dec_ref_deg)

            # For small fields, we can do a simple approximation ignoring spherical geometry:
            d_ra_arcsec  = d_ra_deg  * 3600.0 * np.cos(np.radians(dec_ref_deg))  # cos(dec) if you want
            d_dec_arcsec = d_dec_deg * 3600.0

            # If you want a more precise approach, you'd do a spherical trig approach,
            # but for small fields, this is usually good enough.

            # 5) Convert arcseconds => pixel shift in "reference" image coords
            dx_pix = d_ra_arcsec  / scale_ref
            dy_pix = - d_dec_arcsec / scale_ref
            # Note: we do "dy_pix = -d_dec_arcsec" if we assume +DEC => "up" in the image.
            # You may need to invert or swap RA/DEC sign depending on your orientation.

            # 6) Combine the scale ratio (if needed) and shift into a 2×3 transform.
            #    If you want to guess rotation from the difference in rotation angles,
            #    you can do that here. For now, we do no rotation => angle=0 => cos=1, sin=0.
            angle_rad = 0.0
            cos_a = np.cos(angle_rad)
            sin_a = np.sin(angle_rad)

            # scale_ratio is for "zoom," if you want to handle that.
            # If you prefer no scale difference, set scale_ratio = 1.0
            # or if the difference is small, ignore it.
            # scale_ratio = 1.0

            M = np.array([
                [scale_ratio*cos_a, -scale_ratio*sin_a, dx_pix],
                [scale_ratio*sin_a,  scale_ratio*cos_a, dy_pix]
            ], dtype=np.float32)

            print(f"[DEBUG] Seestar rough transform => dx_pix={dx_pix:.2f}, dy_pix={dy_pix:.2f}, scale={scale_ratio:.3f}")
            return M

        # -----------------------------------------------------
        # 1) Initialize mosaic_sum/mosaic_count from the base image
        # -----------------------------------------------------
        base_img = ensure_float32_in_01(base_item["image"])
        if base_item["path"].lower().endswith(('.fits', '.fit', '.fz')):
            if (base_img.ndim == 2 
                and "header" in base_item 
                and base_item["header"] is not None 
                and base_item["header"].get('BAYERPAT')):
                self.status_label.setText(f"Debayering {base_item['path']}")
                QApplication.processEvents()
                base_img = self.debayer_image(base_img, base_item["path"], base_item["header"])
                print(f"[DEBUG] Finished debayering base image: {base_item['path']}")

        base_img = crop_5px_border(base_img)
        if base_img.size == 0:
            QMessageBox.warning(self, "Crop Error", "Initial image is too small after cropping.")
            return
    
        base_median = np.median(base_img)

        # mosaic_sum holds the sum of pixel intensities
        mosaic_sum = base_img.astype(np.float32, copy=True)
        # mosaic_count tracks how many images contributed at each pixel
        if mosaic_sum.ndim == 3:
            # For color: count “contributed” if any channel is >0
            contrib_mask = np.any(mosaic_sum > 0, axis=2)
            mosaic_count = np.zeros_like(mosaic_sum, dtype=np.float32)
            for c in range(mosaic_sum.shape[2]):
                mosaic_count[..., c][contrib_mask] = 1.0
        else:
            contrib_mask = (mosaic_sum > 0)
            mosaic_count = np.zeros_like(mosaic_sum, dtype=np.float32)
            mosaic_count[contrib_mask] = 1.0

        # We’ll use a helper that returns a mono “view” for alignment:
        def get_current_mosaic_gray():
            """Return current mosaic as a float32 array in [0..1], averaged if color."""
            with np.errstate(divide='ignore', invalid='ignore'):
                stacked = mosaic_sum / np.maximum(mosaic_count, 1e-6)
            # If color, reduce to mono for astroalign
            if stacked.ndim == 3:
                return np.mean(stacked, axis=2).astype(np.float32)
            else:
                return stacked

        self.status_label.setText("Starting alignment of subsequent images...")
        QApplication.processEvents()

        # --- Helper: Process alignment for one image, then accumulate into mosaic_sum/count ---
        def process_alignment(item):
            nonlocal mosaic_sum, mosaic_count

            print(f"[DEBUG] Aligning image: {item['path']}")

            try:
                new_img = item["image"].astype(np.float32)
                print(f"[DEBUG] new_img initial shape={new_img.shape}, dtype={new_img.dtype}, "
                    f"min={np.min(new_img):.3f}, max={np.max(new_img):.3f}")

                # Debayer if needed
                if item["path"].lower().endswith(('.fits', '.fit')):
                    if (new_img.ndim == 2 
                        and "header" in item 
                        and item["header"] is not None 
                        and item["header"].get('BAYERPAT')):
                        print(f"[DEBUG] Debayering image: {item['path']}")
                        new_img = self.debayer_image(new_img, item["path"], item["header"])
                        print(f"[DEBUG] debayered new_img shape={new_img.shape}, dtype={new_img.dtype}, "
                            f"min={np.min(new_img):.3f}, max={np.max(new_img):.3f}")

                new_img = crop_5px_border(new_img)
                if new_img.size == 0:
                    print(f"[DEBUG] new_img is empty after cropping => skip.")
                    self.status_label.setText(f"Skipping {item['path']} (too small after crop).")
                    QApplication.processEvents()
                    return False

                self.status_label.setText(f"Removing linear gradient from {item['path']}...")
                QApplication.processEvents()
                # Create an instance of PolyGradientRemoval with degree 1.
                poly_remover = PolyGradientRemoval(new_img, poly_degree=2, downsample_scale=5, num_sample_points=100)
                # Process the image to remove the gradient
                new_img = poly_remover.process()
                print("[DEBUG] Finished polynomial gradient removal on subframe.")

                # If mono:
                self.status_label.setText(f"Normalizing {item['path']}.")
                QApplication.processEvents()
                new_img = new_img-np.min(new_img)
                if new_img.ndim == 2:
                    new_img = stretch_mono_image(new_img, target_median=base_median, normalize=False, apply_curves=False, curves_boost=0.0)

                else:
                    # color approach - you might do a single ratio or call your stretch_color_image
                    new_img = stretch_color_image(new_img, target_median=base_median, linked=False, normalize=False, apply_curves=False, curves_boost=0.0)


                # If mosaic is color and new_img is mono, expand new_img
                # But remember, mosaic_sum is our "canvas"
                if mosaic_sum.ndim == 3 and new_img.ndim == 2:
                    print("[DEBUG] Expanding new_img from 2D => 3D to match mosaic channels.")
                    new_img = np.repeat(new_img[:, :, np.newaxis], mosaic_sum.shape[2], axis=2)
                elif mosaic_sum.ndim == 2 and new_img.ndim == 3:
                    print("[DEBUG] new_img is color but mosaic is mono => average new_img channels.")
                    new_img = np.mean(new_img, axis=2, dtype=np.float32)

                # Create the grayscale for astroalign from mosaic_sum/mosaic_count
                mosaic_gray = get_current_mosaic_gray()

                new_gray = new_img
                if new_gray.ndim == 3:
                    new_gray = np.mean(new_gray, axis=2)

                # Optional: mild stretch to help astroalign
                mosaic_gray = stretch_mono_image(mosaic_gray, target_median=0.1, normalize=False, apply_curves=False, curves_boost=0.0)
                new_gray = stretch_mono_image(new_gray, target_median=0.1, normalize=False, apply_curves=False, curves_boost=0.0)

                # Attempt rough transform via WCS
                rough_matrix = None
                if ("header" in item and item["header"] is not None
                    and "CTYPE1" in item["header"] and "CTYPE2" in item["header"]):
                    # Normal WCS approach
                    rough_matrix = compute_rough_transform(item["header"], base_item["header"])
                    if rough_matrix is not None:
                        print("[DEBUG] WCS-based rough transform:\n", rough_matrix)
                else:
                    # Fallback: check if we have RA,DEC,XPIXSZ,FOCALLEN, etc.
                    rough_matrix = compute_rough_transform_seestar(item["header"], base_item["header"])
                    if rough_matrix is not None:
                        print("[DEBUG] Seestar rough transform:\n", rough_matrix)

                self.status_label.setText(f"Astroaligning for {item['path']}...")
                QApplication.processEvents()

                # Find transform
                transform_matrix = None
                try:
                    # astroalign wants double precision
                    transform_obj, (src_pts, dst_pts) = astroalign.find_transform(
                        new_gray,
                        mosaic_gray,
                        max_control_points=50,
                        detection_sigma=4,
                        min_area=5
                    )
                    transform_matrix = transform_obj.params[0:2, :].astype(np.float32)
                    print(f"[DEBUG] Astroalign success with {len(src_pts)} stars. transform_matrix:\n{transform_matrix}")

                except Exception as e:
                    print(f"[DEBUG] astroalign.find_transform failed: {e}")
                    self.status_label.setText(f"Alignment failed: {e}")
                    QApplication.processEvents()

                    # Fallback if rough_matrix is available
                    if rough_matrix is not None:
                        print("[DEBUG] Attempting refine_via_overlap fallback with rough_matrix.")
                        transform_matrix = self.refine_via_overlap(new_gray, mosaic_gray, rough_matrix)
                        if transform_matrix is None:
                            print("[DEBUG] Overlap approach also failed => skip this image.")
                            return False
                        print("[DEBUG] Overlap-based refinement succeeded. transform_matrix:\n", transform_matrix)
                    else:
                        print("[DEBUG] No rough transform => skipping image.")
                        return False

                if transform_matrix is None:
                    self.status_label.setText("No transform found; skipping image.")
                    print("[DEBUG] transform_matrix is None => returning False")
                    return False

                self.status_label.setText(f"Astroalign success for {item['path']}")
                QApplication.processEvents()

                # Warp the new image onto mosaic_sum's coordinate system
                h_m, w_m = mosaic_sum.shape[:2]
                new_h, new_w = new_img.shape[:2]

                mosaic_corners = np.array([[0, 0], [w_m, 0], [0, h_m], [w_m, h_m]], dtype=np.float32)
                new_img_corners = np.array([[0, 0], [new_w, 0], [0, new_h], [new_w, new_h]], dtype=np.float32)
                ones = np.ones((4, 1), dtype=np.float32)
                new_img_corners_hom = np.hstack([new_img_corners, ones])

                warped_corners = (transform_matrix @ new_img_corners_hom.T).T
                all_corners = np.vstack([mosaic_corners, warped_corners])
                min_xy = np.min(all_corners, axis=0)
                max_xy = np.max(all_corners, axis=0)

                margin = 10
                new_canvas_width = int(np.ceil(max_xy[0] - min_xy[0])) + margin
                new_canvas_height = int(np.ceil(max_xy[1] - min_xy[1])) + margin
                shift = -min_xy + np.array([margin / 2, margin / 2])
                shift_int = np.round(shift).astype(int)
                y0, x0 = shift_int[1], shift_int[0]

                print(f"[DEBUG] new_canvas_width={new_canvas_width}, new_canvas_height={new_canvas_height}")
                print(f"[DEBUG] shift={shift}, shift_int={shift_int}, y0={y0}, x0={x0}")

                # Expand mosaic_sum/mosaic_count to fit new canvas if needed
                expanded_sum = None
                expanded_count = None

                if mosaic_sum.ndim == 3:
                    channels = mosaic_sum.shape[2]
                    expanded_sum = np.zeros((new_canvas_height, new_canvas_width, channels), dtype=np.float32)
                    expanded_count = np.zeros_like(expanded_sum, dtype=np.float32)
                    # Copy existing mosaic_sum/mosaic_count
                    expanded_sum[y0:y0+h_m, x0:x0+w_m, :] = mosaic_sum
                    expanded_count[y0:y0+h_m, x0:x0+w_m, :] = mosaic_count
                else:
                    expanded_sum = np.zeros((new_canvas_height, new_canvas_width), dtype=np.float32)
                    expanded_count = np.zeros_like(expanded_sum, dtype=np.float32)
                    expanded_sum[y0:y0+h_m, x0:x0+w_m] = mosaic_sum
                    expanded_count[y0:y0+h_m, x0:x0+w_m] = mosaic_count

                # Adjust transform for the shift
                new_transform = transform_matrix.copy()
                new_transform[0, 2] += shift[0]
                new_transform[1, 2] += shift[1]

                # Warp the new_img
                try:
                    warped_new = cv2.warpAffine(
                        new_img,
                        new_transform,
                        (new_canvas_width, new_canvas_height),
                        flags=cv2.INTER_LANCZOS4
                    )
                except cv2.error as cv2_err:
                    print(f"[OpenCV] warpAffine error => {cv2_err}")
                    return False

                # 1) Build the "border_mask" that excludes the outer POST_WARP_BORDER region
                h_w, w_w = warped_new.shape[:2]
                border_mask = np.ones((h_w, w_w), dtype=bool)
                b = POST_WARP_BORDER
                border_mask[:b, :] = False
                border_mask[-b:, :] = False
                border_mask[:, :b] = False
                border_mask[:, -b:] = False

                # 2) Build a "valid_mask" by warping an image of ones using INTER_NEAREST.
                ones_img = np.ones(new_img.shape[:2], dtype=np.uint8)
                warped_mask = cv2.warpAffine(
                    ones_img,
                    new_transform,
                    (new_canvas_width, new_canvas_height),
                    flags=cv2.INTER_NEAREST
                )
                valid_mask = (warped_mask == 1)

                # 2b) Compute a feathering weight from the valid_mask:
                # Compute the distance transform of the valid_mask.
                # This gives, for each pixel inside the valid region, its distance (in pixels)
                # from the nearest 0 (i.e. from the border of the valid region).
                FEATHER_RADIUS = 20  # adjust as needed; this is the maximum distance for feathering
                # Convert valid_mask to uint8 for distance transform.
                valid_uint8 = valid_mask.astype(np.uint8)
                dist = cv2.distanceTransform(valid_uint8, cv2.DIST_L2, 5)
                # Compute weights: linear ramp from 0 (at distance=0) to 1 (at distance>=FEATHER_RADIUS).
                feather_weights = np.clip(dist / FEATHER_RADIUS, 0, 1)

                # 3) Build "mosaic_gray" = the grayscale of (expanded_sum / expanded_count)
                mosaic_gray = np.zeros((new_canvas_height, new_canvas_width), dtype=np.float32)
                if expanded_sum.ndim == 2:
                    nonzero_mask = (expanded_count > 0)
                    mosaic_gray[nonzero_mask] = expanded_sum[nonzero_mask] / expanded_count[nonzero_mask]
                else:
                    sum_channels = np.sum(expanded_sum, axis=2)
                    sum_counts = np.sum(expanded_count, axis=2)
                    nonzero_mask = (sum_counts > 0)
                    mosaic_gray[nonzero_mask] = sum_channels[nonzero_mask] / sum_counts[nonzero_mask]

                # 4) Build new_gray for the warped image
                if warped_new.ndim == 2:
                    new_gray = warped_new
                else:
                    new_gray = np.mean(warped_new, axis=2)

                # 5) Build the brightness_mask: accept pixels where new_gray >= THRESHOLD_RATIO * mosaic_gray.
                brightness_mask = (new_gray >= THRESHOLD_RATIO * mosaic_gray)

                # 6) Combine masks.
                # Here we combine border_mask, brightness_mask, and valid_mask.
                # The final effective weight will be the feathering weight from within the valid_mask,
                # applied only where the other masks also pass.
                combined_mask = border_mask & valid_mask & brightness_mask

                # 7) Add only those pixels, using the feathering weights.
                if warped_new.ndim == 2:
                    # MONO: weight each pixel accordingly.
                    expanded_sum[combined_mask] += warped_new[combined_mask] * feather_weights[combined_mask]
                    expanded_count[combined_mask] += feather_weights[combined_mask]
                else:
                    # COLOR: do it per channel.
                    for c in range(warped_new.shape[2]):
                        expanded_sum[..., c][combined_mask] += warped_new[..., c][combined_mask] * feather_weights[combined_mask]
                        expanded_count[..., c][combined_mask] += feather_weights[combined_mask]

                # 8) Update mosaic_sum/mosaic_count.
                mosaic_sum = expanded_sum
                mosaic_count = expanded_count


                self.status_label.setText(f"Integrated image: {item['path']}")
                QApplication.processEvents()

                print("[DEBUG] process_alignment done successfully for this image.")
                return True

            except Exception as e:
                print(f"[DEBUG] process_alignment error => {e}")
                import traceback
                traceback.print_exc()
                return False

        # ---------------------------------------------------------
        # Process each subsequent image once
        # ---------------------------------------------------------
        failed_items = []
        # We'll do a normal for-loop with enumerate so we can pass index to progress
        for i, item in enumerate(self.loaded_images):
            # If user cancels
            if progress.wasCanceled():
                self.status_label.setText("Alignment canceled by user.")
                break

            # Update the progress label
            progress.setLabelText(f"Aligning image {i+1}/{total_files}: {item['path']}")
            progress.setValue(i)  # update the progress bar

            if item is base_item:
                continue

            success = process_alignment(item)
            if not success:
                failed_items.append(item)

            QApplication.processEvents()  # allow UI updates

        # Final step: mark progress done
        progress.setValue(total_files)

        # ---------------------------------------------------------
        # Reattempt failed images (max 1 additional attempt)
        # ---------------------------------------------------------
        max_retries = 1
        attempt = 1
        while failed_items and attempt <= max_retries:
            reattempt_count = len(failed_items)
            self.status_label.setText(f"Reattempting alignment for {reattempt_count} images (Attempt {attempt})")
            print(f"Reattempting alignment for {reattempt_count} images (Attempt {attempt})")
            QApplication.processEvents()

            # 2) Reset the existing progress bar to track the reattempt pass
            progress.setRange(0, reattempt_count)
            progress.setValue(0)
            progress.setLabelText(f"Reattempt pass {attempt}...")

            current_failures = []
            for i, item in enumerate(failed_items):
                if progress.wasCanceled():
                    self.status_label.setText("Reattempt canceled by user.")
                    break

                progress.setLabelText(f"Reattempting {item['path']} ({i+1}/{reattempt_count})")
                progress.setValue(i)
                QApplication.processEvents()

                success = process_alignment(item)
                if not success:
                    current_failures.append(item)

            progress.setValue(reattempt_count)  # done reattempt pass

            failed_items = current_failures
            attempt += 1

        # All passes complete
        progress.close()
        self.status_label.setText("All alignment attempts complete.")
        QApplication.processEvents()

        # ---------------------------------------------------------
        # Finally, build the average mosaic = mosaic_sum / mosaic_count
        # ---------------------------------------------------------
        with np.errstate(divide='ignore', invalid='ignore'):
            final_mosaic = np.zeros_like(mosaic_sum, dtype=np.float32)
            if final_mosaic.ndim == 2:
                nonzero = (mosaic_count > 0)
                final_mosaic[nonzero] = mosaic_sum[nonzero] / mosaic_count[nonzero]
            else:
                # color
                for c in range(final_mosaic.shape[2]):
                    chan_nonzero = (mosaic_count[..., c] > 0)
                    final_mosaic[..., c][chan_nonzero] = (
                        mosaic_sum[..., c][chan_nonzero] 
                        / mosaic_count[..., c][chan_nonzero]
                    )

        # Optional: you could do a final normalization
        max_val = np.max(final_mosaic)
        if max_val > 0:
            final_mosaic /= max_val

        self.final_mosaic = final_mosaic
        self.spinnerMovie.stop()
        self.spinnerLabel.hide()
        self.status_label.setText("Seestar Mode alignment (sum/divide) complete.")
        QApplication.processEvents()

        display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Robot Telescope Mosaic", parent=self)
        mosaic_win.show()

    # ---------- Star alignment using triangle matching ----------

    def refined_alignment(self, affine_aligned, mosaic_img, method="Homography Transform"):
        """
        Refined alignment that assumes affine_aligned is the result of the affine alignment step.
        It re-detects stars in the candidate (overlap) region and computes a refined transform from
        affine_aligned to mosaic_img. Then it applies the refined transform to affine_aligned and
        returns the fully warped image.
        
        Returns:
        - For "Homography Transform": (warped_image, inlier_count)
        - For "Polynomial Warp Based Transform": (warped_image, inlier_count)
        - If refinement fails, returns None.
        """
        print("\n--- Starting Refined Alignment ---")
        poly_degree = self.settings.value("mosaic/poly_degree", 3, type=int)
        self.status_label.setText("Refinement: Converting images to grayscale...")
        QApplication.processEvents()
        
        # Convert images to grayscale
        if affine_aligned.ndim == 3:
            affine_aligned_gray = np.mean(affine_aligned, axis=-1)
        else:
            affine_aligned_gray = affine_aligned
        if mosaic_img.ndim == 3:
            mosaic_gray = np.mean(mosaic_img, axis=-1)
        else:
            mosaic_gray = mosaic_img

        print("Grayscale conversion done.")
        
        # Compute overlap mask
        self.status_label.setText("Refinement: Computing overlap mask...")
        QApplication.processEvents()
        overlap_mask = (mosaic_gray > 0) & (affine_aligned_gray > 0)

        # Detect stars
        self.status_label.setText("Refinement: Detecting stars in mosaic and affine-aligned images...")
        QApplication.processEvents()
        # Increase max_stars to 50 for debugging purposes.
        mosaic_stars_masked = self.detect_stars(np.where(overlap_mask, mosaic_gray, 0), max_stars=300)
        new_stars_aligned = self.detect_stars(np.where(overlap_mask, affine_aligned_gray, 0), max_stars=300)

        # Debug: Print out the star lists.
        print("Mosaic stars (refined alignment):")
        for s in mosaic_stars_masked:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")
        print("New stars (refined alignment):")
        for s in new_stars_aligned:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")

        self.status_label.setText(f"Refinement: Detected {len(mosaic_stars_masked)} mosaic stars and {len(new_stars_aligned)} new stars.")
        QApplication.processEvents()

        if len(mosaic_stars_masked) < 4 or len(new_stars_aligned) < 4:
            self.status_label.setText("Refinement: Not enough stars detected in candidate region.")
            return None

        # Match stars using position and flux.
        self.status_label.setText("Refinement: Matching stars...")
        QApplication.processEvents()
        # For debugging, you might try a higher threshold.
        matches = self.match_stars(new_stars_aligned, mosaic_stars_masked, distance_thresh=10.0, flux_thresh=1.0)
        print(f"Matched stars: {len(matches)}")
        self.status_label.setText(f"Refinement: {len(matches)} matches found.")
        if len(matches) < 4:
            self.status_label.setText("Refinement: Not enough matched stars for refined transform.")
            return None

        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)

        if method == "Homography Transform":
            self.status_label.setText("Refinement: Computing homography transform...")
            QApplication.processEvents()
            H_refined, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            inliers = int(np.count_nonzero(mask)) if mask is not None else 0
            self.status_label.setText(f"Refinement: Homography computed with {inliers} inliers. Warping image...")
            QApplication.processEvents()
            if H_refined is None:
                self.status_label.setText("Refinement: Homography estimation failed.")
                return None
            warped_image = cv2.warpPerspective(affine_aligned, H_refined,
                                                (affine_aligned.shape[1], affine_aligned.shape[0]),
                                                flags=cv2.INTER_LANCZOS4)
            return (warped_image, inliers)
        elif method == "Polynomial Warp Based Transform":
            self.status_label.setText("Refinement: Computing Polynomial Warp based transform...")
            QApplication.processEvents()
            # Extract control points from matches.
            src_pts = np.float32([match[0][:2] for match in matches])
            dst_pts = np.float32([match[1][:2] for match in matches])
            # Call the static Polynomial Warp warp function.
            try:
                warped_image = MosaicMasterDialog.poly_warp(affine_aligned, src_pts, dst_pts, degree=poly_degree, status_label=self.status_label)
                inliers = len(matches)
                self.status_label.setText(f"Refinement: Polynomial Warp warp applied with {inliers} matched points.")
                return (warped_image, inliers)
            except Exception as e:
                self.status_label.setText(f"Refinement: Polynomial Warp warp failed: {e}")
                return None
        else:
            self.status_label.setText("Refinement: Unexpected transformation method.")
            return None

    @staticmethod
    def poly_warp(image, src_pts, dst_pts, degree=3, status_label=None):
        """
        Warp `image` using a polynomial transformation of the specified degree.
        
        The transformation is defined as:
        u = sum_{i+j<=degree} a_{ij} * x^i * y^j
        v = sum_{i+j<=degree} b_{ij} * x^i * y^j
        
        where the coefficients are solved via least squares using the control points.
        
        Parameters:
        image: Input image.
        src_pts: numpy array of shape (N,2) with control points in the source image.
        dst_pts: numpy array of shape (N,2) with corresponding control points in the destination.
        degree: Degree of the polynomial transformation (allowed 1 to 6, default=3).
        status_label: If provided, a Qt widget where progress messages are displayed.
        
        Returns:
        The warped image.
        """
        h, w = image.shape[:2]
        
        # Function to build the design matrix for points given a degree.
        def build_design_matrix(pts, degree):
            # pts: (N,2) array, where each row is (x, y)
            N = pts.shape[0]
            terms = []
            x = pts[:, 0]
            y = pts[:, 1]
            # Loop over exponents i and j with i+j <= degree.
            for i in range(degree + 1):
                for j in range(degree + 1 - i):
                    terms.append((x**i) * (y**j))
            X = np.vstack(terms).T  # shape: (N, number_of_terms)
            return X

        # Build the design matrix for the control points.
        if status_label is not None:
            status_label.setText("Polynomial warp: Building design matrix for control points...")
            QApplication.processEvents()
        X = build_design_matrix(src_pts, degree)
        
        # Destination coordinates.
        U = dst_pts[:, 0]
        V = dst_pts[:, 1]
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Solving for polynomial coefficients...")
            QApplication.processEvents()
        
        # Solve the least-squares problem.
        coeffs_u, _, _, _ = np.linalg.lstsq(X, U, rcond=None)
        coeffs_v, _, _, _ = np.linalg.lstsq(X, V, rcond=None)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Computing full mapping for image...")
            QApplication.processEvents()
        
        # Build a full grid of coordinates.
        grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
        flat_x = grid_x.ravel()
        flat_y = grid_y.ravel()
        pts_full = np.vstack([flat_x, flat_y]).T  # shape: (h*w, 2)
        
        # Build design matrix for the full grid.
        X_full = build_design_matrix(pts_full, degree)
        
        # Evaluate the polynomial mappings.
        map_u = np.dot(X_full, coeffs_u).reshape(h, w).astype(np.float32)
        map_v = np.dot(X_full, coeffs_v).reshape(h, w).astype(np.float32)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Full mapping computed. Remapping image...")
            QApplication.processEvents()
        
        # Remap the image.
        warped = cv2.remap(image, map_u, map_v, interpolation=cv2.INTER_LANCZOS4, borderMode=cv2.BORDER_CONSTANT)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Image warped.")
            QApplication.processEvents()
        
        return warped



    def estimate_homography_from_stars(self, mosaic_stars, new_stars):
        self.status_label.setText("Matching stars for homography...")
        QApplication.processEvents()
        matches = self.match_stars(new_stars, mosaic_stars, distance_thresh=20.0, flux_thresh=0.5)
        if len(matches) < 4:
            self.status_label.setText("Not enough matched stars for homography.")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} matched stars. Computing homography...")
        QApplication.processEvents()
        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)
        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        inliers = int(np.count_nonzero(mask)) if mask is not None else 0
        self.status_label.setText(f"Homography computed with {inliers} inliers.")
        return H, inliers

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, image_width, settings, ransac_iter=500, inlier_thresh=3.0, norm_trans_thresh=0.2, update_callback=None):
        """
        Runs RANSAC to estimate an affine transform between source and target star coordinates.
        Failsafe checks for translation, scale, rotation, and skew use values from the provided QSettings.
        
        The translation tolerance is a percentage of the image width.
        """
        # Retrieve settings values.
        translation_tolerance_percent = settings.value("mosaic/translation_max_tolerance", 0.1, type=float)
        # Compute the absolute translation tolerance in pixels.
        translation_tolerance = translation_tolerance_percent * image_width

        scale_min = settings.value("mosaic/scale_min_tolerance", 0.85, type=float)
        scale_max = settings.value("mosaic/scale_max_tolerance", 1.15, type=float)
        rotation_max_deg = settings.value("mosaic/rotation_max_tolerance", 45.0, type=float)
        rotation_tolerance = np.radians(rotation_max_deg)
        skew_max = settings.value("mosaic/skew_max_tolerance", 0.05, type=float)  # default: 0.1
        axis_ratio_threshold = settings.value("mosaic/axis_ratio_tolerance", 1.15, type=float)


        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(
                pts_src.reshape(-1, 1, 2), pts_tgt.reshape(-1, 1, 2),
                method=cv2.LMEDS)
            if transform is None:
                continue
            full_mat = np.eye(3, dtype=np.float32)
            full_mat[:2] = transform
            
            # Failsafe: scaling check.
            A = full_mat[:2, :2]
            scale1 = np.linalg.norm(A[:, 0])
            scale2 = np.linalg.norm(A[:, 1])
            scale = (scale1 + scale2) / 2.0
            if scale > scale_max or scale < scale_min:
                continue
            
            # Failsafe: translation check.
            t = full_mat[:2, 2]
            if abs(t[0]) > translation_tolerance or abs(t[1]) > translation_tolerance:
                continue
            
            # New failsafe: check ratio between scales to avoid squashed images.
            if (max(scale1, scale2) / (min(scale1, scale2) + 1e-8)) > axis_ratio_threshold:
                continue

            # Failsafe: rotation angle check.
            angle = np.arctan2(A[1, 0], A[0, 0])
            if abs(angle) > rotation_tolerance: #(np.pi / 4):
                continue
            
            # Failsafe: skew check.
            # For a pure rotation plus uniform scale, the columns of A should be orthogonal.
            v1 = A[:, 0] / (np.linalg.norm(A[:, 0]) + 1e-8)
            v2 = A[:, 1] / (np.linalg.norm(A[:, 1]) + 1e-8)
            skew = abs(np.dot(v1, v2))  # 0 means perfectly orthogonal.
            if skew > skew_max:
                continue

            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars, mosaic_width):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        
        # Compute a normalization factor based on the source coordinate range.
        range_x = np.max(src_coords[:, 0]) - np.min(src_coords[:, 0])
        range_y = np.max(src_coords[:, 1]) - np.min(src_coords[:, 1])
        norm_factor = max(range_x, range_y)
        if norm_factor == 0:
            norm_factor = 1.0
        print("Normalization factor:", norm_factor)
        
        # Normalize coordinates.
        src_norm = src_coords / norm_factor
        tgt_norm = tgt_coords / norm_factor

        self.status_label.setText("Computing Delaunay triangulation (normalized)...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_norm)
        tgt_tri_dict = self.build_triangle_dict(tgt_norm)
        self.status_label.setText("Matching triangles (normalized)...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform_norm, best_inliers = self.ransac_affine(src_norm, tgt_norm, matches, image_width=mosaic_width, settings=self.settings, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        
        if best_transform_norm is None:
            return None, best_inliers

        # Unnormalize the transform.
        # If T_norm is:
        #    y_norm = A_norm * x_norm + t_norm
        # and x_norm = x / norm_factor, then
        #    y = norm_factor * y_norm = A_norm * x + norm_factor * t_norm.
        # Thus, T_full = [A_norm, norm_factor * t_norm].
        best_transform = np.eye(3, dtype=np.float32)
        best_transform[:2, :2] = best_transform_norm[:2, :2]
        best_transform[:2, 2] = best_transform_norm[:2, 2] * norm_factor
        print("Unnormalized transform matrix:\n", best_transform)
        return best_transform, best_inliers



    def stretch_for_display(self, arr):
        """
        Uses your global stretch_mono_image or stretch_color_image to produce
        a display-ready 8-bit image. For color images, uses unlinked stretching.
        """
        arr = arr.astype(np.float32)

        # Decide if it's mono or color based on shape
        if arr.ndim == 3 and arr.shape[2] == 3:
            # Color image => use stretch_color_image with unlinked stretching
            stretched = stretch_color_image(
                image=arr,
                target_median=0.25,   # Adjust if you prefer a different default
                linked=False,         # "unlinked" mode
                normalize=True,       # Ensures final values are in [0,1]
                apply_curves=False,   # Adjust if needed
                curves_boost=0.0
            )
        else:
            # Mono image => use stretch_mono_image
            stretched = stretch_mono_image(
                image=arr,
                target_median=0.25,
                normalize=True,
                apply_curves=False,
                curves_boost=0.0
            )

        # Convert [0,1] => [0,255]
        disp = (stretched * 255.0).clip(0, 255).astype(np.uint8)
        return disp


    def detect_stars(self, image2d, max_stars=50):
        # Retrieve user-defined values for sigma and fwhm.
        sigma_val = self.settings.value("mosaic/star_sigma", 3.0, type=float)
        fwhm_val = self.settings.value("mosaic/star_fwhm", 3.0, type=float)
        
        mean_val, median_val, std_val = sigma_clipped_stats(image2d, sigma=3.0)
        # Use the user-defined fwhm and scale the threshold by the standard deviation.
        daofind = DAOStarFinder(threshold=sigma_val * std_val, fwhm=fwhm_val)
        sources = daofind(image2d - median_val)
        if sources is None or len(sources) == 0:
            return []
        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        # Sort stars by brightness (flux) and select the top ones.
        sorted_indices = np.argsort(-flux)
        top_indices = sorted_indices[:max_stars]
        stars = [(x_coords[i], y_coords[i], flux[i]) for i in top_indices]
        return stars


    def match_stars(self, new_stars, mosaic_stars, distance_thresh=10.0, flux_thresh=0.2):
        """
        Matches stars between two lists.
        new_stars and mosaic_stars should be lists of (x, y, flux).
        
        This version normalizes the flux values in each list by dividing by the median flux.
        
        distance_thresh: maximum distance (in pixels) allowed for a match.
        flux_thresh: allowed absolute difference in normalized flux.
                    For example, if set to 0.2, then the normalized flux difference must be less than 0.2.
                    
        Returns a list of matched pairs: [(new_star, mosaic_star), ...]
        """
        # If either list is empty, return an empty match list.
        if not new_stars or not mosaic_stars:
            return []
        
        # Compute median fluxes.
        new_fluxes = [s[2] for s in new_stars]
        mosaic_fluxes = [s[2] for s in mosaic_stars]
        new_median = np.median(new_fluxes) if new_fluxes else 1.0
        mosaic_median = np.median(mosaic_fluxes) if mosaic_fluxes else 1.0

        # Normalize the flux for each star.
        norm_new_stars = [(s[0], s[1], s[2] / new_median) for s in new_stars]
        norm_mosaic_stars = [(s[0], s[1], s[2] / mosaic_median) for s in mosaic_stars]

        matches = []
        for ns in norm_new_stars:
            best_match = None
            best_distance = float('inf')
            for ms in norm_mosaic_stars:
                dx = ns[0] - ms[0]
                dy = ns[1] - ms[1]
                dist = np.hypot(dx, dy)
                # Check spatial proximity.
                if dist < distance_thresh and dist < best_distance:
                    # Check if the normalized fluxes are similar.
                    # Here, flux_thresh is an absolute threshold on the difference.
                    if abs(ns[2] - ms[2]) < flux_thresh:
                        best_match = ms
                        best_distance = dist
            if best_match is not None:
                matches.append((ns, best_match))
        return matches

    def estimate_transform(self, source_stars, dest_stars):
        min_len = min(len(source_stars), len(dest_stars))
        if min_len < 3:
            return None
        src_pts = np.float32(source_stars[:min_len])
        dst_pts = np.float32(dest_stars[:min_len])
        matrix, inliers = cv2.estimateAffinePartial2D(
            src_pts, dst_pts,
            method=cv2.RANSAC, ransacReprojThreshold=3.0
        )
        if matrix is None:
            return None
        full_mat = np.eye(3, dtype=np.float32)
        full_mat[:2] = matrix
        return full_mat


    def compute_mosaic_bounding_box(self, wcs_items, reference_wcs):
        """
        Compute the mosaic bounding box in pixel coordinates relative to a shared WCS frame,
        properly accounting for rotation and orientation dynamically.
        """
        all_pixels = []

        for itm in wcs_items:
            wcs = itm["wcs"]
            H, W = itm["image"].shape[:2]  # Use only the height and width

            # Get image corner coordinates in world coordinates (RA/Dec)
            pixel_corners = np.array([
                [0, 0],         # Top-left
                [W - 1, 0],     # Top-right
                [0, H - 1],     # Bottom-left
                [W - 1, H - 1]  # Bottom-right
            ])

            # Convert pixel to world coordinates (RA, Dec)
            world_coords = np.column_stack(wcs.pixel_to_world_values(pixel_corners[:, 0], pixel_corners[:, 1]))

            # Convert RA/Dec to pixel coordinates in the reference WCS
            sky_coords = SkyCoord(ra=world_coords[:, 0] * u.deg, dec=world_coords[:, 1] * u.deg, frame='icrs')
            pixel_coords = skycoord_to_pixel(sky_coords, reference_wcs)

            # Ensure we're only using the first two values (x, y)
            all_pixels.append(np.column_stack(pixel_coords[:2]))

        # Stack all pixel coordinates and compute bounding box
        all_pixels = np.vstack(all_pixels)

        min_x, max_x = np.min(all_pixels[:, 0]), np.max(all_pixels[:, 0])
        min_y, max_y = np.min(all_pixels[:, 1]), np.max(all_pixels[:, 1])

        # **Determine whether the mosaic is wider or taller dynamically**
        width = max_x - min_x
        height = max_y - min_y

        print(f"Detected Bounding Box (X={min_x} to {max_x}, Y={min_y} to {max_y})")
        print(f"Calculated Mosaic Size: Width={width}, Height={height}")
        self.status_label.setText(f"Detected Bounding Box: X={min_x} to {max_x}, Y={min_y} to {max_y}")
        self.status_label.setText(f"Calculated Mosaic Size: Width={width}, Height={height}")
        QApplication.processEvents()

        return int(np.floor(min_x)), int(np.floor(min_y)), int(np.ceil(max_x)), int(np.ceil(max_y))

    def create_mosaic(self):
        """Finalize the mosaic (including blending/normalization) and push it to the image manager."""
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        self.finalize_mosaic()
        display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Final Mosaic", parent=self)
        mosaic_win.show()

    def finalize_mosaic(self):
        """Push the final mosaic (and its WCS metadata) to the image manager."""
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        print("🔹 Pushing mosaic to image manager...")

        # Check if self.wcs_metadata exists and is nonempty.
        if not self.wcs_metadata or not any(self.wcs_metadata.values()):
            print("WCS metadata not available; creating minimal header.")
            # Determine if the final mosaic is mono.
            is_mono = (self.final_mosaic.ndim == 2 or (self.final_mosaic.ndim == 3 and self.final_mosaic.shape[2] == 1))
            minimal_header = self.create_minimal_fits_header(self.final_mosaic, is_mono)
            meta = dict(minimal_header)
        else:
            meta = dict(self.wcs_metadata)

        # If the final mosaic is 2D (grayscale), replicate it across three channels.
        final_img = self.final_mosaic
        if final_img.ndim == 2:
            final_img = np.stack([final_img, final_img, final_img], axis=-1)

        self.image_manager.set_image(final_img, metadata=meta, step_name="Mosaic Creation   ")
        print("✅ Mosaic pushed successfully.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.08

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # If the image is 2D, treat it as a single channel.
        if image.ndim == 2:
            # Process as a single channel:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")

            # Add back the original minimum
            image += original_min

            # Clip to [0, 1]
            image = np.clip(image, 0, 1)
            # Optionally, if you want to keep it 2D (since it was originally mono), just return image.
            # If you want to convert to a 3-channel image for display later, you can do that later.
            return image

        # Otherwise, if the image is 3D, process each channel
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel but has 3 dimensions now, convert it back.
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)

        return image


    # ---------- Blind Solve via Astrometry.net ----------
    def perform_blind_solve(self, item):
        """
        Performs a blind solve using Astrometry.net and constructs the WCS header directly.
        If any step fails (e.g. network error), prompts the user to try again.
        """
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return None

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine the file extension of the original image.
            ext = os.path.splitext(item["path"])[1].lower()
            # If the image is not already FITS or TIFF, convert it.
            if ext not in ('.fits', '.fit'):
                # Create a temporary file with a .fit extension.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close it so that save_image can write to it.

                # Generate a minimal FITS header from the image array.
                minimal_header = generate_minimal_fits_header(item["image"])

                # Save the image as a FITS file using the minimal header.
                # (Adjust bit_depth as needed.)
                save_image(
                    img_array=item["image"],
                    filename=temp_file.name,
                    original_format="fit",
                    bit_depth="16-bit",
                    original_header=minimal_header,
                    is_mono=item.get("is_mono", False)
                )
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            # If we created a temporary file (i.e. the original file wasn’t FITS or TIFF), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)

            # Exit the loop once all steps have succeeded.
            break

        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        item["wcs"] = WCS(wcs_header)
        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    # ---------- Blind Solve via ASTAP ----------
    def attempt_astap_solve(self, item):
        """
        Attempt to plate-solve the image using ASTAP.
        Returns a solved header (as a dict) on success or None on failure.
        """
        # 1) Normalize the image (using your stretch_image).
        normalized_image = self.stretch_image(item["image"])
        
        # 2) Save normalized image to a temporary FITS file for ASTAP.
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, item["path"])
        except Exception as e:
            print("Failed to save temporary FITS file:", e)
            return None

        # 3) Run ASTAP on the temporary file.
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            os.remove(tmp_path)
            return None
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            os.remove(tmp_path)
            return None

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return None

        # 4) Retrieve updated header from the temporary file.
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove some extraneous keywords
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
        except Exception as e:
            print("Error reading solved header:", e)
            os.remove(tmp_path)
            return None

        # 5) Merge .wcs file (if ASTAP wrote one) into the solved_header.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                with open(wcs_path, "r") as f:
                    content = f.read()
                pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                for match in re.finditer(pattern, content):
                    key = match.group(1).strip().upper()
                    val = match.group(2).strip()
                    if val.startswith("'") and val.endswith("'"):
                        val = val[1:-1].strip()
                    solved_header[key] = val
            except Exception as e:
                print("Error reading .wcs file:", e)
            finally:
                try:
                    os.remove(wcs_path)
                except Exception as e:
                    print("Error removing .wcs file:", e)

        # Remove the END keyword if present
        solved_header.pop("END", None)
        # Remove any unneeded keywords
        for keyword in ["RANGE_LOW", "RANGE_HIGH", "HISTORY"]:
            solved_header.pop(keyword, None)

        # --- Ensure required WCS keys are present ---
        if "CTYPE1" not in solved_header or not solved_header["CTYPE1"].strip():
            solved_header["CTYPE1"] = "RA---TAN"
        if "CTYPE2" not in solved_header or not solved_header["CTYPE2"].strip():
            solved_header["CTYPE2"] = "DEC--TAN"
        if "RADECSYS" not in solved_header:
            solved_header["RADECSYS"] = "ICRS"
        if "WCSAXES" not in solved_header:
            solved_header["WCSAXES"] = 2

        # Convert known WCS keys to float or int
        expected_float_keys = {"CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2"}
        expected_int_keys = {"NAXIS", "WCSAXES"}

        for key in expected_float_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to float.")

        for key in expected_int_keys:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to int.")

        try:
            save_image(
                img_array=normalized_image,
                filename=item["path"],  # Overwrite the original file
                original_format="fit",
                bit_depth="32",
                original_header=solved_header,  # Updated WCS header
                is_mono=False
            )
            print(f"✅ Updated FITS header with full WCS solution for {item['path']}.")
        except Exception as e:
            print("Error saving updated FITS file using save_image():", e)
            raise e


        # Remove the temporary FITS
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling


        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image


# --------------------------------------------------
# Star Stuff
# --------------------------------------------------      
class StellarAlignmentDialog(QDialog):
    def __init__(self, parent, settings, image_manager):
        """
        Parameters:
          parent: reference to the main window (AstroEditingSuite) so that helper methods
                  (e.g. detect_stars, estimate_transform_from_triangles) can be called.
          settings: QSettings instance (for working directory, etc.)
          image_manager: the ImageManager instance.
        """
        super().__init__(parent)
        self.setWindowTitle("Stellar Alignment")
        self.settings = settings
        self.image_manager = image_manager
        self.parent_window = parent  # for calling helper methods from the main window
        self.stellar_source = None
        self.stellar_target = None
        self.aligned_image = None
        self.autostretch_enabled = False  # Default: No autostretch
        self.initUI()

    def initUI(self):
        main_layout = QHBoxLayout(self)  # Use horizontal layout for side-by-side arrangement

        # ------------------------
        # Left Panel (Selection Controls)
        # ------------------------
        controls_layout = QVBoxLayout()

        # ------------------------
        # Source Image Group
        # ------------------------
        source_group = QGroupBox("Source Image (Reference)")
        source_layout = QVBoxLayout()

        # Radio buttons for selection type.
        source_radio_layout = QHBoxLayout()
        self.source_from_file_radio = QRadioButton("From File")
        self.source_from_slot_radio = QRadioButton("From Slot")
        self.source_from_file_radio.setChecked(True)
        source_radio_layout.addWidget(self.source_from_file_radio)
        source_radio_layout.addWidget(self.source_from_slot_radio)
        source_layout.addLayout(source_radio_layout)

        # File selection controls for source.
        file_source_layout = QHBoxLayout()
        self.source_file_button = QPushButton("Select from File")
        self.source_file_button.clicked.connect(self.select_source_file)
        self.source_file_label = QLabel("No file selected")
        file_source_layout.addWidget(self.source_file_button)
        file_source_layout.addWidget(self.source_file_label)
        source_layout.addLayout(file_source_layout)

        # Slot selection controls for source.
        slot_source_layout = QHBoxLayout()
        self.source_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.source_slot_combo.addItem(slot_name, i)
        self.source_slot_button = QPushButton("Load from Slot")
        self.source_slot_button.clicked.connect(self.load_source_from_slot)
        slot_source_layout.addWidget(self.source_slot_combo)
        slot_source_layout.addWidget(self.source_slot_button)
        source_layout.addLayout(slot_source_layout)

        source_group.setLayout(source_layout)
        controls_layout.addWidget(source_group)

        # ------------------------
        # Target Image Group
        # ------------------------
        target_group = QGroupBox("Target Image (To be Aligned)")
        target_layout = QVBoxLayout()

        # Radio buttons for selection type.
        target_radio_layout = QHBoxLayout()
        self.target_from_file_radio = QRadioButton("From File")
        self.target_from_slot_radio = QRadioButton("From Slot")
        self.target_from_file_radio.setChecked(True)
        target_radio_layout.addWidget(self.target_from_file_radio)
        target_radio_layout.addWidget(self.target_from_slot_radio)
        target_layout.addLayout(target_radio_layout)

        # File selection controls for target.
        file_target_layout = QHBoxLayout()
        self.target_file_button = QPushButton("Select from File")
        self.target_file_button.clicked.connect(self.select_target_file)
        self.target_file_label = QLabel("No file selected")
        file_target_layout.addWidget(self.target_file_button)
        file_target_layout.addWidget(self.target_file_label)
        target_layout.addLayout(file_target_layout)

        # Slot selection controls for target.
        slot_target_layout = QHBoxLayout()
        self.target_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.target_slot_combo.addItem(slot_name, i)
        self.target_slot_button = QPushButton("Load from Slot")
        self.target_slot_button.clicked.connect(self.load_target_from_slot)
        slot_target_layout.addWidget(self.target_slot_combo)
        slot_target_layout.addWidget(self.target_slot_button)
        target_layout.addLayout(slot_target_layout)

        target_group.setLayout(target_layout)
        controls_layout.addWidget(target_group)

        # ------------------------
        # Run Alignment Button
        # ------------------------
        self.run_alignment_button = QPushButton("Run Alignment")
        self.run_alignment_button.clicked.connect(self.run_alignment)
        controls_layout.addWidget(self.run_alignment_button)

        # ------------------------
        # Status Label
        # ------------------------
        self.status_label = QLabel("Status: Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        controls_layout.addWidget(self.status_label)

        main_layout.addLayout(controls_layout)

        # ------------------------
        # Right Panel (Result Preview)
        # ------------------------
        result_layout = QVBoxLayout()
        result_group = QGroupBox("Aligned Image")

        # Preview label
        self.result_preview_label = QLabel()
        self.result_preview_label.setFixedSize(400, 400)
        self.result_preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        result_layout.addWidget(self.result_preview_label)

        # AutoStretch Button
        self.autostretch_button = QPushButton("AutoStretch: OFF")
        self.autostretch_button.clicked.connect(self.toggle_autostretch)
        result_layout.addWidget(self.autostretch_button)

        # Push to Active Slot Button
        self.push_active_button = QPushButton("Push to Active Slot")
        self.push_active_button.clicked.connect(self.push_aligned_to_active)
        result_layout.addWidget(self.push_active_button)

        result_group.setLayout(result_layout)
        main_layout.addWidget(result_group)

        self.setLayout(main_layout)

    def toggle_autostretch(self):
        if self.aligned_image is None:
            QMessageBox.warning(self, "Warning", "No aligned image available to apply autostretch.")
            return

        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.aligned_image  # Reset to the original image if stretch is disabled

        self.update_preview(self.result_preview_label, self.stretched_image)


    def apply_autostretch(self):
        if self.aligned_image is None:
            return  # or handle it as needed
        if len(self.aligned_image.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.aligned_image, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.aligned_image, target_median=0.25, linked=False, normalize=False)

    def update_preview(self, label, image):
        """
        Updates the QLabel to display a preview of the given image with optional autostretch.
        """
        if self.autostretch_enabled:
            image = np.clip(image * 255 / np.max(image), 0, 255).astype(np.uint8)  # Auto-stretch

        if image.ndim == 3 and image.shape[2] == 3:
            h, w, _ = image.shape
            qimg = QImage(image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif image.ndim == 2:
            h, w = image.shape
            qimg = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def detect_stars_by_grid(self, image, stars_per_region=4):
        # Convert to grayscale if needed.
        if image.ndim == 3 and image.shape[2] == 3:
            image_gray = np.mean(image, axis=2)
        else:
            image_gray = image

        H, W = image_gray.shape
        grid_rows, grid_cols = 3, 3
        cell_height, cell_width = H // grid_rows, W // grid_cols

        all_selected_stars = []

        # Precompute global statistics once.
        mean_val, median_val, std_val = sigma_clipped_stats(image_gray, sigma=3.0)
        daofind = DAOStarFinder(threshold=3 * std_val, fwhm=3.0)
        sources = daofind(image_gray - median_val)
        if sources is None or len(sources) == 0:
            return []

        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        regions_used = 0
        # Package stars together (initially as 3-element tuples).
        stars = list(zip(x_coords, y_coords, flux))

        for i in range(grid_rows):
            for j in range(grid_cols):
                x_min = j * cell_width
                x_max = (j+1) * cell_width if j < grid_cols - 1 else W
                y_min = i * cell_height
                y_max = (i+1) * cell_height if i < grid_rows - 1 else H

                # Select stars in this region and attach the cell ID.
                cell_stars = [
                    (star[0], star[1], star[2], (i, j))
                    for star in stars
                    if (x_min <= star[0] < x_max and y_min <= star[1] < y_max)
                ]
                # Sort by brightness (flux) descending.
                cell_stars.sort(key=lambda s: s[2], reverse=True)
                if cell_stars:
                    regions_used += 1
                all_selected_stars.extend(cell_stars[:stars_per_region])
                # Update status for this region:
                self.status_label.setText(f"Region ({i},{j}): Found {len(cell_stars)} stars.")
                QApplication.processEvents()             

        # Optionally, remove duplicates and sort by brightness globally.
        all_selected_stars = list(set(all_selected_stars))
        all_selected_stars.sort(key=lambda s: s[2], reverse=True)
        return all_selected_stars

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, ransac_iter=500, inlier_thresh=3.0, update_callback=None):
        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(pts_src.reshape(-1,1,2), pts_tgt.reshape(-1,1,2), method=cv2.LMEDS)
            if transform is None:
                continue
            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            # Update progress if a callback is provided.
            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        self.status_label.setText("Computing Delaunay triangulation...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_coords)
        tgt_tri_dict = self.build_triangle_dict(tgt_coords)
        self.status_label.setText("Matching triangles...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        # Provide a callback to update status during RANSAC.
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform, best_inliers = self.ransac_affine(src_coords, tgt_coords, matches, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        return best_transform, best_inliers
    
    def select_source_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Source Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load source image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_source = image
            self.source_file_label.setText(path)


    def select_target_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Target Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load target image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_target = image
            self.target_file_label.setText(path)


    def load_source_from_slot(self):
        index = self.source_slot_combo.currentData()
        image = self.image_manager._images.get(index)
        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            image = np.stack([image]*3, axis=-1)
        self.stellar_source = image
        self.source_file_label.setText(f"Loaded from Slot {index}")

    def load_target_from_slot(self):
        index = self.target_slot_combo.currentData()
        image = self.image_manager._images.get(index)
        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            image = np.stack([image]*3, axis=-1)
        self.stellar_target = image
        self.target_file_label.setText(f"Loaded from Slot {index}")

    def update_preview(self, label, image):
        """
        Update a QLabel to display a preview of the given image.
        For display purposes, convert to 8-bit if needed.
        """
        # For display only, convert float32 in [0,1] to 8-bit.
        if image.dtype == np.float32:
            disp = np.clip(image * 255, 0, 255).astype(np.uint8)
        else:
            disp = image
        if disp.ndim == 3 and disp.shape[2] == 3:
            h, w, _ = disp.shape
            qimg = QImage(disp.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif disp.ndim == 2:
            h, w = disp.shape
            qimg = QImage(disp.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def select_corner_stars(self, stars, image_shape, margin=0.15):
        """
        Selects stars that are near the corners (or edges) of the image.
        stars: list of tuples (x, y, flux, cell_id)
        image_shape: (H, W)
        margin: fractional distance from the border
        """
        H, W = image_shape
        selected = []
        for star in stars:
            x, y, _, _ = star
            # Choose stars near left/right and top/bottom margins.
            if (x < margin * W or x > (1 - margin) * W) and (y < margin * H or y > (1 - margin) * H):
                selected.append((x, y))
        return selected


    def run_alignment(self):
        # Ensure both source and target images are loaded.
        if self.source_from_slot_radio.isChecked() and self.stellar_source is None:
            self.load_source_from_slot()
        if self.target_from_slot_radio.isChecked() and self.stellar_target is None:
            self.load_target_from_slot()
        if self.stellar_source is None:
            QMessageBox.warning(self, "Error", "Please select a source image.")
            return
        if self.stellar_target is None:
            QMessageBox.warning(self, "Error", "Please select a target image.")
            return

        # Convert images to grayscale for astroalign computations.
        src = self.stellar_source
        tgt = self.stellar_target
        if src.ndim == 3:
            src_gray = np.mean(src, axis=2)
        else:
            src_gray = src
        if tgt.ndim == 3:
            tgt_gray = np.mean(tgt, axis=2)
        else:
            tgt_gray = tgt

        self.status_label.setText("Computing alignment with astroalign...")
        QApplication.processEvents()

        try:
            import astroalign
            # Compute the transform to align the target image to the source.
            # Note: The order of arguments matters: here we find a transform that maps tgt_gray to src_gray.
            transform_obj, (src_pts, tgt_pts) = astroalign.find_transform(tgt_gray, src_gray)
            # Extract the 3x3 matrix and convert it to a 2x3 affine matrix.
            mat_3x3 = transform_obj.params
            affine_transform = mat_3x3[0:2, :]
        except Exception as e:
            QMessageBox.warning(self, "Alignment Error", f"Astroalign failed: {e}")
            return

        self.status_label.setText("Warping target image with astroalign transform...")
        QApplication.processEvents()

        import cv2
        H, W = src.shape[:2]
        # Apply the computed transform to the target image.
        if tgt.ndim == 2:
            warped_target = cv2.warpAffine(tgt, affine_transform, (W, H), flags=cv2.INTER_LANCZOS4)
        else:
            channels = []
            for i in range(tgt.shape[2]):
                warped_channel = cv2.warpAffine(
                    tgt[:, :, i],
                    affine_transform,
                    (W, H),
                    flags=cv2.INTER_LANCZOS4
                )
                channels.append(warped_channel)
            warped_target = np.stack(channels, axis=2)

        self.aligned_image = warped_target
        self.status_label.setText("Alignment complete with astroalign.")
        self.update_preview(self.result_preview_label, warped_target)

        # Optionally, display the transformation matrix details.
        transform_3x3 = np.eye(3, dtype=np.float32)
        transform_3x3[:2] = affine_transform
        self.show_transform_info(transform_3x3)

        QMessageBox.information(self, "Alignment Complete", "Alignment completed using astroalign.")



    def show_transform_info(self, matrix):
        """
        Decomposes the 3x3 affine matrix and displays its translation, scaling,
        rotation (in degrees), and skew (shear) in a pop-up dialog.
        """
        # Assuming matrix is of the form:
        # [[a, b, tx],
        #  [c, d, ty],
        #  [0, 0, 1]]
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]

        # Compute translation directly.
        translation = (tx, ty)

        # Compute scale in x as the length of the first column.
        scale_x = np.sqrt(a * a + c * c)
        # The rotation angle (in degrees) is the arctan of (c/a)
        rotation_rad = np.arctan2(c, a)
        rotation_deg = np.degrees(rotation_rad)

        # Compute shear (skew). One common formula is:
        shear = (a * b + c * d) / (a * a + c * c)
        # Compute scale_y using the formula:
        # det(A) = a*d - b*c = scale_x * scale_y  => scale_y = det / scale_x
        det = a * d - b * c
        scale_y = det / scale_x

        # Alternatively, you can compute scale_y with a method that accounts for shear:
        # scale_y_alt = np.sqrt(b * b + d * d - shear * shear * (a * a + c * c))
        # (Usually the two values should be similar for well-behaved transforms.)

        info_text = (
            f"Transformation Matrix:\n\n"
            f"[{a:.3f}  {b:.3f}  {tx:.3f}]\n"
            f"[{c:.3f}  {d:.3f}  {ty:.3f}]\n"
            f"[0.000  0.000  1.000]\n\n"
            f"Translation: (tx, ty) = ({tx:.3f}, {ty:.3f})\n"
            f"Scaling: scale_x = {scale_x:.3f}, scale_y = {scale_y:.3f}\n"
            f"Rotation: {rotation_deg:.2f}°\n"
            f"Skew (shear): {shear:.3f}\n"
        )

        # Create a dialog to display the transformation details.
        info_dialog = QDialog(self)
        info_dialog.setWindowTitle("Transformation Matrix Details")
        layout = QVBoxLayout(info_dialog)

        text_edit = QTextEdit(info_dialog)
        text_edit.setReadOnly(True)
        text_edit.setText(info_text)
        layout.addWidget(text_edit)

        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok, info_dialog)
        button_box.accepted.connect(info_dialog.accept)
        layout.addWidget(button_box)

        info_dialog.show()

    def push_aligned_to_active(self):
        """
        Push the aligned image (if available) to the active slot in the image manager.
        """
        if self.aligned_image is None:
            QMessageBox.warning(self, "Error", "No aligned image available. Run alignment first.")
            return
        self.image_manager.set_image(new_image=self.aligned_image, metadata={"description": "Stellar aligned image"}, step_name="Stellar Alignment")
        self.image_manager.image_changed.emit(self.image_manager.current_slot, self.aligned_image, {"description": "Stellar aligned image"})
        QMessageBox.information(self, "Pushed", "Aligned image pushed to the active slot.")
        self.accept()

#############################################
# Worker Signals for Registration Workers
#############################################
class RegistrationWorkerSignals(QObject):
    progress = pyqtSignal(str)           # e.g., "Loaded image X"
    result = pyqtSignal(str)             # e.g., "Saved aligned file path"
    error = pyqtSignal(str)              # e.g., error message
    result_transform = pyqtSignal(str, object)  
    #          ^^^^^^^^^^^^^^^^^^^^^^^
    #  We'll emit (orig_file_path, transform_matrix)

#############################################
# Worker to Process One Image Registration
#############################################
class StarRegistrationWorker(QRunnable):
    def __init__(self, file_path, original_file, current_transform,
                 ref_stars, ref_triangles, output_directory, 
                 use_triangle=False, use_astroalign=False, reference_image=None, downsample_factor: int = 2):
        super().__init__()
        # file_path is used for naming only; always load the raw image from original_file.
        self.file_path = file_path  
        self.original_file = original_file  # persistent key (raw image path)
        self.current_transform = current_transform if current_transform is not None else IDENTITY_2x3
        self.ref_stars = ref_stars
        self.ref_triangles = ref_triangles
        self.output_directory = output_directory
        self.use_triangle = use_triangle
        self.use_astroalign = use_astroalign
        self.reference_image = reference_image  # 2D reference image
        self.downsample_factor = downsample_factor
        self.signals = RegistrationWorkerSignals()

    def run(self):
        try:
            # 1) Load the raw image
            raw_img, img_header, img_bit_depth, img_is_mono = load_image(self.original_file)
            if raw_img is None:
                self.signals.error.emit(f"Could not load {self.original_file}")
                return

            # 2) Apply current cumulative transform to get the candidate image
            candidate_img = StarRegistrationThread.apply_affine_transform_static(raw_img, self.current_transform)
            if candidate_img is None:
                self.signals.error.emit(f"Failed to apply current transform to {self.original_file}")
                return

            # 3) Flatten to 2D if needed
            if candidate_img.ndim == 3:
                img_for_alignment = np.mean(candidate_img, axis=2)
            else:
                img_for_alignment = candidate_img

            # 4) Clean up any NaNs/infs
            if np.isnan(img_for_alignment).any() or np.isinf(img_for_alignment).any():
                img_for_alignment = np.nan_to_num(img_for_alignment, nan=0.0, posinf=0.0, neginf=0.0)

            # 5) Downsample both reference & target
            f = getattr(self, "downsample_factor", 1)
            h, w = img_for_alignment.shape[:2]
            if f > 1:
                small = lambda im: cv2.resize(im, (w // f, h // f), interpolation=cv2.INTER_AREA)
                use_ref = small(self.reference_image)
                use_img = small(img_for_alignment)
            else:
                use_ref, use_img = self.reference_image, img_for_alignment

            # 6) Try astroalign *on the downsampled images* first
            transform = None
            if self.use_astroalign and use_ref is not None and use_ref.ndim == 2:
                transform = self.compute_affine_transform_astroalign(use_img, use_ref)
                if transform is not None:
                    self.signals.progress.emit(f"Astroalign computed delta transform for {os.path.basename(self.file_path)}")
                else:
                    self.signals.progress.emit(f"Astroalign failed for {os.path.basename(self.file_path)}")

            # 7) If astroalign didn’t work, fall back to DAO/RANSAC on the downsampled
            if transform is None:
                self.signals.progress.emit(f"✨ Detecting stars in {os.path.basename(self.file_path)}")
                img_stars = StarRegistrationThread.detect_grid_stars_static(use_img)
                if len(img_stars) < 9:
                    self.signals.error.emit(f"Not enough stars in {self.original_file}")
                    return
                self.signals.progress.emit(f"Detected {len(img_stars)} stars in {os.path.basename(self.file_path)}")

                if self.use_triangle:
                    transform = StarRegistrationThread.compute_affine_transform_triangle_then_ransac(
                        img_stars, self.ref_stars, self.ref_triangles
                    )
                else:
                    transform = StarRegistrationThread.compute_affine_transform_with_ransac_static(
                        img_stars, self.ref_stars, self.ref_triangles
                    )

                if transform is None:
                    self.signals.error.emit(f"Alignment failed for {self.original_file}")
                    return
                self.signals.progress.emit(f"Computed delta transform for {os.path.basename(self.file_path)}")

            # 8) Upscale the small-image translation back to full resolution
            transform = np.array(transform, dtype=np.float64).reshape(2, 3)
            if f > 1:
                transform[0, 2] *= f
                transform[1, 2] *= f

            # 9) Build the cumulative full-res transform
            current_transform = np.array(self.current_transform, dtype=np.float64).reshape(2, 3)
            new_3x3 = np.vstack([transform, [0, 0, 1]])
            curr_3x3 = np.vstack([current_transform, [0, 0, 1]])
            T_total = (new_3x3 @ curr_3x3)[:2, :]

            # 10) Emit the delta so parent updates its record
            self.signals.result_transform.emit(self.original_file, transform)

            # 11) Apply the full-resolution cumulative transform
            aligned_image = StarRegistrationThread.apply_affine_transform_static(raw_img, T_total)
            if aligned_image is None:
                self.signals.error.emit(f"Transform application failed for {self.original_file}")
                return
            if np.isnan(aligned_image).any() or np.isinf(aligned_image).any():
                self.signals.error.emit(f"Aligned image for {self.original_file} contains NaNs/Infs")
                return

            # 12) Save the final aligned frame
            base = os.path.basename(self.file_path)
            name, ext = os.path.splitext(base)
            if not (name.endswith("_r") or name.endswith("_n_r")):
                name += "_r"
            output_filename = os.path.join(self.output_directory, f"{name}.fit")

            save_image(
                img_array=aligned_image,
                filename=output_filename,
                original_format="fit",
                bit_depth=img_bit_depth,
                original_header=img_header,
                is_mono=img_is_mono
            )
            self.signals.result.emit(output_filename)
            self.signals.progress.emit(f"Registered {os.path.basename(self.file_path)}")

        except Exception as e:
            self.signals.error.emit(f"Error processing {self.original_file}: {e}")

    @staticmethod
    def compute_affine_transform_astroalign(source_img, reference_img):
        import astroalign
        try:
            transform_obj, _ = astroalign.find_transform(source_img, reference_img)
            return transform_obj.params[0:2, :]
        except Exception as e:
            print(f"DEBUG: astroalign failed: {e}")
            return None

      


#############################################
# Main Star Registration Thread (Concurrent)
#############################################
# Identity transform (2x3)
IDENTITY_2x3 = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float64)

class StarRegistrationThread(QThread):
    progress_update = pyqtSignal(str)
    registration_complete = pyqtSignal(bool, str)

    def __init__(self, reference_image_path, files_to_align, output_directory, 
                 max_refinement_passes=3, shift_tolerance=0.2):
        super().__init__()
        self.reference_image_path = os.path.normpath(reference_image_path)
        # First, assign original_files.
        self.original_files = [os.path.normpath(f) for f in files_to_align]
        # Copy original_files to files_to_align.
        self.files_to_align = self.original_files.copy()
        self.output_directory = os.path.normpath(output_directory)
        self.max_refinement_passes = max_refinement_passes
        self.shift_tolerance = shift_tolerance
        # Mapping: persistent key (raw file) -> current working file.
        self.file_key_to_current_path = {f: f for f in self.original_files}
        # Store cumulative transforms keyed by the persistent (raw) file path.
        self.alignment_matrices = {}
        self.transform_deltas = []  # List of shift arrays per pass.

    def run(self):
        try:
            # Load reference image.
            ref_image, _, _, _ = load_image(self.reference_image_path)
            if ref_image is None:
                self.registration_complete.emit(False, "Reference image failed to load!")
                return

            # Convert to 2D if needed.
            if ref_image.ndim == 3:
                ref_image = np.mean(ref_image, axis=2)
            ref_image = np.nan_to_num(ref_image, nan=0.0, posinf=0.0, neginf=0.0)
            self.reference_image_2d = ref_image    

            # Detect reference stars.
            ref_stars = self.detect_stars(ref_image)
            if len(ref_stars) < 10:
                self.registration_complete.emit(False, "Insufficient stars in reference image!")
                return
            ref_triangles = self.build_triangle_dict(ref_stars)

            # --- Pre-save all files with the _n_r suffix ---
            pre_saved_files = []
            for fpath in self.files_to_align:
                image, header, fmt, bit_depth = load_image(fpath)
                if image is None:
                    self.progress_update.emit(f"Error loading {fpath} during pre-save.")
                    continue
                base = os.path.basename(fpath)
                name, ext = os.path.splitext(base)
                # Remove trailing _n if present.
                if name.endswith("_n"):
                    name = name[:-2]
                if not name.endswith("_n_r"):
                    name += "_n_r"
                pre_saved = os.path.join(self.output_directory, f"{name}.fit")
                save_image(
                    img_array=image,
                    filename=pre_saved,
                    original_format="fit",
                    bit_depth=bit_depth,
                    original_header=header,
                    is_mono=(image.ndim == 2)
                )
                pre_saved_files.append(pre_saved)
                self.progress_update.emit(f"Pre-saved {base} as {os.path.basename(pre_saved)}")
            self.files_to_align = pre_saved_files

            # --- Registration Passes ---
            for pass_idx in range(self.max_refinement_passes):
                self.progress_update.emit(
                    f"⏳ Refinement Pass {pass_idx+1}/{self.max_refinement_passes}..."
                )
                success, msg = self.run_one_registration_pass(ref_stars, ref_triangles, pass_idx)
                if not success:
                    any_aligned = any(x is not None for x in self.alignment_matrices.values())
                    if not any_aligned:
                        self.registration_complete.emit(False, "No frames could be aligned. Aborting.")
                        return
                    else:
                        self.progress_update.emit("Partial success: some frames permanently failed.")
                        break

                if self.transform_deltas and max(self.transform_deltas[-1]) < self.shift_tolerance:
                    self.progress_update.emit("✅ Convergence reached! Stopping refinement.")
                    break

            # Final rejection check using delta shifts only.
            final_shifts = self.transform_deltas[-1]  # Delta shifts from the last pass.
            old_files = self.files_to_align
            new_files = []
            rejected_files = []
            for f, delta in zip(old_files, final_shifts):
                # If the delta shift (the correction computed in the final pass)
                # exceeds 2 pixels, reject the frame.
                if delta > 2.0:
                    rejected_files.append(f)
                else:
                    new_files.append(f)
            self.files_to_align = new_files

            if rejected_files:
                self.progress_update.emit(
                    f"🚨 Rejected {len(rejected_files)} frame(s) due to shift >2px or rotation >2°."
                )

            aligned_count = sum(1 for v in self.alignment_matrices.values() if v is not None)
            total_count = len(self.alignment_matrices)
            summary = f"Registration complete. Valid frames: {aligned_count}/{total_count}."
            self.registration_complete.emit(True, summary)

        except Exception as e:
            self.registration_complete.emit(False, f"Error: {e}")

    def run_one_registration_pass(self, ref_stars, ref_triangles, pass_index):
        pool = QThreadPool.globalInstance()
        num_cores = os.cpu_count() or 4
        pool.setMaxThreadCount(num_cores)
        self.progress_update.emit(f"Using {num_cores} cores for pass {pass_index+1}.")

        # New mappings for this pass.
        transformed_files = {}
        remaining_files = {}
        skipped_files = []  # List to track skipped images

        use_astroalign = (pass_index < 4)
        for original_file, current_file in self.file_key_to_current_path.items():
            # Get current cumulative transform for persistent key.
            current_transform = self.alignment_matrices.get(original_file, IDENTITY_2x3)
            worker = StarRegistrationWorker(
                file_path=current_file,
                original_file=original_file,
                current_transform=current_transform,
                ref_stars=ref_stars,
                ref_triangles=ref_triangles,
                output_directory=self.output_directory,
                use_triangle=(pass_index >= 5),
                use_astroalign=use_astroalign,
                reference_image=self.reference_image_2d,
                downsample_factor=2
            )
            worker.signals.progress.connect(self.on_worker_progress)
            worker.signals.error.connect(self.on_worker_error)
            worker.signals.result_transform.connect(self.on_worker_result_transform)
            pool.start(worker)
        
        pool.waitForDone()
        
        pass_deltas = []
        aligned_count = 0

        # Iterate over the persistent mapping using the delta shift computed in this pass.
        for original_file, current_file in self.file_key_to_current_path.items():
            # Use the delta shift from the current pass; default to 0 if none.
            delta_shift = self.delta_transforms.get(original_file, 0.0)
            pass_deltas.append(delta_shift)
            # If the delta is above threshold (e.g., 0.2 pixels), update the file.
            if delta_shift > 0.2:
                # Load current working file and re-apply cumulative transform.
                image, original_header, original_format, bit_depth = load_image(current_file)
                transformed_image = self.apply_affine_transform_static(image, self.alignment_matrices.get(original_file))
                if transformed_image is not None and (np.isnan(transformed_image).any() or np.isinf(transformed_image).any()):
                    transformed_image = np.nan_to_num(transformed_image, nan=0.0)
                base = os.path.basename(current_file)
                name, ext = os.path.splitext(base)
                if not (name.endswith("_r") or name.endswith("_n_r")):
                    name += "_r"
                transformed_path = os.path.join(self.output_directory, f"{name}.fit")
                save_image(
                    img_array=transformed_image,
                    filename=transformed_path,
                    original_format="fit",
                    bit_depth=bit_depth,
                    original_header=original_header,
                    is_mono=False
                )
                transformed_files[original_file] = transformed_path
            else:
                # Delta is small, so we consider this frame converged.
                remaining_files[original_file] = current_file
                aligned_count += 1
                skipped_files.append(os.path.basename(current_file))  # Log the filename

        self.transform_deltas.append(pass_deltas)
        # Update the persistent mapping for the next pass.
        self.file_key_to_current_path = {**transformed_files, **remaining_files}

        preview = ", ".join([f"{d:.2f}" for d in pass_deltas[:10]])
        if len(pass_deltas) > 10:
            preview += f" ... ({len(pass_deltas)} total)"
        self.progress_update.emit(f"Pass {pass_index+1} delta shifts: [{preview}]")
        
        # Emit a message listing skipped images if any.
        if skipped_files:
            self.progress_update.emit(f"Skipped images (delta shift < 0.2px): {', '.join(skipped_files)}")

        if aligned_count == 0:
            return False, "All frames already aligned within tolerance."
        failed_count = len(self.file_key_to_current_path) - aligned_count
        if failed_count > 0:
            return True, f"Pass complete. {failed_count} frame(s) failed."
        return True, "Pass complete (all succeeded)."

    def on_worker_result_transform(self, persistent_key, new_transform):
        persistent_key = os.path.normpath(persistent_key)
        # Ensure new_transform is a float64 array with shape (2,3)
        new_transform = np.array(new_transform, dtype=np.float64).reshape(2, 3)
        # Compute the delta shift (from the delta transform)
        delta_shift = np.sqrt(new_transform[0,2]**2 + new_transform[1,2]**2)
        # Record the delta shift in a new dictionary.
        if not hasattr(self, 'delta_transforms'):
            self.delta_transforms = {}
        self.delta_transforms[persistent_key] = delta_shift

        # Now update the cumulative transform.
        prev_transform = self.alignment_matrices.get(persistent_key)
        if prev_transform is not None:
            prev_transform = np.array(prev_transform, dtype=np.float64).reshape(2, 3)
            prev_3x3 = np.vstack([prev_transform, [0, 0, 1]])
            new_3x3 = np.vstack([new_transform, [0, 0, 1]])
            combined = new_3x3 @ prev_3x3
            self.alignment_matrices[persistent_key] = combined[0:2, :]
        else:
            self.alignment_matrices[persistent_key] = new_transform

        print(f"Persistent key: {persistent_key}")
        print(f"T_delta:\n{new_transform}")
        print(f"Delta shift: {delta_shift}")


    
    def on_worker_progress(self, msg):
        self.progress_update.emit(msg)

    def on_worker_error(self, msg):
        self.progress_update.emit("Error: " + msg)

    def on_worker_result(self, out):
        print("Saved: " + out)


    def detect_stars(self, image):
        """
        Run DAOStarFinder multiple times with different FWHMs,
        then combine (deduplicate) the results.
        """
        self.progress_update.emit(f"✨ Detecting all stars in reference frame")
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        mean, median, std = sigma_clipped_stats(image)
        
        # A range of FWHMs you want to try
        fwhm_list = [2.5, 3, 3.5, 4, 5, 6, 7]
        
        all_sources = []
        for fwhm in fwhm_list:
            daofind = DAOStarFinder(fwhm=fwhm, threshold=4 * std)
            sources = daofind(image - median)
            if sources is not None and len(sources) > 0:
                all_sources.append(sources)

        # If we never found any stars, return empty
        if not all_sources:
            return np.empty((0, 2), dtype=np.float32)

        # 1) Combine them all into a single table
        combined_sources = vstack(all_sources)  # Astropy Table vertical stack

        # 2) Optionally remove duplicates
        #    E.g. we can round the (x,y) to 1 decimal place and do a unique operation.
        #    This helps if the same star is found at slightly different coords in different FWHM passes.
        x_rounded = np.round(combined_sources['xcentroid'], 1)
        y_rounded = np.round(combined_sources['ycentroid'], 1)
        xy_rounded = np.array([x_rounded, y_rounded]).T
        
        # We'll build a dictionary to track unique (x_rounded, y_rounded)
        seen = {}
        unique_rows = []
        for i, (rx, ry) in enumerate(xy_rounded):
            key = (rx, ry)
            if key not in seen:
                seen[key] = True
                unique_rows.append(i)

        final_sources = combined_sources[unique_rows]
        
        # Convert to Nx2 NumPy array
        star_coords = np.vstack([final_sources['xcentroid'], final_sources['ycentroid']]).T
        return star_coords.astype(np.float32)

    def build_triangle_dict(self, coords):
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]
            inv = self.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    def compute_triangle_invariant(self, tri_points):
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        
        if sides[0] == 0:
            return None  # Prevent division by zero
        
        # Use higher precision (4 decimal places instead of 2)
        return (round(sides[1] / sides[0], 4), round(sides[2] / sides[0], 4))

    @staticmethod
    def compute_triangle_invariant_static(tri_points):
        """
        Compute the invariant for a triangle defined by three points.
        Returns a tuple (side2/side1, side3/side1) if valid, otherwise None.
        This invariant is independent of scale and rotation.
        """
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1] / sides[0], sides[2] / sides[0])



        


    @staticmethod
    def detect_grid_stars_static_fast(
        image,
        blur_size=9,
        threshold_factor=0.6,
        min_area=1,
        max_area=10000
    ):
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        h, w = image.shape
        margin_x = int(w * 0.05)
        margin_y = int(h * 0.05)
        valid_x_min, valid_x_max = margin_x, w - margin_x
        valid_y_min, valid_y_max = margin_y, h - margin_y

        # Divide the image into a 4x4 grid
        grid_x = np.linspace(valid_x_min, valid_x_max, 4, dtype=int)
        grid_y = np.linspace(valid_y_min, valid_y_max, 4, dtype=int)

        stars = []
        for i in range(len(grid_x) - 1):
            for j in range(len(grid_y) - 1):
                x_min, x_max = grid_x[i], grid_x[i+1]
                y_min, y_max = grid_y[j], grid_y[j+1]
                sub_img = image[y_min:y_max, x_min:x_max]
                if sub_img.size == 0:
                    continue

                # Check if there's enough variance to detect stars
                if np.std(sub_img) > 0:
                    # Detect stars in this subregion
                    local_stars = fast_star_detect(
                        sub_img,
                        blur_size=blur_size,
                        threshold_factor=threshold_factor,
                        min_area=min_area,
                        max_area=max_area
                    )

                    shifted_stars = []
                    for (sx, sy) in local_stars:
                        # Skip any star coordinates that are NaN
                        if np.isnan(sx) or np.isnan(sy):
                            continue
                        gx = np.clip(sx + x_min, valid_x_min, valid_x_max - 1)
                        gy = np.clip(sy + y_min, valid_y_min, valid_y_max - 1)
                        shifted_stars.append((gx, gy))

                    # Optionally filter again (just in case)
                    filtered_stars = [s for s in shifted_stars if not (np.isnan(s[0]) or np.isnan(s[1]))]

                    # Sort by brightness in the global image (casting to int for indexing)
                    sorted_stars = sorted(
                        filtered_stars,
                        key=lambda s: image[int(s[1]), int(s[0])],
                        reverse=True
                    )
                    # Keep only the top 50 stars from this subregion
                    stars.extend(sorted_stars[:20])

        if len(stars) == 0:
            return np.empty((0,2), dtype=np.float32)

        return np.array(stars, dtype=np.float32)

    @staticmethod
    def detect_grid_stars_static(
        image,
        fwhm_list=[2.5, 3, 3.5, 4, 5],
        threshold_factor=4,  # multiplied by std
        min_area=1,
        max_area=10000
    ):

        # If the image is color, average it to produce a single channel.
        print("detecting grid stars dao")
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        h, w = image.shape
        margin_x = int(w * 0.05)
        margin_y = int(h * 0.05)
        valid_x_min, valid_x_max = margin_x, w - margin_x
        valid_y_min, valid_y_max = margin_y, h - margin_y

        # Divide the image into a 4x4 grid.
        grid_x = np.linspace(valid_x_min, valid_x_max, 4, dtype=int)
        grid_y = np.linspace(valid_y_min, valid_y_max, 4, dtype=int)

        stars = []
        for i in range(len(grid_x) - 1):
            for j in range(len(grid_y) - 1):
                x_min, x_max = grid_x[i], grid_x[i+1]
                y_min, y_max = grid_y[j], grid_y[j+1]
                sub_img = image[y_min:y_max, x_min:x_max]
                if sub_img.size == 0:
                    continue

                # Only process subregions with sufficient variance.
                if np.std(sub_img) > 0:
                    # Compute sigma-clipped stats for thresholding.
                    mean, median, std = sigma_clipped_stats(sub_img)
                    # Try each FWHM value.
                    for fwhm in fwhm_list:
                        daofind = DAOStarFinder(fwhm=fwhm, threshold=threshold_factor * std)
                        sources = daofind(sub_img - median)
                        if sources is not None and len(sources) > 0:
                            # Convert the astropy Table to a NumPy array of (x, y) coordinates.
                            local_stars = np.column_stack((sources['xcentroid'], sources['ycentroid']))
                            shifted_stars = []
                            for (sx, sy) in local_stars:
                                # Skip any NaN values.
                                if np.isnan(sx) or np.isnan(sy):
                                    continue
                                # Shift to global image coordinates.
                                gx = np.clip(sx + x_min, valid_x_min, valid_x_max - 1)
                                gy = np.clip(sy + y_min, valid_y_min, valid_y_max - 1)
                                shifted_stars.append((gx, gy))
                            # Optionally, filter out any remaining NaNs.
                            filtered_stars = [s for s in shifted_stars if not (np.isnan(s[0]) or np.isnan(s[1]))]
                            # Sort by brightness using the pixel value in the global image.
                            sorted_stars = sorted(
                                filtered_stars,
                                key=lambda s: image[int(s[1]), int(s[0])],
                                reverse=True
                            )
                            # Keep the top 20 stars from this subregion for this FWHM.
                            stars.extend(sorted_stars[:20])
        if len(stars) == 0:
            return np.empty((0, 2), dtype=np.float32)
        return np.array(stars, dtype=np.float32)


    @staticmethod
    def compute_affine_transform_with_ransac_static(img_stars, ref_stars, ref_triangles, max_attempts=20, max_iter=20, convergence_thresh=0.2):
        print("DEBUG: Starting compute_affine_transform_with_ransac_static")
        attempt = 0
        transform = None
        while attempt < max_attempts:
            attempt += 1
            print(f"DEBUG: Initial RANSAC attempt {attempt}")
            matches = []
            for img_star in img_stars:
                distances = np.linalg.norm(ref_stars - img_star, axis=1)
                closest_idx = np.argmin(distances)
                #if distances[closest_idx] < 20:
                #    matches.append((img_star, ref_stars[closest_idx]))
                matches.append((img_star, ref_stars[closest_idx]))
            print(f"DEBUG: Found {len(matches)} matches on attempt {attempt}")
            if len(matches) < 5:
                print("DEBUG: Not enough matches; continuing to next attempt.")
                continue
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            rough_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=3.0
            )
            # -----------------------------
            # CHECK for NaN => fallback
            # -----------------------------
            if rough_transform is not None:
                if np.isnan(rough_transform).any() or np.isinf(rough_transform).any():
                    print("DEBUG: Rough transform has NaN => trying triangles fallback.")
                    fallback = StarRegistrationThread.compute_affine_transform_from_triangles(
                        img_stars, ref_stars, ref_triangles
                    )
                    if fallback is not None:
                        print("DEBUG: Fallback worked; using triangle-based transform.")
                        transform = fallback
                        break
                    else:
                        rough_transform = None  # Force next attempt
                else:
                    # No NaN => check validity
                    if StarRegistrationThread.is_valid_transform_static(rough_transform):
                        transform = rough_transform
                        print("DEBUG: Rough transform computed successfully.")
                        break
                    else:
                        print("DEBUG: Rough transform invalid; retrying.")
        if transform is None:
            print("DEBUG: Failed to compute initial rough transform.")
            return None
        for iter_num in range(max_iter):
            transformed_img_stars = cv2.transform(img_stars.reshape(-1, 1, 2), transform).reshape(-1, 2)
            matches = []
            for idx, t_star in enumerate(transformed_img_stars):
                distances = np.linalg.norm(ref_stars - t_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 20:
                    matches.append((img_stars[idx], ref_stars[closest_idx]))
            print(f"DEBUG: Refinement iteration {iter_num+1}: found {len(matches)} matches.")
            if len(matches) < 5:
                print("DEBUG: Not enough matches during refinement; aborting transform.")
                return None
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            new_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=3.0
            )
            if new_transform is None:
                print("DEBUG: Refinement failed to compute a new transform; aborting.")
                return None
            delta = np.linalg.norm(new_transform[:, 2] - transform[:, 2])
            print(f"DEBUG: Iteration {iter_num+1}: translation delta = {delta:.3f} pixels")
            transform = new_transform
            if delta < convergence_thresh:
                print("DEBUG: Convergence reached.")
                break
        if not StarRegistrationThread.is_valid_transform_static(transform):
            print("DEBUG: Final transform failed validation.")
            return None
        print("DEBUG: Final transform computed successfully.")
        return transform

    @staticmethod
    def is_valid_transform_static(matrix):
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]
        scale_x = np.sqrt(a**2 + c**2)
        scale_y = np.sqrt(b**2 + d**2)
        skew = np.abs((a * b + c * d) / (a**2 + c**2))
        if not (0.9 <= scale_x <= 1.1 and 0.9 <= scale_y <= 1.1):
            return False
        return True

    @staticmethod
    def apply_affine_transform_static(image, transform_matrix):
        import numpy as np
        import cv2
        # Ensure the transform matrix is a NumPy array of shape (2,3) and type float32.
        transform_matrix = np.array(transform_matrix, dtype=np.float32).reshape(2, 3)
        
        h, w = image.shape[:2]
        # If grayscale, use warpAffine directly.
        if image.ndim == 2:
            aligned = cv2.warpAffine(
                image,
                transform_matrix,
                (w, h),
                flags=cv2.INTER_LANCZOS4,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=0
            )
        else:
            # For color images, apply warpAffine on each channel.
            channels = []
            for i in range(image.shape[2]):
                warped_channel = cv2.warpAffine(
                    image[:, :, i],
                    transform_matrix,
                    (w, h),
                    flags=cv2.INTER_LANCZOS4,
                    borderMode=cv2.BORDER_CONSTANT,
                    borderValue=0
                )
                channels.append(warped_channel)
            aligned = np.stack(channels, axis=2)
        
        return aligned


    @staticmethod
    def compute_affine_transform_from_triangles(img_stars, ref_stars, ref_triangles, method='auto', max_stars=100):
        """
        Compute an affine transform by matching triangles using side–side–side invariants.
        
        If the target image has few stars (e.g. fewer than 30), this function computes invariants for 
        all combinations of three stars; otherwise, it uses Delaunay triangulation to generate triangles.
        
        The 'ref_triangles' is assumed to be built from the reference stars using your build_triangle_dict() method.
        
        The 'method' parameter can be:
        - 'all'    : always compute all combinations (useful if you have very few stars)
        - 'delaunay': always use Delaunay triangulation
        - 'auto'   : use 'all' if len(img_stars) < 30, otherwise 'delaunay'
        
        Returns an affine transform (2x3 matrix) or None if matching fails.
        """
        import numpy as np
        from itertools import combinations
        from scipy.spatial import Delaunay

        if len(img_stars) < 3:
            print("DEBUG: Too few stars in target for triangle matching.")
            return None

        # Decide on method automatically if 'auto'
        if method == 'auto':
            method = 'all' if len(img_stars) < 30 else 'delaunay'
        
        # Option 1: Compute all combinations if method=='all'
        if method == 'all':
            img_triangle_invariants = {}
            # Compute invariants for every combination of 3 stars.
            for comb in combinations(range(len(img_stars)), 3):
                pts = img_stars[list(comb)]
                inv = StarRegistrationThread.compute_triangle_invariant_static(pts)
                if inv is None:
                    continue
                inv_key = (round(inv[0], 2), round(inv[1], 2))
                img_triangle_invariants.setdefault(inv_key, []).append(comb)
            target_tri_dict = img_triangle_invariants
        else:
            # Option 2: Use Delaunay triangulation
            # Optionally limit the star set if it's huge:
            if len(img_stars) > max_stars:
                img_stars = img_stars[:max_stars]
            try:
                tri = Delaunay(img_stars)
            except Exception as e:
                print("DEBUG: Delaunay triangulation failed:", e)
                return None
            target_tri_dict = {}
            for simplex in tri.simplices:
                pts = img_stars[simplex]
                inv = StarRegistrationThread.compute_triangle_invariant_static(pts)
                if inv is None:
                    continue
                inv_key = (round(inv[0], 2), round(inv[1], 2))
                target_tri_dict.setdefault(inv_key, []).append(simplex)

        # Cross-match: For each triangle invariant in the target dictionary,
        # if a matching invariant exists in the reference triangles, add the point pairs.
        matches = []
        for inv_key, sim_list in target_tri_dict.items():
            if inv_key in ref_triangles:
                ref_simplices = ref_triangles[inv_key]
                for s in sim_list:
                    # 's' is either a tuple (if computed from all combinations) or an array (from Delaunay)
                    pts_img = img_stars[list(s)] if isinstance(s, tuple) else img_stars[s]
                    for rs in ref_simplices:
                        pts_ref = ref_stars[rs]
                        # Each triangle yields three matches.
                        for i in range(3):
                            matches.append((pts_img[i], pts_ref[i]))
        if len(matches) < 6:
            print("DEBUG: Not enough triangle matches to run RANSAC.")
            return None

        src_pts = np.array([m[0] for m in matches], dtype=np.float32).reshape(-1, 1, 2)
        dst_pts = np.array([m[1] for m in matches], dtype=np.float32).reshape(-1, 1, 2)

        transform, inliers = cv2.estimateAffinePartial2D(
            src_pts,
            dst_pts,
            method=cv2.RANSAC,
            ransacReprojThreshold=3.0
        )

        if transform is not None:
            if np.isnan(transform).any() or np.isinf(transform).any():
                print("DEBUG: Triangle fallback transform has NaN/Inf.")
                return None
            if not StarRegistrationThread.is_valid_transform_static(transform):
                print("DEBUG: Triangle fallback transform not valid by scale check.")
                return None
            print("DEBUG: Triangle-based transform succeeded.")
            return transform

        return None


    @staticmethod
    def compute_affine_transform_triangle_then_ransac(img_stars, ref_stars, ref_triangles, max_iter=100, convergence_thresh=0.2, ransac_thresh=3.0, max_stars=300):
        """
        First, compute an initial transform using triangle matching.
        Then, refine the transform using nearest-star RANSAC.
        To avoid freezing, only use the top 'max_stars' (if available) from img_stars.
        """
        if len(img_stars) < 3:
            print("DEBUG: Too few stars in target for triangle matching.")
            return None

        # Limit the number of stars to process.
        if len(img_stars) > max_stars:
            img_stars = img_stars[:max_stars]
        
        # Compute the initial transform from triangles.
        initial_transform = StarRegistrationThread.compute_affine_transform_from_triangles(img_stars, ref_stars, ref_triangles)
        if initial_transform is None:
            print("DEBUG: Triangle matching did not yield an initial transform.")
            return None
        print("DEBUG: Initial triangle-based transform computed.")

        # Refine using nearest-star RANSAC starting from the triangle transform.
        transform = initial_transform
        for iter_num in range(max_iter):
            transformed_img_stars = cv2.transform(img_stars.reshape(-1, 1, 2), transform).reshape(-1, 2)
            matches = []
            for idx, t_star in enumerate(transformed_img_stars):
                distances = np.linalg.norm(ref_stars - t_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 20:
                    matches.append((img_stars[idx], ref_stars[closest_idx]))
            print(f"DEBUG (triangle→ransac): Refinement iteration {iter_num+1}: found {len(matches)} matches.")
            if len(matches) < 5:
                print("DEBUG: Not enough matches during refinement; aborting transform.")
                return None
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            new_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=ransac_thresh
            )
            if new_transform is None:
                print("DEBUG: Refinement failed to compute a new transform; aborting.")
                return None
            delta = np.linalg.norm(new_transform[:, 2] - transform[:, 2])
            print(f"DEBUG (triangle→ransac): Iteration {iter_num+1}: translation delta = {delta:.3f} pixels.")
            transform = new_transform
            if delta < convergence_thresh:
                print("DEBUG (triangle→ransac): Convergence reached.")
                break
        if not StarRegistrationThread.is_valid_transform_static(transform):
            print("DEBUG: Final transform (triangle→ransac) failed validation.")
            return None
        print("DEBUG: Final transform (triangle→ransac) computed successfully.")
        return transform

    @staticmethod
    def compute_triangle_invariant_static(tri_points):
        # same logic as compute_triangle_invariant
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])        
    
class StarRegistrationWindow(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the Image Manager
        self.reference_image_path = None
        self.files_to_align = []
        self.output_directory = None
        self.thread = None  # Store thread reference

        self.initUI()

    def initUI(self):
        self.setWindowTitle("Star Registration")
        self.setGeometry(200, 200, 600, 450)
        main_layout = QVBoxLayout(self)

        # ─────────────────────────────────────────
        # Reference Image Selection
        # ─────────────────────────────────────────
        ref_layout = QHBoxLayout()
        self.ref_label = QLabel("Reference Image:")
        self.ref_path_label = QLabel("No reference selected")
        self.ref_path_label.setWordWrap(True)

        self.select_ref_slot_button = QPushButton("From Slot")
        self.select_ref_slot_button.clicked.connect(self.select_reference_from_slot)

        self.select_ref_file_button = QPushButton("From File")
        self.select_ref_file_button.clicked.connect(self.select_reference_from_file)

        ref_layout.addWidget(self.ref_label)
        ref_layout.addWidget(self.ref_path_label)
        ref_layout.addWidget(self.select_ref_slot_button)
        ref_layout.addWidget(self.select_ref_file_button)

        # ─────────────────────────────────────────
        # Image Selection Section
        # ─────────────────────────────────────────
        file_selection_layout = QHBoxLayout()

        self.add_files_button = QPushButton("Select Files")
        self.add_files_button.clicked.connect(self.select_files_to_align)

        self.add_directory_button = QPushButton("Select Directory")
        self.add_directory_button.clicked.connect(self.select_directory_to_align)

        file_selection_layout.addWidget(self.add_files_button)
        file_selection_layout.addWidget(self.add_directory_button)

        # ─────────────────────────────────────────
        # TreeBox for Selected Files
        # ─────────────────────────────────────────
        self.tree_widget = QTreeWidget()
        self.tree_widget.setColumnCount(1)
        self.tree_widget.setHeaderLabels(["Files to Align"])
        self.tree_widget.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Buttons for managing the TreeBox
        tree_buttons_layout = QHBoxLayout()
        self.remove_selected_button = QPushButton("Remove Selected")
        self.remove_selected_button.clicked.connect(self.remove_selected_files)

        self.clear_tree_button = QPushButton("Clear All")
        self.clear_tree_button.clicked.connect(self.clear_tree)

        tree_buttons_layout.addWidget(self.remove_selected_button)
        tree_buttons_layout.addWidget(self.clear_tree_button)

        # ─────────────────────────────────────────
        # Output Directory Selection
        # ─────────────────────────────────────────
        output_layout = QHBoxLayout()
        self.output_label = QLabel("Output Directory:")
        self.output_path_label = QLabel("No directory selected")
        self.output_path_label.setWordWrap(True)

        self.select_output_button = QPushButton("Select Output Folder")
        self.select_output_button.clicked.connect(self.select_output_directory)

        output_layout.addWidget(self.output_label)
        output_layout.addWidget(self.output_path_label)
        output_layout.addWidget(self.select_output_button)

        # ─────────────────────────────────────────
        # Progress Display
        # ─────────────────────────────────────────
        self.progress_label = QLabel("Status: Waiting...")
        self.progress_label.setStyleSheet("color: blue; font-weight: bold;")
        
        # ─────────────────────────────────────────
        # Start Button
        # ─────────────────────────────────────────
        self.start_button = QPushButton("Start Registration")
        self.start_button.setStyleSheet("font-weight: bold; font-size: 14px;")
        self.start_button.clicked.connect(self.start_registration)

        # ─────────────────────────────────────────
        # Add widgets to main layout
        # ─────────────────────────────────────────
        main_layout.addLayout(ref_layout)
        main_layout.addLayout(file_selection_layout)
        main_layout.addWidget(self.tree_widget)
        main_layout.addLayout(tree_buttons_layout)
        main_layout.addLayout(output_layout)
        main_layout.addWidget(self.progress_label)
        main_layout.addWidget(self.start_button)

    # ─────────────────────────────────────────
    # Slot/File Selection for Reference Image
    # ─────────────────────────────────────────
    def select_reference_from_slot(self):
        if self.image_manager:
            available_slots = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
            slot, ok = QInputDialog.getItem(self, "Select Reference Slot", "Choose a reference image slot:", list(available_slots.values()), 0, False)
            if ok:
                slot_index = list(available_slots.values()).index(slot)
                self.reference_image_path = f"Slot {slot_index}"
                self.ref_path_label.setText(self.reference_image_path)

    def select_reference_from_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if file_path:
            self.reference_image_path = file_path
            self.ref_path_label.setText(os.path.basename(file_path))

    # ─────────────────────────────────────────
    # File Selection for Alignment
    # ─────────────────────────────────────────
    def select_files_to_align(self):
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files to Align", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if files:
            for file in files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    def select_directory_to_align(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            supported_extensions = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.fits', '.fit', '.xisf')
            new_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith(supported_extensions)]
            for file in new_files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    # ─────────────────────────────────────────
    # Managing Files in TreeBox
    # ─────────────────────────────────────────
    def remove_selected_files(self):
        selected_items = self.tree_widget.selectedItems()
        for item in selected_items:
            file_name = item.text(0)
            for file_path in self.files_to_align:
                if os.path.basename(file_path) == file_name:
                    self.files_to_align.remove(file_path)
                    break
            index = self.tree_widget.indexOfTopLevelItem(item)
            self.tree_widget.takeTopLevelItem(index)

    def clear_tree(self):
        self.tree_widget.clear()
        self.files_to_align.clear()

    # ─────────────────────────────────────────
    # Output Directory Selection
    # ─────────────────────────────────────────
    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory", "")
        if directory:
            self.output_directory = directory
            self.output_path_label.setText(directory)

    # ─────────────────────────────────────────
    # Start Registration with Signal Handling
    # ─────────────────────────────────────────
    def start_registration(self):
        if not self.reference_image_path:
            QMessageBox.warning(self, "Missing Reference", "Please select a reference image before starting.")
            return
        if not self.files_to_align:
            QMessageBox.warning(self, "No Files", "Please add files to align before starting.")
            return
        if not self.output_directory:
            QMessageBox.warning(self, "No Output Directory", "Please select an output directory before starting.")
            return

        self.progress_label.setText("Status: Running...")
        self.progress_label.setStyleSheet("color: green; font-weight: bold;")

        self.thread = StarRegistrationThread(self.reference_image_path, self.files_to_align, self.output_directory)
        self.thread.progress_update.connect(self.update_progress)
        self.thread.registration_complete.connect(self.registration_finished)
        self.thread.start()

    def update_progress(self, message):
        """Update the progress label with the latest status."""
        self.progress_label.setText(f"Status: {message}")
        QApplication.processEvents()

    def registration_finished(self, success, message):
        """Handle the completion of the registration process."""
        color = "green" if success else "red"
        self.progress_label.setText(f"Status: {message}")
        self.progress_label.setStyleSheet(f"color: {color}; font-weight: bold;")

        if success:
            QMessageBox.information(self, "Registration Complete", message)
        else:
            QMessageBox.warning(self, "Registration Error", message)


class PlateSolver(QDialog):
    """
    A dialog class to handle plate solving.
    
    This class lets the user choose either an image file or a slot image,
    then attempts to run ASTAP on the image (if the ASTAP executable is available),
    falls back to astrometry.net if needed, and finally updates the image metadata/FITS header.
    """
    def __init__(self, settings: QSettings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Plate Solver")
        self.setMinimumWidth(400)
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        self.starnet_exe = self.settings.value("starnet/exe_path", "", type=str)
        self.debug_mode = False
        
        self.image_path = ""  # Will hold the selected image path
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # Instruction Label
        instr_label = QLabel("Select an image source for plate solving:")
        layout.addWidget(instr_label)
        
        # Selection mode combo box (Slot shown first by default)
        self.mode_combo = QComboBox()
        # Reorder items so that "Slot" is default.
        self.mode_combo.addItems(["Slot", "File"])
        self.mode_combo.currentIndexChanged.connect(self.change_mode)
        layout.addWidget(self.mode_combo)
        
        # Stacked widget to hold different UIs
        self.stacked = QStackedWidget()
        layout.addWidget(self.stacked)
        
        # Page 0: Slot selection UI
        slot_page = QWidget()
        slot_layout = QVBoxLayout(slot_page)
        slot_instr = QLabel("Select a slot from which to use the image:")
        slot_layout.addWidget(slot_instr)
        self.slot_combo = QComboBox()
        # Populate with slot names from parent if available
        if self.parent() and hasattr(self.parent(), "slot_names"):
            # Assume slot_names is a dict: {slot_index: "Slot N"}
            for index, name in self.parent().slot_names.items():
                self.slot_combo.addItem(name, index)
        else:
            self.slot_combo.addItems(["Slot 0", "Slot 1", "Slot 2"])
        slot_layout.addWidget(self.slot_combo)
        self.choose_slot_btn = QPushButton("Select Slot")
        self.choose_slot_btn.clicked.connect(self.choose_slot)
        slot_layout.addWidget(self.choose_slot_btn)
        self.slot_status_label = QLabel("No slot selected.")
        slot_layout.addWidget(self.slot_status_label)
        self.stacked.addWidget(slot_page)
        
        # Page 1: File selection UI
        file_page = QWidget()
        file_layout = QVBoxLayout(file_page)
        self.choose_file_btn = QPushButton("Choose Image File")
        self.choose_file_btn.clicked.connect(self.choose_file)
        file_layout.addWidget(self.choose_file_btn)
        self.file_status_label = QLabel("No file selected.")
        file_layout.addWidget(self.file_status_label)
        self.stacked.addWidget(file_page)

        # Add a dedicated status label for overall status messages.
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)        

        # Solve button
        self.solve_btn = QPushButton("Start Plate Solving")
        self.solve_btn.clicked.connect(self.start_plate_solving)
        layout.addWidget(self.solve_btn)

        # --- NEW: Batch Plate Solve button ---
        self.batch_solve_btn = QPushButton("Batch Plate Solve with ASTAP")
        self.batch_solve_btn.clicked.connect(self.openBatchPlateSolver)
        layout.addWidget(self.batch_solve_btn)        
        
        # Close button
        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.reject)
        layout.addWidget(close_btn)
        
        # Set the default mode to Slot (index 0)
        self.mode_combo.setCurrentIndex(0)
        self.stacked.setCurrentIndex(0)
        self.image_path = ""

    def openBatchPlateSolver(self):
        # Directly create an instance of BatchPlateSolverDialog
        dialog = BatchPlateSolverDialog(self.settings, parent=self)
        dialog.show()

    def change_mode(self, index):
        """Change the stacked widget page based on the selection mode."""
        self.stacked.setCurrentIndex(index)
        # Clear any previous selection status
        if index == 0:  # Slot mode
            self.slot_status_label.setText("No slot selected.")
            self.image_path = ""
        elif index == 1:  # File mode
            self.file_status_label.setText("No file selected.")
            self.image_path = ""

    def choose_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Image for Plate Solving",
            "", "Image Files (*.fit *.fits *.png *.tif *.tiff *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.image_path = file_path
            self.file_status_label.setText(f"Selected: {os.path.basename(file_path)}")
        else:
            self.file_status_label.setText("No file selected.")

    def choose_slot(self):
        """Select an image from a slot."""
        # Check if parent's image_manager is available
        if not (self.parent() and hasattr(self.parent(), "image_manager")):
            QMessageBox.warning(self, "Slot Selection", "Slot images are not available.")
            return

        slot_index = self.slot_combo.currentData()
        img_manager = self.parent().image_manager
        image = img_manager._images.get(slot_index, None)

        # Check if there is image data in the slot.
        if image is not None and hasattr(image, "size") and image.size > 0:
            metadata = img_manager._metadata.get(slot_index, {})
            # Set flag to indicate that we're using slot data.
            self._from_slot = True
            # Use the stored file path if available; otherwise, store a dummy value.
            if "file_path" in metadata and metadata["file_path"]:
                self.image_path = metadata["file_path"]
            else:
                self.image_path = f"slot:{slot_index}"
            self.slot_status_label.setText(
                f"Selected: {self.parent().slot_names.get(slot_index, f'Slot {slot_index}')}"
            )
            # Save slot metadata for later merging.
            self._slot_meta = metadata
        else:
            self.slot_status_label.setText("No image in the selected slot.")
            QMessageBox.warning(self, "Slot Selection", "No image available in the selected slot.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def start_plate_solving(self):
        if not self.image_path:
            QMessageBox.warning(self, "Plate Solver", "Please select an image source first.")
            return

        # Determine the appropriate filter for the ASTAP executable.
        if sys.platform.startswith("win"):
            executable_filter = "Executables (*.exe);;All Files (*)"
        else:
            executable_filter = "Executables (astap);;All Files (*)"

        # Check if ASTAP path is set and valid.
        if not self.astap_exe or not os.path.exists(self.astap_exe):
            # Prompt the user to locate the ASTAP executable.
            new_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select ASTAP Executable",
                "",
                executable_filter
            )
            if new_path:
                self.astap_exe = new_path
                # Save the new ASTAP path in settings.
                self.settings.setValue("astap/exe_path", self.astap_exe)
                QMessageBox.information(self, "Plate Solver", "ASTAP path updated successfully.")
            else:
                # If no ASTAP is provided, skip directly to blind solving via astrometry.net.
                QMessageBox.information(self, "Plate Solver", "ASTAP executable not provided; falling back to astrometry.net blind solve.")
                solved = self.run_astrometry_net(self.image_path)
                if solved:
                    QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
                    self.update_metadata()
                    self.accept()
                else:
                    QMessageBox.critical(self, "Plate Solve", "Plate solve failed with astrometry.net.")
                return

        # Try ASTAP first.
        self.update_status("Running ASTAP plate solving...")
        solved = self.run_astap(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using ASTAP!")
            self.accept()
            return
        else:
            QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Trying astrometry.net...")

        # Fall back to astrometry.net.
        solved = self.run_astrometry_net(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
            self.update_metadata()
            self.accept()
        else:
            QMessageBox.critical(self, "Plate Solve", "Plate solve failed with both ASTAP and astrometry.net.")

    def update_status(self, message: str):
        """Update the status label on the current page."""
        index = self.stacked.currentIndex()
        if index == 0:
            self.file_status_label.setText(message)
        else:
            self.slot_status_label.setText(message)

    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def run_astap(self, image_path: str, update_manager=True) -> bool:
        """
        Loads the image data and metadata based on the user's selection:
        - If the user selected a slot (self._from_slot is True), retrieve the image and metadata
            from the ImageManager.
        - Otherwise, use the global load_image() method to load from a file.
        
        The image is normalized using stretch_image(), saved as a temporary FITS file (via
        save_temp_fits_image()), and ASTAP is run on that temporary file.
        
        If ASTAP is successful, the updated (solved) header is retrieved and:
        1. The metadata dictionary for the current slot is updated with the solved header.
        2. If the image was loaded from file (i.e. not a slot) and is a FITS file, the original
            file is updated with the new header.
        3. The user is prompted to save a new FITS file with the solved header.
        
        Returns True if ASTAP exits with exit code 0.
        """
        if getattr(self, "debug_mode", False):
            print("DEBUG MODE: Skipping ASTAP processing.")
            return False
        # --- Load image data and header ---
        if getattr(self, "_from_slot", False):
            # Use data from the ImageManager.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
                if image_data is None:
                    print("No image data found in the selected slot.")
                    return False
                original_header = meta.get("original_header", meta)
                # Save slot metadata for later merging.
                self._slot_meta = meta
                print("Using image data and metadata from slot.")
            else:
                print("No ImageManager found in parent!")
                return False
        else:
            # Load from file using the global load_image() method.
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False
            print("Loaded image data and header from file.")

        # Keep a copy of the original image data (unsqueezed) for saving the new FITS.
        original_image_data = image_data.copy()

        image_data = image_data.astype(np.float32)

        # --- Normalize the image ---
        normalized_image = self.stretch_image(image_data)

        # --- Save normalized image to a temporary FITS file ---
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, image_path)
        except Exception as e:
            print("Failed to save temporary FITS file:", e)
            return False

        # --- Run ASTAP on the temporary file ---
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            return False
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return False

        # --- Retrieve updated header data from the temporary file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Regular expression to match a FITS header keyword and its value.
                    # It assumes a format like: KEY  =  value / comment
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)        
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2: ideally provided by ASTAP's INI file.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Ensure required WCS keys are present with proper numeric types ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # Convert the value to float. If it's meant to be an integer (like WCSAXES),
                    # you can use int(float(...)) if needed.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Compute CROTA1 and CROTA2 if not present ---
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                print(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                print("CD matrix elements not available; cannot compute CROTA values.")


        print("Final solved header to be used:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        # --- Directly update the metadata dictionary for the current slot ---
        if update_manager:
            if self.parent() and hasattr(self.parent(), "image_manager"):
                try:
                    current_slot = self.parent().image_manager.current_slot
                    self.parent().image_manager._metadata[current_slot].update(solved_header)
                    print("ImageManager metadata for slot", current_slot, "updated with solved header.")
                except Exception as e:
                    print("Error updating ImageManager metadata with solved data:", e)
                    return False
            else:
                print("No parent ImageManager found; cannot update solved metadata.")
                return False
        else:
            print("Batch mode: Skipping image manager metadata update.")

        # --- If the image was loaded from file (not a slot) and is a FITS file, update that file with the new header ---
        if not getattr(self, "_from_slot", False) and image_path.lower().endswith((".fits", ".fit")):
            try:
                with fits.open(image_path, mode="update", memmap=False) as hdul:
                    hdr = hdul[0].header
                    # Remove problematic keys before updating.
                    solved_header.pop("COMMENT", None)
                    solved_header.pop("HISTORY", None)
                    for key, value in solved_header.items():
                        hdr[key] = value
                    hdul.flush()
                print("Original FITS file updated with solved header (inline).")
            except Exception as e:
                print("Error updating original FITS file with solved header:", e)
                # Optionally, do not treat this as fatal.

        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                # Determine if the image is mono.
                if original_image_data.ndim == 2 or (original_image_data.ndim == 3 and original_image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False

                # If mono, expand it to 3-channel
                if is_mono:
                    original_image_data = np.stack([original_image_data] * 3, axis=-1)  # Convert to RGB-equivalent format
                    is_mono = False  # Mark as non-mono since we expanded it

                if "file_path" in solved_header:
                    del solved_header["file_path"]                    
                # Save the original image data with the solved header.

                # Print the final header before saving
                print("\n✅ FINAL HEADER BEFORE SAVING:")
                for key, value in solved_header.items():
                    print(f"{key} = {value}")                
                save_image(
                    img_array=original_image_data,
                    filename=save_path,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
            # --- Prompt the user to open the newly saved FITS file ---
            reply = QMessageBox.question(
                self, 
                "Open Plate Solved FITS?", 
                "Do you want to open the newly saved plate-solved FITS file?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if reply == QMessageBox.StandardButton.Yes:
                try:
                    # Load the newly saved FITS file using the global load_image() method.
                    new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                    if new_image is None:
                        QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                    else:
                        # Build a metadata dictionary as in your AstroEditingSuite.
                        metadata = {
                            'file_path': save_path,
                            'original_header': new_header,
                            'bit_depth': new_bit_depth,
                            'is_mono': new_is_mono
                        }
                        # Add the new image and metadata to the ImageManager in the current slot.
                        self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                        print("Plate-solved FITS image loaded and added to ImageManager.")
                except Exception as e:
                    print("Error loading plate-solved FITS file:", e)
                    QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
            else:
                print("User chose not to open the plate-solved FITS file.")
                    
        # --- Clean up temporary files ---
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            print("Error removing INI file:", e)

        return True

    def run_astrometry_net(self, image_path: str):
        """
        Performs a blind solve via Astrometry.net following these steps:
        1. Log in to Astrometry.net using an API key.
        2. Upload the image (converting it to FITS if necessary).
        3. Poll for a job ID.
        4. Poll for calibration data.
        5. Construct a WCS header from the calibration data.
        6. If the image was originally FITS, update that file with the new header.
        7. Store the WCS in the item dictionary.
        
        Returns the constructed WCS header (a FITS Header) on success, or False on failure.
        """
        # Build an item dictionary from the image data.
        if getattr(self, "_from_slot", False):
            # Retrieve from ImageManager.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
                if image_data is None:
                    print("No image data found in the selected slot.")
                    return False
                original_header = meta.get("original_header", meta)
                item = {
                    "path": meta.get("file_path", image_path),
                    "image": image_data,
                    "is_mono": meta.get("is_mono", False)
                }
                self._slot_meta = meta  # Save slot metadata for later merging.
                print("Using image data and metadata from slot for blind solve.")
            else:
                print("No ImageManager found in parent!")
                return False
        else:
            # Load from file using load_image().
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False
            item = {
                "path": image_path,
                "image": image_data,
                "is_mono": is_mono
            }
            print("Loaded image data and header from file for blind solve.")

        # --- Begin blind solve loop ---
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return False

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine file extension.
            ext = os.path.splitext(item["path"])[1].lower()
            if ext not in ('.fits', '.fit'):
                # Convert non-FITS image to a temporary FITS file.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close so save_image can write.
                try:
                    minimal_header = generate_minimal_fits_header(item["image"])
                    save_image(
                        img_array=item["image"],
                        filename=temp_file.name,
                        original_format="fit",
                        bit_depth="16-bit",
                        original_header=minimal_header,
                        is_mono=item.get("is_mono", False)
                    )
                except Exception as e:
                    QMessageBox.critical(self, "Conversion Error", f"Failed to convert image to FITS:\n{e}")
                    return False
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            # If a temporary file was created (for non-FITS images), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)
            break  # Exit loop once all steps succeed.

        # --- Construct the WCS header ---
        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        # Store the WCS in the item.
        item["wcs"] = WCS(wcs_header)

        # --- (Optional) Update the metadata of the slot if applicable ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in wcs_header and "file_path" in self._slot_meta:
                wcs_header["file_path"] = self._slot_meta["file_path"]
            # Directly update the metadata dictionary for the current slot.
            self.parent().image_manager._metadata[self.parent().image_manager.current_slot].update(wcs_header)
            print("ImageManager metadata for current slot updated with solved header.")

        # --- Now prompt the user to save the new plate-solved FITS file ---
        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False
                # Save the original (unsqueezed) image data with the solved header.
                save_image(
                    img_array=image_data,
                    filename=save_path,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=wcs_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
        else:
            print("User cancelled saving the plate-solved FITS file.")

        # --- Prompt the user to open the new plate-solved FITS file ---
        reply = QMessageBox.question(
            self,
            "Open Plate Solved FITS?",
            "Do you want to open the newly saved plate-solved FITS file?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            try:
                new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                if new_image is None:
                    QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                else:
                    metadata = {
                        'file_path': save_path,
                        'original_header': new_header,
                        'bit_depth': new_bit_depth,
                        'is_mono': new_is_mono
                    }
                    self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                    print("Plate-solved FITS image loaded and added to ImageManager.")
            except Exception as e:
                print("Error loading plate-solved FITS file:", e)
                QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
        else:
            print("User chose not to open the plate-solved FITS file.")

        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    def update_metadata(self):
        """
        Placeholder method to update the metadata or FITS header
        with the plate solving results.
        Extend this method to:
          - Read the .wcs or .ini output files from the plate solver
          - Update the image metadata accordingly.
        """
        print("Updating metadata/FITS header... (this is a placeholder)")
        # TODO: Implement metadata update logic here.

class BatchPlateSolverDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Batch Plate Solve")
        self.setMinimumWidth(500)
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        self.inputDirLineEdit = QLineEdit()
        self.outputDirLineEdit = QLineEdit()
        inputBrowseButton = QPushButton("Browse Input Directory")
        outputBrowseButton = QPushButton("Browse Output Directory")
        self.startButton = QPushButton("Start Batch Plate Solve")
        self.statusTextEdit = QTextEdit()
        self.statusTextEdit.setReadOnly(True)
        
        layout.addWidget(QLabel("Input Directory:"))
        layout.addWidget(self.inputDirLineEdit)
        layout.addWidget(inputBrowseButton)
        layout.addWidget(QLabel("Output Directory:"))
        layout.addWidget(self.outputDirLineEdit)
        layout.addWidget(outputBrowseButton)
        layout.addWidget(self.startButton)
        layout.addWidget(QLabel("Status:"))
        layout.addWidget(self.statusTextEdit)
        
        inputBrowseButton.clicked.connect(self.browseInputDir)
        outputBrowseButton.clicked.connect(self.browseOutputDir)
        self.startButton.clicked.connect(self.startBatchPlateSolve)
        
    def browseInputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.inputDirLineEdit.setText(directory)
        
    def browseOutputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.outputDirLineEdit.setText(directory)
            
    def logStatus(self, message):
        self.statusTextEdit.append(message)
        QApplication.processEvents()
        
    def run_astap_batch(self, image_path: str):
        """
        Batch-mode version of ASTAP processing.
        This method loads an image, normalizes it, saves a temporary FITS file,
        runs ASTAP, retrieves the solved header, and returns it.
        It does not update any ImageManager or prompt the user.
        """
        # Load image from file
        image_data, original_header, bit_depth, is_mono = load_image(image_path)
        if image_data is None:
            self.logStatus(f"Failed to load image from file: {image_path}")
            return False

        # Keep a copy of original image data if needed later.
        original_image_data = image_data.copy()

        image_data = image_data.astype(np.float32)
        # Normalize image (using your existing stretch_image method)
        normalized_image = image_data

        # Save temporary FITS file
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, image_path)
        except Exception as e:
            self.logStatus(f"Failed to save temporary FITS file: {e}")
            return False

        # Run ASTAP on temporary file
        astap_exe = self.settings.value("astap/exe_path", "", type=str)
        if not astap_exe or not os.path.exists(astap_exe):
            self.logStatus("ASTAP executable not found.")
            return False

        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        self.logStatus(f"Running ASTAP with arguments: {args}")
        process.start(astap_exe, args)
        if not process.waitForStarted(5000):
            self.logStatus("Failed to start ASTAP process: " + process.errorString())
            return False
        if not process.waitForFinished(300000):
            self.logStatus("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        self.logStatus(f"ASTAP exit code: {exit_code}")
        self.logStatus("ASTAP STDOUT: " + stdout)
        self.logStatus("ASTAP STDERR: " + stderr)
        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                self.logStatus("Error removing temporary file: " + str(e))
            return False

        # Retrieve solved header from temporary FITS file
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            self.logStatus("Initial solved header retrieved:")
            for key, value in solved_header.items():
                self.logStatus(f"{key} = {value}")
        except Exception as e:
            self.logStatus("Error reading solved header after ASTAP: " + str(e))
            return False

        # Check for a corresponding .wcs file and merge its header if present.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                self.logStatus("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    self.logStatus(f"{key} = {value}")
                solved_header.update(wcs_header)
            except Exception as e:
                self.logStatus("Error reading .wcs file: " + str(e))
        else:
            self.logStatus("No .wcs file found; using header from temporary FITS.")

        # Add missing required keys
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                self.logStatus(f"Added missing key {key} with default value {default}.")

        # Convert expected numeric keys
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    self.logStatus(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # Compute CROTA1 and CROTA2 if missing
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                self.logStatus(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                self.logStatus("CD matrix elements not available; cannot compute CROTA values.")

        self.logStatus("Final solved header:")
        for key, value in solved_header.items():
            self.logStatus(f"{key} = {value}")

        try:
            os.remove(tmp_path)
        except Exception as e:
            self.logStatus("Error removing temporary file: " + str(e))
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            self.logStatus("Error removing .wcs file: " + str(e))
        return solved_header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            # In single-image mode, an ImageManager might be available.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                original_header = meta.get("original_header", None)
            else:
                # In batch mode, no ImageManager is available; try reading the header directly.
                try:
                    with fits.open(image_path, memmap=False) as hdul:
                        original_header = dict(hdul[0].header)
                    print("Original FITS header loaded from file.")
                except Exception as e:
                    print("Failed to load header from FITS file; creating a minimal header. Error:", e)
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header


    def startBatchPlateSolve(self):
        inputDir = self.inputDirLineEdit.text().strip()
        outputDir = self.outputDirLineEdit.text().strip()
        if not inputDir or not outputDir:
            QMessageBox.warning(self, "Missing Directories", "Please select both input and output directories.")
            return
        
        acceptable_exts = ['.xisf', '.fits', '.fit', '.tif', '.tiff', '.png', '.jpg', '.jpeg']
        files = [os.path.join(inputDir, f) for f in os.listdir(inputDir)
                 if os.path.splitext(f)[1].lower() in acceptable_exts]
        
        if not files:
            QMessageBox.information(self, "No Files", "No acceptable image files found in the input directory.")
            return
        
        self.logStatus(f"Found {len(files)} files. Starting batch processing...")
        
        for file in files:
            self.logStatus(f"Processing: {file}")
            try:
                # Load image data
                image_data, original_header, bit_depth, is_mono = load_image(file)
                if image_data is None:
                    self.logStatus(f"Failed to load image: {file}")
                    continue

                # Run our batch ASTAP routine (which does not update the ImageManager)
                solved_header = self.run_astap_batch(file)
                if not solved_header:
                    self.logStatus(f"Plate solving failed for: {file}")
                    continue
                
                base_name = os.path.splitext(os.path.basename(file))[0]
                output_file = os.path.join(outputDir, base_name + "_plate_solved.fits")
                
                # Save the image with the solved header
                save_image(
                    img_array=image_data,
                    filename=output_file,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                self.logStatus(f"Saved plate-solved image to: {output_file}")
            except Exception as e:
                self.logStatus(f"Error processing {file}: {e}")
        
        self.logStatus("Batch plate solving completed.")


class PSFViewer(QDialog):
    def __init__(self, image, parent=None):
        """
        Initialize the PSF Viewer dialog using SEP for star detection.
        """
        super().__init__(parent)
        self.setWindowTitle("PSF Viewer")
        self.image = image
        self.zoom_factor = 1.0
        self.log_scale = False
        self.star_catalog = None
        self.histogram_mode = 'PSF'  # Can be toggled later
        self.initUI()
        QTimer.singleShot(0, self.compute_star_catalog)
        # Compute the star catalog using SEP (one-pass detection).
        
        
        

    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Top layout holds the histogram display and the statistics table.
        top_layout = QHBoxLayout()

        # Scroll area for histogram.
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)

        # Statistics table (4 rows: Min, Max, Median, StdDev).
        self.stats_table = QTableWidget(self)
        self.stats_table.setRowCount(4)
        # We'll update the number of columns later based on available data.
        self.stats_table.setColumnCount(1)
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)

        main_layout.addLayout(top_layout)

        # Add a status label to show extraction progress.
        self.status_label = QLabel("Status: Ready", self)
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout.addWidget(self.status_label)
        # Controls layout: Zoom slider, Log scale toggle, and a histogram mode toggle.
        controls_layout = QHBoxLayout()
        
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)  # 50% to 1000%
        self.zoom_slider.setValue(100)       # Default: 100%
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(QLabel("Zoom:"))
        controls_layout.addWidget(self.zoom_slider)
        
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis scaling.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)
        
        # Button to switch between PSF and Flux histograms.
        self.mode_toggle_button = QPushButton("Show Flux Histogram", self)
        self.mode_toggle_button.setToolTip("Switch between PSF (FWHM) and Flux histograms.")
        self.mode_toggle_button.clicked.connect(self.toggleHistogramMode)
        controls_layout.addWidget(self.mode_toggle_button)
        
        main_layout.addLayout(controls_layout)
        
        # Close button.
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        
        # Draw initial histogram.
        self.drawHistogram()
        QApplication.processEvents()

        


    def updateImage(self, new_image):
        """
        Update the current image, recompute the star catalog using SEP,
        and redraw the histogram.
        """
        self.image = new_image
        self.compute_star_catalog()
        self.drawHistogram()

    def compute_star_catalog(self):
        """
        Use SEP to detect stars in one pass.
        This subtracts the background and extracts sources.
        We approximate the effective FWHM as 2 * a (where 'a' is the semi-major axis
        returned by SEP). Other parameters (flux, x, y, etc.) are recorded in the star catalog.
        """
        # Convert image to grayscale if necessary.
        if self.image.ndim == 3:
            image_gray = np.mean(self.image, axis=2)
        else:
            image_gray = self.image

        # SEP requires a float32 array.
        data = image_gray.astype(np.float32)
        
        # Estimate background.
        bkg = sep.Background(data)
        data_sub = data - bkg.back()
        threshold = 3  # Adjust this threshold as needed.
        
        # Extract sources.
        # Run SEP extraction.
        try:
            err_val = bkg.globalrms  # globalrms should be a scalar.
        except Exception as e:
            err_val = np.median(bkg.rms())
        
        # Update status message before extraction.
        self.status_label.setText("Status: Starting Stellar extraction...")
        QApplication.processEvents()

        try:
            sources = sep.extract(data_sub, threshold, err=err_val)
            n_sources = len(sources) if sources is not None else 0
            self.status_label.setText(f"Status: Extraction Completed. Detected {n_sources} objects.")
        except Exception as e:
            self.status_label.setText(f"Status: Extraction Failed: {e}")
            sources = None

        QApplication.processEvents()

        
        if sources is None or len(sources) == 0:
            self.star_catalog = None
            return

        # Define an effective FWHM. Here we use 2*a, so that HFR = a.
        # Now compute the flux radius (HFR) for a flux fraction of 0.5.
        # Use an aperture of 6 * a as recommended.
        try:
            r, flag = sep.flux_radius(data, sources['x'], sources['y'], 6.0 * sources['a'],
                                    0.5, normflux=sources['flux'], subpix=5)
        except Exception as e:
            self.status_label.setText(f"Status: Flux radius computation failed: {e}")
            r = np.zeros(len(sources))
        r = 2*sources['a']
        # Build an Astropy Table for the star catalog.
        from astropy.table import Table
        star_catalog = Table()
        star_catalog['xcentroid'] = sources['x']
        star_catalog['ycentroid'] = sources['y']
        star_catalog['flux'] = sources['flux']
        star_catalog['HFR'] = r  # Use the computed flux radius as HFR.
        star_catalog['a'] = sources['a']
        star_catalog['b'] = sources['b']
        star_catalog['theta'] = sources['theta']

        self.star_catalog = star_catalog
        self.drawHistogram()
        QApplication.processEvents()

    def updateZoom(self, value):
        self.zoom_factor = value / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked):
        self.log_scale = checked
        self.drawHistogram()

    def toggleHistogramMode(self):
        """
        Toggle between displaying a histogram of PSF (FWHM used) values and flux values.
        """
        if self.histogram_mode == 'PSF':
            self.histogram_mode = 'Flux'
            self.mode_toggle_button.setText("Show PSF Histogram")
        else:
            self.histogram_mode = 'PSF'
            self.mode_toggle_button.setText("Show Flux Histogram")
        self.drawHistogram()

    def drawHistogram(self):
        """
        Draw the histogram of either PSF (FWHM used) or flux values from the star catalog.
        """
        # Create a pixmap for drawing.
        base_width = 512
        height = 300
        width = int(base_width * self.zoom_factor)
        pixmap = QPixmap(width, height)
        pixmap.fill(Qt.GlobalColor.white)
        painter = QPainter(pixmap)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        bin_count = 50  # Adjust number of bins as desired.
        
        # Determine the data to histogram.
        if self.star_catalog is None or len(self.star_catalog) == 0:
            data = np.array([])
            bin_edges = np.linspace(0, 1, bin_count + 1)
        else:
            if self.histogram_mode == 'PSF':
                # Use HFR (Half Flux Radius) by dividing the fwhm_used values by 2.
                data = np.array(self.star_catalog['HFR'], dtype=float)
                # With FWHM up to 15, HFR could be up to 7.5.
                bin_edges = np.linspace(0, 7.5, bin_count + 1)
            else:
                # Use the 'flux' column.
                data = np.array(self.star_catalog['flux'])
                if data.size > 0:
                    bin_edges = np.linspace(data.min(), data.max(), bin_count + 1)
                else:
                    bin_edges = np.linspace(0, 1, bin_count + 1)
        
        # Adjust bin edges for log scale if needed.
        if self.log_scale:
            eps = 1e-4
            lower = max(bin_edges[0], eps)
            upper = bin_edges[-1]
            bin_edges = np.logspace(np.log10(lower), np.log10(upper), bin_count + 1)
            def x_pos(val):
                return int((np.log10(val) - np.log10(lower)) / (np.log10(upper) - np.log10(lower)) * width)
        else:
            def x_pos(val):
                return int((val - bin_edges[0]) / (bin_edges[-1] - bin_edges[0]) * width)
        
        # Compute histogram counts.
        if data.size > 0:
            hist, _ = np.histogram(data, bins=bin_edges)
            if hist.max() > 0:
                hist = hist.astype(np.float32) / hist.max()
            else:
                hist = hist.astype(np.float32)
        else:
            hist = np.zeros(bin_count)
        
        # Draw histogram bars.
        painter.setPen(QPen(Qt.GlobalColor.black))
        for i in range(bin_count):
            x0 = x_pos(bin_edges[i])
            x1 = x_pos(bin_edges[i+1])
            bar_width = max(x1 - x0, 1)
            bar_height = hist[i] * height
            painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        
        # Draw x-axis.
        painter.setPen(QPen(Qt.GlobalColor.black, 2))
        painter.drawLine(0, height - 1, width, height - 1)
        
        # Draw tick marks and labels.
        painter.setFont(QFont("Arial", 10))
        if self.log_scale:
            tick_values = np.logspace(np.log10(bin_edges[0]), np.log10(bin_edges[-1]), 6)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 15, height - 10, f"{tick:.3f}")
        else:
            tick_values = np.linspace(bin_edges[0], bin_edges[-1], 6)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 15, height - 10, f"{tick:.2f}")
        
        painter.end()
        self.hist_label.setPixmap(pixmap)
        self.hist_label.resize(pixmap.size())
        
        # Update the statistics table.
        self.updateStatistics()

    def updateStatistics(self):
        """
        Compute and update summary statistics (Min, Max, Median, StdDev) for the following columns in the star catalog:
        HFR, eccentricity, a, b, theta, flux.
        Eccentricity is computed as sqrt(1 - (b/a)**2).
        """
        if self.star_catalog is None or len(self.star_catalog) == 0:
            colnames = []
        else:
            # Our desired column order.
            desired_cols = ['HFR', 'eccentricity', 'a', 'b', 'theta', 'flux']
            # We'll only include columns that exist (eccentricity is computed).
            colnames = [col for col in desired_cols if col in self.star_catalog.colnames or col == 'eccentricity']

            # Compute eccentricity from 'a' and 'b'
            try:
                a = np.array(self.star_catalog['a'], dtype=float)
                b = np.array(self.star_catalog['b'], dtype=float)
                # Avoid division by zero:
                with np.errstate(divide='ignore', invalid='ignore'):
                    ecc = np.sqrt(1.0 - (b / a) ** 2)
                # Replace any NaNs with zero.
                ecc = np.nan_to_num(ecc)
            except Exception:
                ecc = np.zeros(len(self.star_catalog))

        self.stats_table.setColumnCount(len(colnames))
        self.stats_table.setHorizontalHeaderLabels(colnames)
        self.stats_table.setRowCount(4)
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])

        # Loop over each desired column.
        for col_index, col in enumerate(colnames):
            try:
                if col == 'eccentricity':
                    col_data = ecc
                else:
                    col_data = np.array(self.star_catalog[col], dtype=float)
                min_val = np.min(col_data)
                max_val = np.max(col_data)
                med_val = np.median(col_data)
                std_val = np.std(col_data)
            except Exception:
                min_val = max_val = med_val = std_val = 0.0

            for row_index, val in enumerate([min_val, max_val, med_val, std_val]):
                item = QTableWidgetItem(f"{val:.3f}")
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(row_index, col_index, item)


class SupernovaAsteroidHunterTab(QWidget):
    def __init__(self):
        super().__init__()
        # Parameters for the hunter
        self.parameters = {
            "referenceImagePath": "",
            "searchImagePaths": [],
            "threshold": 0.10  # Default threshold value
        }
        # Preprocessed images will be stored here
        self.preprocessed_reference = None
        self.preprocessed_search = []  # List of dicts: {"path": str, "image": np.array}
        # Detected anomaly data for each search image
        self.anomalyData = []
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # Instruction Label
        instructions = QLabel("Select the reference image and search images. Then click Process to hunt for anomalies.")
        layout.addWidget(instructions)

        # --- Reference Image Selection ---
        ref_layout = QHBoxLayout()
        self.ref_line_edit = QLineEdit(self)
        self.ref_line_edit.setPlaceholderText("No reference image selected")
        self.ref_button = QPushButton("Select Reference Image", self)
        self.ref_button.clicked.connect(self.selectReferenceImage)
        ref_layout.addWidget(self.ref_line_edit)
        ref_layout.addWidget(self.ref_button)
        layout.addLayout(ref_layout)

        # --- Search Images Selection ---
        search_layout = QHBoxLayout()
        self.search_list = QListWidget(self)
        self.search_button = QPushButton("Select Search Images", self)
        self.search_button.clicked.connect(self.selectSearchImages)
        search_layout.addWidget(self.search_list)
        search_layout.addWidget(self.search_button)
        layout.addLayout(search_layout)

        # --- Cosmetic Correction Checkbox ---
        self.cosmetic_checkbox = QCheckBox("Apply Cosmetic Correction before Preprocessing", self)
        layout.addWidget(self.cosmetic_checkbox)

        # --- Threshold Slider ---
        thresh_layout = QHBoxLayout()
        self.thresh_label = QLabel("Anomaly Detection Threshold: 0.10", self)
        self.thresh_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.thresh_slider.setMinimum(1)
        self.thresh_slider.setMaximum(50)  # Represents 0.01 to 0.50
        self.thresh_slider.setValue(10)      # 10 => 0.10 threshold
        self.thresh_slider.valueChanged.connect(self.updateThreshold)
        thresh_layout.addWidget(self.thresh_label)
        thresh_layout.addWidget(self.thresh_slider)
        layout.addLayout(thresh_layout)

        # --- Process Button ---
        self.process_button = QPushButton("Process (Cosmetic Correction, Preprocess, and Search)", self)
        self.process_button.clicked.connect(self.process)
        layout.addWidget(self.process_button)

        # --- Progress Labels ---
        self.preprocess_progress_label = QLabel("Preprocessing progress: 0 / 0", self)
        self.search_progress_label = QLabel("Processing progress: 0 / 0", self)
        layout.addWidget(self.preprocess_progress_label)
        layout.addWidget(self.search_progress_label)

        # -- Add a new status label --
        self.status_label = QLabel("Status: Idle", self)
        layout.addWidget(self.status_label)

        # --- New Instance Button ---
        self.new_instance_button = QPushButton("New Instance", self)
        self.new_instance_button.clicked.connect(self.newInstance)
        layout.addWidget(self.new_instance_button)

        self.setLayout(layout)
        self.setWindowTitle("Supernova/Asteroid Hunter")

    def updateThreshold(self, value):
        threshold = value / 100.0  # e.g. slider value 10 becomes 0.10
        self.parameters["threshold"] = threshold
        self.thresh_label.setText(f"Anomaly Detection Threshold: {threshold:.2f}")

    def selectReferenceImage(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "",
                                                   "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_path:
            self.parameters["referenceImagePath"] = file_path
            self.ref_line_edit.setText(os.path.basename(file_path))

    def selectSearchImages(self):
        file_paths, _ = QFileDialog.getOpenFileNames(self, "Select Search Images", "",
                                                     "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_paths:
            self.parameters["searchImagePaths"] = file_paths
            self.search_list.clear()
            for path in file_paths:
                self.search_list.addItem(os.path.basename(path))

    def process(self):
        self.status_label.setText("Process started...")
        QApplication.processEvents()

        # If cosmetic correction is enabled, run it first
        if self.cosmetic_checkbox.isChecked():
            self.status_label.setText("Running Cosmetic Correction...")
            QApplication.processEvents()
            self.runCosmeticCorrectionIfNeeded()

        self.status_label.setText("Preprocessing images...")
        QApplication.processEvents()
        self.preprocessImages()

        self.status_label.setText("Analyzing anomalies...")
        QApplication.processEvents()
        self.runSearch()

        self.status_label.setText("Process complete.")
        QApplication.processEvents()


    def runCosmeticCorrectionIfNeeded(self):
        """
        Runs cosmetic correction on each search image...
        """
        # Dictionary to hold corrected images
        self.cosmetic_images = {}

        for idx, image_path in enumerate(self.parameters["searchImagePaths"]):
            try:
                # Update status label to show which image is being handled
                self.status_label.setText(f"Cosmetic Correction: {idx+1}/{len(self.parameters['searchImagePaths'])} => {os.path.basename(image_path)}")
                QApplication.processEvents()

                img, header, bit_depth, is_mono = load_image(image_path)
                if img is None:
                    print(f"Unable to load image: {image_path}")
                    continue

                # Numba correction
                corrected = bulk_cosmetic_correction_numba(
                    img,
                    hot_sigma=5.0,
                    cold_sigma=5.0,
                    window_size=3
                )
                self.cosmetic_images[image_path] = corrected
                print(f"Cosmetic correction (Numba) applied to: {image_path}")

            except Exception as e:
                print(f"Error in cosmetic correction for {image_path}: {e}")


    def preprocessImages(self):
        # Update status label for reference image
        self.status_label.setText("Preprocessing reference image...")
        QApplication.processEvents()

        ref_path = self.parameters["referenceImagePath"]
        if not ref_path:
            QMessageBox.warning(self, "Error", "No reference image selected.")
            return

        try:
            ref_img, header, bit_depth, is_mono = load_image(ref_path)

            # Create a debug prefix from the reference path (e.g. "C:/data/ref_debug")
            debug_prefix_ref = os.path.splitext(ref_path)[0] + "_debug_ref"

            self.status_label.setText("Applying background neutralization & ABE on reference...")
            QApplication.processEvents()

            # Pass debug_prefix_ref to preprocessImage
            ref_processed = self.preprocessImage(ref_img, debug_prefix=debug_prefix_ref)
            self.preprocessed_reference = ref_processed
            self.preprocess_progress_label.setText("Preprocessing reference image... Done.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to preprocess reference image: {e}")
            return

        self.preprocessed_search = []
        search_paths = self.parameters["searchImagePaths"]
        for i, path in enumerate(search_paths):
            try:
                self.status_label.setText(f"Preprocessing search image {i+1}/{len(search_paths)} => {os.path.basename(path)}")
                QApplication.processEvents()

                # Create a debug prefix from the search path
                debug_prefix_search = os.path.splitext(path)[0] + f"_debug_search_{i+1}"

                if hasattr(self, 'cosmetic_images') and path in self.cosmetic_images:
                    img = self.cosmetic_images[path]
                else:
                    img, header, bit_depth, is_mono = load_image(path)

                # Pass debug_prefix_search to preprocessImage
                processed = self.preprocessImage(img, debug_prefix=debug_prefix_search)
                self.preprocessed_search.append({"path": path, "image": processed})

                self.preprocess_progress_label.setText(f"Preprocessing image {i+1} of {len(search_paths)}... Done.")
                QApplication.processEvents()

            except Exception as e:
                print(f"Failed to preprocess {path}: {e}")

        self.status_label.setText("All search images preprocessed.")
        QApplication.processEvents()



    def preprocessImage(self, img, debug_prefix=None):
        """
        Runs the full preprocessing chain on a single image:
        1. Background Neutralization
        2. Automatic Background Extraction (ABE)
        3. Pixel-math stretching

        Optionally saves debug images if debug_prefix is provided.
        """


        # --- Step 1: Background Neutralization ---
        if img.ndim == 3 and img.shape[2] == 3:
            h, w, _ = img.shape
            sample_x = int(w * 0.45)
            sample_y = int(h * 0.45)
            sample_w = max(1, int(w * 0.1))
            sample_h = max(1, int(h * 0.1))
            sample_region = img[sample_y:sample_y+sample_h, sample_x:sample_x+sample_w, :]
            medians = np.median(sample_region, axis=(0, 1))
            average_median = np.mean(medians)
            neutralized = img.copy()
            for c in range(3):
                diff = medians[c] - average_median
                numerator = neutralized[:, :, c] - diff
                denominator = 1.0 - diff
                if abs(denominator) < 1e-8:
                    denominator = 1e-8
                neutralized[:, :, c] = np.clip(numerator / denominator, 0, 1)
        else:
            neutralized = img


        # --- Step 2: Automatic Background Extraction (ABE) ---
        pgr = PolyGradientRemoval(
            neutralized,
            poly_degree=2,          # or pass in a user choice
            downsample_scale=4,
            num_sample_points=100
        )
        abe = pgr.process()  # returns final polynomial-corrected image in original domain


        # --- Step 3: Pixel Math Stretch ---
        stretched = self.pixel_math_stretch(abe)

        return stretched



    def pixel_math_stretch(self, image):
        """
        Replaces the old pixel math stretch logic by using the existing
        stretch_mono_image or stretch_color_image methods. 
        """
        # Choose a target median (the default you’ve used elsewhere is often 0.25)
        target_median = 0.25

        # Check if the image is mono or color
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Treat it as mono
            stretched = stretch_mono_image(
                image.squeeze(),  # squeeze in case it's (H,W,1)
                target_median=target_median,
                normalize=False,  # Adjust if you want normalization
                apply_curves=False,
                curves_boost=0.0
            )
            # If it was (H,W,1), replicate to 3 channels (optional)
            # or just keep it mono if you prefer
            # For now, replicate to 3 channels:
            stretched = np.stack([stretched]*3, axis=-1)
        else:
            # Full-color image
            stretched = stretch_color_image(
                image,
                target_median=target_median,
                linked=False,      # or False if you want per-channel stretches
                normalize=False,  
                apply_curves=False,
                curves_boost=0.0
            )

        return np.clip(stretched, 0, 1)

    def runSearch(self):
        if self.preprocessed_reference is None:
            QMessageBox.warning(self, "Error", "Reference image not preprocessed.")
            return
        if not self.preprocessed_search:
            QMessageBox.warning(self, "Error", "No search images preprocessed.")
            return

        ref_gray = self.to_grayscale(self.preprocessed_reference)

        self.anomalyData = []
        total = len(self.preprocessed_search)
        for i, search_dict in enumerate(self.preprocessed_search):
            search_img = search_dict["image"]
            search_gray = self.to_grayscale(search_img)

            diff_img = self.subtractImagesOnce(search_gray, ref_gray)
            anomalies = self.detectAnomaliesConnected(diff_img, threshold=self.parameters["threshold"])

            # Just store the anomalies
            self.anomalyData.append({
                "imageName": os.path.basename(search_dict["path"]),
                "anomalyCount": len(anomalies),
                "anomalies": anomalies
            })

            self.search_progress_label.setText(f"Processing image {i+1} of {total}...")
            QApplication.processEvents()

        self.search_progress_label.setText("Search for anomalies complete.")

        # Optionally still show the text-based summary:
        self.showDetailedResultsDialog(self.anomalyData)

        # Now build & show the anomaly tree for user double-click
        self.showAnomalyListDialog()

    def showAnomalyListDialog(self):
        """
        Build a QDialog with a QTreeWidget listing each image and its anomaly count.
        Double-clicking an item will open a non-modal preview.
        """
        if not self.anomalyData:
            QMessageBox.information(self, "Info", "No anomalies or no images processed.")
            return

        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Results")

        layout = QVBoxLayout(dialog)

        self.anomaly_tree = QTreeWidget(dialog)
        self.anomaly_tree.setColumnCount(2)
        self.anomaly_tree.setHeaderLabels(["Image", "Anomaly Count"])
        layout.addWidget(self.anomaly_tree)

        # Populate the tree
        for i, data in enumerate(self.anomalyData):
            item = QTreeWidgetItem([
                data["imageName"],
                str(data["anomalyCount"])
            ])
            # Store an index or reference so we know which image to open
            item.setData(0, Qt.ItemDataRole.UserRole, i)
            self.anomaly_tree.addTopLevelItem(item)

        # Connect double-click
        self.anomaly_tree.itemDoubleClicked.connect(self.onAnomalyItemDoubleClicked)

        dialog.setLayout(layout)
        dialog.resize(300, 200)
        dialog.show()  # non-modal, so the user can keep using the main window

    def onAnomalyItemDoubleClicked(self, item, column):
        """
        Called when the user double-clicks a row in the anomaly tree.
        We'll open a MosaicPreviewWindow showing bounding boxes for that image.
        """
        # Retrieve the index we stored
        idx = item.data(0, Qt.ItemDataRole.UserRole)
        if idx is None:
            return

        # anomalies from anomalyData
        anomalies = self.anomalyData[idx]["anomalies"]
        image_name = self.anomalyData[idx]["imageName"]

        # The preprocessed image from self.preprocessed_search
        # We assume the i-th preprocessed image matches the i-th anomalyData.
        # Make sure your code lines up these two lists the same order.
        # e.g., i=0 => self.preprocessed_search[0], self.anomalyData[0]
        search_img = self.preprocessed_search[idx]["image"]  # already in [0..1], shape (H,W,3)

        if anomalies:
            # Create an annotated image
            annotated_8bit = self.draw_bounding_boxes_on_stretched(search_img, anomalies)

            # Pass to MosaicPreviewWindow
            preview = MosaicPreviewWindow(
                annotated_8bit, 
                title=f"Anomalies in {image_name}", 
                parent=self
            )
            # Optionally disable auto-stretch so the boxes remain bright
            preview.stretch_toggle.setChecked(False)
            preview.resize(800, 600)
            preview.show()  # non-modal
        else:
            QMessageBox.information(self, "No Anomalies", f"No anomalies found for {image_name}.")


    def draw_bounding_boxes_on_stretched(self,
        stretched_image: np.ndarray, 
        anomalies: list
    ) -> np.ndarray:
        """
        1) Convert 'stretched_image' [0..1] -> [0..255] 8-bit color
        2) Draw red rectangles for each anomaly in 'anomalies'.
        Each anomaly is assumed to have keys: minX, minY, maxX, maxY
        3) Return the 8-bit color image (H,W,3).
        """
        import cv2
        import numpy as np

        # Ensure 3 channels
        if stretched_image.ndim == 2:
            stretched_3ch = np.stack([stretched_image]*3, axis=-1)
        elif stretched_image.ndim == 3 and stretched_image.shape[2] == 1:
            stretched_3ch = np.concatenate([stretched_image]*3, axis=2)
        else:
            stretched_3ch = stretched_image

        # Convert float [0..1] => uint8 [0..255]
        img_bgr = (stretched_3ch * 255).clip(0,255).astype(np.uint8)

        # Define the margin
        margin = 15

        # Draw red boxes in BGR color = (0, 0, 255)
        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Expand the bounding box by a 10-pixel margin
            x1_exp = x1 - margin
            y1_exp = y1 - margin
            x2_exp = x2 + margin
            y2_exp = y2 + margin
            cv2.rectangle(
                img_bgr, (x1_exp, y1_exp), (x2_exp, y2_exp),
                color=(255, 0, 0),
                thickness=5
            )

        return img_bgr


    def subtractImagesOnce(self, search_img, ref_img, debug_prefix=None):
        """
        Compute the absolute difference of two images (both already grayscale).
        Both images must have the same dimensions.

        Optionally, if 'debug_prefix' is provided, save the difference
        as a debug image. For example: "mydebugprefix_diff.tif".
        """
        if search_img.shape != ref_img.shape:
            raise ValueError("Image dimensions do not match for difference.")

        # Both search_img and ref_img are assumed in [0..1]
        # so the absolute difference will also be in [0..1].
        result = search_img - ref_img
        print("Computed difference between search and reference images.")

        # If debug_prefix is specified, save the difference image
        # For example:
        #self.debug_save_image(
        #    result,
        #    prefix=debug_prefix,
        #    step_name="diff",
        #    ext=".tif"
        #)
        np.clip(result, 0, 1)  # Ensure result is in [0..1]
        return result

    def debug_save_image(self, image, prefix="debug", step_name="step", ext=".tif"):
        """
        Saves 'image' to disk for debugging. 
        - 'prefix' can be a directory path or prefix for your debug images.
        - 'step_name' is appended to the filename to indicate which step.
        - 'ext' could be '.tif', '.png', or another format you support.

        This example uses your 'save_image' function from earlier or can
        directly use tiff.imwrite or similar.
        """

        # Ensure the image is float32 in [0..1] before saving
        image = image.astype(np.float32, copy=False)

        # Build debug filename
        filename = f"{prefix}_{step_name}{ext}"

        # E.g., if you have a global 'save_image' function:
        save_image(
            image, 
            filename,
            original_format="tif",  # or "png", "fits", etc.
            bit_depth="16-bit"
        )
        print(f"[DEBUG] Saved {step_name} => {filename}")

    def to_grayscale(self, image):
        """
        Converts an image to grayscale by averaging channels if needed.
        If the image is already 2D, return it as is.
        """
        if image.ndim == 2:
            # Already grayscale
            return image
        elif image.ndim == 3 and image.shape[2] == 3:
            # Average the three channels
            return np.mean(image, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:
            # Squeeze out that single channel
            return image[:, :, 0]
        else:
            raise ValueError(f"Unsupported image shape for grayscale: {image.shape}")

    def detectAnomaliesConnected(self, diff_img: np.ndarray, threshold: float = 0.1):
        """
        1) Build mask = diff_img > threshold.
        2) Optionally skip 5% border by zeroing out that region in the mask.
        3) connectedComponentsWithStats => bounding boxes.
        4) Filter by min_area, etc.
        5) Return a list of anomalies, each with minX, minY, maxX, maxY, area.
        """
        h, w = diff_img.shape

        # 1) Create the mask
        mask = (diff_img > threshold).astype(np.uint8)

        # 2) Skip 5% border (optional)
        border_x = int(0.05 * w)
        border_y = int(0.05 * h)
        mask[:border_y, :] = 0
        mask[h - border_y:, :] = 0
        mask[:, :border_x] = 0
        mask[:, w - border_x:] = 0

        # 3) connectedComponentsWithStats => label each region
        # connectivity=8 => 8-way adjacency
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)

        # stats[i] = [x, y, width, height, area], for i in [1..num_labels-1]
        # label_id=0 => background

        anomalies = []
        for label_id in range(1, num_labels):
            x, y, width_, height_, area_ = stats[label_id]

            # bounding box corners
            minX = x
            minY = y
            maxX = x + width_ - 1
            maxY = y + height_ - 1

            # 4) Filter out tiny or huge areas if you want:
            # e.g., skip anything <4x4 => area<16
            if area_ < 25:
                continue
            # e.g., skip bounding boxes bigger than 40 in either dimension if you want
            if width_ > 200 or height_ > 200:
                continue

            anomalies.append({
                "minX": minX,
                "minY": minY,
                "maxX": maxX,
                "maxY": maxY,
                "area": area_
            })

        return anomalies


    def showDetailedResultsDialog(self, anomalyData):
        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Detection Results")
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit(dialog)
        text_edit.setReadOnly(True)
        result_text = "Detailed Anomaly Results:\n\n"

        for data in anomalyData:
            result_text += f"Image: {data['imageName']}\nAnomalies: {data['anomalyCount']}\n"
            for group in data["anomalies"]:
                # Now refer to 'minX', 'minY', 'maxX', 'maxY'
                result_text += (
                    f"  Group Bounding Box: "
                    f"Top-Left ({group['minX']}, {group['minY']}), "
                    f"Bottom-Right ({group['maxX']}, {group['maxY']})\n"
                )
            result_text += "\n"

        text_edit.setText(result_text)
        layout.addWidget(text_edit)
        dialog.setLayout(layout)
        dialog.show()

    def showAnomaliesOnImage(self, image: np.ndarray, anomalies: list, window_title="Anomalies"):
        """
        Displays 'image' in a QDialog with red bounding boxes for each anomaly.
        'image' is assumed to be float32 in [0..1], shape (H,W) or (H,W,3).
        'anomalies' is a list of dicts, each with keys: minX, minY, maxX, maxY, etc.
        """
        import cv2
        import numpy as np

        # 1) Convert to 3-channel if needed
        if image.ndim == 2:
            # grayscale => replicate to 3-ch so we can draw colored rectangles
            image_3ch = np.stack([image, image, image], axis=-1)
        elif image.ndim == 3 and image.shape[2] == 1:
            # single-channel in last dimension
            image_3ch = np.concatenate([image, image, image], axis=2)
        else:
            image_3ch = image

        # 2) Convert float [0..1] => uint8 [0..255], and reorder to BGR if needed
        # OpenCV expects BGR order for color. If your array is already RGB, we can just treat it as BGR if color correctness isn't critical. 
        # For a quick approach, let's do it directly:
        image_bgr = (image_3ch * 255).astype(np.uint8)

        # 3) Draw bounding boxes with a margin
        margin = 10  # You can adjust this as desired
        height, width = image_bgr.shape[:2]

        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Inflate the bounding box
            x1 = max(0, x1 - margin)
            y1 = max(0, y1 - margin)
            x2 = min(width - 1,  x2 + margin)
            y2 = min(height - 1, y2 + margin)

            # Draw the rectangle (BGR color=(255,0,0) => Blue if you want red use (0,0,255))
            cv2.rectangle(
                image_bgr, 
                (x1, y1), (x2, y2), 
                color=(255, 0, 0),  # Blue in BGR
                thickness=5
            )


        # 4) Convert the annotated BGR image back to QImage => QPixmap => show in QDialog
        # We can do something like:
        height, width = image_bgr.shape[:2]

        # For color images, QImage.Format_RGB888 expects an RGB order
        # We can convert BGR->RGB by:
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        qimg = QImage(
            image_rgb.data, 
            width, 
            height, 
            3 * width, 
            QImage.Format.Format_RGB888
        )
        pixmap = QPixmap.fromImage(qimg)

        # 5) Show in a simple QDialog with a QLabel or QGraphicsView
        dialog = QDialog(self)
        dialog.setWindowTitle(window_title)
        layout = QVBoxLayout(dialog)

        label = QLabel(dialog)
        label.setPixmap(pixmap)
        layout.addWidget(label)

        dialog.setLayout(layout)
        dialog.resize(width, height)
        dialog.show()


    def newInstance(self):
        # Reset parameters and UI elements for a new run
        self.parameters = {"referenceImagePath": "", "searchImagePaths": [], "threshold": 0.10}
        self.ref_line_edit.clear()
        self.search_list.clear()
        self.cosmetic_checkbox.setChecked(False)
        self.thresh_slider.setValue(10)
        self.preprocess_progress_label.setText("Preprocessing progress: 0 / 0")
        self.search_progress_label.setText("Processing progress: 0 / 0")
        self.preprocessed_reference = None
        self.preprocessed_search = []
        self.anomalyData = []
        QMessageBox.information(self, "New Instance", "Reset for a new instance.")

class HDRWorker(QObject):
    """
    Worker class to perform WaveScale HDRation in a separate thread.
    Emits signals to update progress.
    """
    progress_update = pyqtSignal(str, int)  # Signal: (current_step, percent_complete)
    finished = pyqtSignal(np.ndarray, np.ndarray)  # Signal: (transformed_rgb, mask)

    def __init__(self, rgb_image, n_scales, compression_factor, mask_gamma, b3_spline_kernel):
        super().__init__()
        self.rgb_image = rgb_image
        self.n_scales = n_scales
        self.compression_factor = compression_factor
        self.mask_gamma = mask_gamma
        self.b3_spline_kernel = b3_spline_kernel

    def run(self):
        try:
            # Step 1: Convert to Lab
            self.progress_update.emit("Converting to Lab color space...", 10)
            lab = self.rgb_to_lab(self.rgb_image)
            L_original = lab[..., 0].copy()  # Store original L for median calculation
            L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

            # Step 2: Decompose using à trous wavelet
            self.progress_update.emit("Performing wavelet decomposition...", 20)
            scales = self.atrous_wavelet_decompose(L, self.n_scales)

            # Step 3: Create Luminance Mask
            self.progress_update.emit("Creating luminance mask...", 30)
            mask = self.create_luminance_mask(L, gamma=self.mask_gamma)

            # Step 4: Apply mask to wavelet planes
            self.progress_update.emit("Applying mask to wavelet planes...", 40)
            wavelet_planes = scales[:-1]
            residual = scales[-1]

            # Step 5: Enhance wavelet planes based on mask and compression factor with decaying influence
            self.progress_update.emit("Enhancing wavelet planes...", 50)
            decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
            for i in range(len(wavelet_planes)):
                # Calculate decay factor for the current scale
                decay_factor = decay_rate ** i  # Higher scales have smaller decay_factor
                # Compute scaling factor with decay
                scaling_factor = (1.0 + (self.compression_factor - 1.0) * mask * decay_factor) * 2
                # Apply scaling to the wavelet plane
                wavelet_planes[i] *= scaling_factor
                # Emit intermediate progress
                percent = 50 + int(((i + 1) / len(wavelet_planes)) * 10)  # Distribute 10% across scales
                self.progress_update.emit(f"Enhancing wavelet scale {i+1}...", percent)

            # Step 6: Reconstruct L channel
            self.progress_update.emit("Reconstructing L channel...", 60)
            L_reconstructed = self.atrous_wavelet_reconstruct(wavelet_planes + [residual])

            # Step 7: Apply midtones transfer to align median luminance
            self.progress_update.emit("Applying midtones transfer...", 70)
            median_original = np.median(L_original)
            median_reconstructed = np.median(L_reconstructed)

            if median_reconstructed == 0:
                scaling_midtones = 1.0
            else:
                scaling_midtones = median_original / median_reconstructed

            L_reconstructed *= scaling_midtones
            L_reconstructed = np.clip(L_reconstructed, 0, 100)

            # Update the Lab image with the reconstructed L channel
            lab[..., 0] = L_reconstructed

            # Step 8: Convert back to RGB
            self.progress_update.emit("Converting back to RGB color space...", 80)
            transformed_rgb = self.lab_to_rgb(lab)

            # Step 9: Apply a non-linear curve to the HDR-enhanced image to dim bright areas
            self.progress_update.emit("Applying dimming curve...", 90)
            transformed_rgb = self.apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0 + self.n_scales * 0.2)

            # Step 10: Finish
            self.progress_update.emit("Finalizing...", 100)
            self.finished.emit(transformed_rgb, mask)

        except Exception as e:
            print(f"Error during HDR transformation: {e}")
            self.finished.emit(None, None)

    # Define necessary methods copied from the main dialog
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    def create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100)^gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)


class WaveScaleHDRDialog(QDialog):
    """
    A self-contained WaveScale HDR dialog that:
      - Displays a preview of the image in a QGraphicsView.
      - Uses à trous (starlet) wavelet decomposition on the L channel in Lab space.
      - Lets you adjust # of scales, coarse compression, and mask gamma, then preview or apply.
      - Applies a simple L-based mask (absolute luminance scaled to [0..1]^gamma) so bright areas get full HDR,
        and dark areas get minimal changes.
      - Displays the luminance mask in a separate window for debugging purposes.
    """

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("WaveScale HDR")
        self.setMinimumSize(800, 600)  # Increased width to better accommodate preview and mask display

        self.image_manager = image_manager

        # Detect if the image is grayscale or RGB
        if self.image_manager.image.ndim == 2:
            self.is_grayscale = True
            # Convert to 3-channel by stacking
            self.original_image_rgb = np.stack([self.image_manager.image] * 3, axis=-1)
        elif self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 3:
            self.is_grayscale = False
            self.original_image_rgb = self.image_manager.image.copy()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format.")
            self.reject()
            return  # Exit initialization if image format is unsupported

        # Make local copies for preview and original
        self.original_image = np.clip(self.original_image_rgb.astype(np.float32), 0, 1)
        self.preview_image = self.original_image.copy()

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the preview area (QGraphicsView in a scrollable region)
        self._create_preview_area()
        self._create_zoom_area()

        # 2) Create the HDR controls
        self._create_controls()

        # 3) Lay out preview & controls with progress display
        content_layout = QVBoxLayout()
        content_layout.addWidget(self.scroll_area)
        content_layout.addWidget(self.zoom_group_box)

        # Create the Progress Display Area
        self._create_progress_display()

        # Create a Horizontal Layout to hold controls and progress side by side
        hbox_layout = QHBoxLayout()
        hbox_layout.addWidget(self.controls_group, stretch=3)        # Allocate more space to controls
        hbox_layout.addWidget(self.progress_group_box, stretch=1)   # Allocate less space to progress

        content_layout.addLayout(hbox_layout)  # Add the HBoxLayout to the content_layout

        self.main_layout.addLayout(content_layout)

        # 4) Bottom buttons (Apply / Cancel)
        self._create_bottom_buttons()

        # 5) Initialize and show the mask display window
        self._create_mask_window()

        # B3-spline kernel for à trous wavelet
        self.b3_spline_kernel = np.array([1, 4, 6, 4, 1], dtype=np.float32) / 16.0

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Convert original image to Lab and compute initial mask
        self.lab_original = self.rgb_to_lab(self.original_image)
        self.L_original = self.lab_original[..., 0].copy()  # Store original L for mask computation
        self.mask = self._create_luminance_mask(self.L_original, gamma=self.mask_gamma_slider.value() / 100.0)



        # Show the initial preview
        self._update_preview_pixmap(self.preview_image)

        # Show the initial mask in MaskDisplayWindow
        self.mask_window.update_mask(self.mask)        

        self.apply_button.setEnabled(False)
        self.preview_button.clicked.connect(self._enable_apply_button)   
        self.mask_gamma_slider.valueChanged.connect(self._on_mask_gamma_changed)        

    def _on_mask_gamma_changed(self, value):
        """
        Recompute the luminance mask based on the new gamma value and update the mask display.
        
        Args:
            value (int): The new value from the mask_gamma_slider.
        """
        try:
            gamma = value / 100.0  # Convert slider value to gamma
            self.mask = self._create_luminance_mask(self.L_original, gamma=gamma)
            self.mask_window.update_mask(self.mask)
            print(f"Mask gamma changed to {gamma}, mask updated.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")

    # -------------------------------------------------------------------------
    # 1) Zoom AREA
    # -------------------------------------------------------------------------
    def _create_zoom_area(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_group_box = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_group_box.setLayout(zoom_layout)

    def _fit_to_preview(self):
        """Fit the entire image within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No image to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0

    # -------------------------------------------------------------------------
    # 1) PREVIEW AREA
    # -------------------------------------------------------------------------
    def _create_preview_area(self):
        """Create a QGraphicsView & QGraphicsScene for the preview, inside a scroll area."""
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)

        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Optionally, enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        self.scroll_area.setWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) CONTROLS
    # -------------------------------------------------------------------------
    def _create_controls(self):
        """Create the HDR sliders (# scales, compression, mask gamma) and zoom buttons."""
        self.controls_group = QGroupBox("HDR Controls")
        controls_layout = QFormLayout()

        # Number of scales
        self.scales_slider = QSlider(Qt.Orientation.Horizontal)
        self.scales_slider.setRange(2, 10)
        self.scales_slider.setValue(5)
        self.scales_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.scales_slider.setTickInterval(1)
        controls_layout.addRow("Number of Scales:", self.scales_slider)

        # Coarse compression
        self.compression_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => factor = 0.1..3.0
        self.compression_slider.setRange(10, 500)
        self.compression_slider.setValue(150)
        self.compression_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.compression_slider.setTickInterval(10)
        controls_layout.addRow("Coarse Compression:", self.compression_slider)

        # Mask gamma
        self.mask_gamma_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => gamma = 0.1..3.0
        self.mask_gamma_slider.setRange(10, 1000)
        self.mask_gamma_slider.setValue(500)
        self.mask_gamma_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.mask_gamma_slider.setTickInterval(10)
        controls_layout.addRow("Mask Gamma:", self.mask_gamma_slider)



        # Preview Button
        self.preview_button = QPushButton("Preview")
        self.preview_button.clicked.connect(self._on_preview_clicked)
        controls_layout.addRow(self.preview_button)

        self.controls_group.setLayout(controls_layout)

    # -------------------------------------------------------------------------
    # 3) BOTTOM BUTTONS
    # -------------------------------------------------------------------------
    def _create_bottom_buttons(self):
        bottom_layout = QHBoxLayout()

        self.apply_button = QPushButton("Apply")
        self.apply_button.clicked.connect(self._on_apply_clicked)
        bottom_layout.addWidget(self.apply_button)

        self.reset_button = QPushButton("Reset")
        self.reset_button.clicked.connect(self._on_reset_clicked)
        bottom_layout.addWidget(self.reset_button)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        bottom_layout.addWidget(self.cancel_button)

        self.main_layout.addLayout(bottom_layout)

    # -------------------------------------------------------------------------
    # 4) MASK DISPLAY WINDOW
    # -------------------------------------------------------------------------
    def _create_mask_window(self):
        """Initialize and show the separate mask display window."""
        self.mask_window = MaskDisplayWindow(self)
        self.mask_window.show()

    # -------------------------------------------------------------------------
    # 5) Progress Display Area
    # -------------------------------------------------------------------------
    def _create_progress_display(self):
        """Create a progress display area on the right side of the content_layout."""
        self.progress_group_box = QGroupBox("Processing Progress")
        progress_layout = QVBoxLayout()

        # Current Step Label
        self.current_step_label = QLabel("Idle")
        self.current_step_label.setAlignment(Qt.AlignmentFlag.AlignTop)
        progress_layout.addWidget(self.current_step_label)

        # Progress Bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        progress_layout.addWidget(self.progress_bar)

        self.progress_group_box.setLayout(progress_layout)

    def _on_reset_clicked(self):
        """Reset the image and sliders to their default states."""
        try:
            # Reset sliders to default values
            self.scales_slider.setValue(5)
            self.compression_slider.setValue(150)
            self.mask_gamma_slider.setValue(500)

            # Reset the preview image to the original image
            self.preview_image = self.original_image.copy()
            self._update_preview_pixmap(self.preview_image)

            # Reset progress display
            self.current_step_label.setText("Idle")
            self.progress_bar.setValue(0)

            # Disable the Apply button since no changes are pending
            self.apply_button.setEnabled(False)

            # Optionally, reset the zoom to default
            self.zoom_factor = 1.0
            self.graphics_view.resetTransform()

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to reset: {e}")

    # -------------------------------------------------------------------------
    # PREVIEW / APPLY
    # -------------------------------------------------------------------------
    def _on_preview_clicked(self):
        """Generate a preview image with current settings and display it."""
        try:
            # Disable buttons to prevent multiple clicks
            self.preview_button.setEnabled(False)
            self.apply_button.setEnabled(False)

            # Reset progress display
            self.current_step_label.setText("Starting HDR Transformation...")
            self.progress_bar.setValue(0)

            # Gather current settings
            n_scales = self.scales_slider.value()
            compression_factor = self.compression_slider.value() / 100.0
            mask_gamma = self.mask_gamma_slider.value() / 100.0

            # Initialize worker and thread
            self.worker = HDRWorker(
                rgb_image=self.original_image,
                n_scales=n_scales,
                compression_factor=compression_factor,
                mask_gamma=mask_gamma,
                b3_spline_kernel=self.b3_spline_kernel
            )
            self.thread = QThread()
            self.worker.moveToThread(self.thread)

            # Connect signals
            self.thread.started.connect(self.worker.run)
            self.worker.progress_update.connect(self._update_progress)
            self.worker.finished.connect(self._on_worker_finished)
            self.worker.finished.connect(self.thread.quit)
            self.worker.finished.connect(self.worker.deleteLater)
            self.thread.finished.connect(self.thread.deleteLater)

            # Start the thread
            self.thread.start()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))
            self.preview_button.setEnabled(True)
            self.apply_button.setEnabled(False)

    def _update_progress(self, step, percent):
        """Update the progress display based on signals from the worker."""
        self.current_step_label.setText(step)
        self.progress_bar.setValue(percent)

    def _on_worker_finished(self, transformed_rgb, mask):
        """Handle the completion of the worker thread."""
        if transformed_rgb is not None:
            if self.is_grayscale:
                # For grayscale, take one channel and keep it single-channel
                mask_expanded = mask[:, :, np.newaxis]  # Shape: (h, w, 1)
                blended_preview = self.original_image[:, :, 0:1] * (1 - mask_expanded) + transformed_rgb[:, :, 0:1] * mask_expanded
                # Stack back to 3 channels for consistent display
                blended_preview = np.repeat(blended_preview, 3, axis=2)
            else:
                # For RGB
                mask_expanded = np.repeat(mask[:, :, np.newaxis], 3, axis=2)  # Shape: (h, w, 3)
                blended_preview = self.original_image * (1 - mask_expanded) + transformed_rgb * mask_expanded

            # Update preview image
            self.preview_image = blended_preview
            self._update_preview_pixmap(blended_preview)

            # Enable Apply button
            self.apply_button.setEnabled(True)

        else:
            QMessageBox.critical(self, "Error", "WaveScale HDR failed.")

        # Re-enable preview button
        self.preview_button.setEnabled(True)

    def _enable_apply_button(self):
        """Enable the Apply button after a preview is generated."""
        self.apply_button.setEnabled(True)

    def _on_apply_clicked(self):
        """Apply the HDR transform to the main image manager and close the dialog."""
        try:
            # Check if a preview has been generated
            if not hasattr(self, 'preview_image'):
                QMessageBox.warning(self, "Warning", "Please generate a preview before applying the transformation.")
                return

            # Use the existing preview_image as the output image
            output_image = self.preview_image.copy()

            # Update the main ImageManager
            self.image_manager.set_image(output_image, {"description": "WaveScale HDR"}, step_name="WaveScale HDR")
            QMessageBox.information(self, "Success", "WaveScale HDR applied.")
            self.accept()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))

    # -------------------------------------------------------------------------
    # UTILITY: UPDATE PREVIEW PIXMAP
    # -------------------------------------------------------------------------
    def _update_preview_pixmap(self, image):
        """Convert `image` (float32 [0..1]) to QPixmap and display."""
        pixmap = self._convert_image_to_pixmap(image)
        self.pixmap_item.setPixmap(pixmap)
        self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

    def _convert_image_to_pixmap(self, image):
        """Convert float32 [0..1] image to QPixmap (RGB888)."""
        image_uint8 = (np.clip(image, 0, 1) * 255).astype(np.uint8)
        h, w = image_uint8.shape[:2]

        if image_uint8.ndim == 2:
            # Grayscale => expand to 3 channels
            image_uint8 = np.repeat(image_uint8[..., None], 3, axis=2)

        bytes_per_line = 3 * w
        qimage = QImage(
            image_uint8.data, w, h, bytes_per_line, QImage.Format.Format_RGB888
        )
        return QPixmap.fromImage(qimage)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self._zoom_in()
        else:
            self._zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def _apply_zoom(self):
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    # -------------------------------------------------------------------------
    # HDR ALGORITHM
    # -------------------------------------------------------------------------
    def _perform_hdr_transform(self, rgb_image, n_scales, compression_factor, mask_gamma):
        """
        1) Convert to Lab
        2) à trous wavelet decompose L
        3) Create L-based mask: M = (L / 100)^gamma
           - bright => near 1
           - dark => near 0
        4) Apply mask to wavelet planes
        5) Compress (enhance) wavelet planes based on mask and compression factor
        6) Reconstruct L
        7) Apply midtones transfer to align median luminance
        8) Convert back to RGB
        9) Return transformed RGB and mask for blending
        """
        # 1) Convert to Lab using custom rgb_to_lab
        lab = self.rgb_to_lab(rgb_image)
        L_original = lab[..., 0].copy()  # Store original L for median calculation

        L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

        # 2) Decompose
        scales = self._atrous_wavelet_decompose(L, n_scales)

        # 3) L-based mask
        mask = self._create_luminance_mask(L, gamma=mask_gamma)
        # => bright areas ~1.0, dark areas ~0.0

        # Update the mask display window
        #self.mask_window.update_mask(mask)

        # 4) Apply mask to wavelet planes
        wavelet_planes = scales[:-1]
        residual = scales[-1]

        # 5) Enhance wavelet planes based on mask and compression factor
        decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
        for i in range(len(wavelet_planes)):
            # Compute scaling factor: 1 + (compression_factor -1) * mask
            decay_factor = decay_rate ** i
            scaling_factor = (1.0 + (compression_factor - 1.0) * mask* decay_factor)*2
            wavelet_planes[i] *= scaling_factor
            print(f"Scale {i} - Scaling Factor Stats: min={scaling_factor.min()}, max={scaling_factor.max()}, mean={scaling_factor.mean()}")
            print(f"Scale {i} - Wavelet Plane Modified Stats: min={wavelet_planes[i].min()}, max={wavelet_planes[i].max()}, mean={wavelet_planes[i].mean()}")

        # Reconstruct L
        L_reconstructed = self._atrous_wavelet_reconstruct(wavelet_planes + [residual])

        # 7) Apply midtones transfer to align median luminance
        median_original = np.median(L_original)
        median_reconstructed = np.median(L_reconstructed)

        if median_reconstructed == 0:
            scaling_midtones = 1.0
        else:
            scaling_midtones = median_original / median_reconstructed

        L_reconstructed *= scaling_midtones
        L_reconstructed = np.clip(L_reconstructed, 0, 100)

        # Update the Lab image with the reconstructed L channel
        lab[..., 0] = L_reconstructed

        # 8) Convert back to RGB using custom lab_to_rgb
        transformed_rgb = self.lab_to_rgb(lab)

        # 9) Return both transformed RGB and mask for blending
        transformed_rgb = self._apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0+n_scales*0.2)
        return transformed_rgb, mask

    def _apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def _create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100) ^ gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)

    def _atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def _atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    # -------------------------------------------------------------------------
    # COLOR SPACE: CUSTOM LAB CONVERSIONS
    # -------------------------------------------------------------------------
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image
            
class BlemishBlasterWorkerSignals(QObject):
    finished = pyqtSignal(np.ndarray)  # Emitted when processing is done

class BlemishBlasterWorker(QRunnable):
    def __init__(self, image, x, y, radius, feather, opacity, channels_to_process=[0,1,2]):
        super().__init__()
        self.image = image.copy()
        self.x = x
        self.y = y
        self.radius = radius
        self.feather = feather
        self.opacity = opacity
        self.channels_to_process = channels_to_process
        self.signals = BlemishBlasterWorkerSignals()

    @pyqtSlot()
    def run(self):
        # Perform blemish removal
        corrected_image = self.remove_blemish(
            self.image, self.x, self.y, self.radius, self.feather, self.opacity, self.channels_to_process
        )
        # Emit the corrected image
        self.signals.finished.emit(corrected_image)

    def remove_blemish(self, image, x, y, radius, feather, opacity, channels_to_process):
        """
        Perform per-pixel blemish removal by sampling from surrounding circles.
        Handles edge cases where correction circles may extend beyond image boundaries.
        """
        corrected_image = image.copy()
        h, w = image.shape[:2]

        # Define angles for surrounding circles
        angles = [0, 60, 120, 180, 240, 300]
        surrounding_centers = []
        for angle in angles:
            rad = math.radians(angle)
            dx = int(math.cos(rad) * (radius * 1.5))  # 1.5 times the radius away
            dy = int(math.sin(rad) * (radius * 1.5))
            surrounding_centers.append((x + dx, y + dy))

        # Calculate medians for each surrounding circle and the target circle
        target_median = self.calculate_median_circle(image, x, y, radius, channels_to_process)
        surrounding_medians = [
            self.calculate_median_circle(image, cx, cy, radius, channels_to_process)
            for cx, cy in surrounding_centers
        ]

        # Determine the three correction circles closest to the target median
        median_diffs = [abs(median - target_median) for median in surrounding_medians]
        closest_indices = np.argsort(median_diffs)[:3]  # Indices of the three closest circles
        selected_circles = [surrounding_centers[i] for i in closest_indices]

        # Iterate through each channel
        for c in channels_to_process:
            # Iterate through each pixel in the target blemish circle
            for i in range(max(y - radius, 0), min(y + radius + 1, h)):
                for j in range(max(x - radius, 0), min(x + radius + 1, w)):
                    dist = math.sqrt((j - x) ** 2 + (i - y) ** 2)
                    if dist <= radius:
                        # Apply feathering based on distance
                        if feather > 0:
                            weight = max(0, min(1, (radius - dist) / (radius * feather)))
                        else:
                            weight = 1

                        # Collect corresponding pixel values from the selected correction circles
                        sampled_values = []
                        for (cx, cy) in selected_circles:
                            # Find the corresponding pixel position
                            corresponding_j = j + (cx - x)
                            corresponding_i = i + (cy - y)

                            # Ensure the corresponding pixel is within image bounds
                            if 0 <= corresponding_i < h and 0 <= corresponding_j < w:
                                if image.ndim == 2:
                                    sampled_values.append(image[corresponding_i, corresponding_j])
                                elif image.ndim == 3:
                                    if image.shape[2] == 1:
                                        sampled_values.append(image[corresponding_i, corresponding_j, 0])
                                    elif image.shape[2] > c:
                                        sampled_values.append(image[corresponding_i, corresponding_j, c])
                                    else:
                                        continue  # Skip if channel is out of bounds

                        if sampled_values:
                            # Calculate the median of the sampled values
                            median_val = np.median(sampled_values)
                        else:
                            # If no valid sampled pixels, retain the original pixel value
                            if image.ndim == 2:
                                median_val = image[i, j]
                            elif image.ndim == 3 and image.shape[2] ==1:
                                median_val = image[i, j,0]
                            else:
                                median_val = image[i,j,c]

                        # Blend the median value into the target pixel using opacity and feathering
                        if image.ndim ==2:
                            original_val = image[i, j]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j] = blended_val
                        elif image.ndim ==3 and image.shape[2] ==1:
                            original_val = image[i, j,0]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j,0] = blended_val
                        elif image.ndim ==3 and image.shape[2] >c:
                            original_val = image[i, j, c]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j, c] = blended_val

        return corrected_image

    def calculate_median_circle(self, image, cx, cy, radius, channels):
        """
        Calculate the median value of a circle for the specified channels.

        Args:
            image (np.ndarray): The image array.
            cx (int): X-coordinate of the circle center.
            cy (int): Y-coordinate of the circle center.
            radius (int): Radius of the circle.
            channels (list): List of channel indices to process.

        Returns:
            float: The overall median value across specified channels.
        """
        values = []
        for c in channels:
            y_min = max(cy - radius, 0)
            y_max = min(cy + radius + 1, image.shape[0])
            x_min = max(cx - radius, 0)
            x_max = min(cx + radius + 1, image.shape[1])

            if image.ndim == 2:
                # Grayscale image (2D)
                roi = image[y_min:y_max, x_min:x_max]
            elif image.ndim == 3:
                if image.shape[2] ==1:
                    # Grayscale image with single channel
                    roi = image[y_min:y_max, x_min:x_max, 0]
                elif image.shape[2] >= c+1:
                    # RGB image
                    roi = image[y_min:y_max, x_min:x_max, c]
                else:
                    continue  # Skip if channel is out of bounds
            else:
                continue  # Unsupported image dimensions

            yy, xx = np.ogrid[:roi.shape[0], :roi.shape[1]]
            dist_from_center = np.sqrt((xx - (cx - x_min))**2 + (yy - (cy - y_min))**2)
            mask = dist_from_center <= radius
            values.extend(roi[mask].flatten())

        return np.median(values) if values else 0.0   
         
class GraphicsView(QGraphicsView):
    """
    Custom QGraphicsView to handle mouse events for blemish removal.
    Emits signals for mouse movements and clicks.
    """
    mouse_moved = pyqtSignal(QPointF)
    mouse_clicked = pyqtSignal(QPointF)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)  # Enable mouse tracking without button presses

    def mouseMoveEvent(self, event):
        pos = self.mapToScene(event.position().toPoint())
        self.mouse_moved.emit(pos)
        super().mouseMoveEvent(event)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            pos = self.mapToScene(event.position().toPoint())
            self.mouse_clicked.emit(pos)
        super().mousePressEvent(event)


class BlemishBlasterDialog(QDialog):
    blemish_removed = pyqtSignal(np.ndarray)  # Signal emitted when a blemish is removed

    def __init__(self, image_manager, parent=None):
        """
        Initializes the BlemishBlaster dialog.

        Args:
            image_manager (ImageManager): The ImageManager instance from the main application.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Blemish Blaster")
        self.setMinimumSize(800, 600)  # Set initial size to 800x600

        self.image_manager = image_manager  # Reference to ImageManager
        self.image = self.image_manager.image.copy()  # Work on a copy for display

        # Triplicate single-channel images to ensure 3 channels
        if self.image.ndim == 2:
            self.image = np.repeat(self.image[:, :, np.newaxis], 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 1:
            self.image = np.repeat(self.image, 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 3:
            pass  # RGB image, no action needed
        else:
            raise ValueError(f"Unsupported image shape: {self.image.shape}")

        self.display_image = self.image.copy()

        # Initialize QScrollArea for image display with scroll bars
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)  # Allow the scroll area to resize its widget

        # Initialize QGraphicsScene and QGraphicsView
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable panning via mouse drag
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)  # Center the image if smaller than viewport

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))

        # Initialize QGraphicsEllipseItem for the correction circle
        self.circle_item = QGraphicsEllipseItem()
        self.circle_item.setPen(QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine))
        self.circle_item.setBrush(QBrush(Qt.BrushStyle.NoBrush))  # Corrected Line
        self.circle_item.setVisible(False)  # Initially hidden
        self.scene.addItem(self.circle_item)

        # Set the graphics_view as the widget inside the scroll area
        self.scroll_area.setWidget(self.graphics_view)

        # Main layout
        self.layout = QVBoxLayout()
        self.setLayout(self.layout)
        self.layout.addWidget(self.scroll_area)

        # Create a horizontal layout to hold controls and visualization side by side
        controls_visualization_layout = QHBoxLayout()

        # Sliders and Controls
        controls_group = self.setup_controls()

        # Visualization
        visualization_group = self.setup_visualization()

        # Add controls and visualization to the horizontal layout
        controls_visualization_layout.addWidget(controls_group)
        controls_visualization_layout.addWidget(visualization_group)

        # Add the horizontal layout to the main vertical layout
        self.layout.addLayout(controls_visualization_layout)

        # Undo, Redo, and Apply Changes Buttons
        self.setup_undo_redo_apply()

        # Thread Pool for handling image processing
        self.threadpool = QThreadPool()

        # Current cursor position
        self.current_x = None
        self.current_y = None

        # Install event filter to capture mouse events
        self.graphics_view.installEventFilter(self)

        self.graphics_view.setMouseTracking(True)
        self.graphics_view.mousePressEvent = self.view_mouse_press_event
        self.graphics_view.mouseMoveEvent = self.view_mouse_move_event

        # Shortcut actions for Undo and Redo
        self.setup_shortcuts()
        self.cursor_over_scrollbar = False     

        self.undo_stack = []
        self.redo_stack = []       
        self.is_stretched = False    

        # Initialize Zoom parameters
        self.zoom_factor = 1.0  # Current zoom level
        self.zoom_step = 1.25   # Zoom increment factor
        self.zoom_min = 0.02     # Minimum zoom (10%)
        self.zoom_max = 2     # Maximum zoom (500%)

    def setup_controls(self):
        """Set up sliders for Correction Radius, Feathering, and Opacity."""
        controls_group = QGroupBox("Controls")
        form_layout = QFormLayout()        

        # Zoom Buttons Layout
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Optionally, add a label to display current zoom level
        self.zoom_label = QLabel("100%")
        zoom_layout.addWidget(self.zoom_label)

        form_layout.addRow("Zoom:", zoom_layout)

 

        # Correction Radius Slider
        self.radius_slider = QSlider(Qt.Orientation.Horizontal)
        self.radius_slider.setMinimum(1)
        self.radius_slider.setMaximum(300)
        self.radius_slider.setValue(10)
        self.radius_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.radius_slider.setTickInterval(10)
        self.radius_slider.valueChanged.connect(self.update_visualization)

        form_layout.addRow("Correction Radius:", self.radius_slider)

        # Feathering Slider
        self.feather_slider = QSlider(Qt.Orientation.Horizontal)
        self.feather_slider.setMinimum(0)
        self.feather_slider.setMaximum(100)
        self.feather_slider.setValue(50)
        self.feather_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.feather_slider.setTickInterval(10)
        self.feather_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Feathering:", self.feather_slider)

        # Opacity Slider
        self.opacity_slider = QSlider(Qt.Orientation.Horizontal)
        self.opacity_slider.setMinimum(0)
        self.opacity_slider.setMaximum(100)
        self.opacity_slider.setValue(100)
        self.opacity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.opacity_slider.setTickInterval(10)
        self.opacity_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Opacity:", self.opacity_slider)

        # Autostretch Button
        self.autostretch_button = QPushButton("Autostretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow("Autostretch:", self.autostretch_button)

        controls_group.setLayout(form_layout)
        return controls_group

    def setup_visualization(self):
        """Set up the feathering and opacity visualization."""
        visualization_group = QGroupBox("Feathering & Opacity Visualization")
        visualization_layout = QHBoxLayout()

        self.visualization_label = QLabel()
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)
        visualization_layout.addWidget(self.visualization_label)

        visualization_group.setLayout(visualization_layout)
        return visualization_group

    def setup_undo_redo_apply(self):
        """Set up Undo, Redo, and Apply Changes buttons."""
        history_group = QGroupBox("History")
        history_layout = QHBoxLayout()

        # Apply Changes Button
        self.apply_button = QPushButton("Apply Changes")
        self.apply_button.clicked.connect(self.apply_changes)
        history_layout.addWidget(self.apply_button)

        # Undo Button
        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.perform_undo)
        history_layout.addWidget(self.undo_button)

        # Redo Button
        self.redo_button = QPushButton("Redo")
        self.redo_button.clicked.connect(self.perform_redo)
        history_layout.addWidget(self.redo_button)

        history_group.setLayout(history_layout)
        self.layout.addWidget(history_group)

    def setup_shortcuts(self):
        """Set up keyboard shortcuts for Undo (Ctrl+Z) and Redo (Ctrl+Y)."""
        undo_shortcut = QAction(self)
        undo_shortcut.setShortcut(QKeySequence.StandardKey.Undo)
        undo_shortcut.triggered.connect(self.perform_undo)
        self.addAction(undo_shortcut)

        redo_shortcut = QAction(self)
        redo_shortcut.setShortcut(QKeySequence.StandardKey.Redo)
        redo_shortcut.triggered.connect(self.perform_redo)
        self.addAction(redo_shortcut)

    def perform_undo(self):
        """Perform undo action by interacting with the local undo stack."""
        if self.undo_stack:
            # Push current image to redo stack
            self.redo_stack.append(self.image.copy())
            # Pop the last image from undo stack
            self.image = self.undo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def perform_redo(self):
        """Perform redo action by interacting with the local redo stack."""
        if self.redo_stack:
            # Push current image to undo stack
            self.undo_stack.append(self.image.copy())
            # Pop the last image from redo stack
            self.image = self.redo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Redo performed.")
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")   

    def create_visualization_pixmap(self):
        """
        Create a visualization of feathering and opacity on a white disc.
        """
        size = 100  # Size of the visualization image
        image = np.ones((size, size, 3), dtype=np.float32)  # White background

        center = (size // 2, size // 2)
        radius = self.radius_slider.value()
        feather = self.feather_slider.value() / 100.0
        opacity = self.opacity_slider.value() / 100.0

        yy, xx = np.ogrid[:size, :size]
        dist_from_center = np.sqrt((xx - center[0])**2 + (yy - center[1])**2)
        mask = dist_from_center <= radius

        # Feathering mask
        if feather > 0:
            feather_mask = np.clip((radius - dist_from_center) / (radius * feather), 0, 1)
        else:
            feather_mask = np.ones_like(mask, dtype=np.float32)

        feather_mask = feather_mask * mask

        # Apply opacity
        # Red color for the correction area
        image[mask] = (1 - opacity * feather_mask)[mask, np.newaxis] * image[mask] + \
                      (opacity * feather_mask)[mask, np.newaxis] * np.array([1, 0, 0])

        # Convert to QImage
        image_uint8 = (image * 255).astype(np.uint8)
        q_image = QImage(image_uint8.data, size, size, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        return pixmap

    def update_visualization(self):
        """Update the visualization pixmap based on current feathering and opacity."""
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)

    def view_mouse_press_event(self, event):
        """Handle mouse press events in the graphics view"""
        if event.button() == Qt.MouseButton.LeftButton:
            # Convert mouse position to scene coordinates
            scene_pos = self.graphics_view.mapToScene(event.pos())
            self.on_mouse_click(scene_pos)
        event.accept()

    def view_mouse_move_event(self, event):
        """Handle mouse move events in the graphics view"""
        # Convert mouse position to scene coordinates
        scene_pos = self.graphics_view.mapToScene(event.pos())
        self.on_mouse_move(scene_pos)
        event.accept()

    def convert_image_to_pixmap(self, image):
        """
        Convert a numpy image array to QPixmap for display.

        Args:
            image (np.ndarray): Image array normalized to [0,1].

        Returns:
            QPixmap: The converted pixmap.
        """
        # Convert from [0,1] to [0,255]
        image_uint8 = np.clip(image * 255, 0, 255).astype(np.uint8)

        if image_uint8.ndim == 2:
            # Grayscale image (2D) - Triplicate to make 3 channels
            height, width = image_uint8.shape
            image_triplicated = np.repeat(image_uint8[:, :, np.newaxis], 3, axis=2)
            bytes_per_line = 3 * width
            q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif image_uint8.ndim == 3:
            if image_uint8.shape[2] == 3:
                # RGB image (3 channels)
                height, width, channels = image_uint8.shape
                bytes_per_line = channels * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif image_uint8.shape[2] == 1:
                # Grayscale image represented as (height, width, 1) - Triplicate to make 3 channels
                height, width, channels = image_uint8.shape
                image_triplicated = np.repeat(image_uint8, 3, axis=2)
                bytes_per_line = 3 * width
                q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            else:
                raise ValueError(f"Unsupported number of channels: {image_uint8.shape[2]}")
        else:
            raise ValueError(f"Unsupported image shape: {image_uint8.shape}")

        return QPixmap.fromImage(q_image)


    def eventFilter(self, source, event):
        """Event filter to capture mouse move and click events."""
        if source == self.graphics_view:
            if event.type() == QEvent.Type.MouseMove:
                pos = self.graphics_view.mapToScene(event.position().toPoint())
                self.on_mouse_move(pos)
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    pos = self.graphics_view.mapToScene(event.position().toPoint())
                    self.on_mouse_click(pos)
            elif event.type() == QEvent.Type.Enter:
                # Optionally, set the cursor to ArrowCursor when entering
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
            elif event.type() == QEvent.Type.Leave:
                self.graphics_view.unsetCursor()
        return super().eventFilter(source, event)

    def on_mouse_move(self, pos):
        """
        Handle mouse move events to display a dynamic circle indicating the blemish removal radius.

        Args:
            pos (QPointF): The position of the mouse in scene coordinates.
        """
        x, y = pos.x(), pos.y()
        self.current_x, self.current_y = x, y

        radius = self.radius_slider.value()

        # Update the circle's position and size
        self.circle_item.setRect(x - radius, y - radius, 2 * radius, 2 * radius)
        self.circle_item.setVisible(True)

        # Detect if cursor is over scroll bars
        viewport_pos = self.graphics_view.mapFromScene(pos)
        scrollbar_over = False

        # Check horizontal scroll bar
        h_scrollbar = self.graphics_view.horizontalScrollBar()
        if h_scrollbar.isVisible():
            h_scrollbar_rect = h_scrollbar.geometry()
            if h_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Check vertical scroll bar
        v_scrollbar = self.graphics_view.verticalScrollBar()
        if v_scrollbar.isVisible():
            v_scrollbar_rect = v_scrollbar.geometry()
            if v_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Update cursor based on position
        if scrollbar_over:
            if self.cursor_over_scrollbar:
                # Already over scrollbar, no action needed
                pass
            else:
                # Now over scrollbar
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = True
        else:
            if self.cursor_over_scrollbar:
                # Moved away from scrollbar, set default cursor
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = False
            else:
                # Already using default cursor, no action needed
                pass
            
    def on_mouse_click(self, pos):
        """
        Handle mouse press events to remove blemishes on click.

        Args:
            pos (QPointF): The position of the mouse click in scene coordinates.
        """
        x, y = int(pos.x()), int(pos.y())

        # Validate coordinates
        if 0 <= x < self.image.shape[1] and 0 <= y < self.image.shape[0]:
            radius = self.radius_slider.value()
            feather = self.feather_slider.value() / 100.0
            opacity = self.opacity_slider.value() / 100.0

            # Determine channels to process based on image dimensionality
            if self.image.ndim == 2:
                channels_to_process = [0]  # Single channel
            elif self.image.ndim == 3:
                channels_to_process = [0, 1, 2]  # RGB channels
            else:
                QMessageBox.warning(self, "Unsupported Image", "Image format not supported for blemish removal.")
                return

            # Start the blemish removal in a separate thread
            worker = BlemishBlasterWorker(
                image=self.image.copy(),  # Pass the current image from ImageManager
                x=x,
                y=y,
                radius=radius,
                feather=feather,
                opacity=opacity,
                channels_to_process=[0, 1, 2]  # RGB channels
            )
            worker.signals.finished.connect(self.on_processing_finished)
            self.threadpool.start(worker)

            self.setEnabled(False)  # Disable the dialog to prevent multiple clicks
            print(f"Started blemish removal at ({x}, {y}) with radius {radius}, feathering {feather}, opacity {opacity}.")

    def on_processing_finished(self, corrected_image):
        """
        Slot to handle the completion of blemish removal.

        Args:
            corrected_image (np.ndarray): The image after blemish removal.
        """
        # Push the current image to the undo stack before updating
        self.undo_stack.append(self.image.copy())
        # Clear the redo stack as new action invalidates future redos
        self.redo_stack.clear()

        # Update the local image with the corrected image
        self.image = corrected_image.copy()
        self.display_image = self.image.copy()
        self.update_display_image()

        self.setEnabled(True)  # Re-enable the dialog
        print("Blemish removal completed.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image

    def autostretch_image(self):
        """Handle the Autostretch button click to stretch or unstretch the image."""
        if not self.is_stretched:
            # Perform stretching
            stretched_image = self.stretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = stretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = True
            self.autostretch_button.setText("Remove Stretch")
            print("Image stretched.")
        else:
            # Optionally, allow removing stretch before applying changes
            # Uncomment the following lines if you want to allow removing stretch manually
            unstretched_image = self.unstretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = unstretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = False
            self.autostretch_button.setText("Autostretch")
            print("Stretch removed.")


    def apply_changes(self):
        """Apply all changes by pushing the final image to the ImageManager."""
        try:
            # If the image is stretched, unstretch it before applying
            if self.is_stretched:
                self.image = self.unstretch_image(self.image)
                self.display_image = self.image.copy()
                self.update_display_image()
                self.is_stretched = False
                self.autostretch_button.setText("Autostretch")
                print("Image unstretched before applying changes.")

            current_slot = self.image_manager.current_slot
            existing_metadata = self.image_manager._metadata.get(current_slot, {}).copy()

            # Ensure 'notes' exists and is a list
            if 'notes' in existing_metadata and isinstance(existing_metadata['notes'], list):
                existing_metadata['notes'].append("Blemish removed using Blemish Blaster.")
                print("Appended blemish removal note to existing metadata.")
            else:
                existing_metadata['notes'] = ["Blemish removed using Blemish Blaster."]
                print("Initialized blemish removal note in metadata.")

            # Push the updated image and metadata to the ImageManager
            self.image_manager.set_image(self.image.copy(), metadata=existing_metadata, step_name="blemish_blaster")
            self.blemish_removed.emit(self.image_manager.image)

            # Clear the undo and redo stacks as changes are now applied
            self.undo_stack.clear()
            self.redo_stack.clear()


            self.accept()
            print("Applied changes to ImageManager.")

        except Exception as e:
            QMessageBox.critical(
                self,
                "Apply Changes Error",
                f"An error occurred while applying changes:\n{str(e)}"
            )
            print(f"ERROR in apply_changes: {e}")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """Zoom in the image by a predefined step."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed in to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        """Zoom out the image by a predefined step."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed out to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def apply_zoom(self):
        """Apply the current zoom factor to the QGraphicsView."""
        self.graphics_view.resetTransform()  # Reset any existing transformations
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def reset_zoom(self):
        """Reset zoom to the default factor (100%)."""
        self.zoom_factor = 1.0
        self.apply_zoom()
        self.zoom_label.setText("100%")
        print("Zoom reset to 100%.")

    def update_display_image(self):
        """Update the display image from the local image and refresh the pixmap."""
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))
        # Optionally, clear the correction circle
        self.circle_item.setVisible(False)

    def closeEvent(self, event):

        super().closeEvent(event)

class PolyGradientRemoval:
    """
    A headless class that replicates the polynomial background removal
    logic from GradientRemovalDialog, minus the RBF step and UI code.

    Flow:
      1) Stretch the image (unlinked linear stretch).
      2) Downsample.
      3) Build an exclusion mask that:
         - Skips zero-valued pixels in any channel.
         - Optionally skip user-specified mask areas if desired (can pass mask to process()).
      4) Generate sample points from corners, borders, quartiles, do gradient_descent_to_dim_spot, skip bright areas.
      5) Fit a polynomial background and subtract it.
      6) Re-normalize median, clip to [0..1].
      7) Unstretch the final image back to the original domain.
    """

    def __init__(
        self,
        image: np.ndarray,
        poly_degree: int = 2,
        downsample_scale: int = 5,
        num_sample_points: int = 100
    ):
        """
        Args:
            image (np.ndarray): Input image in [0..1], shape (H,W) or (H,W,3), float32 recommended.
            poly_degree (int): Polynomial degree (1=linear,2=quadratic).
            downsample_scale (int): Factor for area downsampling.
            num_sample_points (int): Number of sample points to generate.
        """
        self.image = image.copy()
        self.poly_degree = poly_degree
        self.downsample_scale = downsample_scale
        self.num_sample_points = num_sample_points

        # For the stretch/unstretch logic
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False

    def process(self, user_exclusion_mask: np.ndarray = None) -> np.ndarray:
        """
        Main pipeline to remove polynomial gradient. 
        user_exclusion_mask: optional (H,W) boolean array, False => skip those pixels.
        
        Returns the final corrected image in the original brightness domain.
        """
        # 1) Stretch
        stretched = self.pixel_math_stretch(self.image)
        print("stretching")

        # 2) Downsample
        small_stretched = self.downsample_image(stretched, self.downsample_scale)
        h_s, w_s = small_stretched.shape[:2]
        print("downsampling")

        # 3) Build an exclusion mask in the small domain that:

        # 4) Generate sample points from corners/borders/quartiles
        sample_points = generate_sample_points(
            small_stretched,
            num_points=self.num_sample_points
        )
        print("sample points generated")

        # 5) Fit polynomial on the downsampled image
        poly_background_small = self.fit_polynomial_gradient(
            small_stretched, sample_points, degree=self.poly_degree
        )
        print("fit poly")

        # Upscale background to full size
        poly_background = self.upscale_background(
            poly_background_small, stretched.shape[:2]
        )
        print("upscale")

        # Subtract
        after_poly = stretched - poly_background
        print("subtracted")

        # Re-normalize median to original
        original_median = np.median(stretched)
        after_poly = self.normalize_image(after_poly, original_median)
        print("normalized")

        # Clip
        after_poly = np.clip(after_poly, 0, 1)

        # 6) Unstretch
        corrected = self.unstretch_image(after_poly)

        return corrected

    # ---------------------------------------------------------------
    # Helper: Stretch / Unstretch
    # ---------------------------------------------------------------
    def pixel_math_stretch(self, image: np.ndarray) -> np.ndarray:
        """
        Unlinked linear stretch using your existing Numba functions.

        Steps:
        1) If single-channel, replicate to 3-ch so we can store stats & do consistent logic.
        2) For each channel c: subtract the channel's min => data is >= 0.
        3) Compute the median after min subtraction for that channel.
        4) Call the appropriate Numba function:
            - If single-channel (was originally 1-ch), call numba_mono_final_formula
            on the 1-ch array.
            - If 3-ch color, call numba_color_final_formula_unlinked.
        5) Clip to [0,1].
        6) Store self.stretch_original_mins / medians so we can unstretch later.
        """
        target_median = 0.25

        # 1) Handle single-channel => replicate to 3 channels
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            self.was_single_channel = True
            image_3ch = np.stack([image.squeeze()] * 3, axis=-1)
        else:
            self.was_single_channel = False
            image_3ch = image

        image_3ch = image_3ch.astype(np.float32, copy=True)

        H, W, C = image_3ch.shape
        # We assume C=3 now.

        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # 2) Subtract min per channel
        for c in range(C):
            cmin = image_3ch[..., c].min()
            image_3ch[..., c] -= cmin
            self.stretch_original_mins.append(float(cmin))

        # 3) Compute median after min subtraction
        medians_after_sub = []
        for c in range(C):
            cmed = float(np.median(image_3ch[..., c]))
            medians_after_sub.append(cmed)
        self.stretch_original_medians = medians_after_sub

        # 4) Apply the final formula with your Numba functions
        if self.was_single_channel:
            # If originally single-channel, let's do a single pass with numba_mono_final_formula
            # on the single channel. We can do that by extracting one channel from image_3ch.
            # Then replicate the result to 3 channels, or keep it as 1-ch?
            # Typically we keep it as 1-ch in the end, so let's do that.

            # We'll just pick channel 0, run the mono formula, store it back in a 2D array.
            mono_array = image_3ch[..., 0]  # shape (H,W)
            cmed = medians_after_sub[0]     # The median for that channel
            # We call the numba function
            stretched_mono = numba_mono_final_formula(mono_array, cmed, target_median)

            # Now place it back into image_3ch for consistency
            for c in range(3):
                image_3ch[..., c] = stretched_mono
        else:
            # 3-channel unlinked
            medians_rescaled = np.array(medians_after_sub, dtype=np.float32)
            # 'image_3ch' is our 'rescaled'
            stretched_3ch = numba_color_final_formula_unlinked(
                image_3ch, medians_rescaled, target_median
            )
            image_3ch = stretched_3ch

        # 5) Clip to [0..1]
        np.clip(image_3ch, 0.0, 1.0, out=image_3ch)
        image = image_3ch
        return image


    def unstretch_image(self, image: np.ndarray) -> np.ndarray:
        """
        Calls the Numba-optimized unstretch function.
        """
        image = image.astype(np.float32, copy=True)

        # Convert lists to NumPy arrays for efficient Numba processing
        stretch_original_medians = np.array(self.stretch_original_medians, dtype=np.float32)
        stretch_original_mins = np.array(self.stretch_original_mins, dtype=np.float32)

        # Call the Numba function
        unstretched = numba_unstretch(image, stretch_original_medians, stretch_original_mins)

        if self.was_single_channel:
            # Convert back to grayscale
            unstretched = np.mean(unstretched, axis=2, keepdims=True)

        return unstretched


    # ---------------------------------------------------------------
    # Helper: Downsample
    # ---------------------------------------------------------------
    def downsample_image(self, image: np.ndarray, scale: int=6) -> np.ndarray:
        """
        Downsamples with area interpolation.
        """
        h, w = image.shape[:2]
        new_w = max(1, w//scale)
        new_h = max(1, h//scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)



    # ---------------------------------------------------------------
    # 5) Fit Polynomial
    # ---------------------------------------------------------------
    def fit_polynomial_gradient(self, image: np.ndarray, sample_points: np.ndarray, degree: int = 2, patch_size: int = 15) -> np.ndarray:
        """
        Optimized polynomial background fitting.
        - Extracts sample points using vectorized NumPy median calculations.
        - Solves for polynomial coefficients in parallel.
        - Precomputes polynomial basis terms for efficiency.
        """

        H, W = image.shape[:2]
        half_patch = patch_size // 2
        num_samples = len(sample_points)

        # Convert sample points to NumPy arrays
        sample_points = np.array(sample_points, dtype=np.int32)
        x_coords, y_coords = sample_points[:, 0], sample_points[:, 1]

        # Precompute polynomial design matrix
        A = build_poly_terms(x_coords, y_coords, degree)

        # Extract sample values efficiently
        if image.ndim == 3 and image.shape[2] == 3:
            # Color image
            background = np.zeros_like(image, dtype=np.float32)
            for c in range(3):
                # Extract patches and compute medians using vectorized NumPy operations
                z_vals = np.array([
                    np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                    max(0, x-half_patch):min(W, x+half_patch+1), c])
                    for x, y in zip(x_coords, y_coords)
                ], dtype=np.float32)

                # Solve for polynomial coefficients
                coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

                # Generate full polynomial background
                background[..., c] = evaluate_polynomial(H, W, coeffs, degree)

        else:
            # Grayscale image
            background = np.zeros((H, W), dtype=np.float32)

            z_vals = np.array([
                np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                max(0, x-half_patch):min(W, x+half_patch+1)])
                for x, y in zip(x_coords, y_coords)
            ], dtype=np.float32)

            # Solve for polynomial coefficients
            coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

            # Generate full polynomial background
            background = evaluate_polynomial(H, W, coeffs, degree)

        return background
    # ---------------------------------------------------------------
    # 6) Upscale
    # ---------------------------------------------------------------
    def upscale_background(self, background: np.ndarray, out_shape: tuple) -> np.ndarray:
        """
        Resizes 'background' to out_shape=(H,W) using OpenCV interpolation.
        """
        oh, ow = out_shape

        if background.ndim == 3 and background.shape[2] == 3:
            # Resizing each channel efficiently without looping in Python
            return np.stack([cv2.resize(background[..., c], (ow, oh), interpolation=cv2.INTER_LANCZOS4)
                            for c in range(3)], axis=-1)
        else:
            return cv2.resize(background, (ow, oh), interpolation=cv2.INTER_LANCZOS4).astype(np.float32)
    # ---------------------------------------------------------------
    # 7) Normalize
    # ---------------------------------------------------------------
    def normalize_image(self, image: np.ndarray, target_median: float) -> np.ndarray:
        """
        Shift image so its median matches target_median.
        """
        cmed = np.median(image)
        diff = target_median - cmed
        return image + diff

class CustomDoubleSpinBox(QWidget):
    valueChanged = pyqtSignal(float)

    def __init__(self, minimum=0.0, maximum=10.0, initial=0.0, step=0.1, parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial

        # Create a line edit with a double validator.
        self.lineEdit = QLineEdit(f"{initial:.3f}")
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)
        validator = QDoubleValidator(self.minimum, self.maximum, 3, self)
        validator.setNotation(QDoubleValidator.Notation.StandardNotation)
        self.lineEdit.setValidator(validator)
        self.lineEdit.editingFinished.connect(self.onEditingFinished)

        # Create up and down buttons.
        self.upButton = QToolButton()
        self.upButton.setText("▲")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton = QToolButton()
        self.downButton.setText("▼")
        self.downButton.clicked.connect(self.decreaseValue)

        # Arrange buttons vertically.
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Arrange the line edit and button layout horizontally.
        mainLayout = QHBoxLayout()
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        mainLayout.setSpacing(0)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def onEditingFinished(self):
        try:
            new_val = float(self.lineEdit.text())
        except ValueError:
            new_val = self._value
        self.setValue(new_val)

    def setValue(self, val: float):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if abs(val - self._value) > 1e-9:
            self._value = val
            self.lineEdit.setText(f"{val:.3f}")
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def value(self) -> float:
        return self._value

class CustomSpinBox(QWidget):
    """
    A simple custom spin box that mimics QSpinBox functionality.
    Emits valueChanged(int) when the value changes.
    """
    valueChanged = pyqtSignal(int)

    def __init__(self, minimum=0, maximum=100, initial=0, step=1, parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial

        # Create a line edit to show the value.
        self.lineEdit = QLineEdit(str(initial))
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)
        # Optionally, restrict input to integers using a validator.
        from PyQt6.QtGui import QIntValidator
        self.lineEdit.setValidator(QIntValidator(self.minimum, self.maximum, self))
        self.lineEdit.editingFinished.connect(self.editingFinished)

        # Create up and down buttons with arrow text or icons.
        self.upButton = QToolButton()
        self.upButton.setText("▲")
        self.downButton = QToolButton()
        self.downButton.setText("▼")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton.clicked.connect(self.decreaseValue)

        # Arrange the buttons vertically.
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Arrange the line edit and buttons horizontally.
        mainLayout = QHBoxLayout()
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        mainLayout.setSpacing(0)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    @property
    def value(self):
        return self._value

    def setValue(self, val):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if val != self._value:
            self._value = val
            self.lineEdit.setText(str(val))
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def editingFinished(self):
        try:
            newVal = int(self.lineEdit.text())
        except ValueError:
            newVal = self._value
        self.setValue(newVal)

class GradientRemovalDialog(QDialog):
    # Define signals to communicate with AstroEditingSuite
    processing_completed = pyqtSignal(np.ndarray, np.ndarray, bool, str)  # Corrected Image, Gradient Background

    def __init__(self, image, parent=None):
        """
        Initializes the GradientRemoval dialog.

        Args:
            image: Original image as a NumPy array (float32, normalized 0-1).
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Gradient Removal")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowMaximizeButtonHint)
        self.image = image.copy()  # Original image (float32, 0-1)
        self.exclusion_polygons = []  # List of polygons (each polygon is a list of QPoint)
        self.drawing = False
        self.current_polygon = []

        # Initialize parameters with default values
        self.num_sample_points = 100
        self.poly_degree = 2
        self.rbf_smooth = 0.1
        self.show_gradient = False

        # Downsample scale factor (can be made user-definable if needed)
        self.downsample_scale = 4
        self.save_to_slot_1 = False

        # Calculate scale factor to fit image within max_display_size
        original_height, original_width = self.image.shape[:2]
        max_display_size = (800, 600)
        max_width, max_height = max_display_size

        scale_w = max_width / original_width
        scale_h = max_height / original_height
        scale = min(scale_w, scale_h, 1.0)  # Prevent upscaling if image is smaller
        self.scale_factor = scale

        scaled_width = int(original_width * scale)
        scaled_height = int(original_height * scale)

        # Prepare display image (same for grayscale or color)
        display_image = (self.image * 255).astype(np.uint8)
        display_image = cv2.resize(display_image, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)

        # Convert to QImage
        if display_image.ndim == 2:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_Grayscale8)
        else:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_RGB888)

        # Set up QGraphicsScene and QGraphicsView for consistent coordinate mapping
        self.scene = QGraphicsScene(self)
        self.pixmap_item = QGraphicsPixmapItem(QPixmap.fromImage(q_img))
        self.scene.addItem(self.pixmap_item)

        self.view = QGraphicsView(self.scene, self)
        self.view.setRenderHints(QPainter.RenderHint.Antialiasing | QPainter.RenderHint.SmoothPixmapTransform)
        self.view.setAlignment(Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignLeft)
        self.view.setDragMode(QGraphicsView.DragMode.NoDrag)
        self.view.viewport().installEventFilter(self)  # Install event filter on the viewport

        # Set up controls (you can leave your setup_controls() largely unchanged)
        self.setup_controls()

        # Layout
        main_layout = QHBoxLayout()
        main_layout.addWidget(self.view, 1)
        controls_widget = QWidget()
        controls_layout = QVBoxLayout()
        controls_layout.addWidget(self.controls_groupbox)
        controls_layout.addStretch(1)
        self.status_label = QLabel("Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        controls_layout.addWidget(self.status_label)
        controls_widget.setLayout(controls_layout)
        controls_widget.setFixedWidth(300)
        main_layout.addWidget(controls_widget, 0)
        self.setLayout(main_layout)
        self.setMinimumSize(1000, 700)

        # For later use, we keep the original (full-resolution) image and store a scaling factor.
        # Here, self.display_scale is used to display the image. When processing, you work with self.image.
        self.thread = None
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        QTimer.singleShot(0, lambda: self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio))


    def setup_controls(self):
        """
        Sets up the user controls for parameters.
        """
        self.controls_groupbox = QGroupBox("Parameters")
        form_layout = QFormLayout()

        # Number of sample points
        self.sample_points_spinbox = CustomSpinBox(minimum=10, maximum=1000, initial=self.num_sample_points, step=10)
        self.sample_points_spinbox.valueChanged.connect(self.update_num_sample_points)
        form_layout.addRow("Number of Sample Points:", self.sample_points_spinbox)

        # Polynomial degree
        self.poly_degree_spinbox = CustomSpinBox(minimum=1, maximum=10, initial=self.poly_degree, step=1)
        self.poly_degree_spinbox.valueChanged.connect(self.update_poly_degree)
        form_layout.addRow("Polynomial Degree:", self.poly_degree_spinbox)

        # RBF smoothing using CustomDoubleSpinBox
        self.rbf_smooth_spinbox = CustomDoubleSpinBox(minimum=0.0, maximum=10.0, initial=self.rbf_smooth, step=0.1)
        self.rbf_smooth_spinbox.valueChanged.connect(self.update_rbf_smooth)
        form_layout.addRow("RBF Smoothness:", self.rbf_smooth_spinbox)

        # Show gradient removal
        self.show_gradient_checkbox = QCheckBox("Show Gradient Removed")
        self.show_gradient_checkbox.stateChanged.connect(self.update_show_gradient)
        form_layout.addRow(self.show_gradient_checkbox)

        # **New: Slot Selection Dropdown**
        self.save_slot_dropdown = QComboBox()
        self.save_slot_dropdown.addItems(["Slot 1", "Slot 2", "Slot 3", "Slot 4", "Slot 5", "Slot 6", "Slot 7", "Slot 8", "Slot 9"])  # Example slot choices
        form_layout.addRow("Save Gradient To:", self.save_slot_dropdown)

        # Add AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.setStatusTip("Apply auto-stretch to the displayed image")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow(self.autostretch_button)

        # Clear Drawn Exclusion Areas button
        self.clear_exclusion_button = QPushButton("Clear Exclusion Areas")
        self.clear_exclusion_button.setStatusTip("Clear all drawn exclusion areas")
        self.clear_exclusion_button.clicked.connect(self.clear_exclusion_areas)
        form_layout.addRow(self.clear_exclusion_button)

        # Process button
        self.process_button = QPushButton("Process")
        self.process_button.clicked.connect(self.process_image)
        form_layout.addRow(self.process_button)

        # Instruction for Exclusion Zones
        instructions = QLabel("Draw exclusion zones by clicking and dragging on the image.\n"
                            "Press 'Enter' to finalize each polygon.")
        form_layout.addRow(instructions)

        self.controls_groupbox.setLayout(form_layout)

    def autostretch_image(self):
        """
        Applies auto-stretch to the displayed image without affecting the original image.
        """
        # Stretch the original image for display
        stretched_image = siril_style_autostretch(self.image)

        # Get the current pixmap size from the pixmap_item.
        current_pixmap = self.pixmap_item.pixmap()
        scaled_width = current_pixmap.width()
        scaled_height = current_pixmap.height()

        # Prepare display image (convert from float32 [0,1] to uint8)
        display_image = (stretched_image * 255).astype(np.uint8)

        # Resize for display
        display_image = cv2.resize(
            display_image,
            (scaled_width, scaled_height),
            interpolation=cv2.INTER_AREA,
        )

        # Convert to QImage based on whether image is grayscale or color
        if display_image.ndim == 2:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_Grayscale8,
            )
        else:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_RGB888,
            )

        # Update the pixmap with the stretched image
        stretched_pixmap = QPixmap.fromImage(q_img)
        self.pixmap_item.setPixmap(stretched_pixmap)
        # Optionally, re-fit the view:
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)


    def eventFilter(self, source, event):
        if source is self.view.viewport():
            if event.type() == QEvent.Type.KeyPress:
                # Finalize current polygon on Enter key
                if event.key() == Qt.Key.Key_Return or event.key() == Qt.Key.Key_Enter:
                    if self.current_polygon:
                        self.exclusion_polygons.append(self.current_polygon.copy())
                        self.current_polygon = []
                        self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    # Map the mouse position directly to scene coordinates
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon = [scene_point]
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    # Finalize polygon automatically (or wait for Enter if you prefer)
                    self.exclusion_polygons.append(self.current_polygon.copy())
                    self.current_polygon = []
                    self.update_selection()
                    return True
        return super().eventFilter(source, event)

    def update_selection(self):
        """
        Redraws the pixmap with the exclusion polygons overlaid.
        The polygons are stored in scene coordinates.
        """
        # Start by resetting the pixmap item to the original display image.
        # (Since we're working in scene coordinates, we don't need to re-scale manually.)
        self.pixmap_item.setPixmap(self.pixmap_item.pixmap())

        # Create an overlay pixmap
        overlay = QPixmap(self.pixmap_item.pixmap().size())
        overlay.fill(Qt.GlobalColor.transparent)
        painter = QPainter(overlay)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # Draw finalized polygons in green (semi-transparent)
        QPen_pen = QPen(QColor(0, 255, 0), 2)
        QPen_brush = QColor(0, 255, 0, 50)
        painter.setPen(QPen_pen)
        painter.setBrush(QPen_brush)
        for polygon in self.exclusion_polygons:
            # Convert list of QPointF to QPolygonF and draw it
            poly = QPolygonF(polygon)
            painter.drawPolygon(poly)

        # Draw current (in-progress) polygon in red dashed outline
        if self.drawing and len(self.current_polygon) > 1:
            pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.setBrush(Qt.BrushStyle.NoBrush)
            poly = QPolygonF(self.current_polygon)
            painter.drawPolyline(poly)

        painter.end()

        # Create a new QGraphicsPixmapItem for the overlay and add it on top of the image.
        # Remove any existing overlay items.
        for item in self.scene.items():
            if isinstance(item, QGraphicsPixmapItem) and item != self.pixmap_item:
                self.scene.removeItem(item)
        overlay_item = QGraphicsPixmapItem(overlay)
        overlay_item.setZValue(1)  # Ensure it is on top
        self.scene.addItem(overlay_item)


    def clear_exclusion_areas(self):
        """Clears all drawn exclusion polygons."""
        self.exclusion_polygons = []
        self.current_polygon = []
        self.update_selection()


    def update_num_sample_points(self, value):
        self.num_sample_points = value

    def update_poly_degree(self, value):
        self.poly_degree = value

    def update_rbf_smooth(self, value):
        self.rbf_smooth = value

    def update_show_gradient(self, state):
        self.show_gradient = state == Qt.CheckState.Checked

    def mouse_press_event(self, event):
        """
        Handles the mouse press event to initiate drawing.
        Converts the event's position (in label coordinates) to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            # The label's current pixmap is the scaled (displayed) image.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            # Map the mouse position to base coordinates.
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.drawing = True
            self.current_polygon = [base_point]
            self.update_selection()

    def mouse_move_event(self, event):
        """
        Handles the mouse move event to update the current polygon being drawn.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if self.drawing:
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.update_selection()

    def mouse_release_event(self, event):
        """
        Handles the mouse release event to finalize the polygon.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton and self.drawing:
            # Optionally, update with the final point.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.drawing = False
            # Store the polygon (which is in base coordinates)
            self.exclusion_polygons.append(QPolygon(self.current_polygon))
            self.current_polygon = []
            self.update_selection()



    def process_image(self):
        """
        Processes the image to subtract the background in two stages:
        1. Polynomial gradient removal.
        2. RBF gradient removal.
        """
        # Disable the process button to prevent multiple clicks
        self.save_to_slot_1 = self.show_gradient_checkbox.isChecked()
        self.process_button.setEnabled(False)

        # Stretch the image before processing
        self.status_label.setText("Normalizing image for processing...")
        QApplication.processEvents()
        stretched_image = self.stretch_image(self.image)

        # Check if the image is color
        is_color = len(stretched_image.shape) == 3

        # Store original median
        original_median = np.median(stretched_image)

        # Create exclusion mask
        exclusion_mask = self.create_exclusion_mask(stretched_image.shape, self.exclusion_polygons) if self.exclusion_polygons else None

        # ------------------ First Stage: Polynomial Gradient Removal ------------------
        self.status_label.setText("Step 1: Polynomial Gradient Removal")
        QApplication.processEvents()
        # Downsample for polynomial background fitting
        small_image_poly = self.downsample_image(stretched_image, self.downsample_scale)

        # Create a downsampled exclusion mask for polynomial fitting
        if exclusion_mask is not None:
            small_exclusion_mask_poly = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_poly = None

        # Generate sample points for polynomial fitting with exclusions
        poly_sample_points = self.generate_sample_points(
            small_image_poly, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_poly
        )

        # Fit the polynomial gradient
        if is_color:
            poly_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                poly_bg_channel = self.fit_polynomial_gradient(
                    small_image_poly[:, :, channel], poly_sample_points, degree=self.poly_degree
                )
                poly_background[:, :, channel] = self.upscale_background(poly_bg_channel, stretched_image.shape[:2])
        else:
            poly_background_small = self.fit_polynomial_gradient(small_image_poly, poly_sample_points, degree=self.poly_degree)
            poly_background = self.upscale_background(poly_background_small, stretched_image.shape[:2])

        # Subtract the polynomial background
        image_after_poly = stretched_image - poly_background

        # Normalize to restore original median
        image_after_poly = self.normalize_image(image_after_poly, original_median)

        # Clip the values to valid range
        image_after_poly = np.clip(image_after_poly, 0, 1)

        # ------------------ Second Stage: RBF Gradient Removal ------------------
        self.status_label.setText("Step 2: RBF Gradient Removal")
        QApplication.processEvents()
        # Downsample the image after polynomial removal for RBF fitting
        small_image_rbf = self.downsample_image(image_after_poly, self.downsample_scale)

        # Create a downsampled exclusion mask for RBF fitting
        if exclusion_mask is not None:
            small_exclusion_mask_rbf = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_rbf = None

        # Generate sample points for RBF fitting with exclusions
        rbf_sample_points = self.generate_sample_points(
            small_image_rbf, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_rbf
        )

        # Fit the RBF gradient
        if is_color:
            rbf_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                rbf_bg_channel = self.fit_background(
                    small_image_rbf[:, :, channel], rbf_sample_points, smooth=self.rbf_smooth, patch_size=15
                )
                rbf_background[:, :, channel] = self.upscale_background(rbf_bg_channel, stretched_image.shape[:2])
        else:
            rbf_background_small = self.fit_background(small_image_rbf, rbf_sample_points, smooth=self.rbf_smooth, patch_size=15)
            rbf_background = self.upscale_background(rbf_background_small, stretched_image.shape[:2])

        # Subtract the RBF background
        corrected_image = image_after_poly - rbf_background

        # Normalize to restore original median
        corrected_image = self.normalize_image(corrected_image, original_median)

        # Clip the values to valid range
        corrected_image = np.clip(corrected_image, 0, 1)

        # Unstretch both the corrected image and the gradient background
        self.status_label.setText("De-Normalizing the processed images...")
        QApplication.processEvents()
        corrected_image = self.unstretch_image(corrected_image)
        total_background = poly_background + rbf_background
        gradient_background = self.unstretch_image(total_background)

                # Ensure both images are 3-channel RGB
        # Ensure both images are 3-channel RGB
        corrected_image = self.ensure_rgb(corrected_image)
        gradient_background = self.ensure_rgb(gradient_background)


        print("[DEBUG] Step 2 Completed.")

        # ------------------ Emit Results ------------------
        print("[DEBUG] Emitting results...")
        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()

        # Check if the user wants to save the gradient
        save_gradient = self.show_gradient_checkbox.isChecked()

        # Get the selected slot from the dropdown
        selected_slot = self.save_slot_dropdown.currentText()  # Example: "Slot 1"

        if save_gradient:
            print(f"[INFO] Saving extracted gradient to {selected_slot}")
        else:
            print("[INFO] User chose not to save the extracted gradient.")

        # Emit the processed images back to `AstroEditingSuite`
        self.processing_completed.emit(corrected_image, gradient_background, save_gradient, selected_slot)

        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()
        self.accept()

    # ------------------ Helper Functions ------------------
    # Ensure corrected_image and gradient_background are strictly 3-channel RGB
    def ensure_rgb(self,image):
        """
        Ensures the given image is 3-channel RGB.
        Args:
            image: The input NumPy array (can be 2D or 3D with a single channel).
        Returns:
            A 3D NumPy array with shape (height, width, 3).
        """
        if image.ndim == 2:  # Grayscale image
            return np.repeat(image[:, :, np.newaxis], 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:  # Single-channel image with an extra dimension
            return np.repeat(image, 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 3:  # Already RGB
            return image
        else:
            raise ValueError(f"Unexpected image shape: {image.shape}")




    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def downsample_image(self, image, scale=4):
        """
        Downsamples the image by the specified scale factor using area interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            scale: Downsampling scale factor.

        Returns:
            downsampled_image: Downsampled image.
        """
        new_size = (max(1, image.shape[1] // scale), max(1, image.shape[0] // scale))
        return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)

    def upscale_background(self, background, original_shape):
        """
        Upscales the background model to the original image size.

        Args:
            background: 2D NumPy array (single-channel background model).
            original_shape: Tuple of (height, width) for the target size.

        Returns:
            upscaled_background: Upscaled 2D background model.
        """
        if background.ndim == 2:
            # Single-channel (grayscale) input
            return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LANCZOS4)
        elif background.ndim == 3 and background.shape[2] == 1:
            # Ensure input shape is reduced to 2D for single-channel data
            background = background.squeeze()  # Remove singleton dimension

        return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LANCZOS4)



    def divide_into_quartiles(self, image):
        """
        Divides the image into four quartiles.

        Args:
            image: 2D/3D NumPy array of the image.

        Returns:
            quartiles: Dictionary containing quartile images.
        """
        h, w = image.shape[:2]
        half_h, half_w = h // 2, w // 2
        return {
            'top_left': image[:half_h, :half_w],
            'top_right': image[:half_h, half_w:],
            'bottom_left': image[half_h:, :half_w],
            'bottom_right': image[half_h:, half_w:],
        }

    def exclude_bright_regions(self, quartile, exclusion_fraction=0.5):
        """
        Excludes the brightest regions in a quartile based on the exclusion fraction.

        Args:
            quartile: 2D/3D NumPy array of the quartile image.
            exclusion_fraction: Fraction of the brightest pixels to exclude.

        Returns:
            mask: Boolean mask where True indicates eligible pixels.
        """
        flattened = quartile.flatten()
        threshold = np.percentile(flattened, 100 * (1 - exclusion_fraction))
        mask = quartile < threshold
        return mask

    def gradient_descent_to_dim_spot(self, image, x, y, max_iterations=100, patch_size=15):
        """
        Moves a point to a dimmer spot using gradient descent, considering the median of a patch.

        Args:
            image: 2D/3D NumPy array of the image.
            x, y: Initial coordinates of the point.
            max_iterations: Maximum number of descent steps.
            patch_size: Size of the square patch (e.g., 15 for a 15x15 patch).

        Returns:
            (x, y): Coordinates of the dimmest local spot found.
        """
        half_patch = patch_size // 2

        # Get image dimensions and convert to luminance if color
        if len(image.shape) == 3:
            h, w, _ = image.shape
            luminance = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            h, w = image.shape
            luminance = image

        for _ in range(max_iterations):
            # Define patch around the current point
            xmin, xmax = max(0, x - half_patch), min(w, x + half_patch + 1)
            ymin, ymax = max(0, y - half_patch), min(h, y + half_patch + 1)
            patch = luminance[ymin:ymax, xmin:xmax]
            current_value = np.median(patch)

            # Define a 3x3 window around the point
            neighbors = [
                (nx, ny) for nx in range(max(0, x - 1), min(w, x + 2))
                          for ny in range(max(0, y - 1), min(h, y + 2))
                          if (nx, ny) != (x, y)
            ]

            # Find the dimmest neighbor using patch medians
            def patch_median(coord):
                nx, ny = coord
                xmin_n, xmax_n = max(0, nx - half_patch), min(w, nx + half_patch + 1)
                ymin_n, ymax_n = max(0, ny - half_patch), min(h, ny + half_patch + 1)
                neighbor_patch = luminance[ymin_n:ymax_n, xmin_n:xmax_n]
                return np.median(neighbor_patch)

            dimmest_neighbor = min(neighbors, key=patch_median)
            dimmest_value = patch_median(dimmest_neighbor)

            # If the current point is already the dimmest, stop
            if dimmest_value >= current_value:
                break

            # Move to the dimmest neighbor
            x, y = dimmest_neighbor

        return x, y

    def fit_polynomial_gradient(self, image, sample_points, degree=2, patch_size=15):
        """
        Fits a polynomial gradient (up to the specified degree) to the image using sample points.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            degree: Degree of the polynomial (e.g., 1 for linear, 2 for quadratic).
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The polynomial gradient model across the image.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit polynomial model for this channel
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((x**i) * (y**j))
                A = np.column_stack(terms)
                coeffs, _, _, _ = np.linalg.lstsq(A, z, rcond=None)

                # Generate polynomial model
                xx, yy = np.meshgrid(np.arange(w), np.arange(h))
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((xx**i) * (yy**j))
                terms = np.array(terms)
                background[:, :, channel] = np.sum(coeffs[:, None, None] * terms, axis=0)
            return background
        else:  # Grayscale image
            return self.fit_polynomial_gradient(image[:, :, np.newaxis], sample_points, degree, patch_size)

    def generate_sample_points(self, image, num_points=100, exclusion_mask=None):
        """
        Generates sample points for gradient fitting, avoiding exclusion zones.

        Args:
            image: 2D/3D NumPy array of the image.
            num_points: Total number of sample points to generate.
            exclusion_mask: 2D boolean NumPy array where False indicates exclusion.

        Returns:
            points: NumPy array of shape (N, 2) with (x, y) coordinates.
        """
        h, w = image.shape[:2]
        points = []

        # Add border points: 1 in each corner and 5 along each border
        border_margin = 10

        # Corner points
        corners = [
            (border_margin, border_margin),                # Top-left
            (w - border_margin - 1, border_margin),        # Top-right
            (border_margin, h - border_margin - 1),        # Bottom-left
            (w - border_margin - 1, h - border_margin - 1) # Bottom-right
        ]
        for x, y in corners:
            if exclusion_mask is not None and not exclusion_mask[y, x]:
                continue
            x_new, y_new = self.gradient_descent_to_dim_spot(image, x, y)
            if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                continue
            points.append((x_new, y_new))

        # Top and bottom borders
        for x in np.linspace(border_margin, w - border_margin, 5, dtype=int):
            # Top border
            if exclusion_mask is not None and not exclusion_mask[border_margin, x]:
                continue
            x_top, y_top = self.gradient_descent_to_dim_spot(image, x, border_margin)
            if exclusion_mask is not None and not exclusion_mask[y_top, x_top]:
                continue
            points.append((x_top, y_top))
            # Bottom border
            if exclusion_mask is not None and not exclusion_mask[h - border_margin - 1, x]:
                continue
            x_bottom, y_bottom = self.gradient_descent_to_dim_spot(image, x, h - border_margin - 1)
            if exclusion_mask is not None and not exclusion_mask[y_bottom, x_bottom]:
                continue
            points.append((x_bottom, y_bottom))

        # Left and right borders
        for y in np.linspace(border_margin, h - border_margin, 5, dtype=int):
            # Left border
            if exclusion_mask is not None and not exclusion_mask[y, border_margin]:
                continue
            x_left, y_left = self.gradient_descent_to_dim_spot(image, border_margin, y)
            if exclusion_mask is not None and not exclusion_mask[y_left, x_left]:
                continue
            points.append((x_left, y_left))
            # Right border
            if exclusion_mask is not None and not exclusion_mask[y, w - border_margin - 1]:
                continue
            x_right, y_right = self.gradient_descent_to_dim_spot(image, w - border_margin - 1, y)
            if exclusion_mask is not None and not exclusion_mask[y_right, x_right]:
                continue
            points.append((x_right, y_right))

        # Add random points in eligible areas (using quartiles)
        quartiles = self.divide_into_quartiles(image)
        for key, quartile in quartiles.items():
            # Determine the coordinates of the quartile in the full image
            h_quart, w_quart = quartile.shape[:2]
            if "top" in key:
                y_start = 0
            else:
                y_start = h // 2
            if "left" in key:
                x_start = 0
            else:
                x_start = w // 2

            # Create local exclusion mask for the quartile
            if exclusion_mask is not None:
                quart_exclusion_mask = exclusion_mask[y_start:y_start + h_quart, x_start:x_start + w_quart]
            else:
                quart_exclusion_mask = None

            # Convert quartile to grayscale if it has multiple channels
            if quartile.ndim == 3:
                # Assuming the color channels are last, convert to luminance
                quartile_gray = np.dot(quartile[..., :3], [0.2989, 0.5870, 0.1140])
            else:
                quartile_gray = quartile

            # Exclude bright regions
            mask = self.exclude_bright_regions(quartile_gray, exclusion_fraction=0.5)
            if quart_exclusion_mask is not None:
                mask &= quart_exclusion_mask

            eligible_indices = np.argwhere(mask)

            if len(eligible_indices) == 0:
                continue  # Skip if no eligible points in this quartile

            # Ensure we don't request more points than available
            num_points_in_quartile = min(len(eligible_indices), self.num_sample_points // 4)
            selected_indices = eligible_indices[np.random.choice(len(eligible_indices), num_points_in_quartile, replace=False)]

            for idx in selected_indices:
                y_idx, x_idx = idx  # Unpack row to y, x
                y_coord = y_start + y_idx
                x_coord = x_start + x_idx

                # Apply gradient descent to move to a dimmer spot
                x_new, y_new = self.gradient_descent_to_dim_spot(image, x_coord, y_coord)

                # Check if the new point is in exclusion
                if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                    continue  # Skip points in exclusion areas

                points.append((x_new, y_new))

        return np.array(points)

    def fit_background(self, image, sample_points, smooth=0.1, patch_size=15):
        """
        Fits a background model using RBF interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            smooth: Smoothness parameter for the RBF fitting.
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The RBF-based background model.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit RBF for this channel
                rbf = Rbf(x, y, z, function='multiquadric', smooth=smooth, epsilon=1.0)
                grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
                background[:, :, channel] = rbf(grid_x, grid_y)
            return background
        else:  # Grayscale image
            return self.fit_background(image[:, :, np.newaxis], sample_points, smooth, patch_size)

    def calculate_median(self, values):
        """
        Calculates the median of the given values.

        Args:
            values: NumPy array of values.

        Returns:
            median: Median value.
        """
        return np.median(values)

    def calculate_mad(self, values, median):
        """
        Calculates the Median Absolute Deviation (MAD).

        Args:
            values: NumPy array of values.
            median: Median of the values.

        Returns:
            mad: Median Absolute Deviation.
        """
        deviations = np.abs(values - median)
        return np.median(deviations)

    def calculate_noise_weight(self, median, mad):
        """
        Calculates the noise weight based on median and MAD.

        Args:
            median: Median value.
            mad: Median Absolute Deviation.

        Returns:
            noise_weight: Noise weight (0.0 to 1.0).
        """
        if median == 0:
            median = 1e-6  # Avoid division by zero
        noise_factor = 1.0 - (mad / median)
        return max(0.0, min(1.0, noise_factor))

    def calculate_brightness_weight(self, avg_brightness, median_brightness):
        """
        Calculates the brightness weight based on average and median brightness.

        Args:
            avg_brightness: Average brightness of the patch.
            median_brightness: Median brightness of the patch.

        Returns:
            brightness_weight: Brightness weight (0.8 to 1.0).
        """
        if median_brightness == 0:
            median_brightness = 1e-6  # Avoid division by zero
        weight = 1.0 - abs(avg_brightness - median_brightness) / median_brightness
        return max(0.8, min(1.0, weight))  # Limit range for stability

    def calculate_spatial_weight(self, x, y, width, height):
        """
        Calculates the spatial weight based on the position of the point.

        Args:
            x: X-coordinate.
            y: Y-coordinate.
            width: Image width.
            height: Image height.

        Returns:
            spatial_weight: Spatial weight (0.95 to 1.0).
        """
        center_x = width / 2
        center_y = height / 2
        distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
        max_distance = np.sqrt(center_x ** 2 + center_y ** 2)
        normalized_distance = distance / max_distance
        return 0.95 + 0.05 * normalized_distance

    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with False in exclusion areas and True elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.ones(image_shape[:2], dtype=bool)  # Initialize all True

        if not exclusion_polygons:
            return mask  # No exclusions

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                # Scale back to original image coordinates
                x_original = point.x() / self.scale_factor
                y_original = point.y() / self.scale_factor
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Create a single-channel mask
        exclusion_mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Fill the polygons on the exclusion mask
        cv2.fillPoly(exclusion_mask, polygons, 1)  # 1 inside polygons

        # Update the main mask: False inside exclusion polygons
        mask[exclusion_mask == 1] = False

        return mask

    def normalize_image(self, image, target_median):
        """
        Normalizes the image so that its median matches the target median.

        Args:
            image: 2D/3D NumPy array of the image.
            target_median: The desired median value.

        Returns:
            normalized_image: The median-normalized image.
        """
        current_median = np.median(image)
        median_diff = target_median - current_median
        normalized_image = image + median_diff
        return normalized_image


class ImagePreview(QWidget):
    # Define a custom signal that emits the slot number
    closed = pyqtSignal(int)
    
    def __init__(self, image_data, slot, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        # Use the parent's custom slot name if available; otherwise default to "Slot {slot}"
        if parent is not None and hasattr(parent, 'slot_names'):
            custom_name = parent.slot_names.get(slot, f"Slot {slot}")
        else:
            custom_name = f"Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.image_data = image_data  # Numpy array containing the image
        self.zoom_factor = 1.0
        self.slot = slot
        self.is_autostretched = False  # Track if AutoStretch is applied
        self.stretched_image_data = None  # Store stretched image data for visual purposes

        # Create UI components
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidgetResizable(True)
        
        # Install event filter on the scroll area’s viewport
        self.scroll_area.viewport().installEventFilter(self)

        # Convert numpy image data to QImage and display it
        self.update_image_display()

        # Create Zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)  # Zoom range from 1% to 400%
        self.zoom_slider.setValue(100)  # Default zoom (100%)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(lambda: self.adjust_zoom(10))

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(lambda: self.adjust_zoom(-10))

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)

        # AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.clicked.connect(self.apply_autostretch)

        # Create the "Make Active" Button.
        # (We disable it if this slot is already active.)
        self.make_active_button = QPushButton("Make Active")
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            current_active_slot = self.parent().image_manager.current_slot
            if current_active_slot == self.slot:
                self.make_active_button.setEnabled(False)
        self.make_active_button.clicked.connect(self.make_slot_active)
        
        swap_layout = QHBoxLayout()
        swap_layout.addStretch()
        swap_layout.addWidget(self.make_active_button)

        # Layout for zoom controls
        zoom_layout = QHBoxLayout()
        zoom_layout.addWidget(self.zoom_out_button)
        zoom_layout.addWidget(self.zoom_slider)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.fit_to_preview_button)
        zoom_layout.addWidget(self.autostretch_button)

        # Main layout
        layout = QVBoxLayout(self)
        layout.addWidget(self.scroll_area)
        layout.addLayout(zoom_layout)
        layout.addLayout(swap_layout)  # Add swap button layout
        self.setLayout(layout)

        # Variables to handle panning
        self._panning = False
        self._pan_start_x = 0
        self._pan_start_y = 0

    def make_slot_active(self):
        """Sets this preview's slot as the active slot in the image manager."""
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            self.parent().image_manager.set_current_slot(self.slot)
            self.close()  # Optionally close the preview window after setting the active slot
        else:
            QMessageBox.critical(self, "Error", "Parent does not have an image manager.")

    def eventFilter(self, source, event):
        """
        Intercept events on the scroll area's viewport to implement panning and zooming.
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.Wheel:
                # When the wheel is scrolled, adjust zoom.
                if event.angleDelta().y() > 0:
                    self.adjust_zoom(10)  # Zoom in (increase slider value by 10)
                else:
                    self.adjust_zoom(-10)  # Zoom out (decrease slider value by 10)
                event.accept()
                return True  # Indicate the event has been handled.

            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = True
                    self._pan_start_x = event.position().x()
                    self._pan_start_y = event.position().y()
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseMove:
                if self._panning and (event.buttons() & Qt.MouseButton.LeftButton):
                    delta_x = event.position().x() - self._pan_start_x
                    delta_y = event.position().y() - self._pan_start_y
                    # Adjust scroll bars for panning.
                    new_h = self.scroll_area.horizontalScrollBar().value() - int(delta_x)
                    new_v = self.scroll_area.verticalScrollBar().value() - int(delta_y)
                    self.scroll_area.horizontalScrollBar().setValue(new_h)
                    self.scroll_area.verticalScrollBar().setValue(new_v)
                    # Update the start position.
                    self._pan_start_x = event.position().x()
                    self._pan_start_y = event.position().y()
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = False
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                    return True  # Event handled.
        return super().eventFilter(source, event)


    def apply_autostretch(self):
        """Applies AutoStretch to the displayed image for visualization."""
        if self.is_autostretched:
            # If already stretched, reset to the original image
            self.is_autostretched = False
            self.update_image_display()
        else:
            # Perform AutoStretch using the global stretch functions (target median = 0.25) and display it
            self.is_autostretched = True
            self.stretched_image_data = self.stretch_image(self.image_data)
            self.update_image_display()

    def stretch_image(self, image):
        """
        Apply the global stretch functions to the image with a target median of 0.25.
        For grayscale images, use stretch_mono_image.
        For color images, use stretch_color_image.
        """
        target_median = 0.25
        if image.ndim == 2:
            # Grayscale image
            return stretch_mono_image(image, target_median)
        elif image.ndim == 3:
            # Color image (assumes channels are in the last dimension)
            return stretch_color_image(image, target_median, linked=False)
        else:
            raise ValueError("Unsupported image dimensions: must be 2D or 3D")

    def update_image_display(self):
        """Update the QLabel with the current image."""
        # Choose the display image: either autostretched or the original.
        display_image = self.stretched_image_data if self.is_autostretched else self.image_data

        # Normalize image data if necessary
        if display_image.dtype != np.uint8:
            image_data_normalized = np.clip(display_image * 255, 0, 255).astype('uint8')
        else:
            image_data_normalized = display_image

        # Create QImage from the numpy array
        if len(image_data_normalized.shape) == 2:  # Grayscale image
            height, width = image_data_normalized.shape
            bytes_per_line = width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        elif len(image_data_normalized.shape) == 3 and image_data_normalized.shape[2] == 3:  # RGB image
            height, width, channels = image_data_normalized.shape
            bytes_per_line = 3 * width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            QMessageBox.warning(self, "Invalid Image", "Unsupported image format for display.")
            return

        # Convert to pixmap and store the original if not already stored
        pixmap = QPixmap.fromImage(qimage)
        self.original_pixmap = pixmap  # Always update to the current image


        # Scale from the original pixmap size using the current zoom factor
        scaled_pixmap = self.original_pixmap.scaled(
            self.original_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)


    def resizeEvent(self, event):
        """Ensure the image scales appropriately when the window is resized."""
        self.update_image_display()
        super().resizeEvent(event)

    def on_zoom_changed(self, value):
        """Handle changes in zoom slider."""
        self.zoom_factor = value / 100.0  # Convert slider value to zoom factor
        self.update_image_display()

    def adjust_zoom(self, delta):
        """Adjust zoom by a specified delta."""
        new_value = self.zoom_slider.value() + delta
        self.zoom_slider.setValue(max(1, min(400, new_value)))

    def fit_to_preview(self):
        """Fit the image to the preview window."""
        # Ensure we have the original pixmap
        if not hasattr(self, 'original_pixmap') or self.original_pixmap.isNull():
            return

        # Get available size from the scroll area's viewport
        available_size = self.scroll_area.viewport().size()
        pixmap_size = self.original_pixmap.size()

        # Calculate the zoom factor to fit the image
        zoom_factor_w = available_size.width() / pixmap_size.width()
        zoom_factor_h = available_size.height() / pixmap_size.height()
        self.zoom_factor = min(zoom_factor_w, zoom_factor_h)

        # Update the slider value accordingly (convert to percentage)
        self.zoom_slider.setValue(int(self.zoom_factor * 100))
        self.update_image_display()

    def swap_with_slot_zero(self):
        """Swap images between the current slot and Slot 0."""
        confirmation = QMessageBox.question(
            self,
            "Confirm Swap",
            f"Are you sure you want to swap Slot {self.slot} with Slot 0?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            # Debug: Print parent details
            print(f"Attempting to swap Slot {self.slot} with Slot 0.")
            print(f"Parent: {self.parent()}, Type: {type(self.parent())}")
            print(f"Does parent have 'swap_slots'? {'Yes' if hasattr(self.parent(), 'swap_slots') else 'No'}")
            
            # Call the swap_slots method in the parent (AstroEditingSuite)
            if self.parent() and hasattr(self.parent(), 'swap_slots'):
                self.parent().swap_slots(self.slot, 0)

                # Optionally, close the preview window after swapping
                self.close()
            else:
                QMessageBox.critical(self, "Error", "Parent does not have a swap_slots method.")
                print("Error: Parent does not have a swap_slots method.")

    def closeEvent(self, event):
        """Override the close event to emit the custom closed signal."""
        self.closed.emit(self.slot)  # Emit the slot number
        event.accept()  # Proceed with the standard close event

class GraXpertThread(QThread):
    """Thread to execute GraXpert commands."""
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        """Run the GraXpert command and capture output."""
        print(f"[DEBUG] Running command: {self.command}")
        if isinstance(self.command, list):
            print(f"[DEBUG] First item (executable): {self.command[0]}")

        # Copy the current environment and remove variables that might interfere.
        env = os.environ.copy()
        env.pop("PYTHONHOME", None)
        env.pop("PYTHONPATH", None)
        env.pop("DYLD_LIBRARY_PATH", None)
        env.pop("DYLD_FALLBACK_LIBRARY_PATH", None)
        env.pop("PYTHONEXECUTABLE", None)

        process = subprocess.Popen(
            self.command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            env=env,
            start_new_session=True
        )
        for line in process.stdout:
            self.stdout_signal.emit(line.strip())
        for line in process.stderr:
            self.stderr_signal.emit(line.strip())
        self.finished_signal.emit(process.wait())


class RGBCombinationDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.setWindowTitle("RGB Combination")
        self.setModal(True)
        self.image_manager = image_manager  # Reference to ImageManager
        
        self.r_image_path = None
        self.g_image_path = None
        self.b_image_path = None
        self.use_existing_slots = False

        # Retrieve slot_names from parent if available; otherwise use empty dict.
        if parent is not None and hasattr(parent, "slot_names"):
            self.slot_names = parent.slot_names
        else:
            self.slot_names = {}

        # Create UI components
        self.mode_label = QLabel("Select RGB Combination Mode:")
        
        # Radio buttons for mode selection
        self.load_files_radio = QRadioButton("Load Individual Files")
        self.use_slots_radio = QRadioButton("Use Existing Slots")
        self.load_files_radio.setChecked(True)  # Default mode
        
        # Button group to ensure only one radio button is selected
        self.mode_group = QButtonGroup()
        self.mode_group.addButton(self.load_files_radio)
        self.mode_group.addButton(self.use_slots_radio)
        self.mode_group.buttonClicked.connect(self.update_mode)
        
        # GroupBox for mode selection
        self.mode_groupbox = QGroupBox()
        mode_layout = QVBoxLayout()
        mode_layout.addWidget(self.load_files_radio)
        mode_layout.addWidget(self.use_slots_radio)
        self.mode_groupbox.setLayout(mode_layout)
        
        # Load File Mode Widgets
        self.load_r_button = QPushButton("Load Red Image")
        self.load_r_button.clicked.connect(self.load_r_image)
        
        self.load_g_button = QPushButton("Load Green Image")
        self.load_g_button.clicked.connect(self.load_g_image)
        
        self.load_b_button = QPushButton("Load Blue Image")
        self.load_b_button.clicked.connect(self.load_b_image)
        
        self.r_label = QLabel("Red Image: Not Selected")
        self.g_label = QLabel("Green Image: Not Selected")
        self.b_label = QLabel("Blue Image: Not Selected")
        
        # Layout for Load Files Mode
        self.load_files_layout = QVBoxLayout()
        self.load_files_layout.addWidget(self.r_label)
        self.load_files_layout.addWidget(self.load_r_button)
        self.load_files_layout.addWidget(self.g_label)
        self.load_files_layout.addWidget(self.load_g_button)
        self.load_files_layout.addWidget(self.b_label)
        self.load_files_layout.addWidget(self.load_b_button)
        
        # Use Existing Slots Mode Widgets: Three dropdowns for selecting slots for R, G, and B
        self.slots_selection_widget = QGroupBox("Select Slots for R, G, B")
        slots_layout = QHBoxLayout()
        # Red Slot ComboBox
        red_layout = QVBoxLayout()
        red_layout.addWidget(QLabel("Red Slot:"))
        self.red_slot_combo = QComboBox()
        red_layout.addWidget(self.red_slot_combo)
        slots_layout.addLayout(red_layout)
        # Green Slot ComboBox
        green_layout = QVBoxLayout()
        green_layout.addWidget(QLabel("Green Slot:"))
        self.green_slot_combo = QComboBox()
        green_layout.addWidget(self.green_slot_combo)
        slots_layout.addLayout(green_layout)
        # Blue Slot ComboBox
        blue_layout = QVBoxLayout()
        blue_layout.addWidget(QLabel("Blue Slot:"))
        self.blue_slot_combo = QComboBox()
        blue_layout.addWidget(self.blue_slot_combo)
        slots_layout.addLayout(blue_layout)
        self.slots_selection_widget.setLayout(slots_layout)
        
        # Populate the slot dropdowns.
        # Use the image_manager.max_slots if available; for each slot, try to get the name from self.slot_names.
        if self.image_manager is not None and hasattr(self.image_manager, "max_slots"):
            for i in range(self.image_manager.max_slots):
                # Use the stored name if available; note that your rgb_extract stores names keyed by slot number.
                display_text = self.slot_names.get(i, f"Slot {i + 1}")
                self.red_slot_combo.addItem(display_text, i)
                self.green_slot_combo.addItem(display_text, i)
                self.blue_slot_combo.addItem(display_text, i)
        else:
            # Fallback: assume 10 slots.
            for i in range(10):
                display_text = self.slot_names.get(i, f"Slot {i + 1}")
                self.red_slot_combo.addItem(display_text, i)
                self.green_slot_combo.addItem(display_text, i)
                self.blue_slot_combo.addItem(display_text, i)
        
        # Combine and Cancel buttons
        self.combine_button = QPushButton("Combine")
        self.combine_button.clicked.connect(self.combine_images)
        self.combine_button.setEnabled(False)  # Disabled until required inputs are available
        
        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        
        # Layout for buttons
        buttons_layout = QHBoxLayout()
        buttons_layout.addStretch()
        buttons_layout.addWidget(self.combine_button)
        buttons_layout.addWidget(self.cancel_button)
        
        # Main Layout
        self.main_layout = QVBoxLayout()
        self.main_layout.addWidget(self.mode_label)
        self.main_layout.addWidget(self.mode_groupbox)
        self.main_layout.addLayout(self.load_files_layout)
        self.main_layout.addWidget(self.slots_selection_widget)
        self.main_layout.addLayout(buttons_layout)
        
        self.setLayout(self.main_layout)
        
        # Set initial state: show file mode, hide slot selection
        self.set_mode_visibility()
    
    def set_mode_visibility(self):
        if self.load_files_radio.isChecked():
            self.use_existing_slots = False
            for widget in [self.r_label, self.load_r_button,
                           self.g_label, self.load_g_button,
                           self.b_label, self.load_b_button]:
                widget.setEnabled(True)
            self.slots_selection_widget.hide()
        else:
            self.use_existing_slots = True
            for widget in [self.r_label, self.load_r_button,
                           self.g_label, self.load_g_button,
                           self.b_label, self.load_b_button]:
                widget.setEnabled(False)
            self.slots_selection_widget.show()
        self.check_inputs()
    
    def update_mode(self):
        self.set_mode_visibility()
    
    def load_r_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Red Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.r_image_path = file_path
            self.r_label.setText(f"Red Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_g_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Green Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.g_image_path = file_path
            self.g_label.setText(f"Green Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_b_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Blue Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.b_image_path = file_path
            self.b_label.setText(f"Blue Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def check_inputs(self):
        if self.use_existing_slots:
            red_slot = self.red_slot_combo.currentData()
            green_slot = self.green_slot_combo.currentData()
            blue_slot = self.blue_slot_combo.currentData()
            if (self.image_manager._images.get(red_slot) is not None and
                self.image_manager._images.get(green_slot) is not None and
                self.image_manager._images.get(blue_slot) is not None):
                self.combine_button.setEnabled(True)
            else:
                self.combine_button.setEnabled(False)
        else:
            if self.r_image_path and self.g_image_path and self.b_image_path:
                self.combine_button.setEnabled(True)
            else:
                self.combine_button.setEnabled(False)
    
    def combine_images(self):
        try:
            if self.use_existing_slots:
                red_slot = self.red_slot_combo.currentData()
                green_slot = self.green_slot_combo.currentData()
                blue_slot = self.blue_slot_combo.currentData()
                r = self.image_manager._images.get(red_slot).copy()
                g = self.image_manager._images.get(green_slot).copy()
                b = self.image_manager._images.get(blue_slot).copy()
            else:
                r, _, _, _ = load_image(self.r_image_path)
                g, _, _, _ = load_image(self.g_image_path)
                b, _, _, _ = load_image(self.b_image_path)
                if r is None or g is None or b is None:
                    raise ValueError("One or more images failed to load.")
    
            if r.ndim == 3 and r.shape[2] > 1:
                print("Red channel image has multiple channels, extracting first channel.")
                r = r[:, :, 0]
            if g.ndim == 3 and g.shape[2] > 1:
                print("Green channel image has multiple channels, extracting first channel.")
                g = g[:, :, 0]
            if b.ndim == 3 and b.shape[2] > 1:
                print("Blue channel image has multiple channels, extracting first channel.")
                b = b[:, :, 0]
    
            if not (r.shape == g.shape == b.shape):
                raise ValueError("All images must have the same dimensions.")
    
            rgb_image = np.stack([r, g, b], axis=2)
            self.rgb_image = rgb_image  # Store the combined image.
    
            # Use ImageManager.set_image to set the image in the active slot.
            self.image_manager.set_image(new_image=self.rgb_image, metadata={"description": "RGB Combined Image"}, step_name="RGB Combination")
    
            self.accept()  # Close the dialog with success.
            print("RGB Combination successful.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to combine images: {e}")
            print(f"Error in RGB Combination: {e}")

class StarNetThread(QThread):
    # Define signals to communicate with the main thread
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)  # Emit return code

    def __init__(self, command, cwd):
        super().__init__()
        self.command = command
        self.cwd = cwd
        self._process = None  # To handle process termination

    def run(self):
        try:
            # Start the StarNet process
            self._process = subprocess.Popen(
                self.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=self.cwd,
                bufsize=1,
                universal_newlines=True
            )

            # Read stdout and stderr in real-time
            while True:
                output = self._process.stdout.readline()
                if output:
                    self.stdout_signal.emit(output.strip())
                elif self._process.poll() is not None:
                    break

            # Capture remaining stdout
            remaining_stdout, remaining_stderr = self._process.communicate()
            if remaining_stdout:
                self.stdout_signal.emit(remaining_stdout.strip())
            if remaining_stderr:
                self.stderr_signal.emit(remaining_stderr.strip())

            # Emit the return code
            self.finished_signal.emit(self._process.returncode)

        except Exception as e:
            self.stderr_signal.emit(str(e))
            self.finished_signal.emit(-1)

    def stop(self):
        if self._process and self._process.poll() is None:
            self._process.terminate()
            self.wait()

class StarNetDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Star Removal Progress")
        self.setMinimumSize(600, 400)
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout()
        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        layout.addWidget(self.text_edit)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.cancel_process)
        layout.addWidget(self.cancel_button)

        self.setLayout(layout)

    def append_text(self, text):
        self.text_edit.append(text)
        # Auto-scroll to the bottom
        self.text_edit.verticalScrollBar().setValue(self.text_edit.verticalScrollBar().maximum())

    def cancel_process(self):
        self.reject()  # Close the dialog

class DarkStarConfigDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Dark Star Parameters")
        layout = QVBoxLayout(self)

        # Disable GPU
        self.gpu_combo = QComboBox()
        self.gpu_combo.addItems(["No", "Yes"])
        layout.addWidget(QLabel("Disable GPU Acceleration?"))
        layout.addWidget(self.gpu_combo)

        # Mode
        self.mode_combo = QComboBox()
        self.mode_combo.addItems(["unscreen", "additive"])
        layout.addWidget(QLabel("Star Removal Mode"))
        layout.addWidget(self.mode_combo)

        # Show extracted stars
        self.show_stars_combo = QComboBox()
        self.show_stars_combo.addItems(["Yes", "No"])
        layout.addWidget(QLabel("Show Extracted Stars?"))
        layout.addWidget(self.show_stars_combo)

        # Stride
        self.chunk_size_combo = QComboBox()
        self.chunk_size_combo.addItems(["32", "64", "128", "256", "512", "1024", "2048"])
        self.chunk_size_combo.setCurrentText("512")
        layout.addWidget(QLabel("Stride (power of 2):"))
        layout.addWidget(self.chunk_size_combo)

        # Buttons
        buttons = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel
        )
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)

    def get_values(self):
        return {
            "disable_gpu": self.gpu_combo.currentText() == "Yes",
            "mode": self.mode_combo.currentText(),
            "show_extracted_stars": self.show_stars_combo.currentText() == "Yes",
            "chunk_size": int(self.chunk_size_combo.currentText())
        }


class AddStarsDialog(QDialog):
    """
    Dialog for configuring and previewing star additions to an image.
    """
    # Define a custom signal to emit the blended image back to the main application
    stars_added = pyqtSignal(np.ndarray)  # Emitting the blended image

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Add Stars to Image")
        self.image_manager = image_manager  # Reference to ImageManager
        self.current_slot = self.image_manager.current_slot
        self.starless_image = None
        self.stars_only_image = None
        self.blended_image = None
        self.scale_factor = 1.0
        self.fitted = False  # To ensure fit_to_preview is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Preview Area
        self.preview_label = QLabel()
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.preview_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.preview_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.preview_label.setScaledContents(False)

        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        main_layout.addWidget(self.scroll_area)

        # Zoom Controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_button = QPushButton("Fit to Preview")
        fit_button.clicked.connect(self.fit_to_preview)

        # Add tooltips for better user guidance
        zoom_in_button.setToolTip("Increase the zoom level of the preview image.")
        zoom_out_button.setToolTip("Decrease the zoom level of the preview image.")
        fit_button.setToolTip("Automatically fit the image to the preview area.")

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Selection Controls
        selection_layout = QGridLayout()

        # Blend Type Dropdown
        blend_type_label = QLabel("Blend Type:")
        self.blend_type_combo = QComboBox()
        self.blend_type_combo.addItems(["Screen", "Add"])
        self.blend_type_combo.currentIndexChanged.connect(self.update_preview)
        self.blend_type_combo.setToolTip("Select the blend type to apply.")

        selection_layout.addWidget(blend_type_label, 0, 0)
        selection_layout.addWidget(self.blend_type_combo, 0, 1)

        # Starless Image Selection
        starless_label = QLabel("Starless Image:")
        self.starless_combo = QComboBox()
        self.populate_slot_combo(self.starless_combo)
        self.starless_combo.currentIndexChanged.connect(self.load_starless_image)
        starless_file_button = QPushButton("Load from File")
        starless_file_button.clicked.connect(lambda: self.load_image_from_file(source='starless'))
        starless_file_button.setToolTip("Load a starless image from your filesystem.")

        selection_layout.addWidget(starless_label, 1, 0)
        selection_layout.addWidget(self.starless_combo, 1, 1)
        selection_layout.addWidget(starless_file_button, 1, 2)

        # Stars-Only Image Selection
        stars_only_label = QLabel("Stars-Only Image:")
        self.stars_only_combo = QComboBox()
        self.populate_slot_combo(self.stars_only_combo)
        self.stars_only_combo.currentIndexChanged.connect(self.load_stars_only_image)
        stars_only_file_button = QPushButton("Load from File")
        stars_only_file_button.clicked.connect(lambda: self.load_image_from_file(source='stars_only'))
        stars_only_file_button.setToolTip("Load a stars-only image from your filesystem.")

        selection_layout.addWidget(stars_only_label, 2, 0)
        selection_layout.addWidget(self.stars_only_combo, 2, 1)
        selection_layout.addWidget(stars_only_file_button, 2, 2)

        main_layout.addLayout(selection_layout)

        # Blend Ratio Slider
        blend_ratio_layout = QHBoxLayout()
        blend_ratio_label = QLabel("Blend Ratio (Screen/Add Intensity):")
        self.blend_ratio_slider = QSlider(Qt.Orientation.Horizontal)
        self.blend_ratio_slider.setMinimum(0)
        self.blend_ratio_slider.setMaximum(100)
        self.blend_ratio_slider.setValue(100)  # Default to full blend type effect
        self.blend_ratio_slider.setTickInterval(10)
        self.blend_ratio_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.blend_ratio_slider.valueChanged.connect(self.update_preview)
        self.blend_ratio_slider.setToolTip("Adjust the intensity of the selected blend type.")

        blend_ratio_layout.addWidget(blend_ratio_label)
        blend_ratio_layout.addWidget(self.blend_ratio_slider)

        main_layout.addLayout(blend_ratio_layout)

        # Action Buttons
        action_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_blend)
        apply_button.setToolTip("Apply the blended image to the current slot.")
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        cancel_button.setToolTip("Cancel and close the dialog without applying changes.")

        action_layout.addStretch()
        action_layout.addWidget(apply_button)
        action_layout.addWidget(cancel_button)

        main_layout.addLayout(action_layout)

        self.setLayout(main_layout)
        self.setMinimumSize(800, 600)

    def populate_slot_combo(self, combo_box):
        """
        Populates a QComboBox with available image slots from the ImageManager.
        Uses the custom slot names if they have been renamed.
        """
        combo_box.clear()
        # "Select Slot" item, with no slot data
        combo_box.addItem("Select Slot", None)

        parent = self.parent()  # The parent might have slot_names
        for slot in range(self.image_manager.max_slots):
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                if parent is not None and hasattr(parent, "slot_names"):
                    # Use the renamed slot if it exists; otherwise default to "Slot {slot}"
                    name = parent.slot_names.get(slot, f"Slot {slot}")
                else:
                    name = f"Slot {slot}"

                # --> Add the item with the *display text* = name and *data* = slot index
                combo_box.addItem(name, slot)

        # Option to load from file, store a sentinel like "file" or -1
        combo_box.addItem("Load from File", "file")


    def load_image_from_file(self, source):
        """
        Loads an image from a file for either starless or stars-only.
        Utilizes the global load_image method.
        """
        filename, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {'Starless' if source == 'starless' else 'Stars-Only'} Image",
            "",
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.jpg *.jpeg *.raw *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if filename:
            # Utilize the global load_image function
            image, original_header, bit_depth, is_mono = load_image(filename)
            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the selected image.")
                return

            # Assign to the appropriate variable
            if source == 'starless':
                self.starless_image = image
                self.starless_combo.setCurrentIndex(self.starless_combo.count() - 1)  # Select "Load from File"
                print(f"Starless image loaded from file: {filename}")
            elif source == 'stars_only':
                self.stars_only_image = image
                self.stars_only_combo.setCurrentIndex(self.stars_only_combo.count() - 1)  # Select "Load from File"
                print(f"Stars-only image loaded from file: {filename}")

            self.update_preview()

    def load_starless_image(self):
        """Loads the starless image based on the selection in the combo box."""
        selected_data = self.starless_combo.currentData()

        if selected_data is None:
            # This is the "Select Slot" item
            self.starless_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button, so do nothing here
            pass

        else:
            # Here, selected_data should be the integer slot index
            slot = selected_data  
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.starless_image = image.copy()
                print(f"Starless image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.starless_image = None

        self.update_preview()


    def load_stars_only_image(self):
        """Loads the stars-only image based on the selection in the combo box."""
        selected_data = self.stars_only_combo.currentData()

        if selected_data is None:
            # "Select Slot"
            self.stars_only_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button
            pass

        else:
            slot = selected_data
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.stars_only_image = image.copy()
                print(f"Stars-only image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.stars_only_image = None

        self.update_preview()
        
    def blend_images(self):
        """
        Blends the starless and stars-only images based on the selected method and blend ratio.
        Applies the mask to the blended image.
        Returns the final blended image.
        """
        if self.starless_image is None or self.stars_only_image is None:
            return None

        # Ensure both images have the same dimensions
        if self.starless_image.shape != self.stars_only_image.shape:
            QMessageBox.critical(self, "Error", "Images have different dimensions. Please select matching images.")
            return None

        blend_type = self.blend_type_combo.currentText()
        blend_ratio = self.blend_ratio_slider.value() / 100.0  # Convert to [0,1]

        # Compute blended image based on blend type
        if blend_type == "Screen":
            blended_type = self.starless_image + self.stars_only_image - (self.starless_image * self.stars_only_image)
        elif blend_type == "Add":
            blended_type = self.starless_image + self.stars_only_image
        else:
            blended_type = self.starless_image.copy()

        # Apply blend ratio to control the intensity of the blend type
        # blended = (1 - blend_ratio) * starless + blend_ratio * blended_type
        blended = (1 - blend_ratio) * self.starless_image + blend_ratio * blended_type

        # Clip the result to [0,1]
        blended = np.clip(blended, 0.0, 1.0)

        # ✅ Only apply mask if it is actively applied
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                # Ensure mask has correct dimensions
                if mask.shape != self.starless_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match image dimensions.")
                    return None

                # Normalize mask to [0,1]
                if mask.dtype != np.float32:
                    mask = mask.astype('float32') / 255.0

                if mask.ndim == 3:
                    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

                if self.starless_image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=2)
                    mask = np.repeat(mask, self.starless_image.shape[2], axis=2)

                mask = np.clip(mask, 0.0, 1.0)

                final_image = self.starless_image * (1 - mask) + mask * blended
                final_image = np.clip(final_image, 0.0, 1.0)
                print("✅ Applied active mask to the blended image.")
            else:
                final_image = blended
                print("⚠️ No active mask found. Using blended image directly.")
        else:
            final_image = blended
            print("ℹ️ Mask slot is not active. Skipping mask application.")

        return final_image
    def update_preview(self):
        """
        Updates the preview area with the current blended image while maintaining zoom and scroll position.
        """
        final_image = self.blend_images()
        if final_image is not None:
            self.blended_image = final_image.copy()

            # Convert final image to QPixmap
            pixmap = self.convert_to_pixmap(final_image)

            # Store current scroll positions
            h_scroll = self.scroll_area.horizontalScrollBar().value()
            v_scroll = self.scroll_area.verticalScrollBar().value()

            # Scale the pixmap based on scale_factor
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.scale_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )

            # Update the preview label with the scaled pixmap
            self.preview_label.setPixmap(scaled_pixmap)
            self.preview_label.adjustSize()

            # Restore scroll positions
            self.scroll_area.horizontalScrollBar().setValue(h_scroll)
            self.scroll_area.verticalScrollBar().setValue(v_scroll)
            print("Updated preview with the final blended image.")
        else:
            self.preview_label.clear()
            print("Cleared preview due to missing images or errors.")

    def convert_to_pixmap(self, image):
        """
        Converts a numpy image array to QPixmap for display.
        """
        # Ensure image is in [0,1] range
        image = np.clip(image, 0, 1)

        # Convert to 8-bit
        image_8bit = (image * 255).astype(np.uint8)

        # Handle grayscale and RGB images
        if image_8bit.ndim == 2:
            # Grayscale
            q_image = QImage(
                image_8bit.data,
                image_8bit.shape[1],
                image_8bit.shape[0],
                image_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        elif image_8bit.ndim == 3:
            if image_8bit.shape[2] == 3:
                # RGB
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGB888
                )
            elif image_8bit.shape[2] == 4:
                # RGBA
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGBA8888
                )
            else:
                # Unsupported format
                QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
                return QPixmap()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
            return QPixmap()

        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    @announce_zoom
    def zoom_in(self):
        """Zoom in on the preview image."""
        self.scale_factor *= 1.25
        self.update_image()
        print(f"Zoomed in. Current scale factor: {self.scale_factor}")

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the preview image."""
        self.scale_factor /= 1.25
        self.update_image()
        print(f"Zoomed out. Current scale factor: {self.scale_factor}")

    def fit_to_preview(self):
        """Fit the blended image to the preview area."""
        if self.blended_image is None:
            return
        QTimer.singleShot(0, self.perform_fit_to_preview)

    def perform_fit_to_preview(self):
        """
        Performs the fit to preview action after the event loop has processed show events.
        """
        if self.blended_image is None:
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap = self.convert_to_pixmap(self.blended_image)
        pixmap_size = pixmap.size()

        # Calculate scale factor to fit the image within the viewport while maintaining aspect ratio
        scale_w = viewport_size.width() / pixmap_size.width()
        scale_h = viewport_size.height() / pixmap_size.height()
        scale_factor = min(scale_w, scale_h)

        # Apply the scale factor
        self.scale_factor = scale_factor
        self.update_preview()
        print(f"Fitted image to preview. New scale factor: {self.scale_factor}")

    def scale_image(self, factor):
        """Scales the image by the given factor."""
        if self.blended_image is None:
            return
        self.scale_factor *= factor
        self.update_preview()
        print(f"Scaled image by a factor of {factor}. New scale factor: {self.scale_factor}")

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor.
        """
        if self.blended_image is None:
            return

        pixmap = self.convert_to_pixmap(self.blended_image)
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.preview_label.setPixmap(scaled_pixmap)
        self.preview_label.adjustSize()
        print("Updated image display based on new scale factor.")

    def apply_blend(self):
        """
        Applies the blended image to the main application and closes the dialog.
        """
        if self.blended_image is None:
            QMessageBox.warning(self, "No Blend", "No blended image to apply.")
            print("Apply blend failed: No blended image available.")
            return

        # Emit the blended image
        self.stars_added.emit(self.blended_image)
        self.accept()
        print("Applied blended image and closed dialog.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            QTimer.singleShot(0, self.fit_to_preview)  # Schedule fit_to_preview after the event loop
            self.fitted = True
            print("Dialog shown and image fitted to preview.")

class ApertureHelpWindow(QDialog):
    """
    A simple dialog that displays an image to help the user understand
    the aperture parameters (number of vanes, pupil radius, obstruction, vane width, etc.)
    """
    def __init__(self, image_path, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Aperture Help")
        self.setMinimumSize(400, 400)
        layout = QVBoxLayout(self)

        try:
            pixmap = QPixmap(image_path)
            if pixmap.isNull():
                raise ValueError("Could not load image.")
            label = QLabel()
            label.setPixmap(pixmap)
            label.setAlignment(Qt.AlignmentFlag.AlignCenter)
            layout.addWidget(label)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load aperture help image: {e}")
        self.setLayout(layout)

class StarSpikePreviewWindow(QDialog):
    """
    A separate window to display the final star-spiked image for preview.
    Includes:
      - Zoom In, Zoom Out, Fit to Preview controls
      - An optional "Save to Slot" button if an ImageManager is provided
    """
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.setWindowTitle("Star Spike Preview")
        self.setMinimumSize(400, 400)

        # (Optional) If we want to allow saving to slots
        self.image_manager = image_manager
        self.preview_image = None  # We'll store the display image here

        # Zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the image display area (QGraphicsView)
        self._create_image_display_area()

        # 2) Create the zoom controls
        self._create_zoom_controls()

        # 3) Optionally create a "Save to Slot" button if image_manager is present
        if self.image_manager is not None:
            self._create_save_button()

    def _create_image_display_area(self):
        """Create a QGraphicsView & QGraphicsScene for the preview image."""
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        # Add the graphics view to the main layout
        self.main_layout.addWidget(self.graphics_view)

    def _create_zoom_controls(self):
        """Create a group with Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_controls_group = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_controls_group.setLayout(zoom_layout)
        self.main_layout.addWidget(self.zoom_controls_group)

    def _create_save_button(self):
        """Create a 'Save to Slot' button if we have an image_manager."""
        self.save_button = QPushButton("Save to Slot")
        self.save_button.clicked.connect(self._save_to_slot)
        self.main_layout.addWidget(self.save_button)

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def _fit_to_preview(self):
        """Fit the entire image within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No image
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        self.zoom_factor = 1.0

    def _apply_zoom(self):
        """Apply the current zoom factor to the graphics view."""
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def update_image(self, image_array):
        """
        Update the preview with the given image array (color or mono).
        image_array: np.ndarray (H,W) or (H,W,3) in [0..1] or up to e.g. 65535.
        """
        try:
            # Convert to 8-bit for display
            # If float [0..1], scale to 0..255. 
            arr = np.clip(image_array, 0, 1) * 255.0
            arr = arr.astype(np.uint8)

            # Determine shape
            if arr.ndim == 2:
                # Mono => QImage.Format_Grayscale8
                h, w = arr.shape
                qimage = QImage(arr.data, w, h, w, QImage.Format.Format_Grayscale8)
            elif arr.ndim == 3 and arr.shape[2] == 3:
                # Color => QImage.Format_RGB888
                h, w, _ = arr.shape
                qimage = QImage(arr.data, w, h, 3*w, QImage.Format.Format_RGB888)
            else:
                raise ValueError("Unsupported image shape for preview.")

            pixmap = QPixmap.fromImage(qimage)
            self.pixmap_item.setPixmap(pixmap)
            self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())
            self._fit_to_preview()

            # Store the final array if we want to save it
            self.preview_image = image_array

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update preview: {e}")

    def _save_to_slot(self):
        """
        If we have an image_manager, let user pick a slot and store self.preview_image.
        We'll push old image to that slot's undo stack if you have a method like set_image_for_slot(...).
        """
        if self.preview_image is None:
            QMessageBox.warning(self, "No Image", "No preview image to save.")
            return

        if self.image_manager is None:
            QMessageBox.warning(self, "No Manager", "No ImageManager passed to preview window.")
            return

        # Prompt user for a slot index
        slot_idx, ok = QInputDialog.getInt(
            self,
            "Save to Slot",
            f"Enter slot number (0..{self.image_manager.max_slots - 1}):",
            self.image_manager.current_slot,  # default
            0,
            self.image_manager.max_slots - 1,
            1
        )
        if not ok:
            return

        # Build metadata
        new_metadata = {
            "description": "Star-Spiked from Preview",
            "is_float": True
        }

        # If you have set_image_for_slot(...):
        if hasattr(self.image_manager, "set_image_for_slot"):
            self.image_manager.set_image_for_slot(slot_idx, self.preview_image, new_metadata, step_name="Star Spike Tool")
        else:
            # fallback to add_image(...) if you want
            self.image_manager.add_image(slot_idx, self.preview_image, new_metadata)

        QMessageBox.information(self, "Saved", f"Preview image saved to slot {slot_idx}.")

class AdvancedOptionsDialog(QDialog):
    """
    A popup dialog for advanced parameters.
    Contains advanced parameters such as Flux Max Range, BrightScale Min/Max,
    Shrink Min/Max, and now Detect Threshold.
    When accepted, the values can be retrieved by the calling code.
    """
    def __init__(self, parent=None, initial_values=None):
        super().__init__(parent)
        self.setWindowTitle("Advanced Options")
        self.setModal(True)
        layout = QVBoxLayout(self)

        form = QFormLayout()
        self.flux_max_spin = CustomDoubleSpinBox(minimum=1.0, maximum=999999.0,
                                                   initial=initial_values.get('flux_max', 300.0),
                                                   step=50.0)
        form.addRow("Flux Max Range:", self.flux_max_spin)

        self.bscale_min_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                    initial=initial_values.get('bscale_min', 10.0),
                                                    step=1.0)
        form.addRow("BrightScale Min:", self.bscale_min_spin)

        self.bscale_max_spin = CustomDoubleSpinBox(minimum=1.0, maximum=999.0,
                                                    initial=initial_values.get('bscale_max', 30.0),
                                                    step=1.0)
        form.addRow("BrightScale Max:", self.bscale_max_spin)

        self.shrink_min_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                    initial=initial_values.get('shrink_min', 1.0),
                                                    step=0.2)
        form.addRow("Shrink Min:", self.shrink_min_spin)

        self.shrink_max_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                   initial=initial_values.get('shrink_max', 5.0),
                                                   step=0.2)
        form.addRow("Shrink Max:", self.shrink_max_spin)

        # Move Detect Threshold into the advanced options.
        self.detect_thresh_spin = CustomDoubleSpinBox(minimum=0.0, maximum=100.0,
                                                      initial=initial_values.get('detect_thresh', 5.0),
                                                      step=0.1)
        form.addRow("Detect Threshold:", self.detect_thresh_spin)

        layout.addLayout(form)

        # OK and Cancel buttons
        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("OK")
        ok_btn.clicked.connect(self.accept)
        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)
        layout.addLayout(btn_layout)

        self.setLayout(layout)

    def get_values(self):
        return {
            'flux_max': self.flux_max_spin.value(),
            'bscale_min': self.bscale_min_spin.value(),
            'bscale_max': self.bscale_max_spin.value(),
            'shrink_min': self.shrink_min_spin.value(),
            'shrink_max': self.shrink_max_spin.value(),
            'detect_thresh': self.detect_thresh_spin.value(),
            # Note: color boost is now in the basic UI.
        }
       

class StarSpikeTool(QDialog):
    """
    A stand-alone dialog that integrates with AstroEditingSuite.
    - Reads the active image from image_manager.
    - Lets the user define star detection & diffraction parameters.
    - Generates star spikes with multi-threading.
    - Optionally overwrites the same slot in image_manager.
    """
    def __init__(self, image_manager, mask_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Star Spike Tool")
        self.image_manager = image_manager
        self.mask_manager  = mask_manager
        self.final_image = None

        # Set default advanced parameters.
        self.advanced_params = {
            'flux_max': 300.0,
            'bscale_min': 10.0,
            'bscale_max': 30.0,
            'shrink_min': 1.0,
            'shrink_max': 5.0,
            'detect_thresh': 5.0  # default advanced detect threshold.
        }
        # UI Setup
        self._init_ui()
        self._image_data = None

    def _init_ui(self):
        """Builds the layout with basic form parameters, an advanced options popup, and other controls."""
        main_layout = QVBoxLayout(self)

        # Basic parameters form.
        basic_form = QFormLayout()

        # New: Toggle switch for pupil type.
        # Using a QCheckBox as a toggle. When checked, we simulate a JWST pupil.
        # -- Toggle Switch Button for Aperture Type --
        self.pupil_toggle_button = QPushButton("Circular")
        self.pupil_toggle_button.setCheckable(True)
        self.pupil_toggle_button.setChecked(False)  # Start off in 'Circular' mode
        self.pupil_toggle_button.toggled.connect(self._on_pupil_toggle)
        # Optionally style it to look like a sliding switch:
        self.pupil_toggle_button.setStyleSheet("""
            QPushButton {
                min-width: 60px;   max-width: 60px;
                min-height: 28px;  max-height: 28px;
                border-radius: 14px;
                background-color: #ccc;
                border: 1px solid #999;
            }
            QPushButton:checked {
                background-color: #66bb6a; /* A greenish color */
            }
        """)
        basic_form.addRow("Aperture Type:", self.pupil_toggle_button)

        # Store labels for vanes, vane width, and obstruction.
        self.radius_label = QLabel("Pupil Radius:")
        self.radius_spin = CustomDoubleSpinBox(minimum=1.0, maximum=512.0, initial=128.0, step=1.0)
        basic_form.addRow(self.radius_label, self.radius_spin)

        self.obstruction_label = QLabel("Obstruction:")
        self.obstruction_spin = CustomDoubleSpinBox(minimum=0.0, maximum=0.99, initial=0.2, step=0.05)
        basic_form.addRow(self.obstruction_label, self.obstruction_spin)

        self.num_vanes_label = QLabel("Number of Vanes:")
        self.num_vanes_spin = CustomSpinBox(minimum=2, maximum=8, initial=2, step=1)
        basic_form.addRow(self.num_vanes_label, self.num_vanes_spin)

        self.vane_width_label = QLabel("Vane Width:")
        self.vane_width_spin = CustomDoubleSpinBox(minimum=0.1, maximum=50.0, initial=4.0, step=0.5)
        basic_form.addRow(self.vane_width_label, self.vane_width_spin)

        # New: Rotation angle.
        self.rotation_spin = CustomDoubleSpinBox(minimum=0.0, maximum=360.0, initial=0.0, step=1.0)
        basic_form.addRow("Rotation Angle (deg):", self.rotation_spin)

        # The Color Boost control is now in basic UI.
        self.color_boost_spin = CustomDoubleSpinBox(minimum=0.1, maximum=10.0, initial=1.5, step=0.1)
        basic_form.addRow("Spike Boost:", self.color_boost_spin)

        self.blur_sigma_spin = CustomDoubleSpinBox(minimum=0.1, maximum=10.0, initial=2.0, step=0.1)
        basic_form.addRow("PSF Blur Sigma:", self.blur_sigma_spin)

        # Remove Detect Threshold from basic form (will be in advanced)
        # And we already have Flux Min here.
        self.flux_min_spin = CustomDoubleSpinBox(minimum=0.0, maximum=999999.0, initial=30.0, step=10.0)
        basic_form.addRow("Flux Min:", self.flux_min_spin)

        main_layout.addLayout(basic_form)

        # Advanced Options button.
        self.adv_options_btn = QPushButton("Advanced Options...")
        self.adv_options_btn.setToolTip("Configure advanced parameters")
        self.adv_options_btn.clicked.connect(self._show_advanced_options)
        main_layout.addWidget(self.adv_options_btn)

        # Buttons: Generate Spikes and Save to Slot.
        btn_layout = QHBoxLayout()
        self.run_button = QPushButton("Generate Spikes")
        self.run_button.clicked.connect(self._run_spikes)
        btn_layout.addWidget(self.run_button)

        self.save_button = QPushButton("Save to Slot")
        self.save_button.clicked.connect(self._save_to_slot)
        self.save_button.setEnabled(False)
        btn_layout.addWidget(self.save_button)
        main_layout.addLayout(btn_layout)

        # Progress Bar.
        self.progress_bar = QProgressBar()
        self.progress_bar.setValue(0)
        main_layout.addWidget(self.progress_bar)
        # Status label at the bottom.
        self.status_label = QLabel("Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout.addWidget(self.status_label)
        # Help Button.
        self.help_button = QPushButton("Help")
        self.help_button.setToolTip("Click to view an example diagram of the telescope aperture and PSF parameters.")
        self.help_button.clicked.connect(self._show_aperture_help)
        main_layout.addWidget(self.help_button)

        self.setLayout(main_layout)

        # Initialize state of advanced controls based on pupil type.
        self._on_pupil_toggle(self.pupil_toggle_button.isChecked())


    def _on_pupil_toggle(self, checked: bool):
        """
        When toggled, if checked (JWST mode) hide the controls that are not applicable.
        Otherwise, show them.
        """
        if checked:
            self.pupil_toggle_button.setText("JWST")
            self.num_vanes_label.hide()
            self.num_vanes_spin.hide()
            self.vane_width_label.hide()
            self.vane_width_spin.hide()
            self.obstruction_label.hide()
            self.obstruction_spin.hide()
            # Optionally, you might hide the pupil radius control as well if fixed.
            self.radius_spin.hide()
        else:
            self.pupil_toggle_button.setText("Circular")
            self.num_vanes_label.show()
            self.num_vanes_spin.show()
            self.vane_width_label.show()
            self.vane_width_spin.show()
            self.obstruction_label.show()
            self.obstruction_spin.show()
            self.radius_spin.show()

    def _show_advanced_options(self):
        """Opens a popup dialog for advanced options."""
        dialog = AdvancedOptionsDialog(parent=self, initial_values=self.advanced_params)
        if dialog.exec() == QDialog.DialogCode.Accepted:
            self.advanced_params = dialog.get_values()
            print("Advanced parameters updated:")
            print(self.advanced_params)


    def _show_aperture_help(self):
        """Opens a help window to display the aperture/PSF example image."""
        try:
            # Replace 'aperture_path' with your actual file path for the help image.
            help_dialog = ApertureHelpWindow(aperture_path, parent=self)
            help_dialog.show()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to open help image: {e}")


    # --------------------------- Primary logic ---------------------------
    def _run_spikes(self):
        """
        Main entry point to run star detection & add spikes.
        """
        self.status_label.setText("Loading active image...")
        QApplication.processEvents()
        blur_sigma = self.blur_sigma_spin.value()
        # 1) Get the active image array + metadata from image_manager
        image_data, metadata = self.image_manager.get_current_image_and_metadata()
        if image_data is None or image_data.size == 0:
            QMessageBox.warning(self, "No Image", "No image found in the active slot!")
            return

        # Convert to float32 if needed
        self._image_data = image_data.astype(np.float32)
        # If RGBA, strip alpha
        if self._image_data.ndim == 3 and self._image_data.shape[2] == 4:
            self._image_data = self._image_data[..., :3]

        # 2) Gather user params from spinboxes
        num_vanes   = self.num_vanes_spin.value
        obstruction = self.obstruction_spin.value()
        radius      = self.radius_spin.value()
        vane_width  = self.vane_width_spin.value()
        rotation     = self.rotation_spin.value()  # New: rotation angle in degrees
        detect_thresh= self.advanced_params.get('detect_thresh', 5.0)
        flux_min     = self.flux_min_spin.value()
        flux_max   = self.advanced_params.get('flux_max', 300.0)
        bscale_min = self.advanced_params.get('bscale_min', 10.0)
        bscale_max = self.advanced_params.get('bscale_max', 30.0)
        shrink_min = self.advanced_params.get('shrink_min', 1.0)
        shrink_max = self.advanced_params.get('shrink_max', 5.0)
        color_boost = self.color_boost_spin.value()

        # 3) "un-stretch" with midtones(0.95)
        if self._image_data.ndim == 3:
            # apply midtones to each channel
            lin_img = self._image_data.copy()
            for c in range(3):
                lin_img[..., c] = self._midtones_m(lin_img[..., c], 0.95)
            base_for_detect = 0.2126*lin_img[...,0] + 0.7152*lin_img[...,1] + 0.0722*lin_img[...,2]
        else:
            lin_img = self._midtones_m(self._image_data, 0.95)
            base_for_detect = lin_img

        # 4) detect stars
        self.status_label.setText("Detecting stars...")
        QApplication.processEvents()
        stars = self._detect_stars(base_for_detect, detect_thresh, flux_min, 1.0)
        self.status_label.setText(f"Detected {len(stars)} stars.")
        QApplication.processEvents()
        if len(stars) == 0:
            QMessageBox.information(self, "No Stars", "No stars found above flux_min.")
            return

        # 5) build a single pupil for all
        self.status_label.setText("Building pupil and PSFs...")
        QApplication.processEvents()
        big_pupil = self._make_pupil(size=1024, radius=radius,
                                      obstruction=obstruction,
                                      vane_width=vane_width,
                                      num_vanes=num_vanes,
                                      rotation=rotation) 
        psf_r = self._simulate_psf(big_pupil, wavelength_scale=1.15, blur_sigma=blur_sigma)
        psf_g = self._simulate_psf(big_pupil, wavelength_scale=1.0, blur_sigma=blur_sigma)
        psf_b = self._simulate_psf(big_pupil, wavelength_scale=0.85, blur_sigma=blur_sigma)


        # 6) Multi-thread star overlay
        self.status_label.setText("Generating star overlay...")
        if lin_img.ndim == 3:
            H, W, _ = lin_img.shape
        else:
            H, W = lin_img.shape
        canvas = np.zeros((H, W, 3), dtype=np.float32)

        from concurrent.futures import ThreadPoolExecutor, as_completed
        total = len(stars)
        self.progress_bar.setValue(0)
        next_update = 0.05

        def star_runner(i):
            x, y, flux, a, b = stars[i]
            brightness = np.clip(np.log1p(flux)/8.0, 0.1, 3.0)
            tile_size  = int(256 + brightness*20)
            tile_size  = min(tile_size, 768)
            tile_size += tile_size % 2
            pad = tile_size // 2
            if not (pad <= x < W - pad and pad <= y < H - pad):
                return None

            # Extract & scale
            # measure star color from original image (the "lin_img" or maybe the raw image_data)
            r_ratio, g_ratio, b_ratio = self.measure_star_color(self._image_data, x, y, sampling_radius=3)

            # Then incorporate that ratio
            tile_r = self._extract_center_tile(psf_r, tile_size) * brightness * r_ratio
            tile_g = self._extract_center_tile(psf_g, tile_size) * brightness * g_ratio
            tile_b = self._extract_center_tile(psf_b, tile_size) * brightness * b_ratio

            # Then your existing color_boost if you want a global multiplier
            tile_r *= color_boost
            tile_g *= color_boost
            tile_b *= color_boost


            # flux-based final scale
            b_scale, s_factor = self._compute_boost_and_shrink_from_flux(
                flux, 1.0, flux_max, bscale_min, bscale_max, shrink_min, shrink_max
            )
            final_r = self._shrink_and_boost(tile_r, brightness_scale=b_scale, shrink_factor=s_factor)
            final_g = self._shrink_and_boost(tile_g, brightness_scale=b_scale, shrink_factor=s_factor)
            final_b = self._shrink_and_boost(tile_b, brightness_scale=b_scale, shrink_factor=s_factor)

            new_size = final_r.shape[0]
            pad_new  = new_size // 2
            y0, y1   = y - pad_new, y - pad_new + new_size
            x0, x1   = x - pad_new, x - pad_new + new_size
            if (y0 < 0 or y1 > H or x0 < 0 or x1 > W):
                return None

            part = np.zeros((H, W, 3), dtype=np.float32)
            part[y0:y1, x0:x1, 0] = final_r
            part[y0:y1, x0:x1, 1] = final_g
            part[y0:y1, x0:x1, 2] = final_b
            return part

        with ThreadPoolExecutor() as exec_:
            futures = {exec_.submit(star_runner, i): i for i in range(total)}
            for idx, fut in enumerate(as_completed(futures)):
                partial = fut.result()
                if partial is not None:
                    canvas += partial
                pct = (idx + 1) / total
                if pct >= next_update:
                    self.progress_bar.setValue(int(pct * 100))
                    next_update += 0.05

        # 7) combine with lin_img
        self.status_label.setText("Combining star overlay with original image...")
        if lin_img.ndim == 3:
            spiked_lin = np.clip(lin_img + canvas, 0, 1)
        else:
            # If the input is mono but the spikes are RGB, convert spikes to mono before adding
            spikes_mono = 0.2126 * canvas[..., 0] + 0.7152 * canvas[..., 1] + 0.0722 * canvas[..., 2]
            spiked_lin = np.clip(lin_img + spikes_mono, 0, 1)

        # 8) re-stretch with midtones(0.05)
        final = np.zeros_like(spiked_lin)
        if spiked_lin.ndim == 3:
            for c in range(3):
                final[..., c] = self._midtones_m(spiked_lin[..., c], 0.05)
        else:
            final = self._midtones_m(spiked_lin, 0.05)

        # ─── 9) If there’s an active mask, blend final with original ───────────
        applied_mask = self.mask_manager.get_applied_mask()
        if applied_mask is not None:
            # 1) Check dimensions
            h, w = self._image_data.shape[:2]
            if applied_mask.shape[:2] != (h, w):
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the image.")
                return

            # 2) Normalize mask to float [0,1]
            if applied_mask.dtype not in (np.float32, np.float64):
                applied_mask = applied_mask.astype(np.float32) / 255.0
            applied_mask = np.clip(applied_mask, 0.0, 1.0)

            # 3) Expand 2D mask to 3 channels if needed
            if final.ndim == 3 and applied_mask.ndim == 2:
                mask_3c = applied_mask[..., None]
            else:
                mask_3c = applied_mask

            # 4) Blend: keep original where mask==1, use spiked final where mask==0
            blended = final * (mask_3c) + self._image_data * (1.0 - mask_3c)
            final = np.clip(blended, 0.0, 1.0)

        self.final_image = final   
        self.save_button.setEnabled(True)
        self.progress_bar.setValue(100)
        self.status_label.setText("Star spike generation completed.")
        self._preview_spiked_image()

    def _preview_spiked_image(self):
        if self.final_image is None:
            return

        # create and display the preview
        preview = StarSpikePreviewWindow(parent=self, image_manager=self.image_manager)
        preview.update_image(self.final_image)
        preview.show()

    def _save_to_slot(self):
        if self.final_image is None:
            QMessageBox.warning(self, "No Output", "Please run spikes first.")
            return

        # 1) Let the user pick which slot to save into
        slot_idx, ok = QInputDialog.getInt(
            self,
            "Save to Slot",
            f"Enter slot number (0..{self.image_manager.max_slots-1}):",
            self.image_manager.current_slot,  # default
            0,                                # min
            self.image_manager.max_slots-1,   # max
            1                                 # step
        )
        if not ok:
            return  # user canceled

        # 2) Build metadata
        new_metadata = {
            "description": "Star-Spiked",
            "is_float": True  # or any other flags you want
        }

        # 3) Save the final image to the chosen slot
        self.image_manager.set_image_for_slot(slot_idx, self.final_image, new_metadata, step_name="Star Spike Tool")

        QMessageBox.information(self, "Saved", f"Spiked image saved to slot {slot_idx}.")
        self.close()



    # ---------------------- Helper Methods as Private ----------------------

    def _midtones_m(self, x, m):
        """Encapsulated midtones code inside the class."""
        x = np.clip(x, 0.0, 1.0).astype(np.float32)
        out = np.zeros_like(x, dtype=np.float32)
        mask0 = (x == 0)
        out[mask0] = 0.0
        mask1 = (x == 1)
        out[mask1] = 1.0
        eps = 1e-7
        maskm = (np.abs(x - m) < eps)
        out[maskm] = 0.5
        mask_oth = ~(mask0 | mask1 | maskm)
        xm = x[mask_oth]
        num = (m - 1.0)*xm
        den = (2.0*m - 1.0)*xm - m
        out[mask_oth] = np.clip(num/(den+1e-12),0,1)
        return out

    def _make_pupil(self, size=512, radius=100, obstruction=0.3, vane_width=2, num_vanes=4, rotation=0):
        """
        Creates a pupil (aperture mask) based on the selected pupil type.
        If the pupil_type_slider value is >= 50, uses the JWST pupil.
        Otherwise, generates a standard circular pupil with diffraction vanes.
        The 'rotation' argument rotates the vane pattern.
        """
        # Use the slider value instead of a checkbox.
        if self.pupil_toggle_button.isChecked():
            # JWST pupil from a PNG
            return self._load_pupil_from_png(jwstpupil_path, size=size, rotation=rotation)
        else:
            # Build a standard circular pupil.
            y, x = np.indices((size, size)) - size // 2
            r = np.sqrt(x**2 + y**2)
            pupil = (r <= radius).astype(np.float32)
            pupil[r < radius * obstruction] = 0.0
            if num_vanes >= 2:
                rotation_radians = np.deg2rad(rotation)
                for angle in np.linspace(0, np.pi, num_vanes, endpoint=False) + rotation_radians:
                    xp = x * np.cos(angle) + y * np.sin(angle)
                    vane = np.abs(xp) < vane_width
                    pupil[vane] = 0.0
            return pupil

    def _load_pupil_from_png(self, filepath, size=1024, rotation=0.0):
        """
        Loads a JWST pupil mask from a PNG file using OpenCV.

        Args:
            filepath (str): The path to the JWST pupil PNG file.
            size (int): The desired output size (size x size).
            rotation (float): Rotation angle in degrees. Positive values rotate counterclockwise.

        Returns:
            np.ndarray: A (size x size) float32 array with values normalized to [0, 1].
        """
        # Load the image in grayscale
        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError(f"Failed to load image from {filepath}")
        
        # Normalize to [0, 1] (assuming white = open, black = blocked)
        img = img.astype(np.float32) / 255.0

        # Resize if necessary
        if img.shape != (size, size):
            img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)
        
        # Apply rotation if needed
        if abs(rotation) > 1e-3:
            center = (size // 2, size // 2)
            # Get the rotation matrix. Note that cv2.getRotationMatrix2D expects rotation in degrees.
            M = cv2.getRotationMatrix2D(center, rotation, 1.0)
            img = cv2.warpAffine(img, M, (size, size), flags=cv2.INTER_LINEAR,
                                borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        
        return img


    def _simulate_psf(self, pupil, wavelength_scale=1.0, blur_sigma=1.0):
        # Apply a Gaussian blur to the pupil to simulate wavelength-dependent phase variations.
        scaled_pupil = gaussian_filter(pupil, sigma=0.1 * wavelength_scale)
        # Compute Fourier transform to get the raw diffraction pattern.
        fft = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(scaled_pupil)))
        intensity = np.abs(fft)**2
        intensity /= (intensity.max() + 1e-8)
        # Apply a second Gaussian filter (blur_sigma) to simulate additional spreading.
        blurred = gaussian_filter(intensity, sigma=blur_sigma)
        psf = blurred / max(blurred.max(), 1e-8)
        
        # **New step:** Scale the spatial dimensions of the PSF.
        # Here, a lower wavelength_scale (e.g. for blue) produces a smaller PSF.
        # If wavelength_scale=1.0 is our nominal size, then for a channel with
        # wavelength_scale < 1.0 the PSF should be smaller, and vice versa.
        zoom_factor = wavelength_scale   # Adjust this mapping as needed.
        if zoom_factor != 1.0:
            psf = ndi.zoom(psf, zoom=zoom_factor, order=1)
            psf /= psf.max()  # Re-normalize after zooming.
        return psf

    def _extract_center_tile(self, psf, tile_size):
        center = psf.shape[0]//2
        half   = tile_size//2
        y0, x0 = max(0, center-half), max(0, center-half)
        y1, x1 = y0+tile_size, x0+tile_size
        cropped= psf[y0:y1, x0:x1]
        if cropped.shape != (tile_size, tile_size):
            padded = np.zeros((tile_size,tile_size), dtype=np.float32)
            ph, pw = cropped.shape
            padded[:ph, :pw]= cropped
            return padded
        return cropped

    def _detect_stars(self, image, threshold=5.0, flux_min=30.0, size_min=1.0):
        data = image.astype(np.float32)
        bkg = sep.Background(data)
        data_sub = data - bkg.back()
        err_val = bkg.globalrms

        try:
            objects = sep.extract(data_sub, threshold, err=err_val)
        except Exception as e:
            if "internal pixel buffer full" in str(e):
                print("[ERROR] Star detection failed: internal pixel buffer full.")
                QMessageBox.warning(
                    self,
                    "Star Detection Failed",
                    "Star detection failed because the internal pixel buffer was exceeded.\n\n"
                    "Try increasing the detection threshold (sigma) or the minimum flux."
                )
            else:
                print(f"[ERROR] Star detection failed: {e}")
                QMessageBox.critical(
                    self,
                    "Unexpected Error",
                    f"An unexpected error occurred during star detection:\n\n{e}"
                )
            return []

        star_list = []
        for obj in objects:
            flux = obj['flux']
            a = obj['a']
            b = obj['b']
            star_size = max(a, b)
            if flux >= flux_min and star_size >= size_min:
                star_list.append((int(obj['x']), int(obj['y']), flux, a, b))
        return star_list

    def _shrink_and_boost(self, tile, brightness_scale=2.0, shrink_factor=1.5):
        tile = tile*brightness_scale
        tile = np.clip(tile, 0.0, 1.0)
        in_size = tile.shape[0]
        out_size= int(in_size//shrink_factor)
        out_size+= out_size%2
        zoom_factor= out_size/float(in_size)
        smaller= ndi.zoom(tile, zoom_factor, order=1)
        return np.clip(smaller, 0.0,1.0)

    def _compute_boost_and_shrink_from_flux(self,
                                            flux, flux_min, flux_max,
                                            bscale_min, bscale_max,
                                            shrink_min,shrink_max):
        flux_c= np.clip(flux, flux_min, flux_max)
        alpha = 0.0
        if flux_max>flux_min:
            alpha= (flux_c - flux_min)/(flux_max - flux_min)
        brightness_scale= bscale_min + alpha*(bscale_max - bscale_min)
        # invert for shrink => bigger flux => smaller factor
        factor= shrink_max - alpha*(shrink_max - shrink_min)
        return brightness_scale, factor

    def measure_star_color(self, img_color, x, y, sampling_radius=20):
        """
        Measures star color at (x, y) and returns ratios where the brightest channel is 1.0.
        """
        if img_color.ndim == 2:
            print(f"[DEBUG] Mono image at ({x:.1f}, {y:.1f}) – returning white")
            return (1.0, 1.0, 1.0)

        H, W, C = img_color.shape
        if C != 3:
            return (1.0, 1.0, 1.0)

        x0 = max(0, int(x - sampling_radius))
        x1 = min(W, int(x + sampling_radius + 1))
        y0 = max(0, int(y - sampling_radius))
        y1 = min(H, int(y + sampling_radius + 1))

        if x1 <= x0 or y1 <= y0:
            return (1.0, 1.0, 1.0)

        patch = img_color[y0:y1, x0:x1, :]
        mean_col = np.mean(patch, axis=(0, 1))  # shape (3,)
        max_col = np.max(mean_col)

        if max_col < 1e-9:
            return (1.0, 1.0, 1.0)

        r_ratio = mean_col[0] / max_col
        g_ratio = mean_col[1] / max_col
        b_ratio = mean_col[2] / max_col

        return (r_ratio, g_ratio, b_ratio)



class BackgroundNeutralizationDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Background Neutralization")
        self.setGeometry(100, 100, 800, 600)  # Set appropriate size
        self.initUI()
        self.selection_rect_item = None  # To store the QGraphicsRectItem

    def initUI(self):
        layout = QVBoxLayout()

        # Instruction Label
        instruction_label = QLabel("Draw a sample box on the image to define the neutralization region.")
        layout.addWidget(instruction_label)

        # Graphics View for Image Display
        self.graphics_view = QGraphicsView()
        self.scene = QGraphicsScene()
        self.graphics_view.setScene(self.scene)
        layout.addWidget(self.graphics_view)

        # Load and Display Image
        self.load_image()

        # Initialize Variables for Drawing
        self.origin = QPointF()
        self.current_rect = QRectF()
        self.drawing = False

        # Connect Mouse Events
        self.graphics_view.viewport().installEventFilter(self)

        # Apply and Cancel Buttons
        button_layout = QVBoxLayout()
        apply_button = QPushButton("Apply Neutralization")
        apply_button.clicked.connect(self.apply_neutralization)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)

        self.setLayout(layout)

    def load_image(self):
        """Loads the current image from the ImageManager and displays it."""
        image = self.image_manager.image
        if image is not None:
            # Assuming image is a NumPy array normalized to [0,1]
            height, width, channels = image.shape
            if channels == 3:
                q_image = QImage(
                    (image * 255).astype(np.uint8).tobytes(),
                    width,
                    height,
                    3 * width,
                    QImage.Format.Format_RGB888
                )
            else:
                # Handle other channel numbers if necessary
                q_image = QImage(
                    (image * 255).astype(np.uint8).tobytes(),
                    width,
                    height,
                    QImage.Format.Format_Grayscale8
                )
            pixmap = QPixmap.fromImage(q_image)
            self.pixmap_item = QGraphicsPixmapItem(pixmap)
            self.scene.addItem(self.pixmap_item)
            self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        else:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            self.reject()

    def eventFilter(self, source, event):
        """Handles mouse events for drawing the sample box."""
        if source is self.graphics_view.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin = self.graphics_view.mapToScene(event.pos())
                    # Remove existing selection rectangle if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Remove existing rectangle item if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
                    # Draw the new rectangle
                    pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.DashLine)
                    self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                    self.selection_rect_item.setPen(pen)
                    self.scene.addItem(self.selection_rect_item)
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    # Finalize the rectangle
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Ensure minimum size to avoid accidental small selections
                    min_size = 10  # pixels
                    if self.current_rect.width() < min_size or self.current_rect.height() < min_size:
                        QMessageBox.warning(self, "Selection Too Small", "Please draw a larger selection box.")
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                            self.selection_rect_item = None
                        self.current_rect = QRectF()
                    else:
                        # Redraw the rectangle to ensure it's persistent
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                        pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.SolidLine)
                        self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                        self.selection_rect_item.setPen(pen)
                        self.scene.addItem(self.selection_rect_item)
        return super().eventFilter(source, event)

    def apply_neutralization(self):
        """Applies background neutralization based on the selected sample region."""
        if self.current_rect.isNull():
            QMessageBox.warning(self, "No Selection", "Please draw a sample box on the image.")
            return

        # Map the selection rectangle to image coordinates
        image = self.image_manager.image
        if image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            return

        # Get the image dimensions
        height, width, channels = image.shape
        if channels != 3:
            QMessageBox.warning(self, "Not RGB", "Background Neutralization currently supports only 3-channel RGB images.")
            return

        # Calculate scaling factors to map from scene coords to image coords
        scene_rect = self.scene.sceneRect()
        scale_x = width / scene_rect.width()
        scale_y = height / scene_rect.height()

        # Convert scene coordinates to image coordinates
        x = int(self.current_rect.left() * scale_x)
        y = int(self.current_rect.top() * scale_y)
        w = int(self.current_rect.width() * scale_x)
        h = int(self.current_rect.height() * scale_y)

        # Ensure the rectangle is within image bounds
        x = max(0, min(x, width - 1))
        y = max(0, min(y, height - 1))
        w = max(1, min(w, width - x))
        h = max(1, min(h, height - y))

        # Extract the sample region
        sample_region = image[y:y + h, x:x + w, :]  # Shape: (h, w, 3)

        # Calculate medians for each channel
        medians = np.median(sample_region, axis=(0, 1))  # Shape: (3,)
        # Compute the average of these three medians
        average_median = np.mean(medians)

        # Create a copy of the image for adjustments
        adjusted_image = image.copy()

        # For each RGB channel, compute the difference and apply the formula
        # newChannel = (oldChannel - diff) / (1 - diff),
        # where diff = median(channel) - average_median
        for c in range(3):
            diff = medians[c] - average_median

            # Numerator = old - diff
            # Denominator = 1 - diff
            # Make sure we handle any extreme edge cases where (1 - diff) could be 0 or negative
            numerator = adjusted_image[:, :, c] - diff
            denominator = 1.0 - diff

            # Avoid division by zero or extremely small denominators
            # (in normal circumstances, diff should be well within -1..1 for images in [0,1])
            if abs(denominator) < 1e-8:
                # If this occurs, you could skip or handle differently.
                # For safety, just skip or clamp in real code:
                denominator = 1e-8 if denominator >= 0 else -1e-8

            new_values = numerator / denominator

            # Clip the results to [0, 1] to remain in valid image range
            new_values = np.clip(new_values, 0.0, 1.0)

            adjusted_image[:, :, c] = new_values

        # Update the image in the ImageManager
        self.image_manager.set_image(
            adjusted_image,
            metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Background Neutralization"
        )

        # Inform the user
        QMessageBox.information(self, "Success", "Background neutralization applied successfully.")

        # Close the dialog
        self.accept()

class RemoveGreenDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the RemoveGreenDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Remove Green")
        self.initUI()

    def initUI(self):
        """
        Sets up the UI components.
        """
        layout = QVBoxLayout()

        # Instruction Label
        instruction_label = QLabel("Select the amount to remove green noise:")
        layout.addWidget(instruction_label)

        # Slider Configuration
        self.slider = QSlider(Qt.Orientation.Horizontal)
        self.slider.setMinimum(0)
        self.slider.setMaximum(100)  # Represents 0.0 to 1.0
        self.slider.setValue(100)     # Default to 1.0
        self.slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.slider.setTickInterval(10)
        self.slider.valueChanged.connect(self.update_label)
        layout.addWidget(self.slider)

        # Current Value Display
        self.value_label = QLabel("Amount: 1.00")
        layout.addWidget(self.value_label)

        # Buttons Layout
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        cancel_button = QPushButton("Cancel")
        apply_button.clicked.connect(self.apply)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)

        self.setLayout(layout)

    def update_label(self, value):
        """
        Updates the value label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        amount = value / 100.0
        self.value_label.setText(f"Amount: {amount:.2f}")

    def apply(self):
        """
        Applies the Remove Green operation to the image, considering the applied mask.
        """
        amount = self.slider.value() / 100.0

        if self.image_manager.image is not None:
            try:
                # Apply the global SCNR function to reduce green noise
                new_image = apply_average_neutral_scnr(self.image_manager.image, amount=amount)

                # Retrieve the currently applied mask from MaskManager
                applied_mask = self.mask_manager.get_applied_mask()

                if applied_mask is not None:
                    # Ensure mask dimensions match the image dimensions
                    if applied_mask.shape[:2] != self.image_manager.image.shape[:2]:
                        QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                        return

                    # Ensure mask is a float array with values between 0 and 1
                    if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                        applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                    # Clip mask values to [0,1] to avoid unexpected results
                    applied_mask = np.clip(applied_mask, 0.0, 1.0)

                    # If image has multiple channels, ensure mask has the same number of channels
                    if self.image_manager.image.ndim == 3 and applied_mask.ndim == 2:
                        applied_mask = np.expand_dims(applied_mask, axis=-1)

                    # Perform the blending: combined_image = image * (1 - mask) + new_image * mask
                    combined_image = self.image_manager.image * (1 - applied_mask) + new_image * applied_mask

                    # Ensure the combined image's pixel values are within [0,1]
                    combined_image = np.clip(combined_image, 0.0, 1.0)

                    # Update the ImageManager's current image with the combined image
                    self.image_manager.set_image(
                        combined_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Remove Green"
                    )
                else:
                    # No mask applied; update with the processed image directly
                    self.image_manager.set_image(
                        new_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Remove Green"
                    )

                # Inform the user of the successful operation
                QMessageBox.information(self, "Success", f"Remove Green applied with amount {amount:.2f}")

                # Close the dialog
                self.accept()
            except Exception as e:
                # Handle any errors during processing
                QMessageBox.critical(self, "Error", f"Failed to apply Remove Green:\n{e}")
        else:
            # Inform the user if no image is loaded
            QMessageBox.warning(self, "No Image", "No image loaded to apply Remove Green.")
            self.reject()

class CLAHEDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the CLAHEDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("CLAHE")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # CLAHE Parameters Group
        parameters_group = QGroupBox("CLAHE Parameters")
        parameters_layout = QGridLayout()

        # Clip Limit Slider and Label
        clip_label = QLabel("Clip Limit:")
        self.clip_slider = QSlider(Qt.Orientation.Horizontal)
        self.clip_slider.setMinimum(1)
        self.clip_slider.setMaximum(40)  # Represents 0.1 to 4.0
        self.clip_slider.setValue(20)     # Default 2.0
        self.clip_slider.setTickInterval(1)
        self.clip_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.clip_value_label = QLabel("2.0")  # Initial value
        self.clip_slider.setToolTip("Adjust the clip limit for contrast enhancement. Higher values increase contrast.")

        self.clip_slider.valueChanged.connect(self.update_clip_value)
        self.clip_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(clip_label, 0, 0)
        parameters_layout.addWidget(self.clip_slider, 0, 1)
        parameters_layout.addWidget(self.clip_value_label, 0, 2)

        # Tile Grid Size Slider and Label
        tile_label = QLabel("Tile Grid Size:")
        self.tile_slider = QSlider(Qt.Orientation.Horizontal)
        self.tile_slider.setMinimum(1)
        self.tile_slider.setMaximum(32)
        self.tile_slider.setValue(8)        # Default (8,8)
        self.tile_slider.setTickInterval(1)
        self.tile_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.tile_value_label = QLabel("8")  # Initial value
        self.tile_slider.setToolTip("Adjust the size of grid for histogram equalization. Larger values affect broader areas.")

        self.tile_slider.valueChanged.connect(self.update_tile_value)
        self.tile_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(tile_label, 1, 0)
        parameters_layout.addWidget(self.tile_slider, 1, 1)
        parameters_layout.addWidget(self.tile_value_label, 1, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_clahe)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_clip_value(self, value):
        """
        Updates the clip limit label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        clip_limit = value / 10.0  # 0.1 to 4.0
        self.clip_value_label.setText(f"{clip_limit:.1f}")

    def update_tile_value(self, value):
        """
        Updates the tile grid size label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        self.tile_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current slider values and applied mask.
        """
        if self.original_image is None:
            # Clear the scene and then re-add the pixmap item.
            self.preview_scene.clear()
            self.pixmap_item = QGraphicsPixmapItem()  # Reinitialize pixmap item.
            self.preview_scene.addItem(self.pixmap_item)
            self.preview_scene.addText("No image loaded.")
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                preview_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use CLAHE image directly
                preview_image = clahe_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate CLAHE preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)

        # Convert QRect to QRectF before setting
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_clahe(self):
        """
        Applies CLAHE with current parameters to the main image, considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply CLAHE.")
            self.reject()
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                combined_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="CLAHE"
                )
            else:
                # No mask applied; update with the CLAHE-processed image directly
                self.image_manager.set_image(
                    clahe_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="CLAHE"
                )

            # Inform the user of the successful operation
            QMessageBox.information(self, "Success", "CLAHE applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply CLAHE:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders to their default values and updates the preview.
        """
        self.clip_slider.setValue(20)  # Default 2.0
        self.tile_slider.setValue(8)   # Default (8,8)

class MorphologyDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the MorphologyDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Morphological Operations")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # Morphological Parameters Group
        parameters_group = QGroupBox("Morphological Parameters")
        parameters_layout = QGridLayout()

        # Operation Type Selection
        operation_label = QLabel("Operation Type:")
        self.operation_combo = QComboBox()
        self.operation_combo.addItems(["Erosion", "Dilation", "Opening", "Closing"])
        self.operation_combo.setToolTip("Select the type of morphological operation to apply.")
        self.operation_combo.currentTextChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(operation_label, 0, 0)
        parameters_layout.addWidget(self.operation_combo, 0, 1, 1, 2)

        # Kernel Size Slider and Label
        kernel_label = QLabel("Kernel Size:")
        self.kernel_slider = QSlider(Qt.Orientation.Horizontal)
        self.kernel_slider.setMinimum(1)
        self.kernel_slider.setMaximum(31)
        self.kernel_slider.setValue(3)        # Default kernel size
        self.kernel_slider.setTickInterval(2)
        self.kernel_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.kernel_value_label = QLabel("3")  # Initial value
        self.kernel_slider.setToolTip("Adjust the size of the structuring element. Must be an odd number.")

        self.kernel_slider.valueChanged.connect(self.update_kernel_value)
        self.kernel_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(kernel_label, 1, 0)
        parameters_layout.addWidget(self.kernel_slider, 1, 1)
        parameters_layout.addWidget(self.kernel_value_label, 1, 2)

        # Iterations Slider and Label
        iterations_label = QLabel("Iterations:")
        self.iterations_slider = QSlider(Qt.Orientation.Horizontal)
        self.iterations_slider.setMinimum(1)
        self.iterations_slider.setMaximum(10)
        self.iterations_slider.setValue(1)        # Default iterations
        self.iterations_slider.setTickInterval(1)
        self.iterations_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.iterations_value_label = QLabel("1")  # Initial value
        self.iterations_slider.setToolTip("Adjust the number of times the operation is applied.")

        self.iterations_slider.valueChanged.connect(self.update_iterations_value)
        self.iterations_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(iterations_label, 2, 0)
        parameters_layout.addWidget(self.iterations_slider, 2, 1)
        parameters_layout.addWidget(self.iterations_value_label, 2, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_morphology)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image.copy() is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_kernel_value(self, value):
        """
        Updates the kernel size label based on slider position.
        Ensures that the kernel size is always an odd number.
        
        Args:
            value (int): Current value of the slider.
        """
        if value % 2 == 0:
            value += 1  # Ensure kernel size is odd
            if value > self.kernel_slider.maximum():
                value = self.kernel_slider.maximum() - 1 if self.kernel_slider.maximum() % 2 == 0 else self.kernel_slider.maximum()
            self.kernel_slider.setValue(value)
        self.kernel_value_label.setText(str(value))

    def update_iterations_value(self, value):
        """
        Updates the iterations label based on slider position.
        
        Args:
            value (int): Current value of the slider.
        """
        self.iterations_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer to limit the frequency of preview updates.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current parameters and applied mask.
        """
        if self.original_image is None:
            self.pixmap_item.setPixmap(QPixmap())
            self.preview_scene.clear()
            self.preview_scene.addText("No image loaded.")
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1
            self.kernel_slider.setValue(kernel_size)

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                preview_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use morphed image directly
                preview_image = morphed_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate Morphological preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.

        Args:
            image (np.ndarray): Image to display.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))  # Convert QRect to QRectF

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_morphology(self):
        """
        Applies the selected morphological operation with current parameters to the main image,
        considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply morphological operations.")
            self.reject()
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                combined_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="morphology"
                )
            else:
                # No mask applied; update with the morphed image directly
                self.image_manager.set_image(
                    morphed_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="morphology"
                )

            # Inform the user of the successful operation
            QMessageBox.information(self, "Success", f"{self.operation_combo.currentText()} applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply morphological operations:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders and operation type to default values and updates the preview.
        """
        self.operation_combo.setCurrentIndex(0)  # 'Erosion'
        self.kernel_slider.setValue(3)           # Default kernel size
        self.iterations_slider.setValue(1)       # Default iterations

class WhiteBalanceDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("White Balance")
        self.setGeometry(100, 100, 800, 500)  # Adjusted size to remove preview area
        self.initUI()

    def initUI(self):
        main_layout = QVBoxLayout()

        # White Balance Type Selection
        type_label = QLabel("White Balance Type:")
        self.type_combo = QComboBox()
        self.type_combo.addItems(["Star-Based", "Manual", "Auto"])
        self.type_combo.currentTextChanged.connect(self.update_options)

        type_layout = QHBoxLayout()
        type_layout.addWidget(type_label)
        type_layout.addWidget(self.type_combo)
        type_layout.addStretch()

        main_layout.addLayout(type_layout)

        # Standard White Balance Options
        self.standard_widget = QWidget()
        self.standard_layout = QVBoxLayout()

        # Gain Sliders for R, G, B
        gain_group = QGroupBox("Adjust Gain for Each Channel")
        gain_layout = QGridLayout()

        self.r_slider = QSlider(Qt.Orientation.Horizontal)
        self.r_slider.setMinimum(50)
        self.r_slider.setMaximum(150)
        self.r_slider.setValue(100)  # Represents 0.5 to 1.5
        self.r_slider.setTickInterval(10)
        self.r_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.r_label = QLabel("100")

        self.g_slider = QSlider(Qt.Orientation.Horizontal)
        self.g_slider.setMinimum(50)
        self.g_slider.setMaximum(150)
        self.g_slider.setValue(100)
        self.g_slider.setTickInterval(10)
        self.g_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.g_label = QLabel("100")

        self.b_slider = QSlider(Qt.Orientation.Horizontal)
        self.b_slider.setMinimum(50)
        self.b_slider.setMaximum(150)
        self.b_slider.setValue(100)
        self.b_slider.setTickInterval(10)
        self.b_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.b_label = QLabel("100")

        # Connect sliders to update labels
        self.r_slider.valueChanged.connect(lambda val: self.r_label.setText(str(val)))
        self.g_slider.valueChanged.connect(lambda val: self.g_label.setText(str(val)))
        self.b_slider.valueChanged.connect(lambda val: self.b_label.setText(str(val)))

        # Arrange sliders and labels in grid
        gain_layout.addWidget(QLabel("Red Gain:"), 0, 0)
        gain_layout.addWidget(self.r_slider, 0, 1)
        gain_layout.addWidget(self.r_label, 0, 2)

        gain_layout.addWidget(QLabel("Green Gain:"), 1, 0)
        gain_layout.addWidget(self.g_slider, 1, 1)
        gain_layout.addWidget(self.g_label, 1, 2)

        gain_layout.addWidget(QLabel("Blue Gain:"), 2, 0)
        gain_layout.addWidget(self.b_slider, 2, 1)
        gain_layout.addWidget(self.b_label, 2, 2)

        gain_group.setLayout(gain_layout)
        self.standard_layout.addWidget(gain_group)
        self.standard_widget.setLayout(self.standard_layout)
        main_layout.addWidget(self.standard_widget)

        # Star-Based White Balance Options
        self.star_widget = QWidget()
        self.star_layout = QVBoxLayout()
        self.star_widget.setLayout(self.star_layout)
        self.star_widget.hide()  # Hidden initially

        star_info = QLabel("Star-Based White Balance automatically detects stars to adjust colors.")
        self.star_layout.addWidget(star_info)

        # Sensitivity Slider for Star Detection Threshold (scaled from 1 to 100 sigma)
        sensitivity_group = QGroupBox("Detection Sensitivity")
        sensitivity_layout = QHBoxLayout()

        # Add sensitivity direction labels
        more_sensitive_label = QLabel("More Sensitive")
        less_sensitive_label = QLabel("Less Sensitive")

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(1)
        self.sensitivity_slider.setMaximum(100)
        self.sensitivity_slider.setValue(50)  # Default: 50 sigma
        self.sensitivity_slider.setTickInterval(10)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_label = QLabel("Threshold: 50")  # Initial value

        # Create a timer to delay star detection until the user stops adjusting the slider
        self.sensitivity_timer = QTimer()
        self.sensitivity_timer.setSingleShot(True)
        self.sensitivity_timer.setInterval(1000)  # 1 second delay
        self.sensitivity_timer.timeout.connect(self.detect_and_display_stars)

        def update_sensitivity_label(value):
            self.sensitivity_label.setText(f"Threshold: {value:.2f}")
            self.sensitivity_timer.start()  # Restart debounce timer

        self.sensitivity_slider.valueChanged.connect(update_sensitivity_label)

        # Add components to layout
        sensitivity_layout.addWidget(more_sensitive_label)
        sensitivity_layout.addWidget(self.sensitivity_slider)
        sensitivity_layout.addWidget(less_sensitive_label)
        sensitivity_layout.addWidget(self.sensitivity_label)

        sensitivity_group.setLayout(sensitivity_layout)
        self.star_layout.addWidget(sensitivity_group)


        # Autostretch Checkbox
        self.autostretch_checkbox = QCheckBox("Autostretch Display")
        self.autostretch_checkbox.setChecked(True)  # Enable by default
        self.autostretch_checkbox.stateChanged.connect(self.detect_and_display_stars)
        self.star_layout.addWidget(self.autostretch_checkbox)


        # Label to show number of detected stars
        self.star_count_label = QLabel("Detecting stars...")
        self.star_layout.addWidget(self.star_count_label)

        # Image display for detected stars
        self.star_image_label = QLabel()
        self.star_image_label.setFixedSize(800, 500)  # Reduced size as no preview is needed
        self.star_image_label.setStyleSheet("border: 1px solid black;")
        self.star_layout.addWidget(self.star_image_label)

        main_layout.addWidget(self.star_widget)

        # Apply and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_white_balance)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)

        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # **Set initial selection to "Star-Based" and display relevant widgets**
        self.type_combo.setCurrentText("Star-Based")
        self.update_options("Star-Based")

    def update_sensitivity_label(self, value):
        self.sensitivity_label.setText(f"Threshold: {value}")

    def update_options(self, text):
        if text == "Manual":
            self.star_widget.hide()
            self.standard_widget.show()
        elif text == "Auto":
            self.standard_widget.hide()
            self.star_widget.hide()
        elif text == "Star-Based":
            self.standard_widget.hide()
            self.star_widget.show()
            self.star_count_label.setText("Detecting stars...")
            # Trigger star detection and display
            QTimer.singleShot(1000, self.detect_and_display_stars)

    def detect_and_display_stars(self):
        try:
            image = self.image_manager.image
            if image is not None:
                threshold = self.sensitivity_slider.value()  # Convert to float
                autostretch_enabled = self.autostretch_checkbox.isChecked()

                # Apply star-based WB with optional stretch for display
                balanced_image, star_count, image_with_stars = apply_star_based_white_balance(
                    image, threshold, autostretch=autostretch_enabled
                )

                # Convert image_with_stars to QPixmap for display
                height, width, channel = image_with_stars.shape
                bytes_per_line = 3 * width
                q_image = QImage(image_with_stars.data, width, height, bytes_per_line, QImage.Format.Format_BGR888)
                pixmap = QPixmap.fromImage(q_image).scaled(
                    self.star_image_label.width(),
                    self.star_image_label.height(),
                    Qt.AspectRatioMode.KeepAspectRatio
                )
                self.star_image_label.setPixmap(pixmap)
                self.star_count_label.setText(f"Detected {star_count} stars.")
            else:
                self.star_count_label.setText("No image loaded.")
        except Exception as e:
            self.star_count_label.setText("Detection failed.")
            self.star_image_label.clear()
            QMessageBox.critical(self, "Error", f"Failed to detect stars:\n{e}")


    def apply_white_balance(self):
        wb_type = self.type_combo.currentText()

        try:
            image = self.image_manager.image
            if image is not None:
                if wb_type == "Manual":
                    r_gain = self.r_slider.value() / 100.0  # 0.5 to 1.5
                    g_gain = self.g_slider.value() / 100.0
                    b_gain = self.b_slider.value() / 100.0
                    balanced_image = apply_standard_white_balance(image, r_gain, g_gain, b_gain)
                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )
                    QMessageBox.information(self, "Success", "Manual White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Auto":
                    balanced_image = apply_auto_white_balance(image)
                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )
                    QMessageBox.information(self, "Success", "Auto White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Star-Based":
                    threshold = self.sensitivity_slider.value()
                    balanced_image, star_count, _, raw_star_colors, after_star_colors = apply_star_based_white_balance(
                        image,
                        threshold,
                        autostretch=False,
                        reuse_cached_sources=True,
                        return_star_colors=True  # ✅ enable star color scatter plot
                    )

                    # Show the technical scatter plot after applying WB
                    plot_star_color_ratios_comparison(raw_star_colors, after_star_colors)

                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )

                    QMessageBox.information(self, "Success", f"Star-Based White Balance applied successfully.\nDetected {star_count} stars.")
                    self.accept()
                else:
                    raise ValueError("Invalid White Balance Type.")
            else:
                QMessageBox.warning(self, "No Image", "No image loaded to apply White Balance.")
                self.reject()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply White Balance:\n{e}")
            self.reject()

class PixelImage:
    def __init__(self, array):
        self.array = array

    def __getitem__(self, channel_index):
        """
        Return a new PixelImage containing only the requested channel (2D array).
        For example, slot0[0] -> red channel, slot0[1] -> green, slot0[2] -> blue.
        """
        # Make sure the requested channel is valid for this image's shape.
        if self.array.ndim < 3:
            raise ValueError("This image has no channel dimension to index.")
        if not (0 <= channel_index < self.array.shape[2]):
            raise IndexError(f"Channel index {channel_index} is out of range for shape {self.array.shape}")
        
        single_channel = self.array[..., channel_index]  # shape (height, width)
        return PixelImage(single_channel)

    def __add__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array + other.array)
        else:
            return PixelImage(self.array + other)
    __radd__ = __add__

    def __sub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array - other.array)
        else:
            return PixelImage(self.array - other)

    def __rsub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array - self.array)
        else:
            return PixelImage(other - self.array)

    def __mul__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array * other.array)
        else:
            return PixelImage(self.array * other)
    __rmul__ = __mul__

    def __truediv__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array / other.array)
        else:
            return PixelImage(self.array / other)

    def __invert__(self):
        # Overload the ~ operator to mean image inversion: 1 - array.
        return PixelImage(1 - self.array)

    def __xor__(self, other):
        # Overload the ^ operator for exponentiation.
        if isinstance(other, PixelImage):
            return PixelImage(self.array ** other.array)
        else:
            return PixelImage(self.array ** other)

    def __rxor__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array ** self.array)
        else:
            return PixelImage(other ** self.array)

    def __repr__(self):
        return f"PixelImage({self.array})"
    
    def __lt__(self, other):
        if isinstance(other, PixelImage):
            return self.array < other.array
        else:
            return self.array < other   

    def __eq__(self, other):
        if isinstance(other, PixelImage):
            return self.array == other.array
        else:
            return self.array == other

class PixelMathDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Pixel Math")
        
        # Attempt to retrieve QSettings from the parent
        if parent is not None and hasattr(parent, "settings"):
            self.settings = parent.settings
        else:
            self.settings = None

        self.favorites = []
        self.initUI()
        self.load_favorites()

    def initUI(self):
        main_layout = QVBoxLayout(self)

        instruction = QLabel(
            "Enter a pixel math expression using image slot variables.\n"
            "Examples:\n"
            "  (slot0 + slot1) / 2\n"
            "  slot0 - med(slot0)\n"
            "  ~(~slot0 * ~slot1)\n"
            "  slot0 - mean(slot0)\n"
            "  min(slot0) + max(slot0)\n"
            "  log(slot0)\n"
            "  iff(slot0 < med(slot0), 0, 1)\n"
            "  mtf(slot0, 0.25)   <-- midtones transform\n\n"
            "You may also use your renamed slot names (e.g., stars_image, starless_image).\n"
            "Note: The '~' operator means image inversion (i.e., 1 - image),\n"
            "      '^' is overloaded for exponentiation, and 'iff' is a conditional function.\n"
            "      For Separate Expressions use channel indexes ie slot0[0] + slot0[1] etc.\n"
        )
        main_layout.addWidget(instruction)

        # --- Radio Buttons for Single vs. Separate ---
        mode_layout = QHBoxLayout()
        self.single_expr_radio = QRadioButton("Single Expression")
        self.separate_expr_radio = QRadioButton("Separate Expressions (R, G, B)")
        self.single_expr_radio.setChecked(True)
        
        self.mode_button_group = QButtonGroup()
        self.mode_button_group.addButton(self.single_expr_radio)
        self.mode_button_group.addButton(self.separate_expr_radio)
        self.mode_button_group.buttonClicked.connect(self.on_mode_changed)
        
        mode_layout.addWidget(self.single_expr_radio)
        mode_layout.addWidget(self.separate_expr_radio)
        main_layout.addLayout(mode_layout)

        # --- Single Expression Field ---
        self.single_expression_edit = QPlainTextEdit()
        self.single_expression_edit.setPlaceholderText("Enter single pixel math expression")
        self.single_expression_edit.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        main_layout.addWidget(self.single_expression_edit)

        # --- Separate (Per-Channel) Expressions (Tab Widget) ---
        self.tab_widget = QTabWidget()
        self.tab_widget.setVisible(False)  # hidden by default
        # Create a tab for R, G, B
        self.red_edit = QPlainTextEdit()
        self.red_edit.setPlaceholderText("Expression for Red channel")
        self.green_edit = QPlainTextEdit()
        self.green_edit.setPlaceholderText("Expression for Green channel")
        self.blue_edit = QPlainTextEdit()
        self.blue_edit.setPlaceholderText("Expression for Blue channel")

        # Optionally set the same stylesheet on these fields:
        for editor in (self.red_edit, self.green_edit, self.blue_edit):
            editor.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        # Add them as tabs
        tab_r = QWidget()
        tab_r_layout = QVBoxLayout(tab_r)
        tab_r_layout.addWidget(self.red_edit)
        self.tab_widget.addTab(tab_r, "Red")

        tab_g = QWidget()
        tab_g_layout = QVBoxLayout(tab_g)
        tab_g_layout.addWidget(self.green_edit)
        self.tab_widget.addTab(tab_g, "Green")

        tab_b = QWidget()
        tab_b_layout = QVBoxLayout(tab_b)
        tab_b_layout.addWidget(self.blue_edit)
        self.tab_widget.addTab(tab_b, "Blue")

        main_layout.addWidget(self.tab_widget)

        # --- Favorites area ---
        favorites_layout = QHBoxLayout()
        self.favorites_dropdown = QComboBox()
        self.favorites_dropdown.addItem("Select a favorite expression")
        self.favorites_dropdown.currentTextChanged.connect(self.load_favorite)
        favorites_layout.addWidget(self.favorites_dropdown)

        self.save_favorite_button = QPushButton("Save as Favorite")
        self.save_favorite_button.clicked.connect(self.save_favorite)
        favorites_layout.addWidget(self.save_favorite_button)

        # Remove Favorite Button
        self.remove_favorite_button = QPushButton("Remove Favorite")
        self.remove_favorite_button.clicked.connect(self.remove_selected_favorite)
        favorites_layout.addWidget(self.remove_favorite_button)

        # Clear All Favorites Button
        self.clear_all_favorites_button = QPushButton("Clear All Favorites")
        self.clear_all_favorites_button.clicked.connect(self.clear_all_favorites)
        favorites_layout.addWidget(self.clear_all_favorites_button)

        main_layout.addLayout(favorites_layout)

        # --- Buttons (OK, Cancel, Help) ---
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.apply_pixel_math)
        buttons.rejected.connect(self.reject)
        help_button = buttons.addButton("Help", QDialogButtonBox.ButtonRole.HelpRole)
        help_button.clicked.connect(self.show_help)
        main_layout.addWidget(buttons)

        self.setLayout(main_layout)

    def on_mode_changed(self, button):
        """
        Switch UI between single expression mode and separate (R,G,B) mode.
        """
        if button == self.single_expr_radio:
            # Single expression
            self.single_expression_edit.setVisible(True)
            self.tab_widget.setVisible(False)
        else:
            # Separate (R,G,B)
            self.single_expression_edit.setVisible(False)
            self.tab_widget.setVisible(True)

    # --- Favorite Expressions Persistence ---
    def load_favorites(self):
        if self.settings:
            favorites_list = self.settings.value("pixelmath_favorites", [])
            if isinstance(favorites_list, str):
                try:
                    favorites_list = json.loads(favorites_list)
                except Exception:
                    favorites_list = []
            elif not isinstance(favorites_list, list):
                favorites_list = list(favorites_list)
            self.favorites = favorites_list
        else:
            self.favorites = []
        
        self.favorites_dropdown.clear()
        self.favorites_dropdown.addItem("Select a favorite expression")
        for fav in self.favorites:
            self.favorites_dropdown.addItem(fav)

    def save_favorite(self):
        """
        Save the currently visible expression(s) as a favorite.
        For simplicity, we’ll just store the single or the RGB triple.
        """
        if self.single_expr_radio.isChecked():
            expr = self.single_expression_edit.toPlainText().strip()
        else:
            # For separate mode, maybe store the R/G/B together in some notation:
            r_expr = self.red_edit.toPlainText().strip()
            g_expr = self.green_edit.toPlainText().strip()
            b_expr = self.blue_edit.toPlainText().strip()
            expr = f"[R]{r_expr} | [G]{g_expr} | [B]{b_expr}"

        if expr and expr not in self.favorites:
            self.favorites.append(expr)
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.favorites_dropdown.addItem(expr)
            QMessageBox.information(self, "Saved as Favorite", "Expression saved to favorites.")
        else:
            QMessageBox.warning(self, "Invalid Expression", "Expression is empty or already in favorites.")

    def remove_selected_favorite(self):
        """
        Remove the currently selected favorite from the dropdown and from self.favorites.
        """
        current_text = self.favorites_dropdown.currentText()
        if current_text == "Select a favorite expression":
            QMessageBox.information(self, "Remove Favorite", "No valid favorite is selected.")
            return

        # Confirm removal
        reply = QMessageBox.question(
            self, 
            "Remove Favorite", 
            f"Are you sure you want to remove '{current_text}' from favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, 
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            if current_text in self.favorites:
                self.favorites.remove(current_text)
                if self.settings:
                    self.settings.setValue("pixelmath_favorites", self.favorites)
                self.load_favorites()  # reload the dropdown
                QMessageBox.information(self, "Remove Favorite", "Favorite removed successfully.")
            else:
                QMessageBox.warning(self, "Remove Favorite", "Favorite not found in list.")

    def clear_all_favorites(self):
        """
        Clear all favorites after a confirmation.
        """
        reply = QMessageBox.question(
            self,
            "Clear All Favorites",
            "Are you sure you want to remove ALL favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.favorites.clear()
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.load_favorites()
            QMessageBox.information(self, "Clear All Favorites", "All favorites have been removed.")

    def load_favorite(self, favorite_expr):
        """
        If the user picks a favorite that has the [R] [G] [B] format,
        parse it into the separate text fields. Otherwise, treat it as a single expression.
        """
        if favorite_expr == "Select a favorite expression":
            return

        # Quick detection to see if it has the [R] or [G] or [B] tokens
        if "[R]" in favorite_expr or "[G]" in favorite_expr or "[B]" in favorite_expr:
            # Switch to separate mode
            self.separate_expr_radio.setChecked(True)
            self.on_mode_changed(self.separate_expr_radio)

            # Attempt to split them out
            # Simple approach: [R] ... | [G] ... | [B] ...
            parts = favorite_expr.split("|")
            r_expr = ""
            g_expr = ""
            b_expr = ""
            for p in parts:
                p = p.strip()
                if p.startswith("[R]"):
                    r_expr = p[3:].strip()
                elif p.startswith("[G]"):
                    g_expr = p[3:].strip()
                elif p.startswith("[B]"):
                    b_expr = p[3:].strip()

            self.red_edit.setPlainText(r_expr)
            self.green_edit.setPlainText(g_expr)
            self.blue_edit.setPlainText(b_expr)
        else:
            # Single expression
            self.single_expr_radio.setChecked(True)
            self.on_mode_changed(self.single_expr_radio)
            self.single_expression_edit.setPlainText(favorite_expr)
    # --- Pixel Math Evaluation ---
    def show_help(self):
        help_text = (
            "Allowed Operators:\n"
            "  +, -, *, /: Standard arithmetic operations\n"
            "  ^: Exponentiation (overloaded; e.g., slot0 ^ 2 means slot0**2)\n"
            "  ~: Image inversion (i.e., 1 - image)\n"
            "  <, ==: Elementwise comparisons (slot0 < med(slot0))\n\n"
            "Allowed Functions:\n"
            "  med(x), mean(x), min(x), max(x), std(x), mad(x), log(x)\n"
            "  iff(condition, a, b): elementwise conditional\n"
            "  mtf(x, m): Midtones transform\n\n"
            "Variables:\n"
            "  img: The current image (replicated to RGB if needed)\n"
            "  slot0, slot1, ...: image slots\n"
            "  Channels can be accessed via [0],[1],[2]. e.g. slot0[0]\n\n"
            "Notes:\n"
            "  - Grayscale images automatically get 3 channels.\n"
            "  - For separate expressions mode, each expression is evaluated for its channel.\n"
        )
        QMessageBox.information(self, "Pixel Math Help", help_text)

    # Updated helper functions (med, mean, min, max, std, mad, log, iff, mtf) remain unchanged...
    def med(self, x):
        """
        Return a PixelImage where each channel (if present) is replaced by its median value.
        If x is 2D, we replace that entire 2D array with its median.
        """
        if isinstance(x, PixelImage):
            arr = x.array
            if arr.ndim == 2:
                # Single-channel (2D)
                median_val = np.median(arr)
                # Make a new 2D array with every pixel = median_val
                new_arr = np.full_like(arr, median_val)
                return PixelImage(new_arr)
            elif arr.ndim == 3:
                # 3D: compute per-channel medians
                med_vals = np.median(arr, axis=(0, 1))  # shape (3,)
                new_arr = np.empty_like(arr)
                for ch in range(arr.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return PixelImage(new_arr)
            else:
                # Some unexpected dimensionality
                raise ValueError(f"med() got array with unsupported ndim={arr.ndim}")
        else:
            # If x is not a PixelImage but a raw np.ndarray, handle that scenario similarly:
            if x.ndim == 2:
                median_val = np.median(x)
                new_arr = np.full_like(x, median_val)
                return new_arr
            elif x.ndim == 3:
                med_vals = np.median(x, axis=(0,1))
                new_arr = np.empty_like(x)
                for ch in range(x.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return new_arr
            else:
                # 1D or something else
                return np.median(x)
            
    def mean(self, x):
        """Replace each channel (or the single channel) by its mean value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            # Single channel (2D)
            val = np.mean(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            # 3-channel
            means = np.mean(arr, axis=(0, 1))  # shape=(3,)
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = means[ch]
        else:
            # 1D or something else—decide how you want to handle it or just return arr
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def min(self, x):
        """Replace each channel (or the single channel) by its min value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.min(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            mins = np.min(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = mins[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def max(self, x):
        """Replace each channel (or the single channel) by its max value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.max(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            maxs = np.max(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = maxs[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def std(self, x):
        """Replace each channel (or the single channel) by its std value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.std(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            stds = np.std(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = stds[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def mad(self, x):
        """Replace each channel (or the single channel) by its median absolute deviation."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            m = np.median(arr)
            mad_val = np.median(np.abs(arr - m))
            new_arr = np.full(arr.shape, mad_val, dtype=arr.dtype)
        elif arr.ndim == 3:
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                channel = arr[..., ch]
                m = np.median(channel)
                mad_val = np.median(np.abs(channel - m))
                new_arr[..., ch] = mad_val
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def log(self, x):
        if isinstance(x, PixelImage):
            return PixelImage(np.log(x.array))
        else:
            return np.log(x)

    def iff(self, condition, a, b):
        if isinstance(condition, PixelImage):
            cond_val = condition.array
        else:
            cond_val = condition

        if isinstance(a, PixelImage):
            a_val = a.array
        else:
            a_val = a

        if isinstance(b, PixelImage):
            b_val = b.array
        else:
            b_val = b

        result = np.where(cond_val, a_val, b_val)
        if isinstance(condition, PixelImage) or isinstance(a, PixelImage) or isinstance(b, PixelImage):
            return PixelImage(result)
        else:
            return result

    def mtf(self, x, m):
        if isinstance(x, PixelImage):
            arr = x.array
        else:
            arr = x
        with np.errstate(divide='ignore', invalid='ignore'):
            new_arr = ((m - 1) * arr) / (((2 * m - 1) * arr) - m)
            new_arr = np.nan_to_num(new_arr, nan=0.0, posinf=1.0, neginf=0.0)
        if isinstance(x, PixelImage):
            return PixelImage(new_arr)
        else:
            return new_arr

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                if self.image_manager.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                if mask.shape[:2] != self.image_manager.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None


    def evaluate_multiline_expression(self, expr, safe_namespace):
        """
        Allows multiple lines in the user expression.
        - All but the last line are executed with `exec`, so they can contain assignments.
        - The last line is evaluated with `eval` to produce the final result.
        """

        # Split into lines and strip out empty ones
        lines = [line.strip() for line in expr.split('\n') if line.strip()]
        if not lines:
            raise ValueError("No expression provided.")

        # Exec each line except the last
        for line in lines[:-1]:
            exec(line, {"__builtins__": None}, safe_namespace)

        # Evaluate the last line, which must be an expression returning a result
        final_line = lines[-1]
        result = eval(final_line, {"__builtins__": None}, safe_namespace)
        return result

    def apply_pixel_math(self):
        """
        Evaluates the user-entered expression(s) and updates the current image slot.
        If single_expr_radio is checked, we do the usual single-expression approach.
        If separate_expr_radio is checked, we evaluate three expressions (R, G, B).
        """
        if self.single_expr_radio.isChecked():
            # Single expression mode
            expr = self.single_expression_edit.toPlainText().strip()
            if not expr:
                QMessageBox.warning(self, "No Expression", "Please enter a valid pixel math expression.")
                return
            
            try:
                # Evaluate single expression
                result = self.evaluate_expression(expr)

                # Convert PixelImage -> array if needed
                if isinstance(result, PixelImage):
                    new_img = result.array
                else:
                    new_img = result

                # If it's a scalar, fill the current image shape
                current_img = self.image_manager.image
                if current_img.ndim == 2:
                    current_img = np.stack([current_img]*3, axis=-1)
                if np.isscalar(new_img):
                    new_img = np.full(current_img.shape, new_img, dtype=current_img.dtype)

                # Update the image
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = expr
                mask = self.get_active_mask()
                if mask is not None:
                    original = self.image_manager.image
                    if original.ndim == 2:
                        original = np.stack([original]*3, axis=-1)
                    if mask.ndim == 2:
                        mask = np.expand_dims(mask, axis=-1)
                    if mask.shape[2] == 1 and original.ndim == 3:
                        mask = np.repeat(mask, original.shape[2], axis=2)

                    new_img = new_img * mask + original * (1 - mask)
                    new_img = np.clip(new_img, 0.0, 1.0)

                self.image_manager.set_image(new_img, metadata, step_name="Pixel Math")

                QMessageBox.information(self, "Pixel Math", "Pixel math operation applied successfully.")
                self.accept()
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

        else:
            # Separate expressions mode
            expr_r = self.red_edit.toPlainText().strip()
            expr_g = self.green_edit.toPlainText().strip()
            expr_b = self.blue_edit.toPlainText().strip()

            if not expr_r and not expr_g and not expr_b:
                QMessageBox.warning(self, "No Expression", 
                                    "Please enter a valid expression for at least one channel.")
                return

            try:
                # Evaluate each channel expression or treat as 0 if blank
                r_result = self.evaluate_expression(expr_r) if expr_r else 0
                g_result = self.evaluate_expression(expr_g) if expr_g else 0
                b_result = self.evaluate_expression(expr_b) if expr_b else 0

                # Convert PixelImages to arrays
                if isinstance(r_result, PixelImage):
                    r_result = r_result.array
                if isinstance(g_result, PixelImage):
                    g_result = g_result.array
                if isinstance(b_result, PixelImage):
                    b_result = b_result.array

                # Validate shapes: must be scalar or 2D
                def ensure_2d_or_scalar(arr, channel_name):
                    if np.isscalar(arr):
                        return
                    if arr.ndim == 3:
                        raise ValueError(
                            f"Expression for {channel_name} returned a 3D array. "
                            "In separate expressions mode, please specify a single channel, e.g. slot0[0]."
                        )

                ensure_2d_or_scalar(r_result, "Red")
                ensure_2d_or_scalar(g_result, "Green")
                ensure_2d_or_scalar(b_result, "Blue")

                # Now get shape of current image for stacking
                current_img = self.image_manager.image
                if current_img is None:
                    QMessageBox.warning(self, "No Image", "There is no image loaded to operate on.")
                    return
                if current_img.ndim == 2:
                    current_img = np.stack([current_img]*3, axis=-1)
                
                h, w, _ = current_img.shape

                # If scalar, fill to (H,W)
                if np.isscalar(r_result):
                    r_result = np.full((h, w), r_result, dtype=current_img.dtype)
                if np.isscalar(g_result):
                    g_result = np.full((h, w), g_result, dtype=current_img.dtype)
                if np.isscalar(b_result):
                    b_result = np.full((h, w), b_result, dtype=current_img.dtype)

                # Stack
                combined = np.stack([r_result, g_result, b_result], axis=-1)

                # Update the slot
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = f"R:{expr_r}, G:{expr_g}, B:{expr_b}"
                mask = self.get_active_mask()
                if mask is not None:
                    original = self.image_manager.image
                    if original.ndim == 2:
                        original = np.stack([original]*3, axis=-1)
                    if mask.ndim == 2:
                        mask = np.expand_dims(mask, axis=-1)
                    if mask.shape[2] == 1 and original.ndim == 3:
                        mask = np.repeat(mask, original.shape[2], axis=2)

                    combined = combined * mask + original * (1 - mask)
                    combined = np.clip(combined, 0.0, 1.0)

                self.image_manager.set_image(combined, metadata, step_name="Pixel Math")


                QMessageBox.information(self, "Pixel Math", 
                                        "Pixel math operation (per-channel) applied successfully.")
                self.accept()

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

    def evaluate_expression(self, expr):
        """
        Evaluates a single expression in the restricted environment (safe_namespace).
        Returns a PixelImage or numpy array. 
        """
        if not expr:
            return 0  # If no expression, treat as 0

        # Create a safe namespace
        safe_namespace = {
            "np": np,
            "med": self.med,
            "mean": self.mean,
            "min": self.min,
            "max": self.max,
            "std": self.std,
            "mad": self.mad,
            "log": self.log,
            "iff": self.iff,
            "mtf": self.mtf,
        }

        # Insert current image as 'img'
        current_img = self.image_manager.image
        if current_img is None:
            raise ValueError("No current image loaded.")
        if current_img.ndim == 2:
            current_img = np.stack([current_img]*3, axis=-1)
        safe_namespace["img"] = PixelImage(current_img)

        # Insert image slots as slot0, slot1, ...
        max_slots = self.image_manager.max_slots
        parent = self.parent()
        for i in range(max_slots):
            img = self.image_manager._images.get(i, None)
            if img is not None:
                if img.ndim == 2:
                    img = np.stack([img]*3, axis=-1)
                pix_img = PixelImage(img)
                safe_namespace[f"slot{i}"] = pix_img
                if parent is not None and hasattr(parent, "slot_names"):
                    custom_name = parent.slot_names.get(i, None)
                    if custom_name:
                        safe_namespace[custom_name] = pix_img

        # Evaluate
            # Instead of a direct `eval`, we now do:
        return self.evaluate_multiline_expression(expr, safe_namespace)
        if isinstance(result, PixelImage):
            return result
        else:
            return result  # Could be scalar or ndarray

class TransformHandle(QGraphicsEllipseItem):
    def __init__(self, parent_item, scene):
        super().__init__(-5, -5, 10, 10)
        self.parent_item = parent_item
        self.scene = scene

        self.setBrush(QColor("blue"))
        self.setPen(QPen(Qt.PenStyle.SolidLine))
        self.setCursor(Qt.CursorShape.SizeAllCursor)
        self.setZValue(2)

        self.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsItem.GraphicsItemFlag.ItemIsFocusable |
            QGraphicsItem.GraphicsItemFlag.ItemIgnoresParentOpacity |
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable
        )

        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton)
        self.setAcceptHoverEvents(True)

        self.initial_distance = None
        self.initial_angle = None
        self.initial_scale = parent_item.scale()

        self.scene.addItem(self)
        self.update_position()

    def update_position(self):
        corner = self.parent_item.boundingRect().topRight()
        scene_corner = self.parent_item.mapToScene(corner)
        self.setPos(scene_corner)

    def mousePressEvent(self, event):
        center = self.parent_item.mapToScene(self.parent_item.boundingRect().center())
        handle_scene_pos = self.scenePos()
        delta = handle_scene_pos - center
        self.initial_distance = math.hypot(delta.x(), delta.y())
        self.initial_angle = math.degrees(math.atan2(delta.y(), delta.x()))
        self.initial_scale = self.parent_item.scale()
        event.accept()

    def mouseMoveEvent(self, event):
        center = self.parent_item.mapToScene(self.parent_item.boundingRect().center())
        new_pos = self.mapToScene(event.pos())
        delta = new_pos - center
        distance = math.hypot(delta.x(), delta.y())
        angle = math.degrees(math.atan2(delta.y(), delta.x()))

        # Apply scale
        scale_factor = distance / self.initial_distance if self.initial_distance != 0 else 1.0
        scale = max(0.05, self.initial_scale * scale_factor)
        self.parent_item.setScale(scale)

        # Apply rotation
        rotation = angle - self.initial_angle
        self.parent_item.setRotation(rotation)

        self.update_position()
        event.accept()

    def mouseReleaseEvent(self, event):
        self.initial_distance = None
        self.initial_angle = None
        self.initial_scale = self.parent_item.scale()
        event.accept()


class InsertView(QGraphicsView):
    def __init__(self, scene, parent_window):
        super().__init__(scene)
        self.parent_window = parent_window
        self.setRenderHints(QPainter.RenderHint.Antialiasing | QPainter.RenderHint.SmoothPixmapTransform)
        self.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)
        self.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        self.zoom_factor = 1.0
        self.min_zoom = 0.1
        self.max_zoom = 10.0

    def contextMenuEvent(self, event):
        scene_pos = self.mapToScene(event.pos())
        item = self.scene().itemAt(scene_pos, self.transform())

        # If it's a bounding box, get its parent item
        if isinstance(item, QGraphicsRectItem) and item.parentItem() in self.parent_window.inserts:
            item = item.parentItem()

        if isinstance(item, QGraphicsPixmapItem) and item in self.parent_window.inserts:
            menu = QMenu(self)
            positions = {
                "Top-Left": "top_left",
                "Top-Center": "top_center",
                "Top-Right": "top_right",
                "Middle-Left": "middle_left",
                "Center": "center",
                "Middle-Right": "middle_right",
                "Bottom-Left": "bottom_left",
                "Bottom-Center": "bottom_center",
                "Bottom-Right": "bottom_right"
            }
            for label, key in positions.items():
                menu.addAction(label, lambda k=key, i=item: self.parent_window.send_insert_to_position(i, k))
            menu.exec(event.globalPos())
        else:
            super().contextMenuEvent(event)

    def wheelEvent(self, event):
        # Support Ctrl+Wheel only
        if event.modifiers() & Qt.KeyboardModifier.ControlModifier:
            zoom_in = event.angleDelta().y() > 0
            zoom_step = 1.15
            factor = zoom_step if zoom_in else 1 / zoom_step
            self.set_zoom(self.zoom_factor * factor)
        else:
            super().wheelEvent(event)

    def set_zoom(self, new_zoom):
        new_zoom = max(self.min_zoom, min(self.max_zoom, new_zoom))
        self.zoom_factor = new_zoom
        self.setTransform(QTransform().scale(new_zoom, new_zoom))

    def zoom_in(self):
        self.set_zoom(self.zoom_factor * 1.15)

    @announce_zoom
    def zoom_out(self):
        self.set_zoom(self.zoom_factor / 1.15)

    def reset_zoom(self):
        self.set_zoom(1.0)

class SignatureInsertWindow(QMainWindow):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)  # Pass parent to super
        self.image_manager = image_manager
        self.setWindowTitle("Signature / Insert")
        self.setWindowIcon(QIcon(signature_icon_path))
        self.scene = QGraphicsScene(self)
        self.view = InsertView(self.scene, self)
        self.inserts = []
        self.bounding_boxes_enabled = True
        self.bounding_boxes = []
        self.bounding_box_pen = QPen(QColor("red"), 2, Qt.PenStyle.DashLine)


        # Sync timer for handle positioning
        self.sync_timer = QTimer()
        self.sync_timer.timeout.connect(self.sync_handles)
        self.sync_timer.start(16)

        # Set up UI
        central = QWidget(self)
        self.setCentralWidget(central)
        self.initUI(central)
        self.resize(800, 600)

    def initUI(self, parent):
        layout = QHBoxLayout(parent)
        controls = QVBoxLayout()

        load_slot_btn = QPushButton("Load Insert from Slot")
        load_slot_btn.clicked.connect(lambda: self.load_insert_source("slot"))
        load_file_btn = QPushButton("Load Insert from File")
        load_file_btn.clicked.connect(lambda: self.load_insert_source("file"))

        rotate_btn = QPushButton("Rotate Selected 90°")
        rotate_btn.clicked.connect(self.rotate_selected)

        self.scale_slider = QSlider(Qt.Orientation.Horizontal)
        self.scale_slider.setRange(10, 400)
        self.scale_slider.setValue(100)
        self.scale_slider.valueChanged.connect(self.scale_selected)

        self.opacity_slider = QSlider(Qt.Orientation.Horizontal)
        self.opacity_slider.setRange(0, 100)
        self.opacity_slider.setValue(100)
        self.opacity_slider.valueChanged.connect(self.opacity_changed)

        self.draw_box_checkbox = QCheckBox("Draw Bounding Box")
        self.draw_box_checkbox.setChecked(True)
        self.draw_box_checkbox.stateChanged.connect(self.toggle_bounding_boxes)

        # Color selector
        self.box_color_btn = QPushButton("Box Color")
        self.box_color_btn.clicked.connect(self.pick_box_color)

        # Thickness
        self.box_thickness_slider = QSlider(Qt.Orientation.Horizontal)
        self.box_thickness_slider.setRange(1, 10)
        self.box_thickness_slider.setValue(2)
        self.box_thickness_slider.valueChanged.connect(self.update_box_pen)

        # Style selector
        self.box_style_combo = QComboBox()
        self.box_style_combo.addItems(["Solid", "Dash", "Dot", "DashDot", "DashDotDot"])
        self.box_style_combo.currentIndexChanged.connect(self.update_box_pen)

        affix_btn = QPushButton("Affix Inserts")
        affix_btn.clicked.connect(self.affix_inserts)
        clear_btn = QPushButton("Clear All Inserts")
        clear_btn.clicked.connect(self.clear_inserts)

        zoom_controls = QHBoxLayout()
        zoom_in_btn = QPushButton("Zoom In")
        zoom_out_btn = QPushButton("Zoom Out")
        zoom_reset_btn = QPushButton("Reset Zoom")

        zoom_in_btn.clicked.connect(self.view.zoom_in)
        zoom_out_btn.clicked.connect(self.view.zoom_out)
        zoom_reset_btn.clicked.connect(self.view.reset_zoom)

        zoom_controls.addWidget(zoom_out_btn)
        zoom_controls.addWidget(zoom_in_btn)
        zoom_controls.addWidget(zoom_reset_btn)

        controls.addWidget(load_slot_btn)
        controls.addWidget(load_file_btn)
        controls.addSpacing(10)
        controls.addWidget(rotate_btn)
        controls.addWidget(QLabel("Scale Selected (%)"))
        controls.addWidget(self.scale_slider)
        controls.addWidget(QLabel("Transparency (%)"))
        controls.addWidget(self.opacity_slider)        
        controls.addSpacing(10)
        controls.addWidget(self.draw_box_checkbox)
        controls.addWidget(QLabel("Bounding Box Settings"))
        controls.addWidget(self.box_color_btn)
        controls.addWidget(QLabel("Box Thickness"))
        controls.addWidget(self.box_thickness_slider)
        controls.addWidget(QLabel("Box Style"))
        controls.addWidget(self.box_style_combo)        
        controls.addSpacing(10)
        controls.addStretch(1)
        controls.addWidget(QLabel("Right-click on an insert to send it a location."))
        controls.addWidget(affix_btn)
        controls.addWidget(clear_btn)
        controls.addStretch(1)
        controls.addSpacing(10)
        controls.addLayout(zoom_controls)

        container = QWidget()
        container.setLayout(controls)
        layout.addWidget(container)
        layout.addWidget(self.view, stretch=1)
        parent.setLayout(layout)

        self.update_main_image()

    def contextMenuEvent(self, event):
        """Show right-click menu on an insert."""
        item = self.scene.itemAt(self.view.mapToScene(event.pos()), self.view.transform())
        if isinstance(item, QGraphicsPixmapItem) and item in self.inserts:
            menu = QMenu(self)
            positions = {
                "Top-Left": "top_left",
                "Top-Center": "top_center",
                "Top-Right": "top_right",
                "Middle-Left": "middle_left",
                "Center": "center",
                "Middle-Right": "middle_right",
                "Bottom-Left": "bottom_left",
                "Bottom-Center": "bottom_center",
                "Bottom-Right": "bottom_right"
            }
            for label, pos_key in positions.items():
                menu.addAction(label, lambda pk=pos_key, i=item: self.send_insert_to_position(i, pk))
            menu.exec(event.globalPos())

    def send_insert_to_position(self, item, position_key):
        """Move insert to a specific location on the base image, respecting signature size."""
        base_item = next((obj for obj in self.scene.items()
                        if isinstance(obj, QGraphicsPixmapItem) and obj.zValue() == 0), None)
        if not base_item:
            return

        base_rect = base_item.boundingRect()
        item_rect = item.boundingRect()
        item_size = item_rect.size()

        # Compute target top-left point inside the base image
        if position_key == "top_left":
            target = base_rect.topLeft()
        elif position_key == "top_center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2, base_rect.top())
        elif position_key == "top_right":
            target = QPointF(base_rect.right() - item_size.width(), base_rect.top())
        elif position_key == "middle_left":
            target = QPointF(base_rect.left(), base_rect.center().y() - item_size.height() / 2)
        elif position_key == "center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2,
                            base_rect.center().y() - item_size.height() / 2)
        elif position_key == "middle_right":
            target = QPointF(base_rect.right() - item_size.width(),
                            base_rect.center().y() - item_size.height() / 2)
        elif position_key == "bottom_left":
            target = QPointF(base_rect.left(), base_rect.bottom() - item_size.height())
        elif position_key == "bottom_center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2,
                            base_rect.bottom() - item_size.height())
        elif position_key == "bottom_right":
            target = QPointF(base_rect.right() - item_size.width(),
                            base_rect.bottom() - item_size.height())
        else:
            return  # Unknown key

        # Convert target to scene coordinates
        new_scene_pos = base_item.mapToScene(target)
        item.setPos(new_scene_pos)


    def sync_handles(self):
        for item in self.scene.items():
            if isinstance(item, TransformHandle):
                item.update_position()

    def update_main_image(self):
        self.scene.clear()
        arr = self.image_manager.image
        if arr is None:
            return
        qimg = self.numpy_to_qimage(arr)
        pix = QPixmap.fromImage(qimg)
        item = QGraphicsPixmapItem(pix)
        item.setZValue(0)
        self.scene.addItem(item)

    def load_insert_source(self, source):
        pixmap = None

        if source == "file":
            file_path, _ = QFileDialog.getOpenFileName(
                self, "Select Insert Image", "", "Images (*.png *.tif *.tiff)"
            )
            if not file_path:
                return
            pixmap = QPixmap(file_path)

        elif source == "slot":
            # Ask which slot...
            if self.parent() and hasattr(self.parent(), "slot_names"):
                slot_names = self.parent().slot_names
            else:
                slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
            display = [slot_names[i] for i in range(self.image_manager.max_slots)]
            choice, ok = QInputDialog.getItem(self, "Select Slot", "Choose slot:", display, False)
            if not ok:
                return
            idx = display.index(choice)

            # --- ALWAYS use the in-memory image array for slots ---
            img_data = self.image_manager._images.get(idx)
            if img_data is None:
                QMessageBox.warning(self, "Missing Image", f"No image data in slot {idx}.")
                return
            qimg = self.numpy_to_qimage(img_data)
            pixmap = QPixmap.fromImage(qimg)

        # If we still don't have a valid pixmap, warn and bail
        if pixmap is None or pixmap.isNull():
            QMessageBox.warning(self, "Load Failed", "Could not load insert image.")
            return

        # Otherwise add it exactly as before...
        item = QGraphicsPixmapItem(pixmap)
        item.setFlags(
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsFocusable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemSendsGeometryChanges
        )
        item.setTransformationMode(Qt.TransformationMode.SmoothTransformation)
        item.setTransformOriginPoint(item.boundingRect().center())
        item.setZValue(1)
        item.setOpacity(1.0)

        self.scene.addItem(item)
        self.inserts.append(item)
        TransformHandle(item, self.scene)

        if self.bounding_boxes_enabled:
            rect = QGraphicsRectItem(item.boundingRect())
            rect.setParentItem(item)
            rect.setPen(self.bounding_box_pen)
            rect.setAcceptedMouseButtons(Qt.MouseButton.NoButton)
            rect.setAcceptDrops(False)
            rect.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIgnoresParentOpacity, True)
            rect.setFlag(QGraphicsItem.GraphicsItemFlag.ItemDoesntPropagateOpacityToChildren, True)
            rect.setZValue(item.zValue() + 0.1)
            self.scene.addItem(rect)
            self.bounding_boxes.append(rect)


    def rotate_selected(self):
        for it in self.inserts:
            if it.isSelected():
                it.setRotation(it.rotation() + 90)

    def scale_selected(self, value):
        factor = value / 100.0
        for it in self.inserts:
            if it.isSelected():
                it.setScale(factor)
                for box in self.bounding_boxes:
                    if box.parentItem() == it:
                        box.setRect(it.boundingRect())



    def opacity_changed(self, value):
        """Set opacity of selected inserts from 0% (transparent) to 100% (opaque)."""
        opacity = value / 100.0
        for it in self.inserts:
            if it.isSelected():
                it.setOpacity(opacity)

    def toggle_bounding_boxes(self, state):
        self.bounding_boxes_enabled = bool(state)
        for box in self.bounding_boxes:
            box.setVisible(self.bounding_boxes_enabled)

    def pick_box_color(self):
        color = QColorDialog.getColor()
        if color.isValid():
            self.bounding_box_pen.setColor(color)
            self.update_all_bounding_boxes()

    def update_box_pen(self):
        style_map = {
            "Solid": Qt.PenStyle.SolidLine,
            "Dash": Qt.PenStyle.DashLine,
            "Dot": Qt.PenStyle.DotLine,
            "DashDot": Qt.PenStyle.DashDotLine,
            "DashDotDot": Qt.PenStyle.DashDotDotLine
        }
        self.bounding_box_pen.setWidth(self.box_thickness_slider.value())
        self.bounding_box_pen.setStyle(style_map[self.box_style_combo.currentText()])
        self.update_all_bounding_boxes()

    def update_all_bounding_boxes(self):
        for box in self.bounding_boxes:
            box.setPen(self.bounding_box_pen)


    def affix_inserts(self):
        """Bake inserts into the main image and clear overlays."""
        if not self.inserts:
            QMessageBox.information(self, "No Inserts", "There are no inserts to affix.")
            return

        # ✅ Deselect all inserts to avoid selection outlines (but DO NOT hide bounding boxes unless user wants them hidden)
        for it in self.inserts:
            it.setSelected(False)

        # Only hide bounding boxes if checkbox is off
        boxes_to_hide = []
        if not self.bounding_boxes_enabled:
            for box in self.bounding_boxes:
                box.setVisible(False)
                boxes_to_hide.append(box)  # Remember which were hidden

        # 1. Filter items: background + inserts and bounding boxes
        relevant_items = []
        for item in self.scene.items():
            if isinstance(item, QGraphicsPixmapItem) and (item in self.inserts or item.zValue() == 0):
                relevant_items.append(item)
            elif self.bounding_boxes_enabled and isinstance(item, QGraphicsRectItem):
                relevant_items.append(item)


        # 2. Compute bounding rect of relevant items
        bounding_rect = QRectF()
        for item in relevant_items:
            bounding_rect = bounding_rect.united(item.sceneBoundingRect())

        bounding_rect = bounding_rect.normalized()
        x = int(bounding_rect.left())
        y = int(bounding_rect.top())
        width = int(bounding_rect.right()) - x
        height = int(bounding_rect.bottom()) - y

        # 3. Temporarily hide non-relevant items
        hidden_items = []
        for item in self.scene.items():
            if item not in relevant_items:
                item.setVisible(False)
                hidden_items.append(item)

        # 4. Create target QImage and QPainter
        img = QImage(width, height, QImage.Format.Format_ARGB32)
        img.fill(Qt.GlobalColor.transparent)
        painter = QPainter(img)

        # 5. Render scene contents to QImage
        self.scene.render(painter,
                        target=QRectF(0, 0, width, height),
                        source=QRectF(x, y, width, height))
        painter.end()

        # 6. Restore hidden items
        for item in hidden_items:
            item.setVisible(True)

        # Restore any bounding boxes that were temporarily hidden
        for box in boxes_to_hide:
            box.setVisible(True)

        # 7. Convert to NumPy and push to ImageManager (trim alpha)
        arr = self.qimage_to_numpy(img)
        if arr.shape[2] == 4:
            arr = arr[:, :, :3]

        slot = self.image_manager.current_slot
        metadata = self.image_manager._metadata.get(slot, {})
        self.image_manager.set_image(arr, metadata, step_name="Signature Adder")

        # 8. Cleanup overlays
        self.clear_inserts()
        self.update_main_image()


    def clear_inserts(self):
        for it in self.inserts:
            self.scene.removeItem(it)
        self.inserts.clear()
        for box in self.bounding_boxes:
            self.scene.removeItem(box)
        self.bounding_boxes.clear()

    def numpy_to_qimage(self, arr):
        # 1) Normalize & convert to uint8 0–255
        arr = np.clip(arr, 0.0, 1.0)
        arr_uint8 = (arr * 255).astype(np.uint8)

        # 2) Force a contiguous buffer
        arr_c = np.ascontiguousarray(arr_uint8)
        h, w = arr_c.shape[:2]

        # 3) Pick the right QImage format & compute bytesPerLine
        if arr_c.ndim == 2:
            fmt = QImage.Format.Format_Grayscale8
            channels = 1
        elif arr_c.shape[2] == 3:
            fmt = QImage.Format.Format_RGB888
            channels = 3
        elif arr_c.shape[2] == 4:
            fmt = QImage.Format.Format_RGBA8888
            channels = 4
        else:
            raise ValueError(f"Unsupported array shape: {arr_c.shape}")

        bytes_per_line = w * channels

        # 4) Grab a real bytes buffer
        buf = arr_c.tobytes()

        # 5) Build and return the QImage
        return QImage(buf, w, h, bytes_per_line, fmt).copy()

    def qimage_to_numpy(self, img):
        img = img.convertToFormat(QImage.Format.Format_RGBA8888)
        w, h = img.width(), img.height()
        ptr = img.bits()
        ptr.setsize(h * img.bytesPerLine())
        arr = np.frombuffer(ptr, np.uint8).reshape((h, img.bytesPerLine()))
        arr = arr[:, :w * 4].reshape((h, w, 4))
        return arr.astype(np.float32) / 255.0

class XISFViewer(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.image_data = None
        self.file_meta = None
        self.image_meta = None
        self.is_mono = False
        self.bit_depth = None
        self.scale_factor = 1.0
        self.dragging = False
        self.drag_start_pos = QPoint()
        self.autostretch_enabled = False
        self.current_pixmap = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
    
    def initUI(self):
        main_layout = QHBoxLayout()
        splitter = QSplitter(Qt.Orientation.Horizontal)
        splitter.setHandleWidth(5)



        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Left side layout for image display and save button
        left_widget = QWidget()        
        left_layout = QVBoxLayout(left_widget)
        left_widget.setMinimumSize(600, 600)
        
        self.load_button = QPushButton("Load Image File")
        self.load_button.clicked.connect(self.load_xisf)
        #left_layout.addWidget(self.load_button)

        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        # Add a scroll area to allow panning
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setWidgetResizable(False)  # Keep it resizable
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        left_layout.addWidget(self.scroll_area)

        self.toggle_button = QPushButton("Toggle Autostretch", self)
        self.toggle_button.setCheckable(True)
        self.toggle_button.clicked.connect(self.toggle_autostretch)
        left_layout.addWidget(self.toggle_button)        

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.zoom_out_button)
        # Add the "Fit to Window" button
        self.fit_to_window_button = QPushButton("Fit to Window")
        self.fit_to_window_button.clicked.connect(self.fit_to_window)
        zoom_layout.addWidget(self.fit_to_window_button)       
        left_layout.addLayout(zoom_layout)

        # Inside the initUI method, where the Save button is added
        self.save_button = QPushButton("Save As")
        self.save_button.clicked.connect(self.save_as)
        #self.save_button.setEnabled(False)



        # Add the Save button and checkbox to a horizontal layout
        #save_layout = QHBoxLayout()
        #save_layout.addWidget(self.save_button)

        #left_layout.addLayout(save_layout)

        # Add a Batch Process button
        self.batch_process_button = QPushButton("XISF Converter Batch Process")
        self.batch_process_button.clicked.connect(self.open_batch_process_window)
        left_layout.addWidget(self.batch_process_button)


        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        self.load_logo()

        # Right side layout for metadata display
        right_widget = QWidget()
        right_widget.setMinimumWidth(300)
        right_layout = QVBoxLayout()
        self.metadata_tree = QTreeWidget()
        self.metadata_tree.setHeaderLabels(["Property", "Value"])
        self.metadata_tree.setColumnWidth(0, 150)
        right_layout.addWidget(self.metadata_tree)
        
        # Save Metadata button below metadata tree
        self.save_metadata_button = QPushButton("Save Metadata")
        self.save_metadata_button.clicked.connect(self.save_metadata)
        right_layout.addWidget(self.save_metadata_button)
        
        right_widget.setLayout(right_layout)

        # Add left widget and metadata tree to the splitter
        splitter.addWidget(left_widget)
        splitter.addWidget(right_widget)
        splitter.setSizes([800, 200])  # Initial sizes for the left (preview) and right (metadata) sections
        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 0)

        main_layout.addWidget(splitter)
        self.setLayout(main_layout)
        self.setWindowTitle("XISF Liberator V1.2")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        if not self.isVisible():
            return

        # Clear previous content
        self.image_label.clear()
        self.metadata_tree.clear()

        if image is None:
            print(f"XISFViewer: Cleared image display for slot {slot}.")
            return

        # Get image and metadata from the current slot
        if slot == self.image_manager.current_slot:
            if not isinstance(image, np.ndarray):
                image = np.array(image)
            self.image = image
            self.preview_image = None
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', "Unknown File")

        # --- If the file is a FITS file with a Bayer pattern, debayer before converting to 3-channel ---
        if self.filename.lower().endswith(('.fits', '.fit', '.fits.fz', '.fit.fz')):
            if self.original_header and self.original_header.get('BAYERPAT'):
                print(f"Running debayer_image on {self.filename}")
                # Expecting the raw image to be 2D (mono)
                if self.image.ndim == 2:
                    debayered_image, debayered_mono = self.debayer_image(self.image, self.filename, self.original_header, True)
                    self.image_data = debayered_image
                    self.is_mono = debayered_mono
                else:
                    # If it's already 3D, skip debayering.
                    print("Image already has multiple channels; skipping debayering.")
                    self.image_data = self.image
            else:
                self.image_data = self.image
        else:
            self.image_data = self.image

        # --- If the image is still mono (and not debayered), convert 2D to 3-channel RGB for display ---
        if self.is_mono and self.image_data.ndim == 2:
            self.image_data = np.stack([self.image_data] * 3, axis=-1)

        # --- Autostretch if enabled ---
        if self.autostretch_enabled:
            self.apply_autostretch()

        # Display the image
        self.display_image()

        # Update metadata display (if applicable)
        if self.filename.lower().endswith(('.fits', '.fit', '.fits.fz', '.fit.fz', '.xisf',
                                            '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            self.display_metadata(self.filename)

        print(f"XISFViewer: Image updated from ImageManager slot {slot}.")







    def load_logo(self):
        """
        Load and display the XISF Liberator logo before any image is loaded.
        """
        logo_path = resource_path("astrosuite.png")
        if not os.path.exists(logo_path):
            print(f"Logo image not found at path: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        # Load the logo image
        logo_pixmap = QPixmap(logo_path)
        if logo_pixmap.isNull():
            print(f"Failed to load logo image from: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        self.current_pixmap = logo_pixmap  # Store the logo pixmap
        scaled_pixmap = logo_pixmap.scaled(
            logo_pixmap.size() * self.scale_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.resize(scaled_pixmap.size())

    def toggle_autostretch(self):
        if self.image_data is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply autostretch.")
            return        
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.image_data  # Reset to original image if stretch is disabled

        self.display_image()

    def apply_autostretch(self):
        # Determine if the image is mono or color
        if len(self.image_data.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=False, normalize=False)

    def open_batch_process_window(self):
        self.batch_dialog = BatchProcessDialog(self)
        self.batch_dialog.show()


    def load_xisf(self):
        file_name, _ = QFileDialog.getOpenFileName(
            self, 
            "Open Image File", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.fz *.fz *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )

        if file_name:
            try:
                # Use the global load_image function to load the image and its metadata
                image, header, bit_depth, is_mono = load_image(file_name)
                
                # Apply debayering if needed (for non-mono images)
                if is_mono:  # Only debayer if the image is not mono
                    image, is_mono = self.debayer_image(image, file_name, header, is_mono)

                # Check if the image is mono or RGB
                self.is_mono = is_mono
                self.bit_depth = bit_depth
                self.image_data = image

                # Reset scale factor when a new image is loaded
                self.scale_factor = 0.25

                # If autostretch is enabled, apply stretch immediately after loading
                if self.autostretch_enabled:
                    self.apply_autostretch()

                # Display the image with scaling and normalization
                
                self.display_image()

                # Set image metadata (using header from load_image)
                self.file_meta = header  # Use the loaded header for metadata
                self.image_meta = None  # No separate image metadata for XISF in this example
                
                # Display metadata (using the global display_metadata method for appropriate file types)
                self.display_metadata(file_name)

                # Push the loaded image to ImageManager (only if image_manager exists)
                if hasattr(self, 'image_manager'):
                    metadata = {
                        'file_path': file_name,
                        'is_mono': self.is_mono,
                        'bit_depth': self.bit_depth,
                        'source': 'XISF'  # Or specify 'FITS' if applicable
                    }
                    # Push the numpy array to ImageManager (not memoryview)
                    self.image_manager.update_image(np.array(self.image_data), metadata, slot=0)  # Add image to slot 0 in ImageManager

                # Enable save button if the image is loaded successfully
                self.save_button.setEnabled(True)

            except Exception as e:
                self.image_label.setText(f"Failed to load XISF file: {e}")


    def debayer_image(self, image, file_path, header, is_mono):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        # For FITS files, check for BAYERPAT in the header.
        if file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
            print(f"running debayer_image on {file_path}")
            bayer_pattern = header.get('BAYERPAT', None)
            # If BAYERPAT not found, try iterating through HDUs.
            if bayer_pattern is None:
                bayer_header = get_bayer_header(file_path)
                if bayer_header:
                    bayer_pattern = bayer_header.get('BAYERPAT', None)
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                is_mono = False
                image = self.debayer_fits(image, bayer_pattern)
            else:
                print(f"No Bayer pattern found in FITS header: {file_path}")
        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            # For RAW files, apply debayering (assuming debayer_raw exists)
            print(f"Debayering RAW image: {file_path}")
            is_mono = False
            image = self.debayer_raw(image)
        
        return image, is_mono


    def debayer_fits(self, image_data, bayer_pattern):
        """Debayer a FITS image using a basic Bayer pattern (2x2)."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern
            r = image_data[::2, ::2]  # Red
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            b = image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = image_data[::2, ::2]  # Blue
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            r = image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            r = image_data[::2, 1::2]  # Red
            b = image_data[1::2, ::2]  # Blue
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            b = image_data[::2, 1::2]  # Blue
            r = image_data[1::2, ::2]  # Red
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")




    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Debayer a RAW image based on the Bayer pattern."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern (Debayering logic example)
            r = raw_image_data[::2, ::2]  # Red
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            b = raw_image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        
        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = raw_image_data[::2, ::2]  # Blue
            g1 = raw_image_data[::2, 1::2]  # Green 1
            g2 = raw_image_data[1::2, ::2]  # Green 2
            r = raw_image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            r = raw_image_data[::2, 1::2]  # Red
            b = raw_image_data[1::2, ::2]  # Blue
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = raw_image_data[::2, ::2]  # Green 1
            b = raw_image_data[::2, 1::2]  # Blue
            r = raw_image_data[1::2, ::2]  # Red
            g2 = raw_image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")


    def display_image(self):
        if self.image_data is None:
            return

        # pick the right source
        im_data = self.stretched_image if self.autostretch_enabled else self.image_data

        # mono → RGB
        if im_data.ndim == 2:
            im_data = np.stack([im_data] * 3, axis=-1)
        elif im_data.ndim == 3 and im_data.shape[2] == 1:
            im_data = np.repeat(im_data, 3, axis=-1)

        # now we expect a H×W×3 array
        if im_data.ndim != 3 or im_data.shape[2] != 3:
            print(f"Unexpected image shape: {im_data.shape}")
            return

        h, w, c = im_data.shape
        bytes_per_line = c * w

        # prepare an 8-bit buffer
        if im_data.dtype == np.uint8:
            buf8 = im_data

        elif im_data.dtype == np.uint16:
            # linear map 0…65535 → 0…255
            buf8 = (im_data.astype(np.float32) / 65535.0 * 255.0) \
                    .clip(0, 255).astype(np.uint8)

        elif im_data.dtype in (np.float32, np.float64):
            # assume values already in [0…1]
            buf8 = (im_data * 255.0).clip(0, 255).astype(np.uint8)

        else:
            print(f"Unsupported dtype for display: {im_data.dtype}")
            return

        # build a QImage from the 8-bit data
        qimg = QImage(buf8.tobytes(), w, h, bytes_per_line,
                      QImage.Format.Format_RGB888)

        # apply current zoom/scale
        sw = int(qimg.width() * self.scale_factor)
        sh = int(qimg.height() * self.scale_factor)
        scaled = qimg.scaled(sw, sh,
                             Qt.AspectRatioMode.KeepAspectRatio,
                             Qt.TransformationMode.SmoothTransformation)

        pix = QPixmap.fromImage(scaled)
        self.current_pixmap = pix
        self.image_label.setPixmap(pix)
        self.image_label.resize(scaled.size())


    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        self.center_image_on_zoom(1.25)

    @announce_zoom
    def zoom_out(self):
        self.center_image_on_zoom(1 / 1.25)

    def fit_to_window(self):
        if self.image_data is None:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        viewport_width = viewport_size.width()
        viewport_height = viewport_size.height()

        # Get the image dimensions
        if self.autostretch_enabled and hasattr(self, 'stretched_image') and self.stretched_image is not None:
            img_height, img_width = self.stretched_image.shape[:2]
        else:
            img_height, img_width = self.image_data.shape[:2]

        # Calculate scale factors for width and height
        scale_factor_width = viewport_width / img_width
        scale_factor_height = viewport_height / img_height

        # Choose the smaller scale factor to ensure the image fits within the viewport
        self.scale_factor = min(scale_factor_width, scale_factor_height)

        # Update the display
        self.display_image()

    def center_image_on_zoom(self, zoom_factor):
        # Get the current center point of the visible area
        current_center_x = self.scroll_area.horizontalScrollBar().value() + (self.scroll_area.viewport().width() / 2)
        current_center_y = self.scroll_area.verticalScrollBar().value() + (self.scroll_area.viewport().height() / 2)
        
        # Adjust the scale factor
        self.scale_factor *= zoom_factor
        
        # Display the image with the new scale factor
        self.display_image()
        
        # Calculate the new center point after zooming
        new_center_x = current_center_x * zoom_factor
        new_center_y = current_center_y * zoom_factor
        
        # Adjust scrollbars to keep the image centered
        self.scroll_area.horizontalScrollBar().setValue(int(new_center_x - self.scroll_area.viewport().width() / 2))
        self.scroll_area.verticalScrollBar().setValue(int(new_center_y - self.scroll_area.viewport().height() / 2))

        # 4) announce
        pct = int(self.scale_factor * 100)
        print(f"Zoom now {pct}%")
        vp = self.scroll_area.viewport()
        center_local = vp.rect().center()                    # QPoint in viewport coords
        center_global = vp.mapToGlobal(center_local)         # map to screen coords

        QToolTip.showText(center_global, f"{pct}%")

    def wheelEvent(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def display_metadata(self, file_path):
        print("starting display_metadata")
        """
        Load and display metadata from the given file if the file is an XISF or FITS file.
        For other file types, simply skip without failing.
        """
        if not file_path:
            print("No file path provided. Skipping metadata display.")
            return

        if not isinstance(file_path, str):
            print(f"Invalid file path type: {type(file_path)}. Expected a string.")
            return

        try:
            if file_path.lower().endswith('.xisf'):
                print("Loading metadata from XISF file.")
                # XISF handling
                try:
                    # Load XISF file for metadata
                    xisf = XISF(file_path)
                    file_meta = xisf.get_file_metadata()
                    image_meta = xisf.get_images_metadata()[0]

                    # Assign metadata to instance variables
                    self.file_meta = file_meta
                    self.image_meta = image_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add File Metadata
                    file_meta_item = QTreeWidgetItem(["File Metadata"])
                    self.metadata_tree.addTopLevelItem(file_meta_item)
                    for key, value in file_meta.items():
                        item = QTreeWidgetItem([key, str(value.get('value', ''))])  # Ensure 'value' exists
                        file_meta_item.addChild(item)

                    # Add Image Metadata
                    image_meta_item = QTreeWidgetItem(["Image Metadata"])
                    self.metadata_tree.addTopLevelItem(image_meta_item)
                    for key, value in image_meta.items():
                        if key == 'FITSKeywords':
                            fits_item = QTreeWidgetItem(["FITS Keywords"])
                            image_meta_item.addChild(fits_item)
                            for kw, kw_values in value.items():
                                for kw_value in kw_values:
                                    item = QTreeWidgetItem([kw, str(kw_value.get("value", ''))])
                                    fits_item.addChild(item)
                        elif key == 'XISFProperties':
                            props_item = QTreeWidgetItem(["XISF Properties"])
                            image_meta_item.addChild(props_item)
                            for prop_name, prop in value.items():
                                item = QTreeWidgetItem([prop_name, str(prop.get("value", ''))])
                                props_item.addChild(item)
                        else:
                            item = QTreeWidgetItem([key, str(value)])
                            image_meta_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load XISF metadata: {e}")

            elif file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
                print("Loading metadata from FITS file.")
                # FITS handling using get_valid_header
                try:
                    # Unpack the header and ignore the extension index for metadata display.
                    header, _ = get_valid_header(file_path)

                    # Assign metadata to instance variables
                    self.file_meta = header
                    self.image_meta = {}  # FITS files typically don't have separate image-level metadata

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add FITS Header Metadata
                    fits_header_item = QTreeWidgetItem(["FITS Header"])
                    self.metadata_tree.addTopLevelItem(fits_header_item)

                    # Loop through the header and add each keyword
                    for keyword, value in header.items():
                        item = QTreeWidgetItem([keyword, str(value)])
                        fits_header_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load FITS metadata: {e}")

            # Handle Camera Raw files (e.g., .cr2, .nef, .arw, .dng)
            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print("Loading metadata from Camera RAW file.")
                try:
                    # Use rawpy to read RAW file metadata
                    raw_meta = {}
                    with rawpy.imread(file_path) as raw:
                        # Example: Extract some basic metadata
                        raw_meta['camera_whitebalance'] = raw.camera_whitebalance
                        raw_meta['camera_white_level_per_channel'] = raw.camera_white_level_per_channel
                        raw_meta['tone_curve_length'] = len(raw.tone_curve) if raw.tone_curve is not None else 0

                    # Assign metadata to instance variables
                    self.file_meta = {}  # RAW files typically don't have file-level metadata in this context
                    self.image_meta = raw_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add Camera RAW Metadata
                    raw_meta_item = QTreeWidgetItem(["Camera RAW Metadata"])
                    self.metadata_tree.addTopLevelItem(raw_meta_item)

                    for key, value in raw_meta.items():
                        if isinstance(value, (list, tuple, np.ndarray)):
                            for i, item in enumerate(value):
                                raw_meta_item.addChild(QTreeWidgetItem([f"{key}_{i+1}", str(item)]))
                        else:
                            raw_meta_item.addChild(QTreeWidgetItem([key, str(value)]))

                    self.metadata_tree.expandAll()
                except Exception as e:
                    print(f"Failed to load Camera RAW metadata: {e}")

            else:
                # If the file is not a FITS or XISF file, simply return without displaying metadata
                print(f"Skipping metadata for unsupported file type: {file_path}")

        except AttributeError as ae:
            print(f"AttributeError in display_metadata: {ae}")
        except Exception as e:
            print(f"Unexpected error in display_metadata: {e}")


    def save_as(self):
        output_path, _ = QFileDialog.getSaveFileName(self, "Save Image As", "", "XISF (*.xisf);;FITS (*.fits);;TIFF (*.tif);;PNG (*.png)")
        
        if output_path:
            # Determine if we should save the stretched image or the original
            image_to_save = self.stretched_image if self.save_stretched_checkbox.isChecked() and self.stretched_image is not None else self.image_data
            _, ext = os.path.splitext(output_path)
            
            # Determine bit depth and color mode
            is_32bit_float = image_to_save.dtype == np.float32
            is_16bit = image_to_save.dtype == np.uint16
            is_8bit = image_to_save.dtype == np.uint8

            try:
                # Save as FITS file with FITS header only (no XISF properties)
                if ext.lower() in ['.fits', '.fit']:
                    header = fits.Header()
                    crval1, crval2 = None, None
                    
                    # Populate FITS header with FITS keywords and essential WCS keywords only
                    wcs_keywords = ["CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
                    
                    if 'FITSKeywords' in self.image_meta:
                        for keyword, values in self.image_meta['FITSKeywords'].items():
                            for entry in values:
                                if 'value' in entry:
                                    value = entry['value']
                                    if keyword in wcs_keywords:
                                        try:
                                            value = int(value)
                                        except ValueError:
                                            value = float(value)
                                    header[keyword] = value

                    # Manually add WCS information if missing
                    if 'CTYPE1' not in header:
                        header['CTYPE1'] = 'RA---TAN'
                    if 'CTYPE2' not in header:
                        header['CTYPE2'] = 'DEC--TAN'
                    
                    # Add the -SIP suffix if SIP coefficients are present
                    if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                        header['CTYPE1'] = 'RA---TAN-SIP'
                        header['CTYPE2'] = 'DEC--TAN-SIP'

                    # Set default reference pixel (center of the image)
                    if 'CRPIX1' not in header:
                        header['CRPIX1'] = image_to_save.shape[1] / 2  # X center
                    if 'CRPIX2' not in header:
                        header['CRPIX2'] = image_to_save.shape[0] / 2  # Y center

                    # Retrieve RA and DEC values if available
                    if 'FITSKeywords' in self.image_meta:
                        if 'RA' in self.image_meta['FITSKeywords']:
                            crval1 = float(self.image_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
                        if 'DEC' in self.image_meta['FITSKeywords']:
                            crval2 = float(self.image_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

                    # Add CRVAL1 and CRVAL2 to the header if found
                    if crval1 is not None and crval2 is not None:
                        header['CRVAL1'] = crval1
                        header['CRVAL2'] = crval2
                    else:
                        print("RA and DEC values not found in FITS Keywords")

                    # Calculate pixel scale if focal length and pixel size are available
                    if 'FOCALLEN' in self.image_meta['FITSKeywords'] and 'XPIXSZ' in self.image_meta['FITSKeywords']:
                        focal_length = float(self.image_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
                        pixel_size = float(self.image_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
                        pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
                        header['CDELT1'] = -pixel_scale / 3600.0
                        header['CDELT2'] = pixel_scale / 3600.0
                    else:
                        header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
                        header['CDELT2'] = 2.77778e-4

                    # Populate CD matrix using the XISF LinearTransformationMatrix if available
                    if 'XISFProperties' in self.image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in self.image_meta['XISFProperties']:
                        linear_transform = self.image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        header['CD1_1'] = linear_transform[0][0]
                        header['CD1_2'] = linear_transform[0][1]
                        header['CD2_1'] = linear_transform[1][0]
                        header['CD2_2'] = linear_transform[1][1]
                    else:
                        header['CD1_1'] = header['CDELT1']
                        header['CD1_2'] = 0.0
                        header['CD2_1'] = 0.0
                        header['CD2_2'] = header['CDELT2']

                    # Duplicate the mono image to create a 3-channel image if it’s mono
                    if self.is_mono:
                        image_data_fits = np.stack([image_to_save[:, :, 0]] * 3, axis=-1)  # Create 3-channel from mono
                        image_data_fits = np.transpose(image_data_fits, (2, 0, 1))  # Reorder to (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)
                    else:
                        image_data_fits = np.transpose(image_to_save, (2, 0, 1))  # RGB images in (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)

                    hdu = fits.PrimaryHDU(image_data_fits, header=header)
                    hdu.writeto(output_path, overwrite=True)
                    print(f"Saved FITS image with metadata to: {output_path}")

                # Save as TIFF based on bit depth
                elif ext.lower() in ['.tif', '.tiff']:
                    if is_16bit:
                        self.save_tiff(output_path, bit_depth=16)
                    elif is_32bit_float:
                        self.save_tiff(output_path, bit_depth=32)
                    else:
                        self.save_tiff(output_path, bit_depth=8)
                    print(f"Saved TIFF image with {self.bit_depth} bit depth to: {output_path}")

                # Save as PNG
                elif ext.lower() == '.png':
                    # Convert mono images to RGB for PNG format
                    if self.is_mono:
                        image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                        image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)  # Duplicate channel to create RGB
                    else:
                        image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                    Image.fromarray(image_8bit_rgb).save(output_path)
                    print(f"Saved 8-bit PNG image to: {output_path}")

                # Save as XISF with metadata
                elif ext.lower() == '.xisf':
                    XISF.write(output_path, image_to_save, xisf_metadata=self.file_meta)
                    print(f"Saved XISF image with metadata to: {output_path}")

            except Exception as e:
                print(f"Error saving file: {e}")


    def process_batch(self, input_dir, output_dir, file_format, update_status_callback):
        import glob
        from pathlib import Path

        xisf_files = glob.glob(f"{input_dir}/*.xisf")
        if not xisf_files:
            QMessageBox.warning(self, "Error", "No XISF files found in the input directory.")
            update_status_callback("")
            return

        for i, xisf_file in enumerate(xisf_files, start=1):
            try:
                # Update progress
                update_status_callback(f"Processing file {i}/{len(xisf_files)}: {Path(xisf_file).name}")

                # Load the XISF file
                xisf = XISF(xisf_file)
                im_data = xisf.read_image(0)

                # Set metadata
                file_meta = xisf.get_file_metadata()
                image_meta = xisf.get_images_metadata()[0]
                is_mono = im_data.shape[2] == 1 if len(im_data.shape) == 3 else True

                # Determine output file path
                base_name = Path(xisf_file).stem
                output_file = Path(output_dir) / f"{base_name}{file_format}"

                # Save the file using save_direct
                self.save_direct(output_file, im_data, file_meta, image_meta, is_mono)

            except Exception as e:
                update_status_callback(f"Error processing file {Path(xisf_file).name}: {e}")
                continue  # Skip to the next file

        update_status_callback("Batch Processing Complete!")

    def save_direct(self, output_path, image_to_save, file_meta, image_meta, is_mono):
        """
        Save an image directly to the specified path with the given metadata.
        This function does not prompt the user and is suitable for batch processing.
        """
        _, ext = os.path.splitext(output_path)

        # Determine bit depth and color mode
        is_32bit_float = image_to_save.dtype == np.float32
        is_16bit = image_to_save.dtype == np.uint16
        is_8bit = image_to_save.dtype == np.uint8

        try:
            # Save as FITS file with metadata
            if ext.lower() in ['.fits', '.fit']:
                header = fits.Header()
                crval1, crval2 = None, None

                # Populate FITS header with FITS keywords and WCS keywords
                wcs_keywords = [
                    "CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", 
                    "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"
                ]

                if 'FITSKeywords' in image_meta:
                    for keyword, values in image_meta['FITSKeywords'].items():
                        for entry in values:
                            if 'value' in entry:
                                value = entry['value']
                                # Convert only numerical values to float
                                if keyword in wcs_keywords and isinstance(value, (int, float)):
                                    value = float(value)
                                header[keyword] = value

                # Add default WCS information if missing
                if 'CTYPE1' not in header:
                    header['CTYPE1'] = 'RA---TAN'
                if 'CTYPE2' not in header:
                    header['CTYPE2'] = 'DEC--TAN'

                # Add the -SIP suffix for SIP coefficients
                if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                    header['CTYPE1'] = 'RA---TAN-SIP'
                    header['CTYPE2'] = 'DEC--TAN-SIP'

                # Set default reference pixel if missing
                if 'CRPIX1' not in header:
                    header['CRPIX1'] = image_to_save.shape[1] / 2
                if 'CRPIX2' not in header:
                    header['CRPIX2'] = image_to_save.shape[0] / 2

                # Add CRVAL1 and CRVAL2 if available
                if 'RA' in image_meta.get('FITSKeywords', {}):
                    crval1 = float(image_meta['FITSKeywords']['RA'][0]['value'])
                if 'DEC' in image_meta.get('FITSKeywords', {}):
                    crval2 = float(image_meta['FITSKeywords']['DEC'][0]['value'])

                if crval1 is not None and crval2 is not None:
                    header['CRVAL1'] = crval1
                    header['CRVAL2'] = crval2

                # Add CD matrix if available
                if 'XISFProperties' in image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in image_meta['XISFProperties']:
                    linear_transform = image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                    header['CD1_1'] = linear_transform[0][0]
                    header['CD1_2'] = linear_transform[0][1]
                    header['CD2_1'] = linear_transform[1][0]
                    header['CD2_2'] = linear_transform[1][1]
                else:
                    header['CD1_1'] = header['CDELT1'] if 'CDELT1' in header else 0.0
                    header['CD1_2'] = 0.0
                    header['CD2_1'] = 0.0
                    header['CD2_2'] = header['CDELT2'] if 'CDELT2' in header else 0.0

                # Duplicate mono image to create 3-channel if necessary
                if is_mono:
                    image_data_fits = image_to_save[:, :, 0] if len(image_to_save.shape) == 3 else image_to_save
                    header['NAXIS'] = 2  # Mono images are 2-dimensional
                else:
                    image_data_fits = np.transpose(image_to_save, (2, 0, 1))
                    header['NAXIS'] = 3
                    header['NAXIS3'] = 3

                hdu = fits.PrimaryHDU(image_data_fits, header=header)
                hdu.writeto(output_path, overwrite=True)
                print(f"Saved FITS image to: {output_path}")


            # Save as TIFF
            elif ext.lower() in ['.tif', '.tiff']:
                if is_16bit:
                    tiff.imwrite(output_path, (image_to_save * 65535).astype(np.uint16))
                elif is_32bit_float:
                    tiff.imwrite(output_path, image_to_save.astype(np.float32))
                else:
                    tiff.imwrite(output_path, (image_to_save * 255).astype(np.uint8))
                print(f"Saved TIFF image to: {output_path}")

            # Save as PNG
            elif ext.lower() == '.png':
                if is_mono:
                    image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                    image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)
                else:
                    image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                Image.fromarray(image_8bit_rgb).save(output_path)
                print(f"Saved PNG image to: {output_path}")

            # Save as XISF
            elif ext.lower() == '.xisf':
                XISF.write(output_path, image_to_save, xisf_metadata=file_meta)
                print(f"Saved XISF image to: {output_path}")

            else:
                print(f"Unsupported file format: {ext}")

        except Exception as e:
            print(f"Error saving file {output_path}: {e}")


    def save_tiff(self, output_path, bit_depth):
        if bit_depth == 16:
            if self.is_mono:
                tiff.imwrite(output_path, (self.image_data[:, :, 0] * 65535).astype(np.uint16))
            else:
                tiff.imwrite(output_path, (self.image_data * 65535).astype(np.uint16))
        elif bit_depth == 32:
            if self.is_mono:
                tiff.imwrite(output_path, self.image_data[:, :, 0].astype(np.float32))
            else:
                tiff.imwrite(output_path, self.image_data.astype(np.float32))
        else:  # 8-bit
            image_8bit = (self.image_data * 255).astype(np.uint8)
            if self.is_mono:
                tiff.imwrite(output_path, image_8bit[:, :, 0])
            else:
                tiff.imwrite(output_path, image_8bit)

    def save_metadata(self):
        if not self.file_meta and not self.image_meta:
            QMessageBox.warning(self, "Warning", "No metadata to save.")
            return
        file_path, _ = QFileDialog.getSaveFileName(self, "Save Metadata", "", "CSV Files (*.csv);;All Files (*)")
        if file_path:
            try:
                # Flatten metadata function
                def flatten_metadata(data, parent_key=''):
                    items = []
                    for key, value in data.items():
                        new_key = f"{parent_key}.{key}" if parent_key else key
                        if isinstance(value, dict):
                            items.extend(flatten_metadata(value, new_key).items())
                        elif isinstance(value, list):
                            for i, list_item in enumerate(value):
                                list_key = f"{new_key}_{i}"
                                items.extend(flatten_metadata({list_key: list_item}).items())
                        else:
                            items.append((new_key, value if value is not None else ''))  # Replace None with an empty string
                    return dict(items)

                # Flatten both file_meta and image_meta
                flattened_file_meta = flatten_metadata(self.file_meta) if self.file_meta else {}
                flattened_image_meta = flatten_metadata(self.image_meta) if self.image_meta else {}

                # Combine both metadata into one dictionary for CSV
                combined_meta = {**flattened_file_meta, **flattened_image_meta}

                # Write to CSV
                with open(file_path, mode='w', newline='', encoding='utf-8') as file:
                    writer = csv.writer(file)
                    writer.writerow(["Key", "Value"])  # Header row
                    for key, value in combined_meta.items():
                        writer.writerow([key, value])

                QMessageBox.information(self, "Success", f"Metadata saved to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to save metadata: {e}")       

class BatchProcessDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Batch Process")
        self.setMinimumWidth(400)

        layout = QVBoxLayout()

        # Input directory
        self.input_dir_label = QLabel("Input Directory:")
        self.input_dir_button = QPushButton("Select Input Directory")
        self.input_dir_button.clicked.connect(self.select_input_directory)
        self.input_dir = QLineEdit()
        self.input_dir.setReadOnly(True)

        layout.addWidget(self.input_dir_label)
        layout.addWidget(self.input_dir)
        layout.addWidget(self.input_dir_button)

        # Output directory
        self.output_dir_label = QLabel("Output Directory:")
        self.output_dir_button = QPushButton("Select Output Directory")
        self.output_dir_button.clicked.connect(self.select_output_directory)
        self.output_dir = QLineEdit()
        self.output_dir.setReadOnly(True)

        layout.addWidget(self.output_dir_label)
        layout.addWidget(self.output_dir)
        layout.addWidget(self.output_dir_button)

        # File format
        self.format_label = QLabel("Select Output Format:")
        self.format_combo = QComboBox()
        self.format_combo.addItems([".png", ".fit", ".fits", ".tif", ".tiff"])

        layout.addWidget(self.format_label)
        layout.addWidget(self.format_combo)

        # Start Batch Processing button
        self.start_button = QPushButton("Start Batch Processing")
        self.start_button.clicked.connect(self.start_batch_processing)
        layout.addWidget(self.start_button)

        # Status label
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)

        self.setLayout(layout)

    def select_input_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.input_dir.setText(directory)

    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.output_dir.setText(directory)

    def start_batch_processing(self):
        input_dir = self.input_dir.text()
        output_dir = self.output_dir.text()
        file_format = self.format_combo.currentText()

        if not input_dir or not output_dir:
            QMessageBox.warning(self, "Error", "Please select both input and output directories.")
            return

        self.status_label.setText("Initializing batch processing...")
        QApplication.processEvents()  # Ensures UI updates immediately

        # Call the parent function to process files with progress updates
        self.parent().process_batch(input_dir, output_dir, file_format, self.update_status)

        self.status_label.setText("Batch Processing Complete!")

    def update_status(self, message):
        self.status_label.setText(message)
        QApplication.processEvents()  # Ensures UI updates immediately

class MetricsPanel(QWidget):
    """2×2 grid with clickable dots and draggable thresholds."""
    pointClicked = pyqtSignal(int, int)
    thresholdChanged = pyqtSignal(int, float)

    def __init__(self, parent=None):
        super().__init__(parent)
        layout = QVBoxLayout(self)
        grid = QGridLayout()
        layout.addLayout(grid)

        # caching slots
        self._orig_images = None       # last list passed
        self.metrics_data = None       # list of 4 numpy arrays
        self.flags = None              # list of bools
        self._threshold_initialized = [False]*4
        self._open_previews = []

        self.plots, self.scats, self.lines = [], [], []
        titles = ["FWHM (px)", "Eccentricity", "Background", "Star Count"]
        for idx, title in enumerate(titles):
            pw = pg.PlotWidget()
            pw.setTitle(title)
            pw.showGrid(x=True, y=True, alpha=0.3)
            pw.getPlotItem().getViewBox().setBackgroundColor(
                self.palette().color(self.backgroundRole())
            )

            scat = pg.ScatterPlotItem(pen=pg.mkPen(None),
                                      brush=pg.mkBrush(100,100,255,200),
                                      size=8)
            scat.sigClicked.connect(lambda plot, pts, m=idx: self._on_point_click(m, pts))
            pw.addItem(scat)

            line = pg.InfiniteLine(pos=0, angle=0, movable=True,
                                   pen=pg.mkPen('r', width=2))
            line.sigPositionChangeFinished.connect(
                lambda ln, m=idx: self._on_line_move(m, ln))
            pw.addItem(line)

            grid.addWidget(pw, idx//2, idx%2)
            self.plots.append(pw)
            self.scats.append(scat)
            self.lines.append(line)

    @staticmethod
    def _compute_one(i_entry):
        """
        Worker: run SEP on one image entry.
        Returns (idx, fwhm, ecc, orig_back, star_count).
        If SEP overflows its internal pixel buffer, we catch it and
        return sentinel “bad” values so the frame will be flagged.
        """
        idx, entry = i_entry
        import numpy as np, sep

        # rebuild normalized mono data
        img = entry['image_data']
        if img.dtype == np.uint8:
            data = img.astype(np.float32) / 255.0
        elif img.dtype == np.uint16:
            data = img.astype(np.float32) / 65535.0
        else:
            data = np.asarray(img, dtype=np.float32)
        if data.ndim == 3:
            data = data.mean(axis=2)

        # detection parameters
        thresh   = 7.0    # σ threshold
        min_area = 16     # at least a 4×4 blob

        try:
            bkg = sep.Background(data)
            back, gb, gr = bkg.back(), bkg.globalback, bkg.globalrms

            cat = sep.extract(
                data - back,
                thresh,
                err=gr,
                minarea=min_area,
                clean=True,
                deblend_nthresh=32
            )

            if len(cat) > 0:
                sig      = np.sqrt(cat['a'] * cat['b'])
                fwhm     = np.nanmedian(2.3548 * sig)
                ecc      = np.nanmedian(1 - (cat['b'] / cat['a']))
                star_cnt = len(cat)
            else:
                fwhm, ecc, star_cnt = np.nan, np.nan, 0

        except Exception as e:
            # catch SEP overflow (or any other) and mark as “bad” frame
            # you can even check `if "internal pixel buffer full" in str(e):`
            fwhm, ecc, star_cnt = 10.0, 0.5, 0

        orig_back = entry.get('orig_background', np.nan)
        return idx, fwhm, ecc, orig_back, star_cnt


    def compute_all_metrics(self, loaded_images):
        # ─── HEADS-UP DIALOG ───────────────────────────────────────────
        settings = QSettings()
        # default to True (i.e. show warning) if the key isn't there yet
        show = settings.value("metrics/showWarning", True, type=bool)
        if show:
            msg = QMessageBox(self)
            msg.setWindowTitle("Heads-up")
            msg.setText(
                "This is going to use ALL your CPU cores and the UI may lock up until it finishes.\n\n"
                "Continue?"
            )
            msg.setStandardButtons(QMessageBox.StandardButton.Yes |
                                QMessageBox.StandardButton.No)
            cb = QCheckBox("Don't show again", msg)
            msg.setCheckBox(cb)
            answer = msg.exec()
            if answer != QMessageBox.StandardButton.Yes:
                return
            if cb.isChecked():
                settings.setValue("metrics/showWarning", False)  
        """Run SEP over the full list in parallel using threads and cache results."""
        n = len(loaded_images)
        # pre-allocate result arrays
        m0 = np.full(n, np.nan)
        m1 = np.full(n, np.nan)
        m2 = np.full(n, np.nan)
        m3 = np.full(n, np.nan)
        flags = [e.get('flagged', False) for e in loaded_images]

        # set up a cancelable progress dialog
        prog = QProgressDialog("Computing frame metrics…", "Cancel", 0, n, self)
        prog.setWindowModality(Qt.WindowModality.WindowModal)
        prog.setMinimumDuration(0)
        prog.show()
        QApplication.processEvents()

        workers = min((os.cpu_count() or 1), 60)
        tasks   = [(i, loaded_images[i]) for i in range(n)]
        with ProcessPoolExecutor(max_workers=workers) as exe:
            futures = {exe.submit(self._compute_one, t): t[0] for t in tasks}
            done = 0
            for fut in as_completed(futures):
                if prog.wasCanceled():
                    break
                idx, fwhm, ecc, orig_back, star_cnt = fut.result()
                m0[idx], m1[idx], m2[idx], m3[idx] = fwhm, ecc, orig_back, star_cnt
                done += 1
                prog.setValue(done)
                QApplication.processEvents()

        prog.close()

        # stash results
        self._orig_images = loaded_images
        self.metrics_data  = [m0, m1, m2, m3]
        self.flags         = flags
        self._threshold_initialized = [False]*4

    def plot(self, loaded_images, indices=None):
        """
        Plot metrics for loaded_images.
        If indices is given (list/array of ints), only those frames are shown.
        """
        # empty clear
        if not loaded_images:
            self.metrics_data = None
            for pw, scat, line in zip(self.plots, self.scats, self.lines):
                scat.setData(x=[], y=[])
                line.setPos(0)
                pw.getPlotItem().getViewBox().update()
                pw.repaint()
            return

        # compute & cache on first call or new image list
        if self._orig_images is not loaded_images or self.metrics_data is None:
            self.compute_all_metrics(loaded_images)

        # default to all indices
        if indices is None:
            indices = np.arange(len(loaded_images), dtype=int)

        # store for later recoloring
        self._cur_indices = np.array(indices, dtype=int)

        x = np.arange(len(indices))

        for m, (pw, scat, line) in enumerate(zip(self.plots, self.scats, self.lines)):
            arr = self.metrics_data[m]
            y   = arr[indices]

            brushes = [
                pg.mkBrush(255,0,0,200) if self.flags[idx] else pg.mkBrush(100,100,255,200)
                for idx in indices
            ]
            scat.setData(x=x, y=y, brush=brushes, pen=pg.mkPen(None), size=8)

            # initialize threshold line once
            if not self._threshold_initialized[m]:
                mx, mn = np.nanmax(y), np.nanmin(y)
                span   = mx-mn if mx!=mn else 1.0
                line.setPos((mx+0.05*span) if m<3 else 0)
                self._threshold_initialized[m] = True

    def _refresh_scatter_colors(self):
        """Re-color your dots without re-computing SEP, even in subset mode."""
        # For each scatter, its x‐values are local positions into self._cur_indices,
        # so we must map them back to the original-frame index before pulling flags.
        for scat in self.scats:
            x, y = scat.getData()[:2]
            brushes = []
            for xi in x:
                li = int(xi)                    # local index in this subset
                gi = self._cur_indices[li]     # global frame index
                if self.flags[gi]:
                    brushes.append(pg.mkBrush(255,0,0,200))
                else:
                    brushes.append(pg.mkBrush(100,100,255,200))
            scat.setData(x=x, y=y, brush=brushes)

    def _on_point_click(self, metric_idx, points):
        for pt in points:
            frame_idx = int(round(pt.pos().x()))
            mods = QApplication.keyboardModifiers()
            if mods & Qt.KeyboardModifier.ShiftModifier:
                entry  = self._orig_images[frame_idx]
                img    = entry['image_data']
                is_mono= entry.get('is_mono', False)
                dlg = ImagePreviewDialog(img, is_mono)
                dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  
                dlg.show()
                self._open_previews.append(dlg)  # <-- hold a reference

                # optionally prune closed ones:
                dlg.destroyed.connect(lambda _=None, d=dlg: 
                      self._open_previews.remove(d)
                      if d in self._open_previews else None)
            else:
                self.pointClicked.emit(metric_idx, frame_idx)

    def _on_line_move(self, metric_idx, line):
        self.thresholdChanged.emit(metric_idx, line.value())

class MetricsWindow(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        self._thresholds_per_group: dict[str, list[float|None]] = {}
        self.setWindowTitle("Frame Metrics")
        self.resize(800, 600)

        vbox = QVBoxLayout(self)

        # ← **new** instructions label
        instr = QLabel(
            "Instructions:\n"
            " • Use the filter dropdown to restrict by FILTER.\n"
            " • Click a dot to flag/unflag a frame.\n"
            " • Shift-click a dot to preview the image.\n"
            " • Drag the red lines to set thresholds.",
            self
        )
        instr.setWordWrap(True)
        instr.setStyleSheet("color: #ccc; font-size: 12px;")
        vbox.addWidget(instr)

        # → filter selector
        self.group_combo = QComboBox(self)
        self.group_combo.addItem("All")
        self.group_combo.currentTextChanged.connect(self._on_group_change)
        vbox.addWidget(self.group_combo)

        # → the 2×2 metrics panel
        self.metrics_panel = MetricsPanel(self)
        vbox.addWidget(self.metrics_panel)

        # keep status up‐to‐date when things happen
        self.metrics_panel.thresholdChanged.connect(self._update_status)
        self.metrics_panel.pointClicked   .connect(self._update_status)

        # ← status label
        self.status_label = QLabel("", self)
        vbox.addWidget(self.status_label)

        # internal storage
        self._all_images: list[dict] = []
        self._current_indices: list[int] | None = None

    def _update_status(self, *args):
        """Recompute and show: Flagged Items X / Y (Z%)."""
        flags = getattr(self.metrics_panel, 'flags', []) or []
        # which subset are we in?
        idxs = self._current_indices if self._current_indices is not None else range(len(flags))
        total = len(idxs)
        flagged = sum(flags[i] for i in idxs)
        pct = (flagged/total*100) if total else 0.0
        self.status_label.setText(f"Flagged Items {flagged}/{total}  ({pct:.1f}%)")

    def set_images(self, loaded_images: list[dict]):
        """Initialize with a brand-new set of images."""
        self._all_images = loaded_images

        # ─── rebuild the combo-list of FILTER groups ─────────────
        self.group_combo.blockSignals(True)
        self.group_combo.clear()
        self.group_combo.addItem("All")
        seen = set()
        for entry in loaded_images:
            filt = entry.get('header', {}).get('FILTER', 'Unknown')
            if filt not in seen:
                seen.add(filt)
                self.group_combo.addItem(filt)
        self.group_combo.blockSignals(False)

        # ─── reset & seed per-group thresholds ────────────────────
        self._thresholds_per_group.clear()
        self._thresholds_per_group["All"] = [None]*4
        for entry in loaded_images:
            filt = entry.get('header', {}).get('FILTER', 'Unknown')
            if filt not in self._thresholds_per_group:
                self._thresholds_per_group[filt] = [None]*4

        # ─── compute & cache all metrics once ────────────────────
        self.metrics_panel.compute_all_metrics(self._all_images)

        # ─── show “All” by default and plot ───────────────────────
        self._current_indices = None
        self._apply_thresholds("All")
        self.metrics_panel.plot(self._all_images, indices=None)

        # ─── update the flagged-items status label ───────────────
        self._update_status()


    def _on_group_change(self, name: str):
        """Re-plot for the selected FILTER group."""
        if name == "All":
            self._current_indices = None
        else:
            # collect indices matching this filter
            self._current_indices = [
                i for i, e in enumerate(self._all_images)
                if e.get('header', {}).get('FILTER', 'Unknown') == name
            ]

        # apply saved thresholds for this group
        self._apply_thresholds(name)
        # re-draw
        self.metrics_panel.plot(self._all_images, indices=self._current_indices)

    def _on_panel_threshold_change(self, metric_idx: int, new_val: float):
        """User just dragged a threshold line."""
        grp = self.group_combo.currentText()
        # save it for this group
        self._thresholds_per_group[grp][metric_idx] = new_val

        # (if you also want immediate re-flagging in the tree, keep your BlinkTab logic hooked here)

    def _apply_thresholds(self, group_name: str):
        """Restore the four InfiniteLine positions for a given group."""
        saved = self._thresholds_per_group.get(group_name, [None]*4)
        for idx, line in enumerate(self.metrics_panel.lines):
            if saved[idx] is not None:
                line.setPos(saved[idx])
            # if saved[idx] is None, we leave it so that
            # the panel’s own auto-init can run on next plot()

    def update_metrics(self, loaded_images: list[dict]):
        """
        Called whenever BlinkTab.loadImages or clearImages fires.
        If it's a new list, re-init; otherwise just re-plot current group.
        """
        if loaded_images is not self._all_images:
            self.set_images(loaded_images)
        else:
            # same list, just redraw current selection
            self._on_group_change(self.group_combo.currentText())

class BlinkTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()

        self.image_paths = []  # Store the file paths of loaded images
        self.loaded_images = []  # Store the image objects (as numpy arrays)
        self.image_labels = []  # Store corresponding file names for the TreeWidget
        self.image_manager = image_manager  # Reference to ImageManager
        self.metrics_window: MetricsWindow | None = None
        self.zoom_level = 0.5  # Default zoom level
        self.dragging = False  # Track whether the mouse is dragging
        self.last_mouse_pos = None  # Store the last mouse position
        self.thresholds_by_group: dict[str, list[float|None]] = {}
        self.aggressive_stretch_enabled = False
        self.current_sigma = 3.7

        self.initUI()
        self.init_shortcuts()

    def initUI(self):
        main_layout = QHBoxLayout(self)


        # Create a QSplitter to allow resizing between left and right panels
        splitter = QSplitter(Qt.Orientation.Horizontal, self)

        # Left Column for the file loading and TreeView
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)

        # --------------------
        # Instruction Label
        # --------------------
        instruction_text = "Press 'F' to flag/unflag an image.\nRight-click on an image for more options."
        self.instruction_label = QLabel(instruction_text, self)
        self.instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.instruction_label.setWordWrap(True)
        self.instruction_label.setStyleSheet("font-weight: bold;")  # Optional: Make the text bold for emphasis

        self.instruction_label.setStyleSheet(f"""
            QLabel {{
                font-weight: bold;
            }}
        """)

        # Add the instruction label to the left layout at the top
        left_layout.addWidget(self.instruction_label)

        # Horizontal layout for "Select Images" and "Select Directory" buttons
        button_layout = QHBoxLayout()

        # "Select Images" Button
        self.fileButton = QPushButton('Select Images', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        button_layout.addWidget(self.fileButton)

        # "Select Directory" Button
        self.dirButton = QPushButton('Select Directory', self)
        self.dirButton.clicked.connect(self.openDirectoryDialog)
        button_layout.addWidget(self.dirButton)

        left_layout.addLayout(button_layout)

        self.metrics_button = QPushButton("Show Metrics", self)
        self.metrics_button.clicked.connect(self.show_metrics)
        left_layout.addWidget(self.metrics_button)



        # Playback controls (left arrow, play, pause, right arrow)
        playback_controls_layout = QHBoxLayout()

        # Left Arrow Button
        self.left_arrow_button = QPushButton(self)
        self.left_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        self.left_arrow_button.clicked.connect(self.previous_item)
        playback_controls_layout.addWidget(self.left_arrow_button)

        # Play Button
        self.play_button = QPushButton(self)
        self.play_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPlay))
        self.play_button.clicked.connect(self.start_playback)
        playback_controls_layout.addWidget(self.play_button)

        # Pause Button
        self.pause_button = QPushButton(self)
        self.pause_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPause))
        self.pause_button.clicked.connect(self.stop_playback)
        playback_controls_layout.addWidget(self.pause_button)

        # Right Arrow Button
        self.right_arrow_button = QPushButton(self)
        self.right_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowRight))
        self.right_arrow_button.clicked.connect(self.next_item)
        playback_controls_layout.addWidget(self.right_arrow_button)

        left_layout.addLayout(playback_controls_layout)

        # Tree view for file names
        self.fileTree = QTreeWidget(self)
        self.fileTree.setColumnCount(1)
        self.fileTree.setHeaderLabels(["Image Files"])
        self.fileTree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)  # Allow multiple selections
        self.fileTree.itemClicked.connect(self.on_item_clicked)
        self.fileTree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.fileTree.customContextMenuRequested.connect(self.on_right_click)
        self.fileTree.currentItemChanged.connect(self.on_current_item_changed) 
        self.fileTree.setStyleSheet("""
                QTreeWidget::item:selected {
                    background-color: #3a75c4;  /* Blue background for selected items */
                    color: #ffffff;  /* White text color */
                }
            """)
        left_layout.addWidget(self.fileTree)

        # "Clear Flags" Button
        self.clearFlagsButton = QPushButton('Clear Flags', self)
        self.clearFlagsButton.clicked.connect(self.clearFlags)
        left_layout.addWidget(self.clearFlagsButton)

        # "Clear Images" Button
        self.clearButton = QPushButton('Clear Images', self)
        self.clearButton.clicked.connect(self.clearImages)
        left_layout.addWidget(self.clearButton)

        # Add progress bar
        self.progress_bar = QProgressBar(self)
        self.progress_bar.setRange(0, 100)
        left_layout.addWidget(self.progress_bar)

        # Add loading message label
        self.loading_label = QLabel("Loading images...", self)
        left_layout.addWidget(self.loading_label)

        # Set the layout for the left widget
        left_widget.setLayout(left_layout)

        # Add the left widget to the splitter
        splitter.addWidget(left_widget)

        # Right Column for Image Preview
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls: Add Zoom In and Zoom Out buttons
        zoom_controls_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_controls_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_controls_layout.addWidget(self.fit_to_preview_button)

        self.aggressive_button = QPushButton("Aggressive Stretch", self)
        self.aggressive_button.setCheckable(True)
        self.aggressive_button.clicked.connect(self.toggle_aggressive)
        zoom_controls_layout.addWidget(self.aggressive_button)

        right_layout.addLayout(zoom_controls_layout)

        # Scroll area for the preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.preview_label = QLabel(self)
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        right_layout.addWidget(self.scroll_area)

        # Set the layout for the right widget
        right_widget.setLayout(right_layout)

        # Add the right widget to the splitter
        splitter.addWidget(right_widget)

        # Set initial splitter sizes
        splitter.setSizes([300, 700])  # Adjust proportions as needed

        # Add the splitter to the main layout
        main_layout.addWidget(splitter)

        # Set the main layout for the widget
        self.setLayout(main_layout)

        # Initialize playback timer
        self.playback_timer = QTimer(self)
        self.playback_timer.setInterval(200)  # Set the playback interval to 500ms
        self.playback_timer.timeout.connect(self.next_item)

        # Connect the selection change signal to update the preview when arrow keys are used
        self.fileTree.selectionModel().selectionChanged.connect(self.on_selection_changed)
        self.setFocusPolicy(Qt.FocusPolicy.StrongFocus)

    def toggle_aggressive(self):
        self.aggressive_stretch_enabled = self.aggressive_button.isChecked()
        # force a redisplay of the current image
        cur = self.fileTree.currentItem()
        if cur:
            self.on_item_clicked(cur, 0)

    def clearFlags(self):
        """Clear all flagged states, update tree icons & metrics."""
        # 1) Reset internal flag state
        for entry in self.loaded_images:
            entry['flagged'] = False

        # 2) Update tree widget: strip any "⚠️ " prefix and reset color
        normal = self.fileTree.palette().color(QPalette.ColorRole.WindowText)
        for item in self.get_all_leaf_items():
            name = item.text(0).lstrip("⚠️ ")
            item.setText(0, name)
            item.setForeground(0, QBrush(normal))

        # 3) If metrics window is open, refresh its dots & status
        if self.metrics_window:
            panel = self.metrics_window.metrics_panel
            panel.flags = [False] * len(self.loaded_images)
            panel._refresh_scatter_colors()
            # update the "Flagged Items X/Y" label
            self.metrics_window._update_status()

    def show_metrics(self):
        if self.metrics_window is None:
            self.metrics_window = MetricsWindow()
            mp = self.metrics_window.metrics_panel
            mp.pointClicked.connect(self.on_metrics_point)
            mp.thresholdChanged.connect(self.on_threshold_change)

        # ← here ←
        self.metrics_window.set_images(self.loaded_images)
        panel = self.metrics_window.metrics_panel
        self.thresholds_by_group["All"] = [ line.value() for line in panel.lines ]
        self.metrics_window.show()
        self.metrics_window.raise_()

    def on_metrics_point(self, metric_idx, frame_idx):
        # Toggle the flagged state on the image…
        item = self.get_tree_item_for_index(frame_idx)
        if not item:
            return
        self._toggle_flag_on_item(item)

        # Now update the panel’s flags and refresh
        panel = self.metrics_window.metrics_panel
        panel.flags = [entry['flagged'] for entry in self.loaded_images]
        panel._refresh_scatter_colors()
        self.metrics_window._update_status()


    def on_threshold_change(self, metric_idx, threshold):
        panel = self.metrics_window.metrics_panel
        if panel.metrics_data is None:
            return

        # figure out which FILTER group we're in
        group = self.metrics_window.group_combo.currentText()
        # ensure we have a 4-slot list for this group
        thr_list = self.thresholds_by_group.setdefault(group, [None]*4)
        # store the new threshold for this metric
        thr_list[metric_idx] = threshold

        # build the list of indices to re-evaluate
        if group == "All":
            indices = range(len(self.loaded_images))
        else:
            indices = [
                i for i, e in enumerate(self.loaded_images)
                if e.get('header', {}).get('FILTER','Unknown') == group
            ]

        # re‐flag only those frames in this group, OR across all 4 metrics
        for i in indices:
            entry = self.loaded_images[i]
            flagged = False
            for m, thr in enumerate(thr_list):
                if thr is None:
                    continue
                val = panel.metrics_data[m][i]
                if np.isnan(val):
                    continue
                if (m < 3 and val > thr) or (m == 3 and val < thr):
                    flagged = True
                    break
            entry['flagged'] = flagged

            # update the tree icon
            item = self.get_tree_item_for_index(i)
            if item:
                RED = Qt.GlobalColor.red
                normal = self.fileTree.palette().color(QPalette.ColorRole.WindowText)
                name = item.text(0).lstrip("⚠️ ")
                if flagged:
                    item.setText(0, f"⚠️ {name}")
                    item.setForeground(0, QBrush(RED))
                else:
                    item.setText(0, name)
                    item.setForeground(0, QBrush(normal))

        # now push the *entire* up-to-date flagged list into the panel
        panel.flags = [e['flagged'] for e in self.loaded_images]
        panel._refresh_scatter_colors()
        self.metrics_window._update_status()



    def get_tree_item_for_index(self, idx):
        target = os.path.basename(self.image_paths[idx])
        for item in self.get_all_leaf_items():
            if item.text(0).lstrip("⚠️ ") == target:
                return item
        return None

    def compute_metric(self, metric_idx, entry):
        """Recompute a single metric for one image.  Use cached orig_background for metric 2."""
        # metric 2 is the pre-stretch background we already computed
        if metric_idx == 2:
            return entry.get('orig_background', np.nan)

        # otherwise rebuild a float32 [0..1] array from whatever dtype we stored
        img = entry['image_data']
        if img.dtype == np.uint8:
            data = img.astype(np.float32)/255.0
        elif img.dtype == np.uint16:
            data = img.astype(np.float32)/65535.0
        else:
            data = np.asarray(img, dtype=np.float32)
        if data.ndim == 3:
            data = data.mean(axis=2)

        # run SEP for the other metrics
        bkg = sep.Background(data)
        back, gr, rr = bkg.back(), bkg.globalback, bkg.globalrms
        cat = sep.extract(data - back, 5.0, err=gr, minarea=9)
        if len(cat)==0:
            return np.nan

        sig = np.sqrt(cat['a']*cat['b'])
        if metric_idx == 0:
            return np.nanmedian(2.3548*sig)
        elif metric_idx == 1:
            return np.nanmedian(1 - (cat['b']/cat['a']))
        else:  # metric_idx == 3 (star count)
            return len(cat)


    def init_shortcuts(self):
        """Initialize keyboard shortcuts."""
        # Create a shortcut for the "F" key to flag images
        flag_shortcut = QShortcut(QKeySequence("F"), self.fileTree)
        flag_shortcut.activated.connect(self.flag_current_image)

    def openDirectoryDialog(self):
        """Allow users to select a directory and load all images within it recursively."""
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            # Supported image extensions
            supported_extensions = (
                '.png', '.tif', '.tiff', '.fits', '.fit',
                '.xisf', '.cr2', '.nef', '.arw', '.dng',
                '.orf', '.rw2', '.pef'
            )

            # Collect all image file paths recursively
            new_file_paths = []
            for root, _, files in os.walk(directory):
                for file in sorted(files, key=str.lower):  # 🔹 Sort alphabetically (case-insensitive)
                    if file.lower().endswith(supported_extensions):
                        full_path = os.path.join(root, file)
                        if full_path not in self.image_paths:  # Avoid duplicates
                            new_file_paths.append(full_path)

            if new_file_paths:
                self.loadImages(new_file_paths)
            else:
                QMessageBox.information(self, "No Images Found", "No supported image files were found in the selected directory.")


    def clearImages(self):
        """Clear all loaded images and reset the tree view."""
        confirmation = QMessageBox.question(
            self,
            "Clear All Images",
            "Are you sure you want to clear all loaded images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            self.stop_playback()
            self.image_paths.clear()
            self.loaded_images.clear()
            self.image_labels.clear()
            self.fileTree.clear()
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')
            self.current_pixmap = None
            self.progress_bar.setValue(0)
            self.loading_label.setText("Loading images...")

            # (legacy) if you still have this, you can delete it:
            # self.thresholds = [None, None, None, None]

            # also reset the metrics panel (if it’s open)
            if self.metrics_window is not None:
                mp = self.metrics_window.metrics_panel
                # clear out old data & reset flags / thresholds
                mp.metrics_data = None
                mp._threshold_initialized = [False]*4
                for scat in mp.scats:
                    scat.clear()
                for line in mp.lines:
                    line.setPos(0)

                # clear per‐group threshold storage
                self.metrics_window._thresholds_per_group.clear()

        # finally, tell the MetricsWindow to fully re‐init with no images
        if self.metrics_window is not None:
            self.metrics_window.update_metrics([])


    @staticmethod
    def _load_one_image(file_path: str, target_dtype):
        """Load + pre-process one image & return all metadata."""

        # 1) load
        image, header, bit_depth, is_mono = load_image(file_path)
        if image is None or image.size == 0:
            raise ValueError("Empty image")

        # 2) optional debayer
        if is_mono:
            # adjust this call to match your debayer signature
            image = BlinkTab.debayer_image(image, file_path, header)

        # 3) SEP background on mono float32
        data = np.asarray(image, dtype=np.float32, order='C')
        if data.ndim == 3:
            data = data.mean(axis=2)
        bkg = sep.Background(data)
        global_back = bkg.globalback

        # 4) stretch
        target_med = 0.25
        if image.ndim == 2:
            stretched = stretch_mono_image(image, target_med)
        else:
            stretched = stretch_color_image(image, target_med, linked=False)

        # 5) cast to target_dtype
        clipped = np.clip(stretched, 0.0, 1.0)
        if target_dtype is np.uint8:
            stored = (clipped * 255).astype(np.uint8)
        elif target_dtype is np.uint16:
            stored = (clipped * 65535).astype(np.uint16)
        else:
            stored = clipped.astype(np.float32)

        return file_path, header, bit_depth, is_mono, stored, global_back

    @staticmethod
    def debayer_image(image, file_path, header):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        if file_path.lower().endswith(('.fits', '.fit')):
            bayer_pattern = header.get('BAYERPAT', None)
            if bayer_pattern:
                image = debayer_fits_fast(image, bayer_pattern)
        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            image = debayer_raw_fast(image, bayer_pattern="RGGB")
        return image

    @staticmethod
    def _natural_key(path: str):
        """
        Split a filename into text and integer chunks so that 
        “…_2.fit” sorts before “…_10.fit”.
        """
        import re
        name = os.path.basename(path)
        return [int(tok) if tok.isdigit() else tok.lower()
                for tok in re.split(r'(\d+)', name)]

    def loadImages(self, file_paths):
        # 0) early out
        if not file_paths:
            return

        # ---------- NEW: natural sort the list of filenames ----------
        file_paths = sorted(file_paths, key=lambda p: self._natural_key(os.path.basename(p)))

        # 1) pick dtype based on RAM
        mem   = psutil.virtual_memory()
        avail = mem.available / (1024**3)
        if avail <= 16:
            target_dtype = np.uint8
        elif avail <= 32:
            target_dtype = np.uint16
        else:
            target_dtype = np.float32

        total = len(file_paths)
        self.progress_bar.setRange(0,100)
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        # clear old data & tree
        self.image_paths.clear()
        self.loaded_images.clear()
        self.fileTree.clear()

        # 2) fire off all loads in parallel
        futures    = {}
        max_workers = min((os.cpu_count() or 1), 60)
        with ProcessPoolExecutor(max_workers=max_workers) as exe:
            for p in file_paths:
                futures[exe.submit(self._load_one_image, p, target_dtype)] = p

            done = 0
            for fut in as_completed(futures):
                try:
                    path, header, bit_depth, is_mono, stored, back = fut.result()
                except Exception as e:
                    print(f"[WARN] {futures[fut]} load failed: {e}")
                    continue

                header = header or {}

                self.image_paths.append(path)
                self.loaded_images.append({
                    'file_path':      path,
                    'image_data':     stored,
                    'header':         header,
                    'bit_depth':      bit_depth,
                    'is_mono':        is_mono,
                    'flagged':        False,
                    'orig_background': back
                })

                done += 1
                self.progress_bar.setValue(int(100 * done / total))
                QApplication.processEvents()

        # 3) (optional) reorder to input order — in this case file_paths is already sorted
        #    so image_paths/loaded_images follow that same sorted order

        # 4) build a nested grouping: Object -> Filter -> Exposure -> [paths]
        grouped = defaultdict(list)
        for entry in self.loaded_images:
            hdr  = entry['header']
            obj  = hdr.get('OBJECT',   'Unknown')
            filt = hdr.get('FILTER',   'Unknown')
            exp  = hdr.get('EXPOSURE', 'Unknown')
            grouped[(obj, filt, exp)].append(entry['file_path'])
        # ——— NEW: for each group, sort the file list by natural filename order ———
        for key, paths in grouped.items():
            paths.sort(key=lambda p: self._natural_key(os.path.basename(p)))
        # 5) rebuild the tree in sorted key order:
        by_object = defaultdict(lambda: defaultdict(dict))
        for (obj, filt, exp), paths in grouped.items():
            by_object[obj][filt][exp] = paths

        for obj in sorted(by_object, key=lambda o: o.lower()):
            obj_item = QTreeWidgetItem([f"Object: {obj}"])
            self.fileTree.addTopLevelItem(obj_item)
            obj_item.setExpanded(True)

            for filt in sorted(by_object[obj], key=lambda f: f.lower()):
                filt_item = QTreeWidgetItem([f"Filter: {filt}"])
                obj_item.addChild(filt_item)
                filt_item.setExpanded(True)

                for exp in sorted(by_object[obj][filt], key=lambda e: str(e).lower()):
                    exp_item = QTreeWidgetItem([f"Exposure: {exp}"])
                    filt_item.addChild(exp_item)
                    exp_item.setExpanded(True)

                    # leaves: these were already sorted via file_paths/natural sort
                    for p in by_object[obj][filt][exp]:
                        leaf = QTreeWidgetItem([os.path.basename(p)])
                        exp_item.addChild(leaf)

        # 6) final UI touch-ups
        self.loading_label.setText(f"Loaded {len(self.loaded_images)} images.")
        self.progress_bar.setValue(100)
        if self.metrics_window and self.metrics_window.isVisible():
            self.metrics_window.update_metrics(self.loaded_images)

    def findTopLevelItemByName(self, name):
        """Find a top-level item in the tree by its name."""
        for index in range(self.fileTree.topLevelItemCount()):
            item = self.fileTree.topLevelItem(index)
            if item.text(0) == name:
                return item
        return None

    def findChildItemByName(self, parent, name):
        """Find a child item under a given parent by its name."""
        for index in range(parent.childCount()):
            child = parent.child(index)
            if child.text(0) == name:
                return child
        return None


    def _toggle_flag_on_item(self, item: QTreeWidgetItem):
        """Toggle the flagged state on this tree item and its loaded_images entry."""
        file_name = item.text(0).lstrip("⚠️ ")
        # find the matching image entry
        file_path = next((p for p in self.image_paths if os.path.basename(p) == file_name), None)
        if file_path is None:
            return

        idx = self.image_paths.index(file_path)
        entry = self.loaded_images[idx]
        entry['flagged'] = not entry['flagged']

        # update the tree view
        RED = Qt.GlobalColor.red
        palette = self.fileTree.palette()
        normal_color = palette.color(QPalette.ColorRole.WindowText)

        if entry['flagged']:
            item.setText(0, f"⚠️ {file_name}")
            item.setForeground(0, QBrush(RED))
        else:
            item.setText(0, file_name)
            item.setForeground(0, QBrush(normal_color))

    def flag_current_image(self):
        """Called by the F-key: toggle flag on the currently selected item."""
        item = self.fileTree.currentItem()
        if not item:
            QMessageBox.warning(self, "No Selection", "No image is currently selected to flag.")
            return
        self._toggle_flag_on_item(item)
        self.next_item()  # Move to the next item after flagging


    def on_current_item_changed(self, current, previous):
        """Ensure the selected item is visible by scrolling to it."""
        if current:
            self.fileTree.scrollToItem(current, QAbstractItemView.ScrollHint.PositionAtCenter)

    def previous_item(self):
        """Select the previous item in the TreeWidget."""
        current_item = self.fileTree.currentItem()
        if current_item:
            all_items = self.get_all_leaf_items()
            current_index = all_items.index(current_item)
            if current_index > 0:
                previous_item = all_items[current_index - 1]
            else:
                previous_item = all_items[-1]  # Loop back to the last item
            self.fileTree.setCurrentItem(previous_item)
            self.on_item_clicked(previous_item, 0)  # Update the preview

    def next_item(self):
        """Select the next item in the TreeWidget, looping back to the first item if at the end."""
        current_item = self.fileTree.currentItem()
        if current_item:
            # Get all leaf items
            all_items = self.get_all_leaf_items()

            # Check if the current item is in the leaf items
            try:
                current_index = all_items.index(current_item)
            except ValueError:
                # If the current item is not a leaf, move to the first leaf item
                print("Current item is not a leaf. Selecting the first leaf item.")
                if all_items:
                    next_item = all_items[0]
                    self.fileTree.setCurrentItem(next_item)
                    self.on_item_clicked(next_item, 0)
                return

            # Select the next leaf item or loop back to the first
            if current_index < len(all_items) - 1:
                next_item = all_items[current_index + 1]
            else:
                next_item = all_items[0]  # Loop back to the first item

            self.fileTree.setCurrentItem(next_item)
            self.on_item_clicked(next_item, 0)  # Update the preview
        else:
            print("No current item selected.")

    def get_all_leaf_items(self):
        """Get a flat list of all leaf items (actual files) in the TreeWidget."""
        def recurse(parent):
            items = []
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.childCount() == 0:  # It's a leaf item
                    items.append(child)
                else:
                    items.extend(recurse(child))
            return items

        root = self.fileTree.invisibleRootItem()
        return recurse(root)

    def start_playback(self):
        """Start playing through the items in the TreeWidget."""
        if not self.playback_timer.isActive():
            self.playback_timer.start()

    def stop_playback(self):
        """Stop playing through the items."""
        if self.playback_timer.isActive():
            self.playback_timer.stop()


    def openFileDialog(self):
        """Allow users to select multiple images and add them to the existing list."""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Open Images",
            "",
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )
        
        # Filter out already loaded images to prevent duplicates
        new_file_paths = [path for path in file_paths if path not in self.image_paths]

        if new_file_paths:
            self.loadImages(new_file_paths)
        else:
            QMessageBox.information(self, "No New Images", "No new images were selected or all selected images are already loaded.")


    def debayer_fits(self, image_data, bayer_pattern):
        """Debayer a FITS image using a basic Bayer pattern (2x2)."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern
            r = image_data[::2, ::2]  # Red
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            b = image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = image_data[::2, ::2]  # Blue
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            r = image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            r = image_data[::2, 1::2]  # Red
            b = image_data[1::2, ::2]  # Blue
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            b = image_data[::2, 1::2]  # Blue
            r = image_data[1::2, ::2]  # Red
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")

    def remove_item_from_tree(self, file_path):
        """Remove a specific item from the tree view based on file path."""
        file_name = os.path.basename(file_path)
        root = self.fileTree.invisibleRootItem()

        def recurse(parent):
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.text(0).endswith(file_name):
                    parent.removeChild(child)
                    return True
                if recurse(child):
                    return True
            return False

        recurse(root)

    def add_item_to_tree(self, file_path):
        """Add a specific item to the tree view based on file path."""
        # Extract metadata for grouping
        image_entry = next((img for img in self.loaded_images if img['file_path'] == file_path), None)
        if not image_entry:
            return

        header = image_entry['header']
        object_name = header.get('OBJECT', 'Unknown') if header else 'Unknown'
        filter_name = header.get('FILTER', 'Unknown') if header else 'Unknown'
        exposure_time = header.get('EXPOSURE', 'Unknown') if header else 'Unknown'

        # Group images by filter and exposure time
        group_key = (object_name, filter_name, exposure_time)

        # Find or create the object item
        object_item = self.findTopLevelItemByName(f"Object: {object_name}")
        if not object_item:
            object_item = QTreeWidgetItem([f"Object: {object_name}"])
            self.fileTree.addTopLevelItem(object_item)
            object_item.setExpanded(True)

        # Find or create the filter item
        filter_item = self.findChildItemByName(object_item, f"Filter: {filter_name}")
        if not filter_item:
            filter_item = QTreeWidgetItem([f"Filter: {filter_name}"])
            object_item.addChild(filter_item)
            filter_item.setExpanded(True)

        # Find or create the exposure item
        exposure_item = self.findChildItemByName(filter_item, f"Exposure: {exposure_time}")
        if not exposure_item:
            exposure_item = QTreeWidgetItem([f"Exposure: {exposure_time}"])
            filter_item.addChild(exposure_item)
            exposure_item.setExpanded(True)

        # Add the file item
        file_name = os.path.basename(file_path)
        item = QTreeWidgetItem([file_name])
        exposure_item.addChild(item)



    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Debayer a RAW image based on the Bayer pattern, ensuring even dimensions."""
        H, W = raw_image_data.shape
        # Crop to even dimensions if necessary
        if H % 2 != 0:
            raw_image_data = raw_image_data[:H-1, :]
        if W % 2 != 0:
            raw_image_data = raw_image_data[:, :W-1]
        
        if bayer_pattern == 'RGGB':
            r = raw_image_data[::2, ::2]      # Red
            g1 = raw_image_data[::2, 1::2]     # Green 1
            g2 = raw_image_data[1::2, ::2]     # Green 2
            b = raw_image_data[1::2, 1::2]     # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'BGGR':
            b = raw_image_data[::2, ::2]      # Blue
            g1 = raw_image_data[::2, 1::2]     # Green 1
            g2 = raw_image_data[1::2, ::2]     # Green 2
            r = raw_image_data[1::2, 1::2]     # Red

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'GRBG':
            g1 = raw_image_data[::2, ::2]     # Green 1
            r = raw_image_data[::2, 1::2]      # Red
            b = raw_image_data[1::2, ::2]      # Blue
            g2 = raw_image_data[1::2, 1::2]     # Green 2

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'GBRG':
            g1 = raw_image_data[::2, ::2]     # Green 1
            b = raw_image_data[::2, 1::2]      # Blue
            r = raw_image_data[1::2, ::2]      # Red
            g2 = raw_image_data[1::2, 1::2]     # Green 2

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")

    

    def on_item_clicked(self, item, column):
        """Handle click on a file name in the tree to preview the image."""
        self.fileTree.setFocus()

        name = item.text(0).lstrip("⚠️ ").strip()
        file_path = next((p for p in self.image_paths if os.path.basename(p) == name), None)
        if not file_path:
            return

        idx = self.image_paths.index(file_path)
        raw = self.loaded_images[idx]['image_data']

        # bring raw into float [0..1]
        if raw.dtype == np.uint16:
            imgf = raw.astype(np.float32) / 65535.0
        elif raw.dtype == np.uint8:
            imgf = raw.astype(np.float32) / 255.0
        else:
            imgf = raw.astype(np.float32).clip(0,1)

        # choose stretch
        if self.aggressive_stretch_enabled:
            disp = siril_style_autostretch(imgf, sigma=self.current_sigma)
        else:
            # your existing SEP‐based or linked stretch; e.g.:
            if imgf.ndim == 2:
                disp = stretch_mono_image(imgf, target_median=0.25, normalize=True)
            else:
                disp = stretch_color_image(imgf, target_median=0.25, linked=False)

        # convert back to uint8 for display
        disp8 = (disp * 255.0).clip(0,255).astype(np.uint8)
        qimage = self.convert_to_qimage(disp8)
        pixmap = QPixmap.fromImage(qimage)
        self.current_pixmap = pixmap
        self.apply_zoom()

    def apply_zoom(self):
        """Apply the current zoom level to the pixmap and update the display."""
        if not self.current_pixmap:
            return

        # 1) scale & show it
        scaled = self.current_pixmap.scaled(
            self.current_pixmap.size() * self.zoom_level,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation,
        )
        self.preview_label.setPixmap(scaled)
        self.preview_label.resize(scaled.size())

        # 2) center scrollbars
        self.scroll_area.horizontalScrollBar().setValue(
            (scaled.width() - self.scroll_area.viewport().width()) // 2
        )
        self.scroll_area.verticalScrollBar().setValue(
            (scaled.height() - self.scroll_area.viewport().height()) // 2
        )

        # 3) announce zoom
        pct = int(self.zoom_level * 100)
        print(f"Zoom now {pct}%")
        vp = self.scroll_area.viewport()
        center_local = vp.rect().center()                    # QPoint in viewport coords
        center_global = vp.mapToGlobal(center_local)         # map to screen coords

        QToolTip.showText(center_global, f"{pct}%")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        """Increase the zoom level and refresh the image."""
        self.zoom_level = min(self.zoom_level * 1.2, 3.0)  # Cap at 3x
        self.apply_zoom()

    @announce_zoom
    def zoom_out(self):
        """Decrease the zoom level and refresh the image."""
        self.zoom_level = max(self.zoom_level / 1.2, 0.05)  # Cap at 0.2x
        self.apply_zoom()


    def fit_to_preview(self):
        """Adjust the zoom level so the image fits within the QScrollArea viewport."""
        if self.current_pixmap:
            # Get the size of the QScrollArea's viewport
            viewport_size = self.scroll_area.viewport().size()
            pixmap_size = self.current_pixmap.size()

            # Calculate the zoom level required to fit the pixmap in the QScrollArea viewport
            width_ratio = viewport_size.width() / pixmap_size.width()
            height_ratio = viewport_size.height() / pixmap_size.height()
            self.zoom_level = min(width_ratio, height_ratio)

            # Apply the zoom level
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def on_right_click(self, pos):
        """Allow renaming, moving, deleting, and batch operations on images."""
        item = self.fileTree.itemAt(pos)
        menu = QMenu(self)

        if item:
            # Existing actions
            push_action = QAction("Push Image for Processing", self)
            push_action.triggered.connect(lambda: self.push_image_to_manager(item))
            menu.addAction(push_action)

            rename_action = QAction("Rename", self)
            rename_action.triggered.connect(lambda: self.rename_item(item))
            menu.addAction(rename_action)

            move_action = QAction("Move Selected Items", self)
            move_action.triggered.connect(lambda: self.move_items())
            menu.addAction(move_action)

            delete_action = QAction("Delete Selected Items", self)
            delete_action.triggered.connect(lambda: self.delete_items())
            menu.addAction(delete_action)

        # Batch operations
        menu.addSeparator()

        batch_delete_action = QAction("Delete All Flagged Images", self)
        batch_delete_action.triggered.connect(self.batch_delete_flagged_images)
        menu.addAction(batch_delete_action)

        batch_move_action = QAction("Move All Flagged Images", self)
        batch_move_action.triggered.connect(self.batch_move_flagged_images)
        menu.addAction(batch_move_action)

        menu.exec(self.fileTree.mapToGlobal(pos))

    def rename_item(self, item):
        """Allow the user to rename the selected image."""
        current_name = item.text(0).lstrip("⚠️ ")
        new_name, ok = QInputDialog.getText(self, "Rename Image", "Enter new name:", text=current_name)

        if ok and new_name:
            file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)
            if file_path:
                # Get the new file path with the new name
                new_file_path = os.path.join(os.path.dirname(file_path), new_name)

                try:
                    # Rename the file
                    os.rename(file_path, new_file_path)
                    print(f"File renamed from {current_name} to {new_name}")
                    
                    # Update the image paths and tree view
                    self.image_paths[self.image_paths.index(file_path)] = new_file_path
                    item.setText(0, new_name)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

    def batch_rename_items(self):
        """Batch rename selected items by adding a prefix or suffix."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for renaming.")
            return

        # Create a custom dialog for entering the prefix and suffix
        dialog = QDialog(self)
        dialog.setWindowTitle("Batch Rename")
        dialog_layout = QVBoxLayout(dialog)

        instruction_label = QLabel("Enter a prefix or suffix to rename selected files:")
        dialog_layout.addWidget(instruction_label)

        # Create fields for prefix and suffix
        form_layout = QHBoxLayout()

        prefix_field = QLineEdit(dialog)
        prefix_field.setPlaceholderText("Prefix")
        form_layout.addWidget(prefix_field)

        current_filename_label = QLabel("currentfilename", dialog)
        form_layout.addWidget(current_filename_label)

        suffix_field = QLineEdit(dialog)
        suffix_field.setPlaceholderText("Suffix")
        form_layout.addWidget(suffix_field)

        dialog_layout.addLayout(form_layout)

        # Add OK and Cancel buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK", dialog)
        ok_button.clicked.connect(dialog.accept)
        button_layout.addWidget(ok_button)

        cancel_button = QPushButton("Cancel", dialog)
        cancel_button.clicked.connect(dialog.reject)
        button_layout.addWidget(cancel_button)

        dialog_layout.addLayout(button_layout)

        # Show the dialog and handle user input
        if dialog.exec() == QDialog.DialogCode.Accepted:
            prefix = prefix_field.text().strip()
            suffix = suffix_field.text().strip()

            # Rename each selected file
            for item in selected_items:
                current_name = item.text(0)
                file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)

                if file_path:
                    # Construct the new filename
                    directory = os.path.dirname(file_path)
                    new_name = f"{prefix}{current_name}{suffix}"
                    new_file_path = os.path.join(directory, new_name)

                    try:
                        # Rename the file
                        os.rename(file_path, new_file_path)
                        print(f"File renamed from {file_path} to {new_file_path}")

                        # Update the paths and tree view
                        self.image_paths[self.image_paths.index(file_path)] = new_file_path
                        item.setText(0, new_name)

                    except Exception as e:
                        print(f"Failed to rename {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

            print(f"Batch renamed {len(selected_items)} items.")

    def batch_delete_flagged_images(self):
        """Delete all flagged images."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to delete.")
            return

        confirmation = QMessageBox.question(
            self,
            "Confirm Batch Deletion",
            f"Are you sure you want to permanently delete {len(flagged_images)} flagged images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if confirmation == QMessageBox.StandardButton.Yes:
            for img in flagged_images:
                file_path = img['file_path']
                try:
                    os.remove(file_path)
                    print(f"Deleted flagged image: {file_path}")
                except Exception as e:
                    print(f"Failed to delete {file_path}: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to delete {file_path}: {e}")

                # Remove from data structures
                self.image_paths.remove(file_path)
                self.loaded_images.remove(img)

                # Remove from tree view
                self.remove_item_from_tree(file_path)

            QMessageBox.information(self, "Batch Deletion", f"Deleted {len(flagged_images)} flagged images.")

    def batch_move_flagged_images(self):
        """Move all flagged images to a selected directory."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to move.")
            return

        # Select destination directory
        destination_dir = QFileDialog.getExistingDirectory(self, "Select Destination Folder", "")
        if not destination_dir:
            return  # User canceled

        for img in flagged_images:
            src_path = img['file_path']
            file_name = os.path.basename(src_path)
            dest_path = os.path.join(destination_dir, file_name)

            try:
                os.rename(src_path, dest_path)
                print(f"Moved flagged image from {src_path} to {dest_path}")
            except Exception as e:
                print(f"Failed to move {src_path}: {e}")
                QMessageBox.critical(self, "Error", f"Failed to move {src_path}: {e}")
                continue

            # Update data structures
            self.image_paths.remove(src_path)
            self.image_paths.append(dest_path)
            img['file_path'] = dest_path
            img['flagged'] = False  # Reset flag if desired

            # Update tree view
            self.remove_item_from_tree(src_path)
            self.add_item_to_tree(dest_path)

        QMessageBox.information(self, "Batch Move", f"Moved {len(flagged_images)} flagged images.")


    def move_items(self):
        """Allow the user to move selected images to a different directory."""
        selected_items = self.fileTree.selectedItems()
        
        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for moving.")
            return

        # Open file dialog to select a new directory
        new_directory = QFileDialog.getExistingDirectory(self, "Select Destination Folder", "")
        if not new_directory:
            return  # User canceled the directory selection

        for item in selected_items:
            current_name = item.text(0).lstrip("⚠️ ")
            file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)

            if file_path:
                new_file_path = os.path.join(new_directory, current_name)

                try:
                    # Move the file
                    os.rename(file_path, new_file_path)
                    print(f"File moved from {file_path} to {new_file_path}")
                    
                    # Update the image paths
                    self.image_paths[self.image_paths.index(file_path)] = new_file_path
                    item.setText(0, current_name)  # Update the tree view item's text (if needed)

                except Exception as e:
                    print(f"Failed to move {file_path}: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to move the file: {e}")

        # Update the tree view to reflect the moved items
        self.fileTree.clear()
        for file_path in self.image_paths:
            file_name = os.path.basename(file_path)
            item = QTreeWidgetItem([file_name])
            self.fileTree.addTopLevelItem(item)

        print(f"Moved {len(selected_items)} items.")

    def push_image_to_manager(self, item):
        """Push the selected image to the ImageManager."""
        file_name = item.text(0).lstrip("⚠️ ")
        file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

        if file_path and self.image_manager:
            # Load the image into ImageManager
            image, header, bit_depth, is_mono = load_image(file_path)

            # Check for Bayer pattern or RAW image type (For FITS and RAW images)
            if file_path.lower().endswith(('.fits', '.fit')):
                # For FITS, check the header for Bayer pattern
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    print(f"Bayer pattern detected in FITS image: {bayer_pattern}")
                    # Debayer the FITS image based on the Bayer pattern
                    image = self.debayer_fits(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono

            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                # For RAW images, debayer directly using the raw image data
                print(f"Debayering RAW image: {file_path}")
                # We assume `header` contains the Bayer pattern info from rawpy
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    # Debayer the RAW image based on the Bayer pattern
                    image = self.debayer_raw(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono
                else:
                    # If no Bayer pattern in the header, default to RGGB for debayering
                    print("No Bayer pattern found in RAW header. Defaulting to RGGB.")
                    image = self.debayer_raw(image, 'RGGB')
                    is_mono = False  # After debayering, the image is no longer mono

            # Create metadata for the image
            metadata = {
                'file_path': file_path,
                'original_header': header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }

            # Add the debayered image to ImageManager (use the current slot)
            self.image_manager.add_image(self.image_manager.current_slot, image, metadata)
            print(f"Image {file_path} pushed to ImageManager for processing.")

    def delete_items(self):
        """Delete the selected items from the tree, the loaded images list, and the file system."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for deletion.")
            return

        # Confirmation dialog
        reply = QMessageBox.question(
            self,
            'Confirm Deletion',
            f"Are you sure you want to permanently delete {len(selected_items)} selected images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            for item in selected_items:
                file_name = item.text(0).lstrip("⚠️ ")
                file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

                if file_path:
                    try:
                        # Remove the image from image_paths
                        if file_path in self.image_paths:
                            self.image_paths.remove(file_path)
                            print(f"Image path {file_path} removed from image_paths.")
                        else:
                            print(f"Image path {file_path} not found in image_paths.")

                        # Remove the corresponding image from loaded_images
                        matching_image_data = next((entry for entry in self.loaded_images if entry['file_path'] == file_path), None)
                        if matching_image_data:
                            self.loaded_images.remove(matching_image_data)
                            print(f"Image {file_name} removed from loaded_images.")
                        else:
                            print(f"Image {file_name} not found in loaded_images.")

                        # Delete the file from the filesystem
                        os.remove(file_path)
                        print(f"File {file_path} deleted successfully.")

                    except Exception as e:
                        print(f"Failed to delete {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to delete the image file: {e}")

            # Remove the selected items from the TreeWidget
            for item in selected_items:
                parent = item.parent()
                if parent:
                    parent.removeChild(item)
                else:
                    index = self.fileTree.indexOfTopLevelItem(item)
                    if index != -1:
                        self.fileTree.takeTopLevelItem(index)

            print(f"Deleted {len(selected_items)} items.")

            # Clear the preview if the deleted items include the currently displayed image
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')

            self.current_image = None

    def eventFilter(self, source, event):
        """Handle mouse events for dragging."""
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                # Start dragging
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                # Handle dragging
                delta = event.pos() - self.last_mouse_pos
                self.scroll_area.horizontalScrollBar().setValue(
                    self.scroll_area.horizontalScrollBar().value() - delta.x()
                )
                self.scroll_area.verticalScrollBar().setValue(
                    self.scroll_area.verticalScrollBar().value() - delta.y()
                )
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                # Stop dragging
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def on_selection_changed(self, selected, deselected):
        """Handle the selection change event."""
        # Get the selected item from the TreeView
        selected_items = self.fileTree.selectedItems()
        if selected_items:
            item = selected_items[0]  # Get the first selected item (assuming single selection)
            self.on_item_clicked(item, 0)  # Update the preview with the selected image

    def convert_to_qimage(self, img_array):
        """Convert numpy image array to QImage."""
        # 1) Bring everything into a uint8 (0–255) array
        if img_array.dtype == np.uint8:
            arr8 = img_array
        elif img_array.dtype == np.uint16:
            # downscale 16-bit → 8-bit
            arr8 = (img_array.astype(np.float32) / 65535.0 * 255.0).clip(0,255).astype(np.uint8)
        else:
            # assume float in [0..1]
            arr8 = (img_array.clip(0.0, 1.0) * 255.0).astype(np.uint8)

        h, w = arr8.shape[:2]
        buffer = arr8.tobytes()

        if arr8.ndim == 3:
            # RGB
            return QImage(buffer, w, h, 3*w, QImage.Format.Format_RGB888)
        else:
            # grayscale
            return QImage(buffer, w, h, w, QImage.Format.Format_Grayscale8)

class CosmicClarityTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.settings_file = "cosmic_clarity_folder.txt"  # Path to save the folder location
        self.zoom_factor = 1  # Zoom level
        self.drag_start_position = QPoint()  # Starting point for drag
        self.is_dragging = False  # Flag to indicate if dragging
        self.scroll_position = QPoint(0, 0)  # Initialize scroll position
        self.original_image = None  # Image before processing
        self.processed_image = None  # Most recent processed image    
        self.is_selecting_preview = False  # Initialize preview selection attribute
        self.preview_start_position = None
        self.preview_end_position = None
        self.preview_rect = None  # Stores the preview selection rectangle
        self.autostretch_enabled = False  # Track autostretch status
        self.settings = QSettings() 
        self.cosmic_clarity_folder = None
        self.cropped_operation_queue = []
        self.image = None

        self.initUI()

        self.load_cosmic_clarity_folder()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left panel for controls
        left_layout = QVBoxLayout()

        

        # Load button to load an image
        self.load_button = QPushButton("Load Image")
        self.load_button.clicked.connect(self.load_image)
        left_layout.addWidget(self.load_button)

        # AutoStretch toggle button
        self.auto_stretch_button = QPushButton("AutoStretch (Off)")
        self.auto_stretch_button.setCheckable(True)
        self.auto_stretch_button.toggled.connect(self.toggle_auto_stretch)
        left_layout.addWidget(self.auto_stretch_button)

        # Left column for Sharpen, Denoise, and Both
        left_radio_layout = QVBoxLayout()
        self.sharpen_radio = QRadioButton("Sharpen")
        self.denoise_radio = QRadioButton("Denoise")
        self.both_radio = QRadioButton("Both")
        self.sharpen_radio.setChecked(True)  # Default

        left_radio_layout.addWidget(self.sharpen_radio)
        left_radio_layout.addWidget(self.denoise_radio)
        left_radio_layout.addWidget(self.both_radio)

        # Right column for Super Resolution Upscaling
        right_radio_layout = QVBoxLayout()
        self.superres_radio = QRadioButton("Super Resolution Upscaling")
        right_radio_layout.addWidget(self.superres_radio)

        # Connect toggles to UI update method
        self.sharpen_radio.toggled.connect(self.update_ui_for_mode)
        self.denoise_radio.toggled.connect(self.update_ui_for_mode)
        self.both_radio.toggled.connect(self.update_ui_for_mode)
        self.superres_radio.toggled.connect(self.update_ui_for_mode)

        # Main horizontal layout to place columns side-by-side
        main_radio_layout = QHBoxLayout()
        main_radio_layout.addLayout(left_radio_layout)
        main_radio_layout.addLayout(right_radio_layout)

        # Add the combined layout to your parent layout
        left_layout.addLayout(main_radio_layout)


        # GPU Acceleration dropdown
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Add Sharpening specific controls
        self.sharpen_mode_label = QLabel("Sharpening Mode:")
        self.sharpen_mode_dropdown = QComboBox()
        self.sharpen_mode_dropdown.addItems(["Both", "Stellar Only", "Non-Stellar Only"])
        left_layout.addWidget(self.sharpen_mode_label)
        left_layout.addWidget(self.sharpen_mode_dropdown)

        # Dropdown for Sharpen Channels Separately option
        self.sharpen_channels_label = QLabel("Sharpen RGB Channels Separately:")
        self.sharpen_channels_dropdown = QComboBox()
        self.sharpen_channels_dropdown.addItems(["No", "Yes"])  # "No" means don't separate, "Yes" means separate
        left_layout.addWidget(self.sharpen_channels_label)
        left_layout.addWidget(self.sharpen_channels_dropdown)

        # Non-Stellar Sharpening PSF Slider
        self.psf_slider_label = QLabel("Non-Stellar Sharpening PSF (1-8): 3")
        self.psf_slider = QSlider(Qt.Orientation.Horizontal)
        self.psf_slider.setMinimum(10)
        self.psf_slider.setMaximum(80)
        self.psf_slider.setValue(30)
        self.psf_slider.valueChanged.connect(self.update_psf_slider_label)
        left_layout.addWidget(self.psf_slider_label)
        left_layout.addWidget(self.psf_slider)

        # Stellar Amount Slider
        self.stellar_amount_label = QLabel("Stellar Sharpening Amount (0-1): 0.50")
        self.stellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.stellar_amount_slider.setMinimum(0)
        self.stellar_amount_slider.setMaximum(100)
        self.stellar_amount_slider.setValue(50)
        self.stellar_amount_slider.valueChanged.connect(self.update_stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_slider)

        # Non-Stellar Amount Slider
        self.nonstellar_amount_label = QLabel("Non-Stellar Sharpening Amount (0-1): 0.50")
        self.nonstellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.nonstellar_amount_slider.setMinimum(0)
        self.nonstellar_amount_slider.setMaximum(100)
        self.nonstellar_amount_slider.setValue(50)
        self.nonstellar_amount_slider.valueChanged.connect(self.update_nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_slider)

        # Denoise Strength Slider
        self.denoise_strength_label = QLabel("Denoise Strength (0-1): 0.50")
        self.denoise_strength_slider = QSlider(Qt.Orientation.Horizontal)
        self.denoise_strength_slider.setMinimum(0)
        self.denoise_strength_slider.setMaximum(100)
        self.denoise_strength_slider.setValue(50)
        self.denoise_strength_slider.valueChanged.connect(self.update_denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_slider)

        # Denoise Mode dropdown
        self.denoise_mode_label = QLabel("Denoise Mode:")
        self.denoise_mode_dropdown = QComboBox()
        self.denoise_mode_dropdown.addItems(["luminance", "full"])  # 'luminance' for luminance-only, 'full' for full YCbCr denoising
        left_layout.addWidget(self.denoise_mode_label)
        left_layout.addWidget(self.denoise_mode_dropdown)

        # Scale factor dropdown (initially hidden)
        self.scale_label = QLabel("Scale Factor:")
        self.scale_dropdown = QComboBox()
        self.scale_dropdown.addItems(["2x", "3x", "4x"])

        left_layout.addWidget(self.scale_label)
        left_layout.addWidget(self.scale_dropdown)

        # Initially hidden, only show for Super Resolution
        self.scale_label.hide()
        self.scale_dropdown.hide()

        # Execute button
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.run_cosmic_clarity)
        left_layout.addWidget(self.execute_button)

        # Save button to save the processed image
        self.save_button = QPushButton("Save Image")
        self.save_button.clicked.connect(self.save_processed_image_to_disk)
        #left_layout.addWidget(self.save_button)  

        # Spacer to push the wrench button to the bottom
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Cosmic Clarity folder path label
        self.cosmic_clarity_folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.cosmic_clarity_folder_label)

        # Wrench button to select Cosmic Clarity folder
        self.wrench_button = QPushButton()

        # Set the path for the wrench icon
        if hasattr(sys, '_MEIPASS'):
            wrench_path = os.path.join(sys._MEIPASS, "wrench_icon.png")
        else:
            wrench_path = "wrench_icon.png"

        self.wrench_button.setIcon(QIcon(wrench_path))  # Set the wrench icon with the dynamic path
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)  

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)   


        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Right panel for image preview with zoom controls
        right_layout = QVBoxLayout()

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview with click-and-drag functionality
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.image_label)
        right_layout.addWidget(self.scroll_area)

        # Button to open the preview area selection dialog
        self.select_preview_button = QPushButton("Select Preview Area")
        self.select_preview_button.clicked.connect(self.open_preview_dialog)
        right_layout.addWidget(self.select_preview_button)        

        left_widget = QWidget()
        left_widget.setLayout(left_layout)
        left_widget.setFixedWidth(400)

        # Add left and right layouts to the main layout
        main_layout.addWidget(left_widget)
        main_layout.addLayout(right_layout)

        self.setLayout(main_layout)
        self.update_ui_for_mode()

    def update_image_display(self):
        """
        Update the displayed image by scaling the stored base pixmap according
        to the current zoom factor.
        """
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            print("Base pixmap not available. Please update it first.")
            return

        # Calculate new dimensions using the current zoom factor.
        new_width = int(self.base_pixmap.width() * self.zoom_factor)
        new_height = int(self.base_pixmap.height() * self.zoom_factor)
        
        # Scale the base pixmap quickly.
        scaled_pixmap = self.base_pixmap.scaled(
            new_width, new_height,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        
        self.image_label.setPixmap(scaled_pixmap)


        # Optionally, adjust scroll bars to keep the view centered.
        # (You might reuse your current code for centering.)


    def update_base_pixmap(self):
        """
        Process self.image (applying autostretch if enabled) and store it as self.base_pixmap.
        If self.image is empty or not as expected, it skips processing.
        """
        if self.image is None or self.image.size == 0:
            print("[WARNING] No image available to update base pixmap.")
            self.base_pixmap = None
            return

        display_image = self.image.copy()

        # Apply autostretch if enabled.
        if self.auto_stretch_button.isChecked():
            target_median = 0.25
            # Check image dimensions to decide whether it's mono or color.
            if display_image.ndim < 3 or (display_image.ndim == 3 and display_image.shape[2] != 3):
                # Treat as grayscale: if image is 3D but not 3 channels, pick one channel
                try:
                    mono_source = display_image if display_image.ndim == 2 else display_image[:, :, 0]
                    stretched = stretch_mono_image(mono_source, target_median, normalize=True)
                    # Convert grayscale to 3-channel for display.
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            else:
                # Color image with three channels.
                try:
                    display_image = stretch_color_image(display_image, target_median, linked=False, normalize=True)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return

        try:
            display_image_uint8 = (display_image * 255).astype(np.uint8)
        except Exception as e:
            print(f"[ERROR] Converting image to uint8: {e}")
            return

        # Create a QImage from the numpy array.
        if display_image_uint8.ndim == 3 and display_image_uint8.shape[2] == 3:
            height, width, _ = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif display_image_uint8.ndim == 2:
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            print("[ERROR] Unexpected image format!")
            return

        self.base_pixmap = QPixmap.fromImage(qimage)
        print("Base pixmap updated.")

    def update_psf_slider_label(self):
        """Update the label text to display the current value of the PSF slider as a non-integer."""
        psf_value = self.psf_slider.value() / 10  # Convert to a float in the range 1.0 - 8.0
        self.psf_slider_label.setText(f"Non-Stellar Sharpening PSF (1.0-8.0): {psf_value:.1f}")

    def update_stellar_amount_label(self):
        self.stellar_amount_label.setText(f"Stellar Sharpening Amount (0-1): {self.stellar_amount_slider.value() / 100:.2f}")

    def update_nonstellar_amount_label(self):
        self.nonstellar_amount_label.setText(f"Non-Stellar Sharpening Amount (0-1): {self.nonstellar_amount_slider.value() / 100:.2f}")

    def update_denoise_strength_label(self):
        self.denoise_strength_label.setText(f"Denoise Strength (0-1): {self.denoise_strength_slider.value() / 100:.2f}")

    def mousePressEvent(self, event):
        """Handle the start of the drag action or selection of a preview area."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.is_dragging = True
            self.drag_start_position = event.pos()              
                

    def mouseMoveEvent(self, event):
        """Handle dragging or adjusting the preview selection area."""
        if self.is_dragging:
            # Handle image panning
            delta = event.pos() - self.drag_start_position
            self.scroll_area.horizontalScrollBar().setValue(self.scroll_area.horizontalScrollBar().value() - delta.x())
            self.scroll_area.verticalScrollBar().setValue(self.scroll_area.verticalScrollBar().value() - delta.y())
            self.drag_start_position = event.pos()


    def mouseReleaseEvent(self, event):
        """End the drag action or finalize the preview selection area."""
        if event.button() == Qt.MouseButton.LeftButton:
            if self.is_dragging:
                self.is_dragging = False


    def open_preview_dialog(self):
        """Open a preview dialog to select a 640x480 area of the image at 100% scale."""
        if self.image is not None:
            # Pass the 32-bit numpy image directly to maintain bit depth
            self.preview_dialog = PreviewDialog(self.image, parent_tab=self, is_mono=self.is_mono)
            self.preview_dialog.show()
        else:
            print("No image loaded. Please load an image first.")



    def convert_numpy_to_qimage(self, np_img):
        """Convert a numpy array to QImage."""
        # Ensure image is in 8-bit format for QImage compatibility
        if np_img.dtype == np.float32:
            np_img = (np_img * 255).astype(np.uint8)  # Convert normalized float32 to uint8 [0, 255]
        
        if np_img.dtype == np.uint8:
            if len(np_img.shape) == 2:
                # Grayscale image
                height, width = np_img.shape
                bytes_per_line = width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            elif len(np_img.shape) == 3 and np_img.shape[2] == 3:
                # RGB image
                height, width, channels = np_img.shape
                bytes_per_line = 3 * width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            print("Image format not supported for conversion to QImage.")
            return None

    def validate_cosmic_clarity_folder(self):
        """Check if the Cosmic Clarity folder is set and valid."""
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(
                self,
                "Missing Folder",
                "The Cosmic Clarity folder is not set. Please use the wrench icon to select the correct folder."
            )
            return False

        # Determine the expected executable based on the platform
        if os.name == "nt":  # Windows
            expected_executable = "SetiAstroCosmicClarity.exe"
        elif sys.platform == "darwin":  # macOS
            expected_executable = "SetiAstroCosmicClaritymac"
        else:  # Linux
            expected_executable = "SetiAstroCosmicClarity"  # Case-sensitive, no extension

        # Check if the expected executable exists in the folder
        executable_path = os.path.join(self.cosmic_clarity_folder, expected_executable)
        if not os.path.exists(executable_path):
            QMessageBox.warning(
                self,
                "Invalid Folder",
                f"Incorrect Cosmic Clarity folder. Please choose the parent folder containing the Cosmic Clarity executable:\n\n"
                f"Expected file: {expected_executable}"
            )
            return False

        return True



    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.save_cosmic_clarity_folder(folder)
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.update_image_display()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.update_image_display()

    def fit_to_preview(self):
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            return
        preview_width = self.scroll_area.viewport().width()
        self.zoom_factor = preview_width / self.base_pixmap.width()
        self.update_image_display()


    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.update_image_display()  # Call without extra arguments; it will calculate dimensions based on zoom factor
    



    def restore_image(self, image_array):
        """Display a given image array, preserving the current zoom level and scroll position."""
        # Save the current zoom level and scroll position
        current_zoom = self.zoom_factor
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Display the image
        self.show_image(image_array)

        # Restore the zoom level and scroll position
        self.zoom_factor = current_zoom
        self.update_image_display()  # Refresh display with the preserved zoom level

        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])


    def save_cosmic_clarity_folder(self, folder):
        """Save the Cosmic Clarity folder path using QSettings."""
        self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
        print(f"Saved Cosmic Clarity folder to QSettings: {folder}")

    def load_cosmic_clarity_folder(self):
        """Load the saved Cosmic Clarity folder path from QSettings."""
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            print(f"Loaded Cosmic Clarity folder from QSettings: {folder}")
        else:
            print("No saved Cosmic Clarity folder found in QSettings.")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return
        if image is None:
            return        
        if slot == self.image_manager.current_slot:
            self.loaded_image_path = metadata.get('file_path', None)
            self.original_header = metadata.get('original_header', None)
            self.bit_depth = metadata.get('bit_depth', None)
            self.is_mono = metadata.get('is_mono', False)

            # Ensure image is in numpy array format
            if not isinstance(image, np.ndarray):
                image = np.array(image)

            # Handle mono and color images
            if self.is_mono:
                # Squeeze the singleton dimension for grayscale images if it exists
                if len(image.shape) == 3 and image.shape[2] == 1:
                    print(f"Mono image detected with shape: {image.shape}. Squeezing singleton dimension.")
                    image = np.squeeze(image, axis=2)  # Convert (H, W, 1) to (H, W)
                # Do not convert a mono image to 3-channel RGB; keep it as 2D.

            elif len(image.shape) == 3 and image.shape[2] not in [1, 3]:
                # Catch unexpected formats like (H, W, C) where C is not 1 or 3
                raise ValueError(f"Unexpected image format with shape {image.shape}. Must be RGB or Grayscale.")

            self.image = image

            # Show the image using the show_image method
            self.update_base_pixmap()
            # Now update the display by scaling the base pixmap.
            self.update_image_display()
            print(f"CosmicClarityTab: Image updated from ImageManager slot {slot}.")



    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def load_image(self):
        """Load an image and set it as the current and original image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.jpg *.tif *.tiff *.fits *.fit *.jpeg *.xisf)"
        )
        if file_path:
            print(f"Loading file: {file_path}")

            # Load the image and store it as the original image
            image, original_header, bit_depth, is_mono = load_image(file_path)
            
            # Check if the image was loaded successfully
            if image is None:
                print("Error: Failed to load the image data.")
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            print(f"Image loaded successfully. Shape: {image.shape}, Dtype: {image.dtype}")

            # Make a copy of the original image for reference
            try:
                self.original_image = image.copy()
                print("Original image copied successfully.")
            except Exception as e:
                print(f"Error copying original image: {e}")
                QMessageBox.critical(self, "Error", "Failed to copy the original image.")
                return

            # Clear any existing processed image
            self.processed_image = None

            # Attempt to display the loaded image in the preview
            try:
                self.show_image(image)  # Ensure this function can handle 32-bit float images
                print("Image displayed successfully.")
            except Exception as e:
                print(f"Error displaying image: {e}")
                QMessageBox.critical(self, "Error", "Failed to display the image.")
                return

            # Enable or disable buttons as necessary


            # Center scrollbars after a short delay
            try:
                QTimer.singleShot(50, self.center_scrollbars)  # Delay of 50 ms for centering scrollbars
                print("Scrollbars centered.")
            except Exception as e:
                print(f"Error centering scrollbars: {e}")

            # Update the display after another short delay to ensure scrollbars are centered first
            try:
                QTimer.singleShot(100, self.update_image_display)  # Delay of 100 ms for display update
                print("Image display updated.")
            except Exception as e:
                print(f"Error updating image display: {e}")

            # Update ImageManager with the new image
            metadata = {
                'file_path': file_path,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

        else:
            print("No file selected.")



    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def show_image(self, image=None):
        """
        Display the loaded image by updating the base pixmap (which applies autostretch)
        and then updating the display using that pixmap.
        """
        # Use the passed image if provided; otherwise use self.image.
        if image is not None:
            self.image = image

        if self.image is None:
            print("[ERROR] No image to display.")
            QMessageBox.warning(self, "No Image", "No image data available to display.")
            return False

        # Save the current scroll position so it can be restored.
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Update the base pixmap (this applies autostretch if the auto_stretch_button is checked)
        self.update_base_pixmap()
        
        # Now update the display using the base pixmap.
        self.update_image_display()

        # Restore the scroll position.
        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])

        return True


    def store_processed_image(self, processed_image):
        """Store the processed image and update the ImageManager."""
        if processed_image is not None:
            # Prepare metadata for the ImageManager
            metadata = {
                'file_path': self.loaded_image_path,      # Ensure this is correctly set elsewhere
                'original_header': self.original_header,  # Ensure this is correctly set elsewhere
                'bit_depth': self.bit_depth,              # Ensure this is correctly set elsewhere
                'is_mono': self.is_mono                   # Ensure this is correctly set elsewhere
            }

            # Use ImageManager's set_image method to manage undo/redo stack
            if self.image_manager:
                try:
                    self.image_manager.set_image(processed_image, metadata, step_name="Cosmic Clarity")
                    print("CosmicClarityTab: Processed image stored in ImageManager with undo/redo support.")
                except Exception as e:
                    # Handle potential errors during the update
                    QMessageBox.critical(self, "Error", f"Failed to store processed image in ImageManager:\n{e}")
                    print(f"Error storing processed image in ImageManager: {e}")
            else:
                print("ImageManager is not initialized.")
                QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
        else:
            print("No processed image available to store.")
            QMessageBox.warning(self, "Warning", "No processed image available to store.")


    def toggle_auto_stretch(self, checked):
        """Toggle autostretch and update the display."""
        self.autostretch_enabled = checked
        self.auto_stretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        # Recalculate the base pixmap using the new autostretch setting.
        self.update_base_pixmap()
        # Then update the displayed image.
        self.update_image_display()



    def save_input_image(self, file_path):
        """Save the current image to the specified path in TIF format."""
        if self.image is not None:
            try:
                from tifffile import imwrite
                # Force saving as `.tif` format
                if not file_path.endswith(".tif"):
                    file_path += ".tif"
                # If image is mono with shape (H, W, 1), squeeze it to (H, W)
                image_to_save = self.image.astype(np.float32)
                if image_to_save.ndim == 3 and image_to_save.shape[2] == 1:
                    image_to_save = image_to_save.squeeze(axis=2)
                imwrite(file_path, image_to_save)
                print(f"Image saved as TIFF to {file_path}")
            except Exception as e:
                print(f"Error saving input image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save input image:\n{e}")
        else:
            QMessageBox.warning(self, "Warning", "No image to save.")

    def update_ui_for_mode(self):
        if self.superres_radio.isChecked():
            self.hide_sharpen_controls()
            self.hide_denoise_controls()
            self.show_superres_controls()
            self.gpu_label.hide()
            self.gpu_dropdown.hide()
        else:
            self.hide_superres_controls()
            self.gpu_label.show()
            self.gpu_dropdown.show()

            if self.sharpen_radio.isChecked():
                self.show_sharpen_controls()
                self.hide_denoise_controls()
            elif self.denoise_radio.isChecked():
                self.hide_sharpen_controls()
                self.show_denoise_controls()
            elif self.both_radio.isChecked():
                self.show_sharpen_controls()
                self.show_denoise_controls()



    def show_sharpen_controls(self):
        self.sharpen_mode_label.show()
        self.sharpen_mode_dropdown.show()
        self.psf_slider_label.show()
        self.psf_slider.show()
        self.stellar_amount_label.show()
        self.stellar_amount_slider.show()
        self.nonstellar_amount_label.show()
        self.nonstellar_amount_slider.show()
        self.sharpen_channels_label.show()
        self.sharpen_channels_dropdown.show()

    def hide_sharpen_controls(self):
        self.sharpen_mode_label.hide()
        self.sharpen_mode_dropdown.hide()
        self.psf_slider_label.hide()
        self.psf_slider.hide()
        self.stellar_amount_label.hide()
        self.stellar_amount_slider.hide()
        self.nonstellar_amount_label.hide()
        self.nonstellar_amount_slider.hide()
        self.sharpen_channels_label.hide()
        self.sharpen_channels_dropdown.hide()

    def show_denoise_controls(self):
        self.denoise_strength_label.show()
        self.denoise_strength_slider.show()
        self.denoise_mode_label.show()
        self.denoise_mode_dropdown.show()

    def hide_denoise_controls(self):
        self.denoise_strength_label.hide()
        self.denoise_strength_slider.hide()
        self.denoise_mode_label.hide()
        self.denoise_mode_dropdown.hide()

    def show_superres_controls(self):
        self.scale_label.show()
        self.scale_dropdown.show()

    def hide_superres_controls(self):
        self.scale_label.hide()
        self.scale_dropdown.hide()


    def get_psf_value(self):
        """Convert the slider value to a float in the range 1.0 - 8.0."""
        return self.psf_slider.value() / 10.0
    
    def run_cosmic_clarity(self, input_file_path=None):
        """Run Cosmic Clarity with the current parameters."""
        if not self.validate_cosmic_clarity_folder():
            return

        if self.image is None:
            QMessageBox.warning(self, "Warning", "Please load an image first.")
            return

        if self.superres_radio.isChecked():
            self.execute_super_resolution()
            return  # Skip the rest if super-resolution mode is chosen

        psf_value = self.get_psf_value()
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return
        if self.image is None:  # Ensure an image is currently displayed
            QMessageBox.warning(self, "Warning", "Please load an image first.")
            return

        # Check the current autostretch state
        was_autostretch_enabled = self.auto_stretch_button.isChecked()

        # Disable autostretch if it was enabled
        if was_autostretch_enabled:
            self.auto_stretch_button.setChecked(False)

        # Determine mode from the radio buttons
        if self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        elif self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.operation_queue = list(zip(modes, output_suffixes))



        # Start the first operation
        if self.operation_queue:
            self._execute_cosmic_clarity(*self.operation_queue.pop(0))

    def execute_super_resolution(self):
        scale_str = self.scale_dropdown.currentText()
        scale_factor = int(scale_str.replace("x", ""))

        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        os.makedirs(input_folder, exist_ok=True)
        os.makedirs(output_folder, exist_ok=True)

        base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        input_path = os.path.join(input_folder, base_filename + ".tif")

        # Save current image
        self.save_input_image(input_path)

        if sys.platform.startswith("win"):
            executable_name = "setiastrocosmicclarity_superres.exe"
        else:
            executable_name = "setiastrocosmicclarity_superres"

        executable_path = os.path.join(self.cosmic_clarity_folder, executable_name)

        cmd = [
            executable_path,
            "--input", input_path,
            "--output_dir", output_folder,
            "--scale", str(scale_factor),
            "--model_dir", self.cosmic_clarity_folder,  # or "." if models are in executable folder
        ]

        # Directly run superres.py for debugging (assuming it's in the same folder)
        #superres_script = os.path.join(os.path.dirname(os.path.abspath(__file__)), "setiastrocosmicclarity_superres.py")

        #cmd = [
        #    sys.executable,  # path to Python interpreter
        #    superres_script,
        #    "--input", input_path,
        #    "--output_dir", output_folder,
        #    "--scale", str(scale_factor),

        #]

        print(f"Running command: {' '.join(cmd)}")

        self.process_q_superres = QProcess(self)
        self.process_q_superres.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)

        self.process_q_superres.readyReadStandardOutput.connect(self.read_superres_output)
        self.process_q_superres.finished.connect(self.superres_finished)

        self.process_q_superres.start(cmd[0], cmd[1:])

        self.wait_dialog = WaitDialog(self)
        self.wait_dialog.setWindowTitle("Super Resolution Running...")
        self.wait_dialog.cancelled.connect(self.on_wait_cancelled_superres)
        self.wait_dialog.show()


    def read_superres_output(self):
        output = self.process_q_superres.readAllStandardOutput().data().decode("utf-8", errors="replace")
        
        # Check for progress lines explicitly
        for line in output.splitlines():
            if line.startswith("PROGRESS:"):
                try:
                    progress_pct = int(line.split(":")[1].strip().replace('%', ''))
                    self.wait_dialog.set_progress(progress_pct)  # Assuming WaitDialog has set_progress()
                except ValueError:
                    pass  # Invalid progress line, skip
            else:
                self.wait_dialog.append_output(line)


    def superres_finished(self, exitCode, exitStatus):
        self.wait_dialog.close()
        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Super Resolution failed with exit code {exitCode}.")
            return

        scale_str = self.scale_dropdown.currentText()
        base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        suffix = f"_upscaled{scale_str}"
        output_file_glob = os.path.join(output_folder, base_filename + suffix + ".fit")

        matching_files = glob.glob(output_file_glob)
        if matching_files:
            output_file_path = matching_files[0]
            # Load and display the result
            final_img, hdr, bd, mono = load_image(output_file_path)
            if final_img is not None:
                self.show_image(final_img)
                self.store_processed_image(final_img)
                QMessageBox.information(self, "Success", "Super Resolution completed successfully.")
                self.cleanup_files(os.path.join(self.cosmic_clarity_folder, "input", base_filename + ".tif"), output_file_path)
            else:
                QMessageBox.warning(self, "Error", "Failed to load Super Resolution image.")
        else:
            QMessageBox.warning(self, "Error", "Output file not found.")

    def on_wait_cancelled_superres(self):
        if hasattr(self, 'process_q_superres'):
            self.process_q_superres.kill()
            QMessageBox.information(self, "Cancelled", "Super Resolution cancelled.")


    def _execute_cosmic_clarity(self, mode, output_suffix):
        if self.loaded_image_path is None:
            print("Warning: loaded_image_path is None. Using default base filename 'image'.")
            base_filename = "image"
        else:
            base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        print(f"Base filename before saving: {base_filename}")  # Debug print
        """Execute a single Cosmic Clarity operation."""
        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")


        # Save the current previewed image directly to the input folder
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")
        self.save_input_image(input_file_path)  # Save as `.tif`
        self.current_input_file_path = input_file_path

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.tif")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Use QProcess instead of subprocess
        self.process_q = QProcess(self)
        self.process_q.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q.readyReadStandardOutput.connect(self.qprocess_output_main)
        self.process_q.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished(mode, exitCode, exitStatus))

        # Start the process
        self.process_q.setProgram(exe_path)
        self.process_q.setArguments(args)
        self.process_q.start()

        if not self.process_q.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Set up file waiting worker and wait dialog
        self.wait_thread = WaitForFileWorker(output_file_glob, timeout=3000)
        self.wait_thread.fileFound.connect(self.on_file_found)
        self.wait_thread.error.connect(self.on_file_error)
        self.wait_thread.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog = WaitDialog(self)
        self.wait_dialog.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog.show()

        self.wait_thread.start()


    ########################################
    # Below are the new helper slots (methods) to handle signals from worker and dialog.
    ########################################

    def qprocess_output(self):
        if not hasattr(self, 'process_q_cropped') or self.process_q_cropped is None:
            return
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)

    def qprocess_output_main(self):
        """Handle output from the main Cosmic Clarity process."""
        output = self.process_q.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog') and self.wait_dialog:
                        self.wait_dialog.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog') and self.wait_dialog:
                    self.wait_dialog.append_output(line)


    def qprocess_output_cropped(self):
        """Handle output from the cropped Cosmic Clarity process."""
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)


    def qprocess_finished(self, mode, exitCode, exitStatus):
        """Handle process completion for a specific mode."""

        
        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")

        


    def read_process_output(self):
        """Read output from the process and display it in the wait_dialog's text edit."""
        if self.process is None:
            return

        # Read all available lines from stdout
        while True:
            line = self.process.stdout.readline()
            if not line:
                break
            line = line.strip()
            if line:
                # Append the line to the wait_dialog's output text
                self.wait_dialog.append_output(line)

        # Check if process has finished
        if self.process.poll() is not None:
            # Process ended
            self.output_timer.stop()
            # You can handle any cleanup here if needed

    def on_file_found(self, output_file_path):
        print(f"File found: {output_file_path}")
        self.wait_dialog.close()
        self.wait_thread = None

        if getattr(self, 'is_cropped_mode', False):
            # Existing Cropped Mode handling
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                print(f"[ERROR] Failed to load cropped image from {output_file_path}")
                QMessageBox.critical(self, "Error", f"Failed to load cropped image from {output_file_path}.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Apply autostretch if requested
            if getattr(self, 'cropped_apply_autostretch', False):
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to update preview dialog: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update preview dialog:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup with known paths
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tiff")
            self.cleanup_files(input_file_path, output_file_path)

            # Reset cropped mode
            self.is_cropped_mode = False

            # Re-enable Execute button
            self.execute_button.setEnabled(True)
        else:
            # Normal mode logic
            processed_image_path = output_file_path
            self.loaded_image_path = processed_image_path

            # Attempt to load the image with retries
            processed_image, original_header, bit_depth, is_mono = self.load_image_with_retry(processed_image_path)
            if processed_image is None:
                QMessageBox.critical(self, "Error", f"Failed to load image from {processed_image_path} after multiple attempts.")
                print(f"[ERROR] Failed to load image from {processed_image_path} after multiple attempts.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Show the processed image
            try:
                self.show_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Exception occurred while showing image: {e}")
                QMessageBox.critical(self, "Error", f"Exception occurred while showing image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Store the image in memory
            try:
                self.store_processed_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to store processed image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to store processed image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup input and output files
            input_file_path = self.current_input_file_path
            self.cleanup_files(input_file_path, processed_image_path)

            # Check if there are more operations queued
            if hasattr(self, 'operation_queue') and self.operation_queue:
                next_mode, next_suffix = self.operation_queue.pop(0)
                self._execute_cosmic_clarity(next_mode, next_suffix)


    def qprocess_finished_on_cropped(self, mode, exitCode, exitStatus, apply_autostretch):
        """Handle process completion for a specific cropped mode."""
        print(f"Process finished for {mode} operation with exit code {exitCode} and exit status {exitStatus}.")

        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")


        self.wait_dialog_cropped.close()
        print("WaitDialog_cropped closed.")



    def on_file_found_on_cropped(self, output_file_path, mode, apply_autostretch):
        print(f"File found for cropped {mode} operation: {output_file_path}")
        
        try:
            # Load the processed cropped image
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                raise ValueError(f"Failed to load cropped image from {output_file_path}")
            print("Processed image loaded successfully.")

            # Apply autostretch if requested
            if apply_autostretch:
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                    print("Autostretch applied to mono image.")
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)
                    print("Autostretch applied to color image.")

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
                print("Preview dialog updated with processed image.")
            except Exception as e:
                raise RuntimeError(f"Failed to update preview dialog: {e}")

            # Cleanup input and output files with correct extension
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tif")
            self.cleanup_files(input_file_path, output_file_path)
            print("Input and output files cleaned up.")

            # Reset cropped mode flags if necessary
            self.is_cropped_mode = False
            print("Cropped mode flags reset.")

            # Check if there are more operations queued
            if self.cropped_operation_queue:
                next_mode, next_suffix = self.cropped_operation_queue.pop(0)
                print(f"Proceeding to next operation: {next_mode} with suffix {next_suffix}.")
                # Execute the next operation
                self._execute_cosmic_clarity_on_cropped(next_mode, next_suffix, processed_image, apply_autostretch)

        except Exception as e:
            print(f"[ERROR] {e}")
            QMessageBox.critical(self, "Error", f"An error occurred: {e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button




    def on_file_error(self, msg):
        # File not found in time
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.critical(self, "Error", msg)


    def on_file_cancelled(self):
        # The worker was stopped before finding a file
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.information(self, "Cancelled", "File waiting was cancelled.")


    def on_wait_cancelled(self):
        # If we have a QProcess reference, terminate it
        if hasattr(self, 'process_q') and self.process_q is not None:
            self.process_q.kill()  # or self.process_q.terminate()

        QMessageBox.information(self, "Cancelled", "Operation was cancelled by the user.")




    def run_cosmic_clarity_on_cropped(self, cropped_image, apply_autostretch=False):
        """Run Cosmic Clarity on a cropped image, with an option to autostretch upon receipt."""

        if not self.validate_cosmic_clarity_folder():
            return  # Stop execution if the folder is not valid

        if cropped_image is None:  # Ensure a cropped image is provided
            QMessageBox.warning(self, "Warning", "No cropped image provided.")
            return

        # Convert the cropped image to 32-bit floating point format
        cropped_image_32bit = cropped_image.astype(np.float32) / np.max(cropped_image)  # Normalize if needed

        # Determine mode and suffix based on the selected radio button
        if self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        elif self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.cropped_operation_queue = list(zip(modes, output_suffixes))

 
        # Start the first operation
        if self.cropped_operation_queue:
            self._execute_cosmic_clarity_on_cropped(*self.cropped_operation_queue.pop(0), cropped_image_32bit, apply_autostretch)


    def _execute_cosmic_clarity_on_cropped(self, mode, output_suffix, cropped_image_32bit, apply_autostretch):
        """Execute a single Cosmic Clarity operation on a cropped image."""
        print(f"Starting '{mode}' operation with suffix '{output_suffix}'.")

        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        base_filename = "cropped_preview_image"  # Using a fixed name for cropped images
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")  # Changed to .tif

        # Ensure input and output directories exist
        os.makedirs(input_folder, exist_ok=True)
        os.makedirs(output_folder, exist_ok=True)

        # Save the 32-bit floating-point cropped image to the input folder
        try:
            save_image(cropped_image_32bit, input_file_path, "tiff", "32-bit floating point", self.original_header, self.is_mono)
            print(f"Saved cropped image to input path: {input_file_path}")
        except Exception as e:
            print(f"[ERROR] Failed to save cropped image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to save cropped image:\n{e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.*")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Build command arguments
        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Initialize QProcess
        self.process_q_cropped = QProcess(self)
        self.process_q_cropped.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q_cropped.readyReadStandardOutput.connect(self.qprocess_output_cropped)
        self.process_q_cropped.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished_on_cropped(mode, exitCode, exitStatus, apply_autostretch))

        # Start the process
        self.process_q_cropped.setProgram(exe_path)
        self.process_q_cropped.setArguments(args)
        self.process_q_cropped.start()

        if not self.process_q_cropped.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        print(f"Started Cosmic Clarity process for mode '{mode}'.")

        # Set up file waiting worker and wait dialog
        self.wait_thread_cropped = WaitForFileWorker(output_file_glob, timeout=1800)
        self.wait_thread_cropped.fileFound.connect(lambda path: self.on_file_found_on_cropped(path, mode, apply_autostretch))
        self.wait_thread_cropped.error.connect(self.on_file_error)
        self.wait_thread_cropped.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog_cropped = WaitDialog(self)
        self.wait_dialog_cropped.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog_cropped.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog_cropped.show()

        self.wait_thread_cropped.start()
        print("WaitDialog_cropped displayed and WaitForFileWorker started.")


    def build_command_args(self, exe_name, mode):
        """Build the command line arguments for Cosmic Clarity without using a batch file."""
        # exe_name is now fully resolved (including .exe on Windows if needed)
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        cmd = [exe_path]

        # Add sharpening or denoising arguments
        if mode == "sharpen":
            psf_value = self.get_psf_value()
            cmd += [
                "--sharpening_mode", self.sharpen_mode_dropdown.currentText(),
                "--stellar_amount", f"{self.stellar_amount_slider.value() / 100:.2f}",
                "--nonstellar_strength", f"{psf_value:.1f}",
                "--nonstellar_amount", f"{self.nonstellar_amount_slider.value() / 100:.2f}"
            ]
            if self.sharpen_channels_dropdown.currentText() == "Yes":
                cmd.append("--sharpen_channels_separately")
        elif mode == "denoise":
            cmd += [
                "--denoise_strength", f"{self.denoise_strength_slider.value() / 100:.2f}",
                "--denoise_mode", self.denoise_mode_dropdown.currentText()
            ]

        # GPU option
        if self.gpu_dropdown.currentText() == "No":
            cmd.append("--disable_gpu")

        return cmd

    def save_processed_image(self):
        """Save the current displayed image as the processed image."""
        self.processed_image = self.image.copy()


    def save_processed_image_to_disk(self):
        """Save the processed image to disk, using the correct format, bit depth, and header information."""
        if self.processed_image is None:
            QMessageBox.warning(self, "Warning", "No processed image to save.")
            return

        # Prompt user for the file path and format

        save_path, _ = QFileDialog.getSaveFileName(
            self, "Save Processed Image", "", 
            "TIFF Files (*.tif *.tiff);;PNG Files (*.png);;FITS Files (*.fits *.fit)"

        )
        
        if not save_path:
            return  # User cancelled the save dialog

        # Determine the format based on file extension
        _, file_extension = os.path.splitext(save_path)
        file_extension = file_extension.lower().lstrip('.')
        original_format = file_extension if file_extension in ['tiff', 'tif', 'png', 'fits', 'fit'] else 'tiff'

        # Call the save_image function with the necessary parameters
        try:
            save_image(
                img_array=self.processed_image,
                filename=save_path,
                original_format=original_format,
                bit_depth=self.bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            QMessageBox.information(self, "Success", f"Image saved successfully at: {save_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

    def load_image_with_retry(self, file_path, retries=5, delay=2):
        """
        Attempts to load an image multiple times with delays between attempts.

        :param file_path: Path to the image file.
        :param retries: Number of retry attempts.
        :param delay: Delay between retries in seconds.
        :return: Tuple of (image_array, original_header, bit_depth, is_mono) or (None, None, None, None) if failed.
        """

        for attempt in range(1, retries + 1):
            image, original_header, bit_depth, is_mono = load_image(file_path)
            if image is not None:

                return image, original_header, bit_depth, is_mono
            else:
                print(f"[WARNING] Attempt {attempt} failed to load image. Retrying in {delay} seconds...")
                time.sleep(delay)
        print("[ERROR] All attempts to load the image failed.")
        return None, None, None, None


    def wait_for_output_file(self, output_file_glob, timeout=3000, check_interval=1, stable_checks=3):
        """
        Wait for the output file with any extension within the specified timeout.
        Ensures the file size remains constant over a series of checks to confirm it's fully written.

        :param output_file_glob: Glob pattern to match the output file.
        :param timeout: Maximum time to wait in seconds.
        :param check_interval: Time between size checks in seconds.
        :param stable_checks: Number of consecutive checks with the same size.
        :return: Path to the output file or None if not found.
        """
        start_time = time.time()
        last_size = -1
        stable_count = 0

        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                current_size = os.path.getsize(matching_files[0])
                if current_size == last_size:
                    stable_count += 1
                    if stable_count >= stable_checks:
                        print(f"Output file found and stable: {matching_files[0]}")
                        return matching_files[0]
                else:
                    stable_count = 0
                    last_size = current_size
            time.sleep(check_interval)
        
        print("Timeout reached. Output file not found or not stable.")
        return None

    def display_image(self, file_path):
        """Load and display the output image."""
        self.image, self.original_header, self.bit_depth, self.is_mono = load_image(file_path)
        self.display_image()  # Update display with the new image

    def cleanup_files(self, input_file_path, output_file_path):
        """Delete input and output files after processing."""
        try:
            if input_file_path and os.path.exists(input_file_path):
                os.remove(input_file_path)
                print(f"Deleted input file: {input_file_path}")
            else:
                print(f"Input file not found, skipping deletion: {input_file_path}")

            if output_file_path and os.path.exists(output_file_path):
                os.remove(output_file_path)
                print(f"Deleted output file: {output_file_path}")
            else:
                print(f"Output file not found, skipping deletion: {output_file_path}")
        except Exception as e:
            print(f"Failed to delete files: {e}")

class PreviewDialog(QDialog):
    def __init__(self, np_image, parent_tab=None, is_mono=False):
        super().__init__(parent=parent_tab)
        self.setWindowTitle("Select Preview Area")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowContextHelpButtonHint | Qt.WindowType.MSWindowsFixedSizeDialogHint)
        self.setFixedSize(640, 480)  # Fix the size to 640x480
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag

        # Store the 32-bit numpy image for reference
        self.np_image = np_image
        self.original_np_image = np_image.copy()  # Copy to allow undo
        self.parent_tab = parent_tab
        # Track saved scroll positions for Undo
        self.saved_h_scroll = 0
        self.saved_v_scroll = 0        

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch button
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        layout.addWidget(self.autostretch_button)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Add the Process Visible Area and Undo buttons
        button_layout = QHBoxLayout()
        
        self.process_button = QPushButton("Process Visible Area")
        self.process_button.clicked.connect(self.process_visible_area)
        button_layout.addWidget(self.process_button)

        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.undo_last_process)
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        button_layout.addWidget(self.undo_button)

        layout.addLayout(button_layout)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set
                
        # Enable What's This functionality
        self.setWhatsThis(
            "Instructions:\n\n"
            "1. Use the scroll bars to center on the area of the image you want to preview.\n"
            "2. Click and drag to move around the image.\n"
            "3. When ready, click the 'Process Visible Area' button to process the selected section."
        )

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at 100% scale."""
        # Ensure the numpy array is scaled to [0, 255] and converted to uint8
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)
        
        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Display the QImage at 100% scale in QLabel
        self.image_label.setPixmap(QPixmap.fromImage(qimage))
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            # Check the dimensions of self.np_image instead of relying on is_mono.
            if self.np_image.ndim < 3:
                # 2D array: grayscale image.
                try:
                    stretched = stretch_mono_image(self.np_image, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)  # Convert to RGB for display.
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 1:
                # 3D array but with one channel.
                try:
                    mono = np.squeeze(self.np_image, axis=-1)
                    stretched = stretch_mono_image(mono, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch single-channel image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 3:
                # Color image.
                try:
                    display_image = stretch_color_image(self.np_image, target_median, linked=False)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return
            else:
                print("[ERROR] Unexpected image shape during autostretch!")
                return
        else:
            display_image = self.np_image  # Use original image if autostretch is off

        # Convert and display the QImage.
        self.display_qimage(display_image)



    def undo_last_process(self):
        """Revert to the original image in the preview, respecting the autostretch setting."""
        print("Undo last process")
        
        # Reset to the original image
        self.np_image = self.original_np_image.copy()
        
        # Apply autostretch if it is enabled
        if self.autostretch_enabled:
            print("Applying autostretch on undo")
            self.apply_autostretch()
        else:
            # Display the original image without autostretch
            self.display_qimage(self.np_image)
        
        # Restore saved scroll positions with a slight delay
        QTimer.singleShot(0, self.restore_scrollbars)
        print("Scrollbars will be restored to saved positions")


    def restore_scrollbars(self):
        """Restore the scrollbars to the saved positions after a delay."""
        self.scroll_area.horizontalScrollBar().setValue(self.saved_h_scroll)
        self.scroll_area.verticalScrollBar().setValue(self.saved_v_scroll)
        print("Scrollbars restored to saved positions")
   
    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        # Set the horizontal and vertical scrollbar positions to center
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def process_visible_area(self):
        print("Process Visible Area button pressed")  # Initial debug print to confirm button press

        """Crop the image to the visible area and send it to CosmicClarityTab for processing."""

        self.saved_h_scroll = self.scroll_area.horizontalScrollBar().value()
        self.saved_v_scroll = self.scroll_area.verticalScrollBar().value()

        # Calculate the visible area in the original image coordinates
        h_scroll = self.scroll_area.horizontalScrollBar().value()
        v_scroll = self.scroll_area.verticalScrollBar().value()
        visible_rect = QRect(h_scroll, v_scroll, 640, 480)  # 640x480 fixed size
        print(f"Visible area rectangle: {visible_rect}")  # Debug print to confirm visible area coordinates

        # Crop the numpy image array directly using slicing
        if len(self.np_image.shape) == 2:  # Mono image (2D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
            ]
            # Convert cropped mono image to RGB for consistent handling
            cropped_np_image = np.stack([cropped_np_image] * 3, axis=-1)
        elif len(self.np_image.shape) == 3:  # Color image (3D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
                :
            ]
        else:
            print("Error: Unsupported image format")
            return

        if cropped_np_image is None:
            print("Error: Failed to crop numpy image")  # Debug if cropping failed
        else:
            print("Image cropped successfully")  # Debug print to confirm cropping

        # Pass the cropped image to CosmicClarityTab for processing
        if self.parent_tab:
            print("Sending to parent class for processing")  # Debug print before sending to parent
            self.parent_tab.run_cosmic_clarity_on_cropped(cropped_np_image, apply_autostretch=self.autostretch_enabled)
        else:
            print("Error: Failed to send to parent class")  # Debug if parent reference is missing


    def convert_qimage_to_numpy(self, qimage):
        """Convert QImage to a 32-bit float numpy array, preserving the 32-bit precision."""
        qimage = qimage.convertToFormat(QImage.Format.Format_RGB888)
        
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 3)
        
        arr = np.frombuffer(ptr, dtype=np.uint8).reshape((height, width, 3)).astype(np.float32) / 255.0
        return arr

    def closeEvent(self, event):
        """Handle dialog close event if any cleanup is necessary."""
        self.dragging = False
        event.accept()

class WaitDialog(QDialog):
    cancelled = pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Processing...")
        
        self.layout = QVBoxLayout()
        
        self.label = QLabel("Processing, please wait...")
        self.layout.addWidget(self.label)
        
        # Add a QTextEdit to show process output
        self.output_text_edit = QTextEdit()
        self.output_text_edit.setReadOnly(True)
        self.layout.addWidget(self.output_text_edit)

        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.layout.addWidget(self.progress_bar)

        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.cancelled.emit)
        self.layout.addWidget(cancel_button)
        
        self.setLayout(self.layout)

    def append_output(self, text):
        self.output_text_edit.append(text)

    def set_progress(self, pct):
        self.progress_bar.setValue(pct)        

class WaitForFileWorker(QThread):
    fileFound = pyqtSignal(str)
    cancelled = pyqtSignal()
    error = pyqtSignal(str)

    def __init__(self, output_file_glob, timeout=1800, parent=None):
        super().__init__(parent)
        self.output_file_glob = output_file_glob
        self.timeout = timeout
        self._running = True

    def run(self):
        start_time = time.time()
        while self._running and (time.time() - start_time < self.timeout):
            matching_files = glob.glob(self.output_file_glob)

            if matching_files:
                self.fileFound.emit(matching_files[0])
                return
            time.sleep(1)
        if self._running:
            self.error.emit("Output file not found within timeout.")
        else:
            self.cancelled.emit()

    def stop(self):
        self._running = False

class CosmicClaritySatelliteTab(QWidget):
    def __init__(self):
        super().__init__()
        self.cosmic_clarity_folder = None
        self.input_folder = None
        self.output_folder = None
        self.settings_file = "cosmic_clarity_satellite_folder.txt"
        self.file_watcher = QFileSystemWatcher()  # Watcher for input and output folders
        self.file_watcher.directoryChanged.connect(self.on_folder_changed)  # Connect signal
        self.sensitivity = 0.1
        self.settings = QSettings() 
        self.initUI()
        self.load_cosmic_clarity_folder()

    def initUI(self):
        # Main horizontal layout
        main_layout = QHBoxLayout()

        # Left layout for controls and settings
        left_layout = QVBoxLayout()

        # Input/Output Folder Selection in a Horizontal Sizer
        folder_layout = QHBoxLayout()
        self.input_folder_button = QPushButton("Select Input Folder")
        self.input_folder_button.clicked.connect(self.select_input_folder)
        self.output_folder_button = QPushButton("Select Output Folder")
        self.output_folder_button.clicked.connect(self.select_output_folder)
        folder_layout.addWidget(self.input_folder_button)
        folder_layout.addWidget(self.output_folder_button)
        left_layout.addLayout(folder_layout)

        # GPU Acceleration
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Removal Mode
        self.mode_label = QLabel("Satellite Removal Mode:")
        left_layout.addWidget(self.mode_label)
        self.mode_dropdown = QComboBox()
        self.mode_dropdown.addItems(["Full", "Luminance"])
        left_layout.addWidget(self.mode_dropdown)

        # Clip Trail
        self.clip_trail_checkbox = QCheckBox("Clip Satellite Trail to 0.000")
        self.clip_trail_checkbox.setChecked(True)
        left_layout.addWidget(self.clip_trail_checkbox)

        # **Add Sensitivity Slider**
        sensitivity_layout = QHBoxLayout()
        sensitivity_label = QLabel("Clipping Sensitivity (Lower Values more Aggressive Clipping):")
        sensitivity_layout.addWidget(sensitivity_label)

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(1)    # Represents 0.01
        self.sensitivity_slider.setMaximum(50)   # Represents 0.5
        self.sensitivity_slider.setValue(int(self.sensitivity * 100))  # e.g., 0.1 * 100 = 10
        self.sensitivity_slider.setTickInterval(1)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_slider.valueChanged.connect(self.update_sensitivity)
        sensitivity_layout.addWidget(self.sensitivity_slider)

        # Label to display current sensitivity value
        self.sensitivity_value_label = QLabel(f"{self.sensitivity:.2f}")
        sensitivity_layout.addWidget(self.sensitivity_value_label)

        left_layout.addLayout(sensitivity_layout)        

        # Skip Save
        self.skip_save_checkbox = QCheckBox("Skip Save if No Satellite Trail Detected")
        self.skip_save_checkbox.setChecked(False)
        left_layout.addWidget(self.skip_save_checkbox)

        # Process Single Image and Batch Process in a Horizontal Sizer
        process_layout = QHBoxLayout()
        self.process_single_button = QPushButton("Process Single Image")
        self.process_single_button.clicked.connect(self.process_single_image)
        process_layout.addWidget(self.process_single_button)

        self.batch_process_button = QPushButton("Batch Process Input Folder")
        self.batch_process_button.clicked.connect(self.batch_process_folder)
        process_layout.addWidget(self.batch_process_button)
        left_layout.addLayout(process_layout)

        # Live Monitor
        self.live_monitor_button = QPushButton("Live Monitor Input Folder")
        self.live_monitor_button.clicked.connect(self.live_monitor_folder)
        left_layout.addWidget(self.live_monitor_button)

        # Folder Selection
        self.folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.folder_label)
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))  # Ensure the icon is available
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        # Right layout for TreeBoxes
        right_layout = QVBoxLayout()

        # Input Files TreeBox
        input_files_label = QLabel("Input Folder Files:")
        right_layout.addWidget(input_files_label)
        self.input_files_tree = QTreeWidget()
        self.input_files_tree.setHeaderLabels(["Filename"])
        self.input_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.input_files_tree))
        self.input_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.input_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.input_files_tree, pos))
        right_layout.addWidget(self.input_files_tree)

        # Output Files TreeBox
        output_files_label = QLabel("Output Folder Files:")
        right_layout.addWidget(output_files_label)
        self.output_files_tree = QTreeWidget()
        self.output_files_tree.setHeaderLabels(["Filename"])
        self.output_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.output_files_tree))
        self.output_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.output_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.output_files_tree, pos))
        right_layout.addWidget(self.output_files_tree)


        # Add the left and right layouts to the main layout
        main_layout.addLayout(left_layout, stretch=2)  # More space for the left layout
        main_layout.addLayout(right_layout, stretch=1)  # Less space for the right layout

        self.setLayout(main_layout)

    def update_sensitivity(self, value):
        """
        Update the sensitivity value based on the slider's position.
        """
        self.sensitivity = value / 100.0  # Convert from integer to float (0.01 to 0.5)
        self.sensitivity_value_label.setText(f"{self.sensitivity:.2f}")  # Update label





    def preview_image(self, treebox):
        """Preview the selected image."""
        selected_item = treebox.currentItem()
        if selected_item:
            file_path = os.path.join(self.input_folder if treebox == self.input_files_tree else self.output_folder, selected_item.text(0))
            if os.path.isfile(file_path):
                try:
                    image, _, _, is_mono = load_image(file_path)
                    if image is not None:
                        self.current_preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)  # Store reference
                        self.current_preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure cleanup on close
                        self.current_preview_dialog.show()  # Open non-blocking dialog
                    else:
                        QMessageBox.critical(self, "Error", "Failed to load image for preview.")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to preview image: {e}")


    def open_preview_dialog(self, image, is_mono):
        """Open the preview dialog."""
        preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)
        preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure proper cleanup when closed
        preview_dialog.show()  # Open the dialog without blocking the main UI





    def show_context_menu(self, treebox, pos):
        """Show context menu for the treebox."""
        menu = QMenu()
        delete_action = QAction("Delete File")
        rename_action = QAction("Rename File")
        delete_action.triggered.connect(lambda: self.delete_file(treebox))
        rename_action.triggered.connect(lambda: self.rename_file(treebox))
        menu.addAction(delete_action)
        menu.addAction(rename_action)
        menu.exec(treebox.viewport().mapToGlobal(pos))

    def delete_file(self, treebox):
        """Delete the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            if os.path.exists(file_path):
                reply = QMessageBox.question(self, "Confirm Delete", f"Are you sure you want to delete {selected_item.text(0)}?",
                                             QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, QMessageBox.StandardButton.No)
                if reply == QMessageBox.StandardButton.Yes:
                    os.remove(file_path)
                    self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def rename_file(self, treebox):
        """Rename the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            new_name, ok = QInputDialog.getText(self, "Rename File", "Enter new name:", text=selected_item.text(0))
            if ok and new_name:
                new_path = os.path.join(folder, new_name)
                os.rename(file_path, new_path)
                self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def refresh_input_files(self):
        """Populate the input TreeBox with files from the input folder."""
        self.input_files_tree.clear()
        if not self.input_folder:
            return
        for file_name in os.listdir(self.input_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.input_files_tree, [file_name])

    def refresh_output_files(self):
        """Populate the output TreeBox with files from the output folder."""
        self.output_files_tree.clear()
        if not self.output_folder:
            return
        for file_name in os.listdir(self.output_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.output_files_tree, [file_name])



    def select_input_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Input Folder")
        if folder:
            self.input_folder = folder
            self.input_folder_button.setText(f"Input Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_input_files()

    def select_output_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Output Folder")
        if folder:
            self.output_folder = folder
            self.output_folder_button.setText(f"Output Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_output_files()

    def on_folder_changed(self, path):
        """Refresh the TreeBox when files are added or removed from the watched folder."""
        if path == self.input_folder:
            self.refresh_input_files()
        elif path == self.output_folder:
            self.refresh_output_files()


    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
            self.folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    def load_cosmic_clarity_folder(self):
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.folder_label.setText(f"Folder: {folder}")
            print(f"Loaded Cosmic Clarity folder: {folder}")
        else:
            print("No saved Cosmic Clarity folder found.")

    def process_single_image(self):
        # Step 1: Open File Dialog to Select Image
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if not file_path:
            QMessageBox.warning(self, "Warning", "No file selected.")
            return

        # Create temp input and output folders
        temp_input = self.create_temp_folder()
        temp_output = self.create_temp_folder()

        # Copy the selected file to the temp input folder
        shutil.copy(file_path, temp_input)

        # Run Cosmic Clarity Satellite Removal Tool
        try:
            self.run_cosmic_clarity_satellite(temp_input, temp_output)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Error processing image: {e}")
            return

        # Locate the processed file in the temp output folder
        processed_file = glob.glob(os.path.join(temp_output, "*_satellited.*"))
        if processed_file:
            # Move the processed file back to the original folder
            original_folder = os.path.dirname(file_path)
            destination_path = os.path.join(original_folder, os.path.basename(processed_file[0]))
            shutil.move(processed_file[0], destination_path)

            # Inform the user
            QMessageBox.information(self, "Success", f"Processed image saved to: {destination_path}")
        else:
            QMessageBox.warning(self, "Warning", "No output file found.")

        # Cleanup temporary folders
        if os.path.exists(temp_input):
            shutil.rmtree(temp_input)
        if os.path.exists(temp_output):
            shutil.rmtree(temp_output)

    def batch_process_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--batch"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Batch processing finished."))
        self.satellite_thread.start()

    def live_monitor_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--monitor"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.sensitivity_slider.setEnabled(False)
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Live monitoring stopped."))
        self.satellite_thread.finished.connect(lambda:self.sensitivity_slider.setEnabled(True))
        self.satellite_thread.start()

        # **Disable the sensitivity slider**
        


    def on_live_monitor_finished(self):
        """
        Slot to handle actions after live monitoring has finished.
        """
        QMessageBox.information(self, "Live Monitoring", "Live monitoring has been stopped.")
        self.sensitivity_slider.setEnabled(True)

        self.live_monitor_button.setEnabled(True)
        self.stop_monitor_button.setEnabled(False)
        
    @staticmethod
    def create_temp_folder(base_folder="~"):
        """
        Create a temporary folder for processing in the user's directory.
        :param base_folder: Base folder to create the temp directory in (default is the user's home directory).
        :return: Path to the created temporary folder.
        """
        user_dir = os.path.expanduser(base_folder)
        temp_folder = os.path.join(user_dir, "CosmicClarityTemp")
        os.makedirs(temp_folder, exist_ok=True)  # Create the folder if it doesn't exist
        return temp_folder


    def run_cosmic_clarity_satellite(self, input_dir, output_dir, live_monitor=False):
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        # Check if the executable exists
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct command arguments
        command = [
            exe_path,
            "--input", input_dir,
            "--output", output_dir,
            "--mode", self.mode_dropdown.currentText().lower(),
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")
        if live_monitor:
            command.append("--monitor")
        else:
            command.append("--batch")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])

        # Debugging: Print the command to verify
        print(f"Running command: {' '.join(command)}")

        # Execute the command
        try:
            subprocess.run(command, check=True)
            QMessageBox.information(self, "Success", "Processing complete.")
        except subprocess.CalledProcessError as e:
            QMessageBox.critical(self, "Error", f"Processing failed: {e}")

    def execute_script(self, script_path):
        """Execute the batch or shell script."""
        if os.name == 'nt':  # Windows
            subprocess.Popen(["cmd.exe", "/c", script_path], shell=True)
        else:  # macOS/Linux
            subprocess.Popen(["/bin/sh", script_path], shell=True)

    def wait_for_output_files(self, output_file_glob, timeout=1800):
        """Wait for output files matching the glob pattern within a timeout."""
        start_time = time.time()
        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                time.sleep(2)
                return matching_files
            time.sleep(1)
        return None

class ImagePreviewDialog(QDialog):
    def __init__(self, np_image, is_mono=False):
        super().__init__()
        self.setWindowTitle("Image Preview")
        self.resize(640, 480)  # Set initial size
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag
        self.zoom_factor = 1.0  # Track the zoom level

        # Store the 32-bit numpy image for reference
        self.np_image = np_image

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch and Zoom Buttons
        button_layout = QHBoxLayout()
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        button_layout.addWidget(self.autostretch_button)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        layout.addLayout(button_layout)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Enable mouse wheel for zooming
        self.image_label.installEventFilter(self)

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at the current zoom level."""
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)

        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Apply zoom
        pixmap = QPixmap.fromImage(qimage)
        scaled_width = int(pixmap.width() * self.zoom_factor)  # Convert to integer
        scaled_height = int(pixmap.height() * self.zoom_factor)  # Convert to integer
        scaled_pixmap = pixmap.scaled(scaled_width, scaled_height, Qt.AspectRatioMode.KeepAspectRatio)
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        print("applying autostretch")
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            if self.np_image.ndim == 2:
                # mono stretch path
                stretched = stretch_mono_image(self.np_image, target_median)
                display_image = np.stack([stretched]*3, axis=-1)
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 3:
                # color stretch path
                display_image = stretch_color_image(self.np_image, target_median, linked=False)
            else:
                raise ValueError(f"Unexpected image shape for autostretch: {self.np_image.shape}")
        else:
            # autostretch off: just show original
            if self.np_image.ndim == 2:
                display_image = np.stack([self.np_image]*3, axis=-1)
            else:
                display_image = self.np_image


        print(f"Debug: Display image shape before QImage conversion: {display_image.shape}")
        self.display_qimage(display_image)



    @announce_zoom
    def zoom_in(self):
        """Increase the zoom factor and refresh the display."""
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.display_qimage(self.np_image)

    @announce_zoom
    def zoom_out(self):
        """Decrease the zoom factor and refresh the display."""
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.display_qimage(self.np_image)

    def eventFilter(self, source, event):
        """Handle mouse wheel events for zooming."""
        if source == self.image_label and event.type() == QEvent.Type.Wheel:
            if event.angleDelta().y() > 0:
                self.zoom_in()
            else:
                self.zoom_out()
            return True
        return super().eventFilter(source, event)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def resizeEvent(self, event):
        """Handle resizing of the dialog."""
        super().resizeEvent(event)
        self.display_qimage(self.np_image)

class SatelliteProcessingThread(QThread):
    log_signal = pyqtSignal(str)
    finished_signal = pyqtSignal()

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        try:
            self.log_signal.emit(f"Running command: {' '.join(self.command)}")
            subprocess.run(self.command, check=True)
            self.log_signal.emit("Processing complete.")
        except subprocess.CalledProcessError as e:
            self.log_signal.emit(f"Processing failed: {e}")
        except Exception as e:
            self.log_signal.emit(f"Unexpected error: {e}")
        finally:
            self.finished_signal.emit()  # Emit the finished signal            

class StatisticalStretchTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.zoom_factor = 1.0
        self.image = None  # Current image (from ImageManager)
        self.stretched_image = None  # Processed image
        self.current_pixmap = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)


    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # You can adjust this width as needed

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select an image to stretch.
            2. Adjust the target median and optional settings.
            3. Preview the result.
            4. Save the stretched image in your desired format.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton('Select Image', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Target median slider
        self.medianLabel = QLabel('Target Median: 0.25', self)
        self.medianSlider = QSlider(Qt.Orientation.Horizontal)
        self.medianSlider.setMinimum(1)
        self.medianSlider.setMaximum(100)
        self.medianSlider.setValue(25)
        self.medianSlider.valueChanged.connect(self.updateMedianLabel)
        left_layout.addWidget(self.medianLabel)
        left_layout.addWidget(self.medianSlider)

        # Linked/Unlinked stretch checkbox
        self.linkedCheckBox = QCheckBox('Linked Stretch', self)
        self.linkedCheckBox.setChecked(True)
        left_layout.addWidget(self.linkedCheckBox)

        # Normalization checkbox
        self.normalizeCheckBox = QCheckBox('Normalize Image', self)
        left_layout.addWidget(self.normalizeCheckBox)

        # Curves adjustment checkbox
        self.curvesCheckBox = QCheckBox('Apply Curves Adjustment', self)
        self.curvesCheckBox.setCheckState(Qt.CheckState.Unchecked)  # Explicitly set the initial state

        left_layout.addWidget(self.curvesCheckBox)

        # Curves Boost slider (initially hidden)
        self.curvesBoostLabel = QLabel('Curves Boost: 0.00', self)
        self.curvesBoostSlider = QSlider(Qt.Orientation.Horizontal)
        self.curvesBoostSlider.setMinimum(0)
        self.curvesBoostSlider.setMaximum(50)
        self.curvesBoostSlider.setValue(0)
        self.curvesBoostSlider.valueChanged.connect(self.updateCurvesBoostLabel)
        self.curvesBoostLabel.show()
        self.curvesBoostSlider.show()

        left_layout.addWidget(self.curvesBoostLabel)
        left_layout.addWidget(self.curvesBoostSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)      

        # Buttons (Undo and Preview Stretch)
        button_layout = QHBoxLayout()

        self.previewButton = QPushButton('Apply Stretch', self)
        self.previewButton.clicked.connect(self.previewStretch)
        button_layout.addWidget(self.previewButton)

        self.undoButton = QPushButton('Undo', self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undo_image)
        button_layout.addWidget(self.undoButton)

        self.mouseStatusLabel = QLabel('', self)
        left_layout.addWidget(self.mouseStatusLabel)

        left_layout.addLayout(button_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Commented out to move to the right panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton('Zoom In', self)
        # self.zoomInButton.clicked.connect(self.zoom_in)
        # zoom_layout.addWidget(self.zoomInButton)

        # self.zoomOutButton = QPushButton('Zoom Out', self)
        # self.zoomOutButton.clicked.connect(self.zoom_out)
        # zoom_layout.addWidget(self.zoomOutButton)

        # left_layout.addLayout(zoom_layout)



        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 0.25
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.imageLabel.setMouseTracking(True)
        self.imageLabel.installEventFilter(self)

        self.dragging = False
        self.last_pos = QPoint()

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.fileLabel)

            # Update the image display
            self.updateImageDisplay()

            print(f"Statistical Stretch: Image updated from ImageManager slot {slot}.")

    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.preview_image, metadata=metadata, step_name="Statistical Stretch")
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseMove:
            if source in (self.scrollArea.viewport(), self.imageLabel):
                pos = self.imageLabel.mapFrom(source, event.pos())

                if self.imageLabel.pixmap() is not None:
                    pixmap_size = self.imageLabel.pixmap().size()

                    if 0 <= pos.x() < pixmap_size.width() and 0 <= pos.y() < pixmap_size.height():
                        # Convert scaled coordinates back to original image coordinates
                        img_x = int(pos.x() / self.zoom_factor)
                        img_y = int(pos.y() / self.zoom_factor)

                        # Ensure pixel lookup stays within valid range
                        if self.image is not None:
                            h, w = self.image.shape[:2]
                            if 0 <= img_x < w and 0 <= img_y < h:
                                pixel_value = self.image[img_y, img_x]

                                # Display pixel values only when NOT dragging
                                if not self.dragging:
                                    if self.image.ndim == 3:
                                        r, g, b = pixel_value
                                        self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} R:{r:.3f} G:{g:.3f} B:{b:.3f}")
                                    else:
                                        self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} Val:{pixel_value:.3f}")

        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
            return True  # Prevent conflicting events

        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
            return True  # Prevent conflicting events

        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()
            return True  # Prevent conflicting events

        return super().eventFilter(source, event)





    def openFileDialog(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        self.filename, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if self.filename:
            self.fileLabel.setText(self.filename)

            # Load the image using ImageManager
            image, original_header, bit_depth, is_mono = load_image(self.filename)

            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            # Update ImageManager with the new image
            metadata = {
                'file_path': self.filename,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

            print("Image added to ImageManager.")

    def undo_image(self):
        """Undo the last action."""
        if self.image_manager.can_undo():
            self.image_manager.undo()  # Reverts to the previous image
            self.updateImageDisplay()  # Update the display with the reverted image
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def updateMedianLabel(self, value):
        self.medianLabel.setText(f'Target Median: {value / 100:.2f}')

    def updateCurvesBoostLabel(self, value):
        self.curvesBoostLabel.setText(f'Curves Boost: {value / 100:.2f}')

    def previewStretch(self):
        if self.image is not None:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = StatisticalStretchProcessingThread(self.image,
                                                                        self.medianSlider.value(),
                                                                        self.linkedCheckBox.isChecked(),
                                                                        self.normalizeCheckBox.isChecked(),
                                                                        self.curvesCheckBox.isChecked(),
                                                                        self.curvesBoostSlider.value() / 100.0)
            self.processing_thread.preview_generated.connect(self.update_preview)
            self.processing_thread.start()


    def update_preview(self, stretched_image):
        # Save the stretched image for later use in zoom functions
        self.stretched_image = stretched_image

        # Update the preview once the processing thread emits the result
        img = (stretched_image * 255).astype(np.uint8)
        h, w = img.shape[:2]

        if img.ndim == 3:
            bytes_per_line = 3 * w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            bytes_per_line = w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)

        # Create QPixmap from QImage
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

        # Prepare metadata with safeguards
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'target_median': self.medianSlider.value() / 100.0,
                'linked_stretch': self.linkedCheckBox.isChecked(),
                'normalize_image': self.normalizeCheckBox.isChecked(),
                'curves_adjustment': self.curvesCheckBox.isChecked(),
                'curves_boost': self.curvesBoostSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.stretched_image, metadata=metadata, step_name="Statistical Stretch")
                print("StatisticalStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")


    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()    

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    @announce_zoom
    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")

    def saveImage(self):
        if hasattr(self, 'stretched_image') and self.stretched_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.stretched_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.stretched_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')

# Thread for Stat Stretch background processing
class StatisticalStretchProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)  # Signal to send the generated preview image back to the main thread

    def __init__(self, image, target_median, linked, normalize, apply_curves, curves_boost):
        super().__init__()
        self.image = image
        self.target_median = target_median / 100.0  # Ensure proper scaling
        self.linked = linked
        self.normalize = normalize
        self.apply_curves = apply_curves
        self.curves_boost = curves_boost

    def run(self):
        # Perform the image stretching in the background
        if self.image.ndim == 2:  # Mono image
            stretched_image = stretch_mono_image(self.image, self.target_median, self.normalize, self.apply_curves, self.curves_boost)
        else:  # Color image
            stretched_image = stretch_color_image(self.image, self.target_median, self.linked, self.normalize, self.apply_curves, self.curves_boost)

        # Emit the result once done
        self.preview_generated.emit(stretched_image)

# Thread for star stretch background processing
class ProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, stretch_factor, sat_amount, scnr_enabled):
        super().__init__()
        self.image = image
        self.stretch_factor = stretch_factor
        self.sat_amount = sat_amount
        self.scnr_enabled = scnr_enabled

    def run(self):
        # Apply fast pixel math
        stretched_image = applyPixelMath_numba(self.image, self.stretch_factor)

        # Apply saturation adjustment
        stretched_image = adjust_saturation_numba(stretched_image, self.sat_amount)

        # Apply SCNR if enabled
        if self.scnr_enabled:
            stretched_image = applySCNR_numba(stretched_image)

        # Emit the processed image
        self.preview_generated.emit(stretched_image)

class StarStretchTab(QWidget):
    def __init__(self, image_manager):
        super().__init__()
        self.image_manager = image_manager  # Store the ImageManager instance
        self.initUI()
        
        # Connect to ImageManager's image_changed signal
        self.image_manager.image_changed.connect(self.on_image_changed)
        self.image = None  # Store the selected image
        self.stretch_factor = 5.0
        self.sat_amount = 1.0
        self.is_mono = True
        self.remove_green = False
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.last_pos = None
        self.processing_thread = None  # Thread for background processing
        self.original_header = None
        self.current_pixmap = None  # **New Attribute**

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fix the left column width

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the stretch and optional settings.
            3. Preview the result.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Select Stars Only Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Stretch Amount slider with more precision
        self.stretchLabel = QLabel("Stretch Amount: 5.00", self)
        self.stretchSlider = QSlider(Qt.Orientation.Horizontal)
        self.stretchSlider.setMinimum(0)
        self.stretchSlider.setMaximum(800)  # Allow two decimal places of precision
        self.stretchSlider.setValue(500)  # 500 corresponds to 5.00
        self.stretchSlider.valueChanged.connect(self.updateStretchLabel)
        left_layout.addWidget(self.stretchLabel)
        left_layout.addWidget(self.stretchSlider)

        # Color Boost Amount slider
        self.satLabel = QLabel("Color Boost: 1.00", self)
        self.satSlider = QSlider(Qt.Orientation.Horizontal)
        self.satSlider.setMinimum(0)
        self.satSlider.setMaximum(200)
        self.satSlider.setValue(100)  # 100 corresponds to 1.0 boost
        self.satSlider.valueChanged.connect(self.updateSatLabel)
        left_layout.addWidget(self.satLabel)
        left_layout.addWidget(self.satSlider)

        # SCNR checkbox
        self.scnrCheckBox = QCheckBox("Remove Green via SCNR (Optional)", self)
        left_layout.addWidget(self.scnrCheckBox)

        # **Create a horizontal layout for Refresh Preview, Undo, and Redo buttons**
        action_buttons_layout = QHBoxLayout()

        # Refresh Preview button
        self.refreshButton = QPushButton("Refresh Preview", self)
        self.refreshButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.refreshButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Redo button with right arrow icon
        self.redoButton = QPushButton("Redo", self)
        redo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowForward)  # Standard right arrow icon
        self.redoButton.setIcon(redo_icon)
        self.redoButton.clicked.connect(self.redoAction)
        self.redoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.redoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)


        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def saveImage(self):
        # Use the processed/stretched image for saving
        if self.preview_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "stretched_image"
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else os.getcwd()

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(
                            self.preview_image, 
                            save_filename, 
                            original_format, 
                            bit_depth, 
                            self.original_header, 
                            self.is_mono
                        )
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(
                        self.preview_image, 
                        save_filename, 
                        original_format
                    )
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')


    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("StarStretchTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("StarStretchTab: No actions to undo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def redoAction(self):
        if self.image_manager and self.image_manager.can_redo():
            try:
                # Perform the redo operation
                self.image_manager.redo()
                print("StarStretchTab: Redo performed.")
            except Exception as e:
                print(f"Error performing redo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform redo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to redo.")
            print("StarStretchTab: No actions to redo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return  
        if image is None:
            return              
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"StarStretchTab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())
                self.redoButton.setEnabled(self.image_manager.can_redo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')


    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(self, "Select Stars Only Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if selected_file:
            try:
                # Load image with header
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)
                self.filename = selected_file  # Store the selected file path
                self.fileLabel.setText(os.path.basename(selected_file))

                # Push the loaded image to ImageManager so it can be tracked for undo/redo
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': 'Unknown',  # You can update this if needed
                    'is_mono': self.is_mono
                }
                self.image_manager.set_image( self.image, metadata, step_name="StarStretch" )
                print(f"Image {self.filename} pushed to ImageManager.")

                # Update the display with the loaded image (before applying any stretch)
                self.updateImageDisplay()

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"Failed to load image: {e}")

    def updateStretchLabel(self, value):
        self.stretch_factor = value / 100.0  # Precision of two decimals
        self.stretchLabel.setText(f"Stretch Amount: {self.stretch_factor:.2f}")

    def updateSatLabel(self, value):
        self.sat_amount = value / 100.0
        self.satLabel.setText(f"Color Boost: {self.sat_amount:.2f}")

    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = ProcessingThread(self.image, self.stretch_factor, self.sat_amount, self.scnrCheckBox.isChecked())
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'stretch_factor': self.stretch_factor,
                'color_boost': self.sat_amount,
                'remove_green': self.scnrCheckBox.isChecked()
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.preview_image, metadata=metadata, step_name="StarStretch")
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()


    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)
    

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    @announce_zoom
    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")


    def applyStretch(self):
        if self.image is not None and self.image.size > 0:
            print(f"Applying stretch: {self.stretch_factor}, Color Boost: {self.sat_amount:.2f}, SCNR: {self.scnrCheckBox.isChecked()}")
            self.generatePreview()



class FullCurvesTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.initUI()
        self.image = None
        self.image_manager = image_manager
        self.filename = None
        self.original_image = None  # Reference to the original image
        self.preview_image = None   # Reference to the preview image        
        self.zoom_factor = 1.0
        self.original_header = None
        self.bit_depth = None
        self.is_mono = None
        self.curve_mode = "K (Brightness)"  # Default curve mode
        self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)  # Initialize with identity LUT
        self.ghs_sym_pt = None

        # Initialize the Undo stack with a limited size
        self.undo_stack = []
        self.max_undo = 10  # Maximum number of undo steps        

        # Precompute transformation matrices
        self.M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        self.M_inv = np.array([
            [ 3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [ 0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)   

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)             

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        # File label
        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # ——— stretch‐type toggle ———
        self.stretchTypeGroup = QButtonGroup(self)
        h = QHBoxLayout()
        for text in ("Traditional Curves", "Generalized Hyperbolic"):
            btn = QRadioButton(text, self)
            h.addWidget(btn)
            self.stretchTypeGroup.addButton(btn)
        self.stretchTypeGroup.buttons()[0].setChecked(True)
        self.stretchTypeGroup.buttonToggled.connect(self.onStretchTypeChanged)
        left_layout.addLayout(h)

        # Curve Mode Selection
        self.curveModeLabel = QLabel('Select Curve Mode:', self)
        left_layout.addWidget(self.curveModeLabel)

        self.curveModeGroup = QButtonGroup(self)
        curve_modes = [
            ('K (Brightness)', 0, 0),
            ('R', 1, 0),
            ('G', 2, 0),
            ('B', 3, 0),
            ('L*', 0, 1),
            ('a*', 1, 1),
            ('b*', 2, 1),
            ('Chroma', 0, 2),
            ('Saturation', 1, 2)
        ]
        curve_mode_layout = QGridLayout()
        for mode, row, col in curve_modes:
            button = QRadioButton(mode, self)
            if mode == "K (Brightness)":
                button.setChecked(True)
            button.toggled.connect(self.set_curve_mode)
            self.curveModeGroup.addButton(button)
            curve_mode_layout.addWidget(button, row, col)
        left_layout.addLayout(curve_mode_layout)
        self.set_curve_mode()

        # Curve editor
        self.curveEditor = CurveEditor(self)
        self.curveEditor.setSymmetryCallback(self.onCurveSymmetryPoint)
        left_layout.addWidget(self.curveEditor)
        self.curveEditor.setPreviewCallback(lambda lut: self.updatePreviewLUT(lut, self.curve_mode))

        # Status
        self.statusLabel = QLabel('X:0 Y:0', self)
        left_layout.addWidget(self.statusLabel)

        # ——— GHS controls ———
        self.ghsControls = QWidget(self)
        vbox = QVBoxLayout(self.ghsControls)
        # α/β sliders
        slider_row = QHBoxLayout()
        self.alphaSlider = QSlider(Qt.Orientation.Horizontal)
        self.alphaSlider.setRange(1, 300); self.alphaSlider.setValue(50)
        self.alphaLabel = QLabel("1.00")
        slider_row.addWidget(QLabel("α")); slider_row.addWidget(self.alphaSlider); slider_row.addWidget(self.alphaLabel)
        self.betaSlider = QSlider(Qt.Orientation.Horizontal)
        self.betaSlider.setRange(1, 300); self.betaSlider.setValue(50)
        self.betaLabel = QLabel("1.00")
        slider_row.addWidget(QLabel("β")); slider_row.addWidget(self.betaSlider); slider_row.addWidget(self.betaLabel)
        vbox.addLayout(slider_row)
        self.alphaSlider.valueChanged.connect(self.updateGhsCurve)
        self.betaSlider.valueChanged.connect(self.updateGhsCurve)
        # γ slider
        gamma_row = QHBoxLayout()
        gamma_row.addStretch()
        self.gammaSlider = QSlider(Qt.Orientation.Horizontal)
        self.gammaSlider.setRange(0, 500); self.gammaSlider.setValue(100)
        self.gammaLabel = QLabel("1.00")
        gamma_row.addWidget(QLabel("γ")); gamma_row.addWidget(self.gammaSlider); gamma_row.addWidget(self.gammaLabel)
        gamma_row.addStretch()
        vbox.addLayout(gamma_row)
        self.gammaSlider.valueChanged.connect(self.updateGhsCurve)
        # histogram & reset
        btn_row = QHBoxLayout()
        btn_row.addStretch()
        histBtn = QPushButton("Show Histogram")
        histBtn.clicked.connect(self.openHistogram)
        btn_row.addWidget(histBtn)
        resetInfBtn = QPushButton("Reset Inflection")
        resetInfBtn.clicked.connect(self.clearGhsPivot)
        btn_row.addWidget(resetInfBtn)
        btn_row.addStretch()
        vbox.addLayout(btn_row)

        left_layout.addWidget(self.ghsControls)
        self.ghsControls.hide()

        # ——— GHS instructions ———
        self.ghsInstructions = QLabel(self)
        self.ghsInstructions.setWordWrap(True)
        self.ghsInstructions.setStyleSheet("color: gray; font-style: italic;")
        self.ghsInstructions.setText(
            "α controls the main S-curve shape.\n"
            "β controls the slope at the inflection point.\n"
            "γ adjusts overall brightness.\n"
            "Ctrl-click image, curve grid or histogram to set inflection."
        )
        self.ghsInstructions.hide()
        left_layout.addWidget(self.ghsInstructions)

        # Traditional-mode Instructions
        self.tradInstructions = QLabel(self)
        self.tradInstructions.setWordWrap(True)
        self.tradInstructions.setStyleSheet("color: gray; font-style: italic;")
        self.tradInstructions.setText(
            "Double-click to add a curve point.\n"
            "Right-click to delete a curve point.\n"
            "Shift-click on image to add a point at that brightness."
        )
        self.tradInstructions.show()
        left_layout.addWidget(self.tradInstructions)

        # ——— Apply/Undo/Reset ———
        button_layout = QHBoxLayout()
        self.applyButton = QPushButton('Apply Curve', self)
        self.applyButton.clicked.connect(self.startProcessing)
        button_layout.addWidget(self.applyButton)
        self.undoButton = QPushButton('Undo', self)
        self.undoButton.clicked.connect(self.undo)
        self.undoButton.setEnabled(False)
        button_layout.addWidget(self.undoButton)
        self.resetCurveButton = QToolButton(self)
        self.resetCurveButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_BrowserReload))
        self.resetCurveButton.clicked.connect(self.resetCurve)
        button_layout.addWidget(self.resetCurveButton)
        left_layout.addLayout(button_layout)

        # ——— Save/Load ———
        saveloadbutton_layout = QHBoxLayout()
        self.saveCurveBtn = QPushButton("Save Curve", self)
        self.saveCurveBtn.clicked.connect(self.saveCurve)
        saveloadbutton_layout.addWidget(self.saveCurveBtn)
        self.loadCurveBtn = QPushButton("Load Curve", self)
        self.loadCurveBtn.clicked.connect(self.loadCurve)
        saveloadbutton_layout.addWidget(self.loadCurveBtn)
        left_layout.addLayout(saveloadbutton_layout)

        # spinner & spacer & footer
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.hide()
        left_layout.addWidget(self.spinnerLabel)
        left_layout.addSpacerItem(QSpacerItem(20,40,QSizePolicy.Policy.Minimum,QSizePolicy.Policy.Expanding))
        footer_label = QLabel(
            "Written by Franklin Marek<br>"
            "<a href='http://www.setiastro.com'>www.setiastro.com</a>"
        )
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size:10px;")
        left_layout.addWidget(footer_label)

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = ImageLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)
        self.scrollArea.setWidgetResizable(True)
        self.imageLabel.mouseMoved.connect(self.handleImageMouseMove)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 1.0
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.dragging = False
        self.last_pos = QPoint()

    # -----------------------------
    # Spinner Control Methods
    # -----------------------------
    def showSpinner(self):
        """Show the spinner animation."""
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        """Hide the spinner animation."""
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def onStretchTypeChanged(self, btn, checked):
        if not checked:
            return

        is_ghs = (btn.text() == "Generalized Hyperbolic")

        # Show / hide the curve-mode UI vs GHS UI
        self.curveModeLabel.setVisible(not is_ghs)
        for b in self.curveModeGroup.buttons():
            b.setVisible(not is_ghs)
        self.curveEditor.setInteractive(not is_ghs)

        self.ghsControls.setVisible(is_ghs)
        self.ghsInstructions.setVisible(is_ghs)

        self.tradInstructions.setVisible(not is_ghs)

        # Reinitialize handles
        if is_ghs:
            pts = self.generate_ghs_control_points(1.0, 1.0, n=20)
            self.curveEditor.setControlHandles(pts)
        else:
            self.curveEditor.initCurve()

    def openHistogram(self):
        # 1) If we already have one open, just raise it
        if hasattr(self, '_hist_dialog') and self._hist_dialog is not None and self._hist_dialog.isVisible():
            self._hist_dialog.raise_()
            self._hist_dialog.activateWindow()
            return

        # 2) Pull the current image out of ImageManager’s internal store
        slot = self.image_manager.current_slot
        img  = self.image_manager._images.get(slot, None)
        if img is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # 3) If it’s mono, make it 3-channel so the histogram dialog can handle it uniformly
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)

        # 4) Create & keep a reference so it doesn’t get GC’d
        self._hist_dialog = HistogramDialog(self.image_manager, parent=self)

        # 5) Install our event filter to catch Ctrl-clicks there
        self._hist_dialog.hist_label.installEventFilter(self)

        # 6) Connect to image_changed so it stays in sync
        def _update_hist(slot_changed, new_img, metadata):
            if slot_changed != self.image_manager.current_slot or new_img is None:
                return
            if new_img.ndim == 2:
                new_img = np.stack([new_img]*3, axis=-1)
            self._hist_dialog.updateHistogram(new_img)

        self.image_manager.image_changed.connect(_update_hist)

        # 7) Seed it with the current image and show non-modally
        self._hist_dialog.updateHistogram(img)
        self._hist_dialog.show()

        # 8) When it closes, drop our reference so we can make a fresh one next time
        self._hist_dialog.finished.connect(lambda _: setattr(self, '_hist_dialog', None))

    def _onHistClosed(self, result):
        # drop our reference so it can be GC’d next time
        self._hist_dialog = None

    def generate_ghs_control_points(self, alpha, beta, n=10):
        # X in [0…1], compute y = X**alpha / (X**alpha + beta*(1-X)**alpha)
        xs = np.linspace(0,1,n)
        ys = xs**alpha / (xs**alpha + beta*(1-xs)**alpha)
        # map to your 0–360 scene: x*360, (1−y)*360
        return [(x*360, (1-y)*360) for x,y in zip(xs, ys)]

    def updateGhsCurve(self):
        # read sliders
        α = self.alphaSlider.value() / 50.0
        β = self.betaSlider.value() / 50.0
        G = max(0.01, self.gammaSlider.value() / 100.0)
        self.gammaLabel.setText(f"{G:.2f}")
        self.alphaLabel.setText(f"{α:.2f}")
        self.betaLabel .setText(f"{β:.2f}")

        cps = self.curveEditor.control_points
        N   = len(cps)
        if N < 2:
            return

        # pivot in [0..1]
        p = 0.5 if self.ghs_sym_pt is None else float(self.ghs_sym_pt)

        # uniform samples
        us = np.linspace(0.0, 1.0, N)

        # raw S‐curve over full [0,1]
        raw_vs = us**α / (us**α + β*(1.0 - us)**α)
        raw_vs_right = us**α / (us**α + (1/β)*(1.0 - us)**α)

        # mid‐height at u=0.5
        mid_raw = (0.5**α) / (0.5**α + β*(1.0 - 0.5)**α)
        mid_raw_right = (0.5**α) / (0.5**α + (1/β)*(1.0 - 0.5)**α)

        # remap so (0.5,mid_raw) → (p,p)
        up = np.empty_like(us)
        vp = np.empty_like(us)
        left  = us <= 0.5
        right = ~left

        up[left]  =   2*p*us[left]
        vp[left]  =  raw_vs[left] * (p / mid_raw)

        up[right] =   p + 2*(1-p)*(us[right] - 0.5)
        vp[right] =  p + (raw_vs_right[right] - mid_raw_right) * ((1-p)/(1-mid_raw_right))

        # apply gamma lift across *all* points
        vp = vp ** (1.0 / G)

        # map into scene coords and slide handles
        pts = [(u * 360.0, (1.0 - v) * 360.0) for u, v in zip(up, vp)]
        for handle, (x, y) in zip(cps, pts):
            handle.setPos(x, y)

        # redraw
        self.curveEditor.updateCurve()




    def onCurveSymmetryPoint(self, u, v):
        # u is the brightness fraction, v == u on the true inflection point
        self.ghs_sym_pt = u
        # update your status label however you like:
        self.statusLabel.setText(f"Inflection @ K={u:.3f}")
        # regenerate the GHS curve around this pivot:
        self.updateGhsCurve()

    def clearGhsPivot(self):
        """Forget any custom inflection point and recenter to p=0.5."""
        # clear our stored pivot
        self.ghs_sym_pt = None
        # remove the yellow line
        self.curveEditor.clearSymmetryLine()
        # redraw the GHS handles around the default pivot=0.5
        # regenerate with pivot=0.5
        self.updateGhsCurve()
        self.statusLabel.setText("Symmetry reset to center (p=0.5)")

    def saveCurve(self):
        fname, _ = QFileDialog.getSaveFileName(self, "Save Curve As","", "SASC Curve (*.sasc)")
        if not fname:
            return
        if not fname.lower().endswith(".sasc"):
            fname += ".sasc"

        handles = self.curveEditor.getControlHandles()
        try:
            with open(fname, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(["x","y"])
                for x,y in handles:
                    writer.writerow([f"{x:.6f}", f"{y:.6f}"])
            QMessageBox.information(self, "Curve Saved", f"Saved {len(handles)} handles to {fname}")
        except Exception as e:
            QMessageBox.critical(self, "Error Saving Curve", str(e))

    def loadCurve(self):
        fname, _ = QFileDialog.getOpenFileName(self, "Load Curve", "", "SASC Curve (*.sasc)")
        if not fname:
            return

        handles = []
        try:
            with open(fname, newline='') as f:
                reader = csv.reader(f)
                next(reader, None)  # skip header
                for row in reader:
                    x, y = float(row[0]), float(row[1])
                    handles.append((x,y))
        except Exception as e:
            QMessageBox.critical(self, "Error Loading Curve", str(e))
            return

        # reset everything _except_ endpoints
        self.curveEditor.initCurve()

        # now restore just our saved handles
        self.curveEditor.setControlHandles(handles)

        QMessageBox.information(self, "Curve Loaded", f"Restored {len(handles)} handles from {fname}")         

    def set_curve_mode(self):
        selected_button = self.curveModeGroup.checkedButton()
        if selected_button:
            self.curve_mode = selected_button.text()
            # Assuming you have the current LUT, update the preview
            if hasattr(self, 'current_lut'):
                self.updatePreviewLUT(self.current_lut, self.curve_mode)

    def get_visible_region(self):
        """Retrieve the coordinates of the visible region in the image."""
        viewport = self.scrollArea.viewport()
        # Top-left corner of the visible area
        x = self.scrollArea.horizontalScrollBar().value()
        y = self.scrollArea.verticalScrollBar().value()
        # Size of the visible area
        w = viewport.width()
        h = viewport.height()
        return x, y, w, h


    def updatePreviewLUT(self, lut, curve_mode):
        """Apply the 8-bit LUT to the preview image for real-time updates on slot 0."""

        # Access slot0 (recombined image) from ImageManager
        if self.image is None:
            print("No preview image loaded.")
            QMessageBox.warning(self, "No Image", "Preview image is not loaded.")
            return

        try:
            current_scroll_x = self.scrollArea.horizontalScrollBar().value()
            current_scroll_y = self.scrollArea.verticalScrollBar().value()

            # 1) Copy the entire preview in float [0..1]
            base_image = self.image.copy()  # shape: (H, W, 3 or 2)

            # 2) Convert the entire base_image to 8-bit
            image_8bit = (base_image * 255).astype(np.uint8)

            # 3) Make a working copy for transformation
            adjusted_8bit = image_8bit.copy()

            if adjusted_8bit.ndim == 3:  # RGB image
                adjusted_image = adjusted_8bit.copy()

                if curve_mode == "K (Brightness)":
                    # Apply LUT to all channels equally (Brightness)
                    for channel in range(3):
                        adjusted_image[:, :, channel] = lut[adjusted_8bit[:, :, channel]]

                elif curve_mode in ["R", "G", "B"]:
                    # Apply LUT to a single channel
                    channel_index = {"R": 0, "G": 1, "B": 2}[curve_mode]
                    adjusted_image[:, :, channel_index] = lut[adjusted_8bit[:, :, channel_index]]

                elif curve_mode in ["L*", "a*", "b*"]:
                    # Manual RGB to Lab Conversion
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Apply LUT to the respective channel
                    if curve_mode == "L*":
                        # L* typically ranges from 0 to 100
                        L_normalized = np.clip(L / 100.0, 0, 1)  # Normalize to [0,1]
                        L_lut_indices = (L_normalized * 255).astype(np.uint8)
                        L_adjusted = lut[L_lut_indices].astype(np.float32) * 100.0 / 255.0  # Scale back to [0,100]
                        L = L_adjusted

                    elif curve_mode == "a*":
                        # a* typically ranges from -128 to +127
                        a_normalized = np.clip((a + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        a_lut_indices = (a_normalized * 255).astype(np.uint8)
                        a_adjusted = lut[a_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        a = a_adjusted

                    elif curve_mode == "b*":
                        # b* typically ranges from -128 to +127
                        b_normalized = np.clip((b + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        b_lut_indices = (b_normalized * 255).astype(np.uint8)
                        b_adjusted = lut[b_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        b = b_adjusted

                    # Update Lab channels
                    lab_new = np.stack([L, a, b], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Chroma":
                    # === Manual RGB to Lab Conversion ===
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Compute Chroma
                    chroma = np.sqrt(a**2 + b**2)

                    # Define a fixed maximum Chroma for normalization to prevent over-scaling
                    fixed_max_chroma = 200.0  # Adjust this value as needed

                    # Normalize Chroma to [0,1] using fixed_max_chroma
                    chroma_norm = np.clip(chroma / fixed_max_chroma, 0, 1)

                    # Apply LUT to Chroma
                    chroma_lut_indices = (chroma_norm * 255).astype(np.uint8)
                    chroma_adjusted = lut[chroma_lut_indices].astype(np.float32)  # Ensure float32

                    # Compute scaling factor, avoiding division by zero
                    scale = np.ones_like(chroma_adjusted, dtype=np.float32)
                    mask = chroma > 0
                    scale[mask] = chroma_adjusted[mask] / chroma[mask]

                    # Scale a* and b* channels
                    a_new = a * scale
                    b_new = b * scale

                    # Update Lab channels
                    lab_new = np.stack([L, a_new, b_new], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Saturation":
                    # === Manual RGB to HSV Conversion ===
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Split channels
                    R, G, B = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]

                    # Compute Cmax, Cmin, Delta
                    Cmax = np.maximum.reduce([R, G, B])
                    Cmin = np.minimum.reduce([R, G, B])
                    Delta = Cmax - Cmin

                    # Initialize Hue (H), Saturation (S), and Value (V)
                    H = np.zeros_like(Cmax)
                    S = np.zeros_like(Cmax)
                    V = Cmax.copy()

                    # Compute Hue (H)
                    mask = Delta != 0
                    H[mask & (Cmax == R)] = ((G[mask & (Cmax == R)] - B[mask & (Cmax == R)]) / Delta[mask & (Cmax == R)]) % 6
                    H[mask & (Cmax == G)] = ((B[mask & (Cmax == G)] - R[mask & (Cmax == G)]) / Delta[mask & (Cmax == G)]) + 2
                    H[mask & (Cmax == B)] = ((R[mask & (Cmax == B)] - G[mask & (Cmax == B)]) / Delta[mask & (Cmax == B)]) + 4
                    H = H / 6.0  # Normalize Hue to [0,1]

                    # Compute Saturation (S)
                    S[Cmax != 0] = Delta[Cmax != 0] / Cmax[Cmax != 0]

                    # Apply LUT to Saturation (S) channel
                    S_normalized = np.clip(S, 0, 1)  # Ensure S is within [0,1]
                    S_lut_indices = (S_normalized * 255).astype(np.uint8)
                    S_adjusted = lut[S_lut_indices].astype(np.float32) / 255.0  # Normalize back to [0,1]
                    S = S_adjusted

                    # Convert HSV back to RGB
                    C = V * S
                    X = C * (1 - np.abs((H * 6) % 2 - 1))
                    m = V - C

                    # Initialize RGB channels
                    R_new = np.zeros_like(R)
                    G_new = np.zeros_like(G)
                    B_new = np.zeros_like(B)

                    # Define masks for different sectors of Hue
                    mask0 = (H >= 0) & (H < 1/6)
                    mask1 = (H >= 1/6) & (H < 2/6)
                    mask2 = (H >= 2/6) & (H < 3/6)
                    mask3 = (H >= 3/6) & (H < 4/6)
                    mask4 = (H >= 4/6) & (H < 5/6)
                    mask5 = (H >= 5/6) & (H < 1)

                    # Assign RGB values based on the sector of Hue
                    R_new[mask0] = C[mask0]
                    G_new[mask0] = X[mask0]
                    B_new[mask0] = 0

                    R_new[mask1] = X[mask1]
                    G_new[mask1] = C[mask1]
                    B_new[mask1] = 0

                    R_new[mask2] = 0
                    G_new[mask2] = C[mask2]
                    B_new[mask2] = X[mask2]

                    R_new[mask3] = 0
                    G_new[mask3] = X[mask3]
                    B_new[mask3] = C[mask3]

                    R_new[mask4] = X[mask4]
                    G_new[mask4] = 0
                    B_new[mask4] = C[mask4]

                    R_new[mask5] = C[mask5]
                    G_new[mask5] = 0
                    B_new[mask5] = X[mask5]

                    # Add m to match the Value (V)
                    R_new += m
                    G_new += m
                    B_new += m

                    # Stack the channels back together
                    rgb_new = np.stack([R_new, G_new, B_new], axis=2)

                    # Clip RGB to [0,1] to maintain valid color ranges
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                else:
                    # Unsupported curve mode
                    print(f"Unsupported curve mode: {curve_mode}")
                    QMessageBox.warning(self, "Unsupported Mode", f"Unsupported curve mode: {curve_mode}")
                    return

            else:  # Grayscale image
                # For grayscale images, apply LUT directly
                adjusted_image = lut[adjusted_8bit]

            # Convert adjusted_image back to float [0..1]
            preview_image = adjusted_image.astype(np.float32) / 255.0

            # 5) Retrieve the active mask
            mask = self.get_active_mask()


            if mask is not None:
                # 5a) Downsample the mask to match the preview image dimensions
                downsampled_mask = self.downsample_for_preview(mask, max_width=1080)

                # 5b) Ensure mask is properly formatted and normalized
                if downsampled_mask.dtype != np.float32 and downsampled_mask.dtype != np.float64:
                    downsampled_mask = downsampled_mask.astype(np.float32) / 255.0

                # 5c) If preview_image is multi-channel but mask is single-channel, expand mask dimensions
                if preview_image.ndim == 3 and downsampled_mask.ndim == 2:
                    downsampled_mask = np.expand_dims(downsampled_mask, axis=-1)

                # 5d) Ensure mask dimensions match the preview image dimensions
                if downsampled_mask.shape[:2] != preview_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Downsampled mask dimensions do not match the preview image dimensions.")
                    return

                # 5e) Blend the adjusted preview_image with the base_image using the mask
                # Formula: blended_preview = adjusted_image * mask + base_image * (1 - mask)
                blended_preview = preview_image * downsampled_mask + base_image * (1 - downsampled_mask)
                blended_preview = np.clip(blended_preview, 0.0, 1.0)  # Ensure values are within [0,1]
            else:
                # No mask applied; use the adjusted image directly
                blended_preview = preview_image

            # 6) Finally, show the blended preview image
            self.show_image(blended_preview)
            self.scrollArea.horizontalScrollBar().setValue(current_scroll_x)
            self.scrollArea.verticalScrollBar().setValue(current_scroll_y)              

        except Exception as e:
            print(f"Error in updatePreviewLUT: {e}")
            QMessageBox.critical(self, "Error", f"Failed to update preview: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.original_image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None

    def handleImageMouseMove(self, x, y):
        if self.image is None:
            return

        h, w = self.image.shape[:2]
        img_x = int(x / self.zoom_factor)
        img_y = int(y / self.zoom_factor)

        if 0 <= img_x < w and 0 <= img_y < h:
            pixel_value = self.image[img_y, img_x]
            if self.image.ndim == 3:
                # RGB pixel: assuming pixel values are in 0-1
                r, g, b = pixel_value
                text = f"X:{img_x} Y:{img_y} R:{r:.3f} G:{g:.3f} B:{b:.3f}"
                self.curveEditor.updateValueLines(r, g, b, grayscale=False)
            else:
                # Grayscale pixel: value is in 0-1
                text = f"X:{img_x} Y:{img_y} Val:{pixel_value:.3f}"
                # Pass the grayscale value for all channels and set grayscale flag to True
                self.curveEditor.updateValueLines(pixel_value, pixel_value, pixel_value, grayscale=True)
            self.statusLabel.setText(text)



    def startProcessing(self):
        if self.original_image is None:
            QMessageBox.warning(self, "Warning", "No image loaded to apply curve.")
            return

        curve_mode = self.curveModeGroup.checkedButton().text()
        curve_func = self.curveEditor.getCurveFunction()


        source_image = self.original_image.copy()

        # Push the current image to the undo stack before modifying
        self.pushUndo(self.original_image.copy())

        # Show the spinner before starting processing
        self.showSpinner()

        # Initialize and start the processing thread
        self.processing_thread = FullCurvesProcessingThread(source_image, curve_mode, curve_func)
        self.processing_thread.result_ready.connect(self.finishProcessing)
        self.processing_thread.start()
        print("Started FullCurvesProcessingThread.")

    def finishProcessing(self, adjusted_image):
        self.hideSpinner()

        if adjusted_image is None:
            QMessageBox.critical(self, "Error", "Image processing failed.")
            return

        # — Blend with mask if present —
        mask = self.get_active_mask()
        if mask is not None:
            # normalize & expand dims as before…
            if mask.dtype not in (np.float32, np.float64):
                mask = mask.astype(np.float32) / 255.0
            if self.original_image.ndim == 3 and mask.ndim == 2:
                mask = mask[..., None]
            if mask.shape[:2] != self.original_image.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                return
            if mask.ndim == 2:
                mask = mask[..., None]
            if self.original_image.ndim == 3 and mask.shape[2] == 1:
                mask = np.repeat(mask, self.original_image.shape[2], axis=2)

            blended = adjusted_image * mask + self.original_image * (1 - mask)
            blended = np.clip(blended, 0.0, 1.0)
        else:
            blended = adjusted_image

        # — Update master copy and preview —
        self.original_image = blended.copy()
        self.preview_image  = self.downsample_for_preview(blended, max_width=1080)
        self.image          = self.preview_image.copy()
        self.show_image(self.image)

        # — Rebuild curve editor state instead of wiping it —
        is_ghs = (self.stretchTypeGroup.checkedButton().text()
                == "Generalized Hyperbolic")
        if is_ghs:
            # current α, β (and γ if you add it)
            α = self.alphaSlider.value() / 50.0
            β = self.betaSlider.value() / 50.0

            # how many handles do we want? preserve existing count or default 20
            n = len(self.curveEditor.control_points) or 20
            # rebuild the *raw* handles at the correct α/β
            pts = self.generate_ghs_control_points(α, β, n=n)
            self.curveEditor.setControlHandles(pts)

            # now *always* run the GHS remapping (γ + pivot) so the handles
            # end up exactly where the preview curve was
            self.curveEditor.clearSymmetryLine()   # clear any old line
            if self.ghs_sym_pt is not None:
                # restore the yellow pivot line
                self.curveEditor.setSymmetryPoint(self.ghs_sym_pt*360.0, 0)
            # this will apply the γ-lift + remap around p
            self.updateGhsCurve()
        else:
            # Traditional Bézier → back to default
            self.curveEditor.initCurve()

        # finally push it back into ImageManager
        if self.image_manager:
            meta = dict(
                file_path=self.loaded_image_path,
                original_header=self.original_header,
                bit_depth=self.bit_depth,
                is_mono=self.is_mono
            )
            self.image_manager.set_image_with_step_name(
                self.original_image.copy(), meta, step_name="Curves Adjustment"
            )
            print("FullCurvesTab: Image updated in ImageManager with step name.")



    def pushUndo(self, image_state):
        """Push the current image state onto the undo stack."""
        if len(self.undo_stack) >= self.max_undo:
            # Remove the oldest state to maintain the stack size
            self.undo_stack.pop(0)
        self.undo_stack.append(image_state)
        self.updateUndoButtonState()

    def updateUndoButtonState(self):
        """Enable or disable the Undo button based on the undo stack."""
        if hasattr(self, 'undoButton'):
            self.undoButton.setEnabled(len(self.undo_stack) > 0)

    def undo(self):
        """Revert the image to the last state in the undo stack."""
        if not self.undo_stack:
            QMessageBox.information(self, "Undo", "No actions to undo.")
            return

        # Pop the last state from the stack
        last_state = self.undo_stack.pop()

        # Update ImageManager with the previous image state
        if self.image_manager:
            metadata = {
                'file_path': self.loaded_image_path,  # Update as needed
                'original_header': self.original_header,
                'bit_depth': self.bit_depth,
                'is_mono': self.is_mono
            }
            self.image_manager.update_image(updated_image=last_state, metadata=metadata)
            print("Undo: Image reverted in ImageManager.")

        # Update the Undo button state
        self.updateUndoButtonState()


    def resetCurve(self):
        """
        Resets the draggable points in the curve editor.
        — In traditional mode, behaves as before.
        — In generalized hyperbolic mode, resets α/β, clears inflection,
        and redraws exactly 20 GHS handles.
        """
        try:
            is_ghs = self.stretchTypeGroup.checkedButton().text() == "Generalized Hyperbolic"

            if is_ghs:
                # 1) reset sliders & labels
                self.alphaSlider.setValue(50)
                self.betaSlider .setValue(50)
                self.alphaLabel .setText("1.00")
                self.betaLabel  .setText("1.00")

                # 2) clear any inflection pivot
                self.ghs_sym_pt = None
                self.curveEditor.clearSymmetryLine()

                # 3) regenerate the default GHS control points using normalized α,β
                α = self.alphaSlider.value() / 50.0   # -> 1.0
                β = self.betaSlider.value()  / 50.0   # -> 1.0
                pts = self.generate_ghs_control_points(α, β, n=20)
                self.curveEditor.setControlHandles(pts)

            else:
                # traditional curves → back to a clean bezier
                self.curveEditor.initCurve()

            # 4) clear preview LUT & redraw
            self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)
            self.updatePreviewLUT(self.current_lut, self.curve_mode)

        except Exception as e:
            print(f"Error during curve reset: {e}")
            QMessageBox.critical(self, "Error", f"Failed to reset curve: {e}")

    def eventFilter(self, source, event):
        # ——— 1) Histogram Ctrl-click to set inflection ———
        hist = getattr(self, "_hist_dialog", None)
        if ( hist is not None
            and source is hist.hist_label
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ControlModifier ):

            x = event.pos().x()
            w = hist.hist_label.width()
            frac = max(0.0, min(1.0, x / w))

            if hist.log_scale:
                # use *exactly* the same eps/log_min/log_max you drew with
                eps     = hist._hist_eps
                log_min = hist._hist_log_min
                log_max = hist._hist_log_max
                log_val = log_min + frac * (log_max - log_min)
                k = 10 ** log_val
            else:
                k = frac

            # store pivot and redraw GHS
            self.ghs_sym_pt = k
            self.curveEditor.setSymmetryPoint(k*360.0, 0)
            self.statusLabel.setText(f"Symmetry K={k:.4f}")
            self.updateGhsCurve()
            return True

        # ——— 2) Image-view Ctrl-click to set pivot from pixel brightness ———
        if (
            source is self.scrollArea.viewport()
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ControlModifier
        ):
            pos = self.imageLabel.mapFrom(self.scrollArea.viewport(), event.pos())
            pix = self.imageLabel.pixmap()
            if pix and 0 <= pos.x() < pix.width() and 0 <= pos.y() < pix.height():
                img_x = pos.x() / self.zoom_factor
                img_y = pos.y() / self.zoom_factor
                h, w = self.image.shape[:2]
                if 0 <= img_x < w and 0 <= img_y < h:
                    pv = self.image[int(img_y), int(img_x)]
                    k = float(np.mean(pv))
                    self.ghs_sym_pt = k
                    self.curveEditor.setSymmetryPoint(k * 360.0, 0)
                    self.statusLabel.setText(f"Symmetry at K={k:.3f}")
                    self.updateGhsCurve()
                    return True

        # ——— 3) Shift-click to add control point ———
        if (
            source is self.scrollArea.viewport()
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ShiftModifier
        ):
            pos = self.imageLabel.mapFrom(self.scrollArea.viewport(), event.pos())
            pix = self.imageLabel.pixmap()
            if pix and 0 <= pos.x() < pix.width() and 0 <= pos.y() < pix.height():
                img_x = int(pos.x() / self.zoom_factor)
                img_y = int(pos.y() / self.zoom_factor)
                h, w = self.image.shape[:2]
                if 0 <= img_x < w and 0 <= img_y < h:
                    pv = self.image[img_y, img_x]
                    avg = float(np.mean(pv))
                    new_x, new_y = avg * 360.0, (1 - avg) * 360.0
                    self.curveEditor.addControlPoint(new_x, new_y)
                    self.statusLabel.setText(f"Added control point @ X:{new_x:.1f} Y:{new_y:.1f}")
                    return True

        # ——— 4) Fall back to pan/drag ———
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(
                self.scrollArea.horizontalScrollBar().value() - delta.x()
            )
            self.scrollArea.verticalScrollBar().setValue(
                self.scrollArea.verticalScrollBar().value() - delta.y()
            )
            self.last_pos = event.pos()

        return super().eventFilter(source, event)


    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return
        if image is None:
            return                
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
                
            # Set the image and store a copy for later use
            self.loaded_image_path = metadata.get('file_path', None)
            self.image = image
            self.original_image = image.copy()  # Store a copy of the original image
            self.original_header = metadata.get('original_header', None)
            self.bit_depth = metadata.get('bit_depth', None)
            self.is_mono = metadata.get('is_mono', False)

            self.preview_image = self.downsample_for_preview(image, max_width=1080)
            self.image = self.preview_image.copy()
            
            # Save the previous scroll position
            self.previous_scroll_pos = (
                self.scrollArea.horizontalScrollBar().value(),
                self.scrollArea.verticalScrollBar().value()
            )
            
            if not isinstance(self.loaded_image_path, str):
                self.loaded_image_path = ""
            self.fileLabel.setText(self.loaded_image_path)
            
            # Update the UI elements (buttons, etc.)
            self.show_image(image)
            self.update_image_display()

            # Enable or disable buttons based on image processing state
            self.applyButton.setEnabled(True)

            self.undoButton.setEnabled(len(self.undo_stack) > 0)

            print(f"FullCurvesTab: Image updated from ImageManager slot {slot}.")

    def downsample_for_preview(self, image_float32, max_width=1080):
        """
        If image width > max_width, scale it down proportionally.
        Returns a new float32 image in [0..1].
        """


        h, w = image_float32.shape[:2]

        if w <= max_width:
            # No need to downsample
            return image_float32.copy()

        scale_factor = max_width / float(w)
        new_w = max_width
        new_h = int(h * scale_factor)

        # Convert [0..1] float to [0..255] uint8 for OpenCV resizing
        temp_8u = (image_float32 * 255).clip(0,255).astype(np.uint8)

        # Resize with INTER_AREA for best downsampling
        resized_8u = cv2.resize(temp_8u, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # Convert back to float32 in [0..1]
        return resized_8u.astype(np.float32) / 255.0



    def show_image(self, image):
        try:
            # Normalize image to 0-255 and convert to uint8
            display_image = (image * 255).astype(np.uint8)

            # If the image has a singleton third dimension, squeeze it out
            if display_image.ndim == 3 and display_image.shape[2] == 1:
                display_image = display_image.squeeze(axis=2)

            if display_image.ndim == 3 and display_image.shape[2] == 3:
                # RGB Image
                height, width, channels = display_image.shape
                bytes_per_line = 3 * width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif display_image.ndim == 2:
                # Grayscale Image
                height, width = display_image.shape
                bytes_per_line = width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                print("Unsupported image format for display.")
                QMessageBox.critical(self, "Error", "Unsupported image format for display.")
                return

            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)

        except Exception as e:
            print(f"Error displaying image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to display the image: {e}")



    def update_image_display(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """
        Zoom into the image by increasing the zoom factor.
        """
        if self.image is not None:
            self.zoom_factor *= 1.2
            self.show_image(self.image)
            zoom_pct = self.zoom_factor * 100
            print(f"Zoomed in. New zoom: {zoom_pct:.0f}%")

            # Show tooltip at the center of the scrollArea’s viewport
            vp = self.scrollArea.viewport()
            center_local = vp.rect().center()                      # QPoint in viewport coords
            center_global = vp.mapToGlobal(center_local)           # QPoint in screen coords
            QToolTip.showText(center_global, f"{zoom_pct:.0f}%")

        else:
            print("No stretched image to zoom in.")
            QMessageBox.warning(self, "Warning", "No stretched image to zoom in.")


    def zoom_out(self):
        """
        Zoom out of the image by decreasing the zoom factor.
        """
        if self.image is not None:
            self.zoom_factor /= 1.2
            self.show_image(self.image)
            zoom_pct = self.zoom_factor * 100
            print(f"Zoomed out. New zoom: {zoom_pct:.0f}%")

            # Show tooltip at the center of the scrollArea’s viewport
            vp = self.scrollArea.viewport()
            center_local = vp.rect().center()
            center_global = vp.mapToGlobal(center_local)
            QToolTip.showText(center_global, f"{zoom_pct:.0f}%")

        else:
            print("No stretched image to zoom out.")
            QMessageBox.warning(self, "Warning", "No stretched image to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.image.ndim == 3:
                image_width = self.image.shape[1]
            elif self.image.ndim == 2:
                image_width = self.image.shape[1]
            else:
                print("Unexpected image dimensions!")
                QMessageBox.warning(self, "Warning", "Cannot fit image to preview due to unexpected dimensions.")
                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.show_image(self.image)
            
            print(f"Fit to preview applied. New zoom factor: {self.zoom_factor:.2f}")
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def refresh_display(self):
        """
        Refresh the image display based on the current zoom factor.
        """
        if self.stretched_image is None:
            print("No stretched image to display.")
            return

        try:
            # Normalize and convert to uint8 for display
            img = (self.stretched_image * 255).astype(np.uint8)
            h, w = img.shape[:2]

            if img.ndim == 3 and img.shape[2] == 3:
                bytes_per_line = 3 * w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
            elif img.ndim == 2:
                bytes_per_line = w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                raise ValueError("Unsupported image format for display.")

            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

            print("Display refreshed successfully.")
        except Exception as e:
            print(f"Error refreshing display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to refresh display: {e}")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updatePreview()  # Call without extra arguments; it will calculate dimensions based on zoom factor            

    def saveImage(self):
        if self.image is not None:
            # Open the file save dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 'Save Image As', '', 
                'Images (*.tiff *.tif *.png *.fit *.fits *.xisf);;All Files (*)'
            )
            
            if save_filename:
                # Extract the file extension from the user-provided filename
                file_extension = save_filename.split('.')[-1].lower()

                # Map the extension to the format expected by save_image
                if file_extension in ['tif', 'tiff']:
                    file_format = 'tiff'
                elif file_extension == 'png':
                    file_format = 'png'
                elif file_extension in ['fit', 'fits']:
                    file_format = 'fits'
                elif file_extension == 'xisf':
                    file_format = 'xisf'
                else:
                    QMessageBox.warning(self, "Error", f"Unsupported file format: .{file_extension}")
                    return
                
                try:
                    # Initialize metadata if not already set (e.g., for PNG)
                    if not hasattr(self, 'image_meta') or self.image_meta is None:
                        self.image_meta = [{
                            'geometry': (self.image.shape[1], self.image.shape[0], self.image.shape[2] if not self.is_mono else 1),
                            'colorSpace': 'Gray' if self.is_mono else 'RGB'
                        }]

                    if not hasattr(self, 'file_meta') or self.file_meta is None:
                        self.file_meta = {}

                    # Initialize a default header for FITS if none exists
                    if not hasattr(self, 'original_header') or self.original_header is None:
                        print("Creating default FITS header...")
                        self.original_header = {
                            'SIMPLE': True,
                            'BITPIX': -32 if self.bit_depth == "32-bit floating point" else 16,
                            'NAXIS': 2 if self.is_mono else 3,
                            'NAXIS1': self.image.shape[1],
                            'NAXIS2': self.image.shape[0],
                            'NAXIS3': 1 if self.is_mono else self.image.shape[2],
                            'BZERO': 0.0,
                            'BSCALE': 1.0,
                            'COMMENT': "Default header created by Seti Astro Suite"
                        }

                    # Call save_image with the appropriate arguments
                    save_image(
                        self.image,
                        save_filename,
                        file_format,  # Use the user-specified format
                        self.bit_depth,
                        self.original_header,
                        self.is_mono,
                        self.image_meta,
                        self.file_meta
                    )
                    print(f"Image saved successfully to {save_filename}")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

class DraggablePoint(QGraphicsEllipseItem):
    def __init__(self, curve_editor, x, y, color=Qt.GlobalColor.green, lock_axis=None, position_type=None):
        super().__init__(-5, -5, 10, 10)
        self.curve_editor = curve_editor
        self.lock_axis = lock_axis
        self.position_type = position_type
        self.setBrush(QBrush(color))
        self.setFlags(QGraphicsItem.GraphicsItemFlag.ItemIsMovable | QGraphicsItem.GraphicsItemFlag.ItemSendsScenePositionChanges)
        self.setCursor(Qt.CursorShape.OpenHandCursor)
        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton | Qt.MouseButton.RightButton)
        self.setPos(x, y)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.RightButton:
            if self in self.curve_editor.control_points:
                self.curve_editor.control_points.remove(self)
                self.curve_editor.scene.removeItem(self)
                self.curve_editor.updateCurve()
            return
        super().mousePressEvent(event)

    def itemChange(self, change, value):
        if change == QGraphicsItem.GraphicsItemChange.ItemPositionHasChanged:
            new_pos = value
            x = new_pos.x()
            y = new_pos.y()

            if self.position_type == 'top_right':
                dist_to_top = abs(y-0)
                dist_to_right = abs(x-360)
                if dist_to_right<dist_to_top:
                    nx=360
                    ny=min(max(y,0),360)
                else:
                    ny=0
                    nx=min(max(x,0),360)
                x,y=nx,ny
            elif self.position_type=='bottom_left':
                dist_to_left=abs(x-0)
                dist_to_bottom=abs(y-360)
                if dist_to_left<dist_to_bottom:
                    nx=0
                    ny=min(max(y,0),360)
                else:
                    ny=360
                    nx=min(max(x,0),360)
                x,y=nx,ny

            all_points=self.curve_editor.end_points+self.curve_editor.control_points
            other_points=[p for p in all_points if p is not self]
            other_points_sorted=sorted(other_points,key=lambda p:p.scenePos().x())

            insert_index=0
            for i,p in enumerate(other_points_sorted):
                if p.scenePos().x()<x:
                    insert_index=i+1
                else:
                    break

            if insert_index>0:
                left_p=other_points_sorted[insert_index-1]
                left_x=left_p.scenePos().x()
                if x<=left_x:
                    x=left_x+0.0001

            if insert_index<len(other_points_sorted):
                right_p=other_points_sorted[insert_index]
                right_x=right_p.scenePos().x()
                if x>=right_x:
                    x=right_x-0.0001

            x=max(0,min(x,360))
            y=max(0,min(y,360))

            super().setPos(x,y)
            self.curve_editor.updateCurve()

        return super().itemChange(change, value)

class ImageLabel(QLabel):
    mouseMoved = pyqtSignal(float, float)
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)
    def mouseMoveEvent(self, event):
        self.mouseMoved.emit(event.position().x(), event.position().y())
        super().mouseMoveEvent(event)

class CurveEditor(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.scene = QGraphicsScene(self)
        self.setScene(self.scene)
        self.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.setFixedSize(380, 425)
        self.preview_callback = None  # To trigger real-time updates
        self.symmetry_callback = None

        # Initialize control points and curve path
        self.end_points = []  # Start and end points with axis constraints
        self.control_points = []  # Dynamically added control points
        self.curve_path = QPainterPath()
        self.curve_item = None  # Stores the curve line
        self.sym_line = None

        # Set scene rectangle
        self.scene.setSceneRect(0, 0, 360, 360)

        self.initGrid()
        self.initCurve()

    def initGrid(self):
        pen = QPen(Qt.GlobalColor.gray)
        pen.setStyle(Qt.PenStyle.DashLine)
        for i in range(0, 361, 45):  # Grid lines at 0,45,...,360
            self.scene.addLine(i, 0, i, 360, pen)  # Vertical lines
            self.scene.addLine(0, i, 360, i, pen)  # Horizontal lines

        # Add X-axis labels
        # Each line corresponds to i/360.0
        for i in range(0, 361, 45):
            val = i/360.0
            label = QGraphicsTextItem(f"{val:.3f}")
            # Position label slightly below the x-axis (360 is bottom)
            # For X-axis, put them near bottom at y=365 for example
            label.setPos(i-5, 365) 
            self.scene.addItem(label)

        # Optionally add Y-axis labels if needed
        # Similar approach for the Y-axis if you want

    def initCurve(self):
        # Remove existing items from the scene
        # First remove control points
        for p in self.control_points:
            self.scene.removeItem(p)
        # Remove end points
        for p in self.end_points:
            self.scene.removeItem(p)
        # Remove the curve item if any
        if self.curve_item:
            self.scene.removeItem(self.curve_item)
            self.curve_item = None

        # Clear existing point lists
        self.end_points = []
        self.control_points = []

        # Add the default endpoints again
        self.addEndPoint(0, 360, lock_axis=None, position_type='bottom_left', color=Qt.GlobalColor.black)
        self.addEndPoint(360, 0, lock_axis=None, position_type='top_right', color=Qt.GlobalColor.white)

        # Redraw the initial line
        self.updateCurve()

    def getControlHandles(self):
        """Return just the user-added handles (not the endpoints)."""
        # control_points are your green, draggable handles:
        return [(p.scenePos().x(), p.scenePos().y()) for p in self.control_points]

    def setControlHandles(self, handles):
        """Clear existing controls (but keep endpoints), then re-add."""
        # remove any existing controls
        for p in list(self.control_points):
            self.scene.removeItem(p)
        self.control_points.clear()

        # now add back each one
        for x,y in handles:
            self.addControlPoint(x, y)

        # finally redraw spline once
        self.updateCurve()

    def clearSymmetryLine(self):
        """Remove any drawn symmetry line and reset."""
        if self.sym_line:
            self.scene.removeItem(self.sym_line)
            self.sym_line = None
            # redraw without symmetry aid
            self.updateCurve()

    def addEndPoint(self, x, y, lock_axis=None, position_type=None, color=Qt.GlobalColor.red):
        point = DraggablePoint(self, x, y, color=color, lock_axis=lock_axis, position_type=position_type)
        self.scene.addItem(point)
        self.end_points.append(point)

    def addControlPoint(self, x, y, lock_axis=None):

        point = DraggablePoint(self, x, y, color=Qt.GlobalColor.green, lock_axis=lock_axis, position_type=None)
        self.scene.addItem(point)
        self.control_points.append(point)
        self.updateCurve()

    def setSymmetryCallback(self, fn):
        """fn will be called with (u, v) in [0..1] when user ctrl+clicks the grid."""
        self.symmetry_callback = fn

    def setSymmetryPoint(self, x, y):
        pen = QPen(Qt.GlobalColor.yellow)
        pen.setStyle(Qt.PenStyle.DashLine)
        pen.setWidth(2)
        if self.sym_line is None:
            # draw a vertical symmetry line at scene X==x
            self.sym_line = self.scene.addLine(x, 0, x, 360, pen)
        else:
            self.sym_line.setLine(x, 0, x, 360)
        # if you want to re-draw the curve mirrored around x,
        # you can trigger updateCurve() here or elsewhere
        self.updateCurve()

    def catmull_rom_spline(self, p0, p1, p2, p3, t):
        """
        Compute a point on a Catmull-Rom spline segment at parameter t (0<=t<=1).
        Each p is a QPointF.
        """
        t2 = t * t
        t3 = t2 * t

        x = 0.5 * (2*p1.x() + (-p0.x() + p2.x()) * t +
                    (2*p0.x() - 5*p1.x() + 4*p2.x() - p3.x()) * t2 +
                    (-p0.x() + 3*p1.x() - 3*p2.x() + p3.x()) * t3)
        y = 0.5 * (2*p1.y() + (-p0.y() + p2.y()) * t +
                    (2*p0.y() - 5*p1.y() + 4*p2.y() - p3.y()) * t2 +
                    (-p0.y() + 3*p1.y() - 3*p2.y() + p3.y()) * t3)

        # Clamp to bounding box
        x = max(0, min(360, x))
        y = max(0, min(360, y))

        return QPointF(x, y)

    def generateSmoothCurvePoints(self, points):
        """
        Given a sorted list of QGraphicsItems (endpoints + control points),
        generate a list of smooth points approximating a Catmull-Rom spline
        through these points.
        """
        if len(points) < 2:
            return []
        if len(points) == 2:
            # Just a straight line between two points
            p0 = points[0].scenePos()
            p1 = points[1].scenePos()
            return [p0, p1]

        # Extract scene positions
        pts = [p.scenePos() for p in points]

        # For Catmull-Rom, we need points before the first and after the last
        # We'll duplicate the first and last points.
        extended_pts = [pts[0]] + pts + [pts[-1]]

        smooth_points = []
        steps_per_segment = 20  # increase for smoother curve
        for i in range(len(pts) - 1):
            p0 = extended_pts[i]
            p1 = extended_pts[i+1]
            p2 = extended_pts[i+2]
            p3 = extended_pts[i+3]

            # Sample the spline segment between p1 and p2
            for step in range(steps_per_segment+1):
                t = step / steps_per_segment
                pos = self.catmull_rom_spline(p0, p1, p2, p3, t)
                smooth_points.append(pos)

        return smooth_points

    # Add a callback for the preview
    def setPreviewCallback(self, callback):
        self.preview_callback = callback

    def get8bitLUT(self):
        import numpy as np

        # 8-bit LUT size
        lut_size = 256

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 255, lut_size, dtype=np.uint8)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:, 0]   # X from 0 to 360
        ys = curve_array[:, 1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys

        # Input positions for interpolation (0..255 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..255
        output_values = (output_values / 360.0) * 255.0
        output_values = np.clip(output_values, 0, 255).astype(np.uint8)

        return output_values

    def updateCurve(self):
        """Update the curve by redrawing based on endpoints and control points."""
        
        all_points = self.end_points + self.control_points
        if not all_points:
            # No points, no curve
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        # Sort points by X coordinate
        sorted_points = sorted(all_points, key=lambda p: p.scenePos().x())

        # Extract arrays of X and Y
        xs = [p.scenePos().x() for p in sorted_points]
        ys = [p.scenePos().y() for p in sorted_points]

        # Ensure X values are strictly increasing
        unique_xs, unique_ys = [], []
        for i in range(len(xs)):
            if i == 0 or xs[i] > xs[i - 1]:  # Skip duplicate X values
                unique_xs.append(xs[i])
                unique_ys.append(ys[i])

        # If there's only one point or none, we can't interpolate
        if len(unique_xs) < 2:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None

            if len(unique_xs) == 1:
                # Optionally draw a single point
                single_path = QPainterPath()
                single_path.addEllipse(unique_xs[0]-2, unique_ys[0]-2, 4, 4)
                pen = QPen(Qt.GlobalColor.white)
                pen.setWidth(3)
                self.curve_item = self.scene.addPath(single_path, pen)
            return

        try:
            # Create a PCHIP interpolator
            interpolator = PchipInterpolator(unique_xs, unique_ys)
            self.curve_function = interpolator

            # Sample the curve
            sample_xs = np.linspace(unique_xs[0], unique_xs[-1], 361)
            sample_ys = interpolator(sample_xs)

        except ValueError as e:
            print(f"Interpolation Error: {e}")  # Log the error instead of crashing
            return  # Exit gracefully

        curve_points = [QPointF(float(x), float(y)) for x, y in zip(sample_xs, sample_ys)]
        self.curve_points = curve_points

        if not curve_points:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        self.curve_path = QPainterPath()
        self.curve_path.moveTo(curve_points[0])
        for pt in curve_points[1:]:
            self.curve_path.lineTo(pt)

        if self.curve_item:
            self.scene.removeItem(self.curve_item)
        pen = QPen(Qt.GlobalColor.white)
        pen.setWidth(3)
        self.curve_item = self.scene.addPath(self.curve_path, pen)

        # Trigger the preview callback
        if hasattr(self, 'preview_callback') and self.preview_callback:
            # Generate the 8-bit LUT and pass it to the callback
            lut = self.get8bitLUT()
            self.preview_callback(lut)

    def getCurveFunction(self):
        return self.curve_function

    def getCurvePoints(self):
        if not hasattr(self, 'curve_points') or not self.curve_points:
            return []
        return [(pt.x(), pt.y()) for pt in self.curve_points]

    def getLUT(self):
        import numpy as np

        # 16-bit LUT size
        lut_size = 65536

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 65535, lut_size, dtype=np.uint16)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:,0]   # X from 0 to 360
        ys = curve_array[:,1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys


        # Input positions for interpolation (0..65535 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..65535
        output_values = (output_values / 360.0) * 65535.0
        output_values = np.clip(output_values, 0, 65535).astype(np.uint16)

        return output_values
    
    def mousePressEvent(self, event):
        # ctrl+left click on the grid → pick inflection point
        if (event.button() == Qt.MouseButton.LeftButton
                and event.modifiers() & Qt.KeyboardModifier.ControlModifier):
            scene_pt = self.mapToScene(event.pos())
            # clamp into scene rect
            x = max(0, min(360, scene_pt.x()))
            y = max(0, min(360, scene_pt.y()))
            # draw the yellow symmetry line
            self.setSymmetryPoint(x, y)
            # compute normalized (u, v)
            u = x / 360.0
            v = 1.0 - (y / 360.0)
            # tell anyone who cares
            if self.symmetry_callback:
                self.symmetry_callback(u, v)
            return  # consume
        super().mousePressEvent(event)

    def mouseDoubleClickEvent(self, event):
        """
        Handle double-click events to add a new control point.
        """
        scene_pos = self.mapToScene(event.pos())

        self.addControlPoint(scene_pos.x(), scene_pos.y())
        super().mouseDoubleClickEvent(event)

    def keyPressEvent(self, event):
        """Remove selected points on Delete key press."""
        if event.key() == Qt.Key.Key_Delete:
            for point in self.control_points[:]:
                if point.isSelected():
                    self.scene.removeItem(point)
                    self.control_points.remove(point)
            self.updateCurve()
        super().keyPressEvent(event)

    def updateValueLines(self, r, g, b, grayscale=False):
        """
        Update vertical lines on the curve scene.
        For color images (grayscale=False), three lines (red, green, blue) are drawn.
        For grayscale images (grayscale=True), a single gray line is drawn.
        
        Values are assumed to be in the range [0, 1] and mapped to 0–360.
        """
        if grayscale:
            # Map the 0–1 grayscale value to the scene's X coordinate (0–360)
            x = r * 360.0
            if not hasattr(self, "gray_line") or self.gray_line is None:
                self.gray_line = self.scene.addLine(x, 0, x, 360, QPen(Qt.GlobalColor.gray))
            else:
                self.gray_line.setLine(x, 0, x, 360)
            # Hide any color lines if present
            for attr in ("r_line", "g_line", "b_line"):
                if hasattr(self, attr) and getattr(self, attr) is not None:
                    getattr(self, attr).setVisible(False)
        else:
            # Hide grayscale line if present
            if hasattr(self, "gray_line") and self.gray_line is not None:
                self.gray_line.setVisible(False)
            
            # Map each 0–1 value to X coordinate on scene (0–360)
            r_x = r * 360.0
            g_x = g * 360.0
            b_x = b * 360.0

            # Create or update the red line
            if not hasattr(self, "r_line") or self.r_line is None:
                self.r_line = self.scene.addLine(r_x, 0, r_x, 360, QPen(Qt.GlobalColor.red))
            else:
                self.r_line.setLine(r_x, 0, r_x, 360)
            self.r_line.setVisible(True)

            # Create or update the green line
            if not hasattr(self, "g_line") or self.g_line is None:
                self.g_line = self.scene.addLine(g_x, 0, g_x, 360, QPen(Qt.GlobalColor.green))
            else:
                self.g_line.setLine(g_x, 0, g_x, 360)
            self.g_line.setVisible(True)

            # Create or update the blue line
            if not hasattr(self, "b_line") or self.b_line is None:
                self.b_line = self.scene.addLine(b_x, 0, b_x, 360, QPen(Qt.GlobalColor.blue))
            else:
                self.b_line.setLine(b_x, 0, b_x, 360)
            self.b_line.setVisible(True)


def build_curve_lut(curve_func, size=65536):
    """
    Build a LUT of length 'size' that maps float in [0..1] to [0..1],
    using your existing PCHIP curve_func(x) which is defined on x in [0..360].
    We'll do:
       mapped = 360 - curve_func(x)
       out = clamp( mapped / 360, [0..1] )
    """
    lut = np.zeros(size, dtype=np.float32)
    for i in range(size):
        v = i / (size - 1)  # in [0..1]
        x = v * 360.0
        mapped = 360.0 - curve_func(x)
        outv = mapped / 360.0
        if outv < 0.0: outv = 0.0
        elif outv > 1.0: outv = 1.0
        lut[i] = outv
    return lut


class FullCurvesProcessingThread(QThread):
    result_ready = pyqtSignal(np.ndarray)

    def __init__(self, image, curve_mode, curve_func):
        super().__init__()
        self.image = image
        self.curve_mode = curve_mode
        self.curve_func = curve_func

    def run(self):
        adjusted_image = self.process_curve(self.image, self.curve_mode, self.curve_func)
        self.result_ready.emit(adjusted_image)

    @staticmethod
    def process_curve(image, curve_mode, curve_func):
        import numpy as np

        if image is None or curve_func is None:
            return image

        # Ensure image is float32 [0..1]
        if image.dtype != np.float32:
            image = image.astype(np.float32, copy=False)

        # Build a big LUT
        lut = build_curve_lut(curve_func, size=65536)

        # Determine if image is mono
        is_gray = (image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1))
        if is_gray:
            # Convert to 2D if needed
            if image.ndim == 3:
                image = image.reshape(image.shape[0], image.shape[1])
            # For mono images, no matter if the mode is "R", "G", "B", or "K (Brightness)",
            # we simply apply the LUT to the entire image.
            out = image.copy()
            apply_lut_mono_inplace(out, lut)
            return out  # Return a 2D array for mono images.



        # ----------------------------------------------------------------------
        # R/G/B/K (Brightness) => direct LUT application
        # ----------------------------------------------------------------------
        mode = curve_mode.lower()
        if mode == 'r':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 0], lut)
            return out
        elif mode == 'g':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 1], lut)
            return out
        elif mode == 'b':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 2], lut)
            return out
        elif mode == 'k (brightness)':
            out = image.copy()
            apply_lut_color_inplace(out, lut)
            return out

        # -------------------------------------------------------
        # L*, a*, b*, Chroma => do color transform => apply LUT => transform back
        # -------------------------------------------------------
        elif mode in ["l*", "a*", "b*", "chroma"]:
            # 1) Convert RGB -> XYZ -> Lab via Numba
            xyz = rgb_to_xyz_numba(image)             # Numba-based
            lab = xyz_to_lab_numba(xyz)               # Numba-based

            if mode == "l*":
                # L in [0..100]
                L = lab[..., 0] / 100.0
                apply_lut_mono_inplace(L, lut)
                lab[..., 0] = L * 100.0

            elif mode == "a*":
                # a in [-128..127], shift => [0..255], then /255 => [0..1]
                a = lab[..., 1]
                a_norm = (a + 128.0) / 255.0
                a_norm = np.clip(a_norm, 0, 1)
                apply_lut_mono_inplace(a_norm, lut)
                lab[..., 1] = a_norm * 255.0 - 128.0

            elif mode == "b*":
                # b in [-128..127]
                b = lab[..., 2]
                b_norm = (b + 128.0) / 255.0
                b_norm = np.clip(b_norm, 0, 1)
                apply_lut_mono_inplace(b_norm, lut)
                lab[..., 2] = b_norm * 255.0 - 128.0

            elif mode == "chroma":
                a_ = lab[..., 1]
                b_ = lab[..., 2]
                C = np.sqrt(a_ * a_ + b_ * b_)
                C_norm = np.clip(C / 200.0, 0, 1)
                apply_lut_mono_inplace(C_norm, lut)
                C_new = C_norm * 200.0
                ratio = np.divide(C_new, C, out=np.zeros_like(C), where=(C != 0))
                lab[..., 1] = a_ * ratio
                lab[..., 2] = b_ * ratio

            # Convert Lab -> XYZ -> RGB
            xyz_new = lab_to_xyz_numba(lab)           # Numba-based
            out = xyz_to_rgb_numba(xyz_new)           # Numba-based
            return out

        # -------------------------------------------------------
        # HSV saturation => same approach
        # -------------------------------------------------------
        elif mode == "saturation":
            hsv = rgb_to_hsv_numba(image)             # Numba-based
            S = hsv[..., 1]
            apply_lut_mono_inplace(S, lut)
            hsv[..., 1] = S
            out = hsv_to_rgb_numba(hsv)               # Numba-based
            return out

        # If none matched, just return the image
        return image

    @staticmethod
    def rgb_to_xyz(rgb):
        M = np.array([[0.4124564, 0.3575761, 0.1804375],
                      [0.2126729, 0.7151522, 0.0721750],
                      [0.0193339, 0.1191920, 0.9503041]], dtype=np.float32)
        shape = rgb.shape
        out = rgb.reshape(-1,3) @ M.T
        return out.reshape(shape)

    @staticmethod
    def xyz_to_rgb(xyz):
        M_inv = np.array([[ 3.2404542, -1.5371385, -0.4985314],
                          [-0.9692660,  1.8760108,  0.0415560],
                          [ 0.0556434, -0.2040259,  1.0572252]], dtype=np.float32)
        shape = xyz.shape
        out = xyz.reshape(-1,3) @ M_inv.T
        out = np.clip(out, 0, 1)
        return out.reshape(shape)

    @staticmethod
    def f_lab(t):
        delta = 6/29
        mask = t > delta**3
        f = np.zeros_like(t)
        f[mask] = np.cbrt(t[mask])
        f[~mask] = t[~mask]/(3*delta*delta)+4/29
        return f

    @staticmethod
    def xyz_to_lab(xyz):
        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = xyz[:,:,0]/Xn
        Y = xyz[:,:,1]/Yn
        Z = xyz[:,:,2]/Zn

        fx = FullCurvesProcessingThread.f_lab(X)
        fy = FullCurvesProcessingThread.f_lab(Y)
        fz = FullCurvesProcessingThread.f_lab(Z)

        L = (116 * fy - 16)
        a = 500*(fx - fy)
        b = 200*(fy - fz)
        return np.dstack([L, a, b]).astype(np.float32)

    @staticmethod
    def lab_to_xyz(lab):
        L = lab[:,:,0]
        a = lab[:,:,1]
        b = lab[:,:,2]

        delta = 6/29
        fy = (L+16)/116
        fx = fy + a/500
        fz = fy - b/200

        def f_inv(ft):
            return np.where(ft > delta, ft**3, 3*delta*delta*(ft - 4/29))

        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = Xn*f_inv(fx)
        Y = Yn*f_inv(fy)
        Z = Zn*f_inv(fz)
        return np.dstack([X, Y, Z]).astype(np.float32)

    @staticmethod
    def rgb_to_hsv(rgb):
        cmax = rgb.max(axis=2)
        cmin = rgb.min(axis=2)
        delta = cmax - cmin

        H = np.zeros_like(cmax)
        S = np.zeros_like(cmax)
        V = cmax

        mask = delta != 0
        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
        H[mask & (cmax==r)] = 60*(((g[mask&(cmax==r)]-b[mask&(cmax==r)])/delta[mask&(cmax==r)])%6)
        H[mask & (cmax==g)] = 60*(((b[mask&(cmax==g)]-r[mask&(cmax==g)])/delta[mask&(cmax==g)])+2)
        H[mask & (cmax==b)] = 60*(((r[mask&(cmax==b)]-g[mask&(cmax==b)])/delta[mask&(cmax==b)])+4)

        S[cmax>0] = delta[cmax>0]/cmax[cmax>0]
        return np.dstack([H,S,V]).astype(np.float32)

    @staticmethod
    def hsv_to_rgb(hsv):
        H, S, V = hsv[:,:,0], hsv[:,:,1], hsv[:,:,2]
        C = V*S
        X = C*(1-np.abs((H/60.0)%2-1))
        m = V-C

        R = np.zeros_like(H)
        G = np.zeros_like(H)
        B = np.zeros_like(H)

        cond0 = (H<60)
        cond1 = (H>=60)&(H<120)
        cond2 = (H>=120)&(H<180)
        cond3 = (H>=180)&(H<240)
        cond4 = (H>=240)&(H<300)
        cond5 = (H>=300)

        R[cond0]=C[cond0]; G[cond0]=X[cond0]; B[cond0]=0
        R[cond1]=X[cond1]; G[cond1]=C[cond1]; B[cond1]=0
        R[cond2]=0; G[cond2]=C[cond2]; B[cond2]=X[cond2]
        R[cond3]=0; G[cond3]=X[cond3]; B[cond3]=C[cond3]
        R[cond4]=X[cond4]; G[cond4]=0; B[cond4]=C[cond4]
        R[cond5]=C[cond5]; G[cond5]=0; B[cond5]=X[cond5]

        rgb = np.dstack([R+m, G+m, B+m])
        rgb = np.clip(rgb, 0, 1)
        return rgb

class FrequencySeperationTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the shared ImageManager
        self.filename = None
        self.image = None  # Original input image
        self.low_freq_image = None
        self.high_freq_image = None
        self.original_header = None
        self.is_mono = False
        self.processing_thread = None
        self.hfEnhancementThread = None
        self.hf_history = []

        # Default parameters
        self.method = 'Gaussian'
        self.radius = 25
        self.mirror = False
        self.tolerance = 50  # new tolerance param

        # Zoom/pan control
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        # For the preview
        self.spinnerLabel = None
        self.spinnerMovie = None

        # A guard variable to avoid infinite scroll loops
        self.syncing_scroll = False

        self.initUI()

        # Connect to ImageManager's image_changed signal if available
        if self.image_manager:
            self.image_manager.image_changed.connect(self.on_image_changed)
            # Load the existing image from ImageManager, if any
            if self.image_manager.image is not None:
                self.on_image_changed(
                    slot=self.image_manager.current_slot,
                    image=self.image_manager.image,
                    metadata=self.image_manager.current_metadata
                )

    def initUI(self):
        """
        Set up the GUI layout:
          - Left panel with controls (Load, Method, Radius, Mirror, Tolerance, Apply, Save, etc.)
          - Right panel with two scroll areas for HF/LF previews
        """
        main_layout = QHBoxLayout(self)
        self.setLayout(main_layout)

        # -----------------------------
        # Left side: Controls
        # -----------------------------
        left_widget = QWidget(self)
        left_widget.setFixedWidth(250)
        left_layout = QVBoxLayout(left_widget)

        # 1) Load image
        self.loadButton = QPushButton("Load Image", self)
        self.loadButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DirOpenIcon))
        self.loadButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.loadButton)

        self.fileLabel = QLabel("", self)
        left_layout.addWidget(self.fileLabel)

        # Method Combo
        self.method_combo = QComboBox(self)
        self.method_combo.addItems(['Gaussian', 'Median', 'Bilateral'])
        self.method_combo.currentTextChanged.connect(self.on_method_changed)
        left_layout.addWidget(QLabel("Method:", self))
        left_layout.addWidget(self.method_combo)

        # Radius Slider + Label
        self.radiusSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.radiusSlider.setRange(1, 100)
        self.radiusSlider.setValue(10)  # or whatever integer in [1..100] you want
        self.radiusSlider.valueChanged.connect(self.on_radius_changed)

        self.radiusLabel = QLabel("Radius:", self)
        left_layout.addWidget(self.radiusLabel)   
        left_layout.addWidget(self.radiusSlider)

        # Now force an initial update so label is correct from the start
        self.on_radius_changed(self.radiusSlider.value())

        # Tolerance Slider + Label
        self.toleranceSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.toleranceSlider.setRange(0, 100)
        self.toleranceSlider.setValue(self.tolerance)
        self.toleranceSlider.valueChanged.connect(self.on_tolerance_changed)
        self.toleranceLabel = QLabel(f"Tolerance: {self.tolerance}%", self)
        self.toleranceSlider.setEnabled(False)
        self.toleranceLabel.setEnabled(False)
        left_layout.addWidget(self.toleranceLabel)
        left_layout.addWidget(self.toleranceSlider)

        # Apply button
        self.applyButton = QPushButton("Apply - Split HF and LF", self)
        self.applyButton.clicked.connect(self.apply_frequency_separation)
        left_layout.addWidget(self.applyButton)        

        # -----------------------------------
        # *** New Sharpening Controls ***
        # -----------------------------------
        # 1) Checkbox for "Enable Sharpen Scale"
        self.sharpenScaleCheckBox = QCheckBox("Enable Sharpen Scale", self)
        self.sharpenScaleCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.sharpenScaleCheckBox)

        # Sharpen Scale Label + Slider
        self.sharpenScaleLabel = QLabel("Sharpen Scale: 1.00", self)
        left_layout.addWidget(self.sharpenScaleLabel)

        self.sharpenScaleSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.sharpenScaleSlider.setRange(10, 300)  # => 0.1..3.0
        self.sharpenScaleSlider.setValue(100)      # 1.00 initially
        self.sharpenScaleSlider.valueChanged.connect(self.onSharpenScaleChanged)
        left_layout.addWidget(self.sharpenScaleSlider)

        # 2) Checkbox for "Enable Wavelet Sharpening"
        self.waveletCheckBox = QCheckBox("Enable Wavelet Sharpening", self)
        self.waveletCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.waveletCheckBox)

        # Wavelet Sharpening Sliders
        wavelet_title = QLabel("<b>Wavelet Sharpening:</b>", self)
        left_layout.addWidget(wavelet_title)

        self.waveletLevelLabel = QLabel("Wavelet Level: 2", self)
        left_layout.addWidget(self.waveletLevelLabel)

        self.waveletLevelSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletLevelSlider.setRange(1, 5)
        self.waveletLevelSlider.setValue(2)
        self.waveletLevelSlider.valueChanged.connect(self.onWaveletLevelChanged)
        left_layout.addWidget(self.waveletLevelSlider)

        self.waveletBoostLabel = QLabel("Wavelet Boost: 1.20", self)
        left_layout.addWidget(self.waveletBoostLabel)

        self.waveletBoostSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletBoostSlider.setRange(50, 300)  # => 0.5..3.0
        self.waveletBoostSlider.setValue(120)      # 1.20 initially
        self.waveletBoostSlider.valueChanged.connect(self.onWaveletBoostChanged)
        left_layout.addWidget(self.waveletBoostSlider)

        self.enableDenoiseCheckBox = QCheckBox("Enable HF Denoise", self)
        self.enableDenoiseCheckBox.setChecked(False)  # default off or on, your choice
        left_layout.addWidget(self.enableDenoiseCheckBox)

        # Label + Slider for denoise strength
        self.denoiseStrengthLabel = QLabel("Denoise Strength: 3.00", self)
        left_layout.addWidget(self.denoiseStrengthLabel)

        self.denoiseStrengthSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.denoiseStrengthSlider.setRange(0, 50)  # Example range -> 1..50 => 1.0..50.0
        self.denoiseStrengthSlider.setValue(3)      # default 3
        self.denoiseStrengthSlider.valueChanged.connect(self.onDenoiseStrengthChanged)
        left_layout.addWidget(self.denoiseStrengthSlider)
        self.onDenoiseStrengthChanged(self.denoiseStrengthSlider.value())

        # Create a horizontal layout for HF Enhancements and Undo
        hfEnhance_hlayout = QHBoxLayout()

        # Apply HF Enhancements button
        self.applyHFEnhancementsButton = QPushButton("Apply HF Enhancements", self)
        self.applyHFEnhancementsButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        self.applyHFEnhancementsButton.clicked.connect(self.applyHFEnhancements)
        hfEnhance_hlayout.addWidget(self.applyHFEnhancementsButton)

        # Undo button (tool button with back arrow icon)
        self.undoHFButton = QToolButton(self)
        self.undoHFButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack))
        self.undoHFButton.setToolTip("Undo last HF enhancement")
        self.undoHFButton.clicked.connect(self.undoHFEnhancement)
        self.undoHFButton.setEnabled(False)  # Initially disabled
        hfEnhance_hlayout.addWidget(self.undoHFButton)

        # Now add this horizontal layout to the main left_layout
        left_layout.addLayout(hfEnhance_hlayout)

        # ------------------------------------
        # Save HF / LF - in a horizontal layout
        # ------------------------------------
        save_hlayout = QHBoxLayout()

        self.saveHFButton = QPushButton("Save HF", self)
        self.saveHFButton.clicked.connect(self.save_high_frequency)
        save_hlayout.addWidget(self.saveHFButton)

        self.saveLFButton = QPushButton("Save LF", self)
        self.saveLFButton.clicked.connect(self.save_low_frequency)
        save_hlayout.addWidget(self.saveLFButton)

        left_layout.addLayout(save_hlayout)

        # ------------------------------------
        # Import HF / LF - in a separate horizontal layout
        # ------------------------------------
        load_hlayout = QHBoxLayout()

        self.importHFButton = QPushButton("Load HF", self)
        self.importHFButton.clicked.connect(self.loadHF)
        load_hlayout.addWidget(self.importHFButton)

        self.importLFButton = QPushButton("Load LF", self)
        self.importLFButton.clicked.connect(self.loadLF)
        load_hlayout.addWidget(self.importLFButton)

        left_layout.addLayout(load_hlayout)

        # Combine HF + LF
        self.combineButton = QPushButton("Combine HF + LF", self)
        self.combineButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogYesButton))
        self.combineButton.clicked.connect(self.combineHFandLF)
        left_layout.addWidget(self.combineButton)

        # Spinner for background processing
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Provide your spinner path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()
        left_layout.addWidget(self.spinnerLabel)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # -----------------------------
        # Right Panel (vertical layout)
        # -----------------------------
        right_widget = QWidget(self)
        right_vbox = QVBoxLayout(right_widget)

        # 1) Zoom Buttons row (top)
        zoom_hbox = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In")
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        zoom_hbox.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out")
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        zoom_hbox.addWidget(self.zoom_out_btn)

        right_vbox.addLayout(zoom_hbox)

        # 2) HF / LF previews row (below)
        scroll_hbox = QHBoxLayout()

        self.scrollHF = QScrollArea(self)
        self.scrollHF.setWidgetResizable(False)
        self.labelHF = QLabel("High Frequency", self)
        self.labelHF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelHF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollHF.setWidget(self.labelHF)

        self.scrollLF = QScrollArea(self)
        self.scrollLF.setWidgetResizable(False)
        self.labelLF = QLabel("Low Frequency", self)
        self.labelLF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelLF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollLF.setWidget(self.labelLF)

        scroll_hbox.addWidget(self.scrollHF, stretch=1)
        scroll_hbox.addWidget(self.scrollLF, stretch=1)

        right_vbox.addLayout(scroll_hbox, stretch=1)
        main_layout.addWidget(right_widget, stretch=1)

        # Sync scrollbars
        self.scrollHF.horizontalScrollBar().valueChanged.connect(self.syncHFHScroll)
        self.scrollHF.verticalScrollBar().valueChanged.connect(self.syncHFVScroll)
        self.scrollLF.horizontalScrollBar().valueChanged.connect(self.syncLFHScroll)
        self.scrollLF.verticalScrollBar().valueChanged.connect(self.syncLFVScroll)

        # Mouse drag panning
        self.scrollHF.viewport().installEventFilter(self)
        self.scrollLF.viewport().installEventFilter(self)

        # Force initial label update
        self.on_radius_changed(self.radiusSlider.value())
        self.on_tolerance_changed(self.toleranceSlider.value())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    # -----------------------------
    # Image Manager Integration
    # -----------------------------
    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the FrequencySeperationTab if the change is relevant.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if needed

            # Update internal state with the new image and metadata
            self.loaded_image_path = metadata.get('file_path', None)
            self.image = image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = self.loaded_image_path

            # Reset HF / LF placeholders
            self.low_freq_image = None
            self.high_freq_image = None

            # Update UI label to show the file name or indicate no file
            # Update the fileLabel in the Frequency Separation Tab (or any other tab)
            if self.image_manager.image is not None:
                # Retrieve the file path from the metadata in ImageManager
                file_path = self.image_manager._metadata[self.image_manager.current_slot].get('file_path', None)

                # If file_path is a string, get the basename; otherwise, use a default message.
                if file_path and isinstance(file_path, str):
                    display_name = os.path.basename(file_path)
                else:
                    display_name = "No file selected"

                self.fileLabel.setText(display_name)
            else:
                self.fileLabel.setText("No file selected")


            # Automatically apply frequency separation
            self.apply_frequency_separation()

            print(f"FrequencySeperationTab: Image updated from ImageManager slot {slot}.")


    def map_slider_to_radius(self, slider_pos):
        """
        Convert a slider position (0..100) into a non-linear float radius.
        Segment A: [0..10]   -> [0.1..1.0]
        Segment B: [10..50]  -> [1.0..10.0]
        Segment C: [50..100] -> [10.0..100.0]
        """
        if slider_pos <= 10:
            # Scale 0..10 -> 0.1..1.0
            t = slider_pos / 10.0           # t in [0..1]
            radius = 0.1 + t*(1.0 - 0.1)    # 0.1 -> 1.0
        elif slider_pos <= 50:
            # Scale 10..50 -> 1.0..10.0
            t = (slider_pos - 10) / 40.0    # t in [0..1]
            radius = 1.0 + t*(10.0 - 1.0)   # 1.0 -> 10.0
        else:
            # Scale 50..100 -> 10.0..100.0
            t = (slider_pos - 50) / 50.0    # t in [0..1]
            radius = 10.0 + t*(100.0 - 10.0)  # 10.0 -> 100.0
        
        return radius

    def onSharpenScaleChanged(self, val):
        scale = val / 100.0  # 10..300 => 0.1..3.0
        self.sharpenScaleLabel.setText(f"Sharpen Scale: {scale:.2f}")

    def onWaveletLevelChanged(self, val):
        self.waveletLevelLabel.setText(f"Wavelet Level: {val}")

    def onWaveletBoostChanged(self, val):
        boost = val / 100.0  # e.g. 50..300 => 0.50..3.00
        self.waveletBoostLabel.setText(f"Wavelet Boost: {boost:.2f}")

    def onDenoiseStrengthChanged(self, val):
        # Map 0..50 => 0..5.0 by dividing by 10
        denoise_strength = val / 10.0
        self.denoiseStrengthLabel.setText(f"Denoise Strength: {denoise_strength:.2f}")

    # -------------------------------------------------
    # Event Filter for Drag Panning
    # -------------------------------------------------
    def eventFilter(self, obj, event):
        if obj in (self.scrollHF.viewport(), self.scrollLF.viewport()):
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()

                if obj == self.scrollHF.viewport():
                    # Move HF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync LF
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                else:
                    # Move LF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync HF
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(obj, event)

    # -----------------------------
    # Scrolling Sync
    # -----------------------------
    def syncHFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncHFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    # -----------------------------
    # Zooming
    # -----------------------------

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.25
        self.update_previews()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.25
        self.update_previews()

    # -----------------------------
    # Control Handlers
    # -----------------------------
    def on_method_changed(self, text):
        """
        Called whenever the method dropdown changes (Gaussian, Median, Bilateral).
        Enable the tolerance slider only for 'Bilateral'.
        """
        self.method = text
        if self.method == 'Bilateral':
            self.toleranceSlider.setEnabled(True)
            self.toleranceLabel.setEnabled(True)
        else:
            self.toleranceSlider.setEnabled(False)
            self.toleranceLabel.setEnabled(False)

    def on_radius_changed(self, value):
        new_radius = self.map_slider_to_radius(value)  # use self.
        self.radius = new_radius
        self.radiusLabel.setText(f"Radius: {new_radius:.2f}")


    def on_tolerance_changed(self, value):
        self.tolerance = value
        self.toleranceLabel.setText(f"Tolerance: {value}%")  # Update label

    def undoHFEnhancement(self):
        """
        Revert HF to the last state from hf_history, if available.
        Disable Undo if no more history is left.
        """
        if len(self.hf_history) == 0:
            return  # No history to revert
        
        # Pop the last saved HF
        old_hf = self.hf_history.pop()

        # Restore it
        self.high_freq_image = old_hf
        self.update_previews()
        self.fileLabel.setText("Undid last HF enhancement.")

        # If no more states are left, disable the Undo button again
        if len(self.hf_history) == 0:
            self.undoHFButton.setEnabled(False)


    def applyHFEnhancements(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No HF image to enhance.")
            return
        
        self.hf_history.append(self.high_freq_image.copy())

        # Enable the Undo button because now we have at least one state
        self.undoHFButton.setEnabled(True)

        self.showSpinner()

        # If a previous thread is running, kill it safely
        if self.hfEnhancementThread and self.hfEnhancementThread.isRunning():
            self.hfEnhancementThread.quit()
            self.hfEnhancementThread.wait()

        # Check Sharpen Scale
        enable_scale = self.sharpenScaleCheckBox.isChecked()
        sharpen_scale = self.sharpenScaleSlider.value() / 100.0

        # Wavelet
        enable_wavelet = self.waveletCheckBox.isChecked()
        wavelet_level = self.waveletLevelSlider.value()
        wavelet_boost = self.waveletBoostSlider.value() / 100.0

        # Denoise
        enable_denoise = self.enableDenoiseCheckBox.isChecked()
        denoise_strength = float(self.denoiseStrengthSlider.value()/10.0)  # or do /10 if you want finer steps

        # Instantiate HFEnhancementThread with denoise params
        self.hfEnhancementThread = HFEnhancementThread(
            hf_image=self.high_freq_image,
            enable_scale=enable_scale,
            sharpen_scale=sharpen_scale,
            enable_wavelet=enable_wavelet,
            wavelet_level=wavelet_level,
            wavelet_boost=wavelet_boost,
            wavelet_name='db2',
            enable_denoise=enable_denoise,
            denoise_strength=denoise_strength
        )
        self.hfEnhancementThread.enhancement_done.connect(self.onHFEnhancementDone)
        self.hfEnhancementThread.error_signal.connect(self.onHFEnhancementError)
        self.hfEnhancementThread.start()


    def onHFEnhancementDone(self, newHF):
        self.hideSpinner()
        self.high_freq_image = newHF  # updated HF
        self.update_previews()
        self.fileLabel.setText("HF enhancements applied (thread).")

    def onHFEnhancementError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"HF enhancement error: {msg}")

    # -----------------------------
    # Image Selection and Preview Methods
    # -----------------------------
    def selectImage(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        selected_file, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if selected_file:
            try:
                img, header, bit_depth, is_mono = load_image(selected_file)
                if img is None:
                    QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                    return

                print(f"FrequencySeperationTab: Image loaded successfully. Shape: {img.shape}, Dtype: {img.dtype}")

                self.image = img
                self.original_header = header
                self.is_mono = is_mono
                self.filename = selected_file
                self.fileLabel.setText(os.path.basename(selected_file))

                # Reset HF / LF placeholders
                self.low_freq_image = None
                self.high_freq_image = None

                # Update ImageManager with the new image
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': bit_depth,
                    'is_mono': self.is_mono
                }
                self.image_manager.set_current_image(image=img, metadata=metadata)
                print("FrequencySeperationTab: Image updated in ImageManager.")

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"FrequencySeperationTab: Error loading image: {e}")

    def save_high_frequency(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No high-frequency image to save.")
            return
        self._save_image_with_dialog(self.high_freq_image, suffix="_HF")

    def save_low_frequency(self):
        if self.low_freq_image is None:
            self.fileLabel.setText("No low-frequency image to save.")
            return
        self._save_image_with_dialog(self.low_freq_image, suffix="_LF")

    def _save_image_with_dialog(self, image_to_save, suffix=""):
        """
        Always save HF in 32-bit floating point, either .tif or .fits.
        """
        if self.filename:
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + suffix + '.tif'
            original_dir = os.path.dirname(self.filename)
        else:
            default_save_name = "untitled" + suffix + '.tif'
            original_dir = os.getcwd()

        # Restrict the file dialog to TIF/FITS by default,
        # but let's keep .png, etc., in case user tries to pick it.
        # We'll override if they do.
        save_filename, _ = QFileDialog.getSaveFileName(
            self,
            'Save HF Image as 32-bit Float',
            os.path.join(original_dir, default_save_name),
            'TIFF or FITS (*.tif *.tiff *.fits *.fit);;All Files (*)'
        )
        if save_filename:
            # Identify extension
            file_ext = os.path.splitext(save_filename)[1].lower().strip('.')  # e.g. 'tif', 'fits', etc.

            # If user picks something else (png/jpg), override to .tif
            if file_ext not in ['tif', 'tiff', 'fit', 'fits']:
                file_ext = 'tif'
                # Force the filename to end with .tif
                save_filename = os.path.splitext(save_filename)[0] + '.tif'

            # We skip prompting for bit depth since we always want 32-bit float
            bit_depth = "32-bit floating point"

            # Force original_format to the extension we ended up with
            save_image(
                image_to_save,
                save_filename,
                original_format=file_ext,     # e.g. 'tif' or 'fits'
                bit_depth=bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            self.fileLabel.setText(f"Saved 32-bit float HF: {os.path.basename(save_filename)}")


    def loadHF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load High Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                hf, _, _, _ = load_image(selected_file)
                self.high_freq_image = hf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading HF: {str(e)}")

    def loadLF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load Low Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                lf, _, _, _ = load_image(selected_file)
                self.low_freq_image = lf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading LF: {str(e)}")

    def combineHFandLF(self):
        if self.low_freq_image is None or self.high_freq_image is None:
            self.fileLabel.setText("Cannot combine; LF or HF is missing.")
            return

        # Check shape
        if self.low_freq_image.shape != self.high_freq_image.shape:
            self.fileLabel.setText("Error: LF and HF dimensions do not match.")
            return

        # Combine
        combined = self.low_freq_image + self.high_freq_image
        combined = np.clip(combined, 0, 1)  # Ensure values are within [0,1]

        # Retrieve the active mask
        mask = self.get_active_mask()

        if mask is not None:
            # If combined image is multi-channel but mask is single-channel, expand mask dimensions
            if combined.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)

            # Ensure mask dimensions match the combined image dimensions
            if mask.shape[:2] != combined.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the combined image dimensions.")
                return

            # Blend the combined image with the original image using the mask
            # Formula: blended_combined = combined * mask + original_image * (1 - mask)
            blended_combined = combined * mask + self.image * (1 - mask)
            blended_combined = np.clip(blended_combined, 0.0, 1.0)  # Ensure values are within [0,1]
            print("Combined image with mask applied.")
        else:
            # No mask applied; use the combined image directly
            blended_combined = combined
            print("Combined image without mask.")

        # Create a new preview window (non-modal) with the blended combined image
        self.combined_window = CombinedPreviewWindow(
            blended_combined, 
            image_manager=self.image_manager,
            original_header=self.original_header,
            is_mono=self.is_mono
        )
        # Show it. Because we use `show()`, it won't block the main UI
        self.combined_window.show()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Combined image with mask applied.")
        else:
            self.fileLabel.setText("Combined image without mask.")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    # -----------------------------
    # Applying Frequency Separation (background thread)
    # -----------------------------
    def apply_frequency_separation(self):
        if self.image is None:
            self.fileLabel.setText("No input image loaded.")
            return

        self.showSpinner()

        if self.processing_thread and self.processing_thread.isRunning():
            self.processing_thread.quit()
            self.processing_thread.wait()

        # pass in 'tolerance' too
        self.processing_thread = FrequencySeperationThread(
            image=self.image,
            method=self.method,
            radius=self.radius,
            tolerance=self.tolerance
        )
        self.processing_thread.separation_done.connect(self.onSeparationDone)
        self.processing_thread.error_signal.connect(self.onSeparationError)
        self.processing_thread.start()

    def onSeparationDone(self, lf, hf):
        self.hideSpinner()
        self.low_freq_image = lf
        self.high_freq_image = hf
        self.update_previews()

    def onSeparationError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"Error during separation: {msg}")

    # -----------------------------
    # Spinner control
    # -----------------------------
    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # -----------------------------
    # Preview
    # -----------------------------
    def update_previews(self):
        """
        Render HF/LF images with current zoom_factor.
        HF gets an offset of +0.5 for display.
        """
        # Low Frequency
        if self.low_freq_image is not None:
            lf_disp = np.clip(self.low_freq_image, 0, 1)
            pixmap_lf = self._numpy_to_qpixmap(lf_disp)
            # Scale by zoom_factor (cast to int)
            scaled_lf = pixmap_lf.scaled(
                int(pixmap_lf.width() * self.zoom_factor),
                int(pixmap_lf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelLF.setPixmap(scaled_lf)
            self.labelLF.resize(scaled_lf.size())
        else:
            self.labelLF.setText("Low Frequency")
            self.labelLF.resize(self.labelLF.sizeHint())

        # High Frequency
        if self.high_freq_image is not None:
            hf_disp = self.high_freq_image + 0.5
            hf_disp = np.clip(hf_disp, 0, 1)
            pixmap_hf = self._numpy_to_qpixmap(hf_disp)
            scaled_hf = pixmap_hf.scaled(
                int(pixmap_hf.width() * self.zoom_factor),
                int(pixmap_hf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelHF.setPixmap(scaled_hf)
            self.labelHF.resize(scaled_hf.size())
        else:
            self.labelHF.setText("High Frequency")
            self.labelHF.resize(self.labelHF.sizeHint())

    def _numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to a QPixmap for display.
        """
        if img_float32.ndim == 2:
            img_float32 = np.stack([img_float32]*3, axis=-1)

        img_ubyte = (img_float32 * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_img = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_img)

class CombinedPreviewWindow(QWidget):
    """
    A pop-out window that shows the combined HF+LF image in a scrollable, zoomable preview.
    """
    def __init__(self, combined_image, image_manager, original_header=None, is_mono=False, parent=None):
        """
        :param combined_image: Float32 numpy array in [0,1], shape = (H,W) or (H,W,3).
        :param original_header: Optional metadata (for saving as FITS, etc.).
        :param is_mono: Boolean indicating grayscale vs. color.
        """
        super().__init__(parent)
        self.setWindowTitle("Combined HF + LF Preview")
        self.combined_image = combined_image
        self.image_manager = image_manager  # Reference to ImageManage
        self.original_header = original_header
        self.is_mono = is_mono

        # Zoom/panning
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        self.initUI()
        # Render the combined image initially
        self.updatePreview()

    def initUI(self):
        main_layout = QVBoxLayout(self)
        self.setLayout(main_layout)

        # --- Top: Zoom / Fit / Save Buttons ---
        top_btn_layout = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In", self)
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        top_btn_layout.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out", self)
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        top_btn_layout.addWidget(self.zoom_out_btn)

        self.fit_btn = QPushButton("Fit to Preview", self)
        self.fit_btn.clicked.connect(self.fit_to_preview)
        top_btn_layout.addWidget(self.fit_btn)

        # New "Apply Changes" button
        self.apply_btn = QPushButton("Apply Changes/Push for Processing", self)
        self.apply_btn.clicked.connect(self.apply_changes)
        top_btn_layout.addWidget(self.apply_btn)

        main_layout.addLayout(top_btn_layout)

        # --- Scroll Area with a QLabel for image ---
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(False)
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Put the label inside the scroll area
        self.scrollArea.setWidget(self.imageLabel)
        main_layout.addWidget(self.scrollArea)

        # Enable mouse-drag panning
        self.scrollArea.viewport().installEventFilter(self)

        # Provide a decent default window size
        self.resize(1000, 600)

    def eventFilter(self, source, event):
        if source == self.scrollArea.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()
                # Adjust scrollbars
                self.scrollArea.horizontalScrollBar().setValue(
                    self.scrollArea.horizontalScrollBar().value() - delta.x()
                )
                self.scrollArea.verticalScrollBar().setValue(
                    self.scrollArea.verticalScrollBar().value() - delta.y()
                )
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def updatePreview(self):
        """
        Render the combined image into self.imageLabel at the current zoom_factor.
        """
        if self.combined_image is None:
            self.imageLabel.setText("No combined image.")
            return

        # Convert float32 [0,1] -> QPixmap
        pixmap = self.numpy_to_qpixmap(self.combined_image)
        # Scale by zoom_factor
        new_width = int(pixmap.width() * self.zoom_factor)
        new_height = int(pixmap.height() * self.zoom_factor)
        scaled = pixmap.scaled(new_width, new_height, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Update label
        self.imageLabel.setPixmap(scaled)
        self.imageLabel.resize(scaled.size())

    def numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to QPixmap.
        """
        if img_float32.ndim == 2:
            # grayscale
            img_float32 = np.stack([img_float32]*3, axis=-1)
        img_ubyte = (np.clip(img_float32, 0, 1) * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_image = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_image)

    # -----------------------------
    # Zoom
    # -----------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.updatePreview()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.updatePreview()

    def fit_to_preview(self):
        """
        Adjust zoom_factor so the combined image width fits in the scrollArea width.
        """
        if self.combined_image is None:
            return

        # Get the actual image size
        h, w = self.combined_image.shape[:2]
        # The scrollArea's viewport is how much space we have to show it
        viewport_width = self.scrollArea.viewport().width()

        # Estimate new zoom factor so image fits horizontally
        # (You could also consider fitting by height or whichever is smaller.)
        # Must convert w from image to display pixel scale.
        # We'll guess the "base" is 1.0 => original width => we guess that is w pixels wide
        # So new_zoom = viewport_width / (w in original scale).
        new_zoom = viewport_width / float(w)
        if new_zoom < 0.01:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.updatePreview()

    def apply_changes(self):
        """
        Push the combined image to ImageManager's slot 0 for further processing.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "No Image", "There is no combined image to apply.")
            return

        # Metadata for the combined image
        metadata = {
            'file_path': "Combined HF+LF Applied",
            'original_header': self.original_header,
            'is_mono': self.is_mono,
            'bit_depth': "32-bit floating point"
        }

        # Push the combined image to slot 0
        self.image_manager.set_image(self.combined_image, metadata, step_name="Frequency Separation")
        QMessageBox.information(self, "Changes Applied", "The combined image has been pushed to slot 0 for processing.")

        # Close the preview window (optional)
        self.close()       

class HFEnhancementThread(QThread):
    """
    A QThread that can:
      1) Scale HF by 'sharpen_scale' (if enabled)
      2) Wavelet-sharpen HF (if enabled)
      3) Denoise HF (if enabled)
    """
    enhancement_done = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(
        self, 
        hf_image, 
        enable_scale=True,
        sharpen_scale=1.0, 
        enable_wavelet=True,
        wavelet_level=2, 
        wavelet_boost=1.2, 
        wavelet_name='db2',
        enable_denoise=False,
        denoise_strength=3.0,
        parent=None
    ):
        super().__init__(parent)
        self.hf_image = hf_image
        self.enable_scale = enable_scale
        self.sharpen_scale = sharpen_scale
        self.enable_wavelet = enable_wavelet
        self.wavelet_level = wavelet_level
        self.wavelet_boost = wavelet_boost
        self.wavelet_name = wavelet_name
        self.enable_denoise = enable_denoise
        self.denoise_strength = denoise_strength

    def run(self):
        try:
            # Make a copy so we don't mutate the original
            enhanced_hf = self.hf_image.copy()

            # 1) Sharpen Scale
            if self.enable_scale:
                enhanced_hf *= self.sharpen_scale

            # 2) Wavelet Sharpen
            if self.enable_wavelet:
                enhanced_hf = self.wavelet_sharpen(
                    enhanced_hf,
                    wavelet=self.wavelet_name,
                    level=self.wavelet_level,
                    boost=self.wavelet_boost
                )

            # 3) Denoise
            if self.enable_denoise:
                enhanced_hf = self.denoise_hf(enhanced_hf, self.denoise_strength)

            self.enhancement_done.emit(enhanced_hf.astype(np.float32))
        except Exception as e:
            self.error_signal.emit(str(e))

    # -------------------------------------
    # Wavelet Sharpen Methods
    # -------------------------------------
    def wavelet_sharpen(self, hf, wavelet='db2', level=2, boost=1.2):
        """
        Apply wavelet sharpening to the HF image.
        Handles both color and monochrome images.
        """
        # Check if the image is color or mono
        if hf.ndim == 3 and hf.shape[2] == 3:
            # Color image: process each channel separately
            channels = []
            for c in range(3):
                c_data = hf[..., c]
                c_sharp = self.wavelet_sharpen_mono(c_data, wavelet, level, boost)
                channels.append(c_sharp)
            # Stack the channels back into a color image
            return np.stack(channels, axis=-1)
        else:
            # Monochrome image
            return self.wavelet_sharpen_mono(hf, wavelet, level, boost)

    def wavelet_sharpen_mono(self, mono_hf, wavelet, level, boost):
        """
        Apply wavelet sharpening to a single-channel (monochrome) HF image.
        Ensures that the output image has the same dimensions as the input.
        """
        # Perform wavelet decomposition with 'periodization' mode to preserve dimensions
        coeffs = pywt.wavedec2(mono_hf, wavelet=wavelet, level=level, mode='periodization')

        # Boost the detail coefficients
        new_coeffs = [coeffs[0]]  # Approximation coefficients remain unchanged
        for detail in coeffs[1:]:
            cH, cV, cD = detail
            cH *= boost
            cV *= boost
            cD *= boost
            new_coeffs.append((cH, cV, cD))

        # Reconstruct the image with 'periodization' mode
        result = pywt.waverec2(new_coeffs, wavelet=wavelet, mode='periodization')

        # Ensure the reconstructed image has the same shape as the original
        original_shape = mono_hf.shape
        reconstructed_shape = result.shape

        if reconstructed_shape != original_shape:
            # Calculate the difference in dimensions                                            
            delta_h = reconstructed_shape[0] - original_shape[0]
            delta_w = reconstructed_shape[1] - original_shape[1]

            # Crop the excess pixels if the reconstructed image is larger
            if delta_h > 0 or delta_w > 0:
                result = result[:original_shape[0], :original_shape[1]]
            # Pad the image with zeros if it's smaller (rare, but for robustness)
            elif delta_h < 0 or delta_w < 0:
                pad_h = max(-delta_h, 0)
                pad_w = max(-delta_w, 0)
                result = np.pad(result, 
                               ((0, pad_h), (0, pad_w)), 
                               mode='constant', 
                               constant_values=0)

        return result

    # -------------------------------------
    # Denoise HF
    # -------------------------------------
    def denoise_hf(self, hf, strength=3.0):
        """
        Use OpenCV's fastNlMeansDenoisingColored or fastNlMeansDenoising for HF.
        Because HF can be negative, we offset +0.5 -> [0..1], scale -> [0..255].
        """
        # If color
        if hf.ndim == 3 and hf.shape[2] == 3:
            bgr = cv2.cvtColor(hf, cv2.COLOR_RGB2BGR)
            tmp = np.clip(bgr + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            # fastNlMeansDenoisingColored(src, None, hColor, hLuminance, templateWindowSize, searchWindowSize)
            denoised8 = cv2.fastNlMeansDenoisingColored(tmp8, None, strength, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            denoised_rgb = cv2.cvtColor(denoised_f32, cv2.COLOR_BGR2RGB)
            return denoised_rgb
        else:
            # Mono
            tmp = np.clip(hf + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            denoised8 = cv2.fastNlMeansDenoising(tmp8, None, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            return denoised_f32

class FrequencySeperationThread(QThread):
    """
    A QThread that performs frequency separation on a float32 [0,1] image array.
    This keeps the GUI responsive while processing.

    Signals:
        separation_done(np.ndarray, np.ndarray):
            Emitted with (low_freq, high_freq) images when finished.
        error_signal(str):
            Emitted if an error or exception occurs.
    """

    # Signal emitted when separation is complete. 
    # The arguments are low-frequency (LF) and high-frequency (HF) images.
    separation_done = pyqtSignal(np.ndarray, np.ndarray)

    # Signal emitted if there's an error during processing
    error_signal = pyqtSignal(str)

    def __init__(self, image, method='Gaussian', radius=5, tolerance=50, parent=None):
        """
        :param image: Float32 NumPy array in [0,1], shape = (H,W) or (H,W,3).
        :param method: 'Gaussian', 'Median', or 'Bilateral' (default: 'Gaussian').
        :param radius: Numeric value controlling the filter's strength (e.g., Gaussian sigma).
        :param mirror: Boolean to indicate if border handling is mirrored (optional example param).
        """
        super().__init__(parent)
        self.image = image
        self.method = method
        self.radius = radius
        self.tolerance = tolerance

    def run(self):
        try:
            # Convert the input image from RGB to BGR if it's 3-channel
            if self.image.ndim == 3 and self.image.shape[2] == 3:
                bgr = cv2.cvtColor(self.image, cv2.COLOR_RGB2BGR)
            else:
                # If mono, just use it as is
                bgr = self.image.copy()

            # Choose the filter based on self.method
            if self.method == 'Gaussian':
                # For Gaussian, interpret radius as sigma
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)
            elif self.method == 'Median':
                # For Median, the radius is the kernel size (must be odd)
                ksize = max(1, int(self.radius) // 2 * 2 + 1)
                low_bgr = cv2.medianBlur(bgr, ksize)
            elif self.method == 'Bilateral':
                # Example usage: interpret "tolerance" as a fraction of the default 50
                # so if tolerance=50 => sigmaColor=50*(50/100)=25, sigmaSpace=25
                # Or do your own logic for how tolerance modifies Bilateral
                sigma = 50 * (self.tolerance / 100.0)
                d = int(self.radius)
                low_bgr = cv2.bilateralFilter(bgr, d, sigma, sigma)
            else:
                # Fallback to Gaussian if unknown
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)

            # Convert low frequency image back to RGB if it's 3-channel
            if low_bgr.ndim == 3 and low_bgr.shape[2] == 3:
                low_rgb = cv2.cvtColor(low_bgr, cv2.COLOR_BGR2RGB)
            else:
                low_rgb = low_bgr

            # Calculate the high frequency
            # (note: keep in float32 to preserve negative/positive values)
            high_rgb = self.image - low_rgb

            # Emit the results
            self.separation_done.emit(low_rgb, high_rgb)

        except Exception as e:
            # Any error gets reported via the error_signal
            self.error_signal.emit(str(e))



class PalettePickerProcessingThread(QThread):
    """
    Thread for processing images to prevent UI freezing.
    """
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image, oiii_image, sii_image, osc1_image, osc2_image, ha_to_oii_ratio, enable_star_stretch, stretch_factor):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc1_image = osc1_image  # Added for OSC1
        self.osc2_image = osc2_image  # Added for OSC2
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        """
        Perform image processing to generate a combined preview.
        """
        try:
            combined_ha = self.ha_image.copy() if self.ha_image is not None else None
            combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None

            # Process OSC1 if available
            if self.osc1_image is not None:
                # Extract synthetic Ha and OIII from OSC1
                ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
                oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc1 = stretch_mono_image(ha_osc1, target_median=self.stretch_factor)
                    oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
                else:
                    combined_ha = ha_osc1

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
                else:
                    combined_oiii = oiii_osc1

            # Process OSC2 if available
            if self.osc2_image is not None:
                # Extract synthetic Ha and OIII from OSC2
                ha_osc2 = self.osc2_image[:, :, 0]  # Red channel -> Ha
                oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc2 = stretch_mono_image(ha_osc2, target_median=self.stretch_factor)
                    oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc2 * 0.5)
                else:
                    combined_ha = ha_osc2

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
                else:
                    combined_oiii = oiii_osc2

            # Ensure that combined Ha and OIII are present
            if combined_ha is not None and combined_oiii is not None:
                # Combine Ha and OIII based on the specified ratio
                combined = (combined_ha * self.ha_to_oii_ratio) + (combined_oiii * (1 - self.ha_to_oii_ratio))

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    combined = stretch_mono_image(combined, target_median=self.stretch_factor)

                # Incorporate SII channel if available
                if self.sii_image is not None:
                    combined = combined + self.sii_image
                    # Normalize to prevent overflow
                    combined = self.normalize_image(combined)

                self.preview_generated.emit(combined)
            else:
                # If required channels are missing, emit a dummy image or handle accordingly
                combined = np.zeros((100, 100, 3))  # Dummy image
                self.preview_generated.emit(combined)
        except Exception as e:
            print(f"Error in PalettePickerProcessingThread: {e}")
            self.preview_generated.emit(None)

    @staticmethod
    def normalize_image(image):
        return image


class PerfectPalettePickerTab(QWidget):
    """
    Perfect Palette Picker Tab for Seti Astro Suite.
    Creates 12 popular NB palettes from Ha/OIII/SII or OSC channels.
    """
    def __init__(self, image_manager=None, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc1_image = None  # Added for OSC1
        self.osc2_image = None  # Added for OSC2
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc1_filename = None  # Added for OSC1
        self.osc2_filename = None  # Added for OSC2      
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"
        self.dragging = False
        self.last_mouse_position = None
        self.selected_palette_button = None
        self.selected_palette = None  # To track the currently selected palette
        
        # Preview scale factor
        self.preview_scale = 1  # Start at no scaling

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            # self.image_manager.image_changed.connect(self.on_image_changed)
            pass

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(300)

        # Title label
        title_label = QLabel("Perfect Palette Picker", self)
        title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        title_label.setFont(QFont("Helvetica", 14, QFont.Weight.Bold))
        left_layout.addWidget(title_label)

        # Instruction label
        instruction_label = QLabel(self)
        instruction_label.setText(
            "Instructions:\n"
            "1. Add narrowband images or an OSC camera image.\n"
            "2. Check the 'Linear Input Data' checkbox if the images are linear.\n"
            "3. Click 'Create Palettes' to generate the palettes.\n"
            "4. Use the Zoom buttons to zoom in and out.\n"
            "5. Resize the UI by dragging the lower right corner.\n"
            "6. Click on a palette from the preview selection to generate that palette.\n\n"
            "Multiple palettes can be generated."
        )
        instruction_label.setWordWrap(True)
        instruction_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        instruction_label.setStyleSheet(
            "font-size: 8pt; padding: 10px;"
        )
        instruction_label.setFixedHeight(200)
        left_layout.addWidget(instruction_label)

        # "Linear Input Data" checkbox
        self.linear_checkbox = QCheckBox("Linear Input Data", self)
        self.linear_checkbox.setChecked(True)
        self.linear_checkbox.setToolTip(
            "When checked, we apply the 0.25 stretch for previews/final images."
        )
        left_layout.addWidget(self.linear_checkbox)

        # Load buttons for Ha, OIII, SII, OSC
        self.load_ha_button = QPushButton("Load Ha Image", self)
        self.load_ha_button.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.load_ha_button)

        self.ha_label = QLabel("No Ha image loaded.", self)
        self.ha_label.setWordWrap(True)
        left_layout.addWidget(self.ha_label)

        self.load_oiii_button = QPushButton("Load OIII Image", self)
        self.load_oiii_button.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.load_oiii_button)

        self.oiii_label = QLabel("No OIII image loaded.", self)
        self.oiii_label.setWordWrap(True)
        left_layout.addWidget(self.oiii_label)

        self.load_sii_button = QPushButton("Load SII Image", self)
        self.load_sii_button.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.load_sii_button)

        self.sii_label = QLabel("No SII image loaded.", self)
        self.sii_label.setWordWrap(True)
        left_layout.addWidget(self.sii_label)

        # **Add OSC1 Load Button and Label**
        self.load_osc1_button = QPushButton("Load OSC HaO3 Image", self)
        self.load_osc1_button.clicked.connect(lambda: self.load_image('OSC1'))
        left_layout.addWidget(self.load_osc1_button)

        self.osc1_label = QLabel("No OSC HaO3 image loaded.", self)
        self.osc1_label.setWordWrap(True)
        left_layout.addWidget(self.osc1_label)

        # **Add OSC2 Load Button and Label**
        self.load_osc2_button = QPushButton("Load OSC S2O3 Image", self)
        self.load_osc2_button.clicked.connect(lambda: self.load_image('OSC2'))
        left_layout.addWidget(self.load_osc2_button)

        self.osc2_label = QLabel("No OSC S2O3 image loaded.", self)
        self.osc2_label.setWordWrap(True)
        left_layout.addWidget(self.osc2_label)

        # "Create Palettes" button
        create_palettes_button = QPushButton("Create Palettes", self)
        create_palettes_button.clicked.connect(self.prepare_preview_palettes)
        left_layout.addWidget(create_palettes_button)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        self.push_palette_button = QPushButton("Push Final Palette for Further Processing")
        self.push_palette_button.clicked.connect(self.push_final_palette_to_image_manager)
        left_layout.addWidget(self.push_palette_button)

        # Spacer
        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add a "Clear All Images" button
        self.clear_all_button = QPushButton("Clear All Images", self)
        self.clear_all_button.clicked.connect(self.clear_all_images)
        left_layout.addWidget(self.clear_all_button)


        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setFont(QFont("Helvetica", 8))
        left_layout.addWidget(footer_label)

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # Right column for previews and controls
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In", self)
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out", self)
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        fit_to_preview_button = QPushButton("Fit to Preview", self)
        fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(fit_to_preview_button)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.installEventFilter(self)
        self.image_label.setMouseTracking(True)

        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setMinimumSize(400, 250)
        right_layout.addWidget(self.scroll_area, stretch=1)


        # Preview thumbnails grid
        self.thumbs_grid = QGridLayout()
        self.palette_names = [
            "SHO", "HOO", "HSO", "HOS",
            "OSS", "OHH", "OSH", "OHS",
            "HSS", "Realistic1", "Realistic2", "Foraxx"
        ]
        self.thumbnail_buttons = []
        row = 0
        col = 0

        for palette in self.palette_names:
            button = QPushButton(palette, self)
            button.setMinimumSize(200, 100)  # Minimum size for buttons
            button.setMaximumHeight(100)  # Fixed height for buttons
            button.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)  # Expand width, fixed height
            button.setIcon(QIcon())  # Placeholder, will be set later
            button.clicked.connect(lambda checked, p=palette: self.generate_final_palette_image(p))
            button.setIconSize(QSize(200, 100))
            button.setIcon(QIcon())  # Placeholder, will be set later
            self.thumbnail_buttons.append(button)
            self.thumbs_grid.addWidget(button, row, col)
            col += 1
            if col >= 4:
                col = 0
                row += 1

        # Wrap the grid in a QWidget for better layout handling
        thumbs_widget = QWidget()
        thumbs_widget.setLayout(self.thumbs_grid)
        thumbs_widget.setSizePolicy(QSizePolicy.Policy.Preferred, QSizePolicy.Policy.Fixed)

        # Add the thumbnails widget to the layout
        right_layout.addWidget(thumbs_widget, stretch=0)


        # Status label
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        right_layout.addWidget(self.status_label)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.setWindowTitle("Perfect Palette Picker v1.0")

    def clear_all_images(self):
        """
        Clears all loaded images (Ha, OIII, SII, OSC1, OSC2).
        """
        # Clear Ha image and reset filename and label
        self.ha_image = None
        self.ha_filename = None
        self.ha_label.setText("No Ha image loaded.")

        # Clear OIII image and reset filename and label
        self.oiii_image = None
        self.oiii_filename = None
        self.oiii_label.setText("No OIII image loaded.")

        # Clear SII image and reset filename and label
        self.sii_image = None
        self.sii_filename = None
        self.sii_label.setText("No SII image loaded.")

        # Clear OSC1 image and reset filename and label
        self.osc1_image = None
        self.osc1_filename = None
        self.osc1_label.setText("No OSC HaO3 image loaded.")

        # Clear OSC2 image and reset filename and label
        self.osc2_image = None
        self.osc2_filename = None
        self.osc2_label.setText("No OSC S2O3 image loaded.")

        # Clean up preview windows
        self.cleanup_preview_windows()        

        # Update the status label
        self.status_label.setText("All images cleared.")


    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.
        
        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC1', 'OSC2').
        """
        try:
            print(f"Initiating load process for {image_type} image.")
            
            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From File", "From Slot"],
                editable=False
            )
            
            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return
            
            print(f"{image_type} image source selected: {source_choice}")
            
            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return
            
            if result is None:
                # Loading was unsuccessful or cancelled
                return
            
            image, original_header, bit_depth, is_mono, file_path = result
            
            # 🔹 **NEW: Check if grayscale is stored in 3 channels and extract the first channel**
            if image.ndim == 3 and np.all(image[:, :, 0] == image[:, :, 1]) and np.all(image[:, :, 0] == image[:, :, 2]):
                print(f"{image_type} is stored as a 3-channel grayscale image. Extracting the first channel.")
                image = image[:, :, 0]  # Convert to single-channel grayscale

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.ha_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.sii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC1':
                self.osc1_image = image
                self.osc1_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc1_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC2':
                self.osc2_image = image
                self.osc2_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc2_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return
            
            # Apply stretching if linear input is checked
            if self.linear_checkbox.isChecked():
                if is_mono:
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha':
                        self.ha_image = stretch_func(self.ha_image, target_median=0.25)
                    elif image_type == 'OIII':
                        self.oiii_image = stretch_func(self.oiii_image, target_median=0.25)
                    elif image_type == 'SII':
                        self.sii_image = stretch_func(self.sii_image, target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Assuming OSC has multiple channels; stretching would be handled during processing
                        pass
                else:
                    # For multi-channel images, apply stretching to the first channel
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha' and self.ha_image is not None and self.ha_image.ndim == 3:
                        self.ha_image[:, :, 0] = stretch_func(self.ha_image[:, :, 0], target_median=0.25)
                    elif image_type == 'OIII' and self.oiii_image is not None and self.oiii_image.ndim == 3:
                        self.oiii_image[:, :, 0] = stretch_func(self.oiii_image[:, :, 0], target_median=0.25)
                    elif image_type == 'SII' and self.sii_image is not None and self.sii_image.ndim == 3:
                        self.sii_image[:, :, 0] = stretch_func(self.sii_image[:, :, 0], target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Handle stretching for OSC images if necessary
                        pass
        
        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_slot(self, image_type):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            print("ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Build the list using the parent's slot_names dictionary.
        available_slots = []
        # Access parent's slot_names dictionary.
        slot_names = self.parent_window.slot_names if self.parent_window else {}
        for i in range(self.image_manager.max_slots):
            slot_name = slot_names.get(i, f"Slot {i+1}")
            available_slots.append(slot_name)

        slot_choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type} Image",
            "Choose a slot:",
            available_slots,
            editable=False
        )

        if not ok or not slot_choice:
            QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
            print(f"{image_type} image loading cancelled by the user.")
            return None

        # Find the slot index that matches the chosen display name.
        target_slot_num = None
        for i in range(self.image_manager.max_slots):
            current_name = slot_names.get(i, f"Slot {i+1}")
            if current_name == slot_choice:
                target_slot_num = i
                break

        if target_slot_num is None:
            QMessageBox.critical(self, "Error", f"Invalid slot selection: {slot_choice}")
            print(f"Error: Could not map slot name '{slot_choice}' to a slot number.")
            return None

        image = self.image_manager._images.get(target_slot_num, None)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{slot_choice} does not contain an image.")
            print(f"{slot_choice} is empty. Cannot load {image_type} image.")
            return None

        print(f"{image_type} image selected from {slot_choice}.")

        # Retrieve metadata.
        metadata = self.image_manager._metadata.get(target_slot_num, {})
        original_header = metadata.get('header', None)
        bit_depth = metadata.get('bit_depth', "Unknown")
        is_mono = metadata.get('is_mono', False)
        file_path = metadata.get('file_path', None)

        return image, original_header, bit_depth, is_mono, file_path




    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.
        
        Parameters:
            image_type (str): The type of image to load.
        
        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """


        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter

        )
        
        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None
        
        print(f"{image_type} image file selected: {file_path}")
        
        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None
        
        return image, original_header, bit_depth, is_mono, file_path

    def get_image_shape(self, image):
        """Returns the shape of the image or None if not set."""
        return image.shape if image is not None else None


    def prepare_preview_palettes(self):
        """
        
        Prepares the preview thumbnails for each palette based on selected images.
        """
        have_ha = self.ha_image is not None
        have_oiii = self.oiii_image is not None
        have_sii = self.sii_image is not None
        have_osc1 = self.osc1_image is not None
        have_osc2 = self.osc2_image is not None

        print(f"prepare_preview_palettes() => Ha: {have_ha} | OIII: {have_oiii} | SII: {have_sii} | OSC1: {have_osc1} | OSC2: {have_osc2}")


        # 🔹 **NEW: Check for image size mismatches**
        image_shapes = {
            'Ha': self.get_image_shape(self.ha_image),
            'OIII': self.get_image_shape(self.oiii_image),
            'SII': self.get_image_shape(self.sii_image),
            'OSC1': self.get_image_shape(self.osc1_image),
            'OSC2': self.get_image_shape(self.osc2_image),
        }

        # Filter out None values (only check actual loaded images)
        valid_shapes = {k: v for k, v in image_shapes.items() if v is not None}

        # If different shapes are found, show an error and return
        if len(set(valid_shapes.values())) > 1:
            QMessageBox.critical(
                self,
                "Image Size Mismatch",
                f"Error: The selected images have mismatched dimensions!\n\n"
                f"{valid_shapes}"
            )
            self.status_label.setText("Error: Image sizes must match.")
            print(f"[ERROR] Image size mismatch: {valid_shapes}")
            return

        # Initialize combined channels
        combined_ha = self.ha_image.copy() if self.ha_image is not None else None
        combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None
        combined_sii = self.sii_image.copy() if self.sii_image is not None else None  # Initialize combined SII

        # Process OSC1 if available
        if have_osc1:
            # Extract synthetic Ha and OIII from OSC1
            ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
            oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                ha_osc1 = stretch_mono_image(ha_osc1, target_median=0.25)
                oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=0.25)

            # Combine with existing Ha and OIII
            if combined_ha is not None:
                combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
            else:
                combined_ha = ha_osc1

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
            else:
                combined_oiii = oiii_osc1

        # Process OSC2 if available
        if have_osc2:
            # Extract synthetic SII from OSC2 red channel
            sii_osc2 = self.osc2_image[:, :, 0]  # Red channel -> SII
            oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                sii_osc2 = stretch_mono_image(sii_osc2, target_median=0.25)
                oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=0.25)

            # Combine with existing SII
            if combined_sii is not None:
                combined_sii = (combined_sii * 0.5) + (sii_osc2 * 0.5)
            else:
                combined_sii = sii_osc2

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
            else:
                combined_oiii = oiii_osc2    

        # Assign combined images back to self.ha_image, self.oiii_image, and self.sii_image
        self.ha_image = combined_ha
        self.oiii_image = combined_oiii
        self.sii_image = combined_sii  # Updated SII image

        # Ensure images are single-channel
        def ensure_single_channel(image, image_type):
            if image is not None:
                if image.ndim == 3:
                    if image.shape[2] == 1:
                        image = image[:, :, 0]
                        print(f"Converted {image_type} image to single channel: {image.shape}")
                    else:
                        # If image has multiple channels, retain the first channel
                        image = image[:, :, 0]
                        print(f"Extracted first channel from multi-channel {image_type} image: {image.shape}")
                return image
            return None

        self.ha_image = ensure_single_channel(self.ha_image, 'Ha')
        self.oiii_image = ensure_single_channel(self.oiii_image, 'OIII')
        self.sii_image = ensure_single_channel(self.sii_image, 'SII')

        print(f"Combined Ha image shape: {self.ha_image.shape if self.ha_image is not None else 'None'}")
        print(f"Combined OIII image shape: {self.oiii_image.shape if self.oiii_image is not None else 'None'}")
        print(f"Combined SII image shape: {self.sii_image.shape if self.sii_image is not None else 'None'}")

        # Validate required channels
        # Allow if (Ha and OIII) or (SII and OIII) are present
        if not ((self.ha_image is not None and self.oiii_image is not None) or
                (self.sii_image is not None and self.oiii_image is not None)):
            QMessageBox.warning(
                self,
                "Warning",
                "Please load at least Ha and OIII images or SII and OIII images to create palettes."
            )
            self.status_label.setText("Insufficient images loaded.")
            return

        # Start processing thread to generate previews
        ha_to_oii_ratio = 0.3  # Example ratio; adjust as needed
        enable_star_stretch = self.linear_checkbox.isChecked()
        stretch_factor = 0.25  # Example stretch factor; adjust as needed

        self.processing_thread = PalettePickerProcessingThread(
            ha_image=self.ha_image,
            oiii_image=self.oiii_image,
            sii_image=self.sii_image,
            osc1_image=None,  # OSC1 is already processed
            osc2_image=None,  # OSC2 is already processed
            ha_to_oii_ratio=ha_to_oii_ratio,
            enable_star_stretch=enable_star_stretch,
            stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.update_preview_thumbnails)
        self.processing_thread.start()

        self.status_label.setText("Generating preview palettes...")



    def update_preview_thumbnails(self, combined_preview):
        """
        Updates the preview thumbnails with the generated combined preview.
        Downsamples the images for efficient processing of mini-previews.
        """
        if combined_preview is None:
            # Only update the text overlays
            for i, palette in enumerate(self.palette_names):
                pixmap = self.thumbnail_buttons[i].icon().pixmap(self.thumbnail_buttons[i].iconSize())
                if pixmap.isNull():
                    print(f"Failed to retrieve pixmap for palette '{palette}'. Skipping.")
                    continue
                text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white
                painter = QPainter(pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()
                self.thumbnail_buttons[i].setIcon(QIcon(pixmap))
                QApplication.processEvents()

            return

        def downsample_image(image, factor=8):
            """
            Downsample the image by an integer factor using cv2.resize.
            """
            if image is not None:
                height, width = image.shape[:2]
                new_size = (max(1, width // factor), max(1, height // factor))  # Ensure size is at least 1x1
                return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
            return image

        # Downsample images
        ha = downsample_image(self.ha_image)
        oiii = downsample_image(self.oiii_image)
        sii = downsample_image(self.sii_image)

        # Helper function to extract single channel
        def extract_channel(image):
            return image if image is not None and image.ndim == 2 else (image[:, :, 0] if image is not None else None)

        # Helper function for channel substitution
        def get_channel(preferred, substitute):
            return preferred if preferred is not None else substitute

        for i, palette in enumerate(self.palette_names):
            text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white

            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None

            # Define substitution channels
            substituted_ha = sii if not ha_available and sii_available else ha
            substituted_sii = ha if not sii_available and ha_available else sii

            # Map channels based on palette
            if palette == "SHO":
                r = get_channel(extract_channel(sii), substituted_ha)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = extract_channel(oiii)
            elif palette == "HOO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = extract_channel(oiii)
            elif palette == "HSO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = extract_channel(oiii)
            elif palette == "HOS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OSS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OHH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OSH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OHS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "HSS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette in ["Realistic1", "Realistic2", "Foraxx"]:
                r, g, b = self.map_special_palettes(palette, ha, oiii, sii)
            else:
                # Fallback to SHO
                r, g, b = self.map_channels("SHO", ha, oiii, sii)

            # Replace NaNs and clip to [0, 1]
            r = np.clip(np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if r is not None else None
            g = np.clip(np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if g is not None else None
            b = np.clip(np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if b is not None else None

            if r is None or g is None or b is None:
                print(f"One of the channels is None for palette '{palette}'. Skipping this palette.")
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)
                continue

            combined = self.combine_channels_to_color([r, g, b], f"Preview_{palette}")
            if combined is not None:
                # Convert NumPy array to QImage
                q_image = self.numpy_to_qimage(combined)
                if q_image.isNull():
                    print(f"Failed to convert preview for palette '{palette}' to QImage.")
                    continue

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    print(f"Failed to create QPixmap for palette '{palette}'.")
                    continue

                # Scale pixmap
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.preview_scale),
                    int(pixmap.height() * self.preview_scale),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Add text overlay
                painter = QPainter(scaled_pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(scaled_pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()

                # Set pixmap to the corresponding button
                self.thumbnail_buttons[i].setIcon(QIcon(scaled_pixmap))
                self.thumbnail_buttons[i].setIconSize(scaled_pixmap.size())
                self.thumbnail_buttons[i].setToolTip(f"Palette: {palette}")
                QApplication.processEvents()
            else:
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)

        self.status_label.setText("Preview palettes generated successfully.")





    def generate_final_palette_image(self, palette_name):
        """
        Generates the final combined image for the selected palette.
        Handles substitution of SII for Ha or Ha for SII if one is missing.
        """
        try:
            print(f"Generating final palette image for: {palette_name}")
            
            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None
            
            # Define substitution
            if not ha_available and sii_available:
                # Substitute SII for Ha
                substituted_ha = self.sii_image
                substituted_sii = None
                print("Substituting SII for Ha.")
            elif not sii_available and ha_available:
                # Substitute Ha for SII
                substituted_sii = self.ha_image
                substituted_ha = None
                print("Substituting Ha for SII.")
            else:
                substituted_ha = self.ha_image
                substituted_sii = self.sii_image
            
            # Temporarily assign substituted channels
            original_ha = self.ha_image
            original_sii = self.sii_image
            
            self.ha_image = substituted_ha
            self.sii_image = substituted_sii
            
            # Combine channels
            combined_image = self.combine_channels(palette_name)
            
            # Restore original channels
            self.ha_image = original_ha
            self.sii_image = original_sii
            
            if combined_image is not None:
                # Ensure the combined image has the correct shape
                if combined_image.ndim == 4 and combined_image.shape[3] == 3:
                    combined_image = combined_image[:, :, :, 0]  # Remove the extra dimension

                # Convert to QImage
                q_image = self.numpy_to_qimage(combined_image)
                if q_image.isNull():
                    raise ValueError(f"Failed to convert combined image for palette '{palette_name}' to QImage.")

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    raise ValueError(f"Failed to create QPixmap for palette '{palette_name}'.")

                # Scale the pixmap based on zoom factor
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.zoom_factor),
                    int(pixmap.height() * self.zoom_factor),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Display the scaled pixmap in the main preview area
                self.image_label.setPixmap(scaled_pixmap)
                self.image_label.resize(scaled_pixmap.size())
                self.combined_image = combined_image
                self.status_label.setText(f"Final palette '{palette_name}' generated successfully.")

                self.selected_palette = palette_name
                self.update_preview_thumbnails(None)  # Trigger re-render with updated text colors

            else:
                raise ValueError(f"Failed to generate combined image for palette '{palette_name}'.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to generate final image: {e}")
            self.status_label.setText(f"Failed to generate palette '{palette_name}'.")
            print(f"[Error] {e}")

    def highlight_selected_button(self, palette_name):
        """
        Highlights the clicked button by changing its text color and resets others.
        """
        for button in self.thumbnail_buttons:
            if button.text() == palette_name:
                # Change text color to indicate selection
                button.setStyleSheet("color: green; font-weight: bold;")
                self.selected_palette_button = button
            else:
                # Reset text color for non-selected buttons
                button.setStyleSheet("")


    def combine_channels(self, palette_name):
        """
        Combines Ha, OIII, SII channels based on the palette name.
        Ensures that all combined channel values are within the [0, 1] range.
        """
        if palette_name in self.palette_names[:9]:  # Standard palettes
            r, g, b = self.map_channels(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        elif palette_name in self.palette_names[9:]:  # Special palettes
            r, g, b = self.map_special_palettes(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        else:
            # Fallback to SHO
            r, g, b = self.map_channels("SHO", self.ha_image, self.oiii_image, self.sii_image)

        if r is not None and g is not None and b is not None:
            # Replace NaN and Inf with 0
            r = np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0)
            g = np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0)
            b = np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0)

            # Normalize to [0,1]
            r = np.clip(r, 0, 1)
            g = np.clip(g, 0, 1)
            b = np.clip(b, 0, 1)

            # Ensure single-channel
            if r.ndim == 3:
                r = r[:, :, 0]
            if g.ndim == 3:
                g = g[:, :, 0]
            if b.ndim == 3:
                b = b[:, :, 0]

            combined = np.stack([r, g, b], axis=2)
            return combined
        else:
            return None


    def combine_channels_to_color(self, channels, output_id):
        """
        Combines three grayscale images into an RGB image.
        Ensures that all channels are consistent and have no extra dimensions.
        """
        try:
            # Validate input channels
            if len(channels) != 3:
                raise ValueError(f"Expected 3 channels, got {len(channels)}")
            
            # Ensure all channels have the same shape
            for i, channel in enumerate(channels):
                if channel is None:
                    raise ValueError(f"Channel {i} is None.")
                if channel.shape != channels[0].shape:
                    raise ValueError(f"Channel {i} has shape {channel.shape}, expected {channels[0].shape}")
            
            # Ensure all channels are 2D
            channels = [channel[:, :, 0] if channel.ndim == 3 else channel for channel in channels]
            
            # Debugging: Print channel shapes after extraction
            for idx, channel in enumerate(channels):
                print(f"Channel {idx} shape after extraction: {channel.shape}")
            
            # Stack channels along the third axis to create RGB
            rgb_image = np.stack(channels, axis=2)
            print(f"Combined RGB image shape: {rgb_image.shape}")
            return rgb_image
        except Exception as e:
            print(f"Error in combine_channels_to_color: {e}")
            return None

    def map_channels(self, palette_name, ha, oiii, sii):
        """
        Maps the Ha, OIII, SII channels based on the palette name.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        # Substitute SII for Ha if Ha is missing
        if ha is None and sii is not None:
            ha = sii
            print("Ha is missing. Substituting SII for Ha.")
        
        # Substitute Ha for SII if SII is missing
        if sii is None and ha is not None:
            sii = ha
            print("SII is missing. Substituting Ha for SII.")
        
        # Define the channel mappings
        mapping = {
            "SHO": [sii, ha, oiii],
            "HOO": [ha, oiii, oiii],
            "HSO": [ha, sii, oiii],
            "HOS": [ha, oiii, sii],
            "OSS": [oiii, sii, sii],
            "OHH": [oiii, ha, ha],
            "OSH": [oiii, sii, ha],
            "OHS": [oiii, ha, sii],
            "HSS": [ha, sii, sii],
        }
        
        # Retrieve the mapped channels based on the palette name
        mapped_channels = mapping.get(palette_name, [ha, oiii, sii])
             
        return mapped_channels


    def map_special_palettes(self, palette_name, ha, oiii, sii):
        """
        Maps channels for special palettes like Realistic1, Realistic2, Foraxx.
        Ensures all expressions produce values within the [0, 1] range.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        try:
            # Substitute SII for Ha if Ha is missing
            if ha is None and sii is not None:
                ha = sii
                print("Ha is missing in special palette. Substituting SII for Ha.")
        
            # Substitute Ha for SII if SII is missing
            if sii is None and ha is not None:
                sii = ha
                print("SII is missing in special palette. Substituting Ha for SII.")
        
            # Realistic1 mapping
            if palette_name == "Realistic1":
                expr_r = (ha + sii) / 2 if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * ha) + (0.7 * oiii) if (ha is not None and oiii is not None) else (ha if ha is not None else 0)
                expr_b = (0.9 * oiii) + (0.1 * ha) if (ha is not None and oiii is not None) else (oiii if oiii is not None else 0)
        
            # Realistic2 mapping
            elif palette_name == "Realistic2":
                expr_r = (0.7 * ha + 0.3 * sii) if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * sii + 0.7 * oiii) if (sii is not None and oiii is not None) else (oiii if oiii is not None else 0)
                expr_b = oiii if oiii is not None else 0
        
            # Foraxx mapping
            elif palette_name == "Foraxx":
                if ha is not None and oiii is not None and sii is None:
                    expr_r = ha
                    temp = ha * oiii
                    expr_g = (temp ** (1 - temp)) * ha + (1 - (temp ** (1 - temp))) * oiii
                    expr_b = oiii
                elif ha is not None and oiii is not None and sii is not None:
                    temp = oiii ** (1 - oiii)
                    expr_r = (temp * sii) + ((1 - temp) * ha)
                    temp_ha_oiii = ha * oiii
                    expr_g = (temp_ha_oiii ** (1 - temp_ha_oiii)) * ha + (1 - (temp_ha_oiii ** (1 - temp_ha_oiii))) * oiii
                    expr_b = oiii
                else:
                    # Fallback to SHO
                    return self.map_channels("SHO", ha, oiii, sii)
        
            else:
                # Fallback to SHO for any undefined palette
                return self.map_channels("SHO", ha, oiii, sii)
        
            # Replace invalid values and normalize
            expr_r = np.clip(np.nan_to_num(expr_r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_g = np.clip(np.nan_to_num(expr_g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_b = np.clip(np.nan_to_num(expr_b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
        
            return expr_r, expr_g, expr_b
        except Exception as e:
            print(f"[Error] Failed to map palette {palette_name}: {e}")
            return None, None, None


    def extract_oscc_channels(self, osc_image, base_id):
        """
        Extracts R, G, B channels from the OSC image and assigns unique postfixes.
        
        Parameters:
            osc_image (numpy.ndarray): The OSC image array.
            base_id (str): The base identifier for naming.
        
        Returns:
            list: A list containing the extracted R, G, B channels as NumPy arrays.
        """
        if osc_image is None or osc_image.shape[2] < 3:
            print(f"[!] OSC image {base_id} has fewer than 3 channels—skipping extraction.")
            return []

        # Extract channels
        R = osc_image[:, :, 0]  # Red channel
        G = osc_image[:, :, 1]  # Green channel
        B = osc_image[:, :, 2]  # Blue channel

        # Assign unique postfixes
        R_name = f"{base_id}_pppR"
        G_name = f"{base_id}_pppG"
        B_name = f"{base_id}_pppB"

        # For Seti Astro Suite, we might need to create separate image objects or handle naming differently
        # Here, we'll assume that we can manage the names via dictionaries or similar structures

        # Store the extracted channels with their names
        extracted_channels = {
            R_name: R,
            G_name: G,
            B_name: B
        }

        # Optionally, hide these images in the GUI or manage them as needed
        # For example, you might add them to an internal list for cleanup

        # For demonstration, we'll return the list of channels
        return [R, G, B]




    def numpy_to_qimage(self, image_array):
        """
        Converts a NumPy array to QImage.
        Assumes image_array is in the range [0, 1] and in RGB format.
        """
        try:
            # Validate input shape
            if image_array.ndim == 2:
                # Grayscale image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width = image_uint8.shape
                bytes_per_line = width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
                return q_image.copy()
            elif image_array.ndim == 3 and image_array.shape[2] == 3:
                # RGB image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width, channels = image_uint8.shape
                if channels != 3:
                    raise ValueError(f"Expected 3 channels for RGB, got {channels}")
                bytes_per_line = 3 * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
                return q_image.copy()
            else:
                # Invalid shape
                raise ValueError(f"Invalid image shape for QImage conversion: {image_array.shape}")
        except Exception as e:
            print(f"Error converting NumPy array to QImage: {e}")
            return QImage()



    def save_image(self):
        """
        Save the current combined image to a selected path.
        """
        if self.combined_image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                "",
                "Images (*.png *.tif *.tiff *.fits *.fit);;All Files (*)"
            )

            if save_file:
                # Prompt the user for bit depth
                bit_depth, ok = QInputDialog.getItem(
                    self,
                    "Select Bit Depth",
                    "Choose bit depth for saving:",
                    ["16-bit", "32-bit floating point"],
                    0,
                    False
                )
                if ok:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Ensure correct data ordering for FITS format
                    final_image = self.combined_image
                    if selected_format in ['fits', 'fit']:
                        if self.combined_image.ndim == 3:  # RGB image
                            # Transpose to (channels, height, width)
                            final_image = np.transpose(self.combined_image, (2, 0, 1))
                            print(f"Transposed for FITS: {final_image.shape}")
                        elif self.combined_image.ndim == 2:  # Mono image
                            print(f"Mono image, no transposition needed: {final_image.shape}")
                        else:
                            QMessageBox.critical(
                                self,
                                "Error",
                                "Unsupported image dimensions for FITS saving."
                            )
                            return

                    # Check if any loaded image file paths have the `.xisf` extension
                    loaded_file_paths = [
                        self.ha_filename, self.oiii_filename,
                        self.sii_filename, self.osc1_filename, self.osc2_filename
                    ]
                    contains_xisf = any(
                        file_path.lower().endswith('.xisf') for file_path in loaded_file_paths if file_path
                    )

                    # Create a minimal header if any loaded image is XISF
                    sanitized_header = self.original_header if not contains_xisf else self.create_minimal_fits_header(final_image)

                    # Pass the correctly ordered image to the global save_image function
                    try:
                        save_image(
                            img_array=final_image,
                            filename=save_file,
                            original_format=selected_format,
                            bit_depth=bit_depth,
                            original_header=sanitized_header,  # Pass minimal or original header
                            is_mono=self.is_mono
                        )
                        print(f"Image successfully saved to {save_file}.")
                        self.status_label.setText(f"Image saved to: {save_file}")
                    except Exception as e:
                        QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                        print(f"Error saving image: {e}")
            else:
                self.status_label.setText("Save canceled.")
        else:
            QMessageBox.warning(self, "Warning", "No combined image to save.")
            self.status_label.setText("No combined image to save.")


    def create_minimal_fits_header(self, img_array):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if self.is_mono else 3
        header['NAXIS1'] = self.combined_image.shape[1]  # Image width
        header['NAXIS2'] = self.combined_image.shape[0]  # Image height
        if not self.is_mono:
            header['NAXIS3'] = self.combined_image.shape[2]  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header['COMMENT'] = "Minimal FITS header generated by Perfect Palette Picker."

        return header

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms into the main preview image.
        """
        if self.zoom_factor < 5.0:  # Maximum zoom factor
            self.zoom_factor *= 1.25
            self.update_main_preview()
        else:
            print("Maximum zoom level reached.")
            self.status_label.setText("Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out of the main preview image.
        """
        if self.zoom_factor > 0.2:  # Minimum zoom factor
            self.zoom_factor /= 1.25
            self.update_main_preview()
        else:
            print("Minimum zoom level reached.")
            self.status_label.setText("Minimum zoom level reached.")

    def fit_to_preview(self):
        """
        Fits the main preview image to the scroll area.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            if q_image.isNull():
                QMessageBox.critical(self, "Error", "Cannot fit image to preview due to conversion error.")
                return
            pixmap = QPixmap.fromImage(q_image)
            scroll_area_width = self.scroll_area.viewport().width()
            self.zoom_factor = scroll_area_width / pixmap.width()
            self.update_main_preview()
            self.status_label.setText("Image fitted to preview area.")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")

    def update_main_preview(self):
        """
        Updates the main preview image based on the current zoom factor.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            pixmap = QPixmap.fromImage(q_image)
            if pixmap.isNull():
                QMessageBox.critical(self, "Error", "Failed to update main preview. Invalid QPixmap.")
                return

            # Ensure dimensions are integers
            scaled_width = int(pixmap.width() * self.zoom_factor)
            scaled_height = int(pixmap.height() * self.zoom_factor)

            scaled_pixmap = pixmap.scaled(
                scaled_width,
                scaled_height,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.image_label.setPixmap(scaled_pixmap)
            self.image_label.resize(scaled_pixmap.size())
        else:
            self.image_label.clear()





    def create_palette_preview(self, palette_name):
        """
        Creates a mini-preview image for the given palette.
        Returns the combined RGB image as a NumPy array.
        """
        print(f"Creating mini-preview for palette: {palette_name}")
        combined = self.combine_channels(palette_name)
        return combined

    def push_final_palette_to_image_manager(self):
        """
        Pushes the final combined image to the ImageManager for further processing.
        """
        if self.combined_image is not None:
            # Check if any of the loaded file paths have an XISF extension
            loaded_files = [self.ha_filename, self.oiii_filename, self.sii_filename, self.osc1_filename, self.osc2_filename]
            was_xisf = any(file_path and file_path.lower().endswith('.xisf') for file_path in loaded_files)

            # Generate a minimal FITS header if the original header is missing or if the format was XISF
            sanitized_header = self.original_header
            if was_xisf or sanitized_header is None:
                sanitized_header = None

            # Determine the valid file path:
            # Prioritize Ha, then OSC1, then OSC2
            file_path = None
            if self.ha_image is not None and self.ha_filename:
                file_path = self.ha_filename
                print("Using Ha filename as file_path.")
            elif self.osc1_image is not None and self.osc1_filename:
                file_path = self.osc1_filename
                print("Using OSC1 filename as file_path.")
            elif self.osc2_image is not None and self.osc2_filename:
                file_path = self.osc2_filename
                print("Using OSC2 filename as file_path.")
            else:
                # No valid source file, save combined_image to a temporary file
                try:
                    temp_dir = tempfile.gettempdir()
                    timestamp = int(time.time())
                    temp_file_path = os.path.join(temp_dir, f"combined_image_{timestamp}.tif")
                    
                    # Save the combined image using your existing save_image function
                    save_image(
                        img_array=self.combined_image,
                        filename=temp_file_path,
                        original_format='tif',
                        bit_depth=self.bit_depth,
                        original_header=self.original_header,
                        is_mono=self.is_mono
                    )
                    
                    file_path = temp_file_path
                    print(f"Combined image saved to temporary file: {file_path}")
                except Exception as e:
                    print(f"Failed to save combined image to temporary file: {e}")
                    QMessageBox.critical(
                        self, 
                        "Error", 
                        f"Failed to save combined image to temporary file:\n{e}"
                    )
                    return

            # Create metadata for the combined image
            metadata = {
                'file_path': file_path,
                'original_header': sanitized_header,  # Use the sanitized or minimal header
                'bit_depth': self.bit_depth if hasattr(self, 'bit_depth') else "Unknown",
                'is_mono': False,
                'processing_parameters': {
                    'zoom_factor': self.zoom_factor,
                    'preview_scale': self.preview_scale
                },
                'processing_timestamp': datetime.now().isoformat(),
                'source_images': {
                    'Ha': self.ha_filename if self.ha_image is not None else "Not Provided",
                    'OIII': self.oiii_filename if self.oiii_image is not None else "Not Provided",
                    'SII': self.sii_filename if self.sii_image is not None else "Not Provided",
                    'OSC1': self.osc1_filename if self.osc1_image is not None else "Not Provided",
                    'OSC2': self.osc2_filename if self.osc2_image is not None else "Not Provided"
                }
            }

            # Push the image and metadata into the ImageManager
            if self.image_manager:
                try:
                    self.image_manager.update_image(
                        updated_image=self.combined_image, metadata=metadata
                    )
                    print(f"Image pushed to ImageManager with metadata: {metadata}")
                    self.status_label.setText("Final palette image pushed for further processing.")
                except Exception as e:
                    print(f"Error updating ImageManager: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
            else:
                print("ImageManager is not initialized.")
                QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the combined image.")
        else:
            QMessageBox.warning(self, "Warning", "No final palette image to push.")
            self.status_label.setText("No final palette image to push.")



    def mousePressEvent(self, event):
        """
        Starts dragging when the left mouse button is pressed.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_mouse_position = event.pos()
            self.image_label.setCursor(Qt.CursorShape.ClosedHandCursor)

    def mouseMoveEvent(self, event):
        """
        Handles dragging by adjusting the scroll area's position.
        """
        if self.dragging and self.last_mouse_position is not None:
            # Calculate the difference in mouse movement
            delta = event.pos() - self.last_mouse_position
            self.last_mouse_position = event.pos()

            # Adjust the scroll area's scroll position
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )

    def mouseReleaseEvent(self, event):
        """
        Stops dragging when the left mouse button is released.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
            self.last_mouse_position = None
            self.image_label.setCursor(Qt.CursorShape.OpenHandCursor)


    def cleanup_preview_windows(self):
        """
        Cleans up temporary preview images by resetting image variables and clearing GUI elements.
        """
        print("Cleaning up preview windows...")
        
        # 1. Reset Temporary Image Variables
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        print("Temporary preview images (Ha, OIII, SII) have been cleared.")
        
        # 2. Clear GUI Elements Displaying Previews
        # Update the list below with the actual names of your preview labels or buttons
        preview_labels = ['ha_preview_label', 'oiii_preview_label', 'sii_preview_label']
        for label_name in preview_labels:
            if hasattr(self, label_name):
                label = getattr(self, label_name)
                label.clear()  # Removes the pixmap or any displayed content
                print(f"{label_name} has been cleared.")
        
        # 3. Clear Final Image Display (if applicable)
        # Update 'final_image_label' with your actual final image display widget name
        if hasattr(self, 'image_label'):
            self.image_label.clear()
            print("Final image label has been cleared.")
        
        # 4. Reset Thumbnail Buttons (if used for previews)
        # Ensure 'self.thumbnail_buttons' is a list of your thumbnail QPushButtons
        for button in self.thumbnail_buttons:
            button.setIcon(QIcon())    # Remove existing icon



        print("Thumbnail buttons have been reset.")
        
        # 5. Update Status Label
        self.status_label.setText("Preview windows cleaned up.")
        print("Status label updated to indicate cleanup.")
        
        # 6. Process UI Events to Reflect Changes Immediately
        QApplication.processEvents()


    def closeEvent(self, event):
        """
        Handle the close event to perform cleanup.
        """
        self.cleanup_preview_windows()
        event.accept()

class NBtoRGBstarsTab(QWidget):
    def __init__(self, image_manager=None, parent=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc_image = None
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc_filename = None        
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.dragging = False
        self.last_pos = QPoint()
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select Ha, OIII, and SII (optional) narrowband images, or an OSC stars-only image.
            2. Adjust the Ha to OIII Ratio if needed.
            3. Preview the combined result.
            4. Save the final composite image.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # Ha, OIII, SII image selections
        self.haButton = QPushButton('Select Ha Image', self)
        self.haButton.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.haButton)
        self.haLabel = QLabel('No Ha image selected', self)
        left_layout.addWidget(self.haLabel)

        self.oiiiButton = QPushButton('Select OIII Image', self)
        self.oiiiButton.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.oiiiButton)
        self.oiiiLabel = QLabel('No OIII image selected', self)
        left_layout.addWidget(self.oiiiLabel)

        self.siiButton = QPushButton('Select SII Image (Optional)', self)
        self.siiButton.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.siiButton)
        self.siiLabel = QLabel('No SII image selected', self)
        left_layout.addWidget(self.siiLabel)

        self.oscButton = QPushButton('Select OSC Stars Image (Optional)', self)
        self.oscButton.clicked.connect(lambda: self.load_image('OSC'))
        left_layout.addWidget(self.oscButton)
        self.oscLabel = QLabel('No OSC stars image selected', self)
        left_layout.addWidget(self.oscLabel)

        # Ha to OIII Ratio slider
        self.haToOiiRatioLabel, self.haToOiiRatioSlider = self.createRatioSlider("Ha to OIII Ratio", 30)
        left_layout.addWidget(self.haToOiiRatioLabel)
        left_layout.addWidget(self.haToOiiRatioSlider)

        # Star Stretch checkbox and sliders
        self.starStretchCheckBox = QCheckBox("Enable Star Stretch", self)
        self.starStretchCheckBox.setChecked(True)
        self.starStretchCheckBox.toggled.connect(self.toggleStarStretchControls)
        left_layout.addWidget(self.starStretchCheckBox)

        self.stretchSliderLabel, self.stretchSlider = self.createStretchSlider("Stretch Factor", 5.0)
        left_layout.addWidget(self.stretchSliderLabel)
        left_layout.addWidget(self.stretchSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # Preview and Save buttons
        self.previewButton = QPushButton('Preview Combined Image', self)
        self.previewButton.clicked.connect(self.previewCombine)
        left_layout.addWidget(self.previewButton)

        # File label for displaying save status
        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        self.pushButton = QPushButton('Push to Active Slot', self)
        self.pushButton.clicked.connect(self.pushToActiveSlot)
        left_layout.addWidget(self.pushButton)

        # **Remove Zoom Buttons from Left Panel (Not present)**
        # No existing zoom buttons to remove in the left panel

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return       
        if image is None:
            return         
        if slot == self.image_manager.current_slot:

            print(f"NBtoRGBstarsTab: Image updated from ImageManager slot {slot}.")

    def pushToActiveSlot(self):
        """
        Pushes the current combined image to the active slot in the ImageManager,
        along with the associated metadata.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "Warning", "No combined image available to push.")
            return

        # Check if any of the loaded file paths have an XISF extension
        loaded_files = [self.ha_filename, self.oiii_filename, self.sii_filename, self.osc_filename]
        was_xisf = any(file_path and file_path.lower().endswith('.xisf') for file_path in loaded_files)

        # Generate a minimal FITS header if the original header is missing or if the format was XISF
        sanitized_header = self.original_header
        if was_xisf or sanitized_header is None:
            sanitized_header = None  # Use None to avoid saving an empty header

        # Determine the valid file path:
        # Prioritize Ha, then OSC (if available)
        file_path = None
        if self.ha_image is not None and self.ha_filename:
            file_path = self.ha_filename
            print("Using Ha filename as file_path.")
        elif self.osc_image is not None and self.osc_filename:
            file_path = self.osc_filename
            print("Using OSC filename as file_path.")
        else:
            # No valid source file, save combined_image to a temporary file
            try:
                temp_dir = tempfile.gettempdir()
                timestamp = int(time.time())
                temp_file_path = os.path.join(temp_dir, f"combined_image_{timestamp}.tif")

                # Save the combined image using `save_image()`
                save_image(
                    img_array=self.combined_image,
                    filename=temp_file_path,
                    original_format='tif',
                    bit_depth=self.bit_depth if self.bit_depth in ["16-bit", "32-bit unsigned", "32-bit floating point"] else "32-bit floating point",
                    original_header=self.original_header,
                    is_mono=self.is_mono
                )

                file_path = temp_file_path
                print(f"Combined image saved to temporary file: {file_path}")
            except Exception as e:
                print(f"Failed to save combined image to temporary file: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save combined image to temporary file:\n{e}")
                return

        # Create metadata for the combined image
        metadata = {
            'file_path': file_path,
            'original_header': sanitized_header,  # Use the sanitized or minimal header
            'bit_depth': self.bit_depth if hasattr(self, 'bit_depth') else "Unknown",
            'is_mono': False,  # Assume the combined image is color
            'processing_parameters': {
                'ha_to_oii_ratio': self.haToOiiRatioSlider.value() / 100.0,
                'enable_star_stretch': self.starStretchCheckBox.isChecked(),
                'stretch_factor': self.stretchSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Ha': self.ha_filename if self.ha_image is not None else "Not Provided",
                'OIII': self.oiii_filename if self.oiii_image is not None else "Not Provided",
                'SII': self.sii_filename if self.sii_image is not None else "Not Provided",
                'OSC': self.osc_filename if self.osc_image is not None else "Not Provided"
            }
        }

        # Push the image and metadata into the ImageManager
        if self.image_manager:
            try:
                self.image_manager.update_image(
                    updated_image=self.combined_image, metadata=metadata
                )
                print(f"Image pushed to ImageManager with metadata: {metadata}")
                QMessageBox.information(self, "Success", "Combined image pushed to active slot.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the combined image.")


    def createRatioSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value / 100:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(100)
        slider.setValue(default_value)
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def createStretchSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(800)
        slider.setValue(int(default_value * 100))  # Scale to handle float values
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def toggleStarStretchControls(self):
        enabled = self.starStretchCheckBox.isChecked()
        self.stretchSliderLabel.setVisible(enabled)
        self.stretchSlider.setVisible(enabled)

    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.

        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC').
        """
        try:
            print(f"Initiating load process for {image_type} image.")

            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From File", "From Slot"],
                editable=False
            )

            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return

            print(f"{image_type} image source selected: {source_choice}")

            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return

            if result is None:
                # Loading was unsuccessful or cancelled
                return

            image, original_header, bit_depth, is_mono, file_path = result

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.haLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiiiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.siiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC':
                self.osc_image = image
                self.osc_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oscLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return

        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.

        Parameters:
            image_type (str): The type of image to load.

        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter
        )

        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None

        print(f"{image_type} image file selected: {file_path}")

        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None

        return image, original_header, bit_depth, is_mono, file_path

    def load_image_from_slot(self, image_type):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            print("ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Build the list using the parent's slot_names dictionary.
        available_slots = []
        slot_names = self.parent_window.slot_names if self.parent_window else {}
        for i in range(self.image_manager.max_slots):
            slot_name = slot_names.get(i, f"Slot {i+1}")
            available_slots.append(slot_name)

        slot_choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type} Image",
            "Choose a slot:",
            available_slots,
            editable=False
        )

        if not ok or not slot_choice:
            QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
            print(f"{image_type} image loading cancelled by the user.")
            return None

        # Find the slot index that matches the chosen display name.
        target_slot_num = None
        for i in range(self.image_manager.max_slots):
            current_name = slot_names.get(i, f"Slot {i+1}")
            if current_name == slot_choice:
                target_slot_num = i
                break

        if target_slot_num is None:
            QMessageBox.critical(self, "Error", f"Invalid slot selection: {slot_choice}")
            print(f"Error: Could not map slot name '{slot_choice}' to a slot number.")
            return None

        image = self.image_manager._images.get(target_slot_num, None)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{slot_choice} does not contain an image.")
            print(f"{slot_choice} is empty. Cannot load {image_type} image.")
            return None

        print(f"{image_type} image selected from {slot_choice}.")

        # Retrieve metadata.
        metadata = self.image_manager._metadata.get(target_slot_num, {})
        original_header = metadata.get('header', None)
        bit_depth = metadata.get('bit_depth', "Unknown")
        is_mono = metadata.get('is_mono', False)
        file_path = metadata.get('file_path', None)

        return image, original_header, bit_depth, is_mono, file_path


    def previewCombine(self):
        # Check if required images are loaded prior to starting the processing thread
        if not ((self.ha_image is not None and self.oiii_image is not None) or (self.osc_image is not None)):
            QMessageBox.warning(self, "Missing Images", "Please Select Images Before Combining")
            return    
        ha_to_oii_ratio = self.haToOiiRatioSlider.value() / 100.0
        enable_star_stretch = self.starStretchCheckBox.isChecked()
        stretch_factor = self.stretchSlider.value() / 100.0

        # Show spinner before starting processing
        self.showSpinner()

        # Reset zoom factor when a new preview is generated
        self.zoom_factor = 1.0

        # Start background processing
        self.processing_thread = NBtoRGBProcessingThread(
            self.ha_image, self.oiii_image, self.sii_image, self.osc_image,
            ha_to_oii_ratio=ha_to_oii_ratio, enable_star_stretch=enable_star_stretch, stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.updatePreview)
        self.processing_thread.start()

    def updatePreview(self, combined_image):
        # Set the combined image for saving
        self.combined_image = combined_image

        # Convert the image to display format
        try:
            preview_image = (combined_image * 255).astype(np.uint8)
            h, w = preview_image.shape[:2]
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        except Exception as e:
            print(f"Error converting combined image for display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to prepare image for display:\n{e}")
            self.hideSpinner()
            return

        # Store original pixmap for zooming
        self.original_pixmap = QPixmap.fromImage(q_image)

        # Apply initial zoom
        scaled_pixmap = self.original_pixmap.scaled(
            self.original_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def saveImage(self):
        if self.combined_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "output"
            default_save_name = 'NBtoRGBstars.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else ""

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.combined_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.combined_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText("No combined image to save.")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.zoom_factor < 20.0:  # Set a maximum zoom limit (e.g., 500%)
            self.zoom_factor *= 1.25  # Increase zoom by 25%
            self.updateImageDisplay()
        else:
            print("Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        if self.zoom_factor > 0.01:  # Set a minimum zoom limit (e.g., 20%)
            self.zoom_factor /= 1.25  # Decrease zoom by 20%
            self.updateImageDisplay()
        else:
            print("Minimum zoom level reached.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.combined_image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.combined_image.ndim == 3:
                image_width = self.combined_image.shape[1]
            elif self.combined_image.ndim == 2:
                image_width = self.combined_image.shape[1]
            else:
                print("Unexpected image dimensions!")

                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()  # Call without extra arguments; it will calculate dimensions based on zoom factor

    def reset_zoom(self):
        self.zoom_factor = 1.0
        self.updateImageDisplay()

    def updateImageDisplay(self):
        if self.original_pixmap:
            scaled_pixmap = self.original_pixmap.scaled(
                self.original_pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

    # Add event filter for mouse dragging in preview area
    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)

    # Placeholder methods for functionalities
    def handleImageMouseMove(self, x, y):
        # Implement handling mouse movement over the image
        pass


class NBtoRGBProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image=None, oiii_image=None, sii_image=None, osc_image=None, ha_to_oii_ratio=0.3, enable_star_stretch=True, stretch_factor=5.0):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc_image = osc_image
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        # Preprocess input images to ensure mono images are single-channel
        self.ha_image = preprocess_narrowband_image(self.ha_image)
        self.oiii_image = preprocess_narrowband_image(self.oiii_image)
        self.sii_image = preprocess_narrowband_image(self.sii_image)

        # Normalize input images to [0, 1]
        if self.ha_image is not None:
            self.ha_image = np.clip(self.ha_image, 0, 1)
        if self.oiii_image is not None:
            self.oiii_image = np.clip(self.oiii_image, 0, 1)
        if self.sii_image is not None:
            self.sii_image = np.clip(self.sii_image, 0, 1)
        if self.osc_image is not None:
            self.osc_image = np.clip(self.osc_image, 0, 1)

        # Combined RGB logic
        if self.osc_image is not None:
            r_channel = self.osc_image[..., 0]
            g_channel = self.osc_image[..., 1]
            b_channel = self.osc_image[..., 2]

            r_combined = 0.5 * r_channel + 0.5 * (self.sii_image if self.sii_image is not None else r_channel)
            g_combined = self.ha_to_oii_ratio * (self.ha_image if self.ha_image is not None else r_channel) + \
                        (1 - self.ha_to_oii_ratio) * g_channel
            b_combined = b_channel if self.oiii_image is None else self.oiii_image
        else:
            r_combined = 0.5 * self.ha_image + 0.5 * (self.sii_image if self.sii_image is not None else self.ha_image)
            g_combined = self.ha_to_oii_ratio * self.ha_image + (1 - self.ha_to_oii_ratio) * self.oiii_image
            b_combined = self.oiii_image

        # Debugging: Check shapes
        print(f"R combined shape: {r_combined.shape}")
        print(f"G combined shape: {g_combined.shape}")
        print(f"B combined shape: {b_combined.shape}")

        # Normalize combined channels to [0, 1]
        r_combined = np.clip(r_combined, 0, 1)
        g_combined = np.clip(g_combined, 0, 1)
        b_combined = np.clip(b_combined, 0, 1)

        # Stack the channels to create an RGB image
        try:
            combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)
        except ValueError as e:
            print(f"Error while stacking channels: {e}")
            print(f"R: {r_combined.shape}, G: {g_combined.shape}, B: {b_combined.shape}")
            return

        print(f"Combined image shape: {combined_image.shape}")

        # Apply star stretch if enabled
        if self.enable_star_stretch:
            combined_image = self.apply_star_stretch(combined_image)

        # Ensure combined_image is 3-channel
        if combined_image.ndim != 3 or combined_image.shape[2] != 3:
            raise ValueError("Combined image must have three channels (RGB).")

        # Apply SCNR (remove green cast)
        apply_average_neutral_scnr(combined_image)

        # Emit the processed image for preview
        self.preview_generated.emit(combined_image)


    def apply_star_stretch(self, image):
        # Ensure input image is in the range [0, 1]
        assert np.all(image >= 0) and np.all(image <= 1), "Image must be normalized to [0, 1] before star stretch."
        stretched = ((3 ** self.stretch_factor) * image) / ((3 ** self.stretch_factor - 1) * image + 1)
        return np.clip(stretched, 0, 1)

    def apply_scnr(self, image):
        green_channel = image[..., 1]
        max_rg = np.maximum(image[..., 0], image[..., 2])
        green_channel[green_channel > max_rg] = max_rg[green_channel > max_rg]
        image[..., 1] = green_channel
        return image

class HaloBGonTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager

        self.image = None  # Selected image
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.processed_image = None
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.is_mono = True
        self.last_pos = None
        self.processing_thread = None  # For background processing
        self.original_header = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
        

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fixed width for left column

        # Instructions label
        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the reduction amount as needed.
            3. Click Refresh Preview to apply the halo reduction.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Load Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Reduction amount slider
        self.reductionLabel = QLabel("Reduction Amount: Extra Low", self)
        self.reductionSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.reductionSlider.setMinimum(0)
        self.reductionSlider.setMaximum(3)
        self.reductionSlider.setValue(0)  # 0: Extra Low, 1: Low, 2: Medium, 3: High
        self.reductionSlider.setToolTip("Adjust the amount of halo reduction (Extra Low, Low, Medium, High)")
        self.reductionSlider.valueChanged.connect(self.updateReductionLabel)
        left_layout.addWidget(self.reductionLabel)
        left_layout.addWidget(self.reductionSlider)

        # Linear data checkbox
        self.linearDataCheckbox = QCheckBox("Linear Data", self)
        self.linearDataCheckbox.setToolTip("Check if the data is linear")
        left_layout.addWidget(self.linearDataCheckbox)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # **Create a horizontal layout for Refresh Preview and Undo buttons**
        action_buttons_layout = QHBoxLayout()

        # Refresh Preview button
        self.executeButton = QPushButton("Refresh Preview", self)
        self.executeButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.executeButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Comment out or remove the existing zoom buttons in the left panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton("Zoom In", self)
        # self.zoomInButton.clicked.connect(self.zoomIn)
        # zoom_layout.addWidget(self.zoomInButton)
        #
        # self.zoomOutButton = QPushButton("Zoom Out", self)
        # self.zoomOutButton.clicked.connect(self.zoomOut)
        # zoom_layout.addWidget(self.zoomOutButton)
        # left_layout.addLayout(zoom_layout)

        # Footer
        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_layout.addWidget(footer_label)

        left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoomIn)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoomOut)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"Halo-B-Gon Tab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')



    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("HaloBGonTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("HaloBGonTab: No actions to undo.")

        # Update the state of the Undo button
        self.undoButton.setEnabled(self.image_manager.can_undo())

    def updateReductionLabel(self, value):
        labels = ["Extra Low", "Low", "Medium", "High"]
        if 0 <= value < len(labels):
            self.reductionLabel.setText(f"Reduction Amount: {labels[value]}")
        else:
            self.reductionLabel.setText("Reduction Amount: Unknown")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoomIn()
        else:
            self.zoomOut()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoomIn(self):
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        self.updateImageDisplay()

    def zoomOut(self):
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        self.updateImageDisplay()
    
    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.image.ndim == 3:
                image_width = self.image.shape[1]
            elif self.image.ndim == 2:
                image_width = self.image.shape[1]
            else:
                print("Unexpected image dimensions!")
                self.statusLabel.setText("Cannot fit image to preview due to unexpected dimensions.")
                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()

    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Stars Only Image", 
            "", 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                # Load the image with header information
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)  # Ensure load_image returns (image, header, bit_depth, is_mono)
                self.filename = selected_file 
                self.fileLabel.setText(os.path.basename(selected_file))
                
                # Update ImageManager with the loaded image
                if self.image_manager:
                    metadata = {
                        'file_path': selected_file,
                        'original_header': self.original_header,
                        'bit_depth': 'Unknown',  # Update if available
                        'is_mono': self.is_mono
                    }
                    self.image_manager.set_image(self.image, metadata, step_name="load_stars_only")
                    print(f"HaloBGonTab: Loaded image stored in ImageManager.")
                
                self.generatePreview()  # Generate preview after loading
            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                QMessageBox.critical(self, "Error", f"Failed to load image:\n{e}")
                print(f"Failed to load image: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    def applyHaloReduction(self):
        if self.image is None:
            print("No image selected.")
            return

        reduction_amount = self.reductionSlider.value()
        is_linear = self.linearDataCheckbox.isChecked()

        # Show spinner and start background processing
        self.showSpinner()
        self.processing_thread = QThread()
        self.processing_worker = self.HaloProcessingWorker(self.image, reduction_amount, is_linear)
        self.processing_worker.moveToThread(self.processing_thread)
        self.processing_worker.processing_complete.connect(self.updateImage)
        self.processing_thread.started.connect(self.processing_worker.process)
        self.processing_thread.start()

    def updatePreview(self, processed_image):
        """
        Updates the preview with the processed image and applies the active mask if available.
        """
        # Retrieve the active mask
        mask = self.get_active_mask()
        
        if mask is not None:
            print("Applying mask to the processed image.")
            # Ensure mask and image have the same number of channels
            if self.image.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)
            
            # Blend the processed image with the original image using the mask
            # Formula: blended_image = processed_image * mask + original_image * (1 - mask)
            blended_image = processed_image * mask + self.image * (1 - mask)
            blended_image = np.clip(blended_image, 0.0, 1.0)  # Ensure values are within [0,1]
        else:
            print("No mask applied. Using the processed image directly.")
            blended_image = processed_image
        
        # Create metadata for the new image
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update dynamically if available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Ensure ImageManager is initialized
        if self.image_manager:
            try:
                # Set the new image and metadata using the ImageManager
                self.image_manager.set_image(blended_image, metadata, step_name="halo_reduction")
                print("HaloBGonTab: Processed and masked image stored in ImageManager (undoable).")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
                self.hideSpinner()
                return
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
            self.hideSpinner()
            return

        # Convert the blended image to 8-bit for display in the preview
        preview_image = (blended_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        # Update the pixmap and scale it for the preview label
        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # Store the original pixmap
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.zoom_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is complete
        self.hideSpinner()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Halo reduction applied with mask.")
        else:
            self.fileLabel.setText("Halo reduction applied without mask.")
        
        print("HaloBGonTab: Preview updated with processed image.")



    def saveImage(self):
        if self.processed_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_reduced.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                
                if ok and bit_depth:
                    # If linear data is checked, revert to linear before saving
                    if self.linearDataCheckbox.isChecked():
                        saved_image = np.clip(self.processed_image ** 5, 0, 1)  # Revert to linear state
                    else:
                        saved_image = self.processed_image  # Save as is (non-linear)

                    # Call save_image with the necessary parameters
                    save_image(saved_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
                else:
                    self.fileLabel.setText('Save canceled.')
            else:
                self.fileLabel.setText('Save canceled.')



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # Updated generatePreview method in HaloBGonTab to use HaloProcessingThread
    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing with HaloProcessingThread
            self.processing_thread = HaloProcessingThread(
                self.image, 
                self.reductionSlider.value(), 
                self.linearDataCheckbox.isChecked()
            )
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()
        else:
            QMessageBox.warning(self, "Warning", "No image loaded. Please load an image first.")
            print("HaloBGonTab: No image loaded. Cannot generate preview.")

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)


    def createLightnessMask(self, image):
        # Check if the image is already single-channel (grayscale)
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Normalize the grayscale image
            lightness_mask = image.astype(np.float32) / 255.0
        else:
            # Convert to grayscale to create a lightness mask
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0

        # Apply a Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        lightness_mask = cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)

        return lightness_mask

    def createDuplicateImage(self, original):
        return np.copy(original)

    def invert_mask(mask):
        return 1.0 - mask  # Assuming mask is normalized between 0 and 1


    def apply_mask_to_image(image, mask):
        # Ensure mask is 3-channel to match the image dimensions
        mask_rgb = np.stack([mask] * 3, axis=-1)
        return cv2.multiply(image, mask_rgb)


    def apply_curves_to_image(image, reduction_amount):
        # Define the curve based on reduction amount
        if reduction_amount == 0:
            curve = [int((i / 255.0) ** 0.575 * 255) for i in range(256)]
        else:
            curve = [int((i / 255.0) ** 0.4 * 255) for i in range(256)]
        
        lut = np.array(curve, dtype=np.uint8)
        return cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0


    def load_image(self, filename):
        original_header = None
        file_extension = filename.split('.')[-1].lower()

        # Handle different file types and normalize them to [0, 1] range
        if file_extension in ['tif', 'tiff']:
            image = tiff.imread(filename).astype(np.float32) / 65535.0  # For 16-bit TIFF images
        elif file_extension == 'png':
            image = np.array(Image.open(filename).convert('RGB')).astype(np.float32) / 255.0  # Normalize to [0, 1]
        elif file_extension in ['fits', 'fit']:
            with fits.open(filename) as hdul:
                image = hdul[0].data.astype(np.float32)
                original_header = hdul[0].header
                # Normalize if data is 16-bit or higher
                if image.max() > 1:
                    image /= np.max(image)
        else:
            raise ValueError(f"Unsupported file format: {file_extension}")

        return image, original_header

    def save_image(self, image, filename, file_format, bit_depth="16-bit", original_header=None):
        img = Image.fromarray((image * 255).astype(np.uint8))
        img.save(filename)

class HaloProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, reduction_amount, is_linear):
        super().__init__()
        self.image = image
        self.reduction_amount = reduction_amount
        self.is_linear = is_linear


    def run(self):
        processed_image = self.applyHaloReduction(self.image, self.reduction_amount, self.is_linear)
        self.preview_generated.emit(processed_image)

    def applyHaloReduction(self, image, reduction_amount, is_linear):
        # Ensure the image values are in range [0, 1]
        image = np.clip(image, 0, 1)

        # Convert linear to non-linear if the image is linear
        if is_linear:
            image = image ** (1 / 5)  # Gamma correction for linear data

        # Apply halo reduction logic
        lightness_mask = self.createLightnessMask(image)  # Single-channel mask
        inverted_mask = 1.0 - lightness_mask
        duplicated_mask = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)
        enhanced_mask = inverted_mask - duplicated_mask * reduction_amount * 0.33

        # Expand the mask to match the number of channels in the image
        if image.ndim == 3 and image.shape[2] == 3:  # Color image
            enhanced_mask = np.expand_dims(enhanced_mask, axis=-1)  # Add a channel dimension
            enhanced_mask = np.repeat(enhanced_mask, 3, axis=-1)  # Repeat for all 3 channels

        # Ensure the mask matches the data type of the image
        enhanced_mask = enhanced_mask.astype(image.dtype)

        # Verify that the image and mask dimensions match
        if image.shape != enhanced_mask.shape:
            raise ValueError(
                f"Shape mismatch between image {image.shape} and enhanced_mask {enhanced_mask.shape}"
            )

        # Apply the mask to the image
        masked_image = cv2.multiply(image, enhanced_mask)

        # Apply curves to the resulting image
        final_image = self.applyCurvesToImage(masked_image, reduction_amount)

        # Ensure the final image values are within [0, 1]
        return np.clip(final_image, 0, 1)



    def createLightnessMask(self, image):
        # Ensure the image is in a supported format (float32)
        image = image.astype(np.float32)

        # Check if the image is already grayscale
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Image is already grayscale; normalize it
            lightness_mask = image / 255.0
        else:
            # Convert RGB image to grayscale
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0

        # Apply Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        return cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)



    def createDuplicateMask(self, mask):
        # Duplicate the mask and apply additional processing (simulating MMT)
        duplicated_mask = cv2.GaussianBlur(mask, (0, 0), sigmaX=2)
        return duplicated_mask

    def applyMaskToImage(self, image, mask):
        # Blend the original image with the mask based on the reduction level
        mask_rgb = np.stack([mask] * 3, axis=-1)  # Convert to 3-channel
        return cv2.multiply(image, mask_rgb)

    def applyCurvesToImage(self, image, reduction_amount):
        # Apply a curves transformation based on reduction_amount
        if reduction_amount == 0:
            # Extra Low setting, mild curve
            curve = [int((i / 255.0) ** 1.2 * 255) for i in range(256)]
        elif reduction_amount == 1:
            # Low setting, slightly stronger darkening
            curve = [int((i / 255.0) ** 1.5 * 255) for i in range(256)]
        elif reduction_amount == 2:
            # Medium setting, moderate darkening
            curve = [int((i / 255.0) ** 1.8 * 255) for i in range(256)]
        else:
            # High setting, strong darkening effect
            curve = [int((i / 255.0) ** 2.2 * 255) for i in range(256)]

        # Apply the curve transformation as a lookup table
        lut = np.array(curve, dtype=np.uint8)
        transformed_image = cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0
        return transformed_image



class ContinuumSubtractTab(QWidget):
    def __init__(self, image_manager):
        super().__init__()
        self.image_manager = image_manager
        self.initUI()
        self._threads = []
        # — initialize every loadable image to None —
        self.ha_image    = None
        self.sii_image   = None
        self.oiii_image  = None
        self.red_image   = None
        self.green_image = None
        self.osc_image   = None

        self.filename = None
        self.is_mono = True
        self.combined_image = None
        self.processing_thread = None
        self.original_header = None
        self._clickable_images = {}

        if self.image_manager:
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        self.spinnerLabel = QLabel()
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # hidden until we start processing

        self.statusLabel = QLabel("")  
        self.statusLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout = QVBoxLayout()  # overall vertical: columns + bottom row
        columns_layout = QHBoxLayout()  # holds the three groups

        # — NB group —
        nb_group = QGroupBox("Narrowband Filters")
        nb_l = QVBoxLayout()
        for name, attr in [("Ha","ha"), ("SII","sii"), ("OIII","oiii")]:
            btn = QPushButton(f"Load {name}")
            lbl = QLabel(f"No {name}")
            setattr(self, f"{attr}Button", btn)
            setattr(self, f"{attr}Label", lbl)
            btn.clicked.connect(lambda _,n=name: self.loadImage(n))
            nb_l.addWidget(btn)
            nb_l.addWidget(lbl)

        self.linear_output_checkbox = QCheckBox("Output Linear Image Only")
        nb_l.addWidget(self.linear_output_checkbox)    
        nb_l.addStretch(1)
        
        # ** clear-all button **
        self.clear_button = QPushButton("Clear Loaded Images")
        self.clear_button.clicked.connect(self.clear_loaded_images)
        nb_l.addWidget(self.clear_button)
        nb_group.setLayout(nb_l)

        # — Continuum group —
        cont_group = QGroupBox("Continuum Sources")
        cont_l = QVBoxLayout()
        for name, attr in [("Red","red"), ("Green","green"), ("OSC","osc")]:
            btn = QPushButton(f"Load {name}")
            lbl = QLabel(f"No {name}")
            setattr(self, f"{attr}Button", btn)
            setattr(self, f"{attr}Label", lbl)
            btn.clicked.connect(lambda _,n=name: self.loadImage(n))
            cont_l.addWidget(btn)
            cont_l.addWidget(lbl)
        cont_l.addStretch(1)
        cont_group.setLayout(cont_l)

        # — White balance diagnostics —
        wb_group   = QGroupBox("Star-Based WB")
        self.wb_l  = QVBoxLayout()
        self.wb_l.setAlignment(Qt.AlignmentFlag.AlignTop)
        wb_group.setLayout(self.wb_l)

        # put it in a scroll area so many entries won't overflow
        wb_scroll = QScrollArea()
        wb_scroll.setWidgetResizable(True)
        wb_container = QWidget()
        wb_container.setLayout(self.wb_l)
        wb_scroll.setWidget(wb_container)

        # assemble columns
        columns_layout.addWidget(nb_group,    1)  # stretch factor 1
        columns_layout.addWidget(cont_group,  1)  # stretch factor 1
        columns_layout.addWidget(wb_scroll,   2)  # stretch factor 2 (wider)

        # — Bottom row: Execute & status —
        bottom_layout = QHBoxLayout()
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.startContinuumSubtraction)
        bottom_layout.addWidget(self.execute_button, stretch=1)
        # statusLabel must already exist
        bottom_layout.addWidget(self.spinnerLabel, stretch=1)
        bottom_layout.addWidget(self.statusLabel,   stretch=3)

        # — Footer —
        footer = QLabel(
            "Written by Franklin Marek<br>"
            "<a href='http://www.setiastro.com'>www.setiastro.com</a>"
        )
        footer.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer.setOpenExternalLinks(True)
        footer.setStyleSheet("font-size: 10px;")

        # put it all together
        main_layout.addLayout(columns_layout)
        main_layout.addLayout(bottom_layout)
        main_layout.addWidget(footer)
        self.setLayout(main_layout)
        self.installEventFilter(self)


    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            return

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        return

    def clear_loaded_images(self):
        """Clear all loaded NB and continuum images and reset the UI."""
        # 1) Clear all image attributes
        for attr in ("ha_image", "sii_image", "oiii_image",
                    "red_image", "green_image", "osc_image"):
            setattr(self, attr, None)

        # 2) Reset all labels
        self.haLabel    .setText("No Ha image")
        self.siiLabel   .setText("No SII image")
        self.oiiiLabel  .setText("No OIII image")
        self.redLabel   .setText("No Red image")
        self.greenLabel .setText("No Green image")
        self.oscLabel   .setText("No OSC image")

        # 3) Clear any preview state
        self.combined_image = None
        self.original_pixmap = None
        self.imageLabel.clear()

        # 4) Reset zoom
        self.zoom_factor = 1.0
        self.apply_zoom()
        self.zoomInButton .setEnabled(False)
        self.zoomOutButton.setEnabled(False)

        # 5) Disable save/push
        self.save_button   .setEnabled(False)
        self.pushButton    .setEnabled(False)  # if you have a push-to-slot button

        # 6) Reset status
        self.statusLabel.setText("All loaded images cleared.")
        print("All loaded images cleared.")


    def loadImage(self, channel: str):
        """
        Prompt the user to load either from file or from ImageManager slots,
        for the given channel ("Ha", "SII", "OIII", "Red", "Green", "OSC").
        """
        source, ok = QInputDialog.getItem(
            self,
            f"Select {channel} Image Source",
            "Load image from:",
            ["From File", "From Slot"],
            editable=False
        )
        if not ok:
            return

        if source == "From File":
            result = self.loadImageFromFile(channel)
        else:
            result = self.loadImageFromSlot(channel)

        if not result:
            return

        image, header, bit_depth, is_mono, path = result

        # Store into the right attribute & update the right label:
        label_text = os.path.basename(path) if path else "From Slot"
        if channel == "Ha":
            self.ha_image = image
            self.haLabel .setText(label_text)
        elif channel == "SII":
            self.sii_image = image
            self.siiLabel.setText(label_text)
        elif channel == "OIII":
            self.oiii_image = image
            self.oiiiLabel.setText(label_text)
        elif channel == "Red":
            self.red_image = image
            self.redLabel.setText(label_text)
        elif channel == "Green":
            self.green_image = image
            self.greenLabel.setText(label_text)
        elif channel == "OSC":
            self.osc_image = image
            self.oscLabel.setText(label_text)
        else:
            # unexpected channel string
            QMessageBox.critical(self, "Error", f"Unknown channel '{channel}'.")
            return

        # Store header and mono-flag for later saving
        self.original_header = header
        self.is_mono         = is_mono


    def loadImageFromFile(self, channel: str):
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        path, _ = QFileDialog.getOpenFileName(self, f"Select {channel} Image", "", file_filter)
        if not path:
            return None

        try:
            image, header, bit_depth, is_mono = load_image(path)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load {channel} image:\n{e}")
            return None

        return image, header, bit_depth, is_mono, path

    def loadImageFromSlot(self, channel: str):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "No ImageManager; cannot load from slot.")
            return None

        # build the list of display names
        slots = []
        for i in range(self.image_manager.max_slots):
            name = getattr(self.parent(), "slot_names", {}).get(i, f"Slot {i+1}")
            slots.append(name)

        choice, ok = QInputDialog.getItem(
            self, f"Select Slot for {channel}", "Choose slot:", slots, editable=False
        )
        if not ok:
            return None

        # map back to index
        idx = slots.index(choice)
        img = self.image_manager._images.get(idx, None)
        if img is None:
            QMessageBox.warning(self, "Empty Slot", f"{choice} is empty.")
            return None

        meta = self.image_manager._metadata.get(idx, {})
        return img, \
               meta.get("original_header"), \
               meta.get("bit_depth", "Unknown"), \
               meta.get("is_mono", False), \
               meta.get("file_path", None)

    def startContinuumSubtraction(self):
        # — build continuum channels with explicit None checks —
        if hasattr(self, "red_image") and self.red_image is not None:
            cont_red = self.red_image
        elif hasattr(self, "osc_image") and self.osc_image is not None:
            cont_red = self.osc_image[..., 0]
        else:
            cont_red = None

        if hasattr(self, "green_image") and self.green_image is not None:
            cont_green = self.green_image
        elif hasattr(self, "osc_image") and self.osc_image is not None:
            cont_green = self.osc_image[..., 1]
        else:
            cont_green = None

        # — build tasks as before —
        tasks = []
        if self.ha_image is not None and cont_red is not None:
            tasks.append(("Ha",  self.ha_image,  cont_red))
        if self.sii_image is not None and cont_red is not None:
            tasks.append(("SII", self.sii_image, cont_red))
        if self.oiii_image is not None and cont_green is not None:
            tasks.append(("OIII", self.oiii_image, cont_green))

        if not tasks:
            self.statusLabel.setText("Load at least one NB + matching continuum channel (or OSC).")
            return


        self.showSpinner()

        self._threads.clear()
        self._pending = len(tasks)
        self._results = []

        for name, nb, cont in tasks:
            t = ContinuumProcessingThread(nb, cont, self.linear_output_checkbox.isChecked())
            t.status_update.connect(self.update_status_label)
            t.processing_complete.connect(
                lambda img, stars, overlay, raw, after, n=name:
                    self._onOneResult(n, img, stars, overlay, raw, after)
            )
            t.finished.connect(self._onThreadFinished)
            self._threads.append(t)      # keep a reference
            t.start()

    def _onOneResult(self, filt, img, star_count, overlay_qimg, raw_pixels, after_pixels):
        # stash for later slot‐pushing
        self._results.append({
            "filter":  filt,
            "image":   img,
            "stars":   star_count,
            "overlay": overlay_qimg,
            "raw":     raw_pixels,
            "after":   after_pixels
        })

        # build scatter‐plot
        nb_flux   = raw_pixels[:, 0]
        cont_flux = raw_pixels[:, 1]
        h, w = 200, 200
        scatter_img = np.ones((h, w, 3), np.uint8) * 255

        # 1) Compute best-fit in flux space: NB ≈ m·BB + c
        m, c = np.polyfit(cont_flux, nb_flux, 1)

        # 2) Choose two BB positions to draw the line at (0 and 1)
        x0f, y0f = 0.0, c
        x1f, y1f = 1.0, m*1.0 + c

        # clip so we stay within [0,1]
        y0f = np.clip(y0f, 0.0, 1.0)
        y1f = np.clip(y1f, 0.0, 1.0)

        # map to pixel coords
        x0 = int(x0f * (w - 1))
        y0 = int((1 - y0f) * (h - 1))
        x1 = int(x1f * (w - 1))
        y1 = int((1 - y1f) * (h - 1))

        # draw the fit line (in blue, thickness 2)
        cv2.line(scatter_img, (x0, y0), (x1, y1), (255, 0, 0), 2)

        # 3) Plot points
        xs = (cont_flux * (w - 1)).astype(int)
        ys = ((1 - nb_flux) * (h - 1)).astype(int)
        for x, y in zip(xs, ys):
            cv2.circle(scatter_img, (x, y), 2, (0, 0, 255), -1)
        # draw axes
        cv2.line(scatter_img, (0, h - 1), (w - 1, h - 1), (0, 0, 0), 1)  # x-axis
        cv2.line(scatter_img, (0, 0),       (0, h - 1),     (0, 0, 0), 1)  # y-axis

        # put “BB Flux” centered on the x-axis
        font = cv2.FONT_HERSHEY_SIMPLEX
        text = "BB Flux"
        ((tw, th), _) = cv2.getTextSize(text, font, 0.5, 1)
        x_text = (w - tw) // 2
        y_text = h - 5  # just above bottom
        cv2.putText(scatter_img, text, (x_text, y_text), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # put “NB Flux” vertically along the left
        vert_text = "NB Flux"
        # draw each character, stepping down
        for i, ch in enumerate(vert_text):
            # x is a few pixels right of the y-axis, y steps by 15px
            cv2.putText(scatter_img, ch, (2, 15 + i*15), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # convert to QPixmap
        qscatter = QImage(scatter_img.data, w, h, 3*w, QImage.Format.Format_RGB888).copy()
        scatter_pix = QPixmap.fromImage(qscatter)

        # overlay thumbnail
        thumb_pix = QPixmap.fromImage(overlay_qimg).scaled(
            200, 200,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # assemble entry row
        entry = QWidget()
        elay  = QHBoxLayout(entry)

        # 1) star count label
        elay.addWidget(QLabel(f"{filt}: {star_count} stars"))

        # 2) scatter thumbnail
        scatter_label = QLabel()
        scatter_label.setPixmap(scatter_pix)
        scatter_label.setCursor(Qt.CursorShape.PointingHandCursor)
        elay.addWidget(scatter_label)
        # remember it & install filter
        self._clickable_images[scatter_label] = scatter_pix
        scatter_label.installEventFilter(self)

        # 3) overlay thumbnail
        overlay_label = QLabel()
        overlay_label.setPixmap(thumb_pix)
        overlay_label.setCursor(Qt.CursorShape.PointingHandCursor)
        elay.addWidget(overlay_label)
        self._clickable_images[overlay_label] = QPixmap.fromImage(overlay_qimg)
        overlay_label.installEventFilter(self)

        elay.addStretch(1)
        entry.setLayout(elay)

        # add to the WB column
        self.wb_l.addWidget(entry)

    def eventFilter(self, source, event):
        # catch mouse releases on any of our clickable labels
        if event.type() == QEvent.Type.MouseButtonRelease and source in self._clickable_images:
            pix = self._clickable_images[source]
            self._showEnlarged(pix)
            return True
        return super().eventFilter(source, event)

    def _showEnlarged(self, pixmap):
        # simple dialog that just shows the pixmap at window-fitting size
        dlg = QDialog(self)
        dlg.setWindowTitle("Detail View")
        layout = QVBoxLayout(dlg)
        lbl = QLabel()
        lbl.setPixmap(pixmap.scaled(800, 800, Qt.AspectRatioMode.KeepAspectRatio,
                                     Qt.TransformationMode.SmoothTransformation))
        layout.addWidget(lbl)
        dlg.resize(820, 820)
        dlg.exec()  # modal; user closes when done

    def _onThreadFinished(self):
        self._pending -= 1
        if self._pending == 0:
            self.hideSpinner()
            self._pushResultsToSlots(self._results)

    def _pushResultsToSlots(self, results):
        max_slots = self.image_manager.max_slots
        pushed = []
        # make sure we have a place to keep our preview dialogs alive
        if not hasattr(self, '_preview_dialogs'):
            self._preview_dialogs = {}

        for entry in results:
            filt = entry["filter"]
            img  = entry["image"]
            # ensure mono
            if img.ndim == 3 and img.shape[2] == 3:
                img = img[..., 0]  # take one channel for the preview
            for slot in range(max_slots):
                existing = self.image_manager._images.get(slot)
                if existing is None or (isinstance(existing, np.ndarray) and existing.size <= 100):
                    name = f"{filt}_ContSub"
                    meta = {
                        'file_path': name,
                        'is_mono': True,
                        'bit_depth': "32-bit floating point",
                        'source': name
                    }
                    # store and emit
                    self.image_manager._images[slot]   = img
                    self.image_manager._metadata[slot] = meta
                    self.image_manager.image_changed.emit(slot, img, meta)

                    # rename toolbar & menubar
                    mw = self.window()  # AstroEditingSuite
                    mw.slot_names[slot] = name
                    if slot in mw.slot_actions:
                        act = mw.slot_actions[slot]
                        act.setText(name)
                        act.setStatusTip(f"Open preview for {name}")
                    if slot in mw.menubar_slot_actions:
                        mact = mw.menubar_slot_actions[slot]
                        mact.setText(name)
                        mact.setStatusTip(f"Open preview for {name}")
                    mw.menuBar().update()

                    pushed.append(slot)
                    break
            if len(pushed) >= min(3, len(results)):
                break

        self.statusLabel.setText(f"Pushed {len(pushed)} images to slots.")

        # show non-modal previews and keep them alive
        for slot in pushed:
            img  = self.image_manager._images[slot]
            mono = self.image_manager._metadata[slot].get('is_mono', False)
            dlg  = ImagePreviewDialog(img, is_mono=mono)
            title = f"Slot {slot+1}: {mw.slot_names[slot]}"
            dlg.setWindowTitle(title)
            dlg.show()
            # store a reference so it doesn’t get garbage-collected
            self._preview_dialogs[slot] = dlg

        return pushed


    def update_status_label(self, message):
        self.statusLabel.setText(message)

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()



class ContinuumProcessingThread(QThread):
    processing_complete = pyqtSignal(np.ndarray, int, QImage, np.ndarray, np.ndarray)
    status_update = pyqtSignal(str)

    def __init__(self, nb_image, continuum_image, output_linear):
        super().__init__()
        self.nb_image = nb_image
        self.continuum_image = continuum_image
        self.output_linear = output_linear
        self.background_reference = None  # Store the background reference



    def run(self):
        # Ensure both images are mono
        if self.nb_image.ndim == 3 and self.nb_image.shape[2] == 3:
            self.nb_image = self.nb_image[..., 0]  # Take one channel for the NB image

        if self.continuum_image.ndim == 3 and self.continuum_image.shape[2] == 3:
            self.continuum_image = self.continuum_image[..., 0]  # Take one channel for the continuum image

        # Create RGB image
        r_combined = self.nb_image  # Use the normalized NB image as the Red channel
        g_combined = self.continuum_image # Use the normalized continuum image as the Green channel
        b_combined = self.continuum_image  # Use the normalized continuum image as the Blue channel


        # Stack the channels into a single RGB image
        combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)

        self.status_update.emit("Performing background neutralization...")
        QCoreApplication.processEvents()
            # Perform background neutralization
        self.background_neutralization(combined_image)

        # Normalize the red channel to the green channel
        combined_image[..., 0] = self.normalize_channel(combined_image[..., 0], combined_image[..., 1])

        self.status_update.emit("Performing star-based white balance…")
        balanced_rgb, star_count, star_overlay, raw_star_pixels, after_star_pixels = \
            apply_star_based_white_balance(
                combined_image,
                threshold=1.5,
                autostretch=False,
                reuse_cached_sources=True,
                return_star_colors=True
            )
        combined_image[:] = balanced_rgb   # replace working image with the white-balanced one
        
        self.status_update.emit(f"White balance complete ({star_count} stars).")
        QCoreApplication.processEvents()

        # Perform continuum subtraction
        linear_image = combined_image[..., 0] - 0.9*(combined_image[..., 1]-np.median(combined_image[..., 1]))

            # Check if the Output Linear checkbox is checked
        if self.output_linear:
            # Emit the linear image for preview
            self.processing_complete.emit(np.clip(linear_image, 0, 1))
            return  # Exit the method if we only want to output the linear image

        self.status_update.emit("Subtraction complete.")
        QCoreApplication.processEvents()

        # Perform statistical stretch
        target_median = 0.25
        stretched_image = stretch_color_image(linear_image, target_median, True, False)

        # Final image adjustment
        final_image = stretched_image - 0.7*np.median(stretched_image)

        # Clip the final image to stay within [0, 1]
        final_image = np.clip(final_image, 0, 1)

        # Applies Curves Boost
        final_image = apply_curves_adjustment(final_image, np.median(final_image), 0.5)

        self.status_update.emit("Linear to Non-Linear Stretch complete.")
        QCoreApplication.processEvents()

        overlay_uint8 = (star_overlay * 255).astype(np.uint8)
        h2, w2 = overlay_uint8.shape[:2]
        bytes_per_line = 3 * w2
        qimg = QImage(
            overlay_uint8.data, w2, h2, bytes_per_line,
            QImage.Format.Format_RGB888
        ).copy()
        # Emit the final image for preview
        self.processing_complete.emit(
            final_image,          # → np.ndarray
            star_count,           # → int
            qimg,                 # → QImage
            np.array(raw_star_pixels),   # → np.ndarray
            np.array(after_star_pixels)  # → np.ndarray
        )

    def background_neutralization(self, rgb_image):
        height, width, _ = rgb_image.shape
        num_boxes = 200
        box_size = 25
        iterations = 25

        boxes = [(np.random.randint(0, height - box_size), np.random.randint(0, width - box_size)) for _ in range(num_boxes)]
        best_means = np.full(num_boxes, np.inf)

        for _ in range(iterations):
            for i, (y, x) in enumerate(boxes):
                if y + box_size <= height and x + box_size <= width:
                    patch = rgb_image[y:y + box_size, x:x + box_size]
                    patch_median = np.median(patch) if patch.size > 0 else np.inf

                    if patch_median < best_means[i]:
                        best_means[i] = patch_median

                    surrounding_values = []
                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            surrounding_y = y + dy * box_size
                            surrounding_x = x + dx * box_size
                            
                            if (0 <= surrounding_y < height - box_size) and (0 <= surrounding_x < width - box_size):
                                surrounding_patch = rgb_image[surrounding_y:surrounding_y + box_size, surrounding_x:surrounding_x + box_size]
                                if surrounding_patch.size > 0:
                                    surrounding_values.append(np.median(surrounding_patch))

                    if surrounding_values:
                        dimmest_index = np.argmin(surrounding_values)
                        new_y = y + (dimmest_index // 3 - 1) * box_size
                        new_x = x + (dimmest_index % 3 - 1) * box_size
                        boxes[i] = (new_y, new_x)

        # After iterations, find the darkest box median
        darkest_value = np.inf
        background_box = None

        for box in boxes:
            y, x = box
            if y + box_size <= height and x + box_size <= width:
                patch = rgb_image[y:y + box_size, x:y + box_size]
                patch_median = np.median(patch) if patch.size > 0 else np.inf

                if patch_median < darkest_value:
                    darkest_value = patch_median
                    background_box = patch

        if background_box is not None:
            self.background_reference = np.median(background_box.reshape(-1, 3), axis=0)
            
            # Adjust the channels based on the median reference
            channel_medians = np.median(rgb_image, axis=(0, 1))

            # Adjust channels based on the red channel
            for channel in range(3):
                if self.background_reference[channel] < channel_medians[channel]:
                    pedestal = channel_medians[channel] - self.background_reference[channel]
                    rgb_image[..., channel] += pedestal

            # Specifically adjust G and B to match R
            r_median = self.background_reference[0]
            for channel in [1, 2]:  # Green and Blue channels
                if self.background_reference[channel] < r_median:
                    rgb_image[..., channel] += (r_median - self.background_reference[channel])

        self.status_update.emit("Background neutralization complete.")
        QCoreApplication.processEvents()
        return rgb_image
    
    def normalize_channel(self, image_channel, reference_channel):
        mad_image = np.mean(np.abs(image_channel - np.mean(image_channel)))
        mad_ref = np.mean(np.abs(reference_channel - np.mean(reference_channel)))

        median_image = np.median(image_channel)
        median_ref = np.median(reference_channel)

        # Apply the normalization formula
        normalized_channel = (
            image_channel * mad_ref / mad_image
            - (mad_ref / mad_image) * median_image
            + median_ref
        )

        self.status_update.emit("Color calibration complete.")
        QCoreApplication.processEvents()
        return np.clip(normalized_channel, 0, 1)  



    def continuum_subtraction(self, rgb_image):
        red_channel = rgb_image[..., 0]
        green_channel = rgb_image[..., 1]
        
        # Determine Q based on the selection (modify condition based on actual UI element)
        Q = 0.9 if self.output_linear else 1.0

        # Perform the continuum subtraction
        median_green = np.median(green_channel)
        result_image = red_channel - Q * (green_channel - median_green)
        
        return np.clip(result_image, 0, 1)  # Ensure values stay within [0, 1]

def preprocess_narrowband_image(image):
    """
    Preprocess narrowband images to ensure they are single-channel.
    If the image is detected as a mono image stored in 3-channel format, the red channel is used.
    """
    if image is not None:
        if image.ndim == 3:
            if image.shape[2] == 3:
                # Use the red channel if the image is multi-channel
                print("Detected multi-channel RGB data. Using the red channel as mono.")
                image = image[..., 0]
            elif image.shape[2] == 1:
                # Squeeze single redundant channel
                print("Detected 1-channel image with extra dimension. Squeezing to single channel.")
                image = np.squeeze(image, axis=-1)
        elif image.ndim != 2:
            raise ValueError(f"Unexpected image shape: {image.shape}")
    return image



def apply_standard_white_balance(image: np.ndarray, r_gain: float = 1.0, g_gain: float = 1.0, b_gain: float = 1.0) -> np.ndarray:
    """
    Applies standard white balance by adjusting the gain of each color channel.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        r_gain (float): Gain for the Red channel.
        g_gain (float): Gain for the Green channel.
        b_gain (float): Gain for the Blue channel.

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    balanced = image.copy()
    balanced[:, :, 0] *= r_gain
    balanced[:, :, 1] *= g_gain
    balanced[:, :, 2] *= b_gain
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

def apply_auto_white_balance(image: np.ndarray) -> np.ndarray:
    """
    Applies automatic white balance using the Gray World Assumption.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    # Calculate the mean of each channel
    mean_r = np.mean(image[:, :, 0])
    mean_g = np.mean(image[:, :, 1])
    mean_b = np.mean(image[:, :, 2])
    
    # Calculate the overall mean
    mean_all = (mean_r + mean_g + mean_b) / 3
    
    # Calculate gains
    gain_r = mean_all / mean_r if mean_r != 0 else 1.0
    gain_g = mean_all / mean_g if mean_g != 0 else 1.0
    gain_b = mean_all / mean_b if mean_b != 0 else 1.0
    
    # Apply gains
    balanced = image.copy()
    balanced[:, :, 0] *= gain_r
    balanced[:, :, 1] *= gain_g
    balanced[:, :, 2] *= gain_b
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

cached_star_sources = None
cached_flux_radii = None


def plot_star_color_ratios_comparison(raw_pixels: np.ndarray, after_pixels: np.ndarray):


    def compute_ratios(pixels):
        rb = pixels[:, 0] / (pixels[:, 2] + 1e-8)
        gb = pixels[:, 1] / (pixels[:, 2] + 1e-8)
        return rb, gb

    rb_before, gb_before = compute_ratios(raw_pixels)
    rb_after, gb_after = compute_ratios(after_pixels)

    # Define plot bounds
    rmin, rmax = 0.5, 2.0
    gmin, gmax = 0.5, 2.0
    res = 200  # resolution of the background grid

    # Create background color grid
    rb_vals = np.linspace(rmin, rmax, res)
    gb_vals = np.linspace(gmin, gmax, res)
    rb_grid, gb_grid = np.meshgrid(rb_vals, gb_vals)

    rgb_image = np.stack([rb_grid, gb_grid, np.ones_like(rb_grid)], axis=-1)
    rgb_image /= np.max(rgb_image, axis=2, keepdims=True)  # Normalize to [0,1]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)

    def plot_panel(ax, rb_data, gb_data, title):
        ax.imshow(rgb_image, extent=(rmin, rmax, gmin, gmax), origin='lower', aspect='auto')

        ax.scatter(rb_data, gb_data, alpha=0.6, edgecolors='k', label="Stars")

        # Fit best line
        m, b = np.polyfit(rb_data, gb_data, 1)
        x_vals = np.linspace(rmin, rmax, 100)
        ax.plot(x_vals, m * x_vals + b, 'r--', label=f"Best Fit\ny = {m:.2f}x + {b:.2f}")

        # Neutral indicators
        ax.axhline(1.0, color='gray', linestyle=':', linewidth=1)
        ax.axvline(1.0, color='gray', linestyle=':', linewidth=1)
        ax.add_patch(Circle((1.0, 1.0), 0.2, fill=False, edgecolor='blue', linestyle='--', linewidth=1.5))
        ax.text(1.03, 1.17, "Neutral Region", color='blue', fontsize=9)

        ax.set_xlim(rmin, rmax)
        ax.set_ylim(gmin, gmax)
        ax.set_title(f"{title} White Balance")
        ax.set_xlabel("Red / Blue Ratio")
        ax.set_ylabel("Green / Blue Ratio")
        ax.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax.yaxis.set_major_locator(MaxNLocator(integer=True))
        ax.grid(True)
        ax.legend()

    plot_panel(ax1, rb_before, gb_before, "Before")
    plot_panel(ax2, rb_after, gb_after, "After")

    plt.suptitle("Star Color Ratios with RGB Mapping", fontsize=14)
    plt.tight_layout()
    plt.show()


def apply_star_based_white_balance(
    image: np.ndarray,
    threshold: float = 1.5,
    autostretch: bool = True,
    reuse_cached_sources: bool = False,
    return_star_colors: bool = False
) -> tuple:
    global cached_star_sources, cached_flux_radii

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("Input must be an RGB image.")

    # Step 1: Neutralize background using darkest patch
    patch_size = 10
    h, w = image.shape[:2]
    patch_h = h // patch_size
    patch_w = w // patch_size

    min_median_sum = float("inf")
    best_patch = None

    for i in range(patch_size):
        for j in range(patch_size):
            y0 = i * patch_h
            x0 = j * patch_w
            y1 = min(y0 + patch_h, h)
            x1 = min(x0 + patch_w, w)

            patch = image[y0:y1, x0:x1, :]
            medians = np.median(patch, axis=(0, 1))
            if np.sum(medians) < min_median_sum:
                min_median_sum = np.sum(medians)
                best_patch = medians

    if best_patch is None:
        raise RuntimeError("Failed to find a neutral background patch.")

    avg_median = np.mean(best_patch)

    # Apply tone-preserving background neutralization (first pass)
    bg_neutralized = image.copy()
    for c in range(3):
        diff = best_patch[c] - avg_median
        denom = 1.0 - diff if abs(1.0 - diff) > 1e-8 else 1e-8
        bg_neutralized[:, :, c] = np.clip((bg_neutralized[:, :, c] - diff) / denom, 0.0, 1.0)

    # Step 2: Detect or reuse star positions
    # 2) Detect or reuse star positions
    gray_neutral = np.mean(bg_neutralized, axis=2).astype(np.float32)
    bkg2        = sep.Background(gray_neutral)
    data_sub    = gray_neutral - bkg2.back()
    err_val     = bkg2.globalrms

    sources, r = None, None
    if reuse_cached_sources and cached_star_sources is not None:
        sources = cached_star_sources
        r       = cached_flux_radii
    else:
        sources = sep.extract(data_sub, threshold, err=err_val)
        if len(sources) == 0:
            raise ValueError("No stars detected for Star-Based White Balance.")
        r, _ = sep.flux_radius(
            gray_neutral,
            sources['x'], sources['y'],
            2.0 * sources['a'], 0.2,
            normflux=sources['flux'],
            subpix=5
        )
        cached_star_sources  = sources
        cached_flux_radii    = r

    # → throw away anything too big to be a star:
    mask    = (r > 0) & (r <= 10)
    sources = sources[mask]
    r       = r[mask]

    if len(sources) == 0:
        raise ValueError("All detected sources were too large; no valid stars for White Balance.")


    # NEW: Sample star colors from original image (before any adjustments)
    raw_star_pixels = []
    for i in range(len(sources)):
        x = int(sources['x'][i])
        y = int(sources['y'][i])
        if r[i] > 0 and 0 <= y < h and 0 <= x < w:
            raw_star_pixels.append(image[y, x, :])  # use original image here

    # Step 3: Create preview with ellipses
    display_image = stretch_color_image(bg_neutralized.copy(), 0.25) if autostretch else bg_neutralized.copy()
    image_with_stars = cv2.cvtColor((display_image * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

    star_pixels = []
    for i in range(len(sources)):
        x = sources['x'][i]
        y = sources['y'][i]
        a = sources['a'][i]
        b = sources['b'][i]
        theta = sources['theta'][i] * 180. / np.pi

        if r[i] > 0 and 0 <= int(y) < h and 0 <= int(x) < w:
            star_pixels.append(bg_neutralized[int(y), int(x), :])
            center = (int(x), int(y))
            axes = (int(3 * a), int(3 * b))
            cv2.ellipse(image_with_stars, center, axes, angle=theta, startAngle=0, endAngle=360,
                        color=(0, 0, 255), thickness=1)

    star_count = len(star_pixels)
    if star_count == 0:
        raise ValueError("No stars passed filtering for white balance.")

    # Step 4: White balance using brightest average channel
    star_pixels = np.array(star_pixels)
    avg_color = np.mean(star_pixels, axis=0)
    max_val = np.max(avg_color)
    scaling_factors = max_val / avg_color

    balanced = bg_neutralized.copy()
    for ch in range(3):
        balanced[:, :, ch] *= scaling_factors[ch]
    balanced = np.clip(balanced, 0.0, 1.0)

    # Step 5: Final background neutralization using updated image
    patch_size = 10
    h, w = balanced.shape[:2]
    patch_h = h // patch_size
    patch_w = w // patch_size

    min_median_sum = float("inf")
    best_patch = None

    for i in range(patch_size):
        for j in range(patch_size):
            y0 = i * patch_h
            x0 = j * patch_w
            y1 = min(y0 + patch_h, h)
            x1 = min(x0 + patch_w, w)

            patch = balanced[y0:y1, x0:x1, :]
            medians = np.median(patch, axis=(0, 1))
            if np.sum(medians) < min_median_sum:
                min_median_sum = np.sum(medians)
                best_patch = medians

    if best_patch is not None:
        avg_median = np.mean(best_patch)
        for c in range(3):
            diff = best_patch[c] - avg_median
            denom = 1.0 - diff if abs(1.0 - diff) > 1e-8 else 1e-8
            balanced[:, :, c] = np.clip((balanced[:, :, c] - diff) / denom, 0.0, 1.0)

  # Step 6: Collect "after" star pixels from balanced image            
    after_star_pixels = []
    for i in range(len(sources)):
        x = int(sources['x'][i])
        y = int(sources['y'][i])
        if r[i] > 0 and 0 <= y < h and 0 <= x < w:
            after_star_pixels.append(balanced[y, x, :])

    if return_star_colors:
        return balanced, star_count, image_with_stars, np.array(raw_star_pixels), np.array(after_star_pixels)
    return balanced, star_count, image_with_stars

def apply_morphology(image: np.ndarray, operation: str = 'erosion', kernel_size: int = 3, iterations: int = 1) -> np.ndarray:
    """
    Applies a morphological operation to the image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        operation (str): Morphological operation ('erosion', 'dilation', 'opening', 'closing').
        kernel_size (int): Size of the structuring element.
        iterations (int): Number of times the operation is applied.

    Returns:
        np.ndarray: Morphologically processed RGB image.
    """
    # Define the structuring element
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))

    # Convert image to uint8
    image_uint8 = (image * 255).astype(np.uint8)

    # Apply the selected operation
    if operation == 'erosion':
        processed = cv2.erode(image_uint8, kernel, iterations=iterations)
    elif operation == 'dilation':
        processed = cv2.dilate(image_uint8, kernel, iterations=iterations)
    elif operation == 'opening':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif operation == 'closing':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    else:
        raise ValueError("Unsupported morphological operation.")

    # Convert back to float [0,1]
    processed_image = processed.astype(np.float32) / 255.0
    return processed_image

def apply_clahe(image: np.ndarray, clip_limit: float = 2.0, tile_grid_size: tuple = (8, 8)) -> np.ndarray:
    """
    Applies CLAHE to the image for adaptive contrast enhancement.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        clip_limit (float): Threshold for contrast limiting.
        tile_grid_size (tuple): Size of grid for histogram equalization.

    Returns:
        np.ndarray: Contrast-enhanced RGB image.
    """
    if image.ndim == 2:
        # Grayscale image
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        enhanced = clahe.apply((image * 255).astype(np.uint8))
        return enhanced / 255.0
    elif image.ndim == 3 and image.shape[2] == 3:
        # Convert to LAB color space
        lab = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2LAB)
        # Split the channels
        l, a, b = cv2.split(lab)
        # Apply CLAHE to the L-channel
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        cl = clahe.apply(l)
        # Merge the channels back
        limg = cv2.merge((cl, a, b))
        # Convert back to RGB
        enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB) / 255.0
        return enhanced
    else:
        raise ValueError("Input image must be either grayscale or RGB.")

def apply_average_neutral_scnr(image: np.ndarray, amount: float = 1.0) -> np.ndarray:
    """
    Applies the Average Neutral SCNR method to remove green noise from an RGB image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array with shape (H, W, 3).
                            The image should be normalized to the [0, 1] range.
        amount (float): Blending factor between the original and SCNR-processed image.
                        0.0 returns the original image, 1.0 returns the fully SCNR-processed image.

    Returns:
        np.ndarray: The SCNR-processed RGB image.
    """
    if not isinstance(image, np.ndarray):
        raise TypeError("Input image must be a NumPy array.")

    if image.ndim != 3 or image.shape[2] != 3:
        print(f"apply_average_neutral_scnr received invalid image shape: {image.shape}")
        raise ValueError("Input image must have three channels (RGB).")

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("Input image must have three channels (RGB).")

    if not (0.0 <= amount <= 1.0):
        raise ValueError("Amount parameter must be between 0.0 and 1.0.")

    # Ensure the image is in float format
    image = image.astype(np.float32)

    # Separate the channels
    R, G, B = image[..., 0], image[..., 1], image[..., 2]

    # Apply the Average Neutral SCNR formula: G' = min(G, 0.5*(R + B))
    G_scnr = np.minimum(G, 0.5 * (R + B))

    # Create the SCNR image
    scnr_image = image.copy()
    scnr_image[..., 1] = G_scnr  # Replace the green channel

    # Blend the original and SCNR images based on the amount parameter
    final_image = (1.0 - amount) * image + amount * scnr_image

    # Ensure the final image is still within [0, 1]
    final_image = np.clip(final_image, 0.0, 1.0)

    return final_image


def load_image(filename, max_retries=3, wait_seconds=3):
    """
    Loads an image from the specified filename with support for various formats.
    If a "buffer is too small for requested array" error occurs, it retries loading after waiting.

    Parameters:
        filename (str): Path to the image file.
        max_retries (int): Number of times to retry on specific buffer error.
        wait_seconds (int): Seconds to wait before retrying.

    Returns:
        tuple: (image, original_header, bit_depth, is_mono) or (None, None, None, None) on failure.
    """
    attempt = 0
    while attempt <= max_retries:
        try:
            image = None  # Ensure 'image' is explicitly declared
            bit_depth = None
            is_mono = False
            original_header = None

            # --- Unified FITS handling ---
            if filename.lower().endswith(('.fits', '.fit', '.fits.gz', '.fit.gz', '.fz', '.fz')):
                # Use get_valid_header to retrieve the header and extension index.
                original_header, ext_index = get_valid_header(filename)

                
                # Open the file appropriately.
                if filename.lower().endswith(('.fits.gz', '.fit.gz')):
                    print(f"Loading compressed FITS file: {filename}")
                    with gzip.open(filename, 'rb') as f:
                        file_content = f.read()
                    hdul = fits.open(BytesIO(file_content))
                else:
                    if filename.lower().endswith(('.fz', '.fz')):
                        print(f"Loading Rice-compressed FITS file: {filename}")
                    else:
                        print(f"Loading FITS file: {filename}")
                    hdul = fits.open(filename)

                with hdul as hdul:
                    # Retrieve image data from the extension indicated by get_valid_header.
                    image_data = hdul[ext_index].data
                    if image_data is None:
                        raise ValueError(f"No image data found in FITS file in extension {ext_index}.")

                    # Ensure native byte order
                    if image_data.dtype.byteorder not in ('=', '|'):
                        image_data = image_data.astype(image_data.dtype.newbyteorder('='))

                    # ---------------------------------------------------------------------
                    # 1) Detect bit depth and convert to float32
                    # ---------------------------------------------------------------------
                    if image_data.dtype == np.uint8:
                        bit_depth = "8-bit"
                        print("Identified 8-bit FITS image.")
                        image = image_data.astype(np.float32) / 255.0

                    elif image_data.dtype == np.uint16:
                        bit_depth = "16-bit"
                        print("Identified 16-bit FITS image.")
                        image = image_data.astype(np.float32) / 65535.0

                    elif image_data.dtype == np.int32:
                        bit_depth = "32-bit signed"
                        print("Identified 32-bit signed FITS image.")
                        bzero  = original_header.get('BZERO', 0)
                        bscale = original_header.get('BSCALE', 1)
                        image = image_data.astype(np.float32) * bscale + bzero

                    elif image_data.dtype == np.uint32:
                        bit_depth = "32-bit unsigned"
                        print("Identified 32-bit unsigned FITS image.")
                        bzero  = original_header.get('BZERO', 0)
                        bscale = original_header.get('BSCALE', 1)
                        image = image_data.astype(np.float32) * bscale + bzero

                    elif image_data.dtype == np.float32:
                        bit_depth = "32-bit floating point"
                        print("Identified 32-bit floating point FITS image.")
                        image = image_data
                    else:
                        raise ValueError(f"Unsupported FITS data type: {image_data.dtype}")

                    # ---------------------------------------------------------------------
                    # 2) Squeeze out any singleton dimensions (fix weird NAXIS combos)
                    # ---------------------------------------------------------------------
                    image = np.squeeze(image)

                    # ---------------------------------------------------------------------
                    # 3) Interpret final shape to decide if mono or color
                    # ---------------------------------------------------------------------
                    if image.ndim == 2:
                        is_mono = True
                    elif image.ndim == 3:
                        if image.shape[0] == 3 and image.shape[1] > 1 and image.shape[2] > 1:
                            image = np.transpose(image, (1, 2, 0))
                            is_mono = False
                        elif image.shape[-1] == 3:
                            is_mono = False
                        else:
                            raise ValueError(f"Unsupported 3D shape after squeeze: {image.shape}")
                    else:
                        raise ValueError(f"Unsupported FITS dimensions after squeeze: {image.shape}")

                    print(f"Loaded FITS image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
                    return image, original_header, bit_depth, is_mono



            elif filename.lower().endswith(('.tiff', '.tif')):
                print(f"Loading TIFF file: {filename}")
                image_data = tiff.imread(filename)
                print(f"Loaded TIFF image with dtype: {image_data.dtype}")

                # Determine bit depth and normalize
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    image = image_data.astype(np.float32) / 255.0
                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    image = image_data.astype(np.float32) / 65535.0
                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    image = image_data.astype(np.float32) / 4294967295.0
                elif image_data.dtype == np.float32:
                    bit_depth = "32-bit floating point"
                    image = image_data
                else:
                    raise ValueError("Unsupported TIFF format!")

                # Handle mono or RGB TIFFs
                if image_data.ndim == 2:  # Mono
                    is_mono = True
                elif image_data.ndim == 3 and image_data.shape[2] == 3:  # RGB
                    is_mono = False
                else:
                    raise ValueError("Unsupported TIFF image dimensions!")

            elif filename.lower().endswith('.xisf'):
                print(f"Loading XISF file: {filename}")
                xisf = XISF(filename)

                # Read image data (assuming the first image in the XISF file)
                image_data = xisf.read_image(0)  # Adjust the index if multiple images are present

                # Retrieve metadata
                image_meta = xisf.get_images_metadata()[0]  # Assuming single image
                file_meta = xisf.get_file_metadata()


                # Here we check the maximum pixel value to determine bit depth
                # --- Detect the bit depth by dtype ---
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    print("Debug: Detected 8-bit dtype. Normalizing by 255.")
                    image = image_data.astype(np.float32) / 255.0

                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    print("Debug: Detected 16-bit dtype. Normalizing by 65535.")
                    image = image_data.astype(np.float32) / 65535.0

                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    print("Debug: Detected 32-bit unsigned dtype. Normalizing by 4294967295.")
                    image = image_data.astype(np.float32) / 4294967295.0

                elif image_data.dtype == np.float32 or image_data.dtype == np.float64:
                    bit_depth = "32-bit floating point"
                    print("Debug: Detected float dtype. Casting to float32 (no normalization).")
                    image = image_data.astype(np.float32)

                else:
                    raise ValueError(f"Unsupported XISF data type: {image_data.dtype}")

                # Handle mono or RGB XISF
                if image_data.ndim == 2:
                    # We know it's mono. Already normalized in `image`.
                    is_mono = True
                    # If you really want to store it in an RGB shape:
                    #image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 1:
                    # It's mono with shape (H, W, 1)
                    is_mono = True
                    # Squeeze the normalized image, not the original image_data
                    image = np.squeeze(image, axis=2)
                    # If you want an RGB shape, you can do:
                    #image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 3:
                    is_mono = False
                    # We already stored the normalized float32 data in `image`.
                    # So no change needed if it’s already shape (H, W, 3).

                else:
                    raise ValueError("Unsupported XISF image dimensions!")

                # For XISF, you can choose what to set as original_header
                # It could be a combination of file_meta and image_meta or any other relevant information
                original_header = {
                    "file_meta": file_meta,
                    "image_meta": image_meta
                }

                print(f"Loaded XISF image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
                return image, original_header, bit_depth, is_mono

            elif filename.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print(f"Loading RAW file: {filename}")
                with rawpy.imread(filename) as raw:
                    # 1) Read the raw Bayer data (no demosaic)
                    bayer_image = raw.raw_image_visible.astype(np.float32)
                    print(f"Raw Bayer image dtype: {bayer_image.dtype}, "
                        f"min: {bayer_image.min():.2f}, max: {bayer_image.max():.2f}")

                    # 2) Get camera black/white levels
                    black_levels = raw.black_level_per_channel  # e.g. [512, 512, 512, 512]
                    white_level  = raw.white_level              # e.g. 16383 for 14-bit
                    avg_black = float(np.mean(black_levels))    # Simple average

                    # 3) Subtract black level, clip negatives to 0
                    bayer_image -= avg_black
                    bayer_image = np.clip(bayer_image, 0, None)

                    # 4) Divide by (white_level - black_level) to normalize to [0..1]
                    scale = float(white_level - avg_black)
                    if scale <= 0:
                        # Safety check if black >= white
                        scale = 1.0
                    bayer_image /= scale

                    # Now dark frames should hover near 0.0 instead of ~0.7

                    # 5) Check shape to decide if mono vs. color mosaic
                    #    Usually it's 2D for a raw Bayer pattern
                    if bayer_image.ndim == 2:
                        image = bayer_image
                        is_mono = True
                    elif bayer_image.ndim == 3 and bayer_image.shape[2] == 3:
                        # Rare case if raw.raw_image_visible is already color
                        image = bayer_image
                        is_mono = False
                    else:
                        raise ValueError(f"Unexpected RAW Bayer image shape: {bayer_image.shape}")

                    # 6) Assume 16-bit raw data (typical for DSLRs)
                    bit_depth = "16-bit"

                    # 7) Build a minimal header from raw metadata
                    original_header_dict = {
                        'CAMERA': raw.camera_whitebalance[0] if raw.camera_whitebalance else 'Unknown',
                        'EXPTIME': raw.shutter if hasattr(raw, 'shutter') else 0.0,
                        'ISO': raw.iso_speed if hasattr(raw, 'iso_speed') else 0,
                        'FOCAL': raw.focal_len if hasattr(raw, 'focal_len') else 0.0,
                        'DATE': raw.timestamp if hasattr(raw, 'timestamp') else 'Unknown',
                    }

                    # 8) Extract the CFA pattern
                    cfa_pattern = raw.raw_colors_visible  # 2D array of 0/1/2
                    cfa_mapping = {0: 'R', 1: 'G', 2: 'B'}
                    cfa_description = ''.join([cfa_mapping.get(color, '?')
                                            for color in cfa_pattern.flatten()[:4]])
                    original_header_dict['CFA'] = (cfa_description, 'Color Filter Array pattern')

                    # 9) Convert dict → FITS Header
                    original_header = fits.Header()
                    for key, value in original_header_dict.items():
                        original_header[key] = value

                    print(f"RAW file loaded with CFA pattern: {cfa_description}, "
                        f"dark frames ~0, bright frames ~1 now.")
                    return image, original_header, bit_depth, is_mono

            elif filename.lower().endswith('.png'):
                print(f"Loading PNG file: {filename}")
                img = Image.open(filename)

                # Convert unsupported modes to RGB
                if img.mode not in ('L', 'RGB'):
                    print(f"Unsupported PNG mode: {img.mode}, converting to RGB")
                    img = img.convert("RGB")

                # Convert image to numpy array and normalize pixel values to [0, 1]
                image = np.array(img, dtype=np.float32) / 255.0
                bit_depth = "8-bit"

                # Determine if the image is grayscale or RGB
                if len(image.shape) == 2:  # Grayscale image
                    is_mono = True
                elif len(image.shape) == 3 and image.shape[2] == 3:  # RGB image
                    is_mono = False
                else:
                    raise ValueError(f"Unsupported PNG dimensions: {image.shape}")

                print(f"Loaded PNG image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")

            elif filename.lower().endswith(('.jpg', '.jpeg')):
                print(f"Loading JPG file: {filename}")
                img = Image.open(filename)
                if img.mode == 'L':  # Grayscale
                    is_mono = True
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                elif img.mode == 'RGB':  # RGB
                    is_mono = False
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                else:
                    raise ValueError("Unsupported JPG format!")            

            else:
                raise ValueError("Unsupported file format!")

            print(f"Loaded image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
            return image, original_header, bit_depth, is_mono

        except Exception as e:
            error_message = str(e)
            if "buffer is too small for requested array" in error_message.lower():
                if attempt < max_retries:
                    attempt += 1
                    print(f"Error reading image {filename}: {e}")
                    print(f"Retrying in {wait_seconds} seconds... (Attempt {attempt}/{max_retries})")
                    time.sleep(wait_seconds)
                    continue  # Retry loading the image
                else:
                    print(f"Error reading image {filename} after {max_retries} retries: {e}")
            else:
                print(f"Error reading image {filename}: {e}")
            return None, None, None, None

def get_valid_header(file_path):
    """
    Opens the FITS file (handling compressed files as needed), finds the first HDU
    with image data, and then searches through all HDUs for additional keywords (e.g. BAYERPAT).
    Returns a composite header (a copy of the image HDU header updated with extra keywords)
    and the extension index of the image data.
    """
    # Open file appropriately for compressed files
    if file_path.lower().endswith(('.fits.gz', '.fit.gz')):
        
        with gzip.open(file_path, 'rb') as f:
            file_content = f.read()
        hdul = fits.open(BytesIO(file_content))
    else:
        
        hdul = fits.open(file_path)

    with hdul as hdul:
        image_hdu = None
        image_index = None
        # First, find the HDU that contains image data
        for i, hdu in enumerate(hdul):
            
            if hdu.data is not None:
                image_hdu = hdu
                image_index = i
                
                break
        if image_hdu is None:
            raise ValueError("No image data found in FITS file.")

        # Start with a copy of the image HDU header
        composite_header = image_hdu.header.copy()


        # Now search all HDUs for extra keywords (e.g. BAYERPAT)
        for i, hdu in enumerate(hdul):
            if 'BAYERPAT' in hdu.header:
                composite_header['BAYERPAT'] = hdu.header['BAYERPAT']

                break

    return composite_header, image_index

def get_bayer_header(file_path):
    """
    Iterates through all HDUs in the FITS file (handling compressed files if needed)
    to find a header that contains the 'BAYERPAT' keyword.
    Returns the header if found, otherwise None.
    """


    try:
        # Check for compressed files first.
        if file_path.lower().endswith(('.fits.gz', '.fit.gz')):
            with gzip.open(file_path, 'rb') as f:
                file_content = f.read()
            hdul = fits.open(BytesIO(file_content))
        else:
            hdul = fits.open(file_path)
        with hdul as hdul:
            for hdu in hdul:
                if 'BAYERPAT' in hdu.header:
                    return hdu.header
    except Exception as e:
        print(f"Error in get_bayer_header: {e}")
    return None

def save_image(img_array, filename, original_format, bit_depth=None, original_header=None, is_mono=False, image_meta=None, file_meta=None):
 
    """
    Save an image array to a file in the specified format and bit depth.
    """
    img_array = ensure_native_byte_order(img_array)  # Ensure correct byte order
    is_xisf = False  # Flag to determine if the original file was XISF

    # **🔹 Detect If Original File Was XISF**
    if original_header:
        for key in original_header.keys():
            if key.startswith("XISF:"):
                is_xisf = True
                break

    if image_meta and "XISFProperties" in image_meta:
        is_xisf = True  # Confirm XISF metadata exists

    try:
        if original_format == 'png':
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit PNG image to: {filename}")
        elif original_format in ['jpg', 'jpeg']:
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit JPG image to: {filename}")        
        elif original_format in ['tiff', 'tif']:
            # Save TIFF files based on bit depth
            if bit_depth == "8-bit":
                tiff.imwrite(filename, (img_array * 255).astype(np.uint8))  # Save as 8-bit TIFF
            elif bit_depth == "16-bit":
                tiff.imwrite(filename, (img_array * 65535).astype(np.uint16))  # Save as 16-bit TIFF
            elif bit_depth == "32-bit unsigned":
                tiff.imwrite(filename, (img_array * 4294967295).astype(np.uint32))  # Save as 32-bit unsigned TIFF
            elif bit_depth == "32-bit floating point":
                tiff.imwrite(filename, img_array.astype(np.float32))  # Save as 32-bit floating point TIFF
            else:
                raise ValueError("Unsupported bit depth for TIFF!")
            print(f"Saved {bit_depth} TIFF image to: {filename}")

        elif original_format in ['fits', 'fit']:
            # Preserve the original extension
            if not filename.lower().endswith(f".{original_format}"):
                filename = filename.rsplit('.', 1)[0] + f".{original_format}"

            # **📌 CASE 1: ORIGINAL FILE WAS XISF → CONVERT TO FITS HEADER**
            if is_xisf:
                print("Detected XISF metadata. Converting to FITS header...")
                fits_header = fits.Header()

                if 'XISFProperties' in image_meta:
                    xisf_props = image_meta['XISFProperties']

                    # Extract WCS parameters
                    if 'PCL:AstrometricSolution:ReferenceCoordinates' in xisf_props:
                        ref_coords = xisf_props['PCL:AstrometricSolution:ReferenceCoordinates']['value']
                        fits_header['CRVAL1'] = ref_coords[0]
                        fits_header['CRVAL2'] = ref_coords[1]

                    if 'PCL:AstrometricSolution:ReferenceLocation' in xisf_props:
                        ref_pixel = xisf_props['PCL:AstrometricSolution:ReferenceLocation']['value']
                        fits_header['CRPIX1'] = ref_pixel[0]
                        fits_header['CRPIX2'] = ref_pixel[1]

                    if 'PCL:AstrometricSolution:PixelSize' in xisf_props:
                        pixel_size = xisf_props['PCL:AstrometricSolution:PixelSize']['value']
                        fits_header['CDELT1'] = -pixel_size / 3600.0
                        fits_header['CDELT2'] = pixel_size / 3600.0

                    if 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_props:
                        linear_transform = xisf_props['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        fits_header['CD1_1'] = linear_transform[0][0]
                        fits_header['CD1_2'] = linear_transform[0][1]
                        fits_header['CD2_1'] = linear_transform[1][0]
                        fits_header['CD2_2'] = linear_transform[1][1]

                # Ensure essential WCS headers exist
                fits_header.setdefault('CTYPE1', 'RA---TAN')
                fits_header.setdefault('CTYPE2', 'DEC--TAN')

                print("Converted XISF metadata to FITS header.")

            # **📌 CASE 2: ORIGINAL FILE WAS FITS → PRESERVE HEADER**
            elif original_header is not None:
                print("Detected FITS format. Preserving original FITS header.")
                fits_header = fits.Header()
                for key, value in original_header.items():
                    if key.startswith("XISF:"):
                        continue  # Skip XISF metadata

                    if key in ["RANGE_LOW", "RANGE_HIGH"]:
                        print(f"Removing {key} from header to prevent overflow.")
                        continue  # Skip adding RANGE_LOW and RANGE_HIGH

                    if isinstance(value, dict) and 'value' in value:
                        value = value['value']

                    try:
                        fits_header[key] = value
                    except Exception as e:
                        print(f"Skipping problematic key {key} due to error: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

            # **📌 Image Processing for FITS**
            fits_header['BSCALE'] = 1.0
            fits_header['BZERO'] = 0.0

            if is_mono or img_array.ndim == 2:
                img_array_fits = img_array[:, :, 0] if len(img_array.shape) == 3 else img_array
                fits_header['NAXIS'] = 2
            else:
                img_array_fits = np.transpose(img_array, (2, 0, 1))
                fits_header['NAXIS'] = 3
                fits_header['NAXIS3'] = 3

            fits_header['NAXIS1'] = img_array.shape[1]
            fits_header['NAXIS2'] = img_array.shape[0]

            # **💾 Save the FITS File**
            hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
            hdu.writeto(filename, overwrite=True)
            print(f"Saved FITS image to: {filename}")
            return



        elif original_format in ['.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef']:
            # Save as FITS file with metadata
            print("RAW formats are not writable. Saving as FITS instead.")
            filename = filename.rsplit('.', 1)[0] + ".fits"

            if original_header is not None:
                # Convert original_header (dictionary) to astropy Header object
                fits_header = fits.Header()
                for key, value in original_header.items():
                    fits_header[key] = value
                fits_header['BSCALE'] = 1.0  # Scaling factor
                fits_header['BZERO'] = 0.0   # Offset for brightness    

                if is_mono:  # Grayscale FITS
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array[:, :, 0] * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = (img_array[:, :, 0].astype(np.float32) * bscale + bzero).astype(np.uint32)
                    else:  # 32-bit float
                        img_array_fits = img_array[:, :, 0].astype(np.float32)

                    # Update header for a 2D (grayscale) image
                    fits_header['NAXIS'] = 2
                    fits_header['NAXIS1'] = img_array.shape[1]  # Width
                    fits_header['NAXIS2'] = img_array.shape[0]  # Height
                    fits_header.pop('NAXIS3', None)  # Remove if present

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
                else:  # RGB FITS
                    img_array_transposed = np.transpose(img_array, (2, 0, 1))  # Channels, Height, Width
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array_transposed * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = img_array_transposed.astype(np.float32) * bscale + bzero
                        fits_header['BITPIX'] = -32
                    else:  # Default to 32-bit float
                        img_array_fits = img_array_transposed.astype(np.float32)

                    # Update header for a 3D (RGB) image
                    fits_header['NAXIS'] = 3
                    fits_header['NAXIS1'] = img_array_transposed.shape[2]  # Width
                    fits_header['NAXIS2'] = img_array_transposed.shape[1]  # Height
                    fits_header['NAXIS3'] = img_array_transposed.shape[0]  # Channels

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)

                # Write the FITS file
                try:
                    hdu.writeto(filename, overwrite=True)
                    print(f"RAW processed and saved as FITS to: {filename}")
                except Exception as e:
                    print(f"Error saving FITS file: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

        elif original_format == 'xisf':
            try:
                print(f"Original image shape: {img_array.shape}, dtype: {img_array.dtype}")
                print(f"Bit depth: {bit_depth}")

                # Adjust bit depth for saving
                if bit_depth == "16-bit":
                    processed_image = (img_array * 65535).astype(np.uint16)
                elif bit_depth == "32-bit unsigned":
                    processed_image = (img_array * 4294967295).astype(np.uint32)
                else:  # Default to 32-bit float
                    processed_image = img_array.astype(np.float32)

                # Handle mono images explicitly
                if is_mono:
                    print("Detected mono image. Preparing for XISF...")
                    if processed_image.ndim == 3 and processed_image.shape[2] > 1:
                        processed_image = processed_image[:, :, 0]  # Extract single channel
                    processed_image = processed_image[:, :, np.newaxis]  # Add back channel dimension

                    # Update metadata for mono images
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], 1)
                        image_meta[0]['colorSpace'] = 'Gray'
                    else:
                        # Create default metadata for mono images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], 1),
                            'colorSpace': 'Gray'
                        }]

                # Handle RGB images
                else:
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2])
                        image_meta[0]['colorSpace'] = 'RGB'
                    else:
                        # Create default metadata for RGB images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2]),
                            'colorSpace': 'RGB'
                        }]

                # Ensure fallback for `image_meta` and `file_meta`
                if image_meta is None or not isinstance(image_meta, list):
                    image_meta = [{
                        'geometry': (processed_image.shape[1], processed_image.shape[0], 1 if is_mono else 3),
                        'colorSpace': 'Gray' if is_mono else 'RGB'
                    }]
                if file_meta is None:
                    file_meta = {}

                # Debug: Print processed image details and metadata
                print(f"Processed image shape for XISF: {processed_image.shape}, dtype: {processed_image.dtype}")

                # Save the image using XISF.write
                XISF.write(
                    filename,                    # Output path
                    processed_image,             # Final processed image
                    creator_app="Seti Astro Cosmic Clarity",
                    image_metadata=image_meta[0],  # First block of image metadata
                    xisf_metadata=file_meta,       # File-level metadata
                    shuffle=True
                )

                print(f"Saved {bit_depth} XISF image to: {filename}")

            except Exception as e:
                print(f"Error saving XISF file: {e}")
                raise


        else:
            raise ValueError("Unsupported file format!")

    except Exception as e:
        print(f"Error saving image to {filename}: {e}")
        raise




def stretch_mono_image(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Stretches a single-channel (2D) image so that its median ends up near `target_median`.
    Uses the old formula, but with the final math done in a Numba function.
    """
    # 1) Compute black_point from old logic
    black_point = max(np.min(image), np.median(image) - 2.7 * np.std(image))

    # 2) Rescale in Python
    #    r = (val - black_point) / (1 - black_point)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Compute median of *this* rescaled data
    median_rescaled = np.median(rescaled_image)

    # 4) Final stretch in Numba
    stretched_image = numba_mono_final_formula(rescaled_image, median_rescaled, target_median)

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    # 7) Clip result [0..1]
    return np.clip(stretched_image, 0, 1)

def stretch_color_image(image, target_median, linked=True, normalize=False, apply_curves=False, curves_boost=0.0):
    # If image is mono or single-channel, treat as mono
    if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
        mono = image.squeeze()
        mono_stretched = stretch_mono_image(mono, target_median,
                                            normalize=normalize,
                                            apply_curves=apply_curves,
                                            curves_boost=curves_boost)
        # Replicate into 3 channels if you want a 3-channel result
        return np.stack([mono_stretched] * 3, axis=-1)

    # If it's actually color (H, W, 3):
    if linked:
        stretched_image = stretch_color_image_linked(image, target_median,
                                                     normalize=normalize,
                                                     apply_curves=apply_curves,
                                                     curves_boost=curves_boost)
    else:
        stretched_image = stretch_color_image_unlinked(image, target_median,
                                                       normalize=normalize,
                                                       apply_curves=apply_curves,
                                                       curves_boost=curves_boost)
    return stretched_image

def stretch_color_image_linked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Linked color stretch: uses one black_point and one median for all channels.
    """
    # 1) Compute black_point from the combined median, std
    combined_median = np.median(image)
    combined_std = np.std(image)
    black_point = max(np.min(image), combined_median - 2.7 * combined_std)

    # 2) Rescale
    #    (H, W, 3)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Median of the entire rescaled array
    median_rescaled = np.median(rescaled_image)

    # 4) Final formula in Numba
    stretched_image = numba_color_final_formula_linked(
        rescaled_image, 
        median_rescaled, 
        target_median
    )

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)

def stretch_color_image_unlinked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Unlinked color stretch: each channel has its own black_point, own median.
    """
    H, W, _ = image.shape
    rescaled_image = np.zeros_like(image, dtype=np.float32)
    black_points = np.zeros(3, dtype=np.float32)
    medians_rescaled = np.zeros(3, dtype=np.float32)

    # 1) For each channel, compute black point, rescale, find median
    for c in range(3):
        channel = image[..., c]
        channel_median = np.median(channel)
        channel_std = np.std(channel)
        bp = max(channel.min(), channel_median - 2.7 * channel_std)

        # Store black point
        black_points[c] = bp

        # Rescale that channel
        denom_bp = 1.0 - bp
        rescaled_image[..., c] = (channel - bp) / denom_bp

    # 2) For each channel, compute median of the rescaled version
    for c in range(3):
        medians_rescaled[c] = np.median(rescaled_image[..., c])

    # 3) Final formula in Numba
    stretched_image = numba_color_final_formula_unlinked(
        rescaled_image,
        medians_rescaled,
        target_median
    )

    # 4) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 5) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)



def apply_curves_adjustment(image, target_median, curves_boost):
    """
    Original signature unchanged, but now uses a Numba helper
    to do the pixel-by-pixel interpolation.

    'image' can be 2D (H,W) or 3D (H,W,3).
    """
    # Build the curve array as before
    curve = [
        [0.0, 0.0],
        [0.5 * target_median, 0.5 * target_median],
        [target_median, target_median],
        [
            (1/4 * (1 - target_median) + target_median),
            np.power((1/4 * (1 - target_median) + target_median), (1 - curves_boost))
        ],
        [
            (3/4 * (1 - target_median) + target_median),
            np.power(np.power((3/4 * (1 - target_median) + target_median), (1 - curves_boost)), (1 - curves_boost))
        ],
        [1.0, 1.0]
    ]
    # Convert to arrays
    xvals = np.array([p[0] for p in curve], dtype=np.float32)
    yvals = np.array([p[1] for p in curve], dtype=np.float32)

    # Ensure 'image' is float32
    image_32 = image.astype(np.float32, copy=False)

    # Now apply the piecewise linear function in Numba
    adjusted_image = apply_curves_numba(image_32, xvals, yvals)
    return adjusted_image

def resource_path(relative_path):
    """ Get the absolute path to the resource, works for dev and for PyInstaller """
    try:
        # PyInstaller creates a temporary folder and stores path in _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)

def ensure_native_byte_order(array):
    """
    Ensures that the array is in the native byte order.
    If the array is in a non-native byte order, it will convert it.
    """
    if array.dtype.byteorder == '=':  # Already in native byte order
        return array
    elif array.dtype.byteorder in ('<', '>'):  # Non-native byte order
        return array.byteswap().view(array.dtype.newbyteorder('='))
    return array


# Determine if running inside a PyInstaller bundle
if hasattr(sys, '_MEIPASS'):
    # Set path for PyInstaller bundle
    data_path = os.path.join(sys._MEIPASS, "astroquery", "simbad", "data")
else:
    # Set path for regular Python environment
    data_path = "C:/Users/Gaming/Desktop/Python Code/venv/Lib/site-packages/astroquery/simbad/data"

# Ensure the final path doesn't contain 'data/data' duplication
if 'data/data' in data_path:
    data_path = data_path.replace('data/data', 'data')

conf.dataurl = f'file://{data_path}/'

# Access wrench_icon.png, adjusting for PyInstaller executable
if hasattr(sys, '_MEIPASS'):
    wrench_path = os.path.join(sys._MEIPASS, 'wrench_icon.png')
    eye_icon_path = os.path.join(sys._MEIPASS, 'eye.png')
    disk_icon_path = os.path.join(sys._MEIPASS, 'disk.png')
    nuke_path = os.path.join(sys._MEIPASS, 'nuke.png')  
    hubble_path = os.path.join(sys._MEIPASS, 'hubble.png') 
    collage_path = os.path.join(sys._MEIPASS, 'collage.png') 
    annotated_path = os.path.join(sys._MEIPASS, 'annotated.png') 
    colorwheel_path = os.path.join(sys._MEIPASS, 'colorwheel.png')
    font_path = os.path.join(sys._MEIPASS, 'font.png')
    csv_icon_path = os.path.join(sys._MEIPASS, 'cvs.png')
else:
    wrench_path = 'wrench_icon.png'  # Path for running as a script
    eye_icon_path = 'eye.png'  # Path for running as a script
    disk_icon_path = 'disk.png'   
    nuke_path = 'nuke.png' 
    hubble_path = 'hubble.png'
    collage_path = 'collage.png'
    annotated_path = 'annotated.png'
    colorwheel_path = 'colorwheel.png'
    font_path = 'font.png'
    csv_icon_path = 'cvs.png'

# Constants for comoving radial distance calculation
H0 = 69.6  # Hubble constant in km/s/Mpc
WM = 0.286  # Omega(matter)
WV = 0.714  # Omega(vacuum)
c = 299792.458  # speed of light in km/s
Tyr = 977.8  # coefficient to convert 1/H into Gyr
Mpc_to_Gly = 3.262e-3  # Conversion from Mpc to Gly

otype_long_name_lookup = {
    "ev": "transient event",
    "Rad": "Radio-source",
    "mR": "metric Radio-source",
    "cm": "centimetric Radio-source",
    "mm": "millimetric Radio-source",
    "smm": "sub-millimetric source",
    "HI": "HI (21cm) source",
    "rB": "radio Burst",
    "Mas": "Maser",
    "IR": "Infra-Red source",
    "FIR": "Far-Infrared source",
    "MIR": "Mid-Infrared source",
    "NIR": "Near-Infrared source",
    "blu": "Blue object",
    "UV": "UV-emission source",
    "X": "X-ray source",
    "UX?": "Ultra-luminous X-ray candidate",
    "ULX": "Ultra-luminous X-ray source",
    "gam": "gamma-ray source",
    "gB": "gamma-ray Burst",
    "err": "Not an object (error, artefact, ...)",
    "grv": "Gravitational Source",
    "Lev": "(Micro)Lensing Event",
    "LS?": "Possible gravitational lens System",
    "Le?": "Possible gravitational lens",
    "LI?": "Possible gravitationally lensed image",
    "gLe": "Gravitational Lens",
    "gLS": "Gravitational Lens System (lens+images)",
    "GWE": "Gravitational Wave Event",
    "..?": "Candidate objects",
    "G?": "Possible Galaxy",
    "SC?": "Possible Supercluster of Galaxies",
    "C?G": "Possible Cluster of Galaxies",
    "Gr?": "Possible Group of Galaxies",
    "**?": "Physical Binary Candidate",
    "EB?": "Eclipsing Binary Candidate",
    "Sy?": "Symbiotic Star Candidate",
    "CV?": "Cataclysmic Binary Candidate",
    "No?": "Nova Candidate",
    "XB?": "X-ray binary Candidate",
    "LX?": "Low-Mass X-ray binary Candidate",
    "HX?": "High-Mass X-ray binary Candidate",
    "Pec?": "Possible Peculiar Star",
    "Y*?": "Young Stellar Object Candidate",
    "TT?": "T Tau star Candidate",
    "C*?": "Possible Carbon Star",
    "S*?": "Possible S Star",
    "OH?": "Possible Star with envelope of OH/IR type",
    "WR?": "Possible Wolf-Rayet Star",
    "Be?": "Possible Be Star",
    "Ae?": "Possible Herbig Ae/Be Star",
    "HB?": "Possible Horizontal Branch Star",
    "RR?": "Possible Star of RR Lyr type",
    "Ce?": "Possible Cepheid",
    "WV?": "Possible Variable Star of W Vir type",
    "RB?": "Possible Red Giant Branch star",
    "sg?": "Possible Supergiant star",
    "s?r": "Possible Red supergiant star",
    "s?y": "Possible Yellow supergiant star",
    "s?b": "Possible Blue supergiant star",
    "AB?": "Asymptotic Giant Branch Star candidate",
    "LP?": "Long Period Variable candidate",
    "Mi?": "Mira candidate",
    "pA?": "Post-AGB Star Candidate",
    "BS?": "Candidate blue Straggler Star",
    "HS?": "Hot subdwarf candidate",
    "WD?": "White Dwarf Candidate",
    "N*?": "Neutron Star Candidate",
    "BH?": "Black Hole Candidate",
    "SN?": "SuperNova Candidate",
    "LM?": "Low-mass star candidate",
    "BD?": "Brown Dwarf Candidate",
    "mul": "Composite object",
    "reg": "Region defined in the sky",
    "vid": "Underdense region of the Universe",
    "SCG": "Supercluster of Galaxies",
    "ClG": "Cluster of Galaxies",
    "GrG": "Group of Galaxies",
    "CGG": "Compact Group of Galaxies",
    "PaG": "Pair of Galaxies",
    "IG": "Interacting Galaxies",
    "C?*": "Possible (open) star cluster",
    "Gl?": "Possible Globular Cluster",
    "Cl*": "Cluster of Stars",
    "GlC": "Globular Cluster",
    "OpC": "Open (galactic) Cluster",
    "As*": "Association of Stars",
    "St*": "Stellar Stream",
    "MGr": "Moving Group",
    "**": "Double or multiple star",
    "EB*": "Eclipsing binary",
    "Al*": "Eclipsing binary of Algol type",
    "bL*": "Eclipsing binary of beta Lyr type",
    "WU*": "Eclipsing binary of W UMa type",
    "SB*": "Spectroscopic binary",
    "El*": "Ellipsoidal variable Star",
    "Sy*": "Symbiotic Star",
    "CV*": "Cataclysmic Variable Star",
    "DQ*": "CV DQ Her type (intermediate polar)",
    "AM*": "CV of AM Her type (polar)",
    "NL*": "Nova-like Star",
    "No*": "Nova",
    "DN*": "Dwarf Nova",
    "XB*": "X-ray Binary",
    "LXB": "Low Mass X-ray Binary",
    "HXB": "High Mass X-ray Binary",
    "ISM": "Interstellar matter",
    "PoC": "Part of Cloud",
    "PN?": "Possible Planetary Nebula",
    "CGb": "Cometary Globule",
    "bub": "Bubble",
    "EmO": "Emission Object",
    "Cld": "Cloud",
    "GNe": "Galactic Nebula",
    "DNe": "Dark Cloud (nebula)",
    "RNe": "Reflection Nebula",
    "MoC": "Molecular Cloud",
    "glb": "Globule (low-mass dark cloud)",
    "cor": "Dense core",
    "SFR": "Star forming region",
    "HVC": "High-velocity Cloud",
    "HII": "HII (ionized) region",
    "PN": "Planetary Nebula",
    "sh": "HI shell",
    "SR?": "SuperNova Remnant Candidate",
    "SNR": "SuperNova Remnant",
    "of?": "Outflow candidate",
    "out": "Outflow",
    "HH": "Herbig-Haro Object",
    "*": "Star",
    "V*?": "Star suspected of Variability",
    "Pe*": "Peculiar Star",
    "HB*": "Horizontal Branch Star",
    "Y*O": "Young Stellar Object",
    "Ae*": "Herbig Ae/Be star",
    "Em*": "Emission-line Star",
    "Be*": "Be Star",
    "BS*": "Blue Straggler Star",
    "RG*": "Red Giant Branch star",
    "AB*": "Asymptotic Giant Branch Star (He-burning)",
    "C*": "Carbon Star",
    "S*": "S Star",
    "sg*": "Evolved supergiant star",
    "s*r": "Red supergiant star",
    "s*y": "Yellow supergiant star",
    "s*b": "Blue supergiant star",
    "HS*": "Hot subdwarf",
    "pA*": "Post-AGB Star (proto-PN)",
    "WD*": "White Dwarf",
    "LM*": "Low-mass star (M<1solMass)",
    "BD*": "Brown Dwarf (M<0.08solMass)",
    "N*": "Confirmed Neutron Star",
    "OH*": "OH/IR star",
    "TT*": "T Tau-type Star",
    "WR*": "Wolf-Rayet Star",
    "PM*": "High proper-motion Star",
    "HV*": "High-velocity Star",
    "V*": "Variable Star",
    "Ir*": "Variable Star of irregular type",
    "Or*": "Variable Star of Orion Type",
    "Er*": "Eruptive variable Star",
    "RC*": "Variable Star of R CrB type",
    "RC?": "Variable Star of R CrB type candidate",
    "Ro*": "Rotationally variable Star",
    "a2*": "Variable Star of alpha2 CVn type",
    "Psr": "Pulsar",
    "BY*": "Variable of BY Dra type",
    "RS*": "Variable of RS CVn type",
    "Pu*": "Pulsating variable Star",
    "RR*": "Variable Star of RR Lyr type",
    "Ce*": "Cepheid variable Star",
    "dS*": "Variable Star of delta Sct type",
    "RV*": "Variable Star of RV Tau type",
    "WV*": "Variable Star of W Vir type",
    "bC*": "Variable Star of beta Cep type",
    "cC*": "Classical Cepheid (delta Cep type)",
    "gD*": "Variable Star of gamma Dor type",
    "SX*": "Variable Star of SX Phe type (subdwarf)",
    "LP*": "Long-period variable star",
    "Mi*": "Variable Star of Mira Cet type",
    "SN*": "SuperNova",
    "su*": "Sub-stellar object",
    "Pl?": "Extra-solar Planet Candidate",
    "Pl": "Extra-solar Confirmed Planet",
    "G": "Galaxy",
    "PoG": "Part of a Galaxy",
    "GiC": "Galaxy in Cluster of Galaxies",
    "BiC": "Brightest galaxy in a Cluster (BCG)",
    "GiG": "Galaxy in Group of Galaxies",
    "GiP": "Galaxy in Pair of Galaxies",
    "rG": "Radio Galaxy",
    "H2G": "HII Galaxy",
    "LSB": "Low Surface Brightness Galaxy",
    "AG?": "Possible Active Galaxy Nucleus",
    "Q?": "Possible Quasar",
    "Bz?": "Possible Blazar",
    "BL?": "Possible BL Lac",
    "EmG": "Emission-line galaxy",
    "SBG": "Starburst Galaxy",
    "bCG": "Blue compact Galaxy",
    "LeI": "Gravitationally Lensed Image",
    "LeG": "Gravitationally Lensed Image of a Galaxy",
    "LeQ": "Gravitationally Lensed Image of a Quasar",
    "AGN": "Active Galaxy Nucleus",
    "LIN": "LINER-type Active Galaxy Nucleus",
    "SyG": "Seyfert Galaxy",
    "Sy1": "Seyfert 1 Galaxy",
    "Sy2": "Seyfert 2 Galaxy",
    "Bla": "Blazar",
    "BLL": "BL Lac - type object",
    "OVV": "Optically Violently Variable object",
    "QSO": "Quasar"
}

from PyQt6.QtGui import QColor

# ────────────────────────────────────────────────
# 1a) Map each SIMBAD otype → one of our high-level categories
# ────────────────────────────────────────────────
OTYPE_TO_CATEGORY = {
    # Transient & Explosive Events
    "ev":   "Transient & Explosive",
    "rB":   "Transient & Explosive",
    "gB":   "Transient & Explosive",
    "GWE":  "Transient & Explosive",
    "SN*":  "Transient & Explosive",
    "SN?":  "Transient & Explosive",
    "SR?":  "Transient & Explosive",
    "SNR":  "Transient & Explosive",
    "Lev":  "Transient & Explosive",

    # High-Energy / X-ray / γ-ray
    "X":    "High-Energy / X-ray / γ-ray",
    "UX?":  "High-Energy / X-ray / γ-ray",
    "ULX":  "High-Energy / X-ray / γ-ray",
    "gam":  "High-Energy / X-ray / γ-ray",
    "grv":  "High-Energy / X-ray / γ-ray",
    "Psr":  "High-Energy / X-ray / γ-ray",
    "N*?":  "High-Energy / X-ray / γ-ray",
    "BH?":  "High-Energy / X-ray / γ-ray",

    # Radio & sub-millimetric
    "Rad":  "Radio & Sub-mm",
    "mR":   "Radio & Sub-mm",
    "cm":   "Radio & Sub-mm",
    "mm":   "Radio & Sub-mm",
    "smm":  "Radio & Sub-mm",
    "HI":   "Radio & Sub-mm",
    "Mas":  "Radio & Sub-mm",

    # IR / Optical / UV / Blue
    "IR":   "IR / Optical / UV",
    "FIR":  "IR / Optical / UV",
    "MIR":  "IR / Optical / UV",
    "NIR":  "IR / Optical / UV",
    "UV":   "IR / Optical / UV",
    "blu":  "IR / Optical / UV",

    # Gravitational Lensing & Microlensing
    "Lev":  "Gravitational Lensing",
    "LS?":  "Gravitational Lensing",
    "Le?":  "Gravitational Lensing",
    "LI?":  "Gravitational Lensing",
    "gLe":  "Gravitational Lensing",
    "gLS":  "Gravitational Lensing",

    # Stars & Stellar Objects
    "*":    "Stars & Stellar",
    "V*":   "Stars & Stellar",
    "Pe*":  "Stars & Stellar",
    "HB*":  "Stars & Stellar",
    "Y*O":  "Stars & Stellar",
    "Ae*":  "Stars & Stellar",
    "Em*":  "Stars & Stellar",
    "Be*":  "Stars & Stellar",
    "BS*":  "Stars & Stellar",
    "RG*":  "Stars & Stellar",
    "AB*":  "Stars & Stellar",
    "C*":   "Stars & Stellar",
    "S*":   "Stars & Stellar",
    "sg*":  "Stars & Stellar",
    "s*r":  "Stars & Stellar",
    "s*y":  "Stars & Stellar",
    "s*b":  "Stars & Stellar",
    "HS*":  "Stars & Stellar",
    "pA*":  "Stars & Stellar",
    "WD*":  "Stars & Stellar",
    "LM*":  "Stars & Stellar",
    "BD*":  "Stars & Stellar",
    "N*":   "Stars & Stellar",
    "OH*":  "Stars & Stellar",
    "TT*":  "Stars & Stellar",
    "WR*":  "Stars & Stellar",
    "PM*":  "Stars & Stellar",
    "HV*":  "Stars & Stellar",
    "C?*":  "Stars & Stellar",
    "Pec?": "Stars & Stellar",
    "Y*?":  "Stars & Stellar",
    "TT?":  "Stars & Stellar",
    "C*?":  "Stars & Stellar",
    "S*?":  "Stars & Stellar",
    "OH?":  "Stars & Stellar",
    "WR?":  "Stars & Stellar",
    "Be?":  "Stars & Stellar",
    "Ae?":  "Stars & Stellar",
    "HB?":  "Stars & Stellar",
    "RB?":  "Stars & Stellar",
    "sg?":  "Stars & Stellar",
    "s?r":  "Stars & Stellar",
    "s?y":  "Stars & Stellar",
    "s?b":  "Stars & Stellar",
    "pA?":  "Stars & Stellar",
    "BS?":  "Stars & Stellar",
    "HS?":  "Stars & Stellar",
    "WD?":  "Stars & Stellar",    

    # Binaries & Multiples / Variables
    "**":   "Binaries & Variables",
    "EB*":  "Binaries & Variables",
    "Al*":  "Binaries & Variables",
    "bL*":  "Binaries & Variables",
    "WU*":  "Binaries & Variables",
    "SB*":  "Binaries & Variables",
    "El*":  "Binaries & Variables",
    "Sy*":  "Binaries & Variables",
    "CV*":  "Binaries & Variables",
    "DQ*":  "Binaries & Variables",
    "AM*":  "Binaries & Variables",
    "NL*":  "Binaries & Variables",
    "No*":  "Binaries & Variables",
    "DN*":  "Binaries & Variables",
    "XB*":  "Binaries & Variables",
    "LXB":  "Binaries & Variables",
    "HXB":  "Binaries & Variables",
    "Pl?":  "Binaries & Variables",
    "Ce?":  "Binaries & Variables",
    "Ce*":  "Binaries & Variables",
    "cC*":  "Binaries & Variables",
    "**?":  "Binaries & Variables",
    "EB?":  "Binaries & Variables",
    "Sy?":  "Binaries & Variables",
    "CV?":  "Binaries & Variables",
    "No?":  "Binaries & Variables",
    "XB?":  "Binaries & Variables",
    "LX?":  "Binaries & Variables",
    "HX?":  "Binaries & Variables",
    "RR?":  "Binaries & Variables",
    "WV?":  "Binaries & Variables",
    "LP?":  "Binaries & Variables",
    "Mi?":  "Binaries & Variables",
    "Ce?":  "Binaries & Variables",
    "cC*":  "Binaries & Variables",
    "Pl?":  "Binaries & Variables",    

    # Clusters & Associations
    "Cl*":  "Clusters & Associations",
    "GlC":  "Clusters & Associations",
    "OpC":  "Clusters & Associations",
    "As*":  "Clusters & Associations",
    "St*":  "Clusters & Associations",
    "MGr":  "Clusters & Associations",
    "C?*":  "Clusters & Associations",
    "Gl?":  "Clusters & Associations",    

    # Nebulae & Interstellar Matter
    "PN":   "Nebulae & ISM",
    "PN?":  "Nebulae & ISM",
    "EmO":  "Nebulae & ISM",
    "GNe":  "Nebulae & ISM",
    "DNe":  "Nebulae & ISM",
    "RNe":  "Nebulae & ISM",
    "MoC":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "bub":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "sh":   "Nebulae & ISM",
    "SFR":  "Nebulae & ISM",
    "HVC":  "Nebulae & ISM",
    "CGb":  "Nebulae & ISM",
    "PoC":  "Nebulae & ISM",
    "glb":  "Nebulae & ISM",
    "cor":  "Nebulae & ISM",
    "out":  "Nebulae & ISM",
    "HH":   "Nebulae & ISM",
    "HII":  "Nebulae & ISM",
    "ISM":  "Nebulae & ISM",
    "of?":  "Nebulae & ISM",    

    # Galaxies & Active Nuclei
    "G":    "Galaxies & AGN",
    "PoG":  "Galaxies & AGN",
    "EmG":  "Galaxies & AGN",
    "SBG":  "Galaxies & AGN",
    "LSB":  "Galaxies & AGN",
    "AGN":  "Galaxies & AGN",
    "LIN":  "Galaxies & AGN",
    "SyG":  "Galaxies & AGN",
    "Sy1":  "Galaxies & AGN",
    "Sy2":  "Galaxies & AGN",
    "Bla":  "Galaxies & AGN",
    "BLL":  "Galaxies & AGN",
    "OVV":  "Galaxies & AGN",
    "QSO":  "Galaxies & AGN",
    "Q?":   "Galaxies & AGN",
    "AG?":  "Galaxies & AGN",
    "G?":   "Galaxies & AGN",
    "IG":   "Galaxies & AGN",
    "GiC":  "Galaxies & AGN",
    "BiC":  "Galaxies & AGN",
    "GiP":  "Galaxies & AGN",
    "rG":   "Galaxies & AGN",
    "H2G":  "Galaxies & AGN",
    "Bz?":  "Galaxies & AGN",
    "BL?":  "Galaxies & AGN",    


    # Large-Scale Structure: clusters, superclusters, voids
    "ClG":  "Large-Scale Structure",
    "GrG":  "Large-Scale Structure",
    "CGG":  "Large-Scale Structure",
    "PaG":  "Large-Scale Structure",
    "SCG":  "Large-Scale Structure",
    "SC?":  "Large-Scale Structure",
    "C?G":  "Large-Scale Structure",
    "Gr?":  "Large-Scale Structure",
    "vid":  "Large-Scale Structure",
    "GiG":  "Large-Scale Structure",

    # Regions, Clouds & Artefacts
    "reg":  "Regions & Clouds",
    "mul":  "Regions & Clouds",

    # Errors & Artefacts / Unknown
    "err":  "Errors & Artefacts",
    "..?":  "Errors & Artefacts",  
}

# ────────────────────────────────────────────────
# 1b) Assign each category a distinct QColor
# ────────────────────────────────────────────────
CATEGORY_TO_COLOR = {
    "Transient & Explosive":        QColor(255,   0,   0),  # red
    "High-Energy / X-ray / γ-ray":  QColor(255, 165,   0),  # orange
    "Radio & Sub-mm":               QColor(128,   0, 128),  # purple
    "IR / Optical / UV":            QColor(  0, 128,   0),  # green
    "Gravitational Lensing":        QColor(218, 112, 214),  # orchid
    "Stars & Stellar":              QColor(  0,   0, 255),  # blue
    "Binaries & Variables":         QColor(255, 255,   0),  # yellow
    "Clusters & Associations":      QColor(165,  42,  42),  # brown
    "Nebulae & ISM":                QColor(  0, 128, 128),  # teal
    "Galaxies & AGN":               QColor(255,   0, 255),  # magenta
    "Large-Scale Structure":        QColor( 200,  200,  200),  # dark gray
    "Regions & Clouds":             QColor( 95, 158, 160),  # cadet blue
    "Errors & Artefacts":           QColor(128, 128, 128),  # gray
}



Simbad.ROW_LIMIT = 0  # Remove row limit for full results
Simbad.TIMEOUT = 300  # Increase timeout for long queries

# Astrometry.net API constants
ASTROMETRY_API_URL = "http://nova.astrometry.net/api/"
ASTROMETRY_API_KEY_FILE = "astrometry_api_key.txt"

settings = QSettings("Seti Astro", "Seti Astro Suite")

def save_api_key(api_key):
    settings.setValue("astrometry_api_key", api_key)  # Save to QSettings
    print("API key saved.")

def load_api_key():
    api_key = settings.value("astrometry_api_key", "")  # Load from QSettings
    if api_key:
        print("API key loaded.")
    return api_key




class CustomGraphicsView(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.setMouseTracking(True)  # Enable mouse tracking
        self.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable default drag mode to avoid hand cursor
        self.setCursor(Qt.CursorShape.ArrowCursor)  # Set default cursor to arrow
        self.drawing_item = None
        self.start_pos = None     
        self.annotation_items = []  # Store annotation items  
        self.drawing_measurement = False
        self.measurement_start = QPointF()    
         

        self.selected_object = None  # Initialize selected_object to None
        self.show_names = False 

        # Variables for drawing the circle
        self.circle_center = None
        self.circle_radius = 0
        self.drawing_circle = False  # Flag to check if we're currently drawing a circle
        self.dragging = False  # Flag to manage manual dragging


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            if event.modifiers() == Qt.KeyboardModifier.ControlModifier:
                # Start annotation mode with the current tool
                self.start_pos = self.mapToScene(event.pos())

                # Check which tool is currently selected
                if self.parent.current_tool == "Ellipse":
                    self.drawing_item = QGraphicsEllipseItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Rectangle":
                    self.drawing_item = QGraphicsRectItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Arrow":
                    self.drawing_item = QGraphicsLineItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Freehand":
                    self.drawing_item = QGraphicsPathItem()
                    path = QPainterPath(self.start_pos)
                    self.drawing_item.setPath(path)
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Text":
                    text, ok = QInputDialog.getText(self, "Add Text", "Enter text:")
                    if ok and text:
                        text_item = QGraphicsTextItem(text)
                        text_item.setPos(self.start_pos)
                        text_item.setDefaultTextColor(self.parent.selected_color)  # Use selected color
                        text_item.setFont(self.parent.selected_font)  # Use selected font
                        self.parent.main_scene.addItem(text_item)
                        
                        # Store as ('text', text, position, color)
                        self.annotation_items.append(('text', text, self.start_pos, self.parent.selected_color))


                elif self.parent.current_tool == "Compass":
                    self.place_celestial_compass(self.start_pos)

            elif event.modifiers() == Qt.KeyboardModifier.ShiftModifier:
                # Start drawing a circle for Shift+Click
                self.drawing_circle = True
                self.circle_center = self.mapToScene(event.pos())
                self.circle_radius = 0
                self.parent.status_label.setText("Drawing circle: Shift + Drag")
                self.update_circle()

            elif event.modifiers() == Qt.KeyboardModifier.AltModifier:
                # Start celestial measurement for Alt+Click
                self.measurement_start = self.mapToScene(event.pos())
                self.drawing_measurement = True
                self.drawing_item = None  # Clear any active annotation item
    

            else:
                # Detect if an object circle was clicked without Shift or Ctrl
                scene_pos = self.mapToScene(event.pos())
                clicked_object = self.get_object_at_position(scene_pos)
                
                if clicked_object:
                    # Select the clicked object and redraw
                    self.parent.selected_object = clicked_object
                    self.select_object(clicked_object)
                    self.draw_query_results()
                    self.update_mini_preview()
                    
                    # Highlight the corresponding row in the TreeWidget
                    for i in range(self.parent.results_tree.topLevelItemCount()):
                        item = self.parent.results_tree.topLevelItem(i)
                        if item.text(2) == clicked_object["name"]:  # Assuming third element is 'Name'
                            self.parent.results_tree.setCurrentItem(item)
                            break
                else:
                    # Start manual dragging if no modifier is held
                    self.dragging = True
                    self.setCursor(Qt.CursorShape.ClosedHandCursor)  # Use closed hand cursor to indicate dragging
                    self.drag_start_pos = event.pos()  # Store starting position

        super().mousePressEvent(event)


    def mouseDoubleClickEvent(self, event):
        """Handle double-click event on an object in the main image to open SIMBAD or NED URL based on source."""
        scene_pos = self.mapToScene(event.pos())
        clicked_object = self.get_object_at_position(scene_pos)

        if clicked_object:
            object_name = clicked_object.get("name")  # Access 'name' key from the dictionary
            ra = float(clicked_object.get("ra"))  # Ensure RA is a float for precision
            dec = float(clicked_object.get("dec"))  # Ensure Dec is a float for precision
            source = clicked_object.get("source", "Simbad")  # Default to "Simbad" if source not specified

            if source == "Simbad" and object_name:
                # Open Simbad URL with encoded object name
                encoded_name = quote(object_name)
                url = f"https://simbad.cds.unistra.fr/simbad/sim-basic?Ident={encoded_name}&submit=SIMBAD+search"
                webbrowser.open(url)
            elif source == "Vizier":
                # Format the NED search URL with proper RA, Dec, and radius
                radius = 5 / 60  # Radius in arcminutes (5 arcseconds)
                dec_sign = "%2B" if dec >= 0 else "-"  # Determine sign for declination
                ned_url = (
                    f"http://ned.ipac.caltech.edu/conesearch?search_type=Near%20Position%20Search"
                    f"&ra={ra:.6f}d&dec={dec_sign}{abs(dec):.6f}d&radius={radius:.3f}"
                    "&in_csys=Equatorial&in_equinox=J2000.0"
                )
                webbrowser.open(ned_url)
            elif source == "Mast":
                # Open MAST URL using RA and Dec with a small radius for object lookup
                mast_url = f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
                webbrowser.open(mast_url)                
        else:
            super().mouseDoubleClickEvent(event)

    def mouseMoveEvent(self, event):
        scene_pos = self.mapToScene(event.pos())

        if self.drawing_circle:
            # Update the circle radius as the mouse moves
            self.circle_radius = np.sqrt(
                (scene_pos.x() - self.circle_center.x()) ** 2 +
                (scene_pos.y() - self.circle_center.y()) ** 2
            )
            self.update_circle()

        elif self.drawing_measurement:
            # Update the measurement line dynamically as the mouse moves
            if self.drawing_item:
                self.parent.main_scene.removeItem(self.drawing_item)  # Remove previous line if exists
            self.drawing_item = QGraphicsLineItem(QLineF(self.measurement_start, scene_pos))
            self.drawing_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))  # Use green dashed line for measurement
            self.parent.main_scene.addItem(self.drawing_item)

        elif self.drawing_item:
            # Update the current drawing item based on the selected tool and mouse position
            if isinstance(self.drawing_item, QGraphicsEllipseItem) and self.parent.current_tool == "Ellipse":
                # For Ellipse tool, update the ellipse dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsRectItem) and self.parent.current_tool == "Rectangle":
                # For Rectangle tool, update the rectangle dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsLineItem) and self.parent.current_tool == "Arrow":
                # For Arrow tool, set the line from start_pos to current mouse position
                line = QLineF(self.start_pos, scene_pos)
                self.drawing_item.setLine(line)

            elif isinstance(self.drawing_item, QGraphicsPathItem) and self.parent.current_tool == "Freehand":
                # For Freehand tool, add a line to the path to follow the mouse movement
                path = self.drawing_item.path()
                path.lineTo(scene_pos)
                self.drawing_item.setPath(path)

        elif self.dragging:
            # Handle manual dragging by scrolling the view
            delta = event.pos() - self.drag_start_pos
            self.horizontalScrollBar().setValue(self.horizontalScrollBar().value() - delta.x())
            self.verticalScrollBar().setValue(self.verticalScrollBar().value() - delta.y())
            self.drag_start_pos = event.pos()
        else:
            # Update RA/Dec display as the cursor moves
            self.parent.update_ra_dec_from_mouse(event)
            
        super().mouseMoveEvent(event)
                

    def mouseReleaseEvent(self, event):
        if self.drawing_circle and event.button() == Qt.MouseButton.LeftButton:
            # Stop drawing the circle
            self.drawing_circle = False
            self.parent.circle_center = self.circle_center
            self.parent.circle_radius = self.circle_radius

            # Calculate RA/Dec for the circle center
            ra, dec = self.parent.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            if ra is not None and dec is not None:
                self.parent.ra_label.setText(f"RA: {self.parent.convert_ra_to_hms(ra)}")
                self.parent.dec_label.setText(f"Dec: {self.parent.convert_dec_to_dms(dec)}")

                if self.parent.pixscale:
                    radius_arcmin = self.circle_radius * self.parent.pixscale / 60.0
                    self.parent.status_label.setText(
                        f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
                    )
                else:
                    self.parent.status_label.setText("Pixscale not available for radius calculation.")
            else:
                self.parent.status_label.setText("Unable to determine RA/Dec due to missing WCS.")

            # Update circle data and redraw
            self.parent.update_circle_data()
            self.update_circle()

        elif self.drawing_measurement and event.button() == Qt.MouseButton.LeftButton:
            # Complete the measurement when the mouse is released
            self.drawing_measurement = False
            measurement_end = self.mapToScene(event.pos())

            # Calculate celestial distance between start and end points
            ra1, dec1 = self.parent.calculate_ra_dec_from_pixel(self.measurement_start.x(), self.measurement_start.y())
            ra2, dec2 = self.parent.calculate_ra_dec_from_pixel(measurement_end.x(), measurement_end.y())
            
            if ra1 is not None and dec1 is not None and ra2 is not None and dec2 is not None:
                # Compute the angular distance
                angular_distance = self.parent.calculate_angular_distance(ra1, dec1, ra2, dec2)
                distance_text = self.parent.format_distance_as_dms(angular_distance)

                # Create and add the line item for display
                measurement_line_item = QGraphicsLineItem(QLineF(self.measurement_start, measurement_end))
                measurement_line_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))
                self.parent.main_scene.addItem(measurement_line_item)

                # Create a midpoint position for the distance text
                midpoint = QPointF(
                    (self.measurement_start.x() + measurement_end.x()) / 2,
                    (self.measurement_start.y() + measurement_end.y()) / 2
                )

                # Create and add the text item at the midpoint
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(midpoint)
                text_item.setDefaultTextColor(Qt.GlobalColor.green)
                text_item.setFont(self.parent.selected_font)  # Use the selected font
                self.parent.main_scene.addItem(text_item)

                # Store the line and text in annotation items for future reference
                measurement_line = QLineF(self.measurement_start, measurement_end)
                self.annotation_items.append(('line', measurement_line))  # Store QLineF, not QGraphicsLineItem
                self.annotation_items.append(('text', distance_text, midpoint, Qt.GlobalColor.green))

            # Clear the temporary measurement line item without removing the final line
            self.drawing_item = None



        elif self.drawing_item and event.button() == Qt.MouseButton.LeftButton:
            # Finalize the shape drawing and add its properties to annotation_items
            if isinstance(self.drawing_item, QGraphicsEllipseItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('ellipse', rect, color))
            elif isinstance(self.drawing_item, QGraphicsRectItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('rect', rect, color))
            elif isinstance(self.drawing_item, QGraphicsLineItem):
                line = self.drawing_item.line()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('line', line, color))
            elif isinstance(self.drawing_item, QGraphicsTextItem):
                pos = self.drawing_item.pos()
                text = self.drawing_item.toPlainText()
                color = self.drawing_item.defaultTextColor()
                self.annotation_items.append(('text', pos, text, color))
            elif isinstance(self.drawing_item, QGraphicsPathItem):  # Handle Freehand
                path = self.drawing_item.path()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('freehand', path, color))        

            # Clear the temporary drawing item
            self.drawing_item = None

        # Stop manual dragging and reset cursor to arrow
        self.dragging = False
        self.setCursor(Qt.CursorShape.ArrowCursor)
        
        # Update the mini preview to reflect any changes
        self.update_mini_preview()

        super().mouseReleaseEvent(event)


    def draw_measurement_line_and_label(self, distance_ddmmss):
        """Draw the measurement line and label with the celestial distance."""
        # Draw line
        line_item = QGraphicsLineItem(
            QLineF(self.measurement_start, self.measurement_end)
        )
        line_item.setPen(QPen(QColor(0, 255, 255), 2))  # Cyan color for measurement
        self.parent.main_scene.addItem(line_item)

        # Place distance text at the midpoint of the line
        midpoint = QPointF(
            (self.measurement_start.x() + self.measurement_end.x()) / 2,
            (self.measurement_start.y() + self.measurement_end.y()) / 2
        )
        text_item = QGraphicsTextItem(distance_ddmmss)
        text_item.setDefaultTextColor(QColor(0, 255, 255))  # Same color as line
        text_item.setPos(midpoint)
        self.parent.main_scene.addItem(text_item)
        
        # Append both line and text to annotation_items
        self.annotation_items.append(('line', line_item))
        self.annotation_items.append(('text', midpoint, distance_ddmmss, QColor(0, 255, 255)))


    
    def wheelEvent(self, event):
        """Handle zoom in and out with the mouse wheel."""
        if event.angleDelta().y() > 0:
            self.parent.zoom_in()
        else:
            self.parent.zoom_out()        

    def update_circle(self):
        """Draws the search circle on the main scene if circle_center and circle_radius are set."""
        if self.parent.main_image and self.circle_center is not None and self.circle_radius > 0:
            # Clear the main scene and add the main image back
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)        

                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)

                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)                                
                        
            
            # Draw the search circle
            pen_circle = QPen(QColor(255, 0, 0), 2)
            self.parent.main_scene.addEllipse(
                int(self.circle_center.x() - self.circle_radius),
                int(self.circle_center.y() - self.circle_radius),
                int(self.circle_radius * 2),
                int(self.circle_radius * 2),
                pen_circle
            )
            self.update_mini_preview()
        else:
            # If circle is disabled (e.g., during save), clear without drawing
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

    def delete_selected_object(self):
        if self.selected_object is None:
            self.parent.status_label.setText("No object selected to delete.")
            return

        # Remove the selected object from the results list
        self.parent.results = [obj for obj in self.parent.results if obj != self.selected_object]

        # Remove the corresponding row from the TreeBox
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == self.selected_object["name"]:  # Match the name in the third column
                self.parent.results_tree.takeTopLevelItem(i)
                break

        # Clear the selection
        self.selected_object = None
        self.parent.results_tree.clearSelection()

        # Redraw the main and mini previews without the deleted marker
        self.draw_query_results()
        self.update_mini_preview()

        # Update the status label
        self.parent.status_label.setText("Selected object and marker removed.")



    def scrollContentsBy(self, dx, dy):
        """Called whenever the main preview scrolls, ensuring the green box updates in the mini preview."""
        super().scrollContentsBy(dx, dy)
        self.parent.update_green_box()

    def update_mini_preview(self):
        """Update the mini preview with the current view rectangle and any additional mirrored elements."""
        if self.parent.main_image:
            # Scale the main image to fit in the mini preview
            mini_pixmap = self.parent.main_image.scaled(
                self.parent.mini_preview.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            mini_painter = QPainter(mini_pixmap)

            try:
                # Define scale factors based on main image dimensions
                if self.parent.main_image.width() > 0 and self.parent.main_image.height() > 0:
                    scale_factor_x = mini_pixmap.width() / self.parent.main_image.width()
                    scale_factor_y = mini_pixmap.height() / self.parent.main_image.height()

                    # Draw the search circle if it's defined
                    if self.circle_center is not None and self.circle_radius > 0:
                        pen_circle = QPen(QColor(255, 0, 0), 2)
                        mini_painter.setPen(pen_circle)
                        mini_painter.drawEllipse(
                            int(self.circle_center.x() * scale_factor_x - self.circle_radius * scale_factor_x),
                            int(self.circle_center.y() * scale_factor_y - self.circle_radius * scale_factor_y),
                            int(self.circle_radius * 2 * scale_factor_x),
                            int(self.circle_radius * 2 * scale_factor_y)
                        )

                    # Draw the green box representing the current view
                    mini_painter.setPen(QPen(QColor(0, 255, 0), 2))
                    view_rect = self.parent.main_preview.mapToScene(
                        self.parent.main_preview.viewport().rect()
                    ).boundingRect()
                    mini_painter.drawRect(
                        int(view_rect.x() * scale_factor_x),
                        int(view_rect.y() * scale_factor_y),
                        int(view_rect.width() * scale_factor_x),
                        int(view_rect.height() * scale_factor_y)
                    )


                    # Draw dots for each result with a color based on selection status
                    for obj in self.parent.results:
                        ra, dec = obj['ra'], obj['dec']
                        x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                        if x is not None and y is not None:
                            # Change color to green if this is the selected object
                            dot_color = QColor(0, 255, 0) if obj == getattr(self.parent, 'selected_object', None) else QColor(255, 0, 0)
                            mini_painter.setPen(QPen(dot_color, 4))
                            mini_painter.drawPoint(
                                int(x * scale_factor_x),
                                int(y * scale_factor_y)
                            )

                    # Redraw annotation items on the mini preview
                    for item in self.annotation_items:
                        pen = QPen(self.parent.selected_color, 1)  # Use a thinner pen for mini preview
                        mini_painter.setPen(pen)

                        # Interpret item type and draw accordingly
                        if item[0] == 'ellipse':
                            rect = item[1]
                            mini_painter.drawEllipse(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'rect':
                            rect = item[1]
                            mini_painter.drawRect(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'line':
                            line = item[1]
                            mini_painter.drawLine(
                                int(line.x1() * scale_factor_x), int(line.y1() * scale_factor_y),
                                int(line.x2() * scale_factor_x), int(line.y2() * scale_factor_y)
                            )
                        elif item[0] == 'text':
                            text = item[1]            # The text string
                            pos = item[2]             # A QPointF for the position
                            color = item[3]           # The color for the text

                            # Create a smaller font for the mini preview
                            mini_font = QFont(self.parent.selected_font)
                            mini_font.setPointSize(int(self.parent.selected_font.pointSize() * 0.2))  # Scale down font size

                            mini_painter.setFont(mini_font)
                            mini_painter.setPen(color)  # Set the color for the text
                            mini_painter.drawText(
                                int(pos.x() * scale_factor_x), int(pos.y() * scale_factor_y),
                                text
                            )

                        elif item[0] == 'freehand':
                            # Scale the freehand path and draw it
                            path = item[1]
                            scaled_path = QPainterPath()
                            
                            # Scale each point in the path to fit the mini preview
                            for i in range(path.elementCount()):
                                point = path.elementAt(i)
                                if i == 0:
                                    scaled_path.moveTo(point.x * scale_factor_x, point.y * scale_factor_y)
                                else:
                                    scaled_path.lineTo(point.x * scale_factor_x, point.y * scale_factor_y)

                            mini_painter.drawPath(scaled_path)

                        elif item[0] == 'compass':
                            compass = item[1]
                            # Draw the North line
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_line = compass["north_line"]
                            mini_painter.drawLine(
                                int(north_line[0] * scale_factor_x), int(north_line[1] * scale_factor_y),
                                int(north_line[2] * scale_factor_x), int(north_line[3] * scale_factor_y)
                            )

                            # Draw the East line
                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_line = compass["east_line"]
                            mini_painter.drawLine(
                                int(east_line[0] * scale_factor_x), int(east_line[1] * scale_factor_y),
                                int(east_line[2] * scale_factor_x), int(east_line[3] * scale_factor_y)
                            )

                            # Draw North and East labels
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_label = compass["north_label"]
                            mini_painter.drawText(
                                int(north_label[0] * scale_factor_x), int(north_label[1] * scale_factor_y), north_label[2]
                            )

                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_label = compass["east_label"]
                            mini_painter.drawText(
                                int(east_label[0] * scale_factor_x), int(east_label[1] * scale_factor_y), east_label[2]
                            )                            

            finally:
                mini_painter.end()  # Ensure QPainter is properly ended

            self.parent.mini_preview.setPixmap(mini_pixmap)

    def place_celestial_compass(self, center):
        """Draw a celestial compass at a given point aligned with celestial North and East."""
        compass_radius = 50  # Length of the compass lines

        # Get the orientation in radians (assuming `self.parent.orientation` is in degrees)
        orientation_radians = math.radians(self.parent.orientation)

        # Calculate North vector (upwards, adjusted for orientation)
        north_dx = math.sin(orientation_radians) * compass_radius
        north_dy = -math.cos(orientation_radians) * compass_radius

        # Calculate East vector (rightwards, adjusted for orientation)
        east_dx = math.cos(orientation_radians) * -compass_radius
        east_dy = math.sin(orientation_radians) * -compass_radius

        # Draw North line
        north_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + north_dx, center.y() + north_dy
        )
        north_line.setPen(QPen(Qt.GlobalColor.red, 2))
        self.parent.main_scene.addItem(north_line)

        # Draw East line
        east_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + east_dx, center.y() + east_dy
        )
        east_line.setPen(QPen(Qt.GlobalColor.blue, 2))
        self.parent.main_scene.addItem(east_line)

        # Add labels for North and East
        text_north = QGraphicsTextItem("N")
        text_north.setDefaultTextColor(Qt.GlobalColor.red)
        text_north.setPos(center.x() + north_dx - 10, center.y() + north_dy - 10)
        self.parent.main_scene.addItem(text_north)

        text_east = QGraphicsTextItem("E")
        text_east.setDefaultTextColor(Qt.GlobalColor.blue)
        text_east.setPos(center.x() + east_dx - 15, center.y() + east_dy - 10)
        self.parent.main_scene.addItem(text_east)

        # Append all compass components as a tuple to annotation_items for later redrawing
        self.annotation_items.append((
            "compass", {
                "center": center,
                "north_line": (center.x(), center.y(), center.x() + north_dx, center.y() + north_dy),
                "east_line": (center.x(), center.y(), center.x() + east_dx, center.y() + east_dy),
                "north_label": (center.x() + north_dx - 10, center.y() + north_dy - 10, "N"),
                "east_label": (center.x() + east_dx - 15, center.y() + east_dy - 10, "E"),
                "orientation": self.parent.orientation
            }
        ))

    def zoom_to_coordinates(self, ra, dec):
        """Zoom to the specified RA/Dec coordinates and center the view on that position."""
        # Calculate the pixel position from RA and Dec
        pixel_x, pixel_y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
        
        if pixel_x is not None and pixel_y is not None:
            # Center the view on the calculated pixel position
            self.centerOn(pixel_x, pixel_y)
            
            # Reset the zoom level to 1.0 by adjusting the transformation matrix
            self.resetTransform()
            self.scale(1.0, 1.0)

            # Optionally, update the mini preview to reflect the new zoom and center
            self.update_mini_preview()

    def draw_query_results(self):
        """Draw query results with or without names based on the show_names setting."""
        if self.parent.main_image:
            # Clear the main scene and re-add the main image
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)                      
                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)        
                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)                               
            # Ensure the search circle is drawn if circle data is available
            #if self.circle_center is not None and self.circle_radius > 0:
            #    self.update_circle()

            # Draw object markers (circle or crosshair)
            for obj in self.parent.results:
                ra, dec, name = obj["ra"], obj["dec"], obj["name"]
                x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                if x is not None and y is not None:
                    # Determine color: green if selected, red otherwise
                    base_color = obj["color"]
                    pen_color  = QColor(0,255,0) if obj is self.selected_object else base_color
                    pen = QPen(pen_color, 2)

                    if self.parent.marker_style == "Circle":
                        # Draw a circle around the object
                        self.parent.main_scene.addEllipse(int(x - 5), int(y - 5), 10, 10, pen)
                    elif self.parent.marker_style == "Crosshair":
                        # Draw crosshair with a 5-pixel gap in the middle
                        crosshair_size = 10
                        gap = 5
                        line1 = QLineF(x - crosshair_size, y, x - gap, y)
                        line2 = QLineF(x + gap, y, x + crosshair_size, y)
                        line3 = QLineF(x, y - crosshair_size, x, y - gap)
                        line4 = QLineF(x, y + gap, x, y + crosshair_size)
                        for line in [line1, line2, line3, line4]:
                            crosshair_item = QGraphicsLineItem(line)
                            crosshair_item.setPen(pen)
                            self.parent.main_scene.addItem(crosshair_item)
                    if self.parent.show_names:
                        #print(f"Drawing name: {name} at ({x}, {y})")  # Debugging statement
                        text_color = obj.get("color", QColor(Qt.GlobalColor.white))
                        text_item = QGraphicsTextItem(name)
                        text_item.setPos(x + 10, y + 10)  # Offset to avoid overlapping the marker
                        text_item.setDefaultTextColor(text_color)
                        text_item.setFont(self.parent.selected_font)
                        self.parent.main_scene.addItem(text_item)                            
    

    def clear_query_results(self):
        """Clear query markers from the main image without removing annotations."""
        # Clear the main scene and add the main image back
        self.parent.main_scene.clear()
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)
        
        # Redraw the stored annotation items
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item)  
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)       
            elif item[0] == 'compass':
                compass = item[1]
                # North line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                # East line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                # North label
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                # East label
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)
        
        # Update the circle data, if any
        self.parent.update_circle_data()
                        

    def set_query_results(self, results):
        """Store results, assign each object a category & color, then redraw."""
        self.parent.results = results

        for obj in self.parent.results:
            # use the same key you populated in MainWindow.query_simbad
            short_type = obj.get("short_type", "")
            category   = OTYPE_TO_CATEGORY.get(short_type, "Errors & Artefacts")
            obj["category"] = category

            # lookup the QColor for that category (fallback to white)
            obj["color"]    = CATEGORY_TO_COLOR.get(category, QColor(255,255,255))

        self.draw_query_results()

    def get_object_at_position(self, pos):
        """Find the object at the given position in the main preview."""
        for obj in self.parent.results:
            ra, dec = obj["ra"], obj["dec"]
            x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
            if x is not None and y is not None:
                if abs(pos.x() - x) <= 5 and abs(pos.y() - y) <= 5:
                    return obj
        return None


    def select_object(self, selected_obj):
        """Select or deselect the specified object and update visuals."""
        self.selected_object = selected_obj if self.selected_object != selected_obj else None
        self.draw_query_results()  # Redraw to reflect selection

        # Update the TreeWidget selection in MainWindow
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == selected_obj["name"]:  # Assuming 'name' is the unique identifier
                self.parent.results_tree.setCurrentItem(item if self.selected_object else None)
                break

    def undo_annotation(self):
        """Remove the last annotation item from the scene and annotation_items list."""
        if self.annotation_items:
            # Remove the last item from annotation_items
            self.annotation_items.pop()

            # Clear the scene and redraw all annotations except the last one
            self.parent.main_scene.clear()
            if self.parent.main_image:
                self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw remaining annotations
            self.redraw_annotations()

            # Optionally, update the mini preview to reflect changes
            self.update_mini_preview()

    def clear_annotations(self):
        """Clear all annotation items from the scene and annotation_items list."""
        # Clear all items in annotation_items and update the scene
        self.annotation_items.clear()
        self.parent.main_scene.clear()
        
        # Redraw only the main image
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)

        # Optionally, update the mini preview to reflect changes
        self.update_mini_preview()

    def redraw_annotations(self):
        """Helper function to redraw all annotations from annotation_items."""
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item) 
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)                                        
            elif item[0] == 'compass':
                compass = item[1]
                # Redraw north line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                
                # Redraw east line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                
                # Redraw labels
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)        

class ThreeDSettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("3D Model Settings")
        layout = QVBoxLayout(self)

        # Image Plane Style
        layout.addWidget(QLabel("Image Plane Style:"))
        self.plane_style_cb = QComboBox()
        self.plane_style_cb.addItems([
            "Mesh RGB Scatter Plane",
            "Smooth Grayscale Image Plane"
        ])
        layout.addWidget(self.plane_style_cb)

        # Resolution
        res_layout = QHBoxLayout()
        res_layout.addWidget(QLabel("Resolution:"))
        self.res_spin = QSpinBox()
        self.res_spin.setRange(50, 2000)
        self.res_spin.setSingleStep(50)
        self.res_spin.setValue(500)
        res_layout.addWidget(self.res_spin)
        layout.addLayout(res_layout)

        # Z-Axis Range Options (Min-Max/Custom as before)
        layout.addWidget(QLabel("Z-Axis Range:"))
        self.zaxis_cb = QComboBox()
        self.zaxis_cb.addItems(["Default", "Min-Max", "Custom"])
        layout.addWidget(self.zaxis_cb)

        self.custom_widget = QWidget()
        cl = QHBoxLayout(self.custom_widget)
        cl.addWidget(QLabel("Min:"))
        self.zmin_spin = QDoubleSpinBox()
        self.zmin_spin.setRange(-1e6, 1e6)
        self.zmin_spin.setValue(0.0)
        cl.addWidget(self.zmin_spin)
        cl.addWidget(QLabel("Max:"))
        self.zmax_spin = QDoubleSpinBox()
        self.zmax_spin.setRange(-1e6, 1e6)
        self.zmax_spin.setValue(10.0)
        cl.addWidget(self.zmax_spin)
        layout.addWidget(self.custom_widget)
        self.custom_widget.setVisible(False)
        self.zaxis_cb.currentIndexChanged.connect(
            lambda idx: self.custom_widget.setVisible(self.zaxis_cb.currentText() == "Custom")
        )

        # Z-Axis Scale: Log vs Linear
        layout.addWidget(QLabel("Z-Axis Scale:"))
        self.zscale_cb = QComboBox()
        self.zscale_cb.addItems(["Logarithmic", "Linear"])
        layout.addWidget(self.zscale_cb)

        # Linear max input
        self.linear_widget = QWidget()
        ll = QHBoxLayout(self.linear_widget)
        ll.addWidget(QLabel("Linear Z-Max:"))
        self.linear_max_spin = QDoubleSpinBox()
        self.linear_max_spin.setRange(0.1, 1e12)
        self.linear_max_spin.setValue(1e4)
        ll.addWidget(self.linear_max_spin)
        layout.addWidget(self.linear_widget)
        self.linear_widget.setVisible(False)
        self.zscale_cb.currentIndexChanged.connect(
            lambda idx: self.linear_widget.setVisible(self.zscale_cb.currentText() == "Linear")
        )

        self.reverse_cb = QCheckBox("Reverse Z-Axis")
        self.reverse_cb.setChecked(False)
        layout.addWidget(self.reverse_cb)

        # Object Color
        layout.addWidget(QLabel("Object Color:"))
        self.color_cb = QComboBox()
        self.color_cb.addItems(["Image-Based", "Legend Color", "Solid (Custom)"])
        layout.addWidget(self.color_cb)

        self.color_btn = QPushButton("Choose Color…")
        self.custom_color = QColor(255, 0, 0)
        self.color_btn.setVisible(False)
        layout.addWidget(self.color_btn)
        self.color_btn.clicked.connect(self._choose_color)
        self.color_cb.currentIndexChanged.connect(
            lambda idx: self.color_btn.setVisible(self.color_cb.currentText() == "Solid (Custom)")
        )

        # Z-Axis Height control
        layout.addWidget(QLabel("Z-Axis Height (aspect ratio z):"))
        self.zheight_spin = QDoubleSpinBox()
        self.zheight_spin.setRange(0.1, 10.0)
        self.zheight_spin.setSingleStep(0.1)
        self.zheight_spin.setValue(0.5)
        layout.addWidget(self.zheight_spin)

        # ─── Show Connector Lines ─────────────────────────────
        self.lines_cb = QCheckBox("Show Connector Lines")
        self.lines_cb.setChecked(True)
        layout.addWidget(self.lines_cb)

        # OK / Cancel
        btns = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok |
                                QDialogButtonBox.StandardButton.Cancel)
        btns.accepted.connect(self.accept)
        btns.rejected.connect(self.reject)
        layout.addWidget(btns)

    def _choose_color(self):
        col = QColorDialog.getColor(self.custom_color, self, "Select Object Color")
        if col.isValid():
            self.custom_color = col

    def getSettings(self):
        if self.exec() == QDialog.DialogCode.Accepted:
            return {
                "plane_style": self.plane_style_cb.currentText(),
                "resolution": self.res_spin.value(),
                "z_option":   self.zaxis_cb.currentText(),
                "z_min":      self.zmin_spin.value(),
                "z_max":      self.zmax_spin.value(),
                "z_scale":    self.zscale_cb.currentText(),
                "linear_max": self.linear_max_spin.value(),
                "object_color": self.color_cb.currentText(),
                "custom_color": self.custom_color,      # QColor
                "z_height":   self.zheight_spin.value(),
                "show_lines": self.lines_cb.isChecked(),
                "reverse_z":   self.reverse_cb.isChecked(),
            }
        return None

class LegendDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Object Type Legend")
        self.swatches = {}
        layout = QVBoxLayout(self)

        # Build one row per category
        for category, color in CATEGORY_TO_COLOR.items():
            row = QHBoxLayout()

            # color swatch
            swatch = QLabel()
            swatch.setFixedSize(16, 16)
            swatch.setStyleSheet(f"background-color: {color.name()}; border:1px solid #000;")
            row.addWidget(swatch)
            self.swatches[category] = swatch

            # category name
            row.addWidget(QLabel(category))

            # edit‐color button
            btn = QPushButton("Edit…")
            btn.clicked.connect(lambda _, cat=category: self.change_color(cat))
            row.addWidget(btn)

            row.addStretch()
            layout.addLayout(row)

        # OK / Cancel buttons
        btn_row = QHBoxLayout()
        ok = QPushButton("OK")
        ok.clicked.connect(self.accept)
        cancel = QPushButton("Cancel")
        cancel.clicked.connect(self.reject)
        btn_row.addStretch()
        btn_row.addWidget(ok)
        btn_row.addWidget(cancel)
        layout.addLayout(btn_row)

    def change_color(self, category):
        """Open a QColorDialog, update the swatch and CATEGORY_TO_COLOR."""
        initial = CATEGORY_TO_COLOR[category]
        c = QColorDialog.getColor(initial, self, f"Select color for {category}")
        if c.isValid():
            CATEGORY_TO_COLOR[category] = c
            sw = self.swatches[category]
            sw.setStyleSheet(f"background-color: {c.name()}; border:1px solid #000;")

def kelvin_to_rgb(T):
    """Approximate conversion from black‐body temperature (K) to sRGB tuple."""
    # based on Tanner Helland's approximation
    # Clamp input
    T = max(1000, min(T, 40000)) / 100.0
    # red
    if T <= 66:
        r = 255
    else:
        r = 329.698727446 * ((T - 60) ** -0.1332047592)
    # green
    if T <= 66:
        g = 99.4708025861 * math.log(T) - 161.1195681661
    else:
        g = 288.1221695283 * ((T - 60) ** -0.0755148492)
    # blue
    if T >= 66:
        b = 255
    elif T <= 19:
        b = 0
    else:
        b = 138.5177312231 * math.log(T - 10) - 305.0447927307

    # clamp and return CSS‐style rgb()
    def clamp(x): return int(max(0, min(x, 255)))
    return f"rgb({clamp(r)},{clamp(g)},{clamp(b)})"

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("What's In My Image")
        self.setGeometry(100, 100, 800, 600)
        # Track the theme status
        self.is_dark_mode = True
        self.metadata = {}
        self.circle_center = None
        self.circle_radius = 0    
        self.show_names = False  # Boolean to toggle showing names on the main image
        self.max_results = 100  # Default maximum number of query results     
        self.current_tool = None  # Track the active annotation tool
        self.header = Header()
        self.marker_style = "Circle" 
        self.settings = QSettings() 
            

        main_layout = QHBoxLayout()

        # Left Column Layout
        left_panel = QVBoxLayout()

        # Load the image using the resource_path function
        wimilogo_path = resource_path("wimilogo.png")

        # Create a QLabel to display the logo
        self.logo_label = QLabel()

        # Set the logo image to the label
        logo_pixmap = QPixmap(wimilogo_path)

        # Scale the pixmap to fit within a desired size, maintaining the aspect ratio
        scaled_pixmap = logo_pixmap.scaled(200, 100, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Set the scaled pixmap to the label
        self.logo_label.setPixmap(scaled_pixmap)

        # Set alignment to center the logo horizontally
        self.logo_label.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Optionally, you can set a fixed size for the label (this is for layout purposes)
        self.logo_label.setFixedSize(200, 100)  # Adjust the size as needed

        # Add the logo_label to your layout
        left_panel.addWidget(self.logo_label)
       
        button_layout = QHBoxLayout()
        
        # Load button
        self.load_button = QPushButton("Load Image")
        self.load_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogStart))
        self.load_button.clicked.connect(self.open_image)

        # AutoStretch button
        self.auto_stretch_button = QPushButton("AutoStretch")
        self.auto_stretch_button.clicked.connect(self.toggle_autostretch)

        # Add both buttons to the horizontal layout
        button_layout.addWidget(self.load_button)
        button_layout.addWidget(self.auto_stretch_button)

        # Add the button layout to the left panel
        left_panel.addLayout(button_layout)

        # Create the instruction QLabel for search region
        search_region_instruction_label = QLabel("Shift+Click to define a search region")
        search_region_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        search_region_instruction_label.setStyleSheet("font-size: 15px; color: gray;")

        # Add this QLabel to your layout at the appropriate position above RA/Dec
        left_panel.addWidget(search_region_instruction_label)  



        # Query Simbad button
        self.query_button = QPushButton("Query Simbad")
        self.query_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        left_panel.addWidget(self.query_button)
        self.query_button.clicked.connect(lambda: self.query_simbad(self.get_defined_radius()))

        self.legend_button = QPushButton("Legend")
        self.legend_button.clicked.connect(self.show_legend)
        left_panel.addWidget(self.legend_button)

        # Create a horizontal layout for the show names checkbox and clear results button
        show_clear_layout = QHBoxLayout()

        # Create the Show Object Names checkbox
        self.show_names_checkbox = QCheckBox("Show Object Names")
        self.show_names_checkbox.stateChanged.connect(self.toggle_object_names)  # Connect to a function to toggle names
        show_clear_layout.addWidget(self.show_names_checkbox)

        # Create the Clear Results button
        self.clear_results_button = QPushButton("Clear Results")
        self.clear_results_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))
        self.clear_results_button.clicked.connect(self.clear_search_results)  # Connect to a function to clear results
        show_clear_layout.addWidget(self.clear_results_button)

        # Add this horizontal layout to the left panel layout (or wherever you want it to appear)
        left_panel.addLayout(show_clear_layout)   

        # Create a horizontal layout for the two buttons
        button_layout = QHBoxLayout()

        # Show Visible Objects Only button
        self.toggle_visible_objects_button = QPushButton("Show Visible Objects Only")
        self.toggle_visible_objects_button.setCheckable(True)  # Toggle button state
        self.toggle_visible_objects_button.setIcon(QIcon(eye_icon_path))
        self.toggle_visible_objects_button.clicked.connect(self.filter_visible_objects)
        self.toggle_visible_objects_button.setToolTip("Toggle the visibility of objects based on brightness.")
        button_layout.addWidget(self.toggle_visible_objects_button)

        # Save CSV button
        self.save_csv_button = QPushButton("Save CSV")
        self.save_csv_button.setIcon(QIcon(csv_icon_path))
        self.save_csv_button.clicked.connect(self.save_results_as_csv)
        button_layout.addWidget(self.save_csv_button)

        # Add the button layout to the left panel or main layout
        left_panel.addLayout(button_layout)  

        # Advanced Search Button
        self.advanced_search_button = QPushButton("Advanced Search")
        self.advanced_search_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogDetailedView))
        self.advanced_search_button.setCheckable(True)
        self.advanced_search_button.clicked.connect(self.toggle_advanced_search)
        left_panel.addWidget(self.advanced_search_button)

        # Advanced Search Panel (initially hidden)
        self.advanced_search_panel = QVBoxLayout()
        self.advanced_search_panel_widget = QWidget()
        self.advanced_search_panel_widget.setLayout(self.advanced_search_panel)
        self.advanced_search_panel_widget.setFixedWidth(300)
        self.advanced_search_panel_widget.setVisible(False)  # Hide initially        

        # Status label
        self.status_label = QLabel("Status: Ready")
        left_panel.addWidget(self.status_label)

        # Create a horizontal layout
        button_layout = QHBoxLayout()

        # Copy RA/Dec to Clipboard button
        self.copy_button = QPushButton("Copy RA/Dec to Clipboard", self)
        self.copy_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_CommandLink))
        self.copy_button.clicked.connect(self.copy_ra_dec_to_clipboard)
        button_layout.addWidget(self.copy_button)

        # Settings button (wrench icon)
        self.settings_button = QPushButton()
        self.settings_button.setIcon(QIcon(wrench_path))  # Adjust icon path as needed
        self.settings_button.clicked.connect(self.open_settings_dialog)
        button_layout.addWidget(self.settings_button)

        # Add the horizontal layout to the main layout or the desired parent layout
        left_panel.addLayout(button_layout)
        
         # Save Plate Solved Fits Button
        self.save_plate_solved_button = QPushButton("Save Plate Solved Fits")
        self.save_plate_solved_button.setIcon(QIcon(disk_icon_path))
        self.save_plate_solved_button.clicked.connect(self.save_plate_solved_fits)
        left_panel.addWidget(self.save_plate_solved_button)       

        # RA/Dec Labels
        ra_dec_layout = QHBoxLayout()
        self.ra_label = QLabel("RA: N/A")
        self.dec_label = QLabel("Dec: N/A")
        self.orientation_label = QLabel("Orientation: N/A°")
        ra_dec_layout.addWidget(self.ra_label)
        ra_dec_layout.addWidget(self.dec_label)
        ra_dec_layout.addWidget(self.orientation_label)
        left_panel.addLayout(ra_dec_layout)

        # Mini Preview
        self.mini_preview = QLabel("Mini Preview")
        self.mini_preview.setFixedSize(300, 300)
        self.mini_preview.mousePressEvent = self.on_mini_preview_press
        self.mini_preview.mouseMoveEvent = self.on_mini_preview_drag
        self.mini_preview.mouseReleaseEvent = self.on_mini_preview_release
        left_panel.addWidget(self.mini_preview)

  

        footer_label = QLabel("""
            Written by Franklin Marek<br>
            <a href='http://www.setiastro.com'>www.setiastro.com</a>
        """)
        footer_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer_label.setOpenExternalLinks(True)
        footer_label.setStyleSheet("font-size: 10px;")
        left_panel.addWidget(footer_label)

        # Right Column Layout
        right_panel = QVBoxLayout()

        # Zoom buttons above the main preview
        zoom_controls_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_in_button)
        zoom_controls_layout.addWidget(self.zoom_out_button)
        right_panel.addLayout(zoom_controls_layout)        

        # Main Preview
        self.main_preview = CustomGraphicsView(self)
        self.main_scene = QGraphicsScene(self.main_preview)
        self.main_preview.setScene(self.main_scene)
        self.main_preview.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.main_preview.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        right_panel.addWidget(self.main_preview)

        # Save Annotated Image and Save Collage of Objects Buttons in a Horizontal Layout between main image and treebox
        save_buttons_layout = QHBoxLayout()

        # Button to toggle annotation tools section
        self.show_annotations_button = QPushButton("Show Annotation Tools")
        self.show_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogResetButton))
        self.show_annotations_button.clicked.connect(self.toggle_annotation_tools)
        save_buttons_layout.addWidget(self.show_annotations_button)
        
        self.save_annotated_button = QPushButton("Save Annotated Image")
        self.save_annotated_button.setIcon(QIcon(annotated_path))
        self.save_annotated_button.clicked.connect(self.save_annotated_image)
        save_buttons_layout.addWidget(self.save_annotated_button)
        
        self.save_collage_button = QPushButton("Save Collage of Objects")
        self.save_collage_button.setIcon(QIcon(collage_path))
        self.save_collage_button.clicked.connect(self.save_collage_of_objects)
        save_buttons_layout.addWidget(self.save_collage_button)

        # New 3D View Button
        self.show_3d_view_button = QPushButton("3D Distance Model")
        self.show_3d_view_button.clicked.connect(self.show_3d_model_view)
        self.show_3d_view_button.setIcon(    QApplication.style().standardIcon(QStyle.StandardPixmap.SP_TitleBarNormalButton))
        save_buttons_layout.addWidget(self.show_3d_view_button)

        self.show_hr_button = QPushButton("H-R Diagram")
        # Optionally give it an icon:
        self.show_hr_button.setIcon(QApplication.style().standardIcon(
            QStyle.StandardPixmap.SP_DesktopIcon))
        self.show_hr_button.clicked.connect(self.show_hr_diagram)
        save_buttons_layout.addWidget(self.show_hr_button)

        right_panel.addLayout(save_buttons_layout)        

        # Connect scroll events to update the green box in the mini preview
        self.main_preview.verticalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)
        self.main_preview.horizontalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)

        # Create a horizontal layout for the labels
        label_layout = QHBoxLayout()

        # Create the label to display the count of objects
        self.object_count_label = QLabel("Objects Found: 0")

        # Create the label with instructions
        self.instructions_label = QLabel("Right Click a Row for More Options")

        # Add both labels to the horizontal layout
        label_layout.addWidget(self.object_count_label)
        label_layout.addWidget(self.instructions_label)

        # Add the horizontal layout to the main panel layout
        right_panel.addLayout(label_layout)

        self.results_tree = QTreeWidget()
        self.results_tree.setHeaderLabels(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])
        self.results_tree.setFixedHeight(150)
        self.results_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.results_tree.customContextMenuRequested.connect(self.open_context_menu)
        self.results_tree.itemClicked.connect(self.on_tree_item_clicked)
        self.results_tree.itemDoubleClicked.connect(self.on_tree_item_double_clicked)
        self.results_tree.setSortingEnabled(True)
        right_panel.addWidget(self.results_tree)

        self.annotation_buttons = []

        # Annotation Tools Section (initially hidden)
        self.annotation_tools_section = QWidget()
        annotation_tools_layout = QGridLayout(self.annotation_tools_section)

        annotation_instruction_label = QLabel("Ctrl+Click to add items, Alt+Click to measure distance")
        annotation_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        annotation_instruction_label.setStyleSheet("font-size: 10px; color: gray;")        

        self.draw_ellipse_button = QPushButton("Draw Ellipse")
        self.draw_ellipse_button.tool_name = "Ellipse"
        self.draw_ellipse_button.clicked.connect(lambda: self.set_tool("Ellipse"))
        self.annotation_buttons.append(self.draw_ellipse_button)

        self.freehand_button = QPushButton("Freehand (Lasso)")
        self.freehand_button.tool_name = "Freehand"
        self.freehand_button.clicked.connect(lambda: self.set_tool("Freehand"))
        self.annotation_buttons.append(self.freehand_button)

        self.draw_rectangle_button = QPushButton("Draw Rectangle")
        self.draw_rectangle_button.tool_name = "Rectangle"
        self.draw_rectangle_button.clicked.connect(lambda: self.set_tool("Rectangle"))
        self.annotation_buttons.append(self.draw_rectangle_button)

        self.draw_arrow_button = QPushButton("Draw Arrow")
        self.draw_arrow_button.tool_name = "Arrow"
        self.draw_arrow_button.clicked.connect(lambda: self.set_tool("Arrow"))
        self.annotation_buttons.append(self.draw_arrow_button)

        self.place_compass_button = QPushButton("Place Celestial Compass")
        self.place_compass_button.tool_name = "Compass"
        self.place_compass_button.clicked.connect(lambda: self.set_tool("Compass"))
        self.annotation_buttons.append(self.place_compass_button)

        self.add_text_button = QPushButton("Add Text")
        self.add_text_button.tool_name = "Text"
        self.add_text_button.clicked.connect(lambda: self.set_tool("Text"))
        self.annotation_buttons.append(self.add_text_button)

        # Add Color and Font buttons
        self.color_button = QPushButton("Select Color")
        self.color_button.setIcon(QIcon(colorwheel_path))
        self.color_button.clicked.connect(self.select_color)

        self.font_button = QPushButton("Select Font")
        self.font_button.setIcon(QIcon(font_path))
        self.font_button.clicked.connect(self.select_font)

        # Undo button
        self.undo_button = QPushButton("Undo")
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))  # Left arrow icon for undo
        self.undo_button.clicked.connect(self.main_preview.undo_annotation)  # Connect to undo_annotation in CustomGraphicsView

        # Clear Annotations button
        self.clear_annotations_button = QPushButton("Clear Annotations")
        self.clear_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_TrashIcon))  # Trash icon
        self.clear_annotations_button.clicked.connect(self.main_preview.clear_annotations)  # Connect to clear_annotations in CustomGraphicsView

        # Delete Selected Object button
        self.delete_selected_object_button = QPushButton("Delete Selected Object")
        self.delete_selected_object_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))  # Trash icon
        self.delete_selected_object_button.clicked.connect(self.main_preview.delete_selected_object)  # Connect to delete_selected_object in CustomGraphicsView

        # Add the instruction label to the top of the grid layout (row 0, spanning multiple columns)
        annotation_tools_layout.addWidget(annotation_instruction_label, 0, 0, 1, 4)  # Span 5 columns to center it

        # Shift all other widgets down by one row
        annotation_tools_layout.addWidget(self.draw_ellipse_button, 1, 0)
        annotation_tools_layout.addWidget(self.freehand_button, 1, 1)
        annotation_tools_layout.addWidget(self.draw_rectangle_button, 2, 0)
        annotation_tools_layout.addWidget(self.draw_arrow_button, 2, 1)
        annotation_tools_layout.addWidget(self.place_compass_button, 3, 0)
        annotation_tools_layout.addWidget(self.add_text_button, 3, 1)
        annotation_tools_layout.addWidget(self.color_button, 4, 0)
        annotation_tools_layout.addWidget(self.font_button, 4, 1)
        annotation_tools_layout.addWidget(self.undo_button, 1, 4)
        annotation_tools_layout.addWidget(self.clear_annotations_button, 2, 4)
        annotation_tools_layout.addWidget(self.delete_selected_object_button, 3, 4)

        self.annotation_tools_section.setVisible(False)  # Initially hidden
        right_panel.addWidget(self.annotation_tools_section)

        # Advanced Search Panel
        self.advanced_param_label = QLabel("Advanced Search Parameters")
        self.advanced_search_panel.addWidget(self.advanced_param_label)

        # TreeWidget for object types
        self.object_tree = QTreeWidget()
        self.object_tree.setHeaderLabels(["Object Type", "Description"])
        self.object_tree.setColumnWidth(0, 150)
        self.object_tree.setSortingEnabled(True)

        # Populate the TreeWidget with object types from otype_long_name_lookup
        for obj_type, description in otype_long_name_lookup.items():
            item = QTreeWidgetItem([obj_type, description])
            item.setCheckState(0, Qt.CheckState.Checked)  # Start with all items unchecked
            self.object_tree.addTopLevelItem(item)

        self.advanced_search_panel.addWidget(self.object_tree)

        # Buttons for toggling selections
        toggle_buttons_layout = QHBoxLayout()

        # Toggle All
        self.toggle_all_button = QPushButton("Toggle All")
        self.toggle_all_button.clicked.connect(self.toggle_all_items)
        toggle_buttons_layout.addWidget(self.toggle_all_button)

        # Save Custom List
        self.save_list_button = QPushButton("Save List…")
        self.save_list_button.clicked.connect(self.save_custom_list)
        toggle_buttons_layout.addWidget(self.save_list_button)

        # Load Custom List
        self.load_list_button = QPushButton("Load List…")
        self.load_list_button.clicked.connect(self.load_custom_list)
        toggle_buttons_layout.addWidget(self.load_list_button)

        self.advanced_search_panel.addLayout(toggle_buttons_layout)   

        # Add Simbad Search buttons below the toggle buttons
        search_button_layout = QHBoxLayout()

        self.simbad_defined_region_button = QPushButton("Search Defined Region")
        self.simbad_defined_region_button.clicked.connect(self.search_defined_region)
        search_button_layout.addWidget(self.simbad_defined_region_button)

        self.simbad_entire_image_button = QPushButton("Search Entire Image")
        self.simbad_entire_image_button.clicked.connect(self.search_entire_image)
        search_button_layout.addWidget(self.simbad_entire_image_button)

        self.advanced_search_panel.addLayout(search_button_layout)

        # Adding the "Deep Vizier Search" button below the other search buttons
        self.deep_vizier_button = QPushButton("Caution - Deep Vizier Search")
        self.deep_vizier_button.setIcon(QIcon(nuke_path))  # Assuming `nuke_path` is the correct path for the icon
        self.deep_vizier_button.setToolTip("Perform a deep search with Vizier. Caution: May return large datasets.")

        # Connect the button to a placeholder method for the deep Vizier search
        self.deep_vizier_button.clicked.connect(self.perform_deep_vizier_search)

        # Add the Deep Vizier button to the advanced search layout
        self.advanced_search_panel.addWidget(self.deep_vizier_button)

        self.mast_search_button = QPushButton("Search M.A.S.T Database")
        self.mast_search_button.setIcon(QIcon(hubble_path))
        self.mast_search_button.clicked.connect(self.perform_mast_search)
        self.mast_search_button.setToolTip("Search Hubble, JWST, Spitzer, TESS and More.")
        self.advanced_search_panel.addWidget(self.mast_search_button)                        

        # Combine left and right panels
        main_layout.addLayout(left_panel)
        main_layout.addLayout(right_panel)
        main_layout.addWidget(self.advanced_search_panel_widget)
        
        container = QWidget()
        container.setLayout(main_layout)
        self.setCentralWidget(container)

        self.image_path = None
        self.zoom_level = 1.0
        self.main_image = None
        self.green_box = None
        self.dragging = False
        self.center_ra = None
        self.center_dec = None
        self.pixscale = None
        self.orientation = None
        self.parity = None  
        self.circle_center = None
        self.circle_radius = 0  
        self.results = []
        self.wcs = None  # Initialize WCS to None
        # Initialize selected color and font with default values
        self.selected_color = QColor(Qt.GlobalColor.red)  # Default annotation color
        self.selected_font = QFont("Arial", 12)  # Default font for text annotations   
        self.populate_object_tree()     
        self._legend_dock = QDockWidget("Object Type Legend", self)
        legend = LegendDialog(self)
        legend.setModal(False)
    

    def show_legend(self):
        # keep a persistent reference so it doesn't get garbage-collected
        if not hasattr(self, "_legend_dialog"):
            self._legend_dialog = LegendDialog(self)
            self._legend_dialog.setModal(False)
        self._legend_dialog.show()
        self._legend_dialog.raise_()
        self._legend_dialog.activateWindow()




    def populate_object_tree(self):
        self.object_tree.blockSignals(True)
        self.object_tree.clear()

        # 1) Build reverse map: category → list of short codes
        cat_to_types = defaultdict(list)

        # Pre-sort patterns so more specific (longer) come first
        patterns = list(OTYPE_TO_CATEGORY.items())
        patterns.sort(key=lambda x: len(x[0]), reverse=True)

        for code, longname in otype_long_name_lookup.items():
            # first try exact
            cat = OTYPE_TO_CATEGORY.get(code)
            if cat is None:
                # then try wildcard patterns (but skip the lone "*" pattern)
                for pat, candidate_cat in patterns:
                    if any(c in pat for c in "*?") and pat != "*" and fnmatch.fnmatch(code, pat):
                        cat = candidate_cat
                        break
            if cat is None:
                cat = "Errors & Artefacts"
            cat_to_types[cat].append(code)

        # 2) Populate tree
        for category, codes in cat_to_types.items():
            color  = CATEGORY_TO_COLOR.get(category, QColor(200,200,200))
            parent = QTreeWidgetItem(self.object_tree, [category, ""])
            parent.setFlags(parent.flags() | Qt.ItemFlag.ItemIsUserCheckable)
            parent.setCheckState(0, Qt.CheckState.Checked)
            parent.setForeground(0, QBrush(color))
            parent.setFirstColumnSpanned(True)

            for code in sorted(codes):
                desc  = otype_long_name_lookup[code]
                child = QTreeWidgetItem(parent, [code, desc])
                child.setFlags(child.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                child.setCheckState(0, Qt.CheckState.Checked)
                pix = QPixmap(12,12)
                pix.fill(color)
                child.setIcon(0, QIcon(pix))

        self.object_tree.blockSignals(False)

        # wire up a very simple parent→children handler (no partial logic)
        try:
            self.object_tree.itemChanged.disconnect(self.on_object_tree_item_changed)
        except TypeError:
            pass
        self.object_tree.itemChanged.connect(self.on_object_tree_item_changed)


    def get_selected_object_types(self) -> list:
        """
        Return all the otype codes (children) whose checkboxes are checked.
        """
        checked = []
        root = self.object_tree.invisibleRootItem()
        # iterate over each category
        for i in range(root.childCount()):
            category_item = root.child(i)
            # iterate over that category's children
            for j in range(category_item.childCount()):
                child = category_item.child(j)
                if child.checkState(0) == Qt.CheckState.Checked:
                    checked.append(child.text(0))
        return checked


    def update_object_count(self):
        count = self.results_tree.topLevelItemCount()
        self.object_count_label.setText(f"Objects Found: {count}")

    def open_context_menu(self, position):
        
        # Get the item at the mouse position
        item = self.results_tree.itemAt(position)
        if not item:
            return  # If no item is clicked, do nothing
        
        self.on_tree_item_clicked(item)

        # Create the context menu
        menu = QMenu(self)

        # Define actions
        open_website_action = QAction("Open Website", self)
        open_website_action.triggered.connect(lambda: self.results_tree.itemDoubleClicked.emit(item, 0))
        menu.addAction(open_website_action)

        zoom_to_object_action = QAction("Zoom to Object", self)
        zoom_to_object_action.triggered.connect(lambda: self.zoom_to_object(item))
        menu.addAction(zoom_to_object_action)

        copy_info_action = QAction("Copy Object Information", self)
        copy_info_action.triggered.connect(lambda: self.copy_object_information(item))
        menu.addAction(copy_info_action)

        # Display the context menu at the cursor position
        menu.exec(self.results_tree.viewport().mapToGlobal(position))

    def toggle_autostretch(self):
        if not hasattr(self, 'original_image'):
            # Store the original image the first time AutoStretch is applied
            self.original_image = self.image_data.copy()
        
        # Determine if the image is mono or color based on the number of dimensions
        if self.image_data.ndim == 2:
            # Call stretch_mono_image if the image is mono

            stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:
            # Call stretch_color_image if the image is color

            stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=True, normalize=True)
        
        # If the AutoStretch is toggled off (using the same button), restore the original image
        if self.auto_stretch_button.text() == "AutoStretch":
            # Store the stretched image and update the button text to indicate it's on
            self.stretched_image = stretched_image
            self.auto_stretch_button.setText("Turn Off AutoStretch")
        else:
            # Revert to the original image and update the button text to indicate it's off
            stretched_image = self.original_image
            self.auto_stretch_button.setText("AutoStretch")
        

        stretched_image = (stretched_image * 255).astype(np.uint8)


        # Update the display with the stretched image (or original if toggled off)

        height, width = stretched_image.shape[:2]
        bytes_per_line = 3 * width

        # Ensure the image has 3 channels (RGB)
        if stretched_image.ndim == 2:
            stretched_image = np.stack((stretched_image,) * 3, axis=-1)
        elif stretched_image.shape[2] == 1:
            stretched_image = np.repeat(stretched_image, 3, axis=2)



        qimg = QImage(stretched_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        if qimg.isNull():
            print("Failed to create QImage")
            return

        pixmap = QPixmap.fromImage(qimg)
        if pixmap.isNull():
            print("Failed to create QPixmap")
            return

        self.main_image = pixmap
        scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.mini_preview.setPixmap(scaled_pixmap)

        self.main_scene.clear()
        self.main_scene.addPixmap(pixmap)
        self.main_preview.setSceneRect(QRectF(pixmap.rect()))
        self.zoom_level = 1.0
        self.main_preview.resetTransform()
        self.main_preview.centerOn(self.main_scene.sceneRect().center())
        self.update_green_box()

        # Optionally, you can also update any other parts of the UI after stretching the image
        print(f"AutoStretch {'applied to' if self.auto_stretch_button.text() == 'Turn Off AutoStretch' else 'removed from'} the image.")


    def zoom_to_object(self, item):
        """Zoom to the object in the main preview."""
        ra = float(item.text(0))  # Assuming RA is in the first column
        dec = float(item.text(1))  # Assuming Dec is in the second column
        self.main_preview.zoom_to_coordinates(ra, dec)
        

    def copy_object_information(self, item):
        """Copy object information to the clipboard."""
        info = f"RA: {item.text(0)}, Dec: {item.text(1)}, Name: {item.text(2)}, Diameter: {item.text(3)}, Type: {item.text(4)}"
        clipboard = QApplication.clipboard()
        clipboard.setText(info)

    def set_tool(self, tool_name):
        """Sets the current tool and updates button states."""
        self.current_tool = tool_name

        # Reset button styles and highlight the selected button
        for button in self.annotation_buttons:
            if button.tool_name == tool_name:
                button.setStyleSheet("background-color: lightblue;")  # Highlight selected button
            else:
                button.setStyleSheet("")  # Reset other buttons


    def select_color(self):
        """Opens a color dialog to choose annotation color."""
        color = QColorDialog.getColor(self.selected_color, self, "Select Annotation Color")
        if color.isValid():
            self.selected_color = color

    def select_font(self):
        """Opens a font dialog to choose text annotation font."""
        font, ok = QFontDialog.getFont(self.selected_font, self, "Select Annotation Font")
        if ok:
            self.selected_font = font                

    def toggle_annotation_tools(self):
        """Toggle the visibility of the annotation tools section."""
        is_visible = self.annotation_tools_section.isVisible()
        self.annotation_tools_section.setVisible(not is_visible)
        self.show_annotations_button.setText("Hide Annotation Tools" if not is_visible else "Show Annotation Tools")

    def save_plate_solved_fits(self):
        """Save the plate-solved FITS file with WCS header data and the desired bit depth."""
        # Prompt user to select bit depth
        bit_depth, ok = QInputDialog.getItem(
            self, 
            "Select Bit Depth", 
            "Choose the bit depth for the FITS file:",
            ["8-bit", "16-bit", "32-bit"], 
            0, False
        )

        if not ok:
            return  # User cancelled the selection

        # Open file dialog to select where to save the FITS file
        output_image_path, _ = QFileDialog.getSaveFileName(
            self, "Save Plate Solved FITS", "", "FITS Files (*.fits *.fit)"
        )

        if not output_image_path:
            return  # User cancelled save file dialog

        # Verify WCS header data is available
        if not hasattr(self, 'wcs') or self.wcs is None:
            QMessageBox.warning(self, "WCS Data Missing", "WCS header data is not available.")
            return

        # Retrieve image data and WCS header
        image_data = self.image_data  # Raw image data
        wcs_header = self.wcs.to_header(relax=True)  # WCS header, including non-standard keywords
        combined_header = self.original_header.copy() if self.original_header else fits.Header()
        combined_header.update(wcs_header)  # Combine original header with WCS data

        # Convert image data based on selected bit depth
        if self.is_mono:
            # Grayscale (2D) image
            if bit_depth == "8-bit":
                scaled_image = (image_data[:, :, 0] / np.max(image_data) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (image_data[:, :, 0] * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = image_data[:, :, 0].astype(np.float32)
                combined_header['BITPIX'] = -32
        else:
            # RGB (3D) image: Transpose to FITS format (channels, height, width)
            transformed_image = np.transpose(image_data, (2, 0, 1))
            if bit_depth == "8-bit":
                scaled_image = (transformed_image / np.max(transformed_image) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (transformed_image * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = transformed_image.astype(np.float32)
                combined_header['BITPIX'] = -32

            # Update header to reflect 3D structure
            combined_header['NAXIS'] = 3
            combined_header['NAXIS1'] = transformed_image.shape[2]
            combined_header['NAXIS2'] = transformed_image.shape[1]
            combined_header['NAXIS3'] = transformed_image.shape[0]

        # Save the image with combined header (including WCS and original data)
        hdu = fits.PrimaryHDU(scaled_image, header=combined_header)
        try:
            hdu.writeto(output_image_path, overwrite=True)
            QMessageBox.information(self, "File Saved", f"FITS file saved as {output_image_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save FITS file: {str(e)}")



    def save_annotated_image(self):
        """Save the annotated image as a full or cropped view, excluding the search circle."""
        # Create a custom message box
        msg_box = QMessageBox(self)
        msg_box.setWindowTitle("Save Annotated Image")
        msg_box.setText("Do you want to save the Full Image or Cropped Only?")
        
        # Add custom buttons
        full_image_button = msg_box.addButton("Save Full", QMessageBox.ButtonRole.AcceptRole)
        cropped_image_button = msg_box.addButton("Save Cropped", QMessageBox.ButtonRole.DestructiveRole)
        msg_box.addButton(QMessageBox.StandardButton.Cancel)

        # Show the message box and get the user's response
        msg_box.exec()

        # Determine the save type based on the selected button
        if msg_box.clickedButton() == full_image_button:
            save_full_image = True
        elif msg_box.clickedButton() == cropped_image_button:
            save_full_image = False
        else:
            return  # User cancelled

        # Open a file dialog to select the file name and format
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Annotated Image",
            "",
            "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )
        
        if not file_path:
            return  # User cancelled the save dialog

        # Temporarily disable the search circle in the custom graphics view
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.main_preview.circle_center = None  # Hide the circle temporarily
        self.main_preview.circle_radius = 0

        # Redraw annotations without the search circle
        self.main_preview.draw_query_results()

        # Create a QPixmap to render the annotations
        if save_full_image:
            # Save the entire main image with annotations
            pixmap = QPixmap(self.main_image.size())
            pixmap.fill(Qt.GlobalColor.transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter)  # Render the entire scene without the search circle
        else:
            # Save only the currently visible area (cropped view)
            rect = self.main_preview.viewport().rect()
            scene_rect = self.main_preview.mapToScene(rect).boundingRect()
            pixmap = QPixmap(int(scene_rect.width()), int(scene_rect.height()))
            pixmap.fill(Qt.GlobalColor.transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter, QRectF(0, 0, pixmap.width(), pixmap.height()), scene_rect)

        painter.end()  # End QPainter to finalize drawing

        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle

        # Save the QPixmap as an image file in the selected format
        try:
            if pixmap.save(file_path, file_path.split('.')[-1].upper()):
                QMessageBox.information(self, "Save Successful", f"Annotated image saved as {file_path}")
            else:
                raise Exception("Failed to save image due to format or file path issues.")
        except Exception as e:
            QMessageBox.critical(self, "Save Failed", f"An error occurred while saving the image: {str(e)}")


    def save_collage_of_objects(self):
        """Save a collage of 128x128 pixel patches centered around each object, with dynamically spaced text below."""
        # Options for display
        options = ["Name", "RA", "Dec", "Short Type", "Long Type", "Redshift", "Comoving Distance"]

        # Create a custom dialog to select information to display
        dialog = QDialog(self)
        dialog.setWindowTitle("Select Information to Display")
        layout = QVBoxLayout(dialog)
        
        # Add checkboxes for each option
        checkboxes = {}
        for option in options:
            checkbox = QCheckBox(option)
            checkbox.setChecked(True)  # Default to checked
            layout.addWidget(checkbox)
            checkboxes[option] = checkbox

        # Add OK and Cancel buttons
        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        layout.addWidget(button_box)
        button_box.accepted.connect(dialog.accept)
        button_box.rejected.connect(dialog.reject)

        # Show the dialog and get the user's response
        if dialog.exec() == QDialog.DialogCode.Rejected:
            return  # User cancelled

        # Determine which fields to display based on user selection
        selected_fields = [key for key, checkbox in checkboxes.items() if checkbox.isChecked()]

        # Calculate required vertical space for text based on number of selected fields
        text_row_height = 15
        text_block_height = len(selected_fields) * text_row_height
        patch_size = 128
        space_between_patches = max(64, text_block_height + 20)  # Ensure enough space for text between patches

        # Set parameters for collage layout
        number_of_objects = len(self.results)

        if number_of_objects == 0:
            QMessageBox.warning(self, "No Objects", "No objects available to create a collage.")
            return

        # Determine grid size for the collage
        grid_size = math.ceil(math.sqrt(number_of_objects))
        collage_width = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128
        collage_height = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128

        # Create an empty black RGB image for the collage
        collage_image = Image.new("RGB", (collage_width, collage_height), (0, 0, 0))

        # Temporarily disable annotations
        original_show_names = self.show_names
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.show_names = False
        self.main_preview.circle_center = None
        self.main_preview.circle_radius = 0

        try:
            for i, obj in enumerate(self.results):
                # Calculate position in the grid
                row = i // grid_size
                col = i % grid_size
                offset_x = 64 + col * (patch_size + space_between_patches)
                offset_y = 64 + row * (patch_size + space_between_patches)

                # Calculate pixel coordinates around the object
                ra, dec = obj["ra"], obj["dec"]
                x, y = self.calculate_pixel_from_ra_dec(ra, dec)

                # Render the main image without annotations onto a QPixmap
                patch = QPixmap(self.main_image.size())
                patch.fill(Qt.GlobalColor.black)
                painter = QPainter(patch)
                self.main_scene.clear()  # Clear any previous drawings on the scene
                self.main_scene.addPixmap(self.main_image)  # Add only the main image without annotations
                self.main_scene.render(painter)  # Render the scene onto the patch

                # End the painter early to prevent QPaintDevice errors
                painter.end()

                # Crop the relevant area for the object
                rect = QRectF(x - patch_size // 2, y - patch_size // 2, patch_size, patch_size)
                cropped_patch = patch.copy(rect.toRect())
                cropped_image = cropped_patch.toImage().scaled(patch_size, patch_size).convertToFormat(QImage.Format.Format_RGB888)

                # Convert QImage to PIL format for adding to the collage
                bytes_img = cropped_image.bits().asstring(cropped_image.width() * cropped_image.height() * 3)
                pil_patch = Image.frombytes("RGB", (patch_size, patch_size), bytes_img)

                # Paste the patch in the correct location on the collage
                collage_image.paste(pil_patch, (offset_x, offset_y))

                # Draw the selected information below the patch
                draw = ImageDraw.Draw(collage_image)
                font = ImageFont.truetype("arial.ttf", 12)  # Adjust font path as needed
                text_y = offset_y + patch_size + 5

                for field in selected_fields:
                    # Retrieve data and only display if not "N/A"
                    if field == "Name" and obj.get("name") != "N/A":
                        text = obj["name"]
                    elif field == "RA" and obj.get("ra") is not None:
                        text = f"RA: {obj['ra']:.6f}"
                    elif field == "Dec" and obj.get("dec") is not None:
                        text = f"Dec: {obj['dec']:.6f}"
                    elif field == "Short Type" and obj.get("short_type") != "N/A":
                        text = f"Type: {obj['short_type']}"
                    elif field == "Long Type" and obj.get("long_type") != "N/A":
                        text = f"{obj['long_type']}"
                    elif field == "Redshift" and obj.get("redshift") != "N/A":
                        text = f"Redshift: {float(obj['redshift']):.5f}"  # Limit redshift to 5 decimal places
                    elif field == "Comoving Distance" and obj.get("comoving_distance") != "N/A":
                        text = f"Distance: {obj['comoving_distance']} GLy"
                    else:
                        continue  # Skip if field is not available or set to "N/A"

                    # Draw the text and increment the Y position
                    draw.text((offset_x + 10, text_y), text, (255, 255, 255), font=font)
                    text_y += text_row_height  # Space between lines

        finally:
            # Restore the original annotation and search circle settings
            self.show_names = original_show_names
            self.main_preview.circle_center = original_circle_center
            self.main_preview.circle_radius = original_circle_radius

        # Save the collage
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save Collage of Objects", "", "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )

        if file_path:
            collage_image.save(file_path)
            QMessageBox.information(self, "Save Successful", f"Collage saved as {file_path}")


        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle

    def show_3d_model_view(self):
        # ─── 0) Engineering‐notation helper ────────────────────────────
        def eng_notation(x):
            if x == 0:
                return "0"
            exp = int(math.floor(math.log10(abs(x)) / 3) * 3)
            val = x / (10 ** exp)
            prefixes = {
                -12: "p", -9: "n", -6: "µ", -3: "m",
                0: "",  3: "k",  6: "M",  9: "G",
                12: "T", 15: "P"
            }
            return f"{val:.2f}{prefixes.get(exp, f'e{exp}')}"

        # ─── 1) Sanity checks ─────────────────────────────────────────
        if not self.results or self.image_data is None:
            QMessageBox.warning(self, "Data Error", "No image or results available.")
            return
        if self.wcs is None:
            QMessageBox.warning(self, "WCS Missing", "WCS data is required to generate the 3D plot.")
            return

        # ─── 2) Get user settings ────────────────────────────────────
        settings = ThreeDSettingsDialog(self).getSettings()
        if not settings:
            return
        (plane_style, max_res, z_option, z_min, z_max,
        z_scale, linear_max, obj_color, custom_col,
        z_height, show_lines, reverse_z) = (
            settings[k] for k in (
                "plane_style","resolution","z_option","z_min","z_max",
                "z_scale","linear_max","object_color","custom_color",
                "z_height","show_lines","reverse_z"
            )
        )

        # ─── 3) Normalize & downsample image ──────────────────────────
        img = self.image_data
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)
        img_norm = np.clip((img - img.min())/(np.ptp(img)+1e-8), 0, 1)
        full_h, full_w = img.shape[:2]
        scale = min(max_res/full_h, max_res/full_w, 1.0)
        img_ds = np.stack([zoom(img_norm[...,i], scale, order=1)
                        for i in range(3)], axis=-1)
        h_ds, w_ds, _ = img_ds.shape

        # ─── 4) Build plane coordinates ───────────────────────────────
        xs = np.linspace(0, full_w-1, w_ds)
        ys = np.linspace(0, full_h-1, h_ds)
        Xp, Yp = np.meshgrid(xs, ys)
        RA, DEC = self.wcs.pixel_to_world_values(Xp, Yp)
        ra_min, ra_max = float(RA.min()), float(RA.max())
        dec_min, dec_max = float(DEC.min()), float(DEC.max())

        # ─── 5) Gather objects & build labels/URLs ────────────────────
        pix_xs, pix_ys = [], []
        world_xs, world_ys, zs_raw = [], [], []
        labels, names, urls, lines = [], [], [], []
        legend_qcolors = []
        for obj in self.results:
            try:
                name   = obj["name"]
                ra     = float(obj["ra"])
                dec    = float(obj["dec"])

                # --- compute distance in ly, with absolute‐value guard ---
                try:
                    # comoving_distance stored in Gyr:
                    d_gy = float(obj["comoving_distance"])
                    d_ly = abs(d_gy) * 1e9 + 10
                except (ValueError, TypeError):
                    raw_cd = str(obj["comoving_distance"]).strip()
                    if raw_cd.endswith("GLy"):
                        d_ly = abs(float(raw_cd[:-3].strip())) * 1e9 + 10
                    elif raw_cd.endswith("Ly"):
                        d_ly = abs(float(raw_cd[:-2].strip())) + 10
                    else:
                        d_ly = abs(float(raw_cd)) + 10

                # skip any zero/negative after abs
                if d_ly <= 0:
                    continue

                zshift = float(obj.get("redshift", 0.0))

                px, py = self.wcs.world_to_pixel_values(ra, dec)
                if not (0 <= px < full_w and 0 <= py < full_h):
                    continue

                # choose log or linear
                z = math.log10(d_ly) if z_scale == "Logarithmic" else d_ly
                ra0, dec0 = self.wcs.pixel_to_world_values(px, py)

                pix_xs.append(px)
                pix_ys.append(py)
                world_xs.append(ra0)
                world_ys.append(dec0)
                zs_raw.append(z)
                names.append(name)

                labels.append(
                    f"<b>{name}</b><br>"
                    f"RA: {ra:.6f}<br>"
                    f"Dec: {dec:.6f}<br>"
                    f"Distance: {eng_notation(d_ly)} ly<br>"
                    f"Redshift: {zshift:.5f}"
                )

                enc = urllib.parse.quote(name)
                urls.append(
                    f"https://simbad.cds.unistra.fr/simbad/sim-basic?"
                    f"Ident={enc}&submit=SIMBAD+search"
                )
                legend_qcolors.append(obj.get("color", QColor(128,128,128)))

                if show_lines:
                    lines.append(go.Scatter3d(
                        x=[ra0, ra0], y=[dec0, dec0], z=[0, z],
                        mode="lines",
                        line=dict(color="gray", width=1),
                        hoverinfo="skip",
                        showlegend=False
                    ))
            except Exception:
                continue

        if not zs_raw:
            QMessageBox.warning(self, "No Objects", "No valid distance objects to plot.")
            return
        zs = np.array(zs_raw, dtype=float)
        # drop any NaNs before taking min/max
        valid = ~np.isnan(zs)
        if not valid.any():
            QMessageBox.warning(self, "No Objects", "All distance values are invalid.")
            return
        zs = zs[valid]
        print(f"[DEBUG] z_option = {z_option}")
        print(f"[DEBUG] zs_raw (first 10) = {zs_raw[:10]}")
        print(f"[DEBUG] zs array shape = {zs.shape}")
        print(f"[DEBUG] zs.min() = {zs.min()}, zs.max() = {zs.max()}")
        # ─── 6) Determine plane_z & z_range ──────────────────────────
        if z_option == "Min-Max":
            plane_z = float(np.nanmin(zs))
            z_range = (float(np.nanmin(zs)), float(np.nanmax(zs)))
        elif z_option == "Custom":
            plane_z = z_min
            z_range = (z_min, z_max)
        else:  # Default
            plane_z = 0
            z_range = None

        if z_scale == "Linear" and z_option == "Default":
            z_range = (0, linear_max)

        # ─── 7) Build image‐plane layer ──────────────────────────────
        if "Grayscale" in plane_style:
            Zp = np.full_like(RA, plane_z)
            plane = go.Surface(
                x=RA, y=DEC, z=Zp,
                surfacecolor=np.mean(img_ds, axis=2),
                colorscale="gray", showscale=False, opacity=1.0,
                contours={"x": {"show":False}, "y": {"show":False}, "z": {"show":False}}
            )
        else:
            flat = (img_ds*255).astype(int).reshape(-1,3)
            cols = [f"rgb({r},{g},{b})" for r,g,b in flat]
            plane = go.Scatter3d(
                x=RA.flatten(), y=DEC.flatten(), z=[plane_z]*RA.size,
                mode="markers", marker=dict(
                    symbol="square", size=2, line=dict(width=0),
                    color=cols, opacity=1.0
                ),
                hoverinfo="skip", showlegend=False
            )

        # ─── 8) Object colors ────────────────────────────────────────
        H, W = img_norm.shape[:2]
        if obj_color == "Image-Based":
            obj_cols = []
            patch_r = 5
            for px, py in zip(pix_xs, pix_ys):
                cx, cy = int(px), int(py)
                x0, x1 = max(0, cx - patch_r), min(W, cx + patch_r + 1)
                y0, y1 = max(0, cy - patch_r), min(H, cy + patch_r + 1)
                patch = img_norm[y0:y1, x0:x1]
                if patch.size:
                    mr, mg, mb = (patch.reshape(-1,3).mean(axis=0)*255).astype(int)
                else:
                    mr = mg = mb = 0
                obj_cols.append(f"rgb({mr},{mg},{mb})")

        elif obj_color == "Legend Color":
            obj_cols = [f"rgb({qc.red()},{qc.green()},{qc.blue()})" for qc in legend_qcolors]
        elif obj_color == "Solid (Custom)":
            c = custom_col
            obj_cols = [f"rgb({c.red()},{c.green()},{c.blue()})"] * len(zs)
        else:
            obj_cols = ["red"] * len(zs)

        # ─── 9) Scatter objects ───────────────────────────────────────
        scatter = go.Scatter3d(
            x=world_xs, y=world_ys, z=zs,
            mode="markers",
            marker=dict(size=4, color=obj_cols),
            hovertext=labels, hoverinfo="text",
            customdata=urls, name="Objects"
        )

        # ─── 10) Compose figure ───────────────────────────────────────
        fig = go.Figure(data=[plane] + lines + [scatter])
        scene = dict(
            xaxis_title="RA (deg)",
            xaxis=dict(range=[ra_min, ra_max], autorange=False),
            yaxis_title="Dec (deg)",
            yaxis=dict(range=[dec_max, dec_min], autorange=False),
            aspectmode="manual",
            aspectratio=dict(x=1, y=1, z=z_height),
            zaxis=dict(
                title=("log10(Distance in ly)" if z_scale=="Logarithmic" else "Distance (ly)"),
                tickformat="~s",
                **({"range": list(z_range)} if z_range else {}),
                **({"autorange": "reversed"} if reverse_z else {})
            )
        )
        fig.update_layout(title="3D Distance Model", autosize=True, scene=scene,
                        margin=dict(l=0, r=0, b=0, t=40))

        # ─── 11) Build & inject HTML ─────────────────────────────────
        html = fig.to_html(include_plotlyjs="cdn", full_html=True)
        items = "".join(f'<li><a href="{u}" target="_blank">{n}</a></li>'
                        for n,u in zip(names, urls))
        sidebar = ( '<div style="padding:10px;font-family:sans-serif;'
                    'margin-top:20px;border-top:1px solid #ccc;">'
                    '<h3>Objects</h3><ul>' + items + '</ul></div>' )
        js = """
        <script>
        var gd = document.getElementsByClassName('plotly-graph-div')[0];
        gd.on('plotly_click', function(e){
            var url = e.points[0].customdata;
            if(url) window.open(url,'_blank');
        });
        </script>
        """
        html = html.replace("</body>", sidebar + js + "</body>")

        # Save & preview
        default = os.path.expanduser("~/3d_distance_model.html")
        fn,_ = QFileDialog.getSaveFileName(self, "Save 3D Plot As",
                                        default, "HTML Files (*.html)")
        if fn:
            if not fn.lower().endswith(".html"):
                fn += ".html"
            with open(fn, "w", encoding="utf-8") as f:
                f.write(html)

        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".html",
                                        mode="w", encoding="utf-8")
        tmp.write(html); tmp.close()
        webbrowser.open("file://" + tmp.name)


    def show_hr_diagram(self):
        """H-R Diagram: B–V vs Abs V, ticks showing B–V and T_eff together, BB colors."""
        # 1) Sanity
        if not getattr(self, 'query_results', None):
            QMessageBox.information(self, "No Data",
                "Run a SIMBAD query first to gather B, V, and distance data.")
            return

        # 2) Collect data
        B, V, Mv, names = [], [], [], []
        for obj in self.query_results:
            try:
                b = float(obj['Bmag'])
                v = float(obj['Vmag'])
                m = float(obj['absolute_mag'])
            except (TypeError, ValueError, KeyError):
                continue
            B.append(b); V.append(v); Mv.append(m); names.append(obj['name'])
        if not B:
            QMessageBox.warning(self, "Insufficient Data",
                "No objects have valid B-mag, V-mag and absolute magnitude.")
            return

        # 3) Compute B−V & T_eff & colors
        bv = [b - v for b, v in zip(B, V)]
        T_eff = [4600.0 * (1/(0.92*x + 1.7) + 1/(0.92*x + 0.62)) for x in bv]
        colors = [kelvin_to_rgb(T) for T in T_eff]

        # 4) Prepare hover & URLs, now including T_eff
        hover_texts, urls = [], []
        for nm, b, v, m, T in zip(names, B, V, Mv, T_eff):
            hover_texts.append(
                f"<b>{nm}</b><br>"
                f"B: {b:.2f}  V: {v:.2f}<br>"
                f"Abs V: {m:.2f}<br>"
                f"Tₑff: {T:.0f} K"
            )
            enc = urllib.parse.quote(nm)
            urls.append(
                f"https://simbad.cds.unistra.fr/simbad/sim-basic?"
                f"Ident={enc}&submit=SIMBAD+search"
            )

        # 5) Scatter with bigger markers
        scatter = go.Scatter(
            x=bv, y=Mv, mode='markers',
            marker_color=colors, marker_size=20,
            hovertext=hover_texts, customdata=urls,
            name="Stars"
        )
        fig = go.Figure(scatter)

        # 6) Build custom tick labels combining B–V & T_eff
        # choose nice tick positions
        bv_ticks = [-0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5]
        # compute corresponding T
        t_ticks = [4600.0*(1/(0.92*x+1.7)+1/(0.92*x+0.62)) for x in bv_ticks]
        # build two-line labels
        tick_labels = [f"{x:.2f}<br>{int(t):,} K" for x,t in zip(bv_ticks, t_ticks)]

        # 7) Style axes & background
        fig.update_layout(
            title=dict(text="Hertzsprung–Russell Diagram", font_color='white'),
            plot_bgcolor='black',
            paper_bgcolor='black',
            margin=dict(l=40, r=20, t=60, b=60)
        )
        fig.update_xaxes(
            title_text="B−V color (mag) ↔ Tₑff",
            tickvals=bv_ticks,
            ticktext=tick_labels,
            tickfont_color='white',
            title_font=dict(color='white'),
            gridcolor='gray',
            zerolinecolor='gray',
            range=[-0.5, 2.5]
        )
        fig.update_yaxes(
            title_text="Absolute V magnitude (mag)",
            autorange='reversed',
            tickfont_color='white',
            title_font=dict(color='white'),
            gridcolor='gray',
            zerolinecolor='gray'
        )

        # 8) Sidebar & click behaviour
        items = "".join(
            f'<li><a href="{u}" style="color:cyan" target="_blank">{n}</a></li>'
            for n,u in zip(names, urls)
        )
        sidebar = (
            '<div style="padding:10px;font-family:sans-serif;'
            'margin-top:10px;border-top:1px solid #444; background:black; color:white;">'
            '<h3>Objects</h3><ul>' + items + '</ul></div>'
        )
        js = """
        <script>
        var gd = document.getElementsByClassName('plotly-graph-div')[0];
        gd.on('plotly_click', function(e){
            var url = e.points[0].customdata;
            if(url) window.open(url,'_blank');
        });
        </script>
        """

        html = fig.to_html(include_plotlyjs='cdn', full_html=True)
        html = html.replace("</body>", sidebar + js + "</body>")

        # 9) Save & preview
        default = os.path.join(os.path.expanduser("~"), "hr_diagram.html")
        fn, _ = QFileDialog.getSaveFileName(self, "Save H-R Diagram As",
                                            default, "HTML Files (*.html)")
        if fn:
            if not fn.lower().endswith('.html'):
                fn += '.html'
            with open(fn, 'w', encoding='utf-8') as f:
                f.write(html)

        tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.html',
                                        mode='w', encoding='utf-8')
        tmp.write(html); tmp.close()
        webbrowser.open("file://" + tmp.name)
    
    def search_defined_region(self):
        """Perform a Simbad search for the defined region and filter by selected object types."""
        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate the radius in degrees for the defined region (circle radius)
        radius_deg = self.get_defined_radius()

        # Perform the Simbad search in the defined region with the calculated radius
        self.query_simbad(radius_deg)


    def search_entire_image(self):
        """Search the entire image using Simbad with selected object types."""
        selected_types = self.get_selected_object_types()  # Get selected types from the advanced search panel
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate radius as the distance from the image center to a corner
        width, height = self.main_image.width(), self.main_image.height()
        center_x, center_y = width / 2, height / 2
        corner_x, corner_y = width, height  # Bottom-right corner
        # Calculate distance in pixels from center to corner
        radius_px = np.sqrt((corner_x - center_x) ** 2 + (corner_y - center_y) ** 2)
        # Convert radius from pixels to degrees
        radius_deg = float((radius_px * self.pixscale) / 3600.0)

        # Automatically set circle_center and circle_radius for the entire image
        self.circle_center = QPointF(center_x, center_y)  # Assuming QPointF is used
        self.circle_radius = radius_px  # Set this to allow the check in `query_simbad`

        # Perform the query with the calculated radius
        self.query_simbad(radius_deg, max_results=100000)


    def _iterate_leaf_items(self):
        """Yield every otype (child) under every category parent."""
        root = self.object_tree.invisibleRootItem()
        for i in range(root.childCount()):
            parent = root.child(i)
            for j in range(parent.childCount()):
                yield parent.child(j)


    def _update_parent_states(self):
        """Parents become checked if any child is checked, else unchecked."""
        root = self.object_tree.invisibleRootItem()
        for i in range(root.childCount()):
            parent = root.child(i)
            # if any child checked → parent checked, else unchecked
            any_checked = any(
                parent.child(j).checkState(0) == Qt.CheckState.Checked
                for j in range(parent.childCount())
            )
            parent.setCheckState(0, Qt.CheckState.Checked if any_checked else Qt.CheckState.Unchecked)


    def on_object_tree_item_changed(self, item, column):
        # parent toggled → mirror to all children
        if item.childCount() > 0:
            state = item.checkState(0)
            blocker = QSignalBlocker(self.object_tree)
            for i in range(item.childCount()):
                item.child(i).setCheckState(0, state)
            blocker.unblock()
        # child toggled → recompute only its parent
        else:
            parent = item.parent()
            if not parent:
                return
            # parent checked if any child is
            any_checked = any(
                parent.child(i).checkState(0) == Qt.CheckState.Checked
                for i in range(parent.childCount())
            )
            blocker = QSignalBlocker(self.object_tree)
            parent.setCheckState(0, Qt.CheckState.Checked if any_checked else Qt.CheckState.Unchecked)
            blocker.unblock()


    def toggle_all_items(self):
        """Check/uncheck all otype leaf items."""
        leaves      = list(self._iterate_leaf_items())
        all_checked = all(li.checkState(0) == Qt.CheckState.Checked for li in leaves)
        new_state   = Qt.CheckState.Unchecked if all_checked else Qt.CheckState.Checked

        blocker = QSignalBlocker(self.object_tree)
        for li in leaves:
            li.setCheckState(0, new_state)
        blocker.unblock()

        self._update_parent_states()


    def save_custom_list(self):
        """
        Serializes the currently checked otypes to a .json file.
        """
        types = self.get_selected_object_types()
        path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Custom Type List",
            "",
            "JSON Files (*.json)"
        )
        if not path:
            return
        if not path.lower().endswith(".json"):
            path += ".json"
        try:
            with open(path, "w") as f:
                json.dump(types, f, indent=2)
            self.status_label.setText(f"👍 Saved list to {os.path.basename(path)}")
        except Exception as e:
            QMessageBox.critical(self, "Save Failed", str(e))


    def load_custom_list(self):
        """
        Reads a .json of otype codes and re-checks only those.
        """
        path, _ = QFileDialog.getOpenFileName(
            self,
            "Load Custom Type List",
            "",
            "JSON Files (*.json)"
        )
        if not path:
            return

        try:
            with open(path, "r") as f:
                types = set(json.load(f))
        except Exception as e:
            QMessageBox.critical(self, "Load Failed", str(e))
            return

        # block signals so we don't recurse
        blocker = QSignalBlocker(self.object_tree)
        for li in self._iterate_leaf_items():
            li.setCheckState(
                0,
                Qt.CheckState.Checked if li.text(0) in types else Qt.CheckState.Unchecked
            )
        blocker.unblock()

        # now update parents
        self._update_parent_states()
        self.status_label.setText(f"📂 Loaded list from {os.path.basename(path)}")

    def toggle_advanced_search(self):
        """Toggle the visibility of the advanced search panel."""
        is_visible = self.advanced_search_panel_widget.isVisible()
        self.advanced_search_panel_widget.setVisible(not is_visible)

    def save_results_as_csv(self):
        """Save the results from the TreeWidget as a CSV file."""
        path, _ = QFileDialog.getSaveFileName(self, "Save CSV", "", "CSV Files (*.csv)")
        if path:
            with open(path, mode='w', newline='') as file:
                writer = csv.writer(file)
                # Write header
                writer.writerow(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])

                # Write data from TreeWidget
                for i in range(self.results_tree.topLevelItemCount()):
                    item = self.results_tree.topLevelItem(i)
                    row_data = [item.text(column) for column in range(self.results_tree.columnCount())]
                    writer.writerow(row_data)

            QMessageBox.information(self, "CSV Saved", f"Results successfully saved to {path}")        

    def filter_visible_objects(self):
        """Filter objects based on visibility threshold."""
        if not self.main_image:  # Ensure there's an image loaded
            QMessageBox.warning(self, "No Image", "Please load an image first.")
            return

        n = 0.2  # Threshold multiplier, adjust as needed
        median, std_dev = self.calculate_image_statistics(self.main_image)

        # Remove objects below threshold from results
        filtered_results = []
        for obj in self.results:
            if self.is_marker_visible(obj, median, std_dev, n):
                filtered_results.append(obj)

        # Update the results and redraw the markers
        self.results = filtered_results
        self.update_results_tree()
        self.main_preview.draw_query_results()

    def calculate_image_statistics(self, image):
        """Calculate median and standard deviation for a grayscale image efficiently using OpenCV."""
        
        # Convert QPixmap to QImage if necessary
        qimage = image.toImage()

        # Convert QImage to a format compatible with OpenCV
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 4)  # 4 channels (RGBA)
        img_array = np.array(ptr).reshape(height, width, 4)  # Convert to RGBA array

        # Convert to grayscale for analysis
        gray_image = cv2.cvtColor(img_array, cv2.COLOR_RGBA2GRAY)

        # Calculate median and standard deviation
        median = np.median(gray_image)
        _, std_dev = cv2.meanStdDev(gray_image)

        return median, std_dev[0][0]  # std_dev returns a 2D array, so we extract the single value
    
    def is_marker_visible(self, marker, median, std_dev, n):
        """Check if the marker's brightness is above the threshold."""
        threshold = median + n * std_dev
        check_size = 8  # Define a 4x4 region around the marker

        # Convert QPixmap to QImage to access pixel colors
        image = self.main_image.toImage()

        # Get marker coordinates in pixel space
        ra, dec = marker.get('ra'), marker.get('dec')
        if ra is not None and dec is not None:
            x, y = self.calculate_pixel_from_ra_dec(ra, dec)
            if x is None or y is None:
                return False  # Skip marker if it can't be converted to pixels
        else:
            return False

        # Calculate brightness in a 4x4 region around marker coordinates
        brightness_values = []
        for dx in range(-check_size // 2, check_size // 2):
            for dy in range(-check_size // 2, check_size // 2):
                px = x + dx
                py = y + dy
                if 0 <= px < image.width() and 0 <= py < image.height():
                    color = image.pixelColor(px, py)  # Get color from QImage
                    brightness = color.value() if color.isValid() else 0  # Adjust for grayscale
                    brightness_values.append(brightness)

        if brightness_values:
            average_brightness = sum(brightness_values) / len(brightness_values)
            return average_brightness > threshold
        else:
            return False



    def update_results_tree(self):
        """Refresh the TreeWidget to reflect current results."""
        self.results_tree.clear()
        for obj in self.results:
            item = QTreeWidgetItem([
                str(obj['ra']),
                str(obj['dec']),
                obj['name'],
                str(obj['diameter']),
                obj['short_type'],
                obj['long_type'],
                str(obj['redshift']),
                str(obj['comoving_distance'])
            ])
            self.results_tree.addTopLevelItem(item)

    def toggle_object_names(self, state):
        """Toggle the visibility of object names based on the checkbox state."""
        self.show_names = state == Qt.CheckState.Checked
        self.show_names = bool(state)        
        self.main_preview.draw_query_results()  # Redraw to apply the change


    # Function to clear search results and remove markers
    def clear_search_results(self):
        """Clear the search results and remove all markers."""
        self.results_tree.clear()        # Clear the results from the tree
        self.results = []                # Clear the results list
        self.main_preview.results = []   # Clear results from the main preview
        self.main_preview.selected_object = None
        self.main_preview.draw_query_results()  # Redraw the main image without markers
        self.status_label.setText("Results cleared.")

    def on_tree_item_clicked(self, item):
        """Handle item click in the TreeWidget to highlight the associated object."""
        object_name = item.text(2)

        # Find the object in results
        selected_object = next(
            (obj for obj in self.results if obj.get("name") == object_name), None
        )

        if selected_object:
            # Set the selected object in MainWindow and update views
            self.selected_object = selected_object
            self.main_preview.select_object(selected_object)
            self.main_preview.draw_query_results()
            self.main_preview.update_mini_preview() 
            
            

    def on_tree_item_double_clicked(self, item):
        """Handle double-click event on a TreeWidget item to open SIMBAD or NED URL based on source."""
        object_name = item.text(2)  # Assuming 'Name' is in the third column
        ra = float(item.text(0).strip())  # Assuming RA is in the first column
        dec = float(item.text(1).strip())  # Assuming Dec is in the second column
        
        # Retrieve the entry directly from self.query_results
        entry = next((result for result in self.query_results if float(result['ra']) == ra and float(result['dec']) == dec), None)
        source = entry.get('source', 'Simbad') if entry else 'Simbad'  # Default to "Simbad" if entry not found

        if source == "Simbad" and object_name:
            # Open Simbad URL with encoded object name
            encoded_name = quote(object_name)
            simbad_url = f"https://simbad.cds.unistra.fr/simbad/sim-basic?Ident={encoded_name}&submit=SIMBAD+search"
            webbrowser.open(simbad_url)
        elif source == "Vizier":
            # Format the NED search URL with proper RA, Dec, and radius
            radius = 5 / 60  # Radius in arcminutes (5 arcseconds)
            dec_sign = "%2B" if dec >= 0 else "-"  # Determine sign for declination
            ned_url = f"http://ned.ipac.caltech.edu/conesearch?search_type=Near%20Position%20Search&ra={ra:.6f}d&dec={dec_sign}{abs(dec):.6f}d&radius={radius:.3f}&in_csys=Equatorial&in_equinox=J2000.0"
            webbrowser.open(ned_url)
        elif source == "Mast":
            # Open MAST URL using RA and Dec with a small radius for object lookup
            mast_url = f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
            webbrowser.open(mast_url)            

    def copy_ra_dec_to_clipboard(self):
        """Copy the currently displayed RA and Dec to the clipboard."""
        # Access the RA and Dec labels directly
        ra_text = self.ra_label.text()
        dec_text = self.dec_label.text()
        
        # Combine RA and Dec text for clipboard
        clipboard_text = f"{ra_text}, {dec_text}"
        
        clipboard = QApplication.instance().clipboard()
        clipboard.setText(clipboard_text)
        
        QMessageBox.information(self, "Copied", "Current RA/Dec copied to clipboard!")
    

    def open_image(self):
        self.image_path, _ = QFileDialog.getOpenFileName(self, "Open Image", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fit *.fits *.xisf)")
        if self.image_path:
            img_array, original_header, bit_depth, is_mono = load_image(self.image_path)
            if img_array is not None:

                self.image_data = img_array
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono

                # Prepare image for display
                if img_array.ndim == 2:  # Single-channel image
                    img_array = np.stack([img_array] * 3, axis=-1)  # Expand to 3 channels


                # Prepare image for display
                img = (img_array * 255).astype(np.uint8)
                height, width, _ = img.shape
                bytes_per_line = 3 * width
                qimg = QImage(img.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
                pixmap = QPixmap.fromImage(qimg)

                self.main_image = pixmap
                scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
                self.mini_preview.setPixmap(scaled_pixmap)

                self.main_scene.clear()
                self.main_scene.addPixmap(pixmap)
                self.main_preview.setSceneRect(QRectF(pixmap.rect()))
                self.zoom_level = 1.0
                self.main_preview.resetTransform()
                self.main_preview.centerOn(self.main_scene.sceneRect().center())
                self.update_green_box()

                # Initialize WCS from FITS header if it is a FITS file
                if self.image_path.lower().endswith(('.fits', '.fit')):
                    with fits.open(self.image_path) as hdul:
                        self.header = hdul[0].header
                        
                        try:
                            # Use only the first two dimensions for WCS
                            self.wcs = WCS(self.header, naxis=2, relax=True)
                            
                            # Calculate and set pixel scale
                            pixel_scale_matrix = self.wcs.pixel_scale_matrix
                            self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
                            self.center_ra, self.center_dec = self.wcs.wcs.crval
                            self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
                            self.print_corner_coordinates()
                            
                            print(f"Header CROTA2 Value: {self.header.get('CROTA2', 'Not Found')}")

                            # Display WCS information
                            # Set orientation based on WCS data if available
                            if 'CROTA2' in self.header:
                                try:
                                    self.orientation = float(self.header['CROTA2'])  # Convert to float
                                except (ValueError, TypeError):
                                    self.orientation = None
                                    print("CROTA2 found, but could not convert to float.")
                            else:
                                # Use calculate_orientation if CROTA2 is not present
                                self.orientation = calculate_orientation(self.header)
                                if self.orientation is None:
                                    print("Orientation: CD matrix elements not found in WCS header.")

                            # --- ✅ Ensure `self.orientation` is a float before using it ---
                            if self.orientation is not None:
                                try:
                                    self.orientation = float(self.orientation)  # Final conversion check
                                    print(f"Orientation: {self.orientation:.2f}°")
                                    self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                                except (ValueError, TypeError):
                                    print(f"Failed to format orientation: {self.orientation}")
                                    self.orientation_label.setText("Orientation: N/A")
                            else:
                                self.orientation_label.setText("Orientation: N/A")


                            print(f"WCS data loaded from FITS header: RA={self.center_ra}, Dec={self.center_dec}, "
                                f"Pixel Scale={self.pixscale} arcsec/px")
                            
                            
                        except ValueError as e:
                            print("Error initializing WCS:", e)
                            QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from FITS header.")
                elif self.image_path.lower().endswith('.xisf'):
                    # Load WCS from XISF properties
                    xisf_meta = self.extract_xisf_metadata(self.image_path)
                    self.metadata = xisf_meta  # Ensure metadata is stored in self.metadata for later use

                    # Construct WCS header from XISF properties
                    header = self.construct_fits_header_from_xisf(xisf_meta)
                    if header:
                        try:
                            self.initialize_wcs_from_header(header)
                        except ValueError as e:
                            print("Error initializing WCS from XISF:", e)
                            QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from XISF properties.")
                else:
                    # For non-FITS images (e.g., JPEG, PNG), prompt directly for a blind solve
                    self.prompt_blind_solve()

    def extract_xisf_metadata(self, xisf_path):
        """
        Extract metadata from a .xisf file, focusing on WCS and essential image properties.
        """
        try:
            # Load the XISF file
            xisf = XISF(xisf_path)
            
            # Extract file and image metadata
            self.file_meta = xisf.get_file_metadata()
            self.image_meta = xisf.get_images_metadata()[0]  # Get metadata for the first image
            return self.image_meta
        except Exception as e:
            print(f"Error reading XISF metadata: {e}")
            return None

    def initialize_wcs_from_header(self, header):
        """ Initialize WCS data from a FITS header or constructed XISF header """
        try:
            # Use only the first two dimensions for WCS
            self.wcs = WCS(header, naxis=2, relax=True)
            
            # Calculate and set pixel scale
            pixel_scale_matrix = self.wcs.pixel_scale_matrix
            self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
            self.center_ra, self.center_dec = self.wcs.wcs.crval
            self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
            self.print_corner_coordinates()

            # --- 🔍 Debugging Output ---
            print(f"Header CROTA2 Value: {header.get('CROTA2', 'Not Found')}")

            # Display WCS information
            if 'CROTA2' in header:
                try:
                    self.orientation = float(header['CROTA2'])  # Convert to float
                except (ValueError, TypeError):
                    self.orientation = None
                    print("CROTA2 found, but could not convert to float.")
            else:
                self.orientation = calculate_orientation(header)
                if self.orientation is None:
                    print("Orientation: CD matrix elements not found in WCS header.")

            # --- ✅ Ensure `self.orientation` is a float before using it ---
            if self.orientation is not None:
                try:
                    self.orientation = float(self.orientation)  # Final conversion check
                    print(f"Orientation: {self.orientation:.2f}°")
                    self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                except (ValueError, TypeError):
                    print("Final conversion failed. Orientation is not a float.")
                    self.orientation_label.setText("Orientation: N/A")
            else:
                print("Orientation is None.")
                self.orientation_label.setText("Orientation: N/A")

            print(f"WCS data loaded: RA={self.center_ra}, Dec={self.center_dec}, Pixel Scale={self.pixscale} arcsec/px")

        except ValueError as e:
            raise ValueError(f"WCS initialization error: {e}")

    def construct_fits_header_from_xisf(self, xisf_meta):
        """ Convert XISF metadata to a FITS header compatible with WCS """
        header = fits.Header()

        # Define WCS keywords to populate
        wcs_keywords = ["CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", 
                        "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]

        # Populate WCS and FITS keywords
        if 'FITSKeywords' in xisf_meta:
            for keyword, values in xisf_meta['FITSKeywords'].items():
                for entry in values:
                    if 'value' in entry:
                        value = entry['value']
                        if keyword in wcs_keywords:
                            try:
                                value = int(value)
                            except ValueError:
                                value = float(value)
                        header[keyword] = value

        # Manually add WCS information if missing
        header.setdefault('CTYPE1', 'RA---TAN')
        header.setdefault('CTYPE2', 'DEC--TAN')

        # Add SIP distortion suffix if SIP coefficients are present
        if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
            header['CTYPE1'] = 'RA---TAN-SIP'
            header['CTYPE2'] = 'DEC--TAN-SIP'

        # Set default reference pixel to the center of the image
        header.setdefault('CRPIX1', self.image_data.shape[1] / 2)
        header.setdefault('CRPIX2', self.image_data.shape[0] / 2)

        # Retrieve RA and DEC values if available
        if 'RA' in xisf_meta['FITSKeywords']:
            header['CRVAL1'] = float(xisf_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
        if 'DEC' in xisf_meta['FITSKeywords']:
            header['CRVAL2'] = float(xisf_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

        # Calculate pixel scale if focal length and pixel size are available
        if 'FOCALLEN' in xisf_meta['FITSKeywords'] and 'XPIXSZ' in xisf_meta['FITSKeywords']:
            focal_length = float(xisf_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
            pixel_size = float(xisf_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
            pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
            header['CDELT1'] = -pixel_scale / 3600.0
            header['CDELT2'] = pixel_scale / 3600.0
        else:
            header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
            header['CDELT2'] = 2.77778e-4

        # Populate CD matrix using the XISF LinearTransformationMatrix if available
        if 'XISFProperties' in xisf_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_meta['XISFProperties']:
            linear_transform = xisf_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
            header['CD1_1'] = linear_transform[0][0]
            header['CD1_2'] = linear_transform[0][1]
            header['CD2_1'] = linear_transform[1][0]
            header['CD2_2'] = linear_transform[1][1]
        else:
            # Use pixel scale for CD matrix if no linear transformation is defined
            header['CD1_1'] = header['CDELT1']
            header['CD1_2'] = 0.0
            header['CD2_1'] = 0.0
            header['CD2_2'] = header['CDELT2']

        # Ensure numeric types for SIP distortion keywords if present
        sip_keywords = ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
        for sip_key in sip_keywords:
            if sip_key in xisf_meta['XISFProperties']:
                try:
                    value = xisf_meta['XISFProperties'][sip_key]['value']
                    header[sip_key] = int(value) if isinstance(value, str) and value.isdigit() else float(value)
                except ValueError:
                    pass  # Ignore any invalid conversion

        return header

    def print_corner_coordinates(self):
        """Print the RA/Dec coordinates of the four corners of the image for debugging purposes."""
        if not hasattr(self, 'wcs'):
            print("WCS data is incomplete, cannot calculate corner coordinates.")
            return

        width = self.main_image.width()
        height = self.main_image.height()

        # Define the corner coordinates
        corners = {
            "Top-Left": (0, 0),
            "Top-Right": (width, 0),
            "Bottom-Left": (0, height),
            "Bottom-Right": (width, height)
        }

        print("Corner RA/Dec coordinates:")
        for corner_name, (x, y) in corners.items():
            ra, dec = self.calculate_ra_dec_from_pixel(x, y)
            ra_hms = self.convert_ra_to_hms(ra)
            dec_dms = self.convert_dec_to_dms(dec)
            print(f"{corner_name}: RA={ra_hms}, Dec={dec_dms}")

    def calculate_ra_dec_from_pixel(self, x, y):
        """Convert pixel coordinates (x, y) to RA/Dec using Astropy WCS."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert pixel coordinates to sky coordinates
        ra, dec = self.wcs.all_pix2world(x, y, 0)

        return ra, dec
                        


    def update_ra_dec_from_mouse(self, event):
        """Update RA and Dec based on mouse position over the main preview."""
        if self.main_image and self.wcs:
            pos = self.main_preview.mapToScene(event.pos())
            x, y = int(pos.x()), int(pos.y())

            if 0 <= x < self.main_image.width() and 0 <= y < self.main_image.height():
                ra, dec = self.calculate_ra_dec_from_pixel(x, y)
                ra_hms = self.convert_ra_to_hms(ra)
                dec_dms = self.convert_dec_to_dms(dec)

                # Update RA/Dec labels
                self.ra_label.setText(f"RA: {ra_hms}")
                self.dec_label.setText(f"Dec: {dec_dms}")

                # --- 🔍 Debugging Output ---
                #print(f"Current Orientation Type: {type(self.orientation)}, Value: {self.orientation}")

                # ✅ Ensure `self.orientation` is a float before formatting
                if self.orientation is not None:
                    try:
                        self.orientation = float(self.orientation)  # Final safeguard conversion
                        self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                    except (ValueError, TypeError):
                        print(f"Failed to format orientation: {self.orientation}")
                        self.orientation_label.setText("Orientation: N/A")
                else:
                    self.orientation_label.setText("Orientation: N/A")
        else:
            self.ra_label.setText("RA: N/A")
            self.dec_label.setText("Dec: N/A")
            self.orientation_label.setText("Orientation: N/A")



    def convert_ra_to_hms(self, ra_deg):
        """Convert Right Ascension in degrees to Hours:Minutes:Seconds format."""
        ra_hours = ra_deg / 15.0  # Convert degrees to hours
        hours = int(ra_hours)
        minutes = int((ra_hours - hours) * 60)
        seconds = (ra_hours - hours - minutes / 60.0) * 3600
        return f"{hours:02d}h{minutes:02d}m{seconds:05.2f}s"

    def convert_dec_to_dms(self, dec_deg):
        """Convert Declination in degrees to Degrees:Minutes:Seconds format."""
        sign = "-" if dec_deg < 0 else "+"
        dec_deg = abs(dec_deg)
        degrees = int(dec_deg)
        minutes = int((dec_deg - degrees) * 60)
        seconds = (dec_deg - degrees - minutes / 60.0) * 3600
        degree_symbol = "\u00B0"
        return f"{sign}{degrees:02d}{degree_symbol}{minutes:02d}m{seconds:05.2f}s"                 

    def check_astrometry_data(self, header):
        return "CTYPE1" in header and "CTYPE2" in header

    def prompt_blind_solve(self):
        reply = QMessageBox.question(
            self, "Astrometry Data Missing",
            "No astrometry data found in the image. Would you like to perform a blind solve?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.perform_blind_solve()

    def perform_blind_solve(self):
        """
        First attempts to plate-solve the loaded image using ASTAP.
        If that fails, falls back to performing a blind solve via Astrometry.net.
        Updates the WCS (self.wcs) and header (self.header) accordingly.
        """
        # --- First, try ASTAP plate solve ---
        self.status_label.setText("Status: Attempting ASTAP plate solve...")
        QApplication.processEvents()
        solved_header = self.plate_solve_image()  # This method should try to solve via ASTAP and return a header (or None).
        if solved_header is not None:
            self.status_label.setText("ASTAP plate solve succeeded.")
            # instead of manually doing header.update + WCS(...)
            self.apply_wcs_header(solved_header)
            QMessageBox.information(self, "Plate Solve", 
                                    "ASTAP plate solve succeeded. WCS, orientation, and pixscale updated.")
            return

        # --- If ASTAP plate solve failed, fall back to blind solve via Astrometry.net ---
        self.status_label.setText("Status: ASTAP failed. Proceeding with blind solve via Astrometry.net...")
        QApplication.processEvents()

        # Load or prompt for API key
        api_key = load_api_key()
        if not api_key:
            api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
            if ok and api_key:
                save_api_key(api_key)
            else:
                QMessageBox.warning(self, "API Key Required", "Blind solve cannot proceed without an API key.")
                return

        try:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()

            # Step 1: Login to Astrometry.net
            session_key = self.login_to_astrometry(api_key)

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()
            
            # Step 2: Upload the image and get submission ID
            subid = self.upload_image_to_astrometry(self.image_path, session_key)

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            
            # Step 3: Poll for the job ID until it's available
            job_id = self.poll_submission_status(subid)
            if not job_id:
                raise TimeoutError("Failed to retrieve job ID from Astrometry.net after multiple attempts.")
            
            self.status_label.setText("Status: Job ID found, processing image...")
            QApplication.processEvents()

            # Step 4a: Poll for the calibration data, ensuring RA/Dec are available
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                raise TimeoutError("Calibration data did not complete in the expected timeframe.")
            
            # Set pixscale and other necessary attributes from calibration data
            self.pixscale = calibration_data.get('pixscale')

            self.status_label.setText("Status: Calibration complete, downloading WCS file...")
            QApplication.processEvents()

            # Step 4b: Download the WCS FITS file for complete calibration data
            wcs_header = self.retrieve_and_apply_wcs(job_id)
            if not wcs_header:
                raise TimeoutError("Failed to retrieve WCS FITS file from Astrometry.net.")

            self.status_label.setText("Status: Applying astrometric solution to the image...")
            QApplication.processEvents()

            # Apply calibration data to the WCS
            self.apply_wcs_header(wcs_header)
            self.status_label.setText("Status: Blind Solve Complete.")
            QMessageBox.information(self, "Blind Solve Complete", "Astrometric solution applied successfully.")
        except Exception as e:
            self.status_label.setText("Status: Blind Solve Failed.")
            QMessageBox.critical(self, "Blind Solve Failed", f"An error occurred: {str(e)}")

    def plate_solve_image(self):
        """
        Attempts to plate-solve the loaded image using ASTAP.
        If no ASTAP executable is set (or the user cancels its selection),
        it falls back to blind solving via Astrometry.net.
        On success, the method updates self.header and initializes self.wcs.
        """
        if not hasattr(self, 'image_path') or not self.image_path:
            QMessageBox.warning(self, "Plate Solve", "No image loaded.")
            return

        # Check if the ASTAP executable is set in settings.
        astap_exe = self.settings.value("astap/exe_path", "", type=str)
        if not astap_exe or not os.path.exists(astap_exe):
            import sys
            if sys.platform.startswith("win"):
                executable_filter = "Executables (*.exe);;All Files (*)"
            else:
                executable_filter = "Executables (astap);;All Files (*)"
            new_path, _ = QFileDialog.getOpenFileName(
                self, "Select ASTAP Executable", "", executable_filter
            )
            if new_path:
                astap_exe = new_path
                self.settings.setValue("astap/exe_path", astap_exe)
                QMessageBox.information(self, "Plate Solve", "ASTAP path updated successfully.")
            else:
                QMessageBox.information(self, "Plate Solve", "No ASTAP executable provided. Falling back to blind solve.")
                return None

        # Normalize the loaded image.
        normalized = self.stretch_image(self.image_data)
        
        # Save the normalized image to a temporary FITS file.
        try:
            tmp_path = self.save_temp_fits_image(normalized, self.image_path)
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error saving temporary FITS: {e}")
            return

        # Run ASTAP on the temporary file.
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs"]
        print("Running ASTAP with arguments:", args)
        process.start(astap_exe, args)
        if not process.waitForStarted(5000):
            QMessageBox.critical(self, "Plate Solve", "Failed to start ASTAP process.")
            os.remove(tmp_path)
            self.blind_solve_image()
            return
        if not process.waitForFinished(300000):
            QMessageBox.critical(self, "Plate Solve", "ASTAP process timed out.")
            os.remove(tmp_path)
            self.blind_solve_image()
            return

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)
        
        if exit_code != 0:
            os.remove(tmp_path)
            QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Falling back to blind solve.")
            self.blind_solve_image()
            return

        # --- Retrieve the initial solved header from the temporary FITS file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error reading solved header: {e}")
            os.remove(tmp_path)
            self.blind_solve_image()
            return

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                import re
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Matches a FITS header keyword and its value (with an optional comment).
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        # --- Add any missing required WCS keywords ---
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2 are ideally provided by ASTAP.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Convert keys that are expected to be numeric from strings to numbers ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # For keys that should be integers, you can use int(float(...)) if necessary.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Ensure integer keywords are stored as integers ---
        for key in ["WCSAXES", "NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to int.")


        os.remove(tmp_path)
        print("ASTAP plate solving successful. Final solved header:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        # Update the main image header and reinitialize WCS.
        self.header.update(solved_header)
        try:
            self.wcs = WCS(self.header, naxis=2, relax=True)
            QMessageBox.information(self, "Plate Solve", "ASTAP plate solve succeeded. WCS updated.")
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error initializing WCS from solved header: {e}")
            return

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """
        from astropy.io.fits import Header

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def retrieve_and_apply_wcs(self, job_id):
        """Download the wcs.fits file from Astrometry.net, extract WCS header data, and apply it."""
        try:
            wcs_url = f"https://nova.astrometry.net/wcs_file/{job_id}"
            wcs_filepath = "wcs.fits"
            max_retries = 10
            delay = 10  # seconds
            
            for attempt in range(max_retries):
                # Attempt to download the file
                response = requests.get(wcs_url, stream=True)
                response.raise_for_status()

                # Save the WCS file locally
                with open(wcs_filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                # Check if the downloaded file is a valid FITS file
                try:
                    with fits.open(wcs_filepath, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
                        # If it opens correctly, return the header
                        wcs_header = hdul[0].header
                        print("WCS header successfully retrieved.")
                        self.wcs = WCS(wcs_header)
                        return wcs_header
                except Exception as e:
                    print(f"Attempt {attempt + 1}: Failed to process WCS file - possibly HTML instead of FITS. Retrying in {delay} seconds...")
                    print(f"Error: {e}")
                    time.sleep(delay)  # Wait and retry
            
            print("Failed to download a valid WCS FITS file after multiple attempts.")
            return None

        except requests.exceptions.RequestException as e:
            print(f"Error downloading WCS file: {e}")
        except Exception as e:
            print(f"Error processing WCS file: {e}")
            
        return None



    def apply_wcs_header(self, wcs_header):
        """
        Apply a solved WCS header.  Sets self.wcs, self.pixscale (arcsec/pix),
        self.orientation, and updates the orientation label.
        """
        # 1) Initialize the WCS object
        self.wcs = WCS(wcs_header, naxis=2, relax=True)

        # 2) Derive pixel scale (arcsec/pixel)
        if 'CDELT1' in wcs_header:
            # CDELT1 is degrees/pixel
            self.pixscale = abs(float(wcs_header['CDELT1'])) * 3600.0
        elif 'CD1_1' in wcs_header and 'CD2_2' in wcs_header:
            # approximate from CD matrix determinant
            det = (wcs_header['CD1_1'] * wcs_header['CD2_2']
                - wcs_header['CD1_2'] * wcs_header['CD2_1'])
            pixscale_deg = math.sqrt(abs(det))
            self.pixscale = pixscale_deg * 3600.0
        else:
            self.pixscale = None
            print("Warning: could not derive pixscale from header.")

        # 3) Extract orientation (CROTA2 if present)
        if 'CROTA2' in wcs_header:
            self.orientation = float(wcs_header['CROTA2'])
        else:
            # fallback to your custom function
            self.orientation = calculate_orientation(wcs_header)

        # 4) Update the GUI label
        if self.orientation is not None:
            self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
        else:
            self.orientation_label.setText("Orientation: N/A")

        print(f" -> pixscale = {self.pixscale} arcsec/pixel")
        print(f" -> orientation = {self.orientation}°")


    def calculate_pixel_from_ra_dec(self, ra, dec):
        """Convert RA/Dec to pixel coordinates using the WCS data."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert RA and Dec to pixel coordinates using the WCS object
        sky_coord = SkyCoord(ra, dec, unit=(u.deg, u.deg), frame='icrs')
        x, y = self.wcs.world_to_pixel(sky_coord)
        
        return int(x), int(y)

    def login_to_astrometry(self, api_key):
        try:
            response = requests.post(
                ASTROMETRY_API_URL + "login",
                data={'request-json': json.dumps({"apikey": api_key})}
            )
            response_data = response.json()
            if response_data.get("status") == "success":
                return response_data["session"]
            else:
                raise ValueError("Login failed: " + response_data.get("error", "Unknown error"))
        except Exception as e:
            raise Exception("Login to Astrometry.net failed: " + str(e))


    def upload_image_to_astrometry(self, image_path, session_key):
        try:
            # Check if the file is XISF format
            file_extension = os.path.splitext(image_path)[-1].lower()
            if file_extension == ".xisf":
                # Load the XISF image
                xisf = XISF(image_path)
                im_data = xisf.read_image(0)
                
                # Convert to a temporary TIFF file for upload
                temp_image_path = os.path.splitext(image_path)[0] + "_converted.tif"
                if im_data.dtype == np.float32 or im_data.dtype == np.float64:
                    im_data = np.clip(im_data, 0, 1) * 65535
                im_data = im_data.astype(np.uint16)

                # Save as TIFF
                if im_data.shape[-1] == 1:  # Grayscale
                    tiff.imwrite(temp_image_path, np.squeeze(im_data, axis=-1))
                else:  # RGB
                    tiff.imwrite(temp_image_path, im_data)

                print(f"Converted XISF file to TIFF at {temp_image_path} for upload.")
                image_path = temp_image_path  # Use the converted file for upload

            # Upload the image file
            with open(image_path, 'rb') as image_file:
                files = {'file': image_file}
                data = {
                    'request-json': json.dumps({
                        "publicly_visible": "y",
                        "allow_modifications": "d",
                        "session": session_key,
                        "allow_commercial_use": "d"
                    })
                }
                response = requests.post(ASTROMETRY_API_URL + "upload", files=files, data=data)
                response_data = response.json()
                if response_data.get("status") == "success":
                    return response_data["subid"]
                else:
                    raise ValueError("Image upload failed: " + response_data.get("error", "Unknown error"))

        except Exception as e:
            raise Exception("Image upload to Astrometry.net failed: " + str(e))

        finally:
            # Clean up temporary file if created
            if file_extension == ".xisf" and os.path.exists(temp_image_path):
                os.remove(temp_image_path)
                print(f"Temporary TIFF file {temp_image_path} deleted after upload.")



    def poll_submission_status(self, subid):
        """Poll Astrometry.net to retrieve the job ID once the submission is processed."""
        max_retries = 90  # Adjust as necessary
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"submissions/{subid}")
                response_data = response.json()
                jobs = response_data.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
                else:
                    print(f"Polling attempt {retries + 1}: Job not ready yet.")
            except Exception as e:
                print(f"Error while polling submission status: {e}")
            
            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries
        
        return None

    def poll_calibration_data(self, job_id):
        """Poll Astrometry.net to retrieve the calibration data once it's available."""
        max_retries = 90  # Retry for up to 15 minutes (90 * 10 seconds)
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/")
                response_data = response.json()
                if response_data and 'ra' in response_data and 'dec' in response_data:
                    print("Calibration data retrieved:", response_data)
                    return response_data  # Calibration data is complete
                else:
                    print(f"Calibration data not available yet (Attempt {retries + 1})")
            except Exception as e:
                print(f"Error retrieving calibration data: {e}")

            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries

        return None


    #If originally a fits file update the header
    def update_fits_with_wcs(self, filepath, calibration_data):
        if not filepath.lower().endswith(('.fits', '.fit')):
            print("File is not a FITS file. Skipping WCS header update.")
            return

        print("Updating image with calibration data:", calibration_data)
        with fits.open(filepath, mode='update') as hdul:
            header = hdul[0].header
            header['CTYPE1'] = 'RA---TAN'
            header['CTYPE2'] = 'DEC--TAN'
            header['CRVAL1'] = calibration_data['ra']
            header['CRVAL2'] = calibration_data['dec']
            header['CRPIX1'] = hdul[0].data.shape[1] / 2
            header['CRPIX2'] = hdul[0].data.shape[0] / 2
            scale = calibration_data['pixscale'] / 3600
            orientation = np.radians(calibration_data['orientation'])
            header['CD1_1'] = -scale * np.cos(orientation)
            header['CD1_2'] = scale * np.sin(orientation)
            header['CD2_1'] = -scale * np.sin(orientation)
            header['CD2_2'] = -scale * np.cos(orientation)
            header['RADECSYS'] = 'ICRS'

    def on_mini_preview_press(self, event):
        # Set dragging flag and scroll the main preview to the position in the mini preview.
        self.dragging = True
        self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_drag(self, event):
        # Scroll to the new position while dragging in the mini preview.
        if self.dragging:
            self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_release(self, event):
        # Stop dragging
        self.dragging = False

    def scroll_main_preview_to_mini_position(self, event):
        """Scrolls the main preview to the corresponding position based on the mini preview click."""
        if self.main_image:
            # Get the click position in the mini preview
            click_x = event.pos().x()
            click_y = event.pos().y()
            
            # Calculate scale factors based on the difference in dimensions between main image and mini preview
            scale_factor_x = self.main_scene.sceneRect().width() / self.mini_preview.width()
            scale_factor_y = self.main_scene.sceneRect().height() / self.mini_preview.height()
            
            # Scale the click position to the main preview coordinates
            scaled_x = click_x * scale_factor_x
            scaled_y = click_y * scale_factor_y
            
            # Center the main preview on the calculated position
            self.main_preview.centerOn(scaled_x, scaled_y)
            
            # Update the green box after scrolling
            self.main_preview.update_mini_preview()

    def update_green_box(self):
        if self.main_image:
            factor_x = self.mini_preview.width() / self.main_image.width()
            factor_y = self.mini_preview.height() / self.main_image.height()
            
            # Get the current view rectangle in the main preview (in scene coordinates)
            view_rect = self.main_preview.mapToScene(self.main_preview.viewport().rect()).boundingRect()
            
            # Calculate the green box rectangle, shifted upward by half its height to center it
            green_box_rect = QRectF(
                view_rect.x() * factor_x,
                view_rect.y() * factor_y,
                view_rect.width() * factor_x,
                view_rect.height() * factor_y
            )
            
            # Scale the main image for the mini preview and draw the green box on it
            pixmap = self.main_image.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            painter = QPainter(pixmap)
            pen = QPen(QColor(0, 255, 0), 2)
            painter.setPen(pen)
            painter.drawRect(green_box_rect)
            painter.end()
            self.mini_preview.setPixmap(pixmap)

    @staticmethod
    def calculate_angular_distance(ra1, dec1, ra2, dec2):
        # Convert degrees to radians
        ra1, dec1, ra2, dec2 = map(math.radians, [ra1, dec1, ra2, dec2])

        # Haversine formula for angular distance
        delta_ra = ra2 - ra1
        delta_dec = dec2 - dec1
        a = (math.sin(delta_dec / 2) ** 2 +
            math.cos(dec1) * math.cos(dec2) * math.sin(delta_ra / 2) ** 2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        angular_distance = math.degrees(c)
        return angular_distance
    
    @staticmethod
    def format_distance_as_dms(angle):
        degrees = int(angle)
        minutes = int((angle - degrees) * 60)
        seconds = (angle - degrees - minutes / 60) * 3600
        return f"{degrees}° {minutes}' {seconds:.2f}\""


    def wheel_zoom(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()

    @announce_zoom
    def zoom_in(self):
        self.zoom_level *= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()
        
    @announce_zoom
    def zoom_out(self):
        self.zoom_level /= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.update_green_box()


    def compute_pixscale(self):
        """
        Computes the pixel scale (arcsec/pixel) from the header's CD keywords.
        """
        try:
            cd1_1 = float(self.header.get('CD1_1', 0))
            cd1_2 = float(self.header.get('CD1_2', 0))
            # Calculate scale in degrees per pixel and convert to arcsec.
            pixscale = math.sqrt(cd1_1**2 + cd1_2**2) * 3600.0
            print("Calculated pixscale from header:", pixscale)
            return pixscale
        except Exception as e:
            print("Error calculating pixscale:", e)
            return None

    def get_defined_radius(self):
        """
        Returns the radius (in arcminutes) for the current circle.
        If self.pixscale is None, attempt to calculate it manually.
        """
        if self.pixscale is None:
            self.pixscale = self.compute_pixscale()
            if self.pixscale is None:
                print("Warning: Could not compute pixscale from header.")
                return None

        # The circle_radius is in pixels; convert to arcminutes.
        return float((self.circle_radius * self.pixscale) / 3600.0)

    def update_circle_data(self):
        """Updates the status based on the circle's center and radius."""
        if self.circle_center and self.circle_radius > 0:
            # Make sure we have a valid pixscale.
            if self.pixscale is None:
                self.pixscale = self.compute_pixscale()
                if self.pixscale is None:
                    self.status_label.setText("No pixscale available for radius calculation.")
                    print("Warning: Pixscale is None. Cannot calculate radius in arcminutes.")
                    return

            # Convert circle center to RA/Dec and radius to arcminutes.
            ra, dec = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            radius_arcmin = self.circle_radius * self.pixscale / 60.0  # from arcsec to arcmin
            self.status_label.setText(
                f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
            )
        else:
            self.status_label.setText("No search area defined.")



    def get_defined_radius(self):
        """Calculate radius in degrees for the defined region (circle radius)."""
        if self.circle_radius <= 0:
            return 0
        return float((self.circle_radius * self.pixscale) / 3600.0)


    def query_simbad(self, radius_deg, max_results=None):
        """Two-step SIMBAD lookup with debug prints for flux/plx/sp data."""
        max_results = max_results if max_results is not None else self.max_results

        # ——— 1) Validate inputs ———
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area",
                                "Please define a search circle by Shift-clicking and dragging.")
            return

        ra_center, dec_center = self.calculate_ra_dec_from_pixel(
            self.circle_center.x(), self.circle_center.y()
        )
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates",
                                "Could not determine the RA/Dec of the circle center.")
            return

        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected",
                                "Please select at least one object type.")
            return

        # ——— 2) TAP query on BASIC ———
        query = f"""
            SELECT TOP {max_results}
                ra, dec, main_id,
                rvz_redshift, otype, galdim_majaxis
            FROM basic
            WHERE CONTAINS(
                POINT('ICRS', basic.ra, basic.dec),
                CIRCLE('ICRS', {ra_center}, {dec_center}, {radius_deg})
            ) = 1
        """
        for attempt in range(5):
            try:
                result = Simbad.query_tap(query)
                break
            except Exception as e:
                if attempt < 4:
                    time.sleep(1)
                else:
                    QMessageBox.critical(
                        self,
                        "Query Failed",
                        f"Try again later:\n{e}"
            )

        if result is None or len(result) == 0:
            QMessageBox.information(self, "No Results",
                                    "No objects found in the specified area.")
            return

        # ——— 3a) list of all “star” & binary/variable OTYPE codes ———
        star_codes = [
            "*","V*","Pe*","HB*","Y*O","Ae*","Em*","Be*","BS*","RG*","AB*",
            "C*","S*","sg*","s*r","s*y","s*b","HS*","pA*","WD*","LM*","BD*",
            "N*","OH*","TT*","WR*","PM*","HV*","C?*","Pec?","Y*?","TT?","C*?",
            "S*?","OH?","WR?","Be?","Ae?","HB?","RB?","sg?","s?r","s?y","s?b",
            "pA?","BS?","HS?","WD?",
            "**","EB*","Ce*","Ce?","cC*","**?",
            "EB?","Sy?","CV?","No?","XB?","LX?","HX?","RR?","WV?","LP?","Mi?"
        ]

        # 3b) build the two sub-criteria, un-encoded:
        ra_str  = f"{ra_center:.8f}"
        dec_str = f"{dec_center:+.8f}"   # keep the +/– sign
        rad_str = f"{radius_deg:.8f}d"

        region_crit = f"region(CIRCLE,{ra_str} {dec_str},{rad_str})"
        codes_list  = ",".join(f"'{c}'" for c in star_codes)
        otype_crit  = f"otypes in ({codes_list})"

        # combine with a literal '&' (not "AND")
        criteria = f"{region_crit}&{otype_crit}"

        # ——— 3c) fetch _only_ those via sim-sam ———
        sam_url = "https://simbad.cds.unistra.fr/simbad/sim-sam"
        params = {
            "Criteria":      criteria,
            "OutputMode":    "LIST",
            "maxObject":     str(max_results),
            "output.format": "votable",
            "output.params": ",".join([
                "MAIN_ID","RA","DEC",
                "FLUX(B)","FLUX(V)",
                "PLX_VALUE","RVZ_REDSHIFT",
                "OTYPE","SP_TYPE"
            ])
        }

        try:
            resp = requests.get(sam_url, params=params, timeout=300)
            resp.raise_for_status()

            vot = parse_single_table(BytesIO(resp.content))
            tbl = vot.to_table(use_names_over_ids=True)
            extras = { row["MAIN_ID"]: row for row in tbl }

        except Exception as e:
            print(f"DEBUG: sim-sam failed: {e}")
            QMessageBox.warning(
                self,
                "Star-only Extras Failed",
                "Could not fetch star flux/parallax—continuing without them."
            )
            extras = {}

        # ——— 4) Merge & populate results_tree exactly as before ———
        self.results_tree.clear()
        query_results = []

        for row in result:
            name       = row["main_id"]
            short_type = row["otype"]
            if short_type not in selected_types:
                continue

            # basics
            ra, dec = float(row["ra"]), float(row["dec"])
            diam     = row.get("galdim_majaxis", "N/A")
            rz       = row["rvz_redshift"]
            red_z    = float(rz) if rz is not None else None

            # pull extras only if it’s a star
            extra = extras.get(name, {})
            Bmag  = extra.get("FLUX_B")
            Vmag  = extra.get("FLUX_V")
            plx   = extra.get("PLX_VALUE")
            spec  = extra.get("SP_TYPE")

            if plx is not None:
                pv = abs(float(plx))          # <— absolute value here
                if pv > 0:
                    dist_pc  = 1000.0 / pv
                    dist_ly  = dist_pc * 3.261563777
                    # store comoving distance in Gyr for consistency with your zs_raw pipeline:
                    distance = round(dist_ly / 1e9, 9)
                    red_val  = pv              # use the positive parallax in the "redshift" column
                else:
                    # parallax was 0⇒ no distance
                    red_val  = red_z if red_z is not None else "--"
                    distance = (calculate_comoving_distance(red_val)
                                if red_val != "--" else "N/A")
            else:
                red_val  = red_z if red_z is not None else "--"
                distance = (calculate_comoving_distance(red_val)
                            if red_val != "--" else "N/A")

            # absolute V magnitude if we have Vmag & plx
            absV = None
            if Vmag is not None and plx and plx > 0:
                absV = Vmag - (5 * np.log10(1000.0 / plx) - 5)

            long_type = otype_long_name_lookup.get(short_type, short_type)

            # add to tree
            item = QTreeWidgetItem([
                f"{ra:.6f}", f"{dec:.6f}", name,
                str(diam), short_type, long_type,
                f"{red_val:.6f}" if isinstance(red_val, (int,float)) else str(red_val),
                f"{distance:.6f}" if isinstance(distance, float) else str(distance)
            ])
            self.results_tree.addTopLevelItem(item)

            query_results.append({
                'ra': ra, 'dec': dec, 'name': name,
                'diameter': diam,
                'short_type': short_type,
                'long_type': long_type,
                'redshift': red_val,
                'comoving_distance': distance,
                'source': "Simbad",
                'Bmag': Bmag, 'Vmag': Vmag,
                'parallax_mas': plx,
                'spectral_type': spec,
                'absolute_mag': absV
            })

        # ——— 5) Finally hand off to your preview/plotter ———
        self.main_preview.set_query_results(query_results)
        self.query_results = query_results
        self.update_object_count()



    def perform_deep_vizier_search(self):
        CATALOG_NAMES = {
            "J/ApJS/199/26":    "2MRS",
            "VII/259/6dfgs":    "6dF Galaxy Survey",
            "V/147/sdss12":     "SDSS DR12",
            "VII/250/2dfgrs":   "2dFGRS",
            "J/MNRAS/474/3875": "GAMA DR3",
            "VII/291/gladep":   "GLADE+",
            "VII/237":          "HyperLEDA",
            "VII/221/psc":      "IRAS PSCz",
            "II/246":           "2MASS PSC",
            "I/350/gaiaedr3":   "Gaia EDR3",
            "I/322A":           "UCAC4",
            "V/154":            "Pan-STARRS 1",
        }        
        """Perform a Vizier catalog search and parse results, querying redshift surveys first."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area",
                                "Please define a search circle by Shift-clicking and dragging.")
            return

        # Convert center to RA/Dec
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(
            self.circle_center.x(), self.circle_center.y()
        )
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates",
                                "Could not determine the RA/Dec of the circle center.")
            return

        radius_arcmin = float((self.circle_radius * self.pixscale) / 60.0)

        # Query true-redshift surveys first
        catalog_ids = [
            # 1) Major spectroscopic redshift surveys
            "J/ApJS/199/26",     # 2MASS Redshift Survey (2MRS)
            "VII/259/6dfgs",     # 6dF Galaxy Survey
            "V/147/sdss12",      # SDSS DR12 spectroscopic
            "VII/250/2dfgrs",    # 2dF Galaxy Redshift Survey (2dFGRS)
            "J/MNRAS/474/3875",  # GAMA DR3

            # 2) Meta-catalogs & composites
            "VII/291/gladep",    # GLADE+
            "VII/237",           # HyperLEDA
            "VII/221/psc",       # IRAS PSCz

            # 3) Photometric & astrometric surveys
            "II/246",            # 2MASS PSC
            "I/350/gaiaedr3",    # Gaia EDR3
            "I/322A",            # UCAC4
            "V/154"              # Pan-STARRS 1
        ]


        coord = SkyCoord(ra_center, dec_center, unit="deg")
        unique_entries = {}

        try:
            for catalog_id in catalog_ids:
                result = Vizier.query_region(
                    coord, radius=radius_arcmin * u.arcmin, catalog=catalog_id
                )
                if not result:
                    continue

                for row in result[0]:
                    # RA / Dec
                    ra = row.get("RAJ2000", row.get("RA_ICRS", None))
                    dec = row.get("DEJ2000", row.get("DE_ICRS", None))
                    if ra is None or dec is None:
                        continue
                    ra_str, dec_str = str(ra), str(dec)
                    key = (ra_str, dec_str)

                    # Name & types
                    name       = str(row.get("_2MASS", "") or row.get("Source", "") or row.get("SDSS12", ""))
                    type_short = CATALOG_NAMES.get(catalog_id, catalog_id)
                    long_type  = str(row.get("SpType", "N/A"))
                    diameter   = catalog_id

                    # ——— robust redshift/parallax parsing ———
                    if "cz" in row.colnames:
                        raw = row["cz"]
                        try:
                            cz = float(raw)
                            zval = cz / 299792.458
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "z" in row.colnames:
                        raw = row["z"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zhelio" in row.colnames:
                        raw = row["zhelio"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zcmb" in row.colnames:
                        raw = row["zcmb"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zph" in row.colnames:
                        raw = row["zph"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "Plx" in row.colnames:
                        raw = row["Plx"]
                        try:
                            pv = abs(float(raw))
                            redshift = f"{pv:.3f} (Parallax mas)"
                            comoving_distance = f"{1000/pv * 3.2615637769:.5f} Ly"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    else:
                        redshift = "N/A"
                        comoving_distance = "N/A"
                    # ——— end parsing block ———

                    # Duplicate handling: first entry wins, SDSS overrides Pan-STARRS
                    if key not in unique_entries:
                        unique_entries[key] = {
                            "ra": ra_str,
                            "dec": dec_str,
                            "name": name,
                            "diameter": diameter,
                            "short_type": type_short,
                            "long_type": long_type,
                            "redshift": redshift,
                            "comoving_distance": comoving_distance
                        }
                    else:
                        existing = unique_entries[key]["diameter"]
                        if existing == "V/154" and diameter == "V/147/sdss12":
                            unique_entries[key].update({
                                "name": name,
                                "diameter": diameter,
                                "short_type": type_short,
                                "long_type": long_type,
                                "redshift": redshift,
                                "comoving_distance": comoving_distance
                            })

            # Populate tree & preview
            all_results = []
            for e in unique_entries.values():
                item = QTreeWidgetItem([
                    e["ra"], e["dec"], e["name"], e["diameter"],
                    e["short_type"], e["long_type"],
                    e["redshift"], e["comoving_distance"]
                ])
                self.results_tree.addTopLevelItem(item)
                all_results.append(e)

            self.main_preview.set_query_results(all_results)
            self.query_results = all_results
            self.update_object_count()

        except Exception as err:
            QMessageBox.critical(self, "Vizier Search Failed", f"Failed to query Vizier: {err}")



    def perform_mast_search(self):
        """Perform a MAST cone search in the user-defined region using astroquery."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area", "Please define a search circle by Shift-clicking and dragging.")
            return

        # Calculate RA and Dec for the center point
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates", "Could not determine the RA/Dec of the circle center.")
            return

        # Convert radius from arcseconds to degrees (MAST uses degrees)
        search_radius_deg = float((self.circle_radius * self.pixscale) / 3600.0)  # Convert to degrees
        ra_center = float(ra_center)  # Ensure it's a regular float
        dec_center = float(dec_center)  # Ensure it's a regular float

        try:
            # Perform the MAST cone search using Mast.mast_query for the 'Mast.Caom.Cone' service
            observations = Mast.mast_query(
                'Mast.Caom.Cone',
                ra=ra_center,
                dec=dec_center,
                radius=search_radius_deg
            )

            # Limit the results to the first 100 rows
            limited_observations = observations[:100]

            if len(observations) == 0:
                QMessageBox.information(self, "No Results", "No objects found in the specified area on MAST.")
                return

            # Clear previous results
            self.results_tree.clear()
            query_results = []

            # Process each observation in the results
            for obj in limited_observations:

                def safe_get(value):
                    return "N/A" if np.ma.is_masked(value) else str(value)


                ra = safe_get(obj.get("s_ra", "N/A"))
                dec = safe_get(obj.get("s_dec", "N/A"))
                target_name = safe_get(obj.get("target_name", "N/A"))
                instrument = safe_get(obj.get("instrument_name", "N/A"))
                jpeg_url = safe_get(obj.get("dataURL", "N/A"))  # Adjust URL field as needed

                # Add to TreeWidget
                item = QTreeWidgetItem([
                    ra,
                    dec,
                    target_name,
                    instrument,
                    "N/A",  # Placeholder for observation date if needed
                    "N/A",  # Other placeholder
                    jpeg_url,  # URL in place of long type
                    "MAST"  # Source
                ])
                self.results_tree.addTopLevelItem(item)

                # Append full details as a dictionary to query_results
                query_results.append({
                    'ra': ra,
                    'dec': dec,
                    'name': target_name,
                    'diameter': instrument,
                    'short_type': "N/A",
                    'long_type': jpeg_url,
                    'redshift': "N/A",
                    'comoving_distance': "N/A",
                    'source': "Mast"
                })

            # Set query results in the CustomGraphicsView for display
            self.main_preview.set_query_results(query_results)
            self.query_results = query_results  # Keep a reference to results in MainWindow
            self.update_object_count()

        except Exception as e:
            QMessageBox.critical(self, "MAST Query Failed", f"Failed to query MAST: {str(e)}")

    def toggle_show_names(self, state):
        """Toggle showing/hiding names on the main image."""
        self.show_names = state == Qt.CheckState.Checked
        self.main_preview.draw_query_results()  # Redraw with or without names

    def clear_results(self):
        """Clear the search results and remove markers from the main image."""
        self.results_tree.clear()
        self.main_preview.clear_query_results()
        self.status_label.setText("Results cleared.")

    def open_settings_dialog(self):
        """Open settings dialog to adjust max results and marker type."""
        dialog = QDialog(self)
        dialog.setWindowTitle("Settings")
        
        layout = QFormLayout(dialog)
        

        # Max Results setting using CustomSpinBox
        max_results_spinbox = CustomSpinBox(minimum=1, maximum=100000, initial=self.max_results, step=1)
        layout.addRow("Max Results:", max_results_spinbox)

        
        # Marker Style selection
        marker_style_combo = QComboBox()
        marker_style_combo.addItems(["Circle", "Crosshair"])
        marker_style_combo.setCurrentText(self.marker_style)
        layout.addRow("Marker Style:", marker_style_combo)

        # Force Blind Solve button
        force_blind_solve_button = QPushButton("Force Blind Solve")
        force_blind_solve_button.clicked.connect(lambda: self.force_blind_solve(dialog))
        layout.addWidget(force_blind_solve_button)
        
        # OK and Cancel buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(lambda: self.update_settings(max_results_spinbox.value, marker_style_combo.currentText(), dialog))
        buttons.rejected.connect(dialog.reject)
        layout.addWidget(buttons)
        
        dialog.setLayout(layout)
        dialog.exec()

    def update_settings(self, max_results, marker_style, dialog):
        """Update settings based on dialog input."""
        self.max_results = max_results
        self.marker_style = marker_style  # Store the selected marker style
        self.main_preview.draw_query_results()
        dialog.accept()

    def force_blind_solve(self, dialog):
        """Force a blind solve on the currently loaded image."""
        dialog.accept()  # Close the settings dialog
        self.prompt_blind_solve()  # Call the blind solve function


def extract_wcs_data(file_path):
    try:
        # Open the FITS file with minimal validation to ignore potential errors in non-essential parts
        with fits.open(file_path, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
            header = hdul[0].header

            # Extract essential WCS parameters
            wcs_params = {}
            keys_to_extract = [
                'WCSAXES', 'CTYPE1', 'CTYPE2', 'EQUINOX', 'LONPOLE', 'LATPOLE',
                'CRVAL1', 'CRVAL2', 'CRPIX1', 'CRPIX2', 'CUNIT1', 'CUNIT2',
                'CD1_1', 'CD1_2', 'CD2_1', 'CD2_2', 'A_ORDER', 'A_0_0', 'A_0_1', 
                'A_0_2', 'A_1_0', 'A_1_1', 'A_2_0', 'B_ORDER', 'B_0_0', 'B_0_1', 
                'B_0_2', 'B_1_0', 'B_1_1', 'B_2_0', 'AP_ORDER', 'AP_0_0', 'AP_0_1', 
                'AP_0_2', 'AP_1_0', 'AP_1_1', 'AP_2_0', 'BP_ORDER', 'BP_0_0', 
                'BP_0_1', 'BP_0_2', 'BP_1_0', 'BP_1_1', 'BP_2_0'
            ]
            for key in keys_to_extract:
                if key in header:
                    wcs_params[key] = header[key]

            # Manually create a minimal header with WCS information
            wcs_header = fits.Header()
            for key, value in wcs_params.items():
                wcs_header[key] = value

            # Initialize WCS with this custom header
            wcs = WCS(wcs_header)
            print("WCS successfully initialized with minimal header.")
            return wcs

    except Exception as e:
        print(f"Error processing WCS file: {e}")
        return None

# Function to calculate comoving radial distance (in Gly)
def calculate_comoving_distance(z):
    z = abs(z)
    # Initialize variables
    WR = 4.165E-5 / ((H0 / 100) ** 2)  # Omega radiation
    WK = 1 - WM - WV - WR  # Omega curvature
    az = 1.0 / (1 + z)
    n = 1000  # number of points in integration

    # Comoving radial distance
    DCMR = 0.0
    for i in range(n):
        a = az + (1 - az) * (i + 0.5) / n
        adot = sqrt(WK + (WM / a) + (WR / (a ** 2)) + (WV * a ** 2))
        DCMR += 1 / (a * adot)
    
    DCMR = (1 - az) * DCMR / n
    DCMR_Gly = (c / H0) * DCMR * Mpc_to_Gly

    return round(DCMR_Gly, 6)  # Round to three decimal places for display

def calculate_orientation(header):
    """Calculate orientation from CD or PC matrix."""
    cd1_1 = header.get('CD1_1')
    cd1_2 = header.get('CD1_2')
    cd2_1 = header.get('CD2_1')
    cd2_2 = header.get('CD2_2')

    if all(v is not None for v in [cd1_1, cd1_2, cd2_1, cd2_2]):
        orientation = (np.degrees(np.arctan2(cd1_2, cd1_1)) + 180) % 360
        return orientation

    # Try PC matrix fallback
    pc1_1 = header.get('PC1_1')
    pc1_2 = header.get('PC1_2')
    cdelt1 = header.get('CDELT1')
    cdelt2 = header.get('CDELT2')

    if pc1_1 is not None and pc1_2 is not None and cdelt1 is not None and cdelt2 is not None:
        cd1_1 = pc1_1 * cdelt1
        cd1_2 = pc1_2 * cdelt1
        orientation = (np.degrees(np.arctan2(cd1_2, cd1_1)) + 180) % 360
        return orientation

    print("CD or PC matrix not found in header.")
    return None




# Set the directory for the images in the /imgs folder
if getattr(sys, 'frozen', False):  # Check if running as a PyInstaller bundle
    phase_folder = os.path.join(sys._MEIPASS, "imgs")  # Use PyInstaller's temporary directory with /imgs
else:
    phase_folder = os.path.join(os.path.dirname(__file__), "imgs")  # Use the directory of the script file with /imgs


# Set precision for Decimal operations
getcontext().prec = 24

# Suppress warnings
warnings.filterwarnings("ignore")


class CalculationThread(QThread):
    calculation_complete = pyqtSignal(pd.DataFrame, str)
    lunar_phase_calculated = pyqtSignal(int, str)  # phase_percentage, phase_image_name
    lst_calculated = pyqtSignal(str)
    status_update = pyqtSignal(str)

    def __init__(self, latitude, longitude, date, time, timezone, min_altitude, catalog_filters, object_limit):
        super().__init__()
        self.latitude = latitude
        self.longitude = longitude
        self.date = date
        self.time = time
        self.timezone = timezone
        self.min_altitude = min_altitude
        self.catalog_filters = catalog_filters
        self.object_limit = object_limit

    def get_catalog_file_path(self):
        # Define a user-writable location for the catalog (e.g., in the user's home directory)
        user_catalog_path = os.path.join(os.path.expanduser("~"), "celestial_catalog.csv")

        # Check if we are running in a PyInstaller bundle
        if not os.path.exists(user_catalog_path):
            bundled_catalog = os.path.join(getattr(sys, '_MEIPASS', os.path.dirname(__file__)), "celestial_catalog.csv")
            if os.path.exists(bundled_catalog):
                # Copy the bundled catalog to a writable location
                shutil.copyfile(bundled_catalog, user_catalog_path)

        return user_catalog_path  # Return the path to the user-writable catalog

    def run(self):
        try:
            # Convert date and time to astropy Time
            datetime_str = f"{self.date} {self.time}"
            local = pytz.timezone(self.timezone)
            naive_datetime = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M")
            local_datetime = local.localize(naive_datetime)
            astropy_time = Time(local_datetime)

            # Define observer's location
            location = EarthLocation(lat=self.latitude * u.deg, lon=self.longitude * u.deg, height=0 * u.m)

            # Calculate Local Sidereal Time (LST)
            lst = astropy_time.sidereal_time('apparent', self.longitude * u.deg)
            self.lst_calculated.emit(f"Local Sidereal Time: {lst.to_string(unit=u.hour, precision=3)}")

            # Calculate lunar phase
            phase_percentage, phase_image_name = self.calculate_lunar_phase(astropy_time, location)
            self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)

            # Load celestial catalog
            catalog_file = self.get_catalog_file_path()
            if not os.path.exists(catalog_file):
                self.calculation_complete.emit(pd.DataFrame(), "Catalog file not found.")
                return

            df = pd.read_csv(catalog_file, encoding='ISO-8859-1')

            # Apply catalog filters **AFTER reading to avoid index mismatch**
            df = df[df['Catalog'].isin(self.catalog_filters)]
            df.dropna(subset=['RA', 'Dec'], inplace=True)

            # Ensure DataFrame is contiguous
            df.reset_index(drop=True, inplace=True)

            # Convert RA/Dec into SkyCoord objects **vectorized**
            sky_coords = SkyCoord(ra=df['RA'].values * u.deg, dec=df['Dec'].values * u.deg, frame='icrs')

            # Create an AltAz frame for observer location
            altaz_frame = AltAz(obstime=astropy_time, location=location)

            # **Vectorized altitude and azimuth calculation**
            altaz = sky_coords.transform_to(altaz_frame)
            df['Altitude'] = np.round(altaz.alt.deg, 1)
            df['Azimuth'] = np.round(altaz.az.deg, 1)

            # 1) Transform all catalog objects to AltAz:
            altaz_coords = sky_coords.transform_to(altaz_frame)

            # 2) Transform the Moon to AltAz, too:
            moon_altaz = get_body("moon", astropy_time, location).transform_to(altaz_frame)

            # 3) Now calculate separation in AltAz space:
            df['Degrees from Moon'] = np.round(altaz_coords.separation(moon_altaz).deg, 2)

            # **Apply altitude filter after calculations**
            df = df[df['Altitude'] >= self.min_altitude]

            # **Vectorized calculation of "Minutes to Transit"**
            ra_hours = df['RA'].values * (24 / 360.0)  # Convert degrees to hours
            time_diff = ((ra_hours - lst.hour) * u.hour) % (24 * u.hour)  # Hour difference
            df['Minutes to Transit'] = np.round(time_diff.value * 60, 1)

            # Correct Before/After Transit flags efficiently
            df['Before/After Transit'] = np.where(df['Minutes to Transit'] > 720, "After", "Before")
            df['Minutes to Transit'] = np.where(df['Minutes to Transit'] > 720, 1440 - df['Minutes to Transit'], df['Minutes to Transit'])

            # **Optimized Sorting & Selection**
            df = df.nsmallest(self.object_limit, 'Minutes to Transit')  # Faster than full sort

            self.calculation_complete.emit(df, "Calculation complete.")
        except Exception as e:
            self.calculation_complete.emit(pd.DataFrame(), f"Error: {str(e)}")




    def calculate_lunar_phase(self, astropy_time, location):
        moon = get_body("moon", astropy_time, location)
        sun = get_sun(astropy_time)
        elongation = moon.separation(sun).deg

        # Determine lunar phase percentage
        phase_percentage = (1 - np.cos(np.radians(elongation))) / 2 * 100
        phase_percentage = round(phase_percentage)

        # Determine if it is waxing or waning
        future_time = astropy_time + (6 * u.hour)
        future_moon = get_body("moon", future_time, location)
        future_sun = get_sun(future_time)
        future_elongation = future_moon.separation(future_sun).deg
        is_waxing = future_elongation > elongation

        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")


        # Select appropriate lunar phase image based on phase angle
        phase_image_name = "new_moon.png"  # Default

        if 0 <= elongation < 9:
            phase_image_name = "new_moon.png"
        elif 9 <= elongation < 18:
            phase_image_name = "waxing_crescent_1.png" if is_waxing else "waning_crescent_5.png"
        elif 18 <= elongation < 27:
            phase_image_name = "waxing_crescent_2.png" if is_waxing else "waning_crescent_4.png"
        elif 27 <= elongation < 36:
            phase_image_name = "waxing_crescent_3.png" if is_waxing else "waning_crescent_3.png"
        elif 36 <= elongation < 45:
            phase_image_name = "waxing_crescent_4.png" if is_waxing else "waning_crescent_2.png"
        elif 45 <= elongation < 54:
            phase_image_name = "waxing_crescent_5.png" if is_waxing else "waning_crescent_1.png"
        elif 54 <= elongation < 90:
            phase_image_name = "first_quarter.png"
        elif 90 <= elongation < 108:
            phase_image_name = "waxing_gibbous_1.png" if is_waxing else "waning_gibbous_4.png"
        elif 108 <= elongation < 126:
            phase_image_name = "waxing_gibbous_2.png" if is_waxing else "waning_gibbous_3.png"
        elif 126 <= elongation < 144:
            phase_image_name = "waxing_gibbous_3.png" if is_waxing else "waning_gibbous_2.png"
        elif 144 <= elongation < 162:
            phase_image_name = "waxing_gibbous_4.png" if is_waxing else "waning_gibbous_1.png"
        elif 162 <= elongation <= 180:
            phase_image_name = "full_moon.png"


        self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)
        return phase_percentage, phase_image_name



class WhatsInMySky(QWidget):
    def __init__(self):
        super().__init__()
        self.settings_file = os.path.join(os.path.expanduser("~"), "sky_settings.json")
        self.settings = QSettings() 
        self.initUI()  # Build the UI
        self.load_settings()  # Load settings after UI is built
        self.object_limit = self.settings.value("object_limit", 100, type=int)

    def initUI(self):
        layout = QGridLayout()
        fixed_width = 150

        # Latitude, Longitude, Date, Time, Time Zone
        self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo = self.setup_basic_info_fields(layout, fixed_width)

        # Minimum Altitude, Catalog Filters, RA/Dec format
        self.min_altitude_entry, self.catalog_vars, self.ra_dec_format = self.setup_filters(layout, fixed_width)

        # Calculate Button, Status Label, Sidereal Time, Treeview for Results, Custom Object and Save Buttons
        self.setup_controls(layout, fixed_width)

        self.setLayout(layout)
        self.setMinimumWidth(1000)  # Ensures a wide enough starting window

    def setup_basic_info_fields(self, layout, fixed_width):
        self.latitude_entry = QLineEdit()
        self.latitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Latitude:"), 0, 0)
        layout.addWidget(self.latitude_entry, 0, 1)

        self.longitude_entry = QLineEdit()
        self.longitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Longitude:"), 1, 0)
        layout.addWidget(self.longitude_entry, 1, 1)

        self.date_entry = QLineEdit()
        self.date_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Date (YYYY-MM-DD):"), 2, 0)
        layout.addWidget(self.date_entry, 2, 1)

        self.time_entry = QLineEdit()
        self.time_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time (HH:MM):"), 3, 0)
        layout.addWidget(self.time_entry, 3, 1)

        self.timezone_combo = QComboBox()
        self.timezone_combo.addItems(pytz.all_timezones)
        self.timezone_combo.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time Zone:"), 4, 0)
        layout.addWidget(self.timezone_combo, 4, 1)

        return self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo

    def setup_filters(self, layout, fixed_width):
        self.min_altitude_entry = QLineEdit()
        self.min_altitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Min Altitude (0-90 degrees):"), 5, 0)
        layout.addWidget(self.min_altitude_entry, 5, 1)

        catalog_frame = QScrollArea()
        catalog_widget = QWidget()
        catalog_layout = QGridLayout()
        self.catalog_vars = {}
        for i, catalog in enumerate(["Messier", "NGC", "IC", "Caldwell", "Abell", "Sharpless", "LBN", "LDN", "PNG", "User"]):
            chk = QCheckBox(catalog)
            chk.setChecked(False)
            catalog_layout.addWidget(chk, i // 5, i % 5)
            self.catalog_vars[catalog] = chk
        catalog_widget.setLayout(catalog_layout)
        catalog_frame.setWidget(catalog_widget)
        catalog_frame.setFixedWidth(fixed_width + 250)
        layout.addWidget(QLabel("Catalog Filters:"), 6, 0)
        layout.addWidget(catalog_frame, 6, 1)

        # RA/Dec format setup
        self.ra_dec_degrees = QRadioButton("Degrees")
        self.ra_dec_hms = QRadioButton("H:M:S / D:M:S")
        ra_dec_group = QButtonGroup()
        ra_dec_group.addButton(self.ra_dec_degrees)
        ra_dec_group.addButton(self.ra_dec_hms)
        self.ra_dec_degrees.setChecked(True)  # Default to Degrees format
        ra_dec_layout = QHBoxLayout()
        ra_dec_layout.addWidget(self.ra_dec_degrees)
        ra_dec_layout.addWidget(self.ra_dec_hms)
        layout.addWidget(QLabel("RA/Dec Format:"), 7, 0)
        layout.addLayout(ra_dec_layout, 7, 1)

        # Connect the radio buttons to the update function
        self.ra_dec_degrees.toggled.connect(self.update_ra_dec_format)
        self.ra_dec_hms.toggled.connect(self.update_ra_dec_format)

        return self.min_altitude_entry, self.catalog_vars, self.ra_dec_degrees

    def setup_controls(self, layout, fixed_width):
        # Calculate button
        calculate_button = QPushButton("Calculate")
        calculate_button.setFixedWidth(fixed_width)
        layout.addWidget(calculate_button, 8, 0)
        calculate_button.clicked.connect(self.start_calculation)

        # Status label
        self.status_label = QLabel("Status: Idle")
        layout.addWidget(self.status_label, 9, 0, 1, 2)

        # Sidereal time label
        self.lst_label = QLabel("Local Sidereal Time: {:.3f}".format(0.0))
        layout.addWidget(self.lst_label, 10, 0, 1, 2)

        # Lunar phase image and label
        self.lunar_phase_image_label = QLabel()
        layout.addWidget(self.lunar_phase_image_label, 0, 2, 4, 1)  # Position it appropriately

        self.lunar_phase_label = QLabel("Lunar Phase: N/A")
        layout.addWidget(self.lunar_phase_label, 4, 2)

        # Treeview for results (expand dynamically)
        self.tree = QTreeWidget()
        self.tree.setHeaderLabels([
            "Name", "RA", "Dec", "Altitude", "Azimuth", "Minutes to Transit", "Before/After Transit",
            "Degrees from Moon", "Alt Name", "Type", "Magnitude", "Size (arcmin)"
        ])
        self.tree.setSortingEnabled(True)
        header = self.tree.header()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # Allow users to resize columns
        header.setStretchLastSection(False)  # Ensure last column is not stretched automatically

        self.tree.sortByColumn(5, Qt.SortOrder.AscendingOrder)
        layout.addWidget(self.tree, 11, 0, 1, 3)
        self.tree.itemDoubleClicked.connect(self.on_row_double_click)

        # Buttons at the bottom
        add_object_button = QPushButton("Add Custom Object")
        add_object_button.setFixedWidth(fixed_width)
        layout.addWidget(add_object_button, 12, 0)
        add_object_button.clicked.connect(self.add_custom_object)

        save_button = QPushButton("Save to CSV")
        save_button.setFixedWidth(fixed_width)
        layout.addWidget(save_button, 12, 1)
        save_button.clicked.connect(self.save_to_csv)

        # Settings button to change the number of objects displayed
        settings_button = QPushButton()
        settings_button.setIcon(QIcon(wrench_path))  # Use icon_path for the button's icon
        settings_button.setFixedWidth(fixed_width)
        layout.addWidget(settings_button, 12, 2)
        settings_button.clicked.connect(self.open_settings)        

        # Allow the main window to expand
        layout.setColumnStretch(2, 1)  # Makes the right column (with tree widget) expand as the window grows


    def start_calculation(self):
        # Gather the inputs
        latitude = float(self.latitude_entry.text())
        longitude = float(self.longitude_entry.text())
        date_str = self.date_entry.text()
        time_str = self.time_entry.text()
        timezone_str = self.timezone_combo.currentText()
        min_altitude = float(self.min_altitude_entry.text())

        # Validate inputs
        try:
            latitude = float(latitude)
            longitude = float(longitude)
            min_altitude = float(min_altitude)
        except ValueError:
            self.update_status("Invalid input: Latitude, Longitude, and Min Altitude must be numeric.")
            return

        # Save the settings
        self.save_settings(latitude, longitude, date_str, time_str, timezone_str, min_altitude)


        catalog_filters = [catalog for catalog, var in self.catalog_vars.items() if var.isChecked()]
        object_limit = self.object_limit

        # Set up and start the calculation thread
        self.calc_thread = CalculationThread(
            latitude, longitude, date_str, time_str, timezone_str,
            min_altitude, catalog_filters, object_limit
        )
        self.calc_thread.calculation_complete.connect(self.on_calculation_complete)
        self.calc_thread.lunar_phase_calculated.connect(self.update_lunar_phase)
        self.calc_thread.lst_calculated.connect(self.update_lst) 
        self.calc_thread.status_update.connect(self.update_status)
        self.update_status("Calculating...")
        self.calc_thread.start()


    def update_lunar_phase(self, phase_percentage, phase_image_name):
        # Update the lunar phase label
        self.lunar_phase_label.setText(f"Lunar Phase: {phase_percentage}% illuminated")

        # Define the path to the image
        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")
        phase_image_path = os.path.join(phase_folder, phase_image_name)

        # Load and display the lunar phase image if it exists
        if os.path.exists(phase_image_path):
            pixmap = QPixmap(phase_image_path).scaled(100, 100, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            self.lunar_phase_image_label.setPixmap(pixmap)
        else:
            print(f"Image not found: {phase_image_path}")     

    def on_calculation_complete(self, df, message):
        # Handle the data received from the calculation thread
        self.update_status(message)
        if not df.empty:
            self.tree.clear()
            for _, row in df.iterrows():
                # Prepare RA and Dec display based on selected format
                ra_display = row['RA']
                dec_display = row['Dec']

                if self.ra_dec_hms.isChecked():
                    # Convert degrees to H:M:S format
                    sky_coord = SkyCoord(ra=row['RA'] * u.deg, dec=row['Dec'] * u.deg)
                    ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                    dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')

                # Calculate Before/After Transit string
                before_after = row['Before/After Transit']

                # Ensure Size (arcmin) displays correctly as a string
                size_arcmin = row.get('Info', '')
                if pd.notna(size_arcmin):
                    size_arcmin = str(size_arcmin)  # Ensure it's treated as a string

                # Populate each row with the calculated data
                values = [
                    str(row['Name']) if pd.notna(row['Name']) else '',  # Ensure Name is a string or empty
                    str(ra_display),  # RA in either H:M:S or degrees format
                    str(dec_display),  # Dec in either H:M:S or degrees format
                    str(row['Altitude']) if pd.notna(row['Altitude']) else '',  # Altitude as string or empty
                    str(row['Azimuth']) if pd.notna(row['Azimuth']) else '',  # Azimuth as string or empty
                    str(int(row['Minutes to Transit'])) if pd.notna(row['Minutes to Transit']) else '',  # Minutes to Transit as integer string
                    before_after,  # Before/After Transit (already a string)
                    str(round(row['Degrees from Moon'], 2)) if pd.notna(row['Degrees from Moon']) else '',  # Degrees from Moon as rounded string or empty
                    row.get('Alt Name', '') if pd.notna(row.get('Alt Name', '')) else '',  # Alt Name as string or empty
                    row.get('Type', '') if pd.notna(row.get('Type', '')) else '',  # Type as string or empty
                    str(row.get('Magnitude', '')) if pd.notna(row.get('Magnitude', '')) else '',  # Magnitude as string or empty
                    str(size_arcmin) if pd.notna(size_arcmin) else ''  # Size in arcmin as string or empty
                ]

                # Use SortableTreeWidgetItem instead of QTreeWidgetItem
                item = SortableTreeWidgetItem(values)
                self.tree.addTopLevelItem(item)


    def update_status(self, message):
        self.status_label.setText(f"Status: {message}")

    def update_lst(self, message):
        self.lst_label.setText(message)


    def save_settings(self, latitude, longitude, date, time, timezone, min_altitude):
        self.settings.setValue("latitude", latitude)
        self.settings.setValue("longitude", longitude)
        self.settings.setValue("date", date)
        self.settings.setValue("time", time)
        self.settings.setValue("timezone", timezone)
        self.settings.setValue("min_altitude", min_altitude)
        print("Settings saved.")

    def load_settings(self):
        """Load settings from QSettings and populate UI fields."""
        def safe_cast(value, default, cast_type):
            """Safely cast a value to a specific type."""
            try:
                return cast_type(value)
            except (ValueError, TypeError):
                return default

        # Load and cast settings with fallbacks
        self.latitude = safe_cast(self.settings.value("latitude", 0.0), 0.0, float)
        self.longitude = safe_cast(self.settings.value("longitude", 0.0), 0.0, float)
        self.date = self.settings.value("date", datetime.now().strftime("%Y-%m-%d"))
        self.time = self.settings.value("time", "00:00:00")
        self.timezone = self.settings.value("timezone", "UTC")
        self.min_altitude = safe_cast(self.settings.value("min_altitude", 0.0), 0.0, float)
        self.object_limit = safe_cast(self.settings.value("object_limit", 100), 100, int)

        # Populate fields in the UI
        self.latitude_entry.setText(str(self.latitude))
        self.longitude_entry.setText(str(self.longitude))
        self.date_entry.setText(self.date)
        self.time_entry.setText(self.time)
        self.timezone_combo.setCurrentText(self.timezone)
        self.min_altitude_entry.setText(str(self.min_altitude))

        print("Settings loaded:", {
            "latitude": self.latitude,
            "longitude": self.longitude,
            "date": self.date,
            "time": self.time,
            "timezone": self.timezone,
            "min_altitude": self.min_altitude,
            "object_limit": self.object_limit,
        })




    def open_settings(self):
        object_limit, ok = QInputDialog.getInt(self, "Settings", "Enter number of objects to display:", value=self.object_limit, min=1, max=1000)
        if ok:
            self.object_limit = object_limit

    def treeview_sort_column(self, tv, col, reverse):
        l = [(tv.set(k, col), k) for k in tv.get_children('')]
        try:
            l.sort(key=lambda t: float(t[0]) if t[0] else float('inf'), reverse=reverse)
        except ValueError:
            l.sort(reverse=reverse)

        for index, (val, k) in enumerate(l):
            tv.move(k, '', index)

        tv.heading(col, command=lambda: self.treeview_sort_column(tv, col, not reverse))

    def on_row_double_click(self, item: QTreeWidgetItem, column: int):
        """Handle double-clicking an item in the tree view."""
        object_name = item.text(0).replace(" ", "")  # Assuming the name is in the first column
        search_url = f"https://www.astrobin.com/search/?q={object_name}"
        print(f"Opening URL: {search_url}")  # Debugging output
        webbrowser.open(search_url)

    def add_custom_object(self):
        # Gather information for the custom object
        name, ok_name = QInputDialog.getText(self, "Add Custom Object", "Enter object name:")
        if not ok_name or not name:
            return

        ra, ok_ra = QInputDialog.getDouble(self, "Add Custom Object", "Enter RA (in degrees):", decimals=3)
        if not ok_ra:
            return

        dec, ok_dec = QInputDialog.getDouble(self, "Add Custom Object", "Enter Dec (in degrees):", decimals=3)
        if not ok_dec:
            return

        # Create the custom object entry
        new_object = {
            "Name": name,
            "RA": ra,
            "Dec": dec,
            "Catalog": "User Defined",
            "Alt Name": "User Defined",
            "Type": "Custom",
            "Magnitude": "",
            "Info": ""
        }

        # Load the catalog, add the custom object, and save it back
        df = pd.read_csv(self.calc_thread.catalog_file, encoding='ISO-8859-1')
        df = pd.concat([df, pd.DataFrame([new_object])], ignore_index=True)
        df.to_csv(self.calc_thread.catalog_file, index=False, encoding='ISO-8859-1')
        self.update_status(f"Added custom object: {name}")

    def update_ra_dec_format(self):
        """Update the RA/Dec format in the tree based on the selected radio button."""
        is_degrees_format = self.ra_dec_degrees.isChecked()  # Check if degrees format is selected

        for i in range(self.tree.topLevelItemCount()):
            item = self.tree.topLevelItem(i)
            ra_value = item.text(1)  # RA is in the second column
            dec_value = item.text(2)  # Dec is in the third column

            try:
                if is_degrees_format:
                    # Convert H:M:S to degrees only if in H:M:S format
                    if ":" in ra_value:
                        # Conversion from H:M:S format to degrees
                        sky_coord = SkyCoord(ra=ra_value, dec=dec_value, unit=(u.hourangle, u.deg))
                        ra_display = str(round(sky_coord.ra.deg, 3))
                        dec_display = str(round(sky_coord.dec.deg, 3))
                    else:
                        # Already in degrees format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value
                else:
                    # Convert degrees to H:M:S only if in degrees format
                    if ":" not in ra_value:
                        # Conversion from degrees to H:M:S format
                        ra_deg = float(ra_value)
                        dec_deg = float(dec_value)
                        sky_coord = SkyCoord(ra=ra_deg * u.deg, dec=dec_deg * u.deg)
                        ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                        dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')
                    else:
                        # Already in H:M:S format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value

            except ValueError as e:
                print(f"Conversion error: {e}")
                ra_display = ra_value
                dec_display = dec_value
            except Exception as e:
                print(f"Unexpected error: {e}")
                ra_display = ra_value
                dec_display = dec_value

            # Update item with the new RA/Dec display format
            item.setText(1, ra_display)
            item.setText(2, dec_display)



    def save_to_csv(self):
        # Ask user where to save the CSV file
        file_path, _ = QFileDialog.getSaveFileName(self, "Save CSV File", "", "CSV files (*.csv);;All Files (*)")
        if file_path:
            # Extract data from QTreeWidget
            columns = [self.tree.headerItem().text(i) for i in range(self.tree.columnCount())]
            data = [columns]
            for i in range(self.tree.topLevelItemCount()):
                item = self.tree.topLevelItem(i)
                row = [item.text(j) for j in range(self.tree.columnCount())]
                data.append(row)

            # Convert data to DataFrame and save as CSV
            df = pd.DataFrame(data[1:], columns=data[0])
            df.to_csv(file_path, index=False)
            self.update_status(f"Data saved to {file_path}")

class SortableTreeWidgetItem(QTreeWidgetItem):
    def __lt__(self, other):
        # Get the column index being sorted
        column = self.treeWidget().sortColumn()

        # Columns with numeric data for custom sorting (adjust column indices as needed)
        numeric_columns = [3, 4, 5, 7, 10]  # Altitude, Azimuth, Minutes to Transit, Degrees from Moon, Magnitude

        # Check if the column is in numeric_columns for numeric sorting
        if column in numeric_columns:
            try:
                # Attempt to compare as floats
                return float(self.text(column)) < float(other.text(column))
            except ValueError:
                # If conversion fails, fall back to string comparison
                return self.text(column) < other.text(column)
        else:
            # Default string comparison for other columns
            return self.text(column) < other.text(column)


if __name__ == '__main__':
    # ——— Multiprocessing “freeze” support for Windows executables ———
    multiprocessing.freeze_support()
    multiprocessing.set_start_method('spawn', force=True)

    # Configure logging to capture errors for debugging
    logging.basicConfig(
        filename="astro_editing_suite.log",
        level=logging.ERROR,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Start Qt application
    app = QApplication(sys.argv)
    app.setWindowIcon(QIcon(icon_path))

    # ===================== SPLASH SCREEN CODE HERE =====================
    splash_pix = QPixmap(resource_path("astrosuite.png"))
    splash = QSplashScreen(splash_pix)
    splash.show()
    app.processEvents()

    QCoreApplication.setOrganizationName("Seti Astro")
    QCoreApplication.setApplicationName  ("Seti Astro Suite")

    for attempt in range(5):
        try:
            from astroquery.simbad import Simbad

            # ——— use the new, non-deprecated field names ———
            Simbad.add_votable_fields(
                'otype',         # short object type
                'otypes',        # verbose object type
                'mesdiameter',   # was 'diameter'
                'rvz_redshift',  # was 'z_value'
                'B',             # was 'flux(B)'
                'V',             # was 'flux(V)'
                'plx_value',     # was 'plx'
                'sp'             # spectral type
            )

            Simbad.ROW_LIMIT = 0    # no row limit
            Simbad.TIMEOUT   = 60   # seconds

            # if we get here, everything succeeded—stop retrying
            break

        except Exception as e:
            if attempt < 4:
                # wait a second and try again
                time.sleep(1)
            else:
                # last attempt failed: warn and move on
                print("Warning: SIMBAD service is currently unavailable. "
                    "SIMBAD-dependent features may be disabled.")
    try:
        # Initialize main window
        window = AstroEditingSuite()
        window.show()

        # Close the splash screen once the main window is ready
        splash.finish(window)

        sys.exit(app.exec())
    except Exception as e:
        logging.error("Unhandled exception occurred", exc_info=True)
        QMessageBox.critical(
            None,
            "Application Error",
            f"An unexpected error occurred:\n{str(e)}\n\nPlease check the log file for more details."
        )
        sys.exit(1)
