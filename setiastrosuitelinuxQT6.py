# fix_importlib_metadata.py
import sys
import importlib

if getattr(sys, 'frozen', False):
    # 1) Attempt to import both metadata modules
    try:
        std_md = importlib.import_module('importlib.metadata')
    except ImportError:
        std_md = None

    try:
        back_md = importlib.import_module('importlib_metadata')
    except ImportError:
        back_md = None

    # 2) Ensure that any "import importlib.metadata" or
    #    "import importlib_metadata" picks up our loaded module
    if std_md:
        sys.modules['importlib.metadata'] = std_md
        setattr(importlib, 'metadata', std_md)
    if back_md:
        sys.modules['importlib_metadata'] = back_md

    # 3) Pick whichever is available for defaults (prefer stdlib)
    meta = std_md or back_md
    if not meta:
        # nothing to patch
        sys.exit(0)

    # 4) Save originals
    orig_version      = getattr(meta, 'version', None)
    orig_distribution = getattr(meta, 'distribution', None)

    # 5) Define safe fallbacks
    def safe_version(pkg, *args, **kwargs):
        try:
            return orig_version(pkg, *args, **kwargs)
        except Exception:
            return "0.0.0"

    class DummyDist:
        version = "0.0.0"
        metadata = {}

    def safe_distribution(pkg, *args, **kwargs):
        try:
            return orig_distribution(pkg, *args, **kwargs)
        except Exception:
            return DummyDist()

    # 6) Patch both modules (stdlib and back-port) if they exist
    for m in (std_md, back_md):
        if not m:
            continue
        if orig_version:
            m.version = safe_version
        if orig_distribution:
            m.distribution = safe_distribution


import typing_extensions
import urllib



# Standard library imports
from itertools import combinations
from tifffile import imwrite

import pickle
import os
os.environ['LIGHTKURVE_STYLE'] = 'default'
import tempfile
import time
import json
import logging
import math
from datetime import datetime, timedelta, timezone
from decimal import getcontext
from urllib.parse import quote
from urllib.parse import quote_plus
import webbrowser
import warnings
import shutil
import subprocess
from xisf import XISF
import requests
import csv
import lz4.block
import zstandard
import base64
import ast
import platform
from pathlib import Path
import glob
from typing import List, Tuple, Dict, Set
import time
from datetime import datetime
import pywt
from io import BytesIO
import io
import re
from collections import defaultdict
from scipy.spatial import Delaunay, KDTree
from scipy.ndimage import gaussian_filter, laplace
import scipy.ndimage as ndi
import plotly.graph_objects as go
from scipy.ndimage import zoom
import multiprocessing
import matplotlib
matplotlib.use("QtAgg") 
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.colors import hsv_to_rgb
import numpy as np
from typing import List, Tuple, Optional
from skimage.restoration import richardson_lucy, denoise_bilateral, denoise_tv_chambolle
from skimage.color import rgb2gray, rgb2lab, lab2rgb
from skimage.transform import warp_polar, warp
from skimage import img_as_float32
from numpy.fft import fft2, ifft2, fftshift, ifftshift
from typing import Optional, Tuple, Callable
from scipy.signal import medfilt
import matplotlib.ticker as mtick
from scipy.interpolate import RBFInterpolator
import random
if sys.stdout is not None:
    sys.stdout.reconfigure(encoding='utf-8')

from astropy.stats import sigma_clipped_stats
from collections.abc import MutableMapping
from astropy.io.votable import parse_single_table
from astropy.timeseries import LombScargle, BoxLeastSquares
from photutils.detection import DAOStarFinder
from scipy.spatial import ConvexHull
from astropy.table import Table, vstack
from numba import njit, prange
from scipy.optimize import curve_fit
import exifread
from numba_utils import *
import astroalign
import gzip
import traceback
import sep
from astroquery.mast import Tesscut

from lightkurve import TessTargetPixelFile
import oktopus
import lightkurve as lk
from scipy.interpolate import griddata

lk.MPLSTYLE = None

from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed

from astropy.wcs.utils import skycoord_to_pixel
from astropy.coordinates import SkyCoord
from astropy import units as u
import itertools
from astropy.io.fits import Header
from pyvo.dal.exceptions import DALServiceError

# Reproject for WCS-based alignment
try:
    from reproject import reproject_interp
except ImportError:
    reproject_interp = None  # fallback if not installed

# OpenCV for transform estimation & warping
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False


# Third-party library imports
import requests
import numpy as np
import pandas as pd
import cv2
from PIL import Image, ImageDraw, ImageFont

# Astropy and Astroquery imports
from astropy.io import fits
from astropy.time import Time
from astropy.coordinates import SkyCoord, EarthLocation, AltAz, get_body, get_sun
import astropy.units as u
from astropy.wcs import WCS
from astroquery.simbad import Simbad
from astroquery.mast import Mast
from astroquery.vizier import Vizier
import tifffile as tiff
import pytz
from astropy.utils.data import conf

from scipy.interpolate import PchipInterpolator
from scipy.interpolate import Rbf
from scipy.ndimage import median_filter
from scipy.ndimage import convolve
from scipy.signal import fftconvolve
from scipy.interpolate import interp1d

import rawpy
import numpy.ma as ma

import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
from matplotlib.patches import Circle
from matplotlib.figure import Figure
from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as FigureCanvas


#################################
# PyQt6 Imports
#################################
from collections import defaultdict
import fnmatch
import pyqtgraph as pg
import psutil
from PyQt6.QtGui import QIntValidator
# ----- QtWidgets -----
from PyQt6.QtWidgets import (
    QApplication,
    QMainWindow,
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QLabel,
    QPushButton,
    QFileDialog,
    QGraphicsView,
    QGraphicsScene,
    QMessageBox,
    QInputDialog,
    QTreeWidget,
    QTreeWidgetItem,
    QGraphicsPolygonItem,
    QFrame,
    QToolTip,
    QCheckBox,
    QDialog,
    QFormLayout,
    QSpinBox,
    QDialogButtonBox,
    QGridLayout,
    QGraphicsEllipseItem,
    QGraphicsLineItem,
    QGraphicsRectItem,
    QGraphicsPathItem,
    QDoubleSpinBox,
    QColorDialog,
    QFontDialog,
    QStyle,
    QSlider,
    QTabWidget,
    QScrollArea,
    QSizePolicy,
    QSpacerItem,
    QAbstractItemView,
    QToolBar,
    QGraphicsPixmapItem,
    QRubberBand,
    QGroupBox,
    QGraphicsTextItem,
    QComboBox,
    QLineEdit,
    QRadioButton,
    QButtonGroup,
    QHeaderView,
    QStackedWidget,
    QSplitter,
    QMenuBar,
    QTextEdit,
    QPlainTextEdit,      
    QProgressBar,
    QGraphicsItem,
    QToolButton,
    QStatusBar,
    QMenu,
    QTableWidget,
    QTableWidgetItem,
    QListWidget,
    QListWidgetItem,
    QSplashScreen,
    QProgressDialog, 
    QDockWidget,
    QAbstractItemView,
    QStyledItemDelegate,
    QListView,
    QCompleter    
)

# ----- QtGui -----
from PyQt6.QtGui import (
    QPixmap,
    QImage,
    QPainter,
    QPen,
    QColor,
    QTransform,
    QIcon,
    QPainterPath,
    QKeySequence,
    QFont,
    QMovie,
    QCursor,
    QBrush,
    QShortcut,
    QPolygon,
    QFontMetrics,    
    QPolygonF,
    QKeyEvent,
    QPalette, 
    QWheelEvent, 
    QDoubleValidator,
    QFontDatabase,
    QGuiApplication,
    QStandardItemModel,
    QStandardItem,
    QAction  # NOTE: In PyQt6, QAction is in QtGui (moved from QtWidgets)
)

# ----- QtCore -----
from PyQt6.QtCore import (
    Qt,
    QRectF,
    QLineF,
    QPointF,
    QThread,
    pyqtSignal,
    QCoreApplication,
    QPoint,
    QTimer,
    QRect,
    QFileSystemWatcher,
    QEvent,
    pyqtSlot,
    QLocale,
    QProcess,
    QSize,
    QObject,
    QSettings,
    QRunnable,
    QThreadPool,
    QSignalBlocker,
    QStandardPaths,
    QModelIndex,
    QMetaObject
)


# Math functions
from math import sqrt
import math
from copy import deepcopy


VERSION = "2.21.7"


if hasattr(sys, '_MEIPASS'):
    # PyInstaller path
    icon_path = os.path.join(sys._MEIPASS, 'astrosuite.png')
    windowslogo_path = os.path.join(sys._MEIPASS, 'astrosuite.ico')
    green_path = os.path.join(sys._MEIPASS, 'green.png')
    neutral_path = os.path.join(sys._MEIPASS, 'neutral.png')
    whitebalance_path = os.path.join(sys._MEIPASS, 'whitebalance.png')
    morpho_path = os.path.join(sys._MEIPASS, 'morpho.png')
    clahe_path = os.path.join(sys._MEIPASS, 'clahe.png')
    starnet_path = os.path.join(sys._MEIPASS, 'starnet.png')
    staradd_path = os.path.join(sys._MEIPASS, 'staradd.png')
    LExtract_path = os.path.join(sys._MEIPASS, 'LExtract.png')
    LInsert_path = os.path.join(sys._MEIPASS, 'LInsert.png')
    slot0_path = os.path.join(sys._MEIPASS, 'slot0.png')
    slot1_path = os.path.join(sys._MEIPASS, 'slot1.png')
    slot2_path = os.path.join(sys._MEIPASS, 'slot2.png')
    slot3_path = os.path.join(sys._MEIPASS, 'slot3.png')
    slot4_path = os.path.join(sys._MEIPASS, 'slot4.png')
    rgbcombo_path = os.path.join(sys._MEIPASS, 'rgbcombo.png')
    rgbextract_path = os.path.join(sys._MEIPASS, 'rgbextract.png')
    copyslot_path = os.path.join(sys._MEIPASS, 'copyslot.png')
    graxperticon_path = os.path.join(sys._MEIPASS, 'graxpert.png')
    cropicon_path = os.path.join(sys._MEIPASS, 'cropicon.png')
    openfile_path = os.path.join(sys._MEIPASS, 'openfile.png')
    abeicon_path = os.path.join(sys._MEIPASS, 'abeicon.png')    
    undoicon_path = os.path.join(sys._MEIPASS, 'undoicon.png')  
    redoicon_path = os.path.join(sys._MEIPASS, 'redoicon.png')  
    blastericon_path = os.path.join(sys._MEIPASS, 'blaster.png')
    hdr_path = os.path.join(sys._MEIPASS, 'hdr.png')  
    invert_path = os.path.join(sys._MEIPASS, 'invert.png')  
    fliphorizontal_path = os.path.join(sys._MEIPASS, 'fliphorizontal.png')
    flipvertical_path = os.path.join(sys._MEIPASS, 'flipvertical.png')
    rotateclockwise_path = os.path.join(sys._MEIPASS, 'rotateclockwise.png')
    rotatecounterclockwise_path = os.path.join(sys._MEIPASS, 'rotatecounterclockwise.png')
    maskcreate_path = os.path.join(sys._MEIPASS, 'maskcreate.png')
    maskapply_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    maskremove_path = os.path.join(sys._MEIPASS, 'maskremove.png')
    slot5_path = os.path.join(sys._MEIPASS, 'slot5.png')
    slot6_path = os.path.join(sys._MEIPASS, 'slot6.png')
    slot7_path = os.path.join(sys._MEIPASS, 'slot7.png')
    slot8_path = os.path.join(sys._MEIPASS, 'slot8.png')
    slot9_path = os.path.join(sys._MEIPASS, 'slot9.png') 
    pixelmath_path = os.path.join(sys._MEIPASS, 'pixelmath.png')   
    histogram_path = os.path.join(sys._MEIPASS, 'histogram.png') 
    mosaic_path = os.path.join(sys._MEIPASS, 'mosaic.png')
    rescale_path = os.path.join(sys._MEIPASS, 'rescale.png')
    staralign_path = os.path.join(sys._MEIPASS, 'staralign.png')
    mask_path = os.path.join(sys._MEIPASS, 'maskapply.png')
    platesolve_path = os.path.join(sys._MEIPASS, 'platesolve.png')
    psf_path = os.path.join(sys._MEIPASS, 'psf.png')
    supernova_path = os.path.join(sys._MEIPASS, 'supernova.png')
    starregistration_path = os.path.join(sys._MEIPASS, 'starregistration.png')
    stacking_path = os.path.join(sys._MEIPASS, 'stacking.png')
    pedestal_icon_path = os.path.join(sys._MEIPASS, 'pedestal.png')
    starspike_path = os.path.join(sys._MEIPASS, 'starspike.png')
    aperture_path = os.path.join(sys._MEIPASS, 'aperture.png')
    jwstpupil_path = os.path.join(sys._MEIPASS, 'jwstpupil.png')
    signature_icon_path = os.path.join(sys._MEIPASS, 'pen.png')
    livestacking_path = os.path.join(sys._MEIPASS, 'livestacking.png')
    hrdiagram_path = os.path.join(sys._MEIPASS, 'HRDiagram.png')
    convoicon_path = os.path.join(sys._MEIPASS, 'convo.png')
    spcc_icon_path = os.path.join(sys._MEIPASS, 'spcc.png')
    sasp_data_path = os.path.join(sys._MEIPASS, 'SASP_data.fits')
    exoicon_path = os.path.join(sys._MEIPASS, 'exoicon.png')
    peeker_icon = os.path.join(sys._MEIPASS, 'gridicon.png')
    dse_icon_path = os.path.join(sys._MEIPASS, 'dse.png')
    astrobin_filters_csv_path = os.path.join(sys._MEIPASS, 'astrobin_filters.csv')
else:
    # Development path
    icon_path = 'astrosuite.png'
    windowslogo_path = 'astrosuite.ico'
    green_path = 'green.png'
    neutral_path = 'neutral.png'
    whitebalance_path = 'whitebalance.png'
    morpho_path = 'morpho.png'
    clahe_path = 'clahe.png'
    starnet_path = 'starnet.png'
    staradd_path = 'staradd.png'
    LExtract_path = 'LExtract.png'
    LInsert_path = 'LInsert.png'
    slot1_path = 'slot1.png'
    slot0_path = 'slot0.png'
    slot2_path = 'slot2.png'
    slot3_path  = 'slot3.png'
    slot4_path  = 'slot4.png'
    rgbcombo_path = 'rgbcombo.png'
    rgbextract_path = 'rgbextract.png'
    copyslot_path = 'copyslot.png'
    graxperticon_path = 'graxpert.png'
    cropicon_path = 'cropicon.png'
    openfile_path = 'openfile.png'
    abeicon_path = 'abeicon.png'
    undoicon_path = 'undoicon.png'
    redoicon_path = 'redoicon.png'
    blastericon_path = 'blaster.png'
    hdr_path = 'hdr.png'
    invert_path = 'invert.png'
    fliphorizontal_path = 'fliphorizontal.png'
    flipvertical_path = 'flipvertical.png'
    rotateclockwise_path = 'rotateclockwise.png'
    rotatecounterclockwise_path = 'rotatecounterclockwise.png'
    maskcreate_path = 'maskcreate.png'
    maskapply_path = 'maskapply.png'
    maskremove_path = 'maskremove.png'
    slot5_path = 'slot5.png'
    slot6_path = 'slot6.png'
    slot7_path = 'slot7.png'
    slot8_path  = 'slot8.png'
    slot9_path  = 'slot9.png'
    pixelmath_path = 'pixelmath.png'
    histogram_path = 'histogram.png'
    mosaic_path = 'mosaic.png'
    rescale_path = 'rescale.png'
    staralign_path = 'staralign.png'
    mask_path = 'maskapply.png'
    platesolve_path = 'platesolve.png'
    psf_path = 'psf.png'
    supernova_path = 'supernova.png'
    starregistration_path = 'starregistration.png'
    stacking_path = 'stacking.png'
    pedestal_icon_path = 'pedestal.png'
    starspike_path = 'starspike.png'
    aperture_path = 'aperture.png'
    jwstpupil_path = 'jwstpupil.png'
    signature_icon_path = 'pen.png'
    livestacking_path = 'livestacking.png'
    hrdiagram_path = 'HRDiagram.png'
    convoicon_path = 'convo.png'
    spcc_icon_path = 'spcc.png'
    sasp_data_path = 'SASP_data.fits'
    exoicon_path = 'exoicon.png'
    peeker_icon = 'gridicon.png'
    dse_icon_path = 'dse.png'
    astrobin_filters_csv_path = 'astrobin_filters.csv'


def announce_zoom(method):
    def wrapper(self, *args, **kwargs):
        # 1) invoke the real zoom method, swallowing any extra args
        try:
            result = method(self, *args, **kwargs)
        except TypeError:
            result = method(self)

        # 2) now compute the percent and show the tooltip
        try:
            pct = int(self.zoom_factor * 100)

            # look for either naming convention
            sa = getattr(self, "scrollArea", None) \
              or getattr(self, "scroll_area", None)

            if sa is not None:
                vp = sa.viewport()
                center_local  = vp.rect().center()
                center_global = vp.mapToGlobal(center_local)
                QToolTip.showText(center_global, f"{pct}%")
            else:
                # fallback to cursor-position
                QToolTip.showText(QCursor.pos(), f"{pct}%")
        except Exception as e:
            # silently ignore any tooltip failures
            print("announce_zoom tooltip error:", e)

        return result

    return wrapper

class AstroEditingSuite(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowIcon(QIcon(icon_path))
        self.setDockNestingEnabled(True)
        self.current_theme = "dark"  # Default theme
        self.image_manager = ImageManager(max_slots=10, parent=self)  # Initialize ImageManager
        self.mask_manager = self.image_manager.mask_manager
        self.image_manager.image_changed.connect(self.on_image_changed)
        self.settings = QSettings()   # Replace "Seti Astro" with your actual organization name
        self.starnet_exe_path = self.settings.value("starnet/exe_path", type=str)  # Load saved path if available
        self.preview_windows = {}
        self._convo_deconvo_window = None

        # NEW: Dictionary to store custom slot names (default names)
        self.slot_names = SlotNameProxy(self.image_manager)
        self.slot_actions = {}

        # NEW: Dictionary to store custom mask slot names (default names)
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}
        self.mask_slot_actions = {}

        # Initialize the mask banner
        self.mask_banner = QLabel()  # Initialize QLabel
        self.mask_banner.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.mask_banner.setText("Mask Applied: None")  # Default text
        self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
        self.mask_banner.setVisible(False)  # Hidden by default        

        # Initialize UI
        self.current_theme = self.settings.value("theme", "dark")  # Fallback to dark
        self.SFCC_window = None
        self.initUI()
        self.connect_mask_manager_signals()        

    def initUI(self):
        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Enable drag and drop
        self.setAcceptDrops(True)

        # Create a menu bar
        menubar = self.menuBar()  # Use the menu bar directly from QMainWindow

        # --------------------
        # File Menu
        # --------------------
        file_menu = menubar.addMenu("File")
        
        # Create File Menu Actions
        open_action = QAction("Open Image", self)
        open_action.setShortcut('Ctrl+O')
        open_action.setStatusTip('Open an image file')
        open_action.triggered.connect(self.open_image)
        
        save_action = QAction("Save As", self)
        save_action.setShortcut('Ctrl+S')
        save_action.setStatusTip('Save the image to disk')
        save_action.triggered.connect(self.save_image)
        
        undo_action = QAction("Undo", self)
        undo_action.setShortcut('Ctrl+Z')
        undo_action.setStatusTip('Undo the last action')
        undo_action.triggered.connect(self.undo_image)
        
        redo_action = QAction("Redo", self)
        redo_action.setShortcut('Ctrl+Y')
        redo_action.setStatusTip('Redo the last undone action')
        redo_action.triggered.connect(self.redo_image)
        
        exit_action = QAction("Exit", self)
        exit_action.setShortcut('Ctrl+Q')  # Common shortcut for Exit
        exit_action.setStatusTip('Exit the application')
        exit_action.triggered.connect(self.close)  # Close the application

        # --- New Project Actions ---
        save_project_action = QAction("Save Project", self)
        save_project_action.setStatusTip("Save the entire project (images, metadata, masks, etc.)")
        save_project_action.triggered.connect(self.save_project)
        
        open_project_action = QAction("Open Project", self)
        open_project_action.setStatusTip("Open a saved project")
        open_project_action.triggered.connect(self.open_project)   

        new_project_action = QAction("New Project", self)
        new_project_action.setStatusTip("Clear the current project and start a new project (this will erase all data)")
        new_project_action.triggered.connect(self.new_project)     

        # Add actions to the File menu
        file_menu.addAction(open_action)
        file_menu.addAction(save_action)
        file_menu.addSeparator()
        file_menu.addAction(undo_action)
        file_menu.addAction(redo_action)
        file_menu.addSeparator()
        file_menu.addAction(save_project_action)   # New action
        file_menu.addAction(open_project_action)   # New action
        file_menu.addAction(new_project_action) 
        file_menu.addSeparator()
        file_menu.addAction(exit_action)

        # --------------------
        # Themes Menu
        # --------------------
        theme_menu = menubar.addMenu("Themes")
        light_theme_action = QAction("Light Theme", self)
        dark_theme_action = QAction("Dark Theme", self)

        custom_theme_menu = QMenu("Custom Theme", self)
        create_custom_action = QAction("Create New", self)
        apply_custom_action = QAction("Apply Saved", self)
        reset_custom_action = QAction("Reset", self)

        # Connect all actions
        light_theme_action.triggered.connect(lambda: self.apply_theme("light"))
        dark_theme_action.triggered.connect(lambda: self.apply_theme("dark"))
        create_custom_action.triggered.connect(self.open_custom_theme_dialog)
        apply_custom_action.triggered.connect(lambda: self.apply_theme("custom"))
        reset_custom_action.triggered.connect(self.reset_custom_theme)

        # Add actions to submenu
        custom_theme_menu.addAction(create_custom_action)
        custom_theme_menu.addAction(apply_custom_action)
        custom_theme_menu.addSeparator()
        custom_theme_menu.addAction(reset_custom_action)

        # Add to top-level menu
        theme_menu.addAction(light_theme_action)
        theme_menu.addAction(dark_theme_action)
        theme_menu.addMenu(custom_theme_menu)

        # --------------------
        # Functions Menu
        # --------------------
        functions_menu = menubar.addMenu("Functions")

        # Add Histogram Action
        histogram_action = QAction(QIcon(histogram_path), "Histogram", self)
        histogram_action.setStatusTip("Show histogram of Slot 0")
        histogram_action.triggered.connect(self.open_histogram)
        functions_menu.addAction(histogram_action)

        gradient_removal_icon = QIcon(abeicon_path)  # Replace with the actual path variable
        gradient_removal_action = QAction(gradient_removal_icon, "Remove Gradient with SetiAstro ABE", self)
        gradient_removal_action.setShortcut('Ctrl+Shift+G')  # Assign a keyboard shortcut
        gradient_removal_action.setStatusTip('Remove gradient from the current image')
        gradient_removal_action.triggered.connect(self.remove_gradient)

        # Add the new action to the Functions menu
        functions_menu.addAction(gradient_removal_action)

        remove_gradient_action = QAction(QIcon(graxperticon_path), "Remove Gradient with GraXpert", self)
        remove_gradient_action.triggered.connect(self.remove_gradient_with_graxpert)
        functions_menu.addAction(remove_gradient_action)        
        
        # Add Crop to Functions menu
        crop_action = QAction(QIcon(cropicon_path), "Crop Image", self)
        crop_action.setShortcut('Ctrl+K')
        crop_action.setStatusTip('Crop the current image')
        crop_action.triggered.connect(self.open_crop_tool)
        functions_menu.addAction(crop_action)

        pedestal_icon = QIcon(pedestal_icon_path)  # Define pedestal_icon_path appropriately.
        pedestal_action = QAction(pedestal_icon, "Pedestal Remover", self)
        pedestal_action.setShortcut('Ctrl+P')  # Example shortcut
        pedestal_action.setStatusTip("Subtract the minimum value from the active image")
        pedestal_action.triggered.connect(self.remove_pedestal)

        functions_menu.addAction(pedestal_action)

        # Create Remove Green QAction
        remove_green_action = QAction("Remove Green", self)
        remove_green_action.setShortcut('Ctrl+G')  # Assign a keyboard shortcut
        remove_green_action.setStatusTip('Remove green noise from the image')
        remove_green_action.triggered.connect(self.open_remove_green_dialog)
        
        # Add Remove Green to Functions menu
        functions_menu.addAction(remove_green_action)

        background_neutralization_action = QAction("Background Neutralization", self)
        background_neutralization_action.setShortcut('Ctrl+N')  # Assign a keyboard shortcut
        background_neutralization_action.setStatusTip('Neutralize background colors based on a sample region')
        background_neutralization_action.triggered.connect(self.open_background_neutralization_dialog)
        
        # Add to Functions menu
        functions_menu.addAction(background_neutralization_action)        

        # White Balance Action
        whitebalance_action = QAction("White Balance", self)
        whitebalance_action.setShortcut('Ctrl+Shift+W')  # Assign a keyboard shortcut
        whitebalance_action.setStatusTip('Adjust white balance of the image')
        whitebalance_action.triggered.connect(self.open_whitebalance_dialog)
        
        # Add White Balance to Functions menu
        functions_menu.addAction(whitebalance_action)   

        spcc_action = QAction("SFCC (Color Calibration)", self)
        spcc_action.setShortcut('Ctrl+Shift+C')
        spcc_action.setStatusTip('Spectral‐Photometric Color Calibration')
        spcc_action.triggered.connect(self.SFCC_show)
        functions_menu.addAction(spcc_action)

        convo_icon = QIcon(convoicon_path)  # Set this to your 16×16 or 24×24 icon path
        self.convo_deconvo_action = QAction(convo_icon, "Convolution / Deconvolution", self)
        self.convo_deconvo_action.setStatusTip("Open Convolution & Deconvolution tool")
        self.convo_deconvo_action.triggered.connect(self.convo_deconvo_show)
        functions_menu.addAction(self.convo_deconvo_action)

        # Extract Luminance Action with Icon
        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.setShortcut('Ctrl+Shift+E')  # Assign a keyboard shortcut
        extract_luminance_action.setStatusTip('Extract luminance from the current image')
        extract_luminance_action.triggered.connect(self.extract_luminance)

        # Add Extract Luminance to Functions menu
        functions_menu.addAction(extract_luminance_action)

        # Recombine Luminance Action with Icon
        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.setShortcut('Ctrl+Shift+R')  # Assign a keyboard shortcut
        recombine_luminance_action.setStatusTip('Recombine luminance into the RGB image in slot 1')
        recombine_luminance_action.triggered.connect(self.recombine_luminance)

        # Add Recombine Luminance to Functions menu
        functions_menu.addAction(recombine_luminance_action)

        # RGB Combination Action
        rgb_combination_icon = QIcon(rgbcombo_path)
        rgb_combination_action = QAction(rgb_combination_icon, "RGB Combination", self)
        rgb_combination_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        rgb_combination_action.setStatusTip('Combine separate R, G, B images into an RGB image')
        rgb_combination_action.triggered.connect(self.rgb_combination)
        # Add RGB Combination to Functions menu
        functions_menu.addAction(rgb_combination_action)
        
        # RGB Extract Action
        rgb_extract_icon = QIcon(rgbextract_path)
        rgb_extract_action = QAction(rgb_extract_icon, "RGB Extract", self)
        rgb_extract_action.setShortcut('Ctrl+Shift+X')  # Assign a keyboard shortcut
        rgb_extract_action.setStatusTip('Extract R, G, B channels from an RGB image')
        rgb_extract_action.triggered.connect(self.rgb_extract)
        # Add RGB Extract to Functions menu
        functions_menu.addAction(rgb_extract_action)

        blemish_blaster_icon = QIcon(blastericon_path)  # Ensure 'blastericon_path' is correctly defined
        blemish_blaster_action = QAction(blemish_blaster_icon, "Blemish Blaster", self)
        blemish_blaster_action.setShortcut('Ctrl+B')  # Assign a keyboard shortcut (e.g., Ctrl+B)
        blemish_blaster_action.setStatusTip('Remove blemishes from the current image')
        blemish_blaster_action.triggered.connect(self.open_blemish_blaster)  # Connect to handler method

        # Add the Blemish Blaster action to the Functions menu
        functions_menu.addAction(blemish_blaster_action)

        hdr_icon = QIcon(hdr_path)
        hdr_action = QAction(hdr_icon, "WaveScale HDR", self)
        hdr_action.setShortcut('Ctrl+H')
        hdr_action.setStatusTip('Apply WaveScale HDR to the current image')
        hdr_action.triggered.connect(self.open_hdr_dialog)
        functions_menu.addAction(hdr_action)

        dse_action = QAction(QIcon(dse_icon_path), "WaveScale Dark Enhancer", self)
        dse_action.setShortcut("Ctrl+Shift+D")
        dse_action.setStatusTip("Enhance dark nebula and voids using wavelets")
        dse_action.triggered.connect(self.open_dse_dialog)
        functions_menu.addAction(dse_action)

        clahe_action = QAction("CLAHE", self)
        clahe_action.setShortcut('Ctrl+Shift+C')  # Assign a keyboard shortcut
        clahe_action.setStatusTip('Apply Contrast Limited Adaptive Histogram Equalization')
        clahe_action.triggered.connect(self.open_clahe_dialog)
        
        # Add CLAHE to Functions menu
        functions_menu.addAction(clahe_action)


        # Morphological Operations Action
        morpho_action = QAction("Morphological Operations", self)
        morpho_action.setShortcut('Ctrl+Shift+M')  # Assign a keyboard shortcut
        morpho_action.setStatusTip('Apply morphological operations to the image')
        morpho_action.triggered.connect(self.open_morpho_dialog)
        
        # Add Morphological Operations to Functions menu
        functions_menu.addAction(morpho_action)        

        remove_stars_action = QAction("Remove Stars", self)
        remove_stars_action.setShortcut('Ctrl+R')  # Assign a keyboard shortcut
        remove_stars_action.setStatusTip('Remove stars from the image using StarNet')
        remove_stars_action.triggered.connect(self.remove_stars)

        # Add Remove Stars to Functions menu
        functions_menu.addAction(remove_stars_action)

        add_stars_action = QAction("Add Stars", self)
        add_stars_action.setShortcut('Ctrl+A')  # Assign a keyboard shortcut
        add_stars_action.setStatusTip('Add stars back to the current image')
        add_stars_action.triggered.connect(self.add_stars)

        # Add Add Stars to Functions menu
        functions_menu.addAction(add_stars_action)   

        # Pixel Math Action
        pixel_math_action = QAction(QIcon(pixelmath_path), "Pixel Math", self)
        pixel_math_action.setStatusTip("Perform pixel math operations on the current image")
        pixel_math_action.triggered.connect(self.open_pixel_math_dialog)
        functions_menu.addAction(pixel_math_action)         

        self.signature_insert_action = QAction(QIcon(signature_icon_path), "Signature/Insert", self)
        self.signature_insert_action.setStatusTip("Open Signature/Insert tool")
        self.signature_insert_action.triggered.connect(self.open_signature_insert_window)
        functions_menu.addAction(self.signature_insert_action)
        

        # --------------------
        # Geometry Menu
        # --------------------
        geometry_menu = menubar.addMenu("Geometry")

        invert_icon = QIcon(invert_path)  # Ensure 'invert_path' is correctly defined
        invert_action = QAction(invert_icon, "Invert Image", self)
        invert_action.setShortcut("Ctrl+I")
        invert_action.setStatusTip("Invert the colors of the current image")
        invert_action.triggered.connect(self.invert_image)

        # Add the Invert action to the Functions menu
        geometry_menu.addAction(invert_action)


        # Flip Horizontal Action
        flip_horizontal_icon = QIcon(fliphorizontal_path)
        flip_horizontal_action = QAction(flip_horizontal_icon, "Flip Horizontal", self)
        flip_horizontal_action.setShortcut("Ctrl+Shift+H")
        flip_horizontal_action.setStatusTip("Flip the current image horizontally")
        flip_horizontal_action.triggered.connect(self.flip_horizontal)

        # Add to Functions menu
        geometry_menu.addAction(flip_horizontal_action)



        # Flip Vertical Action
        flip_vertical_icon = QIcon(flipvertical_path)
        flip_vertical_action = QAction(flip_vertical_icon, "Flip Vertical", self)
        flip_vertical_action.setShortcut("Ctrl+Shift+V")
        flip_vertical_action.setStatusTip("Flip the current image vertically")
        flip_vertical_action.triggered.connect(self.flip_vertical)

        # Add to Functions menu
        geometry_menu.addAction(flip_vertical_action)



        # Rotate Clockwise Action
        rotate_clockwise_icon = QIcon(rotateclockwise_path)
        rotate_clockwise_action = QAction(rotate_clockwise_icon, "Rotate Clockwise", self)
        rotate_clockwise_action.setShortcut("Ctrl+Shift+R")
        rotate_clockwise_action.setStatusTip("Rotate the current image 90° clockwise")
        rotate_clockwise_action.triggered.connect(self.rotate_clockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_clockwise_action)


        # Rotate Counterclockwise Action
        rotate_counterclockwise_icon = QIcon(rotatecounterclockwise_path)
        rotate_counterclockwise_action = QAction(rotate_counterclockwise_icon, "Rotate Counterclockwise", self)
        rotate_counterclockwise_action.setShortcut("Ctrl+Shift+L")
        rotate_counterclockwise_action.setStatusTip("Rotate the current image 90° counterclockwise")
        rotate_counterclockwise_action.triggered.connect(self.rotate_counterclockwise)

        # Add to Functions menu
        geometry_menu.addAction(rotate_counterclockwise_action)

        #rescale
        rescale_action = QAction("Rescale", self)
        rescale_action.setIcon(QIcon(rescale_path))
        rescale_action.setStatusTip("Rescale the current image by a custom factor")
        rescale_action.triggered.connect(self.rescale_image)
        geometry_menu.addAction(rescale_action)

        # --------------------
        # Slot Menu
        # --------------------
        slot_menu = menubar.addMenu("Slots")

        # Dictionary to store menubar slot actions
        self.menubar_slot_actions = {}

        num_slots = self.image_manager.max_slots

        for slot in range(num_slots):
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            slot_icon = QIcon(slot_icon_path)
            
            slot_name = self.slot_names.get(slot, f"Slot {slot}")

            # Create QAction for the menubar slot
            slot_action = QAction(slot_icon, slot_name, self)
            slot_action.setStatusTip(f"Open preview for {slot_name}")
            slot_action.triggered.connect(lambda checked, s=slot: self.open_preview_window(s))
            
            # Store menubar slot actions for later updates
            self.menubar_slot_actions[slot] = slot_action

            # Add to menu
            slot_menu.addAction(slot_action)

        # Separator & Rename Slot Action
        slot_menu.addSeparator()
        rename_slot_action = QAction("Rename Slot", self)
        rename_slot_action.setStatusTip("Rename a slot with a custom name")
        rename_slot_action.triggered.connect(self.rename_slot)
        slot_menu.addAction(rename_slot_action)


        # --------------------
        # Mask Menu
        # --------------------
        masks_menu = menubar.addMenu("&Masks")

        maskcreate_path = resource_path('maskcreate.png')
        maskapply_path = resource_path('maskapply.png')
        maskremove_path = resource_path('maskremove.png')

        maskcreate_icon = QIcon(maskcreate_path)
        maskapply_icon = QIcon(maskapply_path)
        maskremove_icon = QIcon(maskremove_path)

        # Create Mask Actions
        create_mask_action = QAction(maskcreate_icon, "Create Mask", self)
        create_mask_action.setStatusTip("Create a new mask for the current image")
        create_mask_action.triggered.connect(self.create_mask)

        apply_mask_action = QAction(maskapply_icon, "Apply Mask", self)
        apply_mask_action.setStatusTip("Apply the selected mask to the image")
        apply_mask_action.triggered.connect(self.apply_mask)

        remove_mask_action = QAction(maskremove_icon, "Remove Mask", self)
        remove_mask_action.setStatusTip("Remove the currently applied mask")
        remove_mask_action.triggered.connect(self.remove_mask)

        # Add Mask Actions to Masks Menu
        masks_menu.addAction(create_mask_action)
        masks_menu.addAction(apply_mask_action)
        masks_menu.addAction(remove_mask_action)

        # Add Load Mask action
        load_mask_action = QAction("Load Mask", self)
        load_mask_action.triggered.connect(self.load_mask)
        masks_menu.addAction(load_mask_action)

        # Add Save Mask action
        save_mask_action = QAction("Save Mask", self)
        save_mask_action.triggered.connect(self.save_mask)
        masks_menu.addAction(save_mask_action)

        # Mask Slots Submenu
        mask_slots_menu = masks_menu.addMenu("Mask Slots")


        for slot in range(5):  # Five mask slots (0-4)
            # Use the custom name from the dictionary
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            slot_action = QAction(mask_slot_name, self)
            slot_action.triggered.connect(lambda checked, s=slot: self.preview_mask_slot(s))
            mask_slots_menu.addAction(slot_action)
            self.mask_slot_actions[slot] = slot_action

        # Add a separator and a "Rename Mask Slot" action
        mask_slots_menu.addSeparator()
        rename_mask_slot_action = QAction("Rename Mask Slot", self)
        rename_mask_slot_action.setStatusTip("Rename a mask slot with a custom name")
        rename_mask_slot_action.triggered.connect(self.rename_mask_slot)
        mask_slots_menu.addAction(rename_mask_slot_action)

        # --------------------
        # Star Stuff Menu
        # --------------------
        mosaic_menu = menubar.addMenu("Star Stuff")

        peeker_action = QAction(QIcon(peeker_icon), "Image Peeker…", self)
        peeker_action.setStatusTip("Peek at your image in an n×n grid of panels")
        peeker_action.triggered.connect(self.open_image_peeker)
        mosaic_menu.addAction(peeker_action)

        # Stacking Suite Action (New!)
        stacking_suite_action = QAction(QIcon(stacking_path), "Stacking Suite", self)
        stacking_suite_action.setStatusTip("Calibrate and stack images with advanced methods")
        stacking_suite_action.triggered.connect(self.stacking_suite_action)
        mosaic_menu.addAction(stacking_suite_action)

        live_stacking_action = QAction(QIcon(livestacking_path), "Live Stacking", self)
        live_stacking_action.setStatusTip("Open the Live Stacking interface")
        live_stacking_action.triggered.connect(self.live_stacking)
        mosaic_menu.addAction(live_stacking_action)

        mosaic_master_action = QAction(QIcon(mosaic_path), "Mosaic Master", self)
        mosaic_master_action.setStatusTip("Create a mosaic from multiple images.")
        mosaic_master_action.triggered.connect(self.open_mosaic_master)

        mosaic_menu.addAction(mosaic_master_action)

        # Stellar Alignment Action (added to Mosaic menu and toolbar)
        stellar_align_action = QAction(QIcon(staralign_path), "Stellar Alignment", self)
        stellar_align_action.setStatusTip("Align the target image to the source image using star alignment")
        stellar_align_action.triggered.connect(self.stellar_alignment)
        mosaic_menu.addAction(stellar_align_action)

        star_registration_action = QAction(QIcon(starregistration_path), "Star Registration", self)
        star_registration_action.setStatusTip("Register multiple images based on star alignment")
        star_registration_action.triggered.connect(self.star_registration)
        mosaic_menu.addAction(star_registration_action)        

        plate_solver_action = QAction(QIcon(platesolve_path), "Plate Solver", self)
        plate_solver_action.setStatusTip("Perform plate solving on an image")
        plate_solver_action.triggered.connect(self.launch_plate_solver)
        mosaic_menu.addAction(plate_solver_action)      

        # PSF Viewer Action (New!)
        psf_viewer_action = QAction(QIcon(psf_path), "PSF Viewer", self)
        psf_viewer_action.setStatusTip("View PSF histograms and star statistics")
        psf_viewer_action.triggered.connect(self.psf_viewer)
        mosaic_menu.addAction(psf_viewer_action)        

        # Supernova Action (New!)
        supernova_action = QAction(QIcon(supernova_path), "SuperNova Asteroid Hunter", self)
        supernova_action.setStatusTip("Hunt for anomalies in your images")
        supernova_action.triggered.connect(self.open_supernova_hunter)
        mosaic_menu.addAction(supernova_action)    

        star_spike_icon = QIcon(starspike_path)  # the path to your star spike icon
        star_spike_action = QAction(star_spike_icon, "Star Spike Tool", self)
        star_spike_action.setStatusTip("Add diffraction spikes to stars in the active image")
        star_spike_action.triggered.connect(self.starspiketool)  # connects to the method below
        mosaic_menu.addAction(star_spike_action)

        exo_action = QAction(QIcon(exoicon_path), "Exoplanet Detector", self)
        exo_action.setStatusTip("Detect exoplanet transits from a series of images")
        exo_action.triggered.connect(self.exoplanet_detect)
        mosaic_menu.addAction(exo_action)


        # --------------------
        # Toolbar
        # --------------------
        filebar = QToolBar("File Toolbar")
        filebar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(filebar)

        # Add Open File icon and action
        open_icon = QIcon(openfile_path)  # Replace with the actual path to your "Open File" icon
        open_action = QAction(open_icon, "Open File", self)
        open_action.setStatusTip("Open an image file")
        open_action.triggered.connect(self.open_image)  # Connect to the existing open_image method
        filebar.addAction(open_action)

        # Add Save As disk icon and action
        save_as_icon = QIcon(disk_icon_path)  # Replace with the actual path to your "Save As" icon
        save_as_action = QAction(save_as_icon, "Save As", self)
        save_as_action.setStatusTip("Save the current image")
        save_as_action.triggered.connect(self.save_image)  # Connect to the existing save_image method
        filebar.addAction(save_as_action)

        # Add Undo icon and action
        undo_icon = QIcon(undoicon_path)
        self.undo_action_toolbar = QAction(undo_icon, "Undo", self)
        self.undo_action_toolbar.setStatusTip("Undo the last action")
        self.undo_action_toolbar.triggered.connect(self.undo_image)
        filebar.addAction(self.undo_action_toolbar)

        # Add Redo icon and action
        redo_icon = QIcon(redoicon_path)
        self.redo_action_toolbar = QAction(redo_icon, "Redo", self)
        self.redo_action_toolbar.setStatusTip("Redo the last undone action")
        self.redo_action_toolbar.triggered.connect(self.redo_image)
        filebar.addAction(self.redo_action_toolbar)

        toolbar = QToolBar("Main Toolbar")
        toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(toolbar)
        

        # Add "Copy Slot" Button to Toolbar with Icon
        copy_slot_icon = QIcon(copyslot_path)  # Ensure 'copyslot.png' is the correct path
        copy_slot_action = QAction(copy_slot_icon, "Copy Slot", self)
        copy_slot_action.setStatusTip("Copy the current image in Slot 0 to another slot")
        copy_slot_action.triggered.connect(self.copy_slot_to_target)
        toolbar.addAction(copy_slot_action)

        toolbar.addAction(histogram_action)

        crop_icon = QIcon(cropicon_path)
        crop_action.setIcon(crop_icon)
        toolbar.addAction(crop_action)

        toolbar.addAction(gradient_removal_action)

        remove_gradient_icon = QIcon(graxperticon_path)
        remove_gradient_action.setIcon(remove_gradient_icon)
        remove_gradient_action.setStatusTip("Remove Gradient with GraXpert AI")
        toolbar.addAction(remove_gradient_action)

        # Add Remove Stars Button to Toolbar with Icon
        remove_stars_icon = QIcon(starnet_path)
        remove_stars_action.setIcon(remove_stars_icon)  # Set the icon to the QAction
        remove_stars_action.setToolTip("Remove Stars using StarNet")
        toolbar.addAction(remove_stars_action)  # Add the same QAction to the toolbar

        # Add Add Stars Button to Toolbar with Icon
        add_stars_icon = QIcon(staradd_path)
        add_stars_action.setIcon(add_stars_icon)  # Set the icon to the QAction
        add_stars_action.setToolTip("Add Stars back to the image")
        toolbar.addAction(add_stars_action)  # Add the same QAction to the toolbar

        pedestal_icon = QIcon(pedestal_icon_path)  # Define pedestal_icon_path appropriately.
        pedestal_action = QAction(pedestal_icon, "Pedestal Remover", self)
        pedestal_action.setShortcut('Ctrl+P')  # Example shortcut
        pedestal_action.setStatusTip("Subtract the minimum value from the active image")
        pedestal_action.triggered.connect(self.remove_pedestal)
        toolbar.addAction(pedestal_action)

        # Add "Remove Green" Button to Toolbar with Icon
        remove_green_icon = QIcon(green_path)
        remove_green_action.setIcon(remove_green_icon)  # Set the icon to the QAction
        toolbar.addAction(remove_green_action)  # Add the same QAction to the toolbar

        # Add "Background Neutralization" Button to Toolbar with Icon
        background_neutralization_icon = QIcon(neutral_path)
        background_neutralization_action.setIcon(background_neutralization_icon)  # Set the icon
        background_neutralization_action.setToolTip("Neutralize background colors based on a sample region.")
        toolbar.addAction(background_neutralization_action)  # Add the QAction to the toolbar

        # Add White Balance Button to Toolbar with Icon
        whitebalance_icon = QIcon(whitebalance_path)
        whitebalance_action.setIcon(whitebalance_icon)
        whitebalance_action.setToolTip("Adjust white balance of the image.")
        toolbar.addAction(whitebalance_action)

        spcc_icon = QIcon(spcc_icon_path)  # point this at whatever icon you like
        spcc_action.setIcon(spcc_icon)
        spcc_action.setToolTip("Launch SFCC dialog")
        toolbar.addAction(spcc_action)

        toolbar.addAction(self.convo_deconvo_action)

        extract_luminance_icon = QIcon(LExtract_path)
        extract_luminance_action = QAction(extract_luminance_icon, "Extract Luminance", self)
        extract_luminance_action.triggered.connect(self.extract_luminance)
        toolbar.addAction(extract_luminance_action)

        recombine_luminance_icon = QIcon(LInsert_path)
        recombine_luminance_action = QAction(recombine_luminance_icon, "Recombine Luminance", self)
        recombine_luminance_action.triggered.connect(self.recombine_luminance)
        toolbar.addAction(recombine_luminance_action)

        # Add RGB Combination Button to Toolbar
        toolbar.addAction(rgb_combination_action)

        # Add RGB Extract Button to Toolbar
        toolbar.addAction(rgb_extract_action)

        toolbar.addAction(blemish_blaster_action)

        toolbar.addAction(hdr_action)

        toolbar.addAction(dse_action)

        # Add CLAHE Button to Toolbar with Icon
        clahe_icon = QIcon(clahe_path)
        clahe_action.setIcon(clahe_icon)
        clahe_action.setToolTip("Apply Contrast Limited Adaptive Histogram Equalization.")
        toolbar.addAction(clahe_action)      

        # Add Morphological Operations Button to Toolbar with Icon
        morpho_icon = QIcon(morpho_path)
        morpho_action.setIcon(morpho_icon)
        morpho_action.setToolTip("Apply morphological operations to the image.")
        toolbar.addAction(morpho_action)    

        toolbar.addAction(pixel_math_action)

        toolbar.addAction(self.signature_insert_action)        

        geometrybar = QToolBar("Geometry Toolbar")

        geometrybar.addAction(invert_action)
        self.addToolBar(geometrybar)

        geometrybar.addAction(flip_horizontal_action)
        geometrybar.addAction(flip_vertical_action)        
        geometrybar.addAction(rotate_clockwise_action)
        geometrybar.addAction(rotate_counterclockwise_action)    
        geometrybar.addAction(rescale_action)

        # --------------------
        # Star Stuff Toolbar
        # --------------------        
        mosaictoolbar = QToolBar("Star Stuff Toolbar")
        mosaictoolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mosaictoolbar)  
        mosaictoolbar.addAction(peeker_action)
        mosaictoolbar.addAction(stacking_suite_action)  
        mosaictoolbar.addAction(live_stacking_action)    
        mosaictoolbar.addAction(mosaic_master_action)    
        mosaictoolbar.addAction(stellar_align_action)
        mosaictoolbar.addAction(star_registration_action)
        mosaictoolbar.addAction(plate_solver_action)
        mosaictoolbar.addAction(psf_viewer_action)     
        mosaictoolbar.addAction(supernova_action)   
        mosaictoolbar.addAction(star_spike_action)
        mosaictoolbar.addAction(exo_action)
        
        # --------------------
        # Mask Toolbar
        # --------------------
        mask_toolbar = QToolBar("Mask Toolbar")
        mask_toolbar.setAllowedAreas(Qt.ToolBarArea.AllToolBarAreas)
        self.addToolBar(Qt.ToolBarArea.TopToolBarArea, mask_toolbar)

        # Add Mask Actions to Mask Toolbar
        mask_toolbar.addAction(create_mask_action)
        mask_toolbar.addAction(apply_mask_action)
        mask_toolbar.addAction(remove_mask_action)
        
        # Create a toolbar for slots and dock it on the left side.
        self.slot_toolbar = QToolBar("Slot Toolbar", self)
        self.slot_toolbar.setAllowedAreas(Qt.ToolBarArea.LeftToolBarArea)
        self.slot_toolbar.setOrientation(Qt.Orientation.Vertical)  # Vertical layout
        self.addToolBar(Qt.ToolBarArea.LeftToolBarArea, self.slot_toolbar)

        # Create a button for each slot
        for slot in range(self.image_manager.max_slots):
            # Create a QToolButton for this slot.
            button = QToolButton()
            
            # Retrieve the icon path using getattr. This will look for an attribute
            # like 'slot0_path', 'slot1_path', etc., in your module, defaulting to 'slot0.png'
            slot_icon_path = getattr(sys.modules[__name__], f'slot{slot}_path', 'slot0.png')
            
            # Set the icon and optionally an icon size
            button.setIcon(QIcon(slot_icon_path))
            button.setIconSize(QSize(32, 32))  # Adjust the size as needed
            
            # Set the slot text and style (text below the icon)
            button.setText(self.slot_names[slot])
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Connect the normal (left-click) signal.
            button.clicked.connect(lambda checked, s=slot: self.set_active_slot(s))
            
            # Enable the custom context menu.
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_slot_context_menu(pos, s))
            
            # Add the button to the toolbar and store a reference.
            self.slot_toolbar.addWidget(button)
            self.slot_actions[slot] = button


        # --- Add a dummy separator button with the mask icon ---

        separator_button = QToolButton()
        separator_button.setIcon(QIcon(mask_path))
        separator_button.setIconSize(QSize(64, 64))
        separator_button.setEnabled(False)  # Disable so it doesn't respond to clicks.
        separator_button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonIconOnly)
        self.slot_toolbar.addWidget(separator_button)

        # --- Create mask slot buttons ---
        for slot in range(5):  # Assuming 5 mask slots (0-4)
            button = QToolButton()
            mask_slot_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            button.setText(mask_slot_name)
            # Optionally, set an icon for mask slots:
            # button.setIcon(QIcon("mask_icon.png"))
            button.setToolButtonStyle(Qt.ToolButtonStyle.ToolButtonTextUnderIcon)
            
            # Left-click: apply the mask in that slot.
            button.clicked.connect(lambda checked, s=slot: self.apply_mask_from_slot(s))
            
            # Right-click: open a context menu with "Preview Mask Slot" and "Rename Mask Slot".
            button.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
            button.customContextMenuRequested.connect(lambda pos, s=slot: self.show_mask_slot_context_menu(pos, s))
            
            self.slot_toolbar.addWidget(button)
            self.mask_slot_actions[slot] = button            

        # Highlight the default active slot.
        self.update_slot_toolbar_highlight()

        # --------------------
        # Status Bar
        # --------------------
        self.statusBar = QStatusBar(self)
        self.setStatusBar(self.statusBar)

        # File label (left side)
        self.file_name_label = QLabel("No file selected")
        self.statusBar.addWidget(self.file_name_label)  # Adds on the left

        # Create a container widget for the active slot label in the center.
        middleWidget = QWidget()
        middleLayout = QHBoxLayout(middleWidget)
        middleLayout.setContentsMargins(0, 0, 0, 0)  # Remove extra margins
        # Add stretch before and after the active slot label to center it.
        middleLayout.addStretch(1)
        self.active_slot_label = QLabel("Active Slot: 0")
        middleLayout.addWidget(self.active_slot_label)
        middleLayout.addStretch(1)
        # Add the middle widget with an expanding stretch factor (here using 1)
        self.statusBar.addWidget(middleWidget, 1)

        # Dimension label (right side)
        self.dim_label = QLabel("0 x 0")
        self.statusBar.addPermanentWidget(self.dim_label)  # Adds on the right

        # Connect the image_manager's signal to update the active slot label.
        self.image_manager.current_slot_changed.connect(self.update_active_slot_label)

        # --------------------
        # Tab Widget
        # --------------------
        self.tabs = QTabWidget()
        # Add individual tabs for each tool
        self.tabs.addTab(XISFViewer(image_manager=self.image_manager), "Image Viewer")
        self.tabs.addTab(BlinkTab(image_manager=self.image_manager), "Blink Comparator")
        self.tabs.addTab(CosmicClarityTab(image_manager=self.image_manager), "Cosmic Clarity")
        self.tabs.addTab(CosmicClaritySatelliteTab(), "Cosmic Clarity Satellite")
        self.tabs.addTab(StatisticalStretchTab(image_manager=self.image_manager), "Statistical Stretch")
        self.curves_tab = FullCurvesTab(image_manager=self.image_manager)
        self.tabs.addTab(self.curves_tab, "Curves Utility")
        self.tabs.addTab(PerfectPalettePickerTab(image_manager=self.image_manager, parent=self), "Perfect Palette Picker")
        self.tabs.addTab(NBtoRGBstarsTab(image_manager=self.image_manager, parent=self), "NB to RGB Stars")
        self.tabs.addTab(StarStretchTab(image_manager=self.image_manager), "Star Stretch")
        self.tabs.addTab(FrequencySeperationTab(image_manager=self.image_manager), "Frequency Separation")
        self.tabs.addTab(HaloBGonTab(image_manager=self.image_manager), "Halo-B-Gon")
        self.tabs.addTab(ContinuumSubtractTab(image_manager=self.image_manager, parent=self), "Continuum Subtraction")
        self.tabs.addTab(ImageCombineTab(image_manager=self.image_manager), "Image Combination")
        self.wimi_tab = MainWindow()
        self.tabs.addTab(self.wimi_tab, "What's In My Image")
        self.tabs.addTab(WhatsInMySky(), "What's In My Sky")
        self.tabs.currentChanged.connect(self.on_tab_changed)

        self.curveDock = QDockWidget("Curves Editor", self)
        # let it live on either side
        self.curveDock.setAllowedAreas(
            Qt.DockWidgetArea.LeftDockWidgetArea |
            Qt.DockWidgetArea.RightDockWidgetArea
        )
        # put the actual CurveEditor widget into the dock
        
        self.curveDock.setWidget(self.curves_tab.curveDialog)
        # default dock on the right
        self.addDockWidget(Qt.DockWidgetArea.RightDockWidgetArea, self.curveDock)

        # Set the layout for the main window
        central_widget = QWidget(self)  # Create a central widget
        layout = QVBoxLayout(central_widget)

        layout.addWidget(self.mask_banner)  # Add banner to the layout        
        layout.addWidget(self.tabs)  # Add tabs to the central widget

        # Set the central widget of the main window
        self.setCentralWidget(central_widget)

        # --------------------
        # Quick Navigation Menu
        # --------------------
        quicknav_menu = menubar.addMenu("Quick Navigation")
        for i in range(self.tabs.count()):
            tab_title = self.tabs.tabText(i)
            action = QAction(tab_title, self)
            # Use lambda with default argument to capture the current value of i
            action.triggered.connect(lambda checked, index=i: self.tabs.setCurrentIndex(index))
            quicknav_menu.addAction(action)

        # --------------------
        # FITS Modifier Menu + Toolbar
        # --------------------
        fits_menu = menubar.addMenu("Header Mod && Export")

        self.fits_edit_action = QAction("FITS Header Modifier…", self)
        self.fits_edit_action.setStatusTip("View and edit FITS header for the active image slot")
        self.fits_edit_action.triggered.connect(self.open_fits_modifier)
        fits_menu.addAction(self.fits_edit_action)

        self.astrobin_export_action = QAction("AstroBin Acquisition Exporter…", self)
        self.astrobin_export_action.setStatusTip("Compile FITS headers into AstroBin acquisition CSV")
        self.astrobin_export_action.triggered.connect(self.open_astrobin_exporter)
        fits_menu.addAction(self.astrobin_export_action)

        self.batch_rename_action = QAction("Batch Rename from FITS…", self)
        self.batch_rename_action.setStatusTip("Rename multiple files using FITS header keywords")
        self.batch_rename_action.triggered.connect(self.open_batch_renamer)
        fits_menu.addAction(self.batch_rename_action)        

        # --------------------
        # History Menu
        # --------------------
        history_menu = menubar.addMenu("History")
        view_history_action = QAction("View Undo History", self)
        view_history_action.setStatusTip("View all previous steps for the current slot")
        view_history_action.triggered.connect(self.show_history_dialog)
        history_menu.addAction(view_history_action)

        # --------------------
        # Preferences Menu
        # --------------------
        preferences_menu = menubar.addMenu("Preferences")
        preferences_action = QAction("Open Preferences", self)
        preferences_action.setStatusTip('Modify application settings')
        preferences_action.triggered.connect(self.open_preferences_dialog)
        preferences_menu.addAction(preferences_action)

        update_menu = menubar.addMenu("Update")
        check_update_action = QAction("Check for Updates", self)
        check_update_action.triggered.connect(self.check_for_updates)
        update_menu.addAction(check_update_action)

        # Help Menu with About action
        help_menu = menubar.addMenu("About")
        about_action = QAction("About", self)
        about_action.setStatusTip("About AstroEditingSuite")
        about_action.triggered.connect(self.show_about_dialog)
        help_menu.addAction(about_action)

        self._install_command_search()

        # --------------------
        # Apply Default Theme
        # --------------------
        self.apply_theme(self.current_theme)

        # --------------------
        # Window Properties
        # --------------------
        self.setWindowTitle(f'Seti Astro\'s Suite V{VERSION} QT6')

        self.check_for_updatesstartup()  # Call this in your app's init
        self.update_slot_toolbar_highlight()
        self.curveDock.hide()

    def _install_command_search(self):
        mb = self.menuBar()
        # Harmless on Windows, required on macOS for corner widgets to show
        mb.setNativeMenuBar(False)

        # Remove any previous corner widget (just in case)
        old = mb.cornerWidget(Qt.Corner.TopRightCorner)
        if old is not None:
            old.deleteLater()

        # --- holder so width is respected ---
        holder = QWidget(mb)
        lay = QHBoxLayout(holder)
        lay.setContentsMargins(0, 0, 6, 0)      # a little right padding
        lay.setSpacing(6)

        self._cmd_edit = QLineEdit(holder)
        self._cmd_edit.setPlaceholderText("Search commands…  (Ctrl+Shift+P)")
        self._cmd_edit.setClearButtonEnabled(True)
        self._cmd_edit.setMinimumWidth(250)     # make it wide
        self._cmd_edit.setMaximumWidth(600)     # optional cap
        self._cmd_edit.setSizePolicy(QSizePolicy.Policy.Preferred,
                                    QSizePolicy.Policy.Fixed)
        lay.addWidget(self._cmd_edit)

        mb.setCornerWidget(holder, Qt.Corner.TopRightCorner)
        holder.show()

        # hook up completer/shortcut like before
        self._cmd_model = QStandardItemModel(self)
        self._cmd_completer = QCompleter(self._cmd_model, self)
        self._cmd_completer.setCaseSensitivity(Qt.CaseSensitivity.CaseInsensitive)
        self._cmd_completer.setFilterMode(Qt.MatchFlag.MatchContains)
        popup = QListView(self); popup.setMinimumWidth(420); popup.setIconSize(QSize(18, 18))
        self._cmd_completer.setPopup(popup)
        self._cmd_edit.setCompleter(self._cmd_completer)
        self._cmd_completer.activated[QModelIndex].connect(self._run_selected_completion)
        QShortcut(QKeySequence("Ctrl+Shift+P"), self, activated=self._focus_command_search)
        self._build_command_model()
        self._cmd_edit.returnPressed.connect(self._trigger_first_visible_completion)

    def _focus_command_search(self):
        self._cmd_edit.setFocus(Qt.FocusReason.ShortcutFocusReason)
        self._cmd_edit.selectAll()

    def _trigger_first_visible_completion(self):
        popup = self._cmd_completer.popup()
        # When the popup is showing, Enter will also emit activated, but this is a safety net
        if popup and popup.model() and popup.model().rowCount() > 0:
            idx = popup.model().index(0, 0)
            act = idx.data(Qt.ItemDataRole.UserRole)
            if act:
                act.trigger()
        self._cmd_edit.clear()

    def _run_selected_completion(self, index: QModelIndex):
        act = index.data(Qt.ItemDataRole.UserRole)
        if act:
            act.trigger()
            self._cmd_edit.clear()

    def _build_command_model(self):
        """Create a list of all actions with icons and menu path."""
        self._cmd_model.clear()
        for action, path in self._gather_menu_actions():
            text = (action.text() or "").replace("&", "").strip()
            if not text:
                continue
            it = QStandardItem(text)
            # Icon
            if not action.icon().isNull():
                it.setIcon(action.icon())
            # Tooltip shows where it lives (Menu/Submenu/Action)
            it.setToolTip(path)
            # Stash the QAction itself to trigger later
            it.setData(action, Qt.ItemDataRole.UserRole)
            self._cmd_model.appendRow(it)

    def _gather_menu_actions(self):
        """
        Return [(QAction, 'Menu/Submenu/Action path'), ...] with duplicates removed.
        Includes menu actions and toolbar-only actions.
        """
        results = []
        seen = set()

        def walk_menu(menu: QMenu, prefix: str):
            for a in menu.actions():
                if a.isSeparator():
                    continue
                sub = a.menu()
                title = (a.text() or "").replace("&", "").strip()
                if sub:
                    walk_menu(sub, f"{prefix}{title}/")
                else:
                    if id(a) in seen:
                        continue
                    seen.add(id(a))
                    results.append((a, f"{prefix}{title}"))

        # Menus
        for top_action in self.menuBar().actions():
            m = top_action.menu()
            if m:
                title = (m.title() or "").replace("&", "").strip()
                walk_menu(m, f"{title}/")

        # Toolbars (to catch actions not present in menus)
        for tb in self.findChildren(QToolBar):
            for a in tb.actions():
                if a.isSeparator() or a.menu():
                    continue
                if id(a) in seen:
                    continue
                seen.add(id(a))
                title = (a.text() or "").replace("&", "").strip()
                results.append((a, f"Toolbar/{tb.windowTitle()}/{title}"))

        # Optional: hide a few you might not want
        blacklist = {"", "Exit"}
        results = [(a, p) for (a, p) in results if (a.text() or "").replace("&", "") not in blacklist]
        return results


    def _is_valid_fits_path(self, path: Optional[str]) -> bool:
        if not path or not isinstance(path, str):
            return False
        ext = os.path.splitext(path)[1].lower()
        if ext not in (".fits", ".fit", ".fts", ".fz"):
            return False
        return os.path.isfile(path)

    def open_fits_modifier(self):
        img, meta = self.image_manager.get_current_image_and_metadata()
        file_path = None
        header_obj = None
        if isinstance(meta, dict):
            candidate = meta.get("file_path") or meta.get("FILE") or meta.get("path")
            header_obj = meta.get("fits_header") or meta.get("header")

            # only keep as file_path if it really looks like a FITS file
            if self._is_valid_fits_path(candidate):
                file_path = candidate
            else:
                file_path = None  # treat "Cropped Image" etc. as a label

        # If we have neither a FITS path nor a header, just open the dialog empty and let them click "Open FITS…"
        dlg = FITSModifier(file_path=file_path,
                        header=header_obj if header_obj is not None else fits.Header(),
                        image_manager=self.image_manager,
                        parent=self)
        dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True)
        dlg.show()

    def open_astrobin_exporter(self):
        """
        Open the AstroBin Acquisition Exporter UI (class lives in this codebase).
        """
        dlg = QDialog(self)
        dlg.setWindowTitle("AstroBin Acquisition Exporter")
        dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True)

        lay = QVBoxLayout(dlg)

        # Instantiate your exporter widget (takes only parent)
        exporter_widget = AstrobinExportTab(parent=dlg)
        lay.addWidget(exporter_widget)

        close_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Close, parent=dlg)
        close_box.rejected.connect(dlg.close)
        lay.addWidget(close_box)

        dlg.resize(1000, 720)
        dlg.show()

        # keep a reference so it isn’t GC’d
        self._astrobin_exporter_dialog = dlg

    def open_batch_fits_modifier(self):
        """Open non-modal batch header modification dialog."""
        dlg = BatchFITSHeaderDialog(parent=self)
        dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True)
        dlg.show()

    def open_batch_renamer(self):
        dlg = BatchRenamerDialog(parent=self)
        dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True)
        dlg.resize(1050, 720)
        dlg.show()

    def show_history_dialog(self):
        slot = self.image_manager.current_slot
        self.history_dialog = HistoryExplorerDialog(self.image_manager, slot=self.image_manager.current_slot, parent=self)
        self.history_dialog.show()

    def SFCC_show(self):
        """
        Show (or re‐show) the SFCC dialog.  We keep it in an instance attribute
        so it doesn’t get garbage‐collected.
        """
        if self.SFCC_window is None:
            self.SFCC_window = SFCCDialog(parent=self)


        self.SFCC_window.show()
        self.SFCC_window.raise_()  # bring to front

    def live_stacking(self):
        """
        Slot called when the user clicks “Live Stacking”.
        Will open the LiveStackWindow (to be implemented) and show it.
        """
        # keep a reference so it doesn’t get garbage-collected
        self.live_stack_window = LiveStackWindow(parent=self)
        self.live_stack_window.show()

    def starspiketool(self):
        dialog = StarSpikeTool(self.image_manager, self.mask_manager, parent=self)
        dialog.exec()

    def exoplanet_detect(self):
        win = ExoPlanetWindow(parent=self)
        # force this to be queued → never block the emitter
        win.referenceSelected.connect(
            self._on_reference_selected,
            Qt.ConnectionType.QueuedConnection
        )
        win.show()
        self.exoplanet_detect_window = win

    def _astap_available(self) -> bool:
        """Return True if we can find the ASTAP executable (either in settings or on PATH)."""
        # 1) check user‐configured override in QSettings
        settings = QSettings()
        custom = settings.value("astap/exe_path", type=str)
        if custom:
            # make sure it actually exists and is executable
            if os.path.isfile(custom) and os.access(custom, os.X_OK):
                return True

        # 2) fall back to scanning PATH for the right binary name
        if sys.platform.startswith("win"):
            candidates = ["astap.exe", "astap.com", "astap.bat"]
        else:
            candidates = ["astap"]
        for exe in candidates:
            if shutil.which(exe):
                return True

        return False

    def _on_reference_selected(self, path):
        # switch to WIMI tab
        self.tabs.setCurrentWidget(self.wimi_tab)
        self.wimi_tab.load_image_path(path)

        if not self._astap_available():
            QMessageBox.critical(
                self,
                "Cannot Blind Solve",
                "ASTAP was not found on your system.\n"
                "Please install ASTAP or add it to your PATH before retrying."
            )
            return

        # define the background task
        def do_blind_solve():
            self.wimi_tab.perform_blind_solve2()

        # fire it off
        executor = ThreadPoolExecutor(max_workers=1)
        future = executor.submit(do_blind_solve)

        # when it’s done, schedule a popup on the main thread
        def _notify(_):
            #QTimer.singleShot(0, lambda: QMessageBox.information(self, "Blind Solve", "Blind-solve is complete!"))

            # Forward RA/Dec from WIMI → ExoPlanetWindow
            if hasattr(self, 'exoplanet_detect_window') and self.exoplanet_detect_window:
                ra  = getattr(self.wimi_tab, "center_ra", None)
                dec = getattr(self.wimi_tab, "center_dec", None)
                if ra is not None and dec is not None:
                    self.exoplanet_detect_window.receive_wcs_coordinates(ra, dec)
        future.add_done_callback(_notify)

    def convo_deconvo_show(self):
        """
        Show (or re‐show) the Convolution/Deconvolution dialog.
        Store it as an instance attribute so it doesn’t get garbage‐collected.
        """
        if self._convo_deconvo_window is None:
            self._convo_deconvo_window = ConvoDeconvoDialog(parent=self)
            # If you need to pass data (e.g. the current image) into the dialog,
            # you could do it here, e.g.:
            #   self._convo_deconvo_window.set_image(self.image_manager.get_current_image())
        self._convo_deconvo_window.show()
        self._convo_deconvo_window.raise_()  # bring to front

    def remove_pedestal(self):
        # 1) Prompt the user
        dlg = QMessageBox(self)
        dlg.setWindowTitle("Pedestal Removal")
        dlg.setText("Apply pedestal removal to:")
        btn_current = dlg.addButton(
            "Current Slot", QMessageBox.ButtonRole.YesRole
        )
        btn_all     = dlg.addButton(
            "All Slots",    QMessageBox.ButtonRole.NoRole
        )
        dlg.addButton(QMessageBox.StandardButton.Cancel)
        dlg.exec()

        # 2) Pick slots based on exactly which button got clicked
        if dlg.clickedButton() is btn_current:
            slots = [ self.image_manager.current_slot ]
        elif dlg.clickedButton() is btn_all:
            slots = list(range(self.image_manager.max_slots))
        else:
            return  # canceled

        # 3) Do the pedestal subtraction on each slot you chose
        for slot in slots:
            img = self.image_manager._images.get(slot)
            meta = self.image_manager._metadata.get(slot, {})
            if img is None:
                continue

            if img.ndim == 2:
                new_img = img - img.min()
            else:
                new_img = np.empty_like(img)
                for ch in range(img.shape[2]):
                    new_img[..., ch] = img[..., ch] - img[..., ch].min()

            # 4) Use set_image_for_slot so each slot gets its own undo entry
            self.image_manager.set_image_for_slot(
                slot,
                new_img,
                meta,
                step_name="Pedestal Removal"
            )

        # 5) Let them know
        QMessageBox.information(self, "Pedestal Removal", "Done!")


    def open_signature_insert_window(self):
        self.signature_insert_window = SignatureInsertWindow(self.image_manager, parent=self)
        self.signature_insert_window.show()



    def star_registration(self):
        self.star_registration_window = StarRegistrationWindow(self.image_manager)
        self.star_registration_window.show()

    def show_about_dialog(self):
        dialog = AboutDialog(self)
        dialog.show()

    def open_supernova_hunter(self):
        # Instantiate the SuperNova/Asteroid Hunter widget
        self.supernova_hunter_tab = SupernovaAsteroidHunterTab()
        # Show the new window (or tab)
        self.supernova_hunter_tab.show()

    def open_image_peeker(self):
        # Keep a reference so it doesn't get GC'd
        self._image_peeker = ImagePeekerDialog(
            parent=self,
            image_manager=self.image_manager,
            settings=self.settings
        )
        self._image_peeker.show()

    def stacking_suite_action(self):
        self.stackingsuitewindow = StackingSuiteDialog()
        self.stackingsuitewindow.show()



    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified image slot."""
        # Validate slot range and image availability.
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview is already open.
        if slot in self.preview_windows:
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            return

        # Create and show a new preview window.
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)
        self.preview_windows[slot] = preview
        preview.closed.connect(self.on_preview_closed)
        preview.show()

    def update_mask_slot_toolbar_highlight(self):
        """
        Loops through the mask slot buttons and applies a blue border to any slot that contains a mask.
        """
        for slot, button in self.mask_slot_actions.items():
            mask = self.mask_manager.get_mask(slot)
            if mask is not None:
                # Blue border indicates a mask is saved in this slot.
                button.setStyleSheet("border: 2px solid blue;")
            else:
                # Clear any border if the slot is empty.
                button.setStyleSheet("")


    def connect_mask_manager_signals(self):
        self.mask_manager.mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())
        self.mask_manager.applied_mask_changed.connect(lambda slot, mask: self.update_mask_slot_toolbar_highlight())

    def show_mask_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for a mask slot button with options to preview or rename.
        """
        button = self.mask_slot_actions.get(slot)
        if not button:
            return

        menu = QMenu(button)
        action_preview = menu.addAction("Preview Mask Slot")
        action_rename = menu.addAction("Rename Mask Slot")
        global_pos = button.mapToGlobal(pos)
        selected_action = menu.exec(global_pos)
        if selected_action == action_preview:
            self.preview_mask_slot(slot)
        elif selected_action == action_rename:
            self.rename_mask_slot_by_context(slot)

    def rename_mask_slot_by_context(self, slot):
        """
        Prompts the user to rename a mask slot (given by slot number) and updates the UI.
        """
        new_name, ok = QInputDialog.getText(
            self, "Rename Mask Slot", f"Enter new name for mask slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        self.mask_slot_names[slot] = new_name
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Apply or preview mask for {new_name}")



    def show_slot_context_menu(self, pos, slot):
        """
        Shows a context menu for the slot button, with options to show the slot preview, rename the slot, or clear its contents.
        """
        # Retrieve the corresponding button
        button = self.slot_actions.get(slot)
        if not button:
            return

        # Create a QMenu for this button
        menu = QMenu(self)  # In Qt6, pass self as the parent
        
        # Add actions
        action_show_preview = menu.addAction("Show Slot Preview")
        action_rename = menu.addAction("Rename")
        action_clear = menu.addAction("Clear Slot")  # New clear slot option

        # Execute the menu at the global position
        selected_action = menu.exec(button.mapToGlobal(pos))
        
        # Perform actions based on selection
        if selected_action == action_show_preview:
            self.open_preview_window(slot)
        elif selected_action == action_rename:
            self.rename_slot_by_context(slot)
        elif selected_action == action_clear:
            self.clear_slot_contents(slot)  # Call the new clear function


    def rename_slot_by_context(self, slot):
        """
        Prompts the user to enter a new name for the specified slot and updates the UI.
        """
        # Prompt for the new name for this slot.
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", f"Enter new name for slot {slot} (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces.
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary.
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()


    def clear_slot_contents(self, slot):
        """
        Completely clears the contents of the specified slot and resets the UI in Qt6.
        """
        # Confirm with the user before clearing
        reply = QMessageBox.question(
            self,
            "Clear Slot",
            f"Are you sure you want to clear slot {slot}?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.No:
            return  # User canceled

        # Ensure the ImageManager exists
        if not hasattr(self, 'image_manager'):
            QMessageBox.warning(self, "Error", "ImageManager is not available.")
            return

        # Remove image and metadata from ImageManager
        self.image_manager._images[slot] = None  # Remove image
        self.image_manager._metadata[slot] = {}  # Clear metadata
        self.image_manager._undo_stacks[slot] = []  # Clear undo history
        self.image_manager._redo_stacks[slot] = []  # Clear redo history


        # Close preview window if it exists
        if slot in self.preview_windows:
            self.preview_windows[slot].close()
            del self.preview_windows[slot]

        # Reset slot button UI
        if slot in self.slot_actions:
            button = self.slot_actions[slot]
            button.setText(f"Slot {slot}")  # Reset text
            button.setToolTip("No content available")  # Reset tooltip

        if slot in self.menubar_slot_actions:
            act = self.menubar_slot_actions[slot]
            default_name = f"Slot {slot}"
            act.setText(default_name)
            act.setStatusTip("No content available")

        # Emit signal to update the UI and trigger the image refresh
        self.image_manager.image_changed.emit(slot, np.zeros((1, 1), dtype=np.uint8), {})



    def stellar_alignment(self):
        dialog = StellarAlignmentDialog(self, self.settings, self.image_manager)
        dialog.show()

    def launch_plate_solver(self):
        # Instantiate and run the PlateSolver dialog.
        solver = PlateSolver(self.settings, self)
        solver.show()  # The PlateSolver dialog handles the full process

    def psf_viewer(self):
        """
        Create and show the PSFViewer dialog using the current image
        from the ImageManager's active slot.
        """
        # 1) If it’s already open, just raise it.
        if (hasattr(self, 'psf_viewer_dialog') and
            self.psf_viewer_dialog is not None and
            self.psf_viewer_dialog.isVisible()):
            self.psf_viewer_dialog.raise_()
            self.psf_viewer_dialog.activateWindow()
            return

        # 2) Grab the current slot & image.
        slot = self.image_manager.current_slot
        img, _meta = self.image_manager.get_current_image_and_metadata()

        # 3) Sanity check
        if img is None or img.size == 0:
            QMessageBox.warning(
                self,
                "No Image",
                f"Slot {slot+1} does not contain an image."
            )
            return

        # 4) Ensure 3-channel
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)

        # 5) Create & show the PSFViewer
        self.psf_viewer_dialog = PSFViewer(img, self)

        # 6) Whenever *this* slot’s image changes, push the update through.
        def _on_image_changed(changed_slot, new_img, metadata):
            if changed_slot != slot or self.psf_viewer_dialog is None:
                return
            # ignore empty clears
            if new_img is None or new_img.size == 0:
                return
            if new_img.ndim == 2:
                new_img = np.stack([new_img] * 3, axis=-1)
            self.psf_viewer_dialog.updateImage(new_img)

        self.image_manager.image_changed.connect(_on_image_changed)
        self.psf_viewer_dialog.show()


    def update_slot_toolbar_highlight(self):
        """
        Update the slot toolbar so that:
        - The active slot gets a distinct border (e.g., blue) regardless of occupancy.
        - Non-active slots that are occupied get a green border.
        - Unoccupied non-active slots have no border.
        """
        active_slot = self.image_manager.current_slot
        for slot, button in self.slot_actions.items():
            if button is not None:
                if slot == active_slot:
                    # Active slot: highlight with blue border.
                    button.setStyleSheet("border: 2px solid green; background-color: yellow; color: black;")
                else:
                    # For non-active slots:
                    if self.image_manager._images.get(slot) is not None:
                        # Occupied slot: green border.
                        button.setStyleSheet("border: 2px solid blue;")
                    else:
                        # Unoccupied: clear style.
                        button.setStyleSheet("")


    def set_active_slot(self, slot):
        """Set the specified slot as active and update the slot toolbar highlight."""
        self.image_manager.set_current_slot(slot)
        # Optionally, update other UI elements (such as an "Active Slot" label)
        self.update_slot_toolbar_highlight()


    def on_tab_changed(self, index):
        current_tab = self.tabs.widget(index)
        # Check if the tab has a 'refresh' method.
        if current_tab is self.curves_tab:
            self.curveDock.show()
        else:
            self.curveDock.hide()

        if hasattr(current_tab, "refresh"):
            current_tab.refresh()

    def update_active_slot_label(self, slot):
        # Look up the custom name for this slot; if none exists, fall back to "Slot {slot}"
        slot_name = self.slot_names.get(slot, f"Slot {slot}")
        self.active_slot_label.setText(f"Active Slot: {slot_name}")


    def open_mosaic_master(self):
        """
        Opens a new MosaicMasterDialog (or QMainWindow) where the user can
        add multiple images, star-align them, and create a large mosaic.
        """
        # Create the mosaic master window if not already created, or just each time:
        mosaic_window = MosaicMasterDialog(self.settings, parent=self, image_manager=self.image_manager)

        mosaic_window.show()

    def save_project(self):
        """Save all project data to a single file."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getSaveFileName(
            self,
            "Save Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        # 1) slot names
        slot_names_dict = {
            slot: self.slot_names[slot]
            for slot in range(self.image_manager.max_slots)
        }

        # 2) mask slot names are already plain dicts
        mask_slot_names_dict = dict(self.mask_slot_names)

        # Assemble project data into one dictionary.
        project_data = {
            # ImageManager data: images and metadata
            "images": self.image_manager._images,       # dictionary {slot: image array}
            "metadata": self.image_manager._metadata,   # dictionary {slot: metadata dict}
            # Save custom slot names
            "slot_names": slot_names_dict,  
            # Undo/Redo stacks
            "undo_stacks": self.image_manager._undo_stacks,
            "redo_stacks": self.image_manager._redo_stacks,            
            # MaskManager data
            "masks": self.mask_manager._masks,          # dictionary {slot: mask array}
            "applied_mask_slot": self.mask_manager.applied_mask_slot,
            "applied_mask": self.mask_manager.applied_mask,
            # Save custom mask slot names
            "mask_slot_names": self.mask_slot_names,
            
            # Additional settings
            "current_slot": self.image_manager.current_slot,
            "theme": self.current_theme,
        }

        try:
            with open(fileName, "wb") as f:
                pickle.dump(project_data, f)
            print("Project saved successfully to:", fileName)
        except Exception as e:
            QMessageBox.critical(self, "Save Project Error", f"Error saving project: {str(e)}")


    def open_project(self):
        """Open a project file and repopulate all managers and UI elements."""
        default_dir = self.settings.value("working_directory", "")
        fileName, _ = QFileDialog.getOpenFileName(
            self,
            "Open Project",
            default_dir,
            "Astro Project Files (*.sas)"
        )
        if not fileName:
            return

        try:
            with open(fileName, "rb") as f:
                project_data = pickle.load(f)
        except Exception as e:
            QMessageBox.critical(self, "Open Project Error", f"Error opening project: {str(e)}")
            return

        # Restore ImageManager data
        if "images" in project_data and "metadata" in project_data:
            self.image_manager._images = project_data["images"]
            self.image_manager._metadata = project_data["metadata"]
            self.image_manager.current_slot = project_data.get("current_slot", 0)
            # Restore undo/redo stacks if available
            self.image_manager._undo_stacks = project_data.get(
                "undo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )
            self.image_manager._redo_stacks = project_data.get(
                "redo_stacks", {i: [] for i in range(self.image_manager.max_slots)}
            )            
        else:
            QMessageBox.warning(self, "Project Data", "No image data found in project file.")

        # Restore slot names if available
        if "slot_names" in project_data:
            self.slot_names = project_data["slot_names"]

        # Restore MaskManager data
        if "masks" in project_data:
            self.mask_manager._masks = project_data["masks"]
            self.mask_manager.applied_mask_slot = project_data.get("applied_mask_slot")
            self.mask_manager.applied_mask = project_data.get("applied_mask")
        
        # Restore custom mask slot names
        if "mask_slot_names" in project_data:
            self.mask_slot_names = project_data["mask_slot_names"]

        # Restore additional settings, e.g., theme
        if "theme" in project_data:
            self.current_theme = project_data["theme"]

        # Emit a signal to update the UI for the current slot if needed
        self.image_manager.image_changed.emit(
            self.image_manager.current_slot,
            self.image_manager._images[self.image_manager.current_slot],
            self.image_manager._metadata[self.image_manager.current_slot]
        )

        # **Update the slot menu actions to reflect the new custom slot names**
        for slot, action in self.slot_actions.items():
            new_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")
        
        # (Optionally, update mask slot actions similarly if needed.)
        for slot, action in self.mask_slot_actions.items():
            new_name = self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            action.setText(new_name)
            action.setStatusTip(f"Open preview for {new_name}")        

        print("Project loaded successfully from:", fileName)

    def new_project(self):
        """
        Clears all current project data (images, masks, undo/redo stacks, etc.)
        after warning the user that this operation is destructive.
        """
        reply = QMessageBox.question(
            self,
            "New Project",
            "This will erase all data in current slots and undo/redo stacks. Are you sure you want to create a new project?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply != QMessageBox.StandardButton.Yes:
            print("New project canceled by user.")
            return

        # Clear ImageManager data
        self.image_manager._images = {i: None for i in range(self.image_manager.max_slots)}
        self.image_manager._metadata = {i: {} for i in range(self.image_manager.max_slots)}
        self.image_manager._undo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager._redo_stacks = {i: [] for i in range(self.image_manager.max_slots)}
        self.image_manager.current_slot = 0

        # Clear MaskManager data
        self.mask_manager._masks = {}
        self.mask_manager.applied_mask = None
        self.mask_manager.applied_mask_slot = None

        # Clear preview windows if any
        self.preview_windows = {}

        # Reset custom slot names to defaults
        self.slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
        self.mask_slot_names = {i: f"Mask Slot {i}" for i in range(5)}

        # Update UI elements for slot names (e.g., QToolButtons)
        for slot, action in self.slot_actions.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            action.setText(default_name)
            action.setStatusTip(f"Open preview for {default_name}")

        # --- NEW: Update Menubar Slot Names ---
        for slot, action in self.menubar_slot_actions.items():
            default_name = self.slot_names[slot]
            action.setText(default_name)
            action.setStatusTip(f"Open preview for {default_name}")

        # Update any open preview windows
        for slot, window in self.preview_windows.items():
            default_name = self.slot_names.get(slot, f"Slot {slot}")
            window.setWindowTitle(f"Preview - {default_name}")

        # Update UI elements that are managed outside of ImageManager
        # For instance, update file name label or other status indicators.
        # Here we call update_file_name with default parameters.
        self.update_file_name(0, None, {})

        # Clear all tabs that display images.
        self.clear_all_tabs()


        # ——— Reset masks ——————————————————————————————
        # 1) clear out all masks in MaskManager
        self.mask_manager._masks = {}
        self.mask_manager.applied_mask = None
        self.mask_manager.applied_mask_slot = None

       # 2) reset the banner to hidden
        self.update_mask_banner(-1, None)

        # 3) reset all of the mask‑slot button labels back to "Mask Slot {i}"
        for slot, btn in self.mask_slot_actions.items():
            default_name = self.mask_slot_names[slot]
            btn.setText(default_name)
            btn.setToolTip(default_name)

        # 4) clear any toolbar highlighting on slots
        self.update_slot_toolbar_highlight()
        self.menuBar().update()
        print("New project created: All image, mask, and undo/redo data have been cleared.")



    def clear_all_tabs(self):
        """
        Simulate a tab click by switching to a different tab and back.
        This forces the tab's update logic to clear the image.
        """
        if self.tabs.count() < 2:
            # Only one tab—try calling clear_image() if available.
            current_tab = self.tabs.currentWidget()
            if hasattr(current_tab, "clear_image"):
                current_tab.clear_image()
            return

        # Save the current index.
        current_index = self.tabs.currentIndex()
        # Choose a different tab index.
        new_index = 1 if current_index == 0 else 0
        # Switch to the new index.
        self.tabs.setCurrentIndex(new_index)
        # Immediately switch back.
        self.tabs.setCurrentIndex(current_index)
        print("Simulated tab click to clear image.")

    def open_histogram(self):
        # Check if a histogram dialog is already open; if so, bring it to front.
        if hasattr(self, 'hist_dialog') and self.hist_dialog is not None and self.hist_dialog.isVisible():
            self.hist_dialog.raise_()
            self.hist_dialog.activateWindow()
            return

        # Get the image from the active slot instead of slot 0.
        current_slot = self.image_manager.current_slot
        img = self.image_manager._images.get(current_slot, None)
        if img is None:
            QMessageBox.warning(self, "No Image", f"Slot {current_slot} does not contain an image.")
            return
        # If grayscale, replicate to 3 channels.
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)
        # Create the histogram dialog using the active slot's image.
        self.hist_dialog = HistogramDialog(self.image_manager, self)
        
        # Define a helper function to update the histogram when the active slot changes.
        def update_hist(slot, image, metadata):
            # Update only if the changed slot is the current active slot.
            if slot == self.image_manager.current_slot:
                if image is None:
                    return
                if image.ndim == 2:
                    image = np.stack([image]*3, axis=-1)
                self.hist_dialog.updateHistogram(image)
        
        # Connect the image_changed signal.
        self.image_manager.image_changed.connect(update_hist)
        
        self.hist_dialog.show()


    def rename_slot(self):
        """
        Prompts the user to select a slot and enter a new name (with no spaces).
        The new name is then applied to the slot and updates the UI.
        """
        # Ask the user which slot to rename (0 to max_slots-1)
        slot, ok = QInputDialog.getInt(
            self, "Rename Slot", "Enter slot number to rename:",
            0, 0, self.image_manager.max_slots - 1
        )
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(
            self, "Rename Slot", "Enter new name (no spaces):"
        )
        if not ok or not new_name:
            return

        # Validate that the new name contains no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom name in our dictionary
        self.slot_names[slot] = new_name

        # --- Update Toolbar Slot Name ---
        if slot in self.slot_actions:
            self.slot_actions[slot].setText(new_name)
            self.slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- Update Menubar Slot Name (NEW FIX) ---
        if slot in self.menubar_slot_actions:
            self.menubar_slot_actions[slot].setText(new_name)
            self.menubar_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # --- If there is an open preview window for this slot, update its title ---
        if slot in self.preview_windows:
            self.preview_windows[slot].setWindowTitle(f"Preview - {new_name}")

        # Refresh Menubar
        self.menuBar().update()



    def rename_mask_slot(self):
        """
        Prompts the user to select a mask slot (0-4) and enter a new name (without spaces),
        then updates the mask slot name in the dictionary and the corresponding QAction.
        """
        # Ask for the mask slot number
        slot, ok = QInputDialog.getInt(self, "Rename Mask Slot", "Enter mask slot number (0-4):", 0, 0, 4)
        if not ok:
            return

        # Ask for the new name
        new_name, ok = QInputDialog.getText(self, "Rename Mask Slot", "Enter new name (no spaces):")
        if not ok or not new_name:
            return

        # Validate that the new name has no spaces
        if " " in new_name:
            QMessageBox.warning(self, "Invalid Name", "The name cannot contain spaces.")
            return

        # Update the custom mask slot names dictionary
        self.mask_slot_names[slot] = new_name

        # Update the corresponding QAction text and tooltip
        if slot in self.mask_slot_actions:
            self.mask_slot_actions[slot].setText(new_name)
            self.mask_slot_actions[slot].setStatusTip(f"Open preview for {new_name}")

        # Optionally, if you keep track of open mask preview dialogs, update their titles as well.
        # For example, if you maintain a dictionary self.mask_preview_windows:
        # if slot in self.mask_preview_windows:
        #     self.mask_preview_windows[slot].setWindowTitle(f"Preview - {new_name}")




    def open_pixel_math_dialog(self):
        """Opens the Pixel Math dialog."""
        dialog = PixelMathDialog(self, self.image_manager)
        dialog.exec()  # Using exec() to open as a modal dialog

    def connect_mask_manager_signals(self):
        """
        Connect signals from MaskManager to update the banner dynamically.
        """
        self.mask_manager.applied_mask_changed.connect(self.update_mask_banner)

    def update_mask_banner(self, slot, mask):
        """
        Updates the mask banner to indicate whether a mask is applied,
        using the custom name for the mask slot if available.
        """
        if mask is not None:
            # Check if a custom name exists for this mask slot
            if hasattr(self, 'mask_slot_names'):
                custom_name = self.mask_slot_names.get(slot, f"Slot {slot}")
            else:
                custom_name = f"Slot {slot}"
            self.mask_banner.setText(f"Mask Applied: {custom_name}")
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(True)
        else:
            self.mask_banner.setText("Mask Applied: None")
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")
            self.mask_banner.setVisible(False)


    def preview_mask_slot(self, slot):
        """
        Opens a preview window for the selected mask slot.
        """
        mask = self.mask_manager.get_mask(slot)
        
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask saved in slot {slot}.")
            return

        # Create the mask slot preview dialog
        preview_dialog = MaskSlotPreviewDialog(mask, slot, self)
        preview_dialog.show()


    def create_mask(self):
        """Open the Mask Creation dialog."""
        current_image = self.image_manager.image
        if current_image is None:
            QMessageBox.warning(self, "No Image", "No image available to create a mask.")
            return

        # Open the Mask Creation Dialog
        dialog = MaskCreationDialog(current_image, parent=self)
        dialog.exec()  # Execute the dialog as a modal window


    def apply_mask(self):
        """Prompt user for a mask slot and flag it in MaskManager for application."""
        # 1) Gather all non‐empty mask slots
        available_slots = [
            slot for slot in range(self.mask_manager.max_slots)
            if self.mask_manager.get_mask(slot) is not None
        ]
        if not available_slots:
            QMessageBox.warning(self, "No Masks Available", "There are no masks to apply.")
            return

        # 2) Build the list of display names, using any custom names
        display_names = [
            self.mask_slot_names.get(slot, f"Mask Slot {slot}")
            for slot in available_slots
        ]

        # 3) Ask the user to choose one
        chosen_name, ok = QInputDialog.getItem(
            self,
            "Select Mask Slot",
            "Choose a mask to apply:",
            display_names,
            0,
            False
        )
        if not ok:
            return

        # 4) Map the chosen display name back to the slot index
        idx = display_names.index(chosen_name)
        selected_slot = available_slots[idx]

        # 5) Apply it
        self.mask_manager.apply_mask_from_slot(selected_slot)

        # 6) Update banner (you can also display chosen_name here)
        self.update_mask_banner(selected_slot,
                                self.mask_manager.get_applied_mask())
        print(f"Mask from {chosen_name} (slot {selected_slot}) flagged for application.")

    def apply_mask_from_slot(self, slot):
        """
        Applies the mask stored in the given mask slot.
        Updates the UI (e.g. mask banner) to reflect the applied mask.
        """
        mask = self.mask_manager.get_mask(slot)
        if mask is None:
            QMessageBox.warning(self, "No Mask", f"No mask is saved in slot {slot}.")
            return

        # Apply the mask from the specified slot.
        self.mask_manager.apply_mask_from_slot(slot)
        # Optionally, update any UI elements (for example, a banner) to show the applied mask.
        self.update_mask_banner(slot, self.mask_manager.get_applied_mask())
        print(f"Mask from Slot {slot} flagged for application.")


    def remove_mask(self):
        """Remove the active mask and update the UI."""
        # Check if a mask is currently applied
        if self.mask_manager.get_applied_mask() is None:
            QMessageBox.warning(self, "No Mask", "No mask is currently applied.")
            return

        # Clear the applied mask
        self.mask_manager.clear_applied_mask()


        # Update the UI banner to reflect no active mask
        self.update_mask_banner(-1, None)

        print("Mask removed successfully, banner updated.")


    def load_mask(self):
        """Load a mask from a file."""
        default_dir = self.settings.value("working_directory", "")
        # Open a file dialog to select the mask file
        filename, _ = QFileDialog.getOpenFileName(
            self, 
            "Load Mask", 
            default_dir, 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if not filename:
            return  # User canceled the dialog

        try:
            # Load the mask using the global load_image method
            loaded_image, _, _, _ = load_image(filename)  # Ensure load_image returns (image, header, bit_depth, is_mono)

            # Convert the loaded image to grayscale if it's not already
            if loaded_image.ndim == 3:
                # Assuming RGB; convert to grayscale using OpenCV
                mask = cv2.cvtColor(loaded_image, cv2.COLOR_RGB2GRAY)
            else:
                mask = loaded_image.copy()  # Already single-channel

            # Normalize the mask to [0, 1] if it's not already
            mask = mask.astype(np.float32)
            if mask.max() > 1.0:
                mask /= 255.0
            mask = np.clip(mask, 0.0, 1.0)

            # Prompt the user to select the mask slot
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot", 
                f"Enter mask slot number (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if ok:
                # Set the mask in the selected slot using MaskManager
                self.mask_manager.set_mask(slot_number, mask)
                print(f"AstroEditingSuite: Mask loaded from {filename} into slot {slot_number}.")
            else:

                print("AstroEditingSuite: Mask loading canceled by the user.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load mask:\n{e}")
            print(f"AstroEditingSuite: Failed to load mask: {e}")

    def save_mask(self):
        """Save the active mask to a file."""
        default_dir = self.settings.value("working_directory", "")
        try:
            # Prompt the user to select the mask slot to save
            max_slots = self.mask_manager.max_slots  # Ensure MaskManager has max_slots attribute
            slot_number, ok = QInputDialog.getInt(
                self, 
                "Select Mask Slot to Save", 
                f"Enter mask slot number to save (0 to {max_slots - 1}):", 
                min=0, 
                max=max_slots - 1, 
                step=1
            )

            if not ok:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Retrieve the mask from the selected slot using MaskManager
            mask = self.mask_manager.get_mask(slot_number)
            if mask is None:
                QMessageBox.warning(
                    self, 
                    "No Mask", 
                    f"No mask available in slot {slot_number} to save."
                )
                print(f"AstroEditingSuite: No mask available in slot {slot_number} to save.")
                return

            # Open a save file dialog to specify the destination file
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save Mask", 
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
            )
            if not filename:
                QMessageBox.information(self, "Save Mask", "Mask saving canceled.")
                print("AstroEditingSuite: Mask saving canceled by the user.")
                return

            # Determine the file format based on the file extension
            file_format = os.path.splitext(filename)[1][1:].lower()  # Extract extension without dot

            # Set bit_depth based on file format
            # For PNG and JPEG, bit_depth is not required as they typically use 8-bit
            # For TIFF and FITS, we'll specify 8-bit
            if file_format in ['tif', 'tiff']:
                bit_depth = "8-bit"
            else:
                bit_depth = None  # Not required for formats like PNG

            # Convert mask to appropriate format for saving
            # Assuming mask is single-channel and normalized between 0 and 1
            mask_to_save = (mask * 255).astype(np.uint8)
            if mask_to_save.ndim == 2:
                # Convert to RGB if the save format expects multi-channel
                mask_to_save = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2RGB)

            # Save the mask using the global save_image method
            save_image(
                img_array=mask_to_save, 
                filename=filename, 
                original_format=file_format, 
                bit_depth=bit_depth, 
                original_header=None,  # Masks typically don't have headers
                is_mono=False,         # Masks are RGB after conversion
                image_meta=None,       # Optional metadata
                file_meta=None         # Optional file metadata
            )
            QMessageBox.information(
                self, 
                "Mask Saved", 
                f"Mask from slot {slot_number} saved to {filename}."
            )
            print(f"AstroEditingSuite: Mask from slot {slot_number} saved to {filename}.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save mask:\n{e}")
            print(f"AstroEditingSuite: Failed to save mask: {e}")

    def rescale_image(self):
        """
        Rescales the current image by a user-defined scaling factor using OpenCV.
        The image is expected to be stored as a 32-bit floating point numpy array.
        For example, a factor of 0.5 scales down the image to 50% of its original size,
        while 2 scales it up to 200%.
        """
        try:
            # Ensure that an image is loaded.
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rescaling.")
                return

            # Prompt the user for a scaling factor.
            factor, ok = QInputDialog.getDouble(
                self,
                "Rescale Image",
                "Enter scaling factor (e.g., 0.5 for 50%, 2 for 200%):",
                1.0,    # default value
                0.1,    # minimum value
                10.0,   # maximum value
                2       # number of decimals
            )
            if not ok:
                return

            # Retrieve a copy of the current image.
            current_image = self.image_manager.image.copy()

            # Determine new dimensions based on the scaling factor.
            # current_image.shape is assumed to be (height, width) for grayscale or (height, width, channels) for RGB.
            height, width = current_image.shape[:2]
            new_width = int(width * factor)
            new_height = int(height * factor)

            # Import cv2 and use cv2.resize with the LANCZOS4 interpolation method.
            resized_image = rescale_image_numba(current_image, factor)

            # Prepare metadata (append a description note about rescaling).
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + f" | Rescaled by factor {factor}"

            # Update the ImageManager with the rescaled image.
            self.image_manager.set_image(new_image=resized_image, metadata=metadata, step_name="Rescale Image")
            self.image_manager.image_changed.emit(
                self.image_manager.current_slot,
                resized_image,
                metadata
            )

            QMessageBox.information(
                self,
                "Image Rescaled",
                f"The image has been successfully rescaled by a factor of {factor}."
            )

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rescale image:\n{e}")
            print(f"Error in rescale_image: {e}")

            
    def flip_horizontal(self):
        """
        Flips the current image horizontally.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the horizontal flip using numpy
            flipped_image = flip_horizontal_numba(current_image)  # Flip horizontally

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Horizontally Flipped"


            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata, step_name="Flip Horizontal")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user


            print(f"Image in Slot {self.image_manager.current_slot} flipped horizontally successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image horizontally:\n{e}")
            print(f"Error in flip_horizontal: {e}")

    def flip_vertical(self):
        """
        Flips the current image vertically.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before flipping.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the vertical flip using numpy
            flipped_image = flip_vertical_numba(current_image)  # Flip vertically

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Vertically Flipped"

            # Update the ImageManager with the flipped image
            self.image_manager.set_image(new_image=flipped_image, metadata=metadata, step_name="Flip Vertically")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, flipped_image, metadata)

            # Notify the user


            print(f"Image in Slot {self.image_manager.current_slot} flipped vertically successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to flip image vertically:\n{e}")
            print(f"Error in flip_vertical: {e}")

    def rotate_clockwise(self):
        """
        Rotates the current image 90 degrees clockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_clockwise_numba(current_image)  # Rotate clockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Clockwise"

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata, step_name="Rotate 90° Clockwise")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user


            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° clockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image clockwise:\n{e}")
            print(f"Error in rotate_clockwise: {e}")

    def rotate_counterclockwise(self):
        """
        Rotates the current image 90 degrees counterclockwise.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before rotating.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Perform the rotation using numpy
            rotated_image = rotate_90_counterclockwise_numba(current_image)  # Rotate counterclockwise

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Rotated 90° Counterclockwise"

            # Update the ImageManager with the rotated image
            self.image_manager.set_image(new_image=rotated_image, metadata=metadata, step_name="Rotate Counterclockwise")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, rotated_image, metadata)

            # Notify the user


            print(f"Image in Slot {self.image_manager.current_slot} rotated 90° counterclockwise successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to rotate image counterclockwise:\n{e}")
            print(f"Error in rotate_counterclockwise: {e}")

    def invert_image(self):
        """
        Inverts the colors of the current image.
        """
        try:
            # Check if an image is loaded
            if self.image_manager.image is None:
                QMessageBox.warning(self, "No Image Loaded", "Please load an image before inverting.")
                return

            # Retrieve the current image
            current_image = self.image_manager.image.copy()

            # Check if the image is in a compatible format (e.g., float32 in [0,1])
            if current_image.dtype not in [np.float32, np.float64]:
                QMessageBox.warning(self, "Unsupported Format", "Image inversion supports floating point images.")
                return

            # Perform the inversion
            inverted_image = invert_image_numba(current_image)

            # Prepare metadata
            metadata = self.image_manager._metadata.get(self.image_manager.current_slot, {}).copy()
            metadata['description'] = metadata.get('description', "") + " | Inverted Image"

            # Update the ImageManager with the inverted image
            self.image_manager.set_image(new_image=inverted_image, metadata=metadata, step_name="Image Inversion")

            # Emit the image_changed signal to update the UI
            self.image_manager.image_changed.emit(self.image_manager.current_slot, inverted_image, metadata)

            # Notify the user


            print(f"Image in Slot {self.image_manager.current_slot} inverted successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to invert image:\n{e}")
            print(f"Error in invert_image: {e}")

    def open_hdr_dialog(self):
        """Open the WaveScale HDR dialog."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before using WaveScale HDR.")
            return

        dialog = WaveScaleHDRDialog(self.image_manager, self)
        dialog.exec()

    def open_dse_dialog(self):
        """Open the Dark Structure Enhance dialog."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image Loaded", "Please load an image before using Dark Structure Enhance.")
            return

        dialog = WaveScaleDarkEnhanceDialog(self.image_manager, self)
        dialog.exec()

    def open_blemish_blaster(self):
        """Handler method to open the Blemish Blaster tool."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image Loaded", "Please load an image before using Blemish Blaster.")
            return

        # Initialize and show the Blemish Blaster dialog, passing the ImageManager
        self.blemish_dialog = BlemishBlasterDialog(self.image_manager, self)

        self.blemish_dialog.exec()


    def remove_gradient(self):
        """Handle the Remove Gradient action."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Initialize the GradientRemovalDialog with the current image
        gradient_dialog = GradientRemovalDialog(image=self.image_manager.image.copy(), parent=self)
        gradient_dialog.processing_completed.connect(self.handle_gradient_removal)
        gradient_dialog.exec()


    def handle_gradient_removal(self, corrected_image, gradient_background, save_to_slot_1, selected_slot):
        """
        Handle the processed image after gradient removal.

        Args:
            corrected_image (np.ndarray): The image after gradient removal.
            gradient_background (np.ndarray): The extracted gradient.
            save_to_slot_1 (bool): Whether the user wants to save the gradient background.
            selected_slot (str): The slot number selected (e.g., "Slot 1").
        """
        try:
            # Store the corrected image in the current slot
            current_slot = self.image_manager.current_slot
            metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            metadata['description'] = "Gradient removed"
            self.image_manager.set_image(new_image=corrected_image, metadata=metadata, step_name="Gradient Removal")

            # **Save gradient background only if requested**
            if save_to_slot_1:
                slot_number = int(selected_slot.split(" ")[1])  # Convert "Slot 1" -> 1

                metadata_slot = {
                    'file_path': f"Gradient Background ({selected_slot})",
                    'description': "Extracted Gradient Background",
                    'bit_depth': "32-bit floating point",
                    'is_mono': len(gradient_background.shape) < 3,
                    'gradient_background': gradient_background
                }

                # Save gradient background in the selected slot
                self.image_manager._images[slot_number] = gradient_background
                self.image_manager._metadata[slot_number] = metadata_slot

                print(f"[INFO] Gradient background stored in {selected_slot}.")

                # --- Update slot UI Labels ---
                if hasattr(self, 'slot_names'):
                    self.slot_names[slot_number] = f"Extracted Gradient ({selected_slot})"
                if hasattr(self, 'slot_actions') and slot_number in self.slot_actions:
                    self.slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")
                # --- Update Menubar Slot Name (FIX) ---
                if hasattr(self, 'menubar_slot_actions') and slot_number in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot_number].setText(f"Extracted Gradient ({selected_slot})")
                    self.menubar_slot_actions[slot_number].setStatusTip(f"Open preview for Extracted Gradient ({selected_slot})")

                if hasattr(self, 'preview_windows') and slot_number in self.preview_windows:
                    self.preview_windows[slot_number].setWindowTitle(f"Preview - Extracted Gradient ({selected_slot})")

                self.menuBar().update()
                print(f"[INFO] Gradient removal completed and saved to {selected_slot}.")
            else:
                print("[INFO] User chose not to save the extracted gradient.")

            # Notify the user
            QMessageBox.information(self, "Success", "Gradient removal completed successfully.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply gradient removal:\n{e}")
            print(f"Error in handle_gradient_removal: {e}")


    def check_for_updates(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/refs/heads/main/updates.json"

            # Fetch the JSON data
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()
            update_data = response.json()

            # Convert version strings to tuples for proper comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                msg_box.setDetailedText("\n".join([f"{k}: {v}" for k, v in downloads.items()]))

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        webbrowser.open(downloads.get("Windows", ""))
                    elif platform.startswith("darwin"):
                        webbrowser.open(downloads.get("macOS", ""))
                    elif platform.startswith("linux"):
                        webbrowser.open(downloads.get("Linux", ""))
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
            else:
                QMessageBox.information(self, "No Updates", "You are already running the latest version.")

        except requests.RequestException as e:
            QMessageBox.critical(self, "Error", f"Failed to check for updates:\n{e}")


    def check_for_updatesstartup(self):
        try:
            # URL to the JSON file on GitHub
            update_url = "https://raw.githubusercontent.com/setiastro/setiastrosuite/main/updates.json"

            # Fetch the JSON data with a timeout to prevent hanging
            response = requests.get(update_url, timeout=5)
            response.raise_for_status()  # Raise an exception for HTTP errors
            update_data = response.json()

            # Convert version strings to tuples for accurate comparison.
            current_version_tuple = tuple(map(int, VERSION.split(".")))
            latest_version_str = update_data.get("version", "")
            if not latest_version_str:
                print("Update check: 'version' key not found in update data.")
                return  # Exit silently

            latest_version_tuple = tuple(map(int, latest_version_str.split(".")))

            # Compare versions
            if latest_version_tuple > current_version_tuple:
                notes = update_data.get("notes", "No details provided.")
                downloads = update_data.get("downloads", {})

                # Show a dialog to notify the user about the new version
                msg_box = QMessageBox(self)
                msg_box.setIcon(QMessageBox.Icon.Information)
                msg_box.setWindowTitle("Update Available")
                msg_box.setText(f"A new version ({latest_version_str}) is available!")
                msg_box.setInformativeText(f"Release Notes:\n{notes}")
                msg_box.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
                msg_box.setDefaultButton(QMessageBox.StandardButton.Yes)

                # Add download links to the detailed text
                detailed_text = "\n".join([f"{k}: {v}" for k, v in downloads.items()])
                msg_box.setDetailedText(detailed_text)

                if msg_box.exec() == QMessageBox.StandardButton.Yes:
                    # Open the appropriate link based on the user's OS
                    platform = sys.platform
                    if platform.startswith("win"):
                        download_link = downloads.get("Windows", "")
                    elif platform.startswith("darwin"):
                        download_link = downloads.get("macOS", "")
                    elif platform.startswith("linux"):
                        download_link = downloads.get("Linux", "")
                    else:
                        QMessageBox.warning(self, "Error", "Unsupported platform.")
                        download_link = ""

                    if download_link:
                        webbrowser.open(download_link)
                    else:
                        QMessageBox.warning(self, "Error", "Download link not available.")
                else:
                    # If the user declines the update, you might want to log it or simply do nothing.
                    pass
            else:
                # No update available; you might opt to notify the user at startup,
                # but typically it's best to remain silent.
                pass

        except requests.RequestException as e:
            # Log the error and optionally show a non-intrusive warning.
            print(f"Update check failed: {e}")
            msg_box = QMessageBox(self)
            msg_box.setIcon(QMessageBox.Icon.Warning)
            msg_box.setWindowTitle("Update Check Failed")
            msg_box.setText("Unable to check for updates at this time.")
            msg_box.setInformativeText("Please check your internet connection and try again later.")
            msg_box.setStandardButtons(QMessageBox.StandardButton.Ok)
            msg_box.exec()
        
    def version_str_to_tuple(self, version_str):
        """
        Convert a version string into a tuple of integers for comparison.
        Example: "1.10.2" -> (1, 10, 2)
        """
        return tuple(int(part) for part in version_str.split('.') if part.isdigit())

    def open_preferences_dialog(self):
        dialog = QDialog(self)
        dialog.setWindowTitle("Preferences")
        layout = QVBoxLayout(dialog)

        # Display stored settings using a form layout.
        settings_form = QFormLayout()

        # Define settings fields with appropriate selection methods.
        settings_fields = {
            "GraXpert Path": ("graxpert/path", self.settings.value("graxpert/path", "")),  # Needs FILE selection
            "StarNet Executable Path": ("starnet/exe_path", self.settings.value("starnet/exe_path", "")),  # FILE
            "ASTAP Executable Path": ("astap/exe_path", self.settings.value("astap/exe_path", "")),  # FILE
            "Cosmic Clarity Folder": ("cosmic_clarity_folder", self.settings.value("cosmic_clarity_folder", "")),  # FOLDER
            "Working Directory": ("working_directory", self.settings.value("working_directory", ""))  # FOLDER
        }

        # Create input fields dynamically with file/folder selection buttons.
        input_fields = {}
        for label, (key, value) in settings_fields.items():
            field_widget = QWidget()
            field_layout = QHBoxLayout(field_widget)
            field_layout.setContentsMargins(0, 0, 0, 0)

            # Create the QLineEdit with the stored value.
            field = QLineEdit(str(value))
            input_fields[key] = field
            field_layout.addWidget(field)

            # Create selection button.
            select_button = QPushButton("...")
            select_button.setFixedWidth(30)

            # **Use file selection for executable paths, folder selection for directories**
            if label in ["GraXpert Path", "StarNet Executable Path", "ASTAP Executable Path"]:
                select_button.setToolTip(f"Select file for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_file(f))
            else:
                select_button.setToolTip(f"Select folder for {label}")
                select_button.clicked.connect(lambda _, f=field: self.select_folder(f))

            field_layout.addWidget(select_button)
            settings_form.addRow(label, field_widget)

        # Additional settings fields (without selection buttons).
        additional_fields = {
            "Astrometry API Key": ("astrometry_api_key", self.settings.value("astrometry_api_key", "")),
            "Latitude": ("latitude", self.settings.value("latitude", "")),
            "Longitude": ("longitude", self.settings.value("longitude", "")),
            "Date": ("date", self.settings.value("date", "")),
            "Time": ("time", self.settings.value("time", "")),
            "Timezone": ("timezone", self.settings.value("timezone", "")),
            "Minimum Altitude": ("min_altitude", self.settings.value("min_altitude", ""))
        }

        for label, (key, value) in additional_fields.items():
            field = QLineEdit(str(value))
            settings_form.addRow(label, field)
            input_fields[key] = field

        layout.addLayout(settings_form)

        # **Add Save, Reset, and Cancel buttons**
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Save |
                                QDialogButtonBox.StandardButton.Reset |
                                QDialogButtonBox.StandardButton.Cancel)

        # Save button: Save preferences
        buttons.accepted.connect(lambda: self.save_preferences(input_fields, dialog))

        # Reset button: Clear preferences
        buttons.button(QDialogButtonBox.StandardButton.Reset).clicked.connect(lambda: self.clear_preferences(input_fields))

        # Cancel button: Close the dialog
        buttons.rejected.connect(dialog.reject)

        layout.addWidget(buttons)
        dialog.exec()

    def select_file(self, field):
        """Open file selection dialog for executable files."""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select Executable File",
            "",
            "Executables (*.exe *.AppImage *.sh *.bin *.run);;All Files (*)"
        )
        if file_path:
            field.setText(file_path)

    def select_folder(self, field):
        """Open folder selection dialog."""
        folder_path = QFileDialog.getExistingDirectory(self, "Select Folder")
        if folder_path:
            field.setText(folder_path)

    def save_preferences(self, input_fields, dialog):
        for key, field in input_fields.items():
            self.settings.setValue(key, field.text())
        dialog.accept()
        QMessageBox.information(self, "Preferences Saved", "Settings have been updated successfully.")

    def clear_preferences(self, input_fields):
        reply = QMessageBox.question(self, "Clear Preferences", "Are you sure you want to clear all preferences?", QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
        if reply == QMessageBox.StandardButton.Yes:
            for key in input_fields.keys():
                self.settings.remove(key)
                input_fields[key].clear()
            QMessageBox.information(self, "Preferences Cleared", "All settings have been reset.")


    def open_crop_tool(self):
        """Open the crop tool to crop the current image."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before cropping.")
            return

        # Open the Crop Tool with correct parameters
        crop_tool = CropTool(self.image_manager, self.image_manager.image, self)
        crop_tool.crop_applied.connect(self.apply_cropped_image)
        crop_tool.exec()

    def apply_cropped_image(self, cropped_image):
        """Apply the cropped image to the current slot."""
        current_slot = self.image_manager.current_slot
        metadata = self.image_manager._metadata.get(current_slot, {}).copy()
        metadata['file_path'] = "Cropped Image"

        # Use the proper undo-enabled, step-name-aware method
        self.image_manager.set_image_with_step_name(
            cropped_image,
            metadata,
            step_name="Crop"
        )

        QMessageBox.information(self, "Success", "Cropped image applied.")



    def rgb_combination(self):
        """Handle the RGB Combination action."""
        dialog = RGBCombinationDialog(self, image_manager=self.image_manager)
        if dialog.exec() == QDialog.DialogCode.Accepted:
            # The RGBCombinationDialog calls image_manager.set_image() to store the image in the active slot.
            active_slot = self.image_manager.current_slot
            slot_name = self.image_manager.get_slot_name(active_slot)
            print(f"RGB image stored in {slot_name}.")
            QMessageBox.information(self, "Success", f"RGB image combined and stored in {slot_name}.")
        else:
            print("RGB Combination cancelled by the user.")

    def rgb_extract(self):
        """Handle the RGB Extract action."""
        # 1. Determine which slot to extract from — use the current slot
        slot_to_extract = self.image_manager.current_slot
        image = self.image_manager._images.get(slot_to_extract, None)

        if image is None:
            QMessageBox.warning(self, "No Image", 
                f"Slot {slot_to_extract} does not contain an image to extract from.")
            print(f"Slot {slot_to_extract} is empty. Cannot perform RGB Extract.")
            return

        if image.ndim != 3 or image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", 
                "The selected image is not a valid 3-channel RGB image.")
            print("Invalid image format for RGB Extract. Expected a 3-channel RGB image.")
            return

        # 2. Helper to find the next free slot
        def find_next_free_slot(start=0):
            for s in range(start, self.image_manager.max_slots):
                if self.image_manager._images[s] is None:
                    return s
            return -1

        # 3. Check if we have enough free slots for R, G, B
        r_slot = find_next_free_slot(0)
        if r_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Red channel.")
            return

        g_slot = find_next_free_slot(r_slot + 1)  # or start=0 if you want them anywhere
        if g_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Green channel.")
            return

        b_slot = find_next_free_slot(g_slot + 1)
        if b_slot == -1:
            QMessageBox.warning(self, "No Free Slot", 
                "No empty slot available for the Blue channel.")
            return

        try:
            # 4. Split the RGB channels
            r_channel = image[..., 0].copy()
            g_channel = image[..., 1].copy()
            b_channel = image[..., 2].copy()

            # 5. Define metadata for each channel
            metadata_r = {
                'file_path': f"RGB Extract - Red Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_g = {
                'file_path': f"RGB Extract - Green Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }
            metadata_b = {
                'file_path': f"RGB Extract - Blue Channel from Slot {slot_to_extract}",
                'is_mono': True,
                'bit_depth': "32-bit floating point",
                'original_header': None
            }

            # 6. Store each channel in the free slots found
            self.image_manager._images[r_slot] = r_channel
            self.image_manager._metadata[r_slot] = metadata_r

            self.image_manager._images[g_slot] = g_channel
            self.image_manager._metadata[g_slot] = metadata_g

            self.image_manager._images[b_slot] = b_channel
            self.image_manager._metadata[b_slot] = metadata_b

            # 7. Update your local slot_names / slot_actions, etc.
            #    (Make sure these exist or adapt for your code.)
            #    For example:
            self.slot_names[r_slot] = "Red"
            self.slot_names[g_slot] = "Green"
            self.slot_names[b_slot] = "Blue"

            for slot_id, name in zip([r_slot, g_slot, b_slot], ["Red", "Green", "Blue"]):
                if slot_id in self.slot_actions:
                    self.slot_actions[slot_id].setText(name)
                    self.slot_actions[slot_id].setStatusTip(f"Open preview for {name}")

                if slot_id in self.preview_windows:
                    self.preview_windows[slot_id].setWindowTitle(f"Preview - {name}")

                # Menubar slot names, if used:
                if hasattr(self, 'menubar_slot_actions') and slot_id in self.menubar_slot_actions:
                    self.menubar_slot_actions[slot_id].setText(name)
                    self.menubar_slot_actions[slot_id].setStatusTip(f"Open preview for {name}")

            self.menuBar().update()

            print(f"Extracted R, G, B channels from Slot {slot_to_extract} "
                f"and stored in Slots {r_slot}, {g_slot}, {b_slot} as Red, Green, Blue.")

            QMessageBox.information(
                self, "Success",
                f"RGB channels extracted and stored in slots {r_slot} (Red), {g_slot} (Green), {b_slot} (Blue)."
            )

            # 8. Optionally open preview windows
            self.open_preview_window(slot=r_slot)
            self.open_preview_window(slot=g_slot)
            self.open_preview_window(slot=b_slot)

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to extract RGB channels: {e}")
            print(f"Error during RGB Extract: {e}")

    def extract_luminance(self):
        # Rec.709 linear luma weights
        _LUMA_WEIGHTS = np.array([0.2126, 0.7152, 0.0722], dtype=np.float32)
        """Extracts linear Y' luminance from the active RGB image and stores it in a user-selected slot."""
        # 1) Source checks
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before extracting luminance.")
            return
        current_image = self.image_manager.image
        if current_image.ndim != 3 or current_image.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image", "Luminance extraction requires an RGB image.")
            return

        # 2) Clip to [0,1] (you said you’re already 0–1, but just in case)
        img = np.clip(current_image, 0.0, 1.0).astype(np.float32)

        # 3) Compute Y' = 0.2126 R + 0.7152 G + 0.0722 B
        luminance = img[..., 0]*_LUMA_WEIGHTS[0] + \
                    img[..., 1]*_LUMA_WEIGHTS[1] + \
                    img[..., 2]*_LUMA_WEIGHTS[2]

        # 4) Build slot list & names
        max_slots = getattr(self.image_manager, "max_slots", 10)
        slots = list(range(max_slots))
        if hasattr(self, "slot_names"):
            display_names = [self.slot_names.get(i, f"Slot {i+1}") for i in slots]
        else:
            display_names = [f"Slot {i+1}" for i in slots]

        # 5) Ask user which slot to store luminance
        item, ok = QInputDialog.getItem(
            self, "Select Target Slot",
            "Select the slot to store the luminance image:",
            display_names, editable=False
        )
        if not ok:
            QMessageBox.information(self, "Operation Cancelled", "Luminance extraction was cancelled.")
            return
        target_slot = display_names.index(item)

        # 6) Store luminance
        luminance_metadata = {
            'file_path': "Luminance Extracted",
            'is_mono': True,
            'bit_depth': "32-bit floating point",
        }
        self.image_manager._images[target_slot]   = luminance
        self.image_manager._metadata[target_slot] = luminance_metadata
        print(f"Luminance image updated in slot {target_slot}.")
        self.image_manager.image_changed.emit(target_slot, luminance, luminance_metadata)

        # 7) Update UI names/actions
        if hasattr(self, "slot_names"):
            self.slot_names[target_slot] = "Luminance"
        if hasattr(self, 'slot_actions') and target_slot in self.slot_actions:
            self.slot_actions[target_slot].setText("Luminance")
            self.slot_actions[target_slot].setStatusTip("Open preview for Luminance")
        if hasattr(self, 'menubar_slot_actions') and target_slot in self.menubar_slot_actions:
            self.menubar_slot_actions[target_slot].setText("Luminance")
            self.menubar_slot_actions[target_slot].setStatusTip("Open preview for Luminance")
        self.menuBar().update()

        # 8) Open preview
        self.open_preview_window(slot=target_slot)


    def recombine_luminance(self):
        # Rec.709 linear luma weights
        _LUMA_WEIGHTS = np.array([0.2126, 0.7152, 0.0722], dtype=np.float32)
        """Recombines linear Y' luminance with an RGB image by preserving chroma ratios."""
        # 1) Select slots
        max_slots = getattr(self.image_manager, "max_slots", 10)
        available_slots = list(range(max_slots))
        dialog = RecombineDialog(available_slots, self)
        if dialog.exec() != QDialog.DialogCode.Accepted:
            QMessageBox.information(self, "Operation Cancelled", "Recombination operation was cancelled.")
            return
        luminance_slot, rgb_slot = dialog.getSelections()

        # 2) Retrieve data
        Y = self.image_manager._images[luminance_slot]
        RGB = self.image_manager._images[rgb_slot]

        # 3) Validate inputs
        if RGB is None or RGB.ndim != 3 or RGB.shape[2] != 3:
            QMessageBox.warning(self, "Invalid Image",
                                f"Slot {rgb_slot} must contain an RGB image for recombination.")
            return
        if Y is None or Y.ndim < 2:
            QMessageBox.warning(self, "Invalid Luminance Image",
                                f"Slot {luminance_slot} must contain a 2D luminance image.")
            return
        # if 3-channel luminance, take first channel
        if Y.ndim == 3 and Y.shape[2] > 1:
            QMessageBox.information(
                self, "Multiple Channels Detected",
                f"Luminance image in slot {luminance_slot} has multiple channels. Only the first channel will be used."
            )
            Y = Y[..., 0]

        # 4) Prepare arrays
        Y = np.clip(Y, 0.0, 1.0).astype(np.float32)
        rgb = np.clip(RGB, 0.0, 1.0).astype(np.float32)

        # 5) Compute original luma for chroma ratios
        orig_Y = rgb[...,0]*_LUMA_WEIGHTS[0] + \
                rgb[...,1]*_LUMA_WEIGHTS[1] + \
                rgb[...,2]*_LUMA_WEIGHTS[2]
        eps = 1e-6
        chroma = rgb / (orig_Y[..., None] + eps)

        # 6) Rebuild RGB = chroma × new Y'
        new_rgb = chroma * Y[..., None]
        new_rgb = np.clip(new_rgb, 0.0, 1.0)

        # 7) Push back into manager
        metadata = self.image_manager._metadata[rgb_slot].copy()
        metadata['file_path'] = f"Luminance Recombined (Lum Slot: {luminance_slot}, RGB Slot: {rgb_slot})"
        self.image_manager.set_image(new_rgb, metadata, step_name="Recombine Luminance")
        print(f"Recombined image updated in slot {rgb_slot} with luminance from slot {luminance_slot}.")

    def remove_gradient_with_graxpert(self):
        """Integrate GraXpert for gradient removal."""
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing the gradient.")
            return

        # Prompt user for smoothing value
        smoothing, ok = QInputDialog.getDouble(
            self,
            "GraXpert Smoothing Amount",
            "Enter smoothing amount (0.0 to 1.0):",
            decimals=2,
            min=0.0,
            max=1.0,
            value=0.1
        )
        if not ok:
            return  # User cancelled

        # Save the current image as a TIFF file
        input_basename = "input_image"
        input_path = os.path.join(os.getcwd(), f"{input_basename}.tif")
        save_image(self.image_manager.image, input_path, "tiff", "16-bit", None, is_mono=False)

        # Output will have the same base name with `_GraXpert` suffix
        output_basename = f"{input_basename}_GraXpert"
        output_directory = os.getcwd()

        # Determine the platform-specific GraXpert command
        current_os = platform.system()
        if current_os == "Windows":
            graxpert_cmd = "GraXpert.exe"
        elif current_os == "Darwin":  # macOS
            graxpert_cmd = "/Applications/GraXpert.app/Contents/MacOS/GraXpert"
        elif current_os == "Linux":
            graxpert_cmd = self.get_graxpert_path()
            if not graxpert_cmd:
                return  # User cancelled
        else:
            QMessageBox.critical(self, "Unsupported OS", f"Unsupported operating system: {current_os}")
            return

        # Build the command
        command = [
            graxpert_cmd,
            "-cmd", "background-extraction",
            input_path,
            "-cli",
            "-smoothing", str(smoothing),
            "-gpu", "true"
        ]

        # Run the command
        self.run_graxpert_command(command, output_basename, output_directory)

    def get_graxpert_path(self):
        """Prompt user to select the GraXpert path on Linux and save it."""
        graxpert_path = self.settings.value("graxpert/path", type=str)

        if not graxpert_path or not os.path.exists(graxpert_path):
            QMessageBox.information(self, "GraXpert Path", "Please select the GraXpert executable.")

            graxpert_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select GraXpert Executable",
                "",
                "Executable Files (*)"

            )
            if not graxpert_path:
                QMessageBox.warning(self, "Cancelled", "GraXpert path selection was cancelled.")
                return None  # User cancelled
            if not os.access(graxpert_path, os.X_OK):
                try:
                    os.chmod(graxpert_path, 0o755)  # Add execute permissions
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                    return None

            # Save the path for future use
            self.settings.setValue("graxpert/path", graxpert_path)

        return graxpert_path



    def run_graxpert_command(self, command, output_basename, output_directory):
        """Execute GraXpert asynchronously."""
        dialog = QDialog(self)
        dialog.setWindowTitle("GraXpert Progress")
        dialog.setMinimumSize(600, 400)
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit()
        text_edit.setReadOnly(True)
        layout.addWidget(text_edit)
        cancel_button = QPushButton("Cancel")
        layout.addWidget(cancel_button)

        thread = GraXpertThread(command)
        thread.stdout_signal.connect(text_edit.append)
        thread.stderr_signal.connect(text_edit.append)
        thread.finished_signal.connect(lambda code: self.on_graxpert_finished(code, output_basename, output_directory, dialog))
        cancel_button.clicked.connect(thread.terminate)

        thread.start()
        dialog.exec()

    def on_graxpert_finished(self, return_code, output_basename, output_directory, dialog):
        """Handle GraXpert process completion."""
        dialog.close()
        if return_code != 0:
            QMessageBox.critical(self, "Error", "GraXpert process failed.")
            return

        # Locate the output file with any extension
        output_file = None
        for ext in ["fits", "tif", "tiff", "png"]:
            candidate = os.path.join(output_directory, f"{output_basename}.{ext}")
            if os.path.exists(candidate):
                output_file = candidate
                break

        if not output_file:
            QMessageBox.critical(self, "Error", "GraXpert output file not found.")
            return

        # Load the processed image back
        processed_image, _, _, _ = load_image(output_file)

        # Check the number of dimensions to determine if the image is mono
        if processed_image.ndim == 2:
            print("GraXpert output is a mono image. Converting to RGB...")
            processed_image = np.stack([processed_image] * 3, axis=-1)

        # Set the processed image in the image manager
        self.image_manager.set_image(
            processed_image,
            {'file_path': output_file, 'description': "GraXpert Gradient Removed"}, step_name="GraXpert Gradient Removal"
        )

        QMessageBox.information(self, "Success", "Gradient removed successfully.")


    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)


    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def swap_slots(self, slot_a, slot_b):
        """
        Swap images and metadata between two slots.
        
        :param slot_a: The first slot number.
        :param slot_b: The second slot number.
        """
        try:
            # Retrieve images and metadata from both slots
            image_a = self.image_manager._images.get(slot_a, None)
            metadata_a = self.image_manager._metadata.get(slot_a, {}).copy()
            
            image_b = self.image_manager._images.get(slot_b, None)
            metadata_b = self.image_manager._metadata.get(slot_b, {}).copy()
            
            # Swap the images and metadata
            self.image_manager._images[slot_a] = image_b
            self.image_manager._metadata[slot_a] = metadata_b
            
            self.image_manager._images[slot_b] = image_a
            self.image_manager._metadata[slot_b] = metadata_a
            
            # Emit image_changed signals for both slots
            self.image_manager.image_changed.emit(slot_a, image_b, metadata_b)
            self.image_manager.image_changed.emit(slot_b, image_a, metadata_a)
            
            print(f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            QMessageBox.information(self, "Success", f"Swapped images between Slot {slot_a} and Slot {slot_b}.")
            
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to swap images between Slot {slot_a} and Slot {slot_b}: {e}")
            print(f"Error during swapping slots {slot_a} and {slot_b}: {e}")

    def copy_slot_to_target(self):
        """Copy from any source slot (Image or Mask) to any target slot (Image or Mask)."""
        # Open the enhanced CopySlotDialog
        dialog = CopySlotDialog(self, self.image_manager, self.mask_manager)
        result = dialog.exec()
        
        if result == QDialog.DialogCode.Accepted:
            # Retrieve selected source and target
            source_type, source_slot_num = dialog.get_selected_source()
            target_type, target_slot_num = dialog.get_selected_target()
            
            print(f"User selected to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            # Validate that source and target are not the same
            if source_type == target_type and source_slot_num == target_slot_num:
                QMessageBox.warning(self, "Invalid Operation", "Source and target slots are the same.")
                print("Source and target slots are identical. Operation aborted.")
                return
            
            # Retrieve source data
            try:
                if source_type == "Image":
                    source_image = self.image_manager._images.get(source_slot_num, None)
                    source_metadata = self.image_manager._metadata.get(source_slot_num, {}).copy()
                    if source_image is None:
                        QMessageBox.warning(self, "No Image", f"No image found in Image Slot {source_slot_num}.")
                        print(f"No image found in Image Slot {source_slot_num}.")
                        return
                elif source_type == "Mask":
                    source_image = self.mask_manager.get_mask(source_slot_num)
                    if source_image is None:
                        QMessageBox.warning(self, "No Mask", f"No mask found in Mask Slot {source_slot_num}.")
                        print(f"No mask found in Mask Slot {source_slot_num}.")
                        return
                    # Convert mask to grayscale if it's multi-channel
                    if source_image.ndim == 3:
                        source_image = cv2.cvtColor(source_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted multi-channel Mask Slot {source_slot_num} to grayscale.")
                    # Normalize mask to [0,1] if necessary
                    if source_image.max() > 1.0:
                        source_image = source_image.astype(np.float32) / 255.0
                        print(f"Normalized Mask Slot {source_slot_num} to [0,1].")
                    else:
                        source_image = source_image.astype(np.float32)
                        print(f"Mask Slot {source_slot_num} is already normalized.")
                    source_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Source Type", "Selected source type is invalid.")
                    print("Selected source type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve source data:\n{e}")
                print(f"Failed to retrieve source data: {e}")
                return
            
            # Retrieve target data
            try:
                if target_type == "Image":
                    target_image = self.image_manager._images.get(target_slot_num, None)
                    target_metadata = self.image_manager._metadata.get(target_slot_num, {}).copy()
                elif target_type == "Mask":
                    target_image = self.mask_manager.get_mask(target_slot_num)
                    target_metadata = {}  # Masks may not have metadata
                else:
                    QMessageBox.warning(self, "Invalid Target Type", "Selected target type is invalid.")
                    print("Selected target type is invalid.")
                    return
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to retrieve target data:\n{e}")
                print(f"Failed to retrieve target data: {e}")
                return
            
            # Check if target slot is occupied
            try:
                if target_type == "Image":
                    is_occupied = self.image_manager._images.get(target_slot_num, None) is not None
                elif target_type == "Mask":
                    is_occupied = self.mask_manager.get_mask(target_slot_num) is not None
                else:
                    is_occupied = False
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to check target slot:\n{e}")
                print(f"Failed to check target slot: {e}")
                return
            
            if is_occupied:
                overwrite = QMessageBox.question(
                    self,
                    "Overwrite Confirmation",
                    f"{target_type} Slot {target_slot_num} already contains data. Do you want to overwrite it?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                    QMessageBox.StandardButton.No
                )
                if overwrite != QMessageBox.StandardButton.Yes:
                    QMessageBox.information(self, "Operation Cancelled", "Copy operation cancelled.")
                    print("User chose not to overwrite the target slot.")
                    return
            
            # Proceed with the copy operation
            try:
                # Save current state of the target slot to undo stack (only for images)
                if is_occupied:
                    if target_type == "Image":
                        self.image_manager._undo_stacks[target_slot_num].append(
                            (self.image_manager._images[target_slot_num].copy(),
                            self.image_manager._metadata[target_slot_num].copy())
                        )
                        print(f"Image Slot {target_slot_num} state saved to undo stack.")
                    # For masks, skip saving to an undo stack.

            
            
                # Deep copy to prevent unintended modifications
                copied_image = source_image.copy()
                copied_metadata = source_metadata.copy()
            
                # If copying from a mask to an image slot, ensure grayscale and normalization
                if source_type == "Mask" and target_type == "Image":
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied mask to single-channel grayscale for Image Slot {target_slot_num}.")
                    # Ensure normalization to [0,1]
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied mask to [0,1] for Image Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied mask is already normalized for Image Slot {target_slot_num}.")
            
                # Assign to target slot
                if target_type == "Image":
                    # Ensure image is float32 normalized to [0,1]
                    if copied_image.dtype != np.float32 and copied_image.dtype != np.float64:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Converted copied image to float32 normalized [0,1] for Image Slot {target_slot_num}.")
                    self.image_manager._images[target_slot_num] = copied_image
                    self.image_manager._metadata[target_slot_num] = copied_metadata
                    # Emit image_changed signal
                    self.image_manager.image_changed.emit(target_slot_num, copied_image, copied_metadata)
                    print(f"Copied data assigned to Image Slot {target_slot_num}.")
                    self.update_slot_toolbar_highlight()
                elif target_type == "Mask":
                    # Ensure mask is single-channel and normalized
                    if copied_image.ndim == 3 and copied_image.shape[2] > 1:
                        copied_image = cv2.cvtColor(copied_image, cv2.COLOR_RGB2GRAY)
                        print(f"Converted copied image to single-channel grayscale for Mask Slot {target_slot_num}.")
                    if copied_image.max() > 1.0:
                        copied_image = copied_image.astype(np.float32) / 255.0
                        print(f"Normalized copied image to [0,1] for Mask Slot {target_slot_num}.")
                    else:
                        copied_image = copied_image.astype(np.float32)
                        print(f"Copied image is already normalized for Mask Slot {target_slot_num}.")
                    self.mask_manager.set_mask(target_slot_num, copied_image)
                    # Emit mask_changed signal if available
                    # Assuming MaskManager has a signal similar to image_changed
                    # self.mask_manager.mask_changed.emit(target_slot_num, copied_image)
                    print(f"Copied data assigned to Mask Slot {target_slot_num}.")
            
                QMessageBox.information(
                    self, 
                    "Copy Successful", 
                    f"{source_type} Slot {source_slot_num} successfully copied to {target_type} Slot {target_slot_num}."
                )
                print(f"Copy successful: {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.")
            
            except Exception as e:
                QMessageBox.critical(
                    self, 
                    "Copy Failed", 
                    f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}.\nError: {e}"
                )
                print(f"Failed to copy from {source_type} Slot {source_slot_num} to {target_type} Slot {target_slot_num}. Error: {e}")
        else:
            print("Copy Slot operation cancelled by the user.")

    # --------------------
    # Slot Preview Methods
    # --------------------
    def open_preview_window(self, slot):
        """Opens a separate preview window for the specified slot."""
        print(f"Attempting to open preview window for Slot {slot}. Current preview_windows: {self.preview_windows}")
        # Check if the slot index is valid
        if slot < 0 or slot >= self.image_manager.max_slots:
            QMessageBox.warning(self, "Invalid Slot", f"Slot {slot} is out of range.")
            return

        # Check if the slot has an image
        image = self.image_manager._images[slot]
        if image is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # Check if a preview window for this slot already exists
        if slot in self.preview_windows:
            # If the window is already open, bring it to the front
            existing_window = self.preview_windows[slot]
            existing_window.raise_()
            existing_window.activateWindow()
            print(f"Preview window for Slot {slot} is already open.")
            return

        # Create a new ImagePreview window with a copy of the image data
        image_copy = image.copy()
        preview = ImagePreview(image_data=image_copy, slot=slot, parent=self)  # Pass parent=self


        # Store the reference to prevent garbage collection
        self.preview_windows[slot] = preview
        print(f"Stored preview window for Slot {slot} in preview_windows.")

        # Connect the custom closed signal to the on_preview_closed method
        preview.closed.connect(self.on_preview_closed)

        # Show the preview window
        preview.show()
        print(f"Opened preview window for Slot {slot}.")

    def on_preview_closed(self, slot):
        """Handles the cleanup when a preview window is closed."""
        if slot in self.preview_windows:
            del self.preview_windows[slot]
            print(f"Preview window for Slot {slot} has been closed and removed from tracking.")
        else:
            print(f"No preview window found for Slot {slot} to remove.")

    def _format_status_name(self, metadata: dict) -> str:
        # Prefer file basename; fall back to display_name; otherwise “Untitled”
        file_path = metadata.get("file_path") or metadata.get("FILE") or metadata.get("path")
        if isinstance(file_path, (str, bytes, os.PathLike)):
            base = os.path.basename(str(file_path))
        else:
            base = metadata.get("display_name") or "Untitled"

        step = (metadata.get("step_name") or "").strip()
        return f"{base} — {step}" if step else base

    def on_image_changed(self, slot, image, metadata):
        """Update the status bar (file + step) and refresh any open previews."""
        try:
            self.file_name_label.setText(self._format_status_name(metadata or {}))
        except Exception:
            self.file_name_label.setText("Untitled")

        # update dims (your existing logic)
        if image is not None:
            if image.ndim == 2:
                h, w = image.shape
                self.dim_label.setText(f"{w} x {h}")
            elif image.ndim == 3:
                h, w, c = image.shape
                self.dim_label.setText(f"{w} x {h} x {c}")
            else:
                self.dim_label.setText("Unknown dimensions")
        else:
            self.dim_label.setText("—")

        # refresh preview if open
        if slot in self.preview_windows:
            preview_window = self.preview_windows[slot]
            preview_window.update_image_data(image.copy())
            self.update_slot_toolbar_highlight()

     

    def add_stars(self):
        """
        Opens the AddStarsDialog to configure and preview star additions.
        """
        try:
            print("Opening AddStarsDialog...")
            add_stars_dialog = AddStarsDialog(self.image_manager, parent=self)
            add_stars_dialog.stars_added.connect(self.receive_blended_image)
            add_stars_dialog.exec()  # Modal dialog
            print("AddStarsDialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to open AddStarsDialog:\n{e}")
            print(f"Failed to open AddStarsDialog: {e}")

    def receive_blended_image(self, blended_image):
        """
        Receives the blended image from AddStarsDialog and updates the current slot.
        """
        if blended_image is not None:
            current_slot = self.image_manager.current_slot

            # Prepare metadata
            current_metadata = self.image_manager._metadata.get(current_slot, {}).copy()
            addition_note = "Stars added using AddStarsDialog."
            if 'notes' in current_metadata and isinstance(current_metadata['notes'], list):
                current_metadata['notes'].append(addition_note)
            else:
                current_metadata['notes'] = [addition_note]

            # Assign the blended image and metadata to the current slot
            self.image_manager.set_image(blended_image, current_metadata, step_name="Star Addition")

            # Emit the image_changed signal with all required arguments
            self.image_manager.image_changed.emit(current_slot, blended_image, current_metadata)

            QMessageBox.information(self, "Success", "Stars added successfully.")
            print("Stars added successfully.")


    def remove_stars(self):
        """
        Prompts the user to select a star removal tool and then removes stars from the current image
        using either StarNet or CosmicClarityDarkStar and generates a stars-only image.
        Supports Windows, macOS, and Linux platforms.
        """
        # Prompt the user to select which tool to use.
        tool, ok = QInputDialog.getItem(
            self,
            "Select Star Removal Tool",
            "Choose a tool:",
            ["StarNet", "CosmicClarityDarkStar"],
            0,
            False
        )
        if not ok:
            print("User cancelled star removal tool selection.")
            return

        if tool == "CosmicClarityDarkStar":
            self.remove_stars_darkstar()
            return

        # --- StarNet branch (existing code) ---
        self.starnet_exe_path = self.settings.value("starnet/exe_path", "")

        print("Starting star removal process using StarNet...")

        # Step 1: Verify StarNet Executable Path
        if not self.starnet_exe_path:
            print("StarNet executable path not set. Prompting user to select executable.")
            self.select_starnet_exe()
            if not self.starnet_exe_path:
                print("User cancelled StarNet executable selection.")
                return  # User cancelled the selection
            else:
                print(f"StarNet executable selected: {self.starnet_exe_path}")
        else:
            print(f"Using existing StarNet executable path: {self.starnet_exe_path}")

        # Step 1.5: Check if the executable exists
        if not os.path.exists(self.starnet_exe_path):
            QMessageBox.critical(self, "StarNet Not Found",
                                f"StarNet executable not found at {self.starnet_exe_path}. Aborting star removal process.")
            print(f"StarNet executable not found: {self.starnet_exe_path}")
            return

        # Step 2: Ensure current image is loaded
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing stars.")
            print("No image loaded. Exiting star removal process.")
            return

        print("Image is loaded. Proceeding with star removal.")

        # Step 3: Determine the Operating System
        current_os = platform.system()
        print(f"Operating System detected: {current_os}")
        if current_os not in ["Windows", "Darwin", "Linux"]:
            QMessageBox.critical(self, "Unsupported OS",
                                f"The current operating system '{current_os}' is not supported.")
            print(f"Unsupported operating system: {current_os}")
            return

        # Step 4: Ask if the image is linear
        reply = QMessageBox.question(
            self,
            "Image Linearity",
            "Is the current image linear?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        
        if self.image_manager.image.ndim == 2 or (self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 1):
            print("Converting single-channel image to 3-channel RGB...")
            processing_image = np.stack([self.image_manager.image] * 3, axis=-1)
        else:
            processing_image = self.image_manager.image

        if reply == QMessageBox.StandardButton.Yes:
            print("Image is linear. Applying stretch.")

            # Apply stretch
            stretched_image = self.stretch_image(processing_image)
            processing_image = stretched_image
            print("Image stretched successfully.")
            self.image_was_stretched = True
        else:
            print("Image is not linear. Proceeding without stretching.")
            self.image_was_stretched = False

        # Step 4: Set Command Parameters Based on OS
        self.starnet_dir = os.path.dirname(self.starnet_exe_path)
        self.input_image_path = os.path.join(self.starnet_dir, "imagetoremovestars.tif")
        self.output_image_path = os.path.join(self.starnet_dir, "starless.tif")
        original_image = processing_image

        print(f"StarNet directory: {self.starnet_dir}")
        print(f"Input image path: {self.input_image_path}")
        print(f"Output image path: {self.output_image_path}")

        # Convert image from [0,1] to [0, 65535] for 16-bit TIFF
        image_16bit = (original_image * 65535).astype(np.uint16)
        image_bgr_16bit = cv2.cvtColor(image_16bit, cv2.COLOR_RGB2BGR)
        cv2.imwrite(self.input_image_path, image_bgr_16bit)
        print(f"Input image saved at {self.input_image_path}")

        # Prepare the command based on the OS
        if current_os == "Windows":
            chunk_size = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(chunk_size)
            ]
            print("Preparing command for Windows.")
        elif current_os == "Linux":
            chunk_size = 256
            command = [
                self.starnet_exe_path,
                self.input_image_path,
                self.output_image_path,
                str(chunk_size)
            ]
            print("Preparing command for Linux.")
        elif current_os == "Darwin":
            executable_name = os.path.basename(self.starnet_exe_path).lower()
            if "starnet2" in executable_name:
                command = [
                    self.starnet_exe_path,
                    "--input", self.input_image_path,
                    "--output", self.output_image_path
                ]
                print("Preparing command for macOS using StarNet2 arguments.")
            else:
                command = [
                    self.starnet_exe_path,
                    self.input_image_path,
                    self.output_image_path
                ]
                print("Preparing command for macOS using StarNet++ arguments.")

        print(f"StarNet command: {' '.join(command)}")

        # Step 5: Ensure the StarNet Executable has Execute Permissions (for macOS and Linux)
        if current_os in ["Darwin", "Linux"]:
            if not os.access(self.starnet_exe_path, os.X_OK):
                print(f"StarNet executable not executable. Setting execute permissions for {self.starnet_exe_path}")
                try:
                    os.chmod(self.starnet_exe_path, 0o755)
                    print("Execute permissions set.")
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error",
                                        f"Failed to set execute permissions for StarNet executable: {e}")
                    print(f"Failed to set execute permissions for {self.starnet_exe_path}: {e}")
                    return
            else:
                print("StarNet executable already has execute permissions.")
        else:
            print("No need to set execute permissions for Windows.")

        # Step 6: Initialize and Show StarNetDialog
        starnet_dialog = StarNetDialog()
        starnet_dialog.show()

        # Step 7: Initialize StarNetThread
        self.starnet_thread = StarNetThread(command, self.starnet_dir)
        self.starnet_thread.stdout_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.stderr_signal.connect(starnet_dialog.append_text)
        self.starnet_thread.finished_signal.connect(lambda return_code: self.on_starnet_finished(return_code, starnet_dialog, self.output_image_path))
        starnet_dialog.cancel_button.clicked.connect(self.starnet_thread.stop)
        self.starnet_thread.start()


    def on_starnet_finished(self, return_code, dialog, output_image_path):
        """
        Handles the completion of the StarNet process.
        """
        dialog.append_text(f"\nProcess finished with return code {return_code}.\n")
        if return_code != 0:
            QMessageBox.critical(self, "StarNet Error", f"StarNet failed with return code {return_code}.")
            print(f"StarNet failed with return code {return_code}.")
            dialog.close()
            return

        # Step 8: Load the starless image
        if not os.path.exists(output_image_path):
            QMessageBox.critical(self, "StarNet Error", "Starless image was not created.")
            print(f"Starless image was not created at {output_image_path}.")
            dialog.close()
            return

        dialog.append_text(f"Starless image found at {output_image_path}. Loading image...\n")
        starless_bgr = cv2.imread(output_image_path, cv2.IMREAD_UNCHANGED)
        if starless_bgr is None:
            QMessageBox.critical(self, "StarNet Error", "Failed to load starless image.")
            dialog.close()
            return

        dialog.append_text("Starless image loaded successfully.\n")
        starless_rgb = cv2.cvtColor(starless_bgr, cv2.COLOR_BGR2RGB).astype('float32') / 65535.0

        # Unstretch if needed
        if getattr(self, 'image_was_stretched', False):
            dialog.append_text("Unstretching the starless image...\n")
            starless_rgb = self.unstretch_image(starless_rgb)
            dialog.append_text("Starless image unstretched successfully.\n")
        else:
            dialog.append_text("Image was not stretched. Proceeding without unstretching.\n")

        # Ensure 3-channel
        if starless_rgb.ndim == 2 or (starless_rgb.ndim == 3 and starless_rgb.shape[2] == 1):
            starless_rgb = np.stack([starless_rgb]*3, axis=-1)

        orig = self.image_manager.image
        if orig.ndim == 2 or (orig.ndim == 3 and orig.shape[2] == 1):
            original_rgb = np.stack([orig]*3, axis=-1)
        else:
            original_rgb = orig

        # Step 9: Generate Stars-Only image
        dialog.append_text("Generating stars-only image...\n")
        with np.errstate(divide='ignore', invalid='ignore'):
            stars_only = (original_rgb - starless_rgb) / (1.0 - starless_rgb)
            stars_only = np.nan_to_num(stars_only, nan=0.0, posinf=0.0, neginf=0.0)
        stars_only = np.clip(stars_only, 0.0, 1.0)
        dialog.append_text("Stars-only image generated.\n")

        # ─── Apply mask to Stars-Only ─────────────────────────────────────
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = stars_only.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32')/255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    mask3 = mask[:, :, None]
                    mask3 = np.repeat(mask3, 3, axis=2)
                    mask3 = np.clip(mask3, 0.0, 1.0)
                    stars_only = stars_only * mask3
                    dialog.append_text("✅ Applied active mask to the stars-only image.\n")
                else:
                    dialog.append_text("⚠️ Stars-only mask size mismatch; skipping mask on stars-only.\n")
        else:
            dialog.append_text("ℹ️ No active mask for stars-only; skipping.\n")

        # Step 10: Push Stars-Only to next slot
        available_slot = None
        for slot in range(self.image_manager.max_slots):
            img = self.image_manager._images.get(slot)
            if img is None or (isinstance(img, np.ndarray) and img.shape[:2] <= (10,10)):
                available_slot = slot
                break

        if available_slot is not None:
            meta = {'slot_name': 'Stars_Only'}
            self.image_manager.update_image(stars_only, metadata=meta, slot=available_slot)
            self.image_manager._metadata[available_slot]['slot_name'] = "Stars_Only"
            self.slot_names[available_slot] = "Stars_Only"
            if available_slot in self.slot_actions:
                self.slot_actions[available_slot].setText("Stars_Only")
            if available_slot in self.preview_windows:
                self.preview_windows[available_slot].setWindowTitle("Preview - Stars_Only")
            if hasattr(self, 'menubar_slot_actions') and available_slot in self.menubar_slot_actions:
                self.menubar_slot_actions[available_slot].setText("Stars_Only")
            self.menuBar().update()
            self.open_preview_window(slot=available_slot)
            dialog.append_text(f"Stars-only image pushed to slot {available_slot}.\n")
        else:
            dialog.append_text("⚠️ No available slot for stars-only image.\n")

        # ─── Mask-blend Starless and update ─────────────────────────────────
        dialog.append_text("Preparing to update ImageManager with starless (mask-blend)...\n")
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = starless_rgb.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32')/255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    mask3 = mask[:, :, None]
                    mask3 = np.repeat(mask3, 3, axis=2)
                    mask3 = np.clip(mask3, 0.0, 1.0)
                    final_starless = starless_rgb * mask3 + original_rgb * (1.0 - mask3)
                    dialog.append_text("✅ Applied active mask to the starless image.\n")
                else:
                    dialog.append_text("⚠️ Starless mask size mismatch; skipping mask on starless.\n")
                    final_starless = starless_rgb
            else:
                dialog.append_text("⚠️ No active mask found; using raw starless.\n")
                final_starless = starless_rgb
        else:
            dialog.append_text("ℹ️ Mask not active; using raw starless.\n")
            final_starless = starless_rgb

        # Step 11: Update ImageManager with starless
        self.image_manager.set_image(
            final_starless,
            metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}),
            step_name="Stars Removed"
        )
        QMessageBox.information(self, "Success", "Starless image updated successfully.")
        dialog.append_text("ImageManager updated with starless image.\n")

        # Cleanup
        try:
            if os.path.exists(self.input_image_path):
                os.remove(self.input_image_path)
            if os.path.exists(self.output_image_path):
                os.remove(self.output_image_path)
        except Exception as e:
            dialog.append_text(f"Cleanup error: {e}\n")

        dialog.close()




    def remove_stars_darkstar(self):
        """
        Removes stars from the current image using CosmicClarityDarkStar headless mode
        and generates a stars-only image. In this branch no linearity or conversion is needed –
        the input image is assumed to be a 32-bit, 0-1 normalized array.
        """
        print("Starting star removal process using CosmicClarityDarkStar...")

        # Retrieve the parent Cosmic Clarity folder from settings.
        cosmic_clarity_folder = self.settings.value("cosmic_clarity_folder", "")
        if not cosmic_clarity_folder:
            QMessageBox.critical(self, "Cosmic Clarity Folder Error",
                                "Cosmic Clarity folder not set in preferences.")
            print("Cosmic Clarity folder not set in preferences.")
            return

        # Determine the CosmicClarityDarkStar executable based on OS.
        current_os = platform.system()
        if current_os == "Windows":
            executable_name = "setiastrocosmicclarity_darkstar.exe"
        else:
            executable_name = "setiastrocosmicclarity_darkstar"
        darkstar_exe_path = os.path.join(cosmic_clarity_folder, executable_name)
        print(f"Using CosmicClarityDarkStar executable: {darkstar_exe_path}")

        if not os.path.exists(darkstar_exe_path):
            QMessageBox.critical(self, "CosmicClarityDarkStar Not Found",
                                f"CosmicClarityDarkStar executable not found at {darkstar_exe_path}. Aborting star removal process.")
            print(f"CosmicClarityDarkStar executable not found: {darkstar_exe_path}")
            return

        # Step 2: Ensure current image is loaded
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "Please load an image before removing stars.")
            print("No image loaded. Exiting star removal process.")
            return

        print("Image is loaded. Proceeding with star removal using CosmicClarityDarkStar.")

        # Prompt the user for Dark Star parameters:
        # Show parameter dialog
        config_dialog = DarkStarConfigDialog(self)
        if not config_dialog.exec():
            print("User cancelled Dark Star settings dialog.")
            return
        params = config_dialog.get_values()
        disable_gpu = params["disable_gpu"]
        mode = params["mode"]
        show_extracted_stars = params["show_extracted_stars"]
        chunk_size_value = params["chunk_size"]

        # Set up input/output folders (which Dark Star will use automatically)
        input_dir = os.path.join(cosmic_clarity_folder, "input")
        output_dir = os.path.join(cosmic_clarity_folder, "output")
        os.makedirs(input_dir, exist_ok=True)
        os.makedirs(output_dir, exist_ok=True)

        # Save the current image in the input folder as a 32-bit TIFF.
        base_filename = "imagetoremovestars.tif"
        self.input_image_path = os.path.join(input_dir, base_filename)
        print(f"Saving input image as 32-bit float TIFF to {self.input_image_path} ...")
        save_image(
            self.image_manager.image,
            self.input_image_path,
            original_format="tif",
            bit_depth="32-bit floating point",
            original_header=None,
            is_mono=False,
            image_meta=None,
            file_meta=None
        )
        print(f"Input image saved at {self.input_image_path}")

        # Build command arguments based on user choices.
        args_list = []
        if disable_gpu:
            args_list.append("--disable_gpu")
        args_list.extend(["--star_removal_mode", mode])
        if show_extracted_stars:
            args_list.append("--show_extracted_stars")
        args_list.extend(["--chunk_size", str(chunk_size_value)])

        # Final command to launch Dark Star
        command = [darkstar_exe_path] + args_list
        print(f"CosmicClarityDarkStar command: {' '.join(command)}")

        # Ensure executable permissions if needed
        if current_os in ["Darwin", "Linux"]:
            if not os.access(darkstar_exe_path, os.X_OK):
                print(f"Setting execute permissions for: {darkstar_exe_path}")
                try:
                    os.chmod(darkstar_exe_path, 0o755)
                except Exception as e:
                    QMessageBox.critical(self, "Permission Error",
                                        f"Failed to set execute permissions for DarkStar executable: {e}")
                    print(f"Permission error: {e}")
                    return
            else:
                print("Executable permission already set.")
        else:
            print("Windows platform — execute permission check skipped.")

        # Show progress dialog
        darkstar_dialog = StarNetDialog()
        darkstar_dialog.show()

        # Run Dark Star in background thread
        self.darkstar_thread = StarNetThread(command, output_dir)
        self.darkstar_thread.stdout_signal.connect(darkstar_dialog.append_text)
        self.darkstar_thread.stderr_signal.connect(darkstar_dialog.append_text)
        self.darkstar_thread.finished_signal.connect(
            lambda return_code: self.on_darkstar_finished(return_code, darkstar_dialog, output_dir)
        )
        darkstar_dialog.cancel_button.clicked.connect(self.darkstar_thread.stop)
        self.darkstar_thread.start()



    def on_darkstar_finished(self, return_code, dialog, output_dir):
        """
        Handles the completion of the CosmicClarityDarkStar process.
        Loads the starless image (with _starless suffix) and, if generated, the stars-only image (with _stars_only suffix).
        Updates the ImageManager and cleans up temporary files.
        """
        dialog.append_text(f"\nProcess finished with return code {return_code}.\n")
        if return_code != 0:
            QMessageBox.critical(self, "CosmicClarityDarkStar Error",
                                f"CosmicClarityDarkStar failed with return code {return_code}.")
            dialog.close()
            return

        # ─── Load starless ───────────────────────────────────────────
        starless_path = os.path.join(output_dir, "imagetoremovestars_starless.tif")
        if not os.path.exists(starless_path):
            QMessageBox.critical(self, "CosmicClarityDarkStar Error", "Starless image was not created.")
            dialog.close()
            return

        dialog.append_text(f"Loading starless image from {starless_path}...\n")
        starless = cv2.imread(starless_path, cv2.IMREAD_UNCHANGED)
        if starless is None:
            QMessageBox.critical(self, "CosmicClarityDarkStar Error", "Failed to load starless image.")
            dialog.close()
            return

        dialog.append_text("Starless image loaded successfully.\n")
        starless_rgb = cv2.cvtColor(starless, cv2.COLOR_BGR2RGB).astype('float32')

        # Ensure 3-channel
        if starless_rgb.ndim == 2 or (starless_rgb.ndim == 3 and starless_rgb.shape[2] == 1):
            starless_rgb = np.stack([starless_rgb]*3, axis=-1)

        orig = self.image_manager.image
        if orig.ndim == 2 or (orig.ndim == 3 and orig.shape[2] == 1):
            original_rgb = np.stack([orig]*3, axis=-1)
        else:
            original_rgb = orig

        # ─── Load & mask-push stars-only ─────────────────────────────
        stars_path = os.path.join(output_dir, "imagetoremovestars_stars_only.tif")
        if os.path.exists(stars_path):
            dialog.append_text(f"Loading stars-only image from {stars_path}...\n")
            stars_only = cv2.imread(stars_path, cv2.IMREAD_UNCHANGED)
            if stars_only is not None:
                stars_only_rgb = cv2.cvtColor(stars_only, cv2.COLOR_BGR2RGB).astype('float32')

                # Apply active mask to stars-only if present
                mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
                if mask_slot == self.image_manager.current_slot:
                    mask = self.image_manager.mask_manager.get_applied_mask()
                    if mask is not None:
                        h, w = stars_only_rgb.shape[:2]
                        if mask.shape == (h, w):
                            if mask.dtype != np.float32:
                                mask = mask.astype('float32') / 255.0
                            if mask.ndim == 3:
                                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                            m3 = mask[:, :, None]
                            m3 = np.repeat(m3, 3, axis=2)
                            stars_only_rgb *= np.clip(m3, 0.0, 1.0)
                            dialog.append_text("✅ Applied active mask to stars-only image.\n")
                        else:
                            dialog.append_text("⚠️ Stars-only mask size mismatch; skipping mask.\n")
                    else:
                        dialog.append_text("⚠️ No active mask for stars-only; skipping.\n")
                else:
                    dialog.append_text("ℹ️ Mask not active for stars-only; skipping.\n")

                # push into next free slot
                available_slot = None
                for slot in range(self.image_manager.max_slots):
                    img = self.image_manager._images.get(slot)
                    if img is None or (isinstance(img, np.ndarray) and img.shape[:2] <= (10,10)):
                        available_slot = slot
                        break
                if available_slot is not None:
                    meta = {'slot_name': 'Stars_Only'}
                    self.image_manager.update_image(stars_only_rgb, metadata=meta, slot=available_slot)
                    self.image_manager._metadata[available_slot]['slot_name'] = "Stars_Only"
                    self.slot_names[available_slot] = "Stars_Only"
                    if available_slot in self.slot_actions:
                        self.slot_actions[available_slot].setText("Stars_Only")
                    if available_slot in self.preview_windows:
                        self.preview_windows[available_slot].setWindowTitle("Preview - Stars_Only")
                    if hasattr(self, 'menubar_slot_actions') and available_slot in self.menubar_slot_actions:
                        self.menubar_slot_actions[available_slot].setText("Stars_Only")
                    self.menuBar().update()
                    self.open_preview_window(slot=available_slot)
                    dialog.append_text(f"Stars-only image pushed to slot {available_slot}.\n")
                else:
                    dialog.append_text("⚠️ No available slot for stars-only image.\n")
            else:
                dialog.append_text("Failed to load stars-only image.\n")
        else:
            dialog.append_text("No stars-only image generated.\n")

        # ─── Mask-blend starless & update ──────────────────────────────
        dialog.append_text("Mask-blending starless image before update...\n")
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.image_manager.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                h, w = starless_rgb.shape[:2]
                if mask.shape == (h, w):
                    if mask.dtype != np.float32:
                        mask = mask.astype('float32') / 255.0
                    if mask.ndim == 3:
                        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                    m3 = mask[:, :, None]
                    m3 = np.repeat(m3, 3, axis=2)
                    final_starless = starless_rgb * m3 + original_rgb * (1.0 - m3)
                    dialog.append_text("✅ Applied active mask to starless image.\n")
                else:
                    dialog.append_text("⚠️ Starless mask size mismatch; skipping mask.\n")
                    final_starless = starless_rgb
            else:
                dialog.append_text("⚠️ No active mask found; using raw starless.\n")
                final_starless = starless_rgb
        else:
            dialog.append_text("ℹ️ Mask not active; using raw starless.\n")
            final_starless = starless_rgb

        # ─── Final update ───────────────────────────────────────────────
        self.image_manager.set_image(
            final_starless,
            metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}),
            step_name="Stars Removed"
        )
        QMessageBox.information(self, "Success",
                                "Starless image updated successfully via CosmicClarityDarkStar.")
        dialog.append_text("ImageManager updated with starless image.\n")

        # ─── Cleanup ───────────────────────────────────────────────────
        try:
            for p in (self.input_image_path, starless_path, stars_path):
                if os.path.exists(p):
                    os.remove(p)
            dialog.append_text("Temporary files cleaned up.\n")
        except Exception as e:
            dialog.append_text(f"Cleanup error: {e}\n")

        dialog.close()



    
    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.15

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def select_starnet_exe(self):
        """
        Prompts the user to select the StarNet executable based on the operating system.
        Saves the path using QSettings for future use.
        """


        current_os = platform.system()

        if current_os == "Windows":
            filter_str = "Executable Files (*.exe)"
        elif current_os in ["Linux", "Darwin"]:
            # For Unix-based systems, executables may not have extensions
            filter_str = "All Executable Files (*)"
        else:
            QMessageBox.critical(self, "Unsupported OS", f"The current operating system '{current_os}' is not supported.")
            return

        exe_path, _ = QFileDialog.getOpenFileName(
            self,
            "Select StarNet Executable",
            "",
            filter_str

        )
        if exe_path:
            # For Windows, ensure the file has .exe extension
            if current_os == "Windows" and not exe_path.lower().endswith('.exe'):
                QMessageBox.warning(self, "Invalid File", "Please select a valid .exe file for StarNet.")
                return
            # For Unix-based systems, optionally check if it's executable
            elif current_os in ["Linux", "Darwin"]:
                if not os.access(exe_path, os.X_OK):
                    reply = QMessageBox.question(
                        self,
                        "Set Execute Permissions",
                        "The selected file does not have execute permissions. Would you like to add them?",
                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                        QMessageBox.StandardButton.Yes
                    )
                    if reply == QMessageBox.StandardButton.Yes:
                        try:
                            os.chmod(exe_path, 0o755)
                        except Exception as e:
                            QMessageBox.critical(self, "Permission Error", f"Failed to set execute permissions:\n{e}")
                            return
                    else:
                        QMessageBox.information(self, "Cancelled", "Execute permissions not set. Cannot proceed.")
                        return
            self.starnet_exe_path = exe_path
            # Save the path using QSettings
            self.settings.setValue("starnet/exe_path", self.starnet_exe_path)
            QMessageBox.information(self, "StarNet Executable Set", f"StarNet executable set to:\n{exe_path}")
        else:
            QMessageBox.information(self, "Cancelled", "StarNet executable selection was cancelled.")



    def open_clahe_dialog(self):
        """Opens the CLAHE dialog window."""
        dialog = CLAHEDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_morpho_dialog(self):
        """Opens the Morphological Operations dialog window."""
        dialog = MorphologyDialog(self.image_manager, self.mask_manager, self)
        dialog.exec()

    def open_whitebalance_dialog(self):
        """Opens the White Balance dialog window."""
        dialog = WhiteBalanceDialog(self.image_manager, self)
        dialog.exec()

    def open_background_neutralization_dialog(self):
        """Opens the Background Neutralization dialog window."""
        dialog = BackgroundNeutralizationDialog(self.image_manager, self)
        dialog.exec()

    def open_remove_green_dialog(self):
        """
        Opens the RemoveGreenDialog.
        """
        if self.image_manager.image is None:
            QMessageBox.warning(self, "No Image", "No image loaded in the current slot.")
            return

        dialog = RemoveGreenDialog(
            image_manager=self.image_manager,
            mask_manager=self.mask_manager,
            parent=self
        )
        dialog.exec()


    def dragEnterEvent(self, event):
        """Handle the drag enter event."""
        # Check if the dragged content is a file
        if event.mimeData().hasUrls():
            event.accept()
        else:
            event.ignore()

    def dropEvent(self, event):
        """Handle the drop event."""
        # Get the file path from the dropped file
        file_path = event.mimeData().urls()[0].toLocalFile()
        
        # Check if the file is an image (you can customize this check as needed)
        if file_path.lower().endswith(('.png', '.tif', '.tiff', '.fits', '.xisf', '.fit', '.fit.gz', '.fits.gz', '.jpg', '.jpeg', '.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            try:
                # Load the image into ImageManager
                image, header, bit_depth, is_mono = load_image(file_path)
                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }
                self.image_manager.add_image(self.image_manager.current_slot, image, metadata)  # Make sure to specify the slot here
                print(f"Image {file_path} loaded successfully via drag and drop.")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {e}")
        else:
            QMessageBox.warning(self, "Invalid File", "Only image files are supported.")

    def update_file_name(self, slot, image, metadata):
        """Update the file name in the status bar."""
        file_path = metadata.get('file_path', None)
        
        if file_path:
            # Debugging: Print type and value of file_path
            print(f"DEBUG: file_path type: {type(file_path)}, value: {file_path}")
            
            # Check if file_path is a QLabel
            if isinstance(file_path, QLabel):
                # Extract text from QLabel
                file_path_str = file_path.text()
                print("WARNING: 'file_path' was a QLabel. Extracted text.")
            elif isinstance(file_path, (str, bytes, os.PathLike)):
                # Correct type
                file_path_str = file_path
            else:
                # Unsupported type
                file_path_str = "Invalid file path"
                QMessageBox.warning(
                    self,
                    "Invalid File Path",
                    f"The provided file path is invalid (type: {type(file_path)})."
                )
                print(f"WARNING: 'file_path' is of unsupported type: {type(file_path)}")
                self.file_name_label.setText(file_path_str)
                return  # Exit early since the path is invalid
            
            # Safely set the file name label
            try:
                base_name = os.path.basename(file_path_str)
                self.file_name_label.setText(base_name)
                print(f"File name updated to: {base_name}")
            except Exception as e:
                QMessageBox.critical(
                    self,
                    "Error Updating File Name",
                    f"An error occurred while updating the file name:\n{str(e)}"
                )
                print(f"ERROR: Failed to set file name label: {e}")
        else:
            self.file_name_label.setText("No file selected")
            print("No file path provided in metadata.")
        
        # If slot == 0 and we have a valid image, update dimensions
        if image is not None:
            # Check the number of dimensions in the image array.
            if image.ndim == 2:
                # 2D image (height, width)
                h, w = image.shape
                self.dim_label.setText(f"{w} x {h}")
                print(f"Image dimensions updated to: {w} x {h}")
            elif image.ndim == 3:
                # 3D image (height, width, channels)
                h, w, c = image.shape
                self.dim_label.setText(f"{w} x {h} x {c}")
                print(f"Image dimensions updated to: {w} x {h} x {c}")
            else:
                self.dim_label.setText("Unknown dimensions")
                print("Image dimensions not updated due to unrecognized shape.")
        else:
            # No image available
            self.dim_label.setText("—")
            print("Image dimensions not updated.")   

    def apply_theme(self, theme):
        """Apply the selected theme to the application and persist it."""
        self.current_theme = theme
        self.settings.setValue("theme", theme)

        if theme == "light":
            light_stylesheet = """ 
            QWidget {
                background-color: #f0f0f0;
                color: #000000;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 2px;
            }
            QPushButton {
                background-color: #e0e0e0;
                border: 1px solid #cccccc;
                color: #000000;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #d0d0d0;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #ffffff;
            }
            QTreeWidget {
                background-color: #ffffff;
                border: 1px solid #cccccc;
                color: #000000;
            }
            QHeaderView::section {
                background-color: #f0f0f0;
                color: #000000;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #cccccc; 
                background-color: #f0f0f0;
            }
            QTabBar::tab {
                background: #e0e0e0;
                color: #000000;
                padding: 5px;
                border: 1px solid #cccccc;
                border-bottom: none;
            }
            QTabBar::tab:selected {
                background: #d0d0d0;
                border-color: #000000;
            }
            QTabBar::tab:hover {
                background: #c0c0c0;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;
            }
            QMenu {
                background-color: #f0f0f0;
                color: #000000;
            }
            QMenu::item:selected {
                background-color: #d0d0d0; 
                color: #000000;
            }
            """
            self.setStyleSheet(light_stylesheet)

        elif theme == "dark":
            dark_stylesheet = """
            QWidget {
                background-color: #2b2b2b;
                color: #dcdcdc;
                font-family: Arial, sans-serif;
            }
            QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 2px;
            }
            QPushButton {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
                padding: 5px;
            }
            QPushButton:hover {
                background-color: #4a4a4a;
            }
            QScrollBar:vertical, QScrollBar:horizontal {
                background: #3c3f41;
            }
            QTreeWidget {
                background-color: #3c3f41;
                border: 1px solid #5c5c5c;
                color: #ffffff;
            }
            QHeaderView::section {
                background-color: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
            }
            QTabWidget::pane { 
                border: 1px solid #5c5c5c; 
                background-color: #2b2b2b;
            }
            QTabBar::tab {
                background: #3c3f41;
                color: #dcdcdc;
                padding: 5px;
                border: 1px solid #5c5c5c;
                border-bottom: none;
            }
            QTabBar::tab:selected {
                background: #4a4a4a;
                border-color: #dcdcdc;
            }
            QTabBar::tab:hover {
                background: #505050;
            }
            QTabBar::tab:!selected {
                margin-top: 2px;
            }
            QMenu {
                background-color: #2b2b2b;
                color: #dcdcdc;
            }
            QMenu::item:selected {
                background-color: #3a75c4;
                color: #ffffff;
            }       
            """
            self.setStyleSheet(dark_stylesheet)

        elif theme == "custom":
            custom_stylesheet = self.settings.value("custom_stylesheet", "")
            if custom_stylesheet:
                self.setStyleSheet(custom_stylesheet)
            else:
                print("⚠️ No custom stylesheet found in settings.")

        # Update mask banner styling
        if self.mask_manager.get_applied_mask() is not None:
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
        else:
            self.mask_banner.setStyleSheet("background-color: transparent; color: #dcdcdc; font-size: 14px; padding: 5px;")


    def open_custom_theme_dialog(self):
        # Ask user for a background color
        bg_color = QColorDialog.getColor(title="Select Background Color", parent=self)
        if not bg_color.isValid():
            return

        # Ask user for a text color
        text_color = QColorDialog.getColor(title="Select Text Color", parent=self)
        if not text_color.isValid():
            return

        # Ask user for a font
        font, ok = QFontDialog.getFont(self)
        if not ok:
            return

        self.current_theme = "custom"

        # Generate a stylesheet using user choices
        lighter_bg = bg_color.lighter(300)
        darker_bg = bg_color.darker(120)

        custom_stylesheet = f"""
        QWidget {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
            font-family: {font.family()};
            font-size: {font.pointSize()}pt;
        }}

        QLineEdit, QComboBox, QSpinBox, QDoubleSpinBox {{
            background-color: {bg_color.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
            padding: 2px;
        }}

        QLabel {{
            background-color: {darker_bg.name()};
            color: {text_color.name()};
        }}

        QPushButton {{
            background-color: {lighter_bg.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
            padding: 5px;
        }}

        QPushButton:hover {{
            background-color: {text_color.name()};
            color: {bg_color.name()};
        }}

        QScrollBar:vertical, QScrollBar:horizontal {{
            background: {darker_bg.name()};
        }}

        QTreeWidget {{
            background-color: {darker_bg.name()};
            border: 1px solid {text_color.name()};
            color: {text_color.name()};
        }}

        QHeaderView::section {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
            padding: 5px;
        }}

        QTabWidget::pane {{ 
            border: 1px solid {text_color.name()}; 
            background-color: {bg_color.name()};
        }}

        QTabBar::tab {{
            background: {lighter_bg.name()};
            color: {text_color.name()};
            padding: 5px;
            border: 1px solid {text_color.name()};
            border-bottom: none;
        }}

        QTabBar::tab:selected {{
            background: {text_color.name()};
            color: {bg_color.name()};
            border-color: {text_color.name()};
        }}

        QTabBar::tab:hover {{
            background: {text_color.name()};
            color: {bg_color.name()};
        }}

        QTabBar::tab:!selected {{
            margin-top: 2px;
        }}

        QMenu {{
            background-color: {bg_color.name()};
            color: {text_color.name()};
        }}

        QMenu::item:selected {{
            background-color: {text_color.name()};
            color: {bg_color.name()};
        }}
        """
        self.setStyleSheet(custom_stylesheet)

        # Adjust banner style accordingly
        if self.mask_manager.get_applied_mask() is not None:
            self.mask_banner.setStyleSheet("background-color: orange; color: black; font-size: 14px; padding: 5px;")
        else:
            self.mask_banner.setStyleSheet(f"background-color: transparent; color: {text_color.name()}; font-size: 14px; padding: 5px;")

        self.settings.setValue("custom_stylesheet", custom_stylesheet)
        self.settings.setValue("theme", "custom")
        self.current_theme = "custom"            

    def reset_custom_theme(self):
        confirm = QMessageBox.question(
            self,
            "Reset Custom Theme",
            "Are you sure you want to reset the custom theme to default?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if confirm == QMessageBox.StandardButton.Yes:
            self.settings.remove("custom_stylesheet")
            self.settings.setValue("theme", "dark")
            self.apply_theme("dark")
            QMessageBox.information(self, "Custom Theme Reset", "Custom theme has been reset to dark mode.")



    def open_image(self):
        default_dir = self.settings.value("working_directory", "")

        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Open Images",
            default_dir,
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.fits.gz *.fit.gz *.fz *.xisf *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )

        if not file_paths:
            return

        # Save last folder location
        self.settings.setValue("working_directory", os.path.dirname(file_paths[0]))

        slot = self.image_manager.current_slot  # Start at current slot

        for file_path in file_paths:
            try:
                image, header, bit_depth, is_mono = load_image(file_path)
                if image is None:
                    raise ValueError("Loaded image is None")

                # Find the next empty or <10x10 slot
                while slot < self.image_manager.max_slots:
                    existing_img = self.image_manager._images.get(slot)
                    if existing_img is None or existing_img.size == 0 or existing_img.shape[0] < 10 or existing_img.shape[1] < 10:
                        break
                    slot += 1

                if slot >= self.image_manager.max_slots:
                    QMessageBox.warning(self, "No Slots Available", "Ran out of image slots.")
                    break

                metadata = {
                    'file_path': file_path,
                    'original_header': header,
                    'bit_depth': bit_depth,
                    'is_mono': is_mono
                }

                self.image_manager.add_image(slot, image, metadata)

                self.update_slot_toolbar_highlight()
                print(f"Image loaded to slot {slot}: {file_path}")
                slot += 1

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to load image: {file_path}\n{e}")




    def save_image(self):
        """Save the current image to a selected path."""
        default_dir = self.settings.value("working_directory", "")
        if self.image_manager.image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                default_dir,
                "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
            )
            
            if save_file:
                self.settings.setValue("working_directory", os.path.dirname(save_file))
                try:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit', 'xisf', 'jpg', 'jpeg']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Define formats that do not require bit depth selection
                    no_bit_depth_formats = ['png', 'jpg', 'jpeg']

                    # Initialize bit_depth variable
                    bit_depth = None

                    if selected_format in no_bit_depth_formats:
                        # For PNG, JPG, JPEG, set bit depth to '8-bit' automatically
                        bit_depth = '8-bit'
                        print(f"Selected format '{selected_format}' does not require bit depth selection. Using bit depth: {bit_depth}.")
                    else:
                        # Prompt the user for bit depth selection for other formats
                        bit_depth, ok = QInputDialog.getItem(
                            self,
                            "Select Bit Depth",
                            "Choose bit depth for saving:",
                            ["32-bit floating point", "16-bit"],
                            0,
                            False
                        )
                        if not ok or not bit_depth:
                            QMessageBox.information(self, "Cancelled", "Save operation cancelled.")
                            print("Save operation cancelled by the user during bit depth selection.")
                            return

                    # Retrieve the image and metadata
                    image_data = self.image_manager.image
                    metadata = self.image_manager._metadata[self.image_manager.current_slot]
                    original_header = metadata.get('original_header', None)
                    is_mono = metadata.get('is_mono', False)

                    # Create a minimal header if the original header is missing and format is FITS
                    if original_header is None and selected_format in ['fits', 'fit']:
                        print("Creating a minimal FITS header for the data...")
                        original_header = self.create_minimal_fits_header(image_data, is_mono)

                    # Pass the image to the global save_image function
                    save_image(
                        img_array=image_data,
                        filename=save_file,
                        original_format=selected_format,
                        bit_depth=bit_depth,
                        original_header=original_header,
                        is_mono=is_mono
                    )
                    print(f"Image successfully saved to {save_file}.")

                    # Correctly access the status bar using the statusBar() method
                    self.statusBar.showMessage(f"Image saved to: {save_file}", 5000)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                    print(f"Error saving image: {e}")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded.")




    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def undo_image(self):
        if self.image_manager.can_undo():
            step = self.image_manager.undo()
            self.statusBar.showMessage(f"Undo: {step or 'Unnamed'}", 4000)
            self.update_undo_redo_action_labels()
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def redo_image(self):
        if self.image_manager.can_redo():
            step = self.image_manager.redo()
            self.statusBar.showMessage(f"Redo: {step or 'Unnamed'}", 4000)
            self.update_undo_redo_action_labels()
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")      


    def update_undo_redo_action_labels(self):
        slot = self.image_manager.current_slot

        # ---- Undo Label + Tip ----
        if self.image_manager.can_undo(slot):
            _, _, step_name = self.image_manager._undo_stacks[slot][-1]
            self.undo_action_toolbar.setText("Undo")
            self.undo_action_toolbar.setToolTip(f"Undo {step_name}")
            self.undo_action_toolbar.setStatusTip(f"Undo: {step_name}")
        else:
            self.undo_action_toolbar.setToolTip("Undo (no actions)")
            self.undo_action_toolbar.setStatusTip("Undo the last action")

        # ---- Redo Label + Tip ----
        if self.image_manager.can_redo(slot):
            _, _, step_name = self.image_manager._redo_stacks[slot][-1]
            self.redo_action_toolbar.setText("Redo")
            self.redo_action_toolbar.setToolTip(f"Redo {step_name}")
            self.redo_action_toolbar.setStatusTip(f"Redo: {step_name}")
        else:
            self.redo_action_toolbar.setToolTip("Redo (no actions)")
            self.redo_action_toolbar.setStatusTip("Redo the last undone action")




    def closeEvent(self, event):
        """Prompt the user before exiting the application."""
        reply = QMessageBox.question(
            self,
            "Exit Confirmation",
            "Are you sure you want to exit?\nDon't forget to save your work.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            event.accept()
        else:
            event.ignore()


class AboutDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("About Seti Astro Suite")
        layout = QVBoxLayout()

        # Create a QLabel with rich text (HTML) for clickable links
        about_text = (
            f"<h2>Seti Astro's Suite {VERSION}</h2>"
            "<p>Written by Franklin Marek</p>"
            "<p>Website: <a href='http://www.setiastro.com'>www.setiastro.com</a></p>"
            "<p>Donations: <a href='https://www.setiastro.com/checkout/donate?donatePageId=65ae7e7bac20370d8c04c1ab'>Click here to donate</a></p>"
        )
        label = QLabel(about_text)
        label.setTextFormat(Qt.TextFormat.RichText)
        label.setTextInteractionFlags(Qt.TextInteractionFlag.TextBrowserInteraction)
        label.setOpenExternalLinks(True)
        
        layout.addWidget(label)
        self.setLayout(layout)

class RecombineDialog(QDialog):
    def __init__(self, available_slots, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Recombine Luminance and RGB Images")
        self.selected_lum_slot = None
        self.selected_rgb_slot = None
        self.initUI(available_slots)
    
    def initUI(self, available_slots):
        layout = QVBoxLayout()
        
        # Instruction Label
        instruction_label = QLabel("Select the slots for Luminance and RGB images:")
        layout.addWidget(instruction_label)
        
        # Luminance Slot Selection
        lum_layout = QHBoxLayout()
        lum_label = QLabel("Luminance Slot:")
        self.lum_combo = QComboBox()
        self.lum_combo.addItems([f"Slot {slot}" for slot in available_slots])
        lum_layout.addWidget(lum_label)
        lum_layout.addWidget(self.lum_combo)
        layout.addLayout(lum_layout)
        
        # RGB Slot Selection
        rgb_layout = QHBoxLayout()
        rgb_label = QLabel("RGB Slot:")
        self.rgb_combo = QComboBox()
        self.rgb_combo.addItems([f"Slot {slot}" for slot in available_slots])
        rgb_layout.addWidget(rgb_label)
        rgb_layout.addWidget(self.rgb_combo)
        layout.addLayout(rgb_layout)
        
        # Buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK")
        cancel_button = QPushButton("Cancel")
        ok_button.clicked.connect(self.validate_and_accept)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(ok_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)
        
        self.setLayout(layout)
    
    def validate_and_accept(self):
        """Ensure that the selected slots are different before accepting."""
        lum_slot = self.lum_combo.currentIndex()
        rgb_slot = self.rgb_combo.currentIndex()
        
        if lum_slot == rgb_slot:
            QMessageBox.warning(
                self,
                "Invalid Selection",
                "Luminance and RGB slots must be different. Please select distinct slots."
            )
            return
        self.selected_lum_slot = lum_slot
        self.selected_rgb_slot = rgb_slot
        self.accept()
    
    def getSelections(self):
        """Return the selected luminance and RGB slot numbers."""
        return self.selected_lum_slot, self.selected_rgb_slot


class CopySlotDialog(QDialog):
    def __init__(self, parent, image_manager, mask_manager):
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Copy Slot")
        self.initUI()
    
    def initUI(self):
        layout = QVBoxLayout()
        
        # Source Type Selection
        source_type_layout = QHBoxLayout()
        source_type_label = QLabel("Source Type:")
        self.source_type_combo = QComboBox()
        self.source_type_combo.addItems(["Image", "Mask"])
        self.source_type_combo.currentTextChanged.connect(self.update_source_slots)
        source_type_layout.addWidget(source_type_label)
        source_type_layout.addWidget(self.source_type_combo)
        layout.addLayout(source_type_layout)
        
        # Source Slot Selection
        source_slot_layout = QHBoxLayout()
        source_slot_label = QLabel("Source Slot:")
        self.source_slot_combo = QComboBox()
        source_slot_layout.addWidget(source_slot_label)
        source_slot_layout.addWidget(self.source_slot_combo)
        layout.addLayout(source_slot_layout)
        
        # Target Type Selection
        target_type_layout = QHBoxLayout()
        target_type_label = QLabel("Target Type:")
        self.target_type_combo = QComboBox()
        self.target_type_combo.addItems(["Image", "Mask"])
        self.target_type_combo.currentTextChanged.connect(self.update_target_slots)
        target_type_layout.addWidget(target_type_label)
        target_type_layout.addWidget(self.target_type_combo)
        layout.addLayout(target_type_layout)
        
        # Target Slot Selection
        target_slot_layout = QHBoxLayout()
        target_slot_label = QLabel("Target Slot:")
        self.target_slot_combo = QComboBox()
        target_slot_layout.addWidget(target_slot_label)
        target_slot_layout.addWidget(self.target_slot_combo)
        layout.addLayout(target_slot_layout)
        
        # Initialize slot selections
        self.update_source_slots(self.source_type_combo.currentText())
        self.update_target_slots(self.target_type_combo.currentText())
        
        # Dialog buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)
        
        self.setLayout(layout)
    
    def update_source_slots(self, source_type):
        self.source_slot_combo.clear()
        if source_type == "Image":
            # Use parent's custom names if available; fall back to default text if not.
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif source_type == "Mask":
            # For masks, we use default text (or you could create a similar renaming mechanism)
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.source_slot_combo.addItem(text, slot_number)
    
    def update_target_slots(self, target_type):
        self.target_slot_combo.clear()
        if target_type == "Image":
            if self.parent() is not None and hasattr(self.parent(), 'slot_names'):
                available_slots = [
                    (self.parent().slot_names.get(i, f"Image Slot {i}"), i)
                    for i in range(self.image_manager.max_slots)
                ]
            else:
                available_slots = [(f"Image Slot {i}", i) for i in range(self.image_manager.max_slots)]
        elif target_type == "Mask":
            available_slots = [(f"Mask Slot {i}", i) for i in range(self.mask_manager.max_slots)]
        else:
            available_slots = []
        for text, slot_number in available_slots:
            self.target_slot_combo.addItem(text, slot_number)
    
    def get_selected_source(self):
        source_type = self.source_type_combo.currentText()
        # Retrieve the slot number from the combo box item data.
        source_slot_num = self.source_slot_combo.currentData()
        return (source_type, source_slot_num)
    
    def get_selected_target(self):
        target_type = self.target_type_combo.currentText()
        target_slot_num = self.target_slot_combo.currentData()
        return (target_type, target_slot_num)

def siril_style_autostretch(image, sigma=3.0):
    """
    Perform a 'Siril-style histogram stretch' using MAD for robust contrast enhancement.
    
    Parameters:
        image (np.ndarray): Input image, assumed to be normalized to [0, 1] range.
        sigma (float): How many MADs to stretch from the median.
    
    Returns:
        np.ndarray: Stretched image in [0, 1] range.
    """
    def stretch_channel(channel):
        median = np.median(channel)
        mad = np.median(np.abs(channel - median))
        min_val = np.min(channel)
        max_val = np.max(channel)

        # Convert MAD to an equivalent of std (optional, keep raw MAD if preferred)
        mad_std_equiv = mad * 1.4826

        black_point = max(min_val, median - sigma * mad_std_equiv)
        white_point = min(max_val, median + sigma * mad_std_equiv)

        if white_point - black_point <= 1e-6:
            return np.zeros_like(channel)  # Avoid divide-by-zero

        stretched = (channel - black_point) / (white_point - black_point)
        return np.clip(stretched, 0, 1)

    if image.ndim == 2:
        return stretch_channel(image)
    elif image.ndim == 3 and image.shape[2] == 3:
        return np.stack([stretch_channel(image[..., c]) for c in range(3)], axis=-1)
    else:
        raise ValueError("Unsupported image format for histogram stretch.")

HANDLE_SIZE = 80

class ResizableRotatableRectItem(QGraphicsRectItem):
    """
    A rectangle item with 4 corner handles for resizing and
    alt+drag to rotate.
    """
    def __init__(self, rect: QRectF, parent=None):
        super().__init__(rect, parent)
        # ── make the rectangle’s pen cosmetic ────────────────────
        pen = QPen(Qt.GlobalColor.green, 2)   # 2px wide
        pen.setCosmetic(True)                # stays 2px no matter the zoom
        self.setPen(pen)
        self._fixed_aspect_ratio = None 

        # no fill
        self.setBrush(QBrush(Qt.BrushStyle.NoBrush))        
        self.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges
        )
        self.setAcceptHoverEvents(True)
        self._handles = {}
        self._active_handle = None
        self._rotating = False
        self._rotation_start = 0.0
        self._pivot_scene = QPointF()
        self._initHandles()
        # only set origin _once_ here
        self.setTransformOriginPoint(self.rect().center())

    
    def setFixedAspectRatio(self, ratio: Optional[float]):
        """Lock resize to this width/height ratio, or None to free‐hand."""
        self._fixed_aspect_ratio = ratio

    def _initHandles(self):
        pen = QPen(Qt.GlobalColor.green,2)
        pen.setCosmetic(True)  # Make pen size independent of zoom level
        brush = QBrush(Qt.GlobalColor.white)
        for pos in ("tl","tr","br","bl"):
            h = QGraphicsEllipseItem(0,0, HANDLE_SIZE, HANDLE_SIZE, self)
            h.setPen(pen)
            h.setBrush(brush)
            h.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIsMovable, False)
            self._handles[pos] = h
        self._updateHandlePositions()

    def _updateHandlePositions(self):
        r = self.rect()
        s = HANDLE_SIZE
        corners = {
            "tl": QPointF(r.left()-s/2,  r.top()-s/2),
            "tr": QPointF(r.right()-s/2, r.top()-s/2),
            "br": QPointF(r.right()-s/2, r.bottom()-s/2),
            "bl": QPointF(r.left()-s/2,  r.bottom()-s/2),
        }
        for pos, item in self._handles.items():
            item.setPos(corners[pos])

        # reset the transform‐origin to the box’s true center
        scene_ctr = self.mapToScene(self.boundingRect().center())


    def hoverMoveEvent(self, ev):
        for pos, h in self._handles.items():
            if h.contains(h.mapFromScene(ev.scenePos())):
                self._setCursorForHandle(pos)
                return
        self.setCursor(Qt.CursorShape.SizeAllCursor)
        super().hoverMoveEvent(ev)

    def mousePressEvent(self, ev):
        if ev.modifiers() == Qt.KeyboardModifier.ShiftModifier:
            # start rotating
            self._rotating = True
            # store where we began, in degrees
            pivot = self.mapToScene(self.rect().center())
            self._pivot_scene = pivot
            v0 = ev.scenePos() - pivot
            self._angle_ref = math.degrees(math.atan2(v0.y(), v0.x()))
            # and the item’s starting rotation
            self._rotation_start = self.rotation()
            ev.accept()
            return

        # check for handle‐resize
        for pos, h in self._handles.items():
            if h.contains(h.mapFromScene(ev.scenePos())):
                self._active_handle = pos
                ev.accept()
                return

        # fallback to move
        super().mousePressEvent(ev)

    def mouseMoveEvent(self, ev):
        if self._rotating:
            # compute new absolute angle
            v_new = ev.scenePos() - self._pivot_scene
            a_new = math.degrees(math.atan2(v_new.y(), v_new.x()))
            delta = a_new - self._angle_ref
            # apply full delta from the very start
            self.setRotation(self._rotation_start + delta)
            ev.accept()
            return

        if self._active_handle:
            self._resizeViaHandle(ev.scenePos())
            ev.accept()
            return

        super().mouseMoveEvent(ev)


    def mouseReleaseEvent(self, ev):
        # 1) finish rotating or resizing
        if self._rotating:
            self._rotating = False
            ev.accept()
        elif self._active_handle:
            self._active_handle = None
            ev.accept()
        else:
            super().mouseReleaseEvent(ev)

        # 2) now gather everything you want to debug
        rect         = self.rect()
        pos          = self.pos()
        angle        = self.rotation()
        pivot_scene  = self.mapToScene(rect.center())
        corners_local  = [
            rect.topLeft(), rect.topRight(),
            rect.bottomRight(), rect.bottomLeft()
        ]
        corners_scene = [self.mapToScene(c) for c in corners_local]

        # 3) print it
        print("🔶 [DEBUG CropRect]")
        print(f"    rect (local): {rect}")
        print(f"    pos (item):   {pos}")
        print(f"    rotation °:   {angle:.2f}")
        print(f"    pivot (scene): ({pivot_scene.x():.1f}, {pivot_scene.y():.1f})")
        for i, pt in enumerate(corners_scene, 1):
            print(f"    corner {i} (scene): ({pt.x():.1f}, {pt.y():.1f})")
        print("🔶 [END DEBUG]\n")

    def itemChange(self, change, value):
        """
        Qt calls this whenever position, rotation, scale, etc. change.
        We use it to update our handle‐positions so they follow both moves and rotations.
        """
        if change in (
            QGraphicsItem.GraphicsItemChange.ItemPositionHasChanged,
            QGraphicsItem.GraphicsItemChange.ItemRotationHasChanged
        ):
            self._updateHandlePositions()
        return super().itemChange(change, value)

    def _refreshPivot(self):
        scene_ctr = self.mapToScene(self.boundingRect().center())
        self.setTransformOriginPoint(self.mapFromScene(scene_ctr))

    def _resizeViaHandle(self, scene_pt: QPointF):
        r = self.rect()
        p = self.mapFromScene(scene_pt)
        # adjust rect based on which handle
        if self._active_handle == "tl":
            r.setTopLeft(p)
        elif self._active_handle == "tr":
            r.setTopRight(p)
        elif self._active_handle == "br":
            r.setBottomRight(p)
        elif self._active_handle == "bl":
            r.setBottomLeft(p)

        # enforce aspect if locked
        if self._fixed_aspect_ratio:
            w = r.width()
            h_target = w / self._fixed_aspect_ratio
            # decide whether top or bottom moved
            if self._active_handle in ("tl", "tr"):
                r.setTop(r.bottom() - h_target)
            else:
                r.setBottom(r.top() + h_target)

        r = r.normalized()
        self.setRect(r)
        self._updateHandlePositions()

    def _setCursorForHandle(self, handle_name):
        cursors = {
            "tl": Qt.CursorShape.SizeFDiagCursor,
            "br": Qt.CursorShape.SizeFDiagCursor,
            "tr": Qt.CursorShape.SizeBDiagCursor,
            "bl": Qt.CursorShape.SizeBDiagCursor,
        }
        self.setCursor(cursors.get(handle_name, Qt.CursorShape.ArrowCursor))

class CropTool(QDialog):
    """A cropping tool with a resizable, rotatable rectangle."""
    crop_applied = pyqtSignal(object)
    # before: previous_crop_rect = None
    previous_crop_rect = (None, 0.0, QPointF(0, 0))

    def __init__(self, image_manager, image_data, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Crop Tool")
        self.setGeometry(100,100,800,600)
        self.image_manager = image_manager
        self.original_image_data = image_data.copy()
        self.image_data = image_data
        self.scene = QGraphicsScene(self)
        self.view  = QGraphicsView(self.scene)
        self._rect_item = None
        self.selection_rect_item = None
        self.drawing = False
        self.origin = QPointF()
        instr = QLabel(
            "• Click-and-drag to draw crop rectangle\n"
            "• Drag any corner handle to resize\n"
            "• Shift + drag a corner handle to rotate"
        )
        layout = QVBoxLayout(self)

        instr.setAlignment(Qt.AlignmentFlag.AlignCenter)
        instr.setStyleSheet("font-style: italic; color: gray;")
        layout.addWidget(instr)

        ratio_layout = QHBoxLayout()
        ratio_layout.addStretch(1) 
        ratio_layout.addWidget(QLabel("Aspect Ratio:"))
        self.aspect_combo = QComboBox()
        self.aspect_combo.addItems([
            "Free",
            "Original",
            "1:1",
            "16:9",
            "9:16",
            "4:3",
        ])
        ratio_layout.addWidget(self.aspect_combo)
        ratio_layout.addStretch(1)  # push combo to the left
        layout.addLayout(ratio_layout)

        # remember original image AR
        h, w = self.original_image_data.shape[:2]
        self._orig_ar = w / h

        # connect
        self.aspect_combo.currentTextChanged.connect(self._onAspectRatioChanged)

        # install filter after view is created:
        self.view.viewport().installEventFilter(self)
        # Layout & buttons

        layout.addWidget(self.view)

        btns = [
            ("Toggle Autostretch", self.toggle_autostretch),
            ("Load Previous Crop", self.load_previous_crop),
            ("Apply Crop",         self.apply_crop),
            ("Batch Crop All Slots", self.batch_crop_all_slots),
        ]
        for txt, slot in btns:
            b = QPushButton(txt);  b.clicked.connect(slot)
            layout.addWidget(b)

        self.setLayout(layout)
        self._loadImage()
        self.view.viewport().installEventFilter(self)

    def _onAspectRatioChanged(self, text: str):
        # figure out numeric ratio (or None for free‑hand)
        if text == "Free":
            ar = None
        elif text == "Original":
            ar = self._orig_ar
        else:
            a, b = map(float, text.split(":"))
            ar = a / b

        # lock future drags to this aspect
        if self._rect_item:
            self._rect_item.setFixedAspectRatio(ar)

            # if we have a live rect and a ratio, immediately reshape it
            if ar is not None:
                from PyQt6.QtCore import QRectF

                # grab the old rectangle (in item‑local coords)
                old = self._rect_item.rect()
                w   = old.width()
                h   = w / ar

                # center it around the old center
                cx, cy = old.center().x(), old.center().y()
                new_rect = QRectF(cx - w/2, cy - h/2, w, h)

                # apply it
                self._rect_item.setRect(new_rect)

                # reset the transform‑origin to the new center
                self._rect_item.setTransformOriginPoint(new_rect.center())

                # and move the handles
                self._rect_item._updateHandlePositions()

    def _loadImage(self):
        """Load the current image into the scene and remember the pixmap item."""
        img = self.image_data
        if img.ndim == 3 and img.shape[2] == 1:
            img = img.squeeze(2)
        if img.ndim == 3:
            h, w, _ = img.shape
            q = QImage((img * 255).astype(np.uint8).tobytes(), w, h, 3 * w,
                       QImage.Format.Format_RGB888)
        else:
            h, w = img.shape
            q = QImage((img * 255).astype(np.uint8).tobytes(), w, h, w,
                       QImage.Format.Format_Grayscale8)

        pix = QPixmap.fromImage(q)
        self.scene.clear()
        pix_item = QGraphicsPixmapItem(pix)
        pix_item.setZValue(-1)             # so rectangle stays on top
        self.scene.addItem(pix_item)
        self._pixmap_item = pix_item       # 🌟 remember for coordinate mapping
        self.view.fitInView(self.scene.itemsBoundingRect(),
                            Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, ev):
        super().resizeEvent(ev)
        if self.scene.items():
            self.view.fitInView(self.scene.itemsBoundingRect(), Qt.AspectRatioMode.KeepAspectRatio)

    def eventFilter(self, source, ev):
        if source is self.view.viewport():
            if ev.type() in (
                QEvent.Type.MouseButtonPress,
                QEvent.Type.MouseMove,
                QEvent.Type.MouseButtonRelease
            ):
                scene_pt = self.view.mapToScene(ev.pos())

            # 1) drawing first rectangle
            if self._rect_item is None:
                # start drawing
                if ev.type() == QEvent.Type.MouseButtonPress and ev.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin  = scene_pt
                    return True

                # live update
                if ev.type() == QEvent.Type.MouseMove and getattr(self, "drawing", False):
                    # compute raw rect
                    r = QRectF(self.origin, scene_pt).normalized()

                    # enforce drop‑down ratio
                    txt = self.aspect_combo.currentText()
                    if txt != "Free":
                        if txt == "Original":
                            ar = self._orig_ar
                        else:
                            a, b = map(float, txt.split(":"))
                            ar = a / b
                        w = r.width()
                        h_target = w / ar
                        if scene_pt.y() < self.origin.y():
                            r.setTop(r.bottom() - h_target)
                        else:
                            r.setBottom(r.top() + h_target)
                        r = r.normalized()

                    # redraw dashed rect
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                    pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.DashLine)
                    pen.setCosmetic(True)
                    self.selection_rect_item = self.scene.addRect(r, pen)
                    return True

                # finalize on mouse up
                if ev.type() == QEvent.Type.MouseButtonRelease \
                   and ev.button() == Qt.MouseButton.LeftButton \
                   and getattr(self, "drawing", False):

                    self.drawing = False
                    final_r = QRectF(self.origin, scene_pt).normalized()

                    # enforce ratio one more time
                    txt = self.aspect_combo.currentText()
                    if txt != "Free":
                        if txt == "Original":
                            ar = self._orig_ar
                        else:
                            a, b = map(float, txt.split(":"))
                            ar = a / b
                        w = final_r.width()
                        h_target = w / ar
                        if scene_pt.y() < self.origin.y():
                            final_r.setTop(final_r.bottom() - h_target)
                        else:
                            final_r.setBottom(final_r.top() + h_target)
                        final_r = final_r.normalized()

                    # remove the live dashed rect
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)

                    # create the true, rotatable item
                    self._rect_item = ResizableRotatableRectItem(final_r)
                    # lock its aspect
                    self._rect_item.setFixedAspectRatio(
                        None if txt=="Free"
                        else (self._orig_ar if txt=="Original" else (a/b))
                    )

                    # save & add
                    pos   = self._rect_item.pos()
                    angle = self._rect_item.rotation()
                    CropTool.previous_crop_rect = (final_r, angle, pos)
                    self.scene.addItem(self._rect_item)
                    return True

            # 2) once we have a rect, let its own handlers take over
            return False

        return super().eventFilter(source, ev)



    def _getCurrentRect(self):
        """Return QRectF in image‐pixel coords (ignoring rotation)."""
        if not self._rect_item:
            return None
        r = self._rect_item.rect()
        # Use itemsBoundingRect() to cover the entire pixmap
        sb = self.scene.itemsBoundingRect()
        if sb.isEmpty():
            return None
        scale_x = self.original_image_data.shape[1] / sb.width()
        scale_y = self.original_image_data.shape[0] / sb.height()
        return QRectF(
            r.left()   * scale_x,
            r.top()    * scale_y,
            r.width()  * scale_x,
            r.height() * scale_y
        )


    def toggle_autostretch(self):
        stretched = siril_style_autostretch(self.original_image_data, sigma=3.0)
        if stretched is None:
            return
        # grab and clear
        saved = self._getCurrentRect()
        self.image_data = stretched
        self._loadImage()
        if saved and not saved.isNull():
            # restore size/angle/position triple
            rect, old_angle, old_pos = CropTool.previous_crop_rect
            self._rect_item = ResizableRotatableRectItem(rect)
            self._rect_item.setPos(old_pos)
            self._rect_item.setRotation(old_angle)
            self._rect_item.setTransformOriginPoint(rect.center())
            self.scene.addItem(self._rect_item)

    def load_previous_crop(self):
        rect, angle, pos = CropTool.previous_crop_rect
        if rect is None:
            QMessageBox.information(self, "No Previous", "No previous crop stored.")
            return

        # remove old
        if self._rect_item:
            self.scene.removeItem(self._rect_item)

        # create, then re‐position & rotate
        self._rect_item = ResizableRotatableRectItem(rect)
        self._rect_item.setPos(pos)
        self._rect_item.setRotation(angle)
        self._rect_item.setTransformOriginPoint(rect.center())
        self.scene.addItem(self._rect_item)

    def apply_crop(self):
        if not self._rect_item:
            QMessageBox.warning(self, "No Selection", "Draw (and finalize) a crop first.")
            return

        # 1) Gather your four corners in SCENE coords
        rect_local   = self._rect_item.rect()
        corners_local = [
            rect_local.topLeft(), rect_local.topRight(),
            rect_local.bottomRight(), rect_local.bottomLeft()
        ]
        corners_scene = [self._rect_item.mapToScene(pt) for pt in corners_local]

        # 2) Map those into **image** pixel coords
        pm  = self._pixmap_item.pixmap()
        pm_w, pm_h    = pm.width(), pm.height()
        h_img, w_img  = self.original_image_data.shape[:2]
        sx, sy        = w_img/pm_w, h_img/pm_h

        src_pts = np.array([
            [p.x()*sx, p.y()*sy] for p in corners_scene
        ], dtype=np.float32)  # shape (4,2)

        # 3) Compute target rectangle size (edge lengths)
        width  = np.linalg.norm(src_pts[1] - src_pts[0])
        height = np.linalg.norm(src_pts[3] - src_pts[0])

        # 4) Build your destination points for a perfect upright rect
        dst_pts = np.array([
            [0,      0],
            [width,  0],
            [width,  height],
            [0,      height]
        ], dtype=np.float32)

        # 5) Compute perspective transform & warp
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)
        cropped = cv2.warpPerspective(
            self.original_image_data,
            M,
            (int(np.round(width)), int(np.round(height))),
            flags=cv2.INTER_LINEAR
        )

        # 6) Emit result & close
        self.crop_applied.emit(cropped)
        self.accept()


    def batch_crop_all_slots(self):
        """
        Apply the same rotated & moved crop to all images in image_manager,
        using a perspective warp so the crop is exact.
        """
        # 1) Make sure we have a selection
        if not self._rect_item:
            QMessageBox.warning(self, "No Selection", "Draw & finalize a crop first.")
            return

        # 2) Get the four corners of the rect in SCENE coords
        rect_local    = self._rect_item.rect()
        local_corners = [
            rect_local.topLeft(), rect_local.topRight(),
            rect_local.bottomRight(), rect_local.bottomLeft()
        ]
        scene_corners = [self._rect_item.mapToScene(pt) for pt in local_corners]

        # 3) Map scene → image‐pixel coords
        pm      = self._pixmap_item.pixmap()
        pm_w, pm_h = pm.width(), pm.height()
        h_img, w_img = self.original_image_data.shape[:2]
        sx, sy = w_img/pm_w, h_img/pm_h

        src_pts = np.array([
            [pt.x()*sx, pt.y()*sy] for pt in scene_corners
        ], dtype=np.float32)  # shape (4,2)

        # 4) Compute the width/height of the target rectangle
        width  = np.linalg.norm(src_pts[1] - src_pts[0])
        height = np.linalg.norm(src_pts[3] - src_pts[0])
        w_out, h_out = int(round(width)), int(round(height))

        # 5) Build destination corners (axis-aligned)
        dst_pts = np.array([
            [0,      0],
            [w_out,  0],
            [w_out,  h_out],
            [0,      h_out]
        ], dtype=np.float32)

        # 6) Compute one perspective transform
        M = cv2.getPerspectiveTransform(src_pts, dst_pts)

        # 7) Gather occupied slots
        occupied = [s for s,im in self.image_manager._images.items() if im is not None]
        if not occupied:
            QMessageBox.information(self, "No Images", "There are no images to crop.")
            return

        # 8) Confirm
        reply = QMessageBox.question(
            self, "Confirm Batch Crop",
            f"Apply this rotated crop to all {len(occupied)} images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if reply != QMessageBox.StandardButton.Yes:
            return

        # 9) Warp & crop each slot
        for slot in occupied:
            img = self.image_manager._images[slot]
            # apply the same warp
            cropped = cv2.warpPerspective(
                img, M, (w_out, h_out),
                flags=cv2.INTER_LINEAR,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=0
            )

            # push undo / clear redo
            self.image_manager._undo_stacks[slot].append(
                (img.copy(), self.image_manager._metadata[slot].copy())
            )
            self.image_manager._redo_stacks[slot].clear()

            # store & emit
            self.image_manager._images[slot] = cropped
            self.image_manager.image_changed.emit(
                slot, cropped, self.image_manager._metadata[slot]
            )

        QMessageBox.information(
            self, "Batch Crop Completed",
            f"Successfully cropped {len(occupied)} images."
        )
        self.accept()


class SlotNameProxy(MutableMapping):
    """
    A dict‐like view on ImageManager.slot_name metadata.
    Reads come from get_slot_name(), writes go through rename_slot().
    """
    def __init__(self, manager):
        self.manager = manager

    def __getitem__(self, key):
        # returns the display name for slot `key`
        return self.manager.get_slot_name(key)

    def __setitem__(self, key, value):
        # ask the ImageManager to rename it
        self.manager.rename_slot(key, value)

    def __delitem__(self, key):
        raise NotImplementedError("Cannot delete slot names")

    def __iter__(self):
        return iter(range(self.manager.max_slots))

    def __len__(self):
        return self.manager.max_slots

class ImageManager(QObject):
    """
    Manages multiple image slots with associated metadata and supports undo/redo operations for each slot.
    Emits a signal whenever an image or its metadata changes.
    """
    
    # Signal emitted when an image or its metadata changes.
    # Parameters:
    # - slot (int): The slot number.
    # - image (np.ndarray): The new image data.
    # - metadata (dict): Associated metadata for the image.
    image_changed = pyqtSignal(int, np.ndarray, dict)
    current_slot_changed = pyqtSignal(int)    
    # Keys we always carry forward unless caller explicitly supplies a non-empty replacement
    PRESERVE_META_KEYS = ("file_path", "FILE", "path", "fits_header", "header")


    def __init__(self, max_slots=5, parent=None):
        """
        Initializes the ImageManager with a specified number of slots.
        
        :param max_slots: Maximum number of image slots to manage.
        """
        super().__init__()
        self.parent = parent
        self.max_slots = max_slots
        self._images = {i: None for i in range(max_slots)}
        self._metadata = {i: {} for i in range(max_slots)}
        self._undo_stacks = {i: [] for i in range(max_slots)}
        self._redo_stacks = {i: [] for i in range(max_slots)}
        self.current_slot = 0  # Default to the first slot
        self.active_previews = {}  # Track active preview windows by slot
        self.mask_manager = MaskManager(max_slots)  # Add a MaskManager

    def _looks_like_path(self, v: object) -> bool:
        if not isinstance(v, str):
            return False
        # treat as path if it has a separator or a known extension
        ext_ok = v.lower().endswith((".fits", ".fit", ".fts", ".fz", ".fits.fz"))
        return (os.path.sep in v) or ext_ok

    def _attach_step_name(self, merged_meta: Dict, step_name: Optional[str]) -> Dict:
        if step_name is not None and str(step_name).strip():
            merged_meta["step_name"] = step_name.strip()
        return merged_meta

    def _merge_metadata(self, base: Optional[Dict], updates: Optional[Dict]) -> Dict:
        out = (base or {}).copy()
        if not updates:
            return out
        for k, v in updates.items():
            if k in ("file_path", "FILE", "path"):
                # Only accept if it looks like a real path; ignore labels like "Cropped Image"
                if not self._looks_like_path(v):
                    continue
            if k in ("fits_header", "header"):
                # Don’t replace with None/blank
                if v is None or (isinstance(v, str) and not v.strip()):
                    continue
            out[k] = v
        return out

    def _emit_change(self, slot: int):
        """Centralized emitter to avoid passing None metadata to listeners."""
        img = self._images[slot]
        meta = self._metadata[slot]
        self.image_changed.emit(slot, img, meta)
        if self.parent and hasattr(self.parent, "update_undo_redo_action_labels"):
            self.parent.update_undo_redo_action_labels()

    def get_current_image_and_metadata(self):
        slot = self.current_slot
        return self._images[slot], self._metadata[slot]

    def rename_slot(self, slot: int, new_name: str):
        """Store a custom slot_name in metadata and emit an update."""
        if 0 <= slot < self.max_slots:
            self._metadata[slot]['slot_name'] = new_name

            # explicitly check for None, avoid ambiguous truth-check on ndarray
            existing = self._images[slot]
            if existing is None:
                img = np.zeros((1,1), dtype=np.uint8)
            else:
                img = existing

            # re-emit image_changed so UI labels (menus/toolbars) can refresh
            self.image_changed.emit(slot, img, self._metadata[slot])
        else:
            print(f"ImageManager: cannot rename slot {slot}, out of range")

    def get_mask(self, slot=None):
        """
        Retrieves the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        :return: Mask as numpy array or None.
        """
        if slot is None:
            slot = self.current_slot
        return self.mask_manager.get_mask(slot)

    def set_mask(self, mask, slot=None):
        """
        Sets a mask for the current or specified slot.
        :param mask: Numpy array representing the mask.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.set_mask(slot, mask)

    def clear_mask(self, slot=None):
        """
        Clears the mask for the current or specified slot.
        :param slot: Slot number. If None, uses current slot.
        """
        if slot is None:
            slot = self.current_slot
        self.mask_manager.clear_mask(slot)        

    def set_current_slot(self, slot):
        if 0 <= slot < self.max_slots:
            self.current_slot = slot
            self.current_slot_changed.emit(slot)
            # Use a non-empty placeholder if the slot is empty
            image_to_emit = self._images[slot] if self._images[slot] is not None and self._images[slot].size > 0 else np.zeros((1, 1), dtype=np.uint8)
            self.image_changed.emit(slot, image_to_emit, self._metadata[slot])
            print(f"ImageManager: Current slot set to {slot}.")
        else:
            print(f"ImageManager: Slot {slot} is out of range.")


    def add_image(self, slot, image, metadata):
        """
        Adds an image and its metadata to a specified slot.
        
        :param slot: The slot number where the image will be added.
        :param image: The image data (numpy array).
        :param metadata: A dictionary containing metadata for the image.
        """
        if 0 <= slot < self.max_slots:
            self._images[slot] = image
            self._metadata[slot] = metadata
            # Clear undo/redo stacks when a new image is added
            self._undo_stacks[slot].clear()
            self._redo_stacks[slot].clear()
            self.current_slot = slot
            self.image_changed.emit(slot, image, metadata)
            print(f"ImageManager: Image added to slot {slot} with metadata.")
        else:
            print(f"ImageManager: Slot {slot} is out of range. Max slots: {self.max_slots}")
        if metadata is None:
            metadata = {}
        metadata.setdefault("step_name", "Loaded")


    def set_image(self, new_image, metadata, step_name=None):
        slot = self.current_slot
        if self._images[slot] is not None:
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), step_name or "Unnamed Step")
            )
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")

        merged = self._merge_metadata(self._metadata[slot], metadata)
        merged = self._attach_step_name(merged, step_name)  # <-- add this
        self._images[slot] = new_image
        self._metadata[slot] = merged
        self._emit_change(slot)
        print(f"ImageManager: Image set for slot {slot} with merged metadata.")


    def set_image_for_slot(self, slot, new_image, metadata, step_name=None):
        if slot < 0 or slot >= self.max_slots:
            print(f"ImageManager: Slot {slot} is out of range. Max slots={self.max_slots}")
            return

        if self._images[slot] is not None:
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), step_name or "Unnamed Step")
            )
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")

        merged = self._merge_metadata(self._metadata[slot], metadata)
        merged = self._attach_step_name(merged, step_name)
        self._images[slot] = new_image
        self._metadata[slot] = merged
        self.current_slot = slot
        self._emit_change(slot)
        print(f"ImageManager: Image set for slot {slot} with merged metadata.")


    @property
    def image(self):
        return self._images[self.current_slot]

    @image.setter
    def image(self, new_image):
        """
        Default image setter that stores undo as an unnamed step.
        """
        self.set_image_with_step_name(new_image, self._metadata[self.current_slot], step_name="Unnamed Step")

    def set_image_with_step_name(self, new_image, metadata, step_name="Unnamed Step"):
        slot = self.current_slot
        if self._images[slot] is not None:
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), step_name)
            )
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous image in slot {slot} pushed to undo stack (step: {step_name})")
        else:
            print(f"ImageManager: No existing image in slot {slot} to push to undo stack.")

        merged = self._merge_metadata(self._metadata[slot], metadata)
        merged = self._attach_step_name(merged, step_name)
        self._images[slot] = new_image
        self._metadata[slot] = merged
        self._emit_change(slot)
        print(f"ImageManager: Image set for slot {slot} via set_image_with_step_name (merged).")


    def get_slot_name(self, slot):
        """
        Returns the display name for a given slot.
        If a slot has been renamed (stored under "slot_name" in metadata), that name is returned.
        Otherwise, it returns "Slot X" (using 1-indexed numbering for display).
        """
        metadata = self._metadata.get(slot, {})
        if 'slot_name' in metadata:
            return metadata['slot_name']
        else:
            return f"Slot {slot}"


    def set_metadata(self, metadata):
        slot = self.current_slot
        if self._images[slot] is not None:
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy())
            )
            self._redo_stacks[slot].clear()
            print(f"ImageManager: Previous metadata in slot {slot} pushed to undo stack.")
        else:
            print(f"ImageManager: No existing image in slot {slot} to set metadata.")

        merged = self._merge_metadata(self._metadata[slot], metadata)
        self._metadata[slot] = merged
        self._emit_change(slot)
        print(f"ImageManager: Metadata set for slot {slot} (merged).")

    def update_image(self, updated_image, metadata=None, slot=None):
        if slot is None:
            slot = self.current_slot

        self._images[slot] = updated_image
        if metadata is not None:
            merged = self._merge_metadata(self._metadata[slot], metadata)
            self._metadata[slot] = merged

        self._emit_change(slot)

    def can_undo(self, slot=None):
        """
        Determines if there are actions available to undo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if undo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._undo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_undo.")
            return False

    def can_redo(self, slot=None):
        """
        Determines if there are actions available to redo for the specified slot.
        
        :param slot: (Optional) The slot number to check. If None, uses current_slot.
        :return: True if redo is possible, False otherwise.
        """
        if slot is None:
            slot = self.current_slot
        if 0 <= slot < self.max_slots:
            return len(self._redo_stacks[slot]) > 0
        else:
            print(f"ImageManager: Slot {slot} is out of range. Cannot check can_redo.")
            return False

    def undo(self, slot=None):
        if slot is None:
            slot = self.current_slot

        if 0 <= slot < self.max_slots and self.can_undo(slot):
            self._redo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), "Redo of Previous Step")
            )

            popped = self._undo_stacks[slot].pop()
            if len(popped) == 3:
                prev_img, prev_meta, step_name = popped
            else:
                prev_img, prev_meta = popped
                step_name = "Unnamed Undo Step"

            self._images[slot] = prev_img
            self._metadata[slot] = prev_meta
            self.image_changed.emit(slot, prev_img, prev_meta)

            print(f"ImageManager: Undo performed on slot {slot}: {step_name}")
            return step_name
        else:
            print(f"ImageManager: Cannot perform undo on slot {slot}.")
            return None



    def redo(self, slot=None):
        if slot is None:
            slot = self.current_slot

        if 0 <= slot < self.max_slots and self.can_redo(slot):
            self._undo_stacks[slot].append(
                (self._images[slot].copy(), self._metadata[slot].copy(), "Undo of Redone Step")
            )

            popped = self._redo_stacks[slot].pop()
            if len(popped) == 3:
                redo_img, redo_meta, step_name = popped
            else:
                redo_img, redo_meta = popped
                step_name = "Unnamed Redo Step"

            self._images[slot] = redo_img
            self._metadata[slot] = redo_meta
            self.image_changed.emit(slot, redo_img, redo_meta)

            print(f"ImageManager: Redo performed on slot {slot}: {step_name}")
            return step_name
        else:
            print(f"ImageManager: Cannot perform redo on slot {slot}.")
            return None

    def get_history_image(self, slot: int, index: int):
        """
        Get a specific image from the undo stack (not applied, just for preview).
        :param slot: Slot number.
        :param index: Index from the bottom (0 = oldest).
        """
        if 0 <= slot < self.max_slots:
            stack = self._undo_stacks[slot]
            if 0 <= index < len(stack):
                img, meta, _ = stack[index] if len(stack[index]) == 3 else (*stack[index], "Unnamed")
                return img.copy(), meta.copy()
        return None, None

    def get_image_for_slot(self, slot: int) -> Optional[np.ndarray]:
        """Return the image stored in slot, or None if empty."""
        return self._images.get(slot)

class FITSModifier(QDialog):
    """
    Non-modal editor that shows a FITS header in a tree and lets the user edit/save.
    If both file_path and header are provided, file takes precedence for I/O;
    edits can also be pushed back into ImageManager metadata for the active slot.
    """
    def __init__(self, file_path: Optional[str], header, image_manager=None, parent=None):

        super().__init__(parent)
        self.setWindowTitle("FITS Header Editor")
        self.resize(800, 600)

        self.image_manager = image_manager
        self.file_path = file_path if (file_path and os.path.isfile(file_path)) else None
        self.hdul = None
        self.current_hdu_index = 0
        self._fallback_header = header

        self._populating = False
        self._dirty = False
              

        # UI
        top = QHBoxLayout()
        self.path_label = QLabel(self.file_path or "(no file)")
        self.open_btn = QPushButton("Open FITS…")
        self.reload_btn = QPushButton("Reload")
        self.hdu_combo = QComboBox()
        self.save_btn = QPushButton("Save")
        self.saveas_btn = QPushButton("Save As…")
        #self.apply_to_slot_btn = QPushButton("Apply to Slot Metadata")

        top.addWidget(QLabel("File:"))
        top.addWidget(self.path_label, 1)
        top.addWidget(QLabel("HDU:"))
        top.addWidget(self.hdu_combo)
        top.addWidget(self.open_btn)
        top.addWidget(self.reload_btn)
        top.addWidget(self.save_btn)
        top.addWidget(self.saveas_btn)
        #top.addWidget(self.apply_to_slot_btn)

        batch = QHBoxLayout()
        self.batch_btn = QPushButton("Batch Modify...")
        batch.addStretch()
        batch.addWidget(self.batch_btn)
        batch.addStretch()

        self.tree = QTreeWidget()
        self.tree.setColumnCount(3)
        self.tree.setHeaderLabels(["Keyword", "Value", "Comment"])
        self.tree.setAlternatingRowColors(True)
        self.tree.setRootIsDecorated(False)
        self.tree.setEditTriggers(QTreeWidget.EditTrigger.DoubleClicked | QTreeWidget.EditTrigger.SelectedClicked)
        self.tree.setUniformRowHeights(True)  # perf + consistent row paint
        self.tree.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.tree.setSelectionMode(QAbstractItemView.SelectionMode.SingleSelection)

        # Strong selection + hover contrast (handles active/inactive window states)
        self.tree.setStyleSheet("""
        QTreeWidget::item:selected:active {
            background-color: #1E90FF;   /* DodgerBlue */
            color: white;
        }
        QTreeWidget::item:selected:!active {
            background-color: #5AA7FF;   /* lighter when window inactive */
            color: white;
        }
        QTreeWidget::item:hover {
            background-color: rgba(30,144,255,0.18);
        }
        QTreeWidget::item {
            padding: 2px 6px;            /* gives the selection a little breathing room */
        }
        """)


        bottom = QHBoxLayout()
        self.add_key_edit = QLineEdit(); self.add_key_edit.setPlaceholderText("KEYWORD")
        self.add_val_edit = QLineEdit(); self.add_val_edit.setPlaceholderText("Value")
        self.add_com_edit = QLineEdit(); self.add_com_edit.setPlaceholderText("Comment (optional)")
        self.add_btn = QPushButton("Add/Update")
        self.del_btn = QPushButton("Delete Selected")
        self.all_hdus_chk = QCheckBox("Apply add/update/delete to all HDUs")
        bottom.addWidget(self.add_key_edit)
        bottom.addWidget(self.add_val_edit)
        bottom.addWidget(self.add_com_edit)
        bottom.addWidget(self.all_hdus_chk)
        bottom.addWidget(self.add_btn)
        bottom.addWidget(self.del_btn)

        layout = QVBoxLayout(self)
        layout.addLayout(top)
        layout.addLayout(batch)
        layout.addWidget(self.tree, 1)
        layout.addLayout(bottom)

        # Signals
        self.open_btn.clicked.connect(self._choose_file)
        self.reload_btn.clicked.connect(self._reload)
        self.hdu_combo.currentIndexChanged.connect(self._on_hdu_changed)
        self.save_btn.clicked.connect(self._save_in_place)
        self.saveas_btn.clicked.connect(self._save_as_copy)
        #self.apply_to_slot_btn.clicked.connect(self._apply_to_slot_metadata)
        self.add_btn.clicked.connect(self._add_or_update_keyword)
        self.del_btn.clicked.connect(self._delete_selected)

        # Initial content
        if self.file_path:
            ok = self._load_file(self.file_path)
            if not ok and header is not None:
                self._init_from_header(header)
        elif header is not None:
            self._init_from_header(header)
        else:
            # No FITS on disk and no header provided: start empty
            self._init_from_header(fits.Header())

        self.tree.itemChanged.connect(self._on_item_changed)  
        self.tree.currentItemChanged.connect(self._on_row_selected)
        self.batch_btn.clicked.connect(self._open_batch_modifier)

    # ---- helpers ----
    def _update_multi_hdu_ui(self):
        n = len(self.hdul) if self.hdul else 0
        # Only show when there are multiple HDUs
        self.all_hdus_chk.setVisible(n > 1)    

    def _on_row_selected(self, curr, prev):
        if not curr:
            return
        self.add_key_edit.setText(curr.text(0))
        self.add_val_edit.setText(curr.text(1))
        self.add_com_edit.setText(curr.text(2))

    def _selected_row_triplet(self) -> Tuple[str, str, str]:
        it = self.tree.currentItem()
        if not it:
            return "", "", ""
        return (it.text(0).strip(), it.text(1), it.text(2))

    def _open_batch_modifier(self):
        key, val, com = self._selected_row_triplet()
        # Open non-modally and prefill fields from the selected row
        dlg = BatchFITSHeaderDialog(parent=self,
                                    preset_keyword=key,
                                    preset_value=val,
                                    preset_comment=com)
        dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True)
        dlg.show()

    def _init_from_header(self, header):
        phdu = fits.PrimaryHDU()
        if isinstance(header, fits.Header):
            phdu.header = header.copy()
        elif isinstance(header, dict):
            for k, v in header.items():
                try:
                    phdu.header[k] = v
                except Exception:
                    pass
        self.hdul = fits.HDUList([phdu])
        self._refresh_hdu_combo()
        self._populate_tree_from_header(phdu.header)

    def _apply_to_slot_metadata(self):
        if not self.image_manager:
            QMessageBox.warning(self, "No ImageManager", "No image manager bound.")
            return
        self._sync_tree_to_header()
        slot = self.image_manager.current_slot
        img, meta = self.image_manager.get_current_image_and_metadata()
        meta = {} if meta is None else meta
        hdr = self.hdul[self.current_hdu_index].header.copy()
        meta['fits_header'] = hdr
        self.image_manager.update_image(img, metadata=meta, slot=slot)
        #QMessageBox.information(self, "Applied", "Updated header applied to current slot metadata.")

    def _set_dirty(self, dirty=True):
        self._dirty = dirty
        self.setWindowTitle("FITS Header Editor" + (" *" if dirty else ""))

    def _sync_tree_to_header(self):
        """Write current tree rows into the current HDU header in-memory."""
        if not self.hdul:
            return
        hdr = self.hdul[self.current_hdu_index].header
        self._collect_tree_into_header(hdr)

    def _choose_file(self):
        fn, _ = QFileDialog.getOpenFileName(self, "Open FITS", self._last_dir(), "FITS files (*.fits *.fit *.fts *.fz)")
        if not fn:
            return
        self._load_file(fn)

    def _load_file(self, path) -> bool:
        try:
            if self.hdul is not None:
                self.hdul.close()
        except Exception:
            pass
        try:
            self.hdul = fits.open(path, mode='update', memmap=False)
        except Exception as e:
            QMessageBox.warning(self, "Invalid FITS",
                                f"This file does not appear to be a valid FITS:\n\n{path}\n\n{e}\n\n"
                                "Tip: Choose a FITS file via 'Open FITS…' or edit an in-memory header.")
            self.hdul = None
            self.file_path = None
            self.path_label.setText("(no file)")
            self.hdu_combo.clear()
            self._update_multi_hdu_ui() if hasattr(self, "_update_multi_hdu_ui") else None
            # Leave the tree empty; caller may fall back to provided header
            return False

        self.file_path = path
        self.path_label.setText(path)
        self._save_last_dir(os.path.dirname(path))
        self._refresh_hdu_combo()
        self._populate_tree_from_header(self.hdul[self.current_hdu_index].header)
        return True

    def _reload(self):
        if not self.hdul and not self.file_path:
            return
        if self.file_path:
            self._load_file(self.file_path)
        else:
            # Only transient header in memory – just repopulate from it
            self._populate_tree_from_header(self.hdul[0].header)

    def _refresh_hdu_combo(self):
        self.hdu_combo.blockSignals(True)
        self.hdu_combo.clear()
        for i, hdu in enumerate(self.hdul):
            name = getattr(hdu, 'name', 'UNKNOWN')
            self.hdu_combo.addItem(f"{i}: {name}")
        self.hdu_combo.setCurrentIndex(0)
        self.current_hdu_index = 0
        self.hdu_combo.blockSignals(False)
        self._update_multi_hdu_ui()

    def _on_hdu_changed(self, idx):
        self.current_hdu_index = int(idx)
        hdr = self.hdul[self.current_hdu_index].header
        self._populate_tree_from_header(hdr)

    def _populate_tree_from_header(self, header: fits.Header):
        self._populating = True
        try:
            self.tree.blockSignals(True)
            self.tree.clear()
            for card in header.cards:
                key = card.keyword
                val = "" if key in ("HISTORY", "COMMENT") else self._val_to_str(card.value)
                com = "" if key in ("HISTORY", "COMMENT") else (card.comment or "")
                it = QTreeWidgetItem([key, val, com])
                it.setFlags(it.flags() | Qt.ItemFlag.ItemIsEditable)
                self.tree.addTopLevelItem(it)
            self.tree.resizeColumnToContents(0)
        finally:
            self.tree.blockSignals(False)
            self._populating = False
            self._set_dirty(False)

    def _collect_tree_into_header(self, header: fits.Header):
        """Overwrite FITS header from the tree contents."""
        # Start fresh to preserve tree order
        new_header = fits.Header()
        for i in range(self.tree.topLevelItemCount()):
            it = self.tree.topLevelItem(i)
            key = (it.text(0) or "").strip()
            val_txt = it.text(1)
            com = it.text(2)
            if not key:
                continue
            if key in ("HISTORY", "COMMENT"):
                # For simplicity, store value text into HISTORY/COMMENT (one row each)
                if key == "HISTORY" and val_txt:
                    new_header.add_history(val_txt)
                elif key == "COMMENT" and val_txt:
                    new_header.add_comment(val_txt)
                else:
                    # keep blank entry as a simple comment line if present
                    if key == "COMMENT" and not val_txt and com:
                        new_header.add_comment(com)
                continue
            try:
                val = self._parse_val(val_txt)
                new_header[key] = (val, com if com else None)
            except Exception:
                # If parsing fails, fall back to string
                new_header[key] = (val_txt, com if com else None)

        # Overwrite provided header object in hdul
        header.clear()
        header.update(new_header)

    def _save_in_place(self):
        if self.hdul is None:
            QMessageBox.warning(self, "No Header", "Nothing to save.")
            return
        self._sync_tree_to_header()
        if self.file_path:
            try:
                self.hdul.flush()
                self._set_dirty(False)
                QMessageBox.information(self, "Saved", f"Header saved to: {self.file_path} and slot metadata updated!")
            except Exception as e:
                QMessageBox.critical(self, "Save Error", str(e))
        else:
            self._save_as_copy()

        self._apply_to_slot_metadata()    

    def _on_item_changed(self, item, column):
        if self._populating:
            return
        # Any edit inside the tree updates the in-memory header and marks dirty
        self._sync_tree_to_header()
        self._set_dirty(True)

    def _save_as_copy(self):
        if self.hdul is None:
            QMessageBox.warning(self, "No Header", "Nothing to save.")
            return
        out, _ = QFileDialog.getSaveFileName(self, "Save FITS As", self._last_dir(), "FITS files (*.fits *.fit *.fts)")
        if not out:
            return
        try:
            self._sync_tree_to_header()
            self.hdul.writeto(out, overwrite=True)
            self._save_last_dir(os.path.dirname(out))
            self._set_dirty(False)
            QMessageBox.information(self, "Saved", f"Header saved to: {out}")
        except Exception as e:
            QMessageBox.critical(self, "Save Error", str(e))

    def _add_or_update_keyword(self):
        key = (self.add_key_edit.text() or "").strip()
        # If no key typed but a row is selected, treat as “apply current row edits”
        if not key and self.tree.currentItem() is not None:
            self._sync_tree_to_header()
            self._set_dirty(True)
            # Optional: refresh tree to normalize formatting
            self._populate_tree_from_header(self.hdul[self.current_hdu_index].header)
            return

        if not key:
            return

        val = self.add_val_edit.text()
        com = self.add_com_edit.text()
        try:
            parsed_val = self._parse_val(val)
        except Exception:
            parsed_val = val

        targets = range(len(self.hdul)) if self.all_hdus_chk.isChecked() and self.hdul else [self.current_hdu_index]
        for idx in targets:
            hdr = self.hdul[idx].header
            hdr[key] = (parsed_val, com if com else None)

        self._set_dirty(True)

        # Reflect into tree for current HDU
        if not self.all_hdus_chk.isChecked():
            self._populate_tree_from_header(self.hdul[self.current_hdu_index].header)

    def _add_or_update_keyword(self):
        key = self.add_key_edit.text().strip()
        if not key:
            return
        val = self.add_val_edit.text()
        com = self.add_com_edit.text()
        try:
            parsed_val = self._parse_val(val)
        except Exception:
            parsed_val = val  # leave as string if parsing fails

        targets = range(len(self.hdul)) if self.all_hdus_chk.isChecked() and self.hdul else [self.current_hdu_index]
        for idx in targets:
            hdr = self.hdul[idx].header
            hdr[key] = (parsed_val, com if com else None)
        # Reflect into tree for current HDU
        if not self.all_hdus_chk.isChecked():
            self._populate_tree_from_header(self.hdul[self.current_hdu_index].header)

    def _delete_selected(self):
        items = self.tree.selectedItems()
        if not items:
            return
        targets = range(len(self.hdul)) if self.all_hdus_chk.isChecked() and self.hdul else [self.current_hdu_index]
        for it in items:
            key = it.text(0).strip()
            for idx in targets:
                hdr = self.hdul[idx].header
                # For HISTORY/COMMENT delete this line by rebuilding without it:
                if key in ("HISTORY", "COMMENT"):
                    # rebuild by skipping this exact line
                    rebuilt = fits.Header()
                    for c in hdr.cards:
                        if c.keyword == key:
                            # keep others, skip if value matches this line’s value
                            if (key == "HISTORY" and c.value == it.text(1)) or \
                               (key == "COMMENT" and (c.value == it.text(1) or c.comment == it.text(2))):
                                continue
                        rebuilt.append(c)
                    hdr.clear(); hdr.update(rebuilt)
                else:
                    if key in hdr:
                        del hdr[key]
        # Reflect in current view
        self._populate_tree_from_header(self.hdul[self.current_hdu_index].header)

    # ---- value parsing helpers ----
    def _parse_val(self, s: str):
        if s is None:
            return ""
        t = s.strip()
        if t.lower() in ("true", "t"): return True
        if t.lower() in ("false", "f"): return False
        if t.lower() in ("nan",): return np.nan
        # int?
        try:
            if t.startswith("0x"):
                return int(t, 16)
            return int(t)
        except ValueError:
            pass
        # float?
        try:
            return float(t)
        except ValueError:
            pass
        # quoted strings? remove surrounding quotes
        if (t.startswith('"') and t.endswith('"')) or (t.startswith("'") and t.endswith("'")):
            return t[1:-1]
        return t

    def _val_to_str(self, v):
        if isinstance(v, (float, np.floating)) and np.isnan(v):
            return "nan"
        return str(v)

    def closeEvent(self, e):
        try:
            if self.hdul is not None:
                self.hdul.close()
        except Exception:
            pass
        super().closeEvent(e)

    # ---- QSettings helpers ----
    def _settings(self):
        return self.parent().settings if (self.parent() and hasattr(self.parent(), "settings")) else QSettings()
    def _last_dir(self):
        return self._settings().value("fits_modifier/last_dir", "", type=str) or ""
    def _save_last_dir(self, d):
        self._settings().setValue("fits_modifier/last_dir", d)

class BatchFITSHeaderDialog(QDialog):
    def __init__(self, parent=None, preset_keyword: str = "", preset_value: str = "", preset_comment: str = ""):
        super().__init__(parent)
        self.setWindowTitle("Batch Modify FITS Headers")
        self.resize(520, 220)

        v = QVBoxLayout(self)

        row1 = QHBoxLayout()
        self.files_edit = QLineEdit(); self.files_edit.setPlaceholderText("No files selected")
        self.pick_btn = QPushButton("Choose FITS Files…")
        row1.addWidget(self.files_edit, 1); row1.addWidget(self.pick_btn)

        row2 = QHBoxLayout()
        self.key_edit = QLineEdit(); self.key_edit.setPlaceholderText("KEYWORD")
        self.val_edit = QLineEdit(); self.val_edit.setPlaceholderText("Value (leave blank for delete)")
        self.com_edit = QLineEdit(); self.com_edit.setPlaceholderText("Comment (optional)")
        row2.addWidget(self.key_edit); row2.addWidget(self.val_edit); row2.addWidget(self.com_edit)

        row3 = QHBoxLayout()
        self.mode_combo = QComboBox()
        self.mode_combo.addItems(["Add/Update", "Delete"])
        self.all_hdus_chk = QCheckBox("Apply to all HDUs")
        self.add_if_missing_chk = QCheckBox("Add if missing (for Add/Update)")
        self.add_if_missing_chk.setChecked(True)
        row3.addWidget(self.mode_combo)
        row3.addWidget(self.all_hdus_chk)
        row3.addWidget(self.add_if_missing_chk)
        row3.addStretch()

        row4 = QHBoxLayout()
        self.run_btn = QPushButton("Run")
        self.close_btn = QPushButton("Close")
        row4.addStretch(); row4.addWidget(self.run_btn); row4.addWidget(self.close_btn)

        v.addLayout(row1)
        v.addLayout(row2)
        v.addLayout(row3)
        v.addLayout(row4)

        # Prefill from the single editor’s selection
        if preset_keyword:
            self.key_edit.setText(preset_keyword)
        if preset_value:
            self.val_edit.setText(preset_value)
        if preset_comment:
            self.com_edit.setText(preset_comment)

        self.pick_btn.clicked.connect(self._pick_files)
        self.run_btn.clicked.connect(self._run)
        self.close_btn.clicked.connect(self.close)

        self.files = []

    def _settings(self):
        return self.parent().settings if (self.parent() and hasattr(self.parent(), "settings")) else QSettings()

    def _pick_files(self):
        last = self._settings().value("fits_modifier/batch_dir", "", type=str) or ""
        files, _ = QFileDialog.getOpenFileNames(self, "Select FITS files", last, "FITS files (*.fits *.fit *.fts *.fz)")
        if not files:
            return
        self.files = files
        self.files_edit.setText(f"{len(files)} files selected")
        self._settings().setValue("fits_modifier/batch_dir", os.path.dirname(files[0]))

    def _parse_val(self, s: str):
        # match editor’s parser
        t = (s or "").strip()
        if t == "": return ""
        if t.lower() in ("true", "t"): return True
        if t.lower() in ("false", "f"): return False
        if t.lower() in ("nan",): return np.nan
        try:
            if t.startswith("0x"):
                return int(t, 16)
            return int(t)
        except ValueError:
            pass
        try:
            return float(t)
        except ValueError:
            pass
        if (t.startswith('"') and t.endswith('"')) or (t.startswith("'") and t.endswith("'")):
            return t[1:-1]
        return t

    def _run(self):
        if not self.files:
            QMessageBox.warning(self, "No files", "Please choose one or more FITS files.")
            return
        key = self.key_edit.text().strip()
        if not key:
            QMessageBox.warning(self, "Missing keyword", "Please enter a FITS keyword.")
            return

        mode = self.mode_combo.currentText()
        apply_all_hdus = self.all_hdus_chk.isChecked()
        add_if_missing = self.add_if_missing_chk.isChecked()
        com = self.com_edit.text().strip()
        value_txt = self.val_edit.text()

        n_ok, n_err = 0, 0
        for fp in self.files:
            try:
                with fits.open(fp, mode='update', memmap=False) as hdul:
                    targets = range(len(hdul)) if apply_all_hdus else [0]
                    if mode == "Delete":
                        for i in targets:
                            hdr = hdul[i].header
                            if key in ("HISTORY", "COMMENT"):
                                # delete all lines that match value/comment text loosely
                                rebuilt = fits.Header()
                                for c in hdr.cards:
                                    if c.keyword == key:
                                        if value_txt and str(c.value) == value_txt:
                                            continue
                                        if (not value_txt) and (not com):
                                            # delete all such lines
                                            continue
                                        if com and (c.comment == com):
                                            continue
                                    rebuilt.append(c)
                                hdr.clear(); hdr.update(rebuilt)
                            else:
                                if key in hdr:
                                    del hdr[key]
                        hdul.flush()
                    else:
                        # Add/Update
                        try:
                            val = self._parse_val(value_txt)
                        except Exception:
                            val = value_txt
                        for i in targets:
                            hdr = hdul[i].header
                            if key in hdr or add_if_missing:
                                hdr[key] = (val, com if com else None)
                        hdul.flush()
                n_ok += 1
            except Exception as e:
                print(f"[Batch FITS] Error on {fp}: {e}")
                n_err += 1

        QMessageBox.information(self, "Batch Complete", f"Updated {n_ok} file(s); {n_err} error(s).")

ASTROBIN_FILTER_URL = "https://app.astrobin.com/equipment/explorer/filter?page=1"

OFFLINE_FILTERS_CSV_DEFAULT = astrobin_filters_csv_path

class _IdOnlyCompleter(QCompleter):
    """
    Shows 'ID — Brand — Name' in the popup, but when a row is chosen it inserts only the ID.
    """
    def pathFromIndex(self, index):
        # Return the numeric ID stored in UserRole
        return index.data(Qt.ItemDataRole.UserRole) or super().pathFromIndex(index)

class _AstrobinIdDelegate(QStyledItemDelegate):
    """
    QLineEdit with int validator + optional completer for the AstroBin ID column.
    """
    def __init__(self, parent=None, completer: Optional[QCompleter] = None):

        super().__init__(parent)
        self._completer = completer

    def createEditor(self, parent, option, index):
        editor = QLineEdit(parent)
        editor.setPlaceholderText("e.g. 4408")
        editor.setValidator(QIntValidator(1, 999_999_999, editor))
        if self._completer is not None:
            editor.setCompleter(self._completer)
        return editor

class _IntOnlyDelegate(QStyledItemDelegate):
    """Editor that only allows integers (for AstroBin ID column)."""
    def createEditor(self, parent, option, index):
        editor = QLineEdit(parent)
        editor.setPlaceholderText("e.g. 4408")
        editor.setValidator(QIntValidator(1, 999999999, editor))
        return editor


class FilterIdDialog(QDialog):
    """
    Editable table: local filter name ↔ AstroBin numeric ID.
    Populates with union of:
      - filters seen in this dataset, and
      - previously saved mapping from QSettings.

    Saves back into QSettings as "Name=ID;Name2=ID2;...".
    """
    BLANK_ROWS = 6  # how many empty rows to offer at the bottom


    def __init__(self, parent, filters_in_data: List[str], settings: QSettings,
                current_map: Optional[Dict[str, str]] = None):
        super().__init__(parent)
        self.setWindowTitle("AstroBin Filter IDs")
        self.settings = settings

        base_names = sorted({f for f in (filters_in_data or []) if f and f != "Unknown"}, key=str.lower)

        # ⬇️ merge settings + current exporter map, prefer current exporter values on conflicts
        stored_map = self._load_mapping()
        if current_map:
            stored_map = {**stored_map, **current_map}

        all_names = sorted(set(base_names) | set(stored_map.keys()), key=str.lower)

        # ---- Layout ----
        root = QVBoxLayout(self)

        # Help row with link
        # Help row with link
        help_row = QHBoxLayout()
        help_label = QLabel("Edit filter names and their AstroBin numeric IDs.")
        help_btn = QToolButton(self)
        help_btn.setText("?")
        help_btn.setToolTip("Open AstroBin Equipment Explorer (Filters)")
        help_btn.clicked.connect(lambda: webbrowser.open(ASTROBIN_FILTER_URL))

        self.load_db_btn = QPushButton(self)  # <- keep a handle on it
        self.load_db_btn.setToolTip("Search or load the offline filters database.")
        self.load_db_btn.clicked.connect(self._on_offline_action)

        help_row.addWidget(help_label)
        help_row.addStretch(1)
        help_row.addWidget(self.load_db_btn)
        help_row.addWidget(help_btn)
        root.addLayout(help_row)

        # Table
        self.table = QTableWidget(self)
        self.table.setColumnCount(2)
        self.table.setHorizontalHeaderLabels(["Filter name", "AstroBin ID"])
        self.table.horizontalHeader().setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        self.table.horizontalHeader().setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        self.table.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.table.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.table.setEditTriggers(QAbstractItemView.EditTrigger.AllEditTriggers)

        # numeric delegate on column 1 (AstroBin ID)
        self._load_offline_db()                         # tries settings/default path automatically
        self._id_completer = self._make_id_completer()  # may be None if no CSV found
        self.table.setItemDelegateForColumn(1, _AstrobinIdDelegate(self.table, completer=self._id_completer))

        self._update_offline_button_text()  # <- set initial text depending on DB presence

        # Fill rows
        rows = len(all_names) + self.BLANK_ROWS
        self.table.setRowCount(rows)
        r = 0
        for name in all_names:
            name_item = QTableWidgetItem(name)
            name_item.setFlags(name_item.flags() | Qt.ItemFlag.ItemIsEditable)
            id_item = QTableWidgetItem(str(stored_map.get(name, "")))
            id_item.setFlags(id_item.flags() | Qt.ItemFlag.ItemIsEditable)
            id_item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)

            self.table.setItem(r, 0, name_item)
            self.table.setItem(r, 1, id_item)
            r += 1

        # trailing blank rows
        while r < rows:
            self.table.setItem(r, 0, QTableWidgetItem(""))
            self.table.setItem(r, 1, QTableWidgetItem(""))
            # make them editable
            self.table.item(r, 0).setFlags(self.table.item(r, 0).flags() | Qt.ItemFlag.ItemIsEditable)
            self.table.item(r, 1).setFlags(self.table.item(r, 1).flags() | Qt.ItemFlag.ItemIsEditable)
            self.table.item(r, 1).setTextAlignment(Qt.AlignmentFlag.AlignCenter)
            r += 1

        root.addWidget(self.table, 1)

        # Row actions
        row_actions = QHBoxLayout()
        self.btn_add = QPushButton("Add row")
        self.btn_add.clicked.connect(self._add_row)
        self.btn_del = QPushButton("Delete selected")
        self.btn_del.clicked.connect(self._delete_selected_rows)
        row_actions.addWidget(self.btn_add)
        row_actions.addWidget(self.btn_del)
        row_actions.addStretch(1)
        root.addLayout(row_actions)

        # OK/Cancel buttons
        btns = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel,
            parent=self
        )
        btns.accepted.connect(self.accept)
        btns.rejected.connect(self.reject)
        root.addWidget(btns)

        # optional nicety: focus first cell
        self.table.setCurrentCell(0, 0)

    # ----- helpers -----
    def _update_offline_button_text(self):
        if getattr(self, "_offline_rows", None):
            self.load_db_btn.setText("Search offline DB…")
        else:
            self.load_db_btn.setText("Load offline DB…")

    def _on_offline_action(self):
        if getattr(self, "_offline_rows", None):
            self._open_offline_search()   # search picker
        else:
            self._browse_offline_db()     # first-time: pick CSV
            self._id_completer = self._make_id_completer()
            self.table.setItemDelegateForColumn(1, _AstrobinIdDelegate(self.table, completer=self._id_completer))
            self._update_offline_button_text()

    def _add_row(self):
        r = self.table.rowCount()
        self.table.insertRow(r)
        self.table.setItem(r, 0, QTableWidgetItem(""))
        self.table.setItem(r, 1, QTableWidgetItem(""))
        # editable + centered
        self.table.item(r, 0).setFlags(self.table.item(r, 0).flags() | Qt.ItemFlag.ItemIsEditable)
        self.table.item(r, 1).setFlags(self.table.item(r, 1).flags() | Qt.ItemFlag.ItemIsEditable)
        self.table.item(r, 1).setTextAlignment(Qt.AlignmentFlag.AlignCenter)
        self.table.scrollToBottom()
        self.table.setCurrentCell(r, 0)

    def _delete_selected_rows(self):
        rows = sorted({i.row() for i in self.table.selectedIndexes()}, reverse=True)
        for r in rows:
            self.table.removeRow(r)

    def _load_mapping(self) -> Dict[str, str]:

        self.settings.beginGroup("astrobin_exporter")
        raw = self.settings.value("filter_map", "")
        self.settings.endGroup()
        mapping: Dict[str, str] = {}
        if isinstance(raw, str) and raw:
            for chunk in raw.split(";"):
                if "=" in chunk:
                    k, v = chunk.split("=", 1)
                    k, v = k.strip(), v.strip()
                    if k:
                        mapping[k] = v
        return mapping

    def mapping(self) -> Dict[str, str]:
        """
        Read table -> {name: id}. Keeps only rows with a non-empty name.
        If ID is empty, the pair is skipped (you can still use the filter name as fallback elsewhere).
        """
        mp: Dict[str, str] = {}
        rows = self.table.rowCount()
        for r in range(rows):
            name_item = self.table.item(r, 0)
            id_item = self.table.item(r, 1)
            name = (name_item.text().strip() if name_item else "")
            fid = (id_item.text().strip() if id_item else "")
            if not name:
                continue
            # keep only numeric IDs; ignore if blank or non-numeric
            if fid and fid.isdigit():
                mp[name] = fid
        return mp

    def save_to_settings(self):
        mp = self.mapping()
        blob = ";".join(f"{k}={v}" for k, v in mp.items())
        self.settings.beginGroup("astrobin_exporter")
        self.settings.setValue("filter_map", blob)
        self.settings.endGroup()

    def _find_offline_csv(self) -> Optional[str]:

        # 1) user-specified path in settings
        self.settings.beginGroup("astrobin_exporter")
        saved = self.settings.value("offline_filters_csv", "")
        self.settings.endGroup()
        if isinstance(saved, str) and saved and os.path.isfile(saved):
            return saved
        # 2) default next to the app
        if os.path.isfile(OFFLINE_FILTERS_CSV_DEFAULT):
            return OFFLINE_FILTERS_CSV_DEFAULT
        return None

    def _open_offline_search(self):
        if not getattr(self, "_offline_rows", None):
            QMessageBox.information(self, "No DB", "Offline filters database not loaded yet.")
            return

        dlg = QDialog(self)
        dlg.setWindowTitle("Search AstroBin Filters (offline)")
        v = QVBoxLayout(dlg)

        q = QLineEdit(dlg)
        q.setPlaceholderText("Search ID, brand, or name…")
        v.addWidget(q)

        tbl = QTableWidget(dlg)
        tbl.setColumnCount(3)
        tbl.setHorizontalHeaderLabels(["ID", "Brand", "Name"])
        hdr = tbl.horizontalHeader()
        hdr.setSectionResizeMode(0, QHeaderView.ResizeMode.ResizeToContents)
        hdr.setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        hdr.setSectionResizeMode(2, QHeaderView.ResizeMode.Stretch)
        tbl.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        tbl.setSelectionMode(QAbstractItemView.SelectionMode.SingleSelection)
        v.addWidget(tbl, 1)

        # --- fill rows ---
        rows = sorted(self._offline_rows, key=lambda r: (r.get("brand","").lower(), r.get("name","").lower()))
        tbl.setRowCount(len(rows))
        for r, data in enumerate(rows):
            for c, key in enumerate(("id","brand","name")):
                it = QTableWidgetItem(data.get(key,""))
                if c == 0:
                    it.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                tbl.setItem(r, c, it)

        dlg.resize(500, 350)              # initial dialog size
        tbl.resizeColumnsToContents()       # let Qt compute good starting widths
        hdr.resizeSection(0, 90)            # ID column ~90 px
        hdr.resizeSection(1, 90)           # Brand column ~220 px

        def apply_filter(text: str):
            t = (text or "").lower()
            for r in range(tbl.rowCount()):
                row_txt = " ".join((tbl.item(r, c).text() if tbl.item(r, c) else "") for c in range(3)).lower()
                tbl.setRowHidden(r, t not in row_txt)

        q.textChanged.connect(apply_filter)

        btns = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel, parent=dlg)
        v.addWidget(btns)
        btns.accepted.connect(dlg.accept)
        btns.rejected.connect(dlg.reject)

        tbl.doubleClicked.connect(lambda *_: dlg.accept())

        if dlg.exec() == QDialog.DialogCode.Accepted:
            r = tbl.currentRow()
            if r >= 0:
                fid = tbl.item(r, 0).text()
                cur = self.table.currentRow()
                if cur < 0:
                    cur = 0
                item = QTableWidgetItem(fid)
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.table.setItem(cur, 1, item)
                self.table.setCurrentCell(cur, 1)
                self.table.editItem(item)

    def _load_offline_db(self, csv_path: Optional[str] = None) -> List[Dict]:

        """
        Returns list of dicts: {'id': '4413', 'brand': 'Brand', 'name': 'Filter Name'}
        """
        if not csv_path:
            csv_path = self._find_offline_csv()
        self._offline_rows = []
        if not csv_path:
            return self._offline_rows

        try:
            with open(csv_path, newline="", encoding="utf-8") as f:
                rdr = csv.DictReader(f)
                for row in rdr:
                    fid = (row.get("id") or "").strip()
                    if not fid.isdigit():
                        continue
                    self._offline_rows.append({
                        "id": fid,
                        "brand": (row.get("brand") or "").strip(),
                        "name": (row.get("name") or "").strip()
                    })
            # remember the path
            self.settings.beginGroup("astrobin_exporter")
            self.settings.setValue("offline_filters_csv", csv_path)
            self.settings.endGroup()
        except Exception as e:
            print(f"[WARN] Failed to load offline CSV: {e}")
        return self._offline_rows

    def _make_id_completer(self) -> Optional[QCompleter]:

        """
        Build a completer from self._offline_rows that shows 'ID — Brand — Name'
        but inserts only the ID into the editor.
        """
        rows = getattr(self, "_offline_rows", None) or []
        if not rows:
            return None

        model = QStandardItemModel()
        for r in rows:
            fid = r["id"]
            brand = r.get("brand") or ""
            name  = r.get("name")  or ""
            disp = f"{fid} — {brand} — {name}".strip(" —")
            it = QStandardItem(disp)
            it.setData(fid, Qt.ItemDataRole.UserRole)   # what we want to insert
            model.appendRow(it)

        comp = _IdOnlyCompleter(model, self)
        comp.setCaseSensitivity(Qt.CaseSensitivity.CaseInsensitive)
        comp.setFilterMode(Qt.MatchFlag.MatchContains)   # substring matches
        comp.setCompletionRole(Qt.ItemDataRole.DisplayRole)
        return comp

    def _browse_offline_db(self):
        path, _ = QFileDialog.getOpenFileName(
            self, "Select AstroBin Filters CSV", "", "CSV files (*.csv);;All files (*)"
        )
        if not path:
            return
        self._load_offline_db(path)
        self._id_completer = self._make_id_completer()
        # re-attach a new delegate with the fresh completer
        self.table.setItemDelegateForColumn(1, _AstrobinIdDelegate(self.table, completer=self._id_completer))


class AstrobinExportTab(QWidget):
    """
    Blink-like organizer on the left; on the right, global inputs (f/number and more)
    and a live table of aggregated rows; copy CSV to clipboard.

    Aggregation key: (date, filterID, exposure)
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.settings = QSettings()
        self.file_paths: List[str] = []
        self.records: List[dict] = []
        self.rows: List[dict] = []
        self._filter_map: Dict[str, str] = self._load_filter_map()

        self._build_ui()
        self._load_defaults()

    # ---------------- UI ----------------
    def _build_ui(self):
        root = QHBoxLayout(self)
        splitter = QSplitter(Qt.Orientation.Horizontal, self)
        root.addWidget(splitter)

        # LEFT: tree + file controls
        left = QWidget(self)
        lyt = QVBoxLayout(left)
        self.info_lbl = QLabel("Load FITS via 'Select Folder…' or 'Add Files…' to begin.")
        lyt.addWidget(self.info_lbl)

        btn_row = QHBoxLayout()
        self.btn_open = QPushButton("Select Folder…")
        self.btn_open.clicked.connect(self.open_directory)
        btn_row.addWidget(self.btn_open)

        self.btn_add_files = QPushButton("Add Files…")
        self.btn_add_files.clicked.connect(self.open_files)
        btn_row.addWidget(self.btn_add_files)

        self.btn_clear = QPushButton("Clear")
        self.btn_clear.clicked.connect(self.clear_images)
        btn_row.addWidget(self.btn_clear)

        btn_row.addStretch(1)
        lyt.addLayout(btn_row)

        self.tree = QTreeWidget(self)
        self.tree.setColumnCount(1)
        self.tree.setHeaderLabels(["Files (Object → Filter → Exposure)"])

        # make the column user-resizable, allow long text, and enable h-scrolling
        hdr = self.tree.header()
        hdr.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)
        hdr.setStretchLastSection(False)  # let the column grow wider than the viewport
        self.tree.setTextElideMode(Qt.TextElideMode.ElideNone)
        self.tree.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.tree.setHorizontalScrollMode(QAbstractItemView.ScrollMode.ScrollPerPixel)

        self.tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.tree.itemChanged.connect(self._on_tree_item_changed)
        lyt.addWidget(self.tree)

        splitter.addWidget(left)

        # RIGHT: inputs + table + actions
        right = QWidget(self)
        rlyt = QVBoxLayout(right)

        # Global inputs (now a 3×3 grid)
        form_box = QGroupBox("Global inputs (used if FITS headers are missing/zero)")
        grid = QGridLayout(form_box)

        # row 0
        grid.addWidget(QLabel("f/number"), 0, 0)
        self.fnum_edit = QLineEdit(self)
        self.fnum_edit.setPlaceholderText("e.g. 4.0")
        self.fnum_edit.setValidator(QDoubleValidator(0.0, 999.0, 2, self))
        self.fnum_edit.textChanged.connect(self._recompute)
        grid.addWidget(self.fnum_edit, 0, 1)

        grid.addWidget(QLabel("Darks (#)"), 0, 2)
        self.darks_edit = QLineEdit(self); self._setup_int_line(self.darks_edit, 0, 999999)
        grid.addWidget(self.darks_edit, 0, 3)

        grid.addWidget(QLabel("Flats (#)"), 0, 4)
        self.flats_edit = QLineEdit(self); self._setup_int_line(self.flats_edit, 0, 999999)
        grid.addWidget(self.flats_edit, 0, 5)

        # row 1
        grid.addWidget(QLabel("Flat-darks (#)"), 1, 0)
        self.flatdarks_edit = QLineEdit(self); self._setup_int_line(self.flatdarks_edit, 0, 999999)
        grid.addWidget(self.flatdarks_edit, 1, 1)

        grid.addWidget(QLabel("Bias (#)"), 1, 2)
        self.bias_edit = QLineEdit(self); self._setup_int_line(self.bias_edit, 0, 999999)
        grid.addWidget(self.bias_edit, 1, 3)

        grid.addWidget(QLabel("Bortle"), 1, 4)
        self.bortle_edit = QLineEdit(self)
        self.bortle_edit.setPlaceholderText("0–9")
        self.bortle_edit.setValidator(QIntValidator(0, 9, self))
        self.bortle_edit.textChanged.connect(self._recompute)
        grid.addWidget(self.bortle_edit, 1, 5)

        # row 2
        grid.addWidget(QLabel("Mean SQM"), 2, 0)
        self.mean_sqm_edit = QLineEdit(self)
        self.mean_sqm_edit.setPlaceholderText("e.g. 21.30")
        self.mean_sqm_edit.setValidator(QDoubleValidator(0.0, 25.0, 2, self))
        self.mean_sqm_edit.textChanged.connect(self._recompute)
        grid.addWidget(self.mean_sqm_edit, 2, 1)

        grid.addWidget(QLabel("Mean FWHM"), 2, 2)
        self.mean_fwhm_edit = QLineEdit(self)
        self.mean_fwhm_edit.setPlaceholderText("e.g. 2.10")
        self.mean_fwhm_edit.setValidator(QDoubleValidator(0.0, 50.0, 2, self))
        self.mean_fwhm_edit.textChanged.connect(self._recompute)
        grid.addWidget(self.mean_fwhm_edit, 2, 3)

        self.noon_cb = QCheckBox("Group nights noon → noon (local time)")
        self.noon_cb.setToolTip("Prevents splitting a single observing night at midnight.")
        self.noon_cb.setChecked(self.settings.value("astrobin_exporter/noon_to_noon", True, type=bool))
        self.noon_cb.toggled.connect(self._recompute)
        grid.addWidget(self.noon_cb, 2, 4, 1, 2)

        # keep last 2 cells open or use a spacer
        grid.addItem(QSpacerItem(0, 0, QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Minimum), 2, 4, 1, 2)

        # Filter mapping row (below the 3×3 grid, spanning full width)
        map_row = QHBoxLayout()
        self.filter_summary = QLabel(self._filters_summary_text())
        map_row.addWidget(self.filter_summary)
        self.btn_edit_filters = QPushButton("Manage Filter IDs…")
        self.btn_edit_filters.clicked.connect(self._edit_filters)
        map_row.addWidget(self.btn_edit_filters)
        qmark = QToolButton(self); qmark.setText("?")
        qmark.setToolTip("Open AstroBin Equipment Explorer (Filters)")
        qmark.clicked.connect(lambda: webbrowser.open(ASTROBIN_FILTER_URL))
        map_row.addWidget(qmark)
        map_row.addStretch(1)
        map_wrap = QWidget(self); map_wrap.setLayout(map_row)
        grid.addWidget(map_wrap, 3, 0, 1, 6)

        rlyt.addWidget(form_box)

        # Aggregated table
        self.table = QTableWidget(self)
        cols = ['date','filter','number','duration','gain','iso','binning','sensorCooling',
                'fNumber','darks','flats','flatDarks','bias','bortle','meanSqm','meanFwhm','temperature']
        self.table.setColumnCount(len(cols))
        self.table.setHorizontalHeaderLabels(cols)

        hdr_tbl = self.table.horizontalHeader()
        hdr_tbl.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)    # ← enable dragging
        hdr_tbl.setStretchLastSection(False)
        hdr_tbl.setMinimumSectionSize(50)
        self.table.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.table.setHorizontalScrollMode(QAbstractItemView.ScrollMode.ScrollPerPixel)
        rlyt.addWidget(self.table, 1)

        # CSV preview
        rlyt.addWidget(QLabel("CSV Preview:"))
        self.csv_view = QTextEdit(self)
        self.csv_view.setReadOnly(True)
        try:
            self.csv_view.setFont(QFontDatabase.systemFont(QFontDatabase.SystemFont.FixedFont))
        except Exception:
            pass
        rlyt.addWidget(self.csv_view, 1)

        # Actions
        act_row = QHBoxLayout()
        self.btn_refresh = QPushButton("Recompute")
        self.btn_refresh.clicked.connect(self._recompute)
        act_row.addWidget(self.btn_refresh)

        self.btn_copy_csv = QPushButton("Copy CSV")
        self.btn_copy_csv.clicked.connect(self._copy_csv_to_clipboard)
        act_row.addWidget(self.btn_copy_csv)

        act_row.addStretch(1)
        rlyt.addLayout(act_row)

        splitter.addWidget(right)
        splitter.setSizes([350, 650])
        self.setLayout(root)

    def _setup_int_line(self, line: QLineEdit, lo: int, hi: int):
        line.setValidator(QIntValidator(lo, hi, self))
        line.setPlaceholderText("0")
        line.textChanged.connect(self._recompute)

    # --------------- Settings ---------------
    def _load_defaults(self):
        self.settings.beginGroup("astrobin_exporter")
        self.fnum_edit.setText(str(self.settings.value("fnumber", "")))
        self.darks_edit.setText(str(self.settings.value("darks", "")))
        self.flats_edit.setText(str(self.settings.value("flats", "")))
        self.flatdarks_edit.setText(str(self.settings.value("flatdarks", "")))
        self.bias_edit.setText(str(self.settings.value("bias", "")))
        self.bortle_edit.setText(str(self.settings.value("bortle", "")))
        self.mean_sqm_edit.setText(str(self.settings.value("mean_sqm", "")))
        self.mean_fwhm_edit.setText(str(self.settings.value("mean_fwhm", "")))
        self.noon_cb.setChecked(self.settings.value("noon_to_noon", True, type=bool))
        self._last_dir = str(self.settings.value("last_dir", "")) or ""
        self.settings.endGroup()

    def _save_defaults(self):
        self.settings.beginGroup("astrobin_exporter")
        self.settings.setValue("fnumber", self.fnum_edit.text().strip())
        self.settings.setValue("darks", self.darks_edit.text().strip())
        self.settings.setValue("flats", self.flats_edit.text().strip())
        self.settings.setValue("flatdarks", self.flatdarks_edit.text().strip())
        self.settings.setValue("bias", self.bias_edit.text().strip())
        self.settings.setValue("bortle", self.bortle_edit.text().strip())
        self.settings.setValue("mean_sqm", self.mean_sqm_edit.text().strip())
        self.settings.setValue("mean_fwhm", self.mean_fwhm_edit.text().strip())
        self.settings.setValue("noon_to_noon", self.noon_cb.isChecked())
        # last_dir is saved when you actually pick a folder/files
        self.settings.endGroup()

    def _get_last_dir(self) -> str:
        return getattr(self, "_last_dir", "") or ""

    def _save_last_dir(self, path: str):
        if not path:
            return
        self._last_dir = path
        self.settings.beginGroup("astrobin_exporter")
        self.settings.setValue("last_dir", path)
        self.settings.endGroup()

    def clear_images(self):
        """Clear all loaded FITS paths and UI state (tree, table, CSV preview)."""
        self.file_paths.clear()
        self.records.clear()
        self.rows.clear()

        # Tree
        self.tree.blockSignals(True)
        self.tree.clear()
        self.tree.blockSignals(False)

        # Table
        self.table.setRowCount(0)

        # CSV preview
        self.csv_view.clear()

        # Info label
        self.info_lbl.setText("Cleared. Load FITS via 'Select Folder…' or 'Add Files…' to begin.")

    def _load_filter_map(self) -> Dict[str, str]:
        """
        Load the filter-name -> AstroBin-ID map.
        - On first run (no saved map), seed with sensible defaults.
        - After that, DO NOT merge defaults back in; use only what the user saved.
        """
        defaults = {"Ha":"4408", "OIII":"4413", "SII":"4418", "L":"4450", "R":"4455", "G":"4445", "B":"4440"}

        self.settings.beginGroup("astrobin_exporter")
        raw = self.settings.value("filter_map", "")
        self.settings.endGroup()

        # First run: seed settings with defaults so they appear in the editor and can be edited/removed.
        if not raw:
            blob = ";".join(f"{k}={v}" for k, v in defaults.items())
            self.settings.beginGroup("astrobin_exporter")
            self.settings.setValue("filter_map", blob)
            self.settings.endGroup()
            return defaults.copy()

        # Subsequent runs: load ONLY the user's saved mapping.
        mapping: Dict[str, str] = {}
        for chunk in str(raw).split(";"):
            if "=" in chunk:
                k, v = chunk.split("=", 1)
                k, v = k.strip(), v.strip()
                if k and v.isdigit():
                    mapping[k] = v
        return mapping

    def _filters_summary_text(self) -> str:
        if not self._filter_map:
            return "No mappings set"
        pairs = sorted(self._filter_map.items(), key=lambda kv: kv[0].lower())
        return ", ".join(f"{k}→{v}" for k, v in pairs)

    def _edit_filters(self):
        names_in_data = sorted({rec.get("FILTER","Unknown") for rec in self.records if rec.get("FILTER")}, key=str.lower)
        # your FilterIdDialog should accept current_map, otherwise remove that kwarg
        dlg = FilterIdDialog(self, names_in_data, self.settings, current_map=self._filter_map)
        if dlg.exec() == QDialog.DialogCode.Accepted:
            dlg.save_to_settings()
            self._filter_map = self._load_filter_map()
            self.filter_summary.setText(self._filters_summary_text())
            self._recompute()

    # ---------------- Loading & tree ----------------
    @staticmethod
    def _natural_key(path: str):
        name = os.path.basename(path)
        return [int(tok) if tok.isdigit() else tok.lower()
                for tok in re.split(r'(\d+)', name)]

    def open_directory(self):
        start = self._get_last_dir() or ""
        directory = QFileDialog.getExistingDirectory(self, "Select Folder Containing FITS Files", start)
        if not directory:
            return
        self._save_last_dir(directory)

        paths = []
        for root, _, files in os.walk(directory):
            for fn in files:
                if fn.lower().endswith((".fit", ".fits")):
                    paths.append(os.path.join(root, fn))
        paths.sort(key=self._natural_key)
        if not paths:
            QMessageBox.information(self, "No FITS", "No .fit/.fits files found.")
            return
        self.file_paths = paths
        self._read_headers()
        self._build_tree()
        self._recompute()

    def open_files(self):
        """Let the user add one or more FITS files (without scanning a directory)."""
        start = self._get_last_dir() or ""
        paths, _ = QFileDialog.getOpenFileNames(
            self, "Select FITS Files", start, "FITS files (*.fit *.fits);;All Files (*)"
        )
        if not paths:
            return
        # save the directory of the first selection
        self._save_last_dir(os.path.dirname(paths[0]))

        # Deduplicate vs. what's already loaded
        new_paths = [p for p in paths if p not in self.file_paths]
        if not new_paths:
            QMessageBox.information(self, "No New Files", "All selected files are already in the list.")
            return

        self.file_paths.extend(new_paths)
        self.file_paths = sorted(set(self.file_paths), key=self._natural_key)

        self._read_headers()
        self._build_tree()
        self._recompute()

    def _read_headers(self):
        self.records.clear()
        ok, bad = 0, 0
        for fp in self.file_paths:
            try:
                with fits.open(fp) as hdul:
                    h = hdul[0].header
                rec = {
                    "PATH": fp,
                    "NAME": os.path.basename(fp),
                    "OBJECT": str(h.get("OBJECT", "Unknown")),
                    "FILTER": str(h.get("FILTER", "Unknown")),
                    "EXPOSURE": self._safe_float(h.get("EXPOSURE", 0.0)),
                    "GAIN": str(h.get("GAIN", "0")),
                    "ISO": str(h.get("ISO", "0")),
                    "BINNING": self._derive_binning(h),
                    "CCD_TEMP": self._safe_float(h.get("CCD-TEMP", 0.0)),
                    "FOCTEMP": self._safe_float(h.get("FOCTEMP", 0.0)),
                    "DARK": str(h.get("DARK","0")),
                    "FLAT": str(h.get("FLAT","0")),
                    "FLATDARK": str(h.get("FLATDARK","0")),
                    "BIAS": str(h.get("BIAS","0")),
                    "BORTLE": str(h.get("BORTLE","0")),
                    "MEAN_SQM": str(h.get("MEAN_SQM","0")),
                    "MEAN_FWHM": str(h.get("MEAN_FWHM","0")),
                    "DATE": self._to_date_only(str(h.get("DATE-OBS","0"))),
                    "DATEOBS": str(h.get("DATE-OBS","")),
                }
                self.records.append(rec)
                ok += 1
            except Exception as e:
                print(f"[WARN] Failed to read {fp}: {e}")
                bad += 1
        self.info_lbl.setText(f"Loaded {ok} FITS ({bad} failed).")

    @staticmethod
    def _safe_float(x, default=0.0) -> float:
        try:
            return float(x)
        except Exception:
            return float(default)

    @staticmethod
    def _derive_binning(h) -> str:
        for k in ("XBINNING", "XBIN", "CCDXBIN"):
            if k in h:
                try:
                    return str(int(float(h[k])))
                except Exception:
                    return str(h[k])
        return "0"

    @staticmethod
    def _to_date_only(date_obs: str) -> str:
        if not date_obs or date_obs == "0":
            return "0"
        return date_obs.split("T")[0].strip()

    def _parse_date_obs(self, s: str) -> Optional[datetime]:

        s = (s or "").strip()
        if not s or s == "0":
            return None
        # FITS often has a trailing 'Z'
        s = s.replace("Z", "+00:00")
        try:
            dt = datetime.fromisoformat(s)
        except Exception:
            return None
        # Assume UTC if naive
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt

    def _night_date_str(self, date_obs: str, noon_to_noon: bool) -> str:
        """Return YYYY-MM-DD for the 'astronomical night' using local time."""
        dt = self._parse_date_obs(date_obs)
        if not dt:
            # Fallback: best effort from what's there
            return (date_obs.split("T")[0] if date_obs else "0")

        local_tz = datetime.now().astimezone().tzinfo
        ldt = dt.astimezone(local_tz)
        if noon_to_noon:
            # map 00:00–11:59 to previous calendar date
            ldt = ldt - timedelta(hours=12)
        return ldt.date().isoformat()

    def _build_tree(self):
        self.tree.blockSignals(True)
        self.tree.clear()

        # Group like Blink: Object → Filter → Exposure → file
        grouped: Dict[Tuple[str, str, float], List[dict]] = defaultdict(list)
        for rec in self.records:
            key = (rec["OBJECT"], rec["FILTER"], rec["EXPOSURE"])
            grouped[key].append(rec)

        by_obj: Dict[str, Dict[str, Dict[float, List[dict]]]] = defaultdict(lambda: defaultdict(dict))
        for (obj, filt, exp), lst in grouped.items():
            by_obj[obj].setdefault(filt, {})
            by_obj[obj][filt][exp] = lst

        for obj in sorted(by_obj, key=str.lower):
            obj_item = QTreeWidgetItem([f"Object: {obj}"])
            obj_item.setFlags(obj_item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
            obj_item.setCheckState(0, Qt.CheckState.Checked)
            self.tree.addTopLevelItem(obj_item)
            obj_item.setExpanded(True)

            for filt in sorted(by_obj[obj], key=str.lower):
                filt_item = QTreeWidgetItem([f"Filter: {filt}"])
                filt_item.setFlags(filt_item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                filt_item.setCheckState(0, Qt.CheckState.Checked)
                obj_item.addChild(filt_item)
                filt_item.setExpanded(True)

                for exp in sorted(by_obj[obj][filt].keys(), key=lambda e: str(e)):
                    exp_item = QTreeWidgetItem([f"Exposure: {exp}"])
                    exp_item.setData(0, Qt.ItemDataRole.UserRole, float(exp))
                    exp_item.setFlags(exp_item.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                    exp_item.setCheckState(0, Qt.CheckState.Checked)
                    filt_item.addChild(exp_item)
                    for rec in by_obj[obj][filt][exp]:
                        leaf = QTreeWidgetItem([rec["NAME"]])
                        leaf.setData(0, Qt.ItemDataRole.UserRole, rec["PATH"])
                        leaf.setFlags(leaf.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                        leaf.setCheckState(0, Qt.CheckState.Checked)
                        exp_item.addChild(leaf)

        self.tree.blockSignals(False)

        # default-fit the column to its text, keep it resizable,
        # and ensure h-scroll appears when the width exceeds the viewport
        self.tree.header().setStretchLastSection(False)
        self.tree.resizeColumnToContents(0)
        self.tree.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.tree.setHorizontalScrollMode(QAbstractItemView.ScrollMode.ScrollPerPixel)
        self.tree.setTextElideMode(Qt.TextElideMode.ElideNone)

    def _has_gain(self, v) -> bool:
        s = str(v).strip()
        if not s:
            return False
        try:
            return float(s) > 0.0
        except Exception:
            return False

    def _on_tree_item_changed(self, item: QTreeWidgetItem, _col: int):
        state = item.checkState(0)
        for i in range(item.childCount()):
            ch = item.child(i)
            ch.setCheckState(0, state)
        self._recompute()

    # ---------------- Aggregation ----------------
    def _included_paths(self) -> set:
        paths = set()
        def recurse(node: QTreeWidgetItem):
            if node.childCount() == 0:
                if node.checkState(0) == Qt.CheckState.Checked:
                    p = node.data(0, Qt.ItemDataRole.UserRole)
                    if isinstance(p, str):
                        paths.add(p)
                return
            for i in range(node.childCount()):
                recurse(node.child(i))
        root = self.tree.invisibleRootItem()
        for i in range(root.childCount()):
            recurse(root.child(i))
        return paths

    def _fallback(self, header_val: str, global_val: str) -> str:
        """Use global_val if header_val is empty/'0'/'0.0' and global_val is non-empty."""
        hv = (header_val or "").strip()
        gv = (global_val or "").strip()
        if hv in ("", "0", "0.0") and gv != "":
            return gv
        return hv or "0"

    def _recompute(self):
        self._save_defaults()
        noon_to_noon = self.noon_cb.isChecked()

        selected = self._included_paths()
        if not selected:
            self.rows = []
            self._refresh_table()
            self._refresh_csv_text()
            return

        agg = defaultdict(lambda: {
            'date': '0', 'filter': '0', 'number': 0, 'duration': 0, 'gain': '0', 'iso': '0',
            'binning': '0', 'sensorCooling': 0, 'fNumber': '0', 'darks': '0', 'flats': '0',
            'flatDarks': '0', 'bias': '0', 'bortle': '0', 'meanSqm': '0', 'meanFwhm': '0',
            'temperature_sum': 0.0, 'temp_count': 0
        })

        # globals
        fnum = self.fnum_edit.text().strip() or "0"
        g_darks = self.darks_edit.text().strip()
        g_flats = self.flats_edit.text().strip()
        g_flatdarks = self.flatdarks_edit.text().strip()
        g_bias = self.bias_edit.text().strip()
        g_bortle = self.bortle_edit.text().strip()
        g_sqm = self.mean_sqm_edit.text().strip()
        g_fwhm = self.mean_fwhm_edit.text().strip()

        for rec in self.records:
            if rec["PATH"] not in selected:
                continue

            date = self._night_date_str(rec.get("DATEOBS",""), noon_to_noon)
            filt_name = rec["FILTER"] or "0"
            filt_id = self._filter_map.get(filt_name, filt_name)  # fallback to name if not mapped
            exposure = rec["EXPOSURE"] or 0.0
            key = (date, str(filt_id), float(exposure))

            item = agg[key]
            item['date'] = date
            item['filter'] = str(filt_id)
            item['duration'] = exposure
            item['gain'] = rec["GAIN"]
            item['iso'] = rec["ISO"]
            item['binning'] = rec["BINNING"]
            item['sensorCooling'] = int(round(rec["CCD_TEMP"])) if rec["CCD_TEMP"] else 0
            item['fNumber'] = fnum

            # per your request: use global text when headers are missing/zero
            item['darks'] = self._fallback(rec["DARK"], g_darks)
            item['flats'] = self._fallback(rec["FLAT"], g_flats)
            item['flatDarks'] = self._fallback(rec["FLATDARK"], g_flatdarks)
            item['bias'] = self._fallback(rec["BIAS"], g_bias)
            item['bortle'] = self._fallback(rec["BORTLE"], g_bortle)
            item['meanSqm'] = self._fallback(rec["MEAN_SQM"], g_sqm)
            item['meanFwhm'] = self._fallback(rec["MEAN_FWHM"], g_fwhm)

            # temperature average from FOCTEMP
            if rec["FOCTEMP"]:
                item['temperature_sum'] += float(rec["FOCTEMP"])
                item['temp_count'] += 1
            item['number'] += 1

        out = []
        for (_date, _fid, _exp), v in agg.items():
            temp = int(round(v['temperature_sum'] / v['temp_count'])) if v['temp_count'] > 0 else 0
            row = {
                'date': v['date'], 'filter': v['filter'], 'number': v['number'],
                'duration': v['duration'], 'gain': v['gain'], 'iso': v['iso'],
                'binning': v['binning'], 'sensorCooling': v['sensorCooling'], 'fNumber': v['fNumber'],
                'darks': v['darks'], 'flats': v['flats'], 'flatDarks': v['flatDarks'],
                'bias': v['bias'], 'bortle': v['bortle'], 'meanSqm': v['meanSqm'],
                'meanFwhm': v['meanFwhm'], 'temperature': temp
            }

            # NEW: if gain is present/positive, blank ISO so it won’t interfere
            if self._has_gain(row['gain']):
                row['iso'] = ""

            out.append(row)

        out.sort(key=lambda r: (r['date'], r['filter'], float(r['duration'])))
        self.rows = out
        self._refresh_table()
        self._refresh_csv_text()

    def _refresh_table(self):
        cols = ['date','filter','number','duration','gain','iso','binning','sensorCooling',
                'fNumber','darks','flats','flatDarks','bias','bortle','meanSqm','meanFwhm','temperature']
        self.table.setRowCount(len(self.rows))
        self.table.setColumnCount(len(cols))
        self.table.setHorizontalHeaderLabels(cols)

        for r, row in enumerate(self.rows):
            for c, key in enumerate(cols):
                item = QTableWidgetItem(str(row.get(key, "")))
                if key == "filter" and not str(row.get(key, "")).isdigit():
                    item.setForeground(Qt.GlobalColor.red)
                self.table.setItem(r, c, item)

        # default-fit to contents, but keep columns draggable afterward
        self.table.resizeColumnsToContents()


    # ---------------- Export ----------------
    def _rows_to_csv_str(self) -> str:
        base_fields = ['date','filter','number','duration','gain','iso','binning',
                    'sensorCooling','fNumber','darks','flats','flatDarks','bias',
                    'bortle','meanSqm','meanFwhm','temperature']

        # If ANY row has a numeric gain, remove ISO column entirely.
        drop_iso = any(self._has_gain(r.get('gain', '')) for r in (self.rows or []))
        fieldnames = [f for f in base_fields if f != 'iso'] if drop_iso else base_fields

        buf = io.StringIO()
        writer = csv.DictWriter(buf, fieldnames=fieldnames, extrasaction='ignore')
        writer.writeheader()
        writer.writerows(self.rows or [])
        return buf.getvalue()

    def _refresh_csv_text(self):
        self.csv_view.setPlainText(self._rows_to_csv_str())

    def _copy_csv_to_clipboard(self):
        txt = self._rows_to_csv_str()
        if not txt.strip():
            QMessageBox.information(self, "Nothing to copy", "There is no CSV content yet.")
            return
        QGuiApplication.clipboard().setText(txt)
        QMessageBox.information(self, "Copied", "CSV copied to clipboard.")

class BatchRenamerDialog(QDialog):
    """
    Batch rename files using a template like:
      LIGHT_{FILTER}_{EXPOSURE:.0f}s_{DATE-OBS:%Y%m%d}_{#03}.{ext}

    Supports:
      - Any FITS keyword in braces: {FILTER}, {EXPOSURE}, {OBJECT}, …
      - Optional format spec: {EXPOSURE:.1f}, {DATE-OBS:%Y%m%d}
      - Counter: {#} or {#03} (zero-padded width)
      - Extension placeholder: {ext} (original extension, no dot)
    """


    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Batch Rename from FITS")
        self.settings = QSettings()
        self.files: list[str] = []
        self.headers: dict[str, fits.Header] = {}
        self.union_keys: list[str] = []
        # Make sure the dialog has a system menu + title so min/max can appear
        def _wflag(name):
            try:
                # PyQt6
                return getattr(Qt.WindowType, name)
            except AttributeError:
                # PyQt5
                return getattr(Qt, name)

        self.setWindowFlag(_wflag("WindowSystemMenuHint"), True)
        self.setWindowFlag(_wflag("WindowTitleHint"), True)
        self.setWindowFlag(_wflag("WindowMinMaxButtonsHint"), True)
        self.setWindowFlag(_wflag("WindowContextHelpButtonHint"), False)
        self.setSizeGripEnabled(True)  
        self._build_ui()
        self._load_settings()

    # ---------- UI ----------
    def _build_ui(self):
        root = QVBoxLayout(self)

        # Top: source and destination
        io_row = QHBoxLayout()
        self.src_edit = QLineEdit(self)
        self.src_edit.setPlaceholderText("Select a folder or add files…")
        btn_scan = QPushButton("Scan Folder…", self); btn_scan.clicked.connect(self._scan_folder)
        btn_add = QPushButton("Add Files…", self); btn_add.clicked.connect(self._add_files)
        io_row.addWidget(QLabel("Source:"))
        io_row.addWidget(self.src_edit, 1)
        io_row.addWidget(btn_scan)
        io_row.addWidget(btn_add)

        self.dest_edit = QLineEdit(self)
        self.dest_edit.setPlaceholderText("(optional) Rename into this folder; leave empty to rename in place")
        btn_dest = QPushButton("Browse…", self); btn_dest.clicked.connect(self._pick_dest)
        io_row2 = QHBoxLayout()
        io_row2.addWidget(QLabel("Destination:"))
        io_row2.addWidget(self.dest_edit, 1)
        io_row2.addWidget(btn_dest)

        root.addLayout(io_row); root.addLayout(io_row2)

        # Middle: template & options
        pat_box = QGroupBox("Filename pattern")
        pat_lay = QHBoxLayout(pat_box)

        self.pattern_edit = QLineEdit(self)
        self.pattern_edit.setPlaceholderText("e.g. LIGHT_{FILTER}_{EXPOSURE:.0f}s_{DATE-OBS:%Y%m%d}_{#03}.{ext}")
        self.pattern_edit.textChanged.connect(self._refresh_preview)

        self.lower_cb = QCheckBox("lowercase", self);     self.lower_cb.toggled.connect(self._refresh_preview)
        self.slug_cb  = QCheckBox("spaces→_", self);      self.slug_cb.toggled.connect(self._refresh_preview)
        self.keep_ext_cb = QCheckBox("append .{ext} if missing", self); self.keep_ext_cb.setChecked(True)
        self.index_start = QSpinBox(self); self.index_start.setRange(0, 999999); self.index_start.setValue(1)
        self.index_start.valueChanged.connect(self._refresh_preview)

        self.token_combo = QComboBox(self)
        self.token_combo.setSizeAdjustPolicy(QComboBox.SizeAdjustPolicy.AdjustToContents)
        self.token_combo.setMinimumContentsLength(12)
        self.token_combo.setEditable(False)
        self.token_combo.setToolTip("Insert token")
        self.token_combo.activated.connect(
                lambda idx: self._insert_token(self.token_combo.itemText(idx))
            )

        insert_btn = QPushButton("Insert", self)
        insert_btn.clicked.connect(lambda: self._insert_token(self.token_combo.currentText()))

        pat_lay.addWidget(QLabel("Template:")); pat_lay.addWidget(self.pattern_edit, 1)
        pat_lay.addWidget(self.token_combo); pat_lay.addWidget(insert_btn)
        pat_lay.addWidget(self.lower_cb); pat_lay.addWidget(self.slug_cb)
        pat_lay.addWidget(QLabel("Index start:")); pat_lay.addWidget(self.index_start)
        pat_lay.addWidget(self.keep_ext_cb)

        root.addWidget(pat_box)

        # Splitter: keys list | table
        split = QSplitter(Qt.Orientation.Horizontal, self)

        # Keys list
        left = QWidget(self); lyt = QVBoxLayout(left)
        left.setFixedWidth(180)  # pick a width you like
        self.keys_list = QListWidget(self)
        self.keys_list.itemDoubleClicked.connect(self._insert_key_from_list)
        lyt.addWidget(QLabel("Available FITS keywords (double-click to insert):"))
        lyt.addWidget(self.keys_list, 1)
  
        split.addWidget(left)

        # Table
        right = QWidget(self); rlyt = QVBoxLayout(right)
        self.table = QTableWidget(self); self.table.setColumnCount(4)
        self.table.setHorizontalHeaderLabels(["Old path", "→", "New name", "Status"])
        self.table.horizontalHeader().setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        self.table.horizontalHeader().setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        self.table.horizontalHeader().setSectionResizeMode(2, QHeaderView.ResizeMode.Stretch)
        self.table.horizontalHeader().setSectionResizeMode(3, QHeaderView.ResizeMode.ResizeToContents)
        self.table.setSelectionBehavior(QAbstractItemView.SelectionBehavior.SelectRows)
        self.table.setEditTriggers(QAbstractItemView.EditTrigger.NoEditTriggers)


        # Ellipsize long cell text in the middle (e.g., C:\...\filename.fits)
        try:
            self.table.setTextElideMode(Qt.TextElideMode.ElideMiddle)  # PyQt6
        except AttributeError:
            self.table.setTextElideMode(Qt.ElideMiddle)                # PyQt5        
        rlyt.addWidget(QLabel("Preview"))
        rlyt.addWidget(self.table, 1)
        split.addWidget(right)
        split.setSizes([250, 700])

        root.addWidget(split, 1)
        split.setStretchFactor(0, 0)
        split.setStretchFactor(1, 1)
        split.setCollapsible(0, False)  


        # Buttons
        btns = QDialogButtonBox(self)
        self.btn_preview = btns.addButton("Preview", QDialogButtonBox.ButtonRole.ActionRole)
        self.btn_rename  = btns.addButton("Rename", QDialogButtonBox.ButtonRole.AcceptRole)
        self.btn_close   = btns.addButton(QDialogButtonBox.StandardButton.Close)
        self.btn_preview.clicked.connect(self._refresh_preview)
        self.btn_rename.clicked.connect(self._do_rename)
        self.btn_close.clicked.connect(self.close)
        root.addWidget(btns)

        self._populate_token_keywords()

    # ---------- settings ----------
    def _load_settings(self):
        self.settings.beginGroup("batchrename")
        self.src_edit.setText(self.settings.value("last_dir", "", type=str) or "")
        self.dest_edit.setText(self.settings.value("dest_dir", "", type=str) or "")
        self.pattern_edit.setText(self.settings.value("pattern",
            "LIGHT_{FILTER}_{EXPOSURE:.0f}s_{DATE-OBS:%Y%m%d}_{#03}.{ext}", type=str))
        self.lower_cb.setChecked(self.settings.value("lower", False, type=bool))
        self.slug_cb.setChecked(self.settings.value("slug", True, type=bool))
        self.keep_ext_cb.setChecked(self.settings.value("keep_ext", True, type=bool))
        self.index_start.setValue(self.settings.value("index_start", 1, type=int))
        self.settings.endGroup()
        if self.src_edit.text():
            self._scan_existing(self.src_edit.text())

    def _save_settings(self):
        self.settings.beginGroup("batchrename")
        self.settings.setValue("last_dir", self.src_edit.text().strip())
        self.settings.setValue("dest_dir", self.dest_edit.text().strip())
        self.settings.setValue("pattern", self.pattern_edit.text().strip())
        self.settings.setValue("lower", self.lower_cb.isChecked())
        self.settings.setValue("slug", self.slug_cb.isChecked())
        self.settings.setValue("keep_ext", self.keep_ext_cb.isChecked())
        self.settings.setValue("index_start", self.index_start.value())
        self.settings.endGroup()

    # ---------- file loading ----------
    def _scan_folder(self):
        start = self.src_edit.text().strip()
        path = QFileDialog.getExistingDirectory(self, "Select Folder", start or "")
        if not path: return
        self.src_edit.setText(path)
        self._scan_existing(path)
        self._save_settings()


    def _scan_existing(self, path: str):
        paths = []
        for root, _, files in os.walk(path):
            for f in files:
                if f.lower().endswith((".fits", ".fit", ".fts", ".fz")):
                    paths.append(os.path.join(root, f))
        paths.sort()
        self._set_files(paths)


    def _add_files(self):
        start = self.src_edit.text().strip() or ""
        files, _ = QFileDialog.getOpenFileNames(
            self, "Add FITS files", start, "FITS files (*.fit *.fits *.fts *.fz);;All files (*)"
        )
        if not files: return
        new = sorted(set(self.files) | set(files))
        self._set_files(new)
        if not self.src_edit.text() and files:
            self.src_edit.setText(os.path.dirname(files[0]))
        self._save_settings()


    def _set_files(self, paths: List[str]):
        self.files = paths
        self.headers.clear()
        union = set()
        ok, bad = 0, 0
        for p in self.files:
            try:
                with fits.open(p, memmap=False) as hdul:
                    h = hdul[0].header
                self.headers[p] = h
                union.update([str(k) for k in h.keys()])
                ok += 1
            except Exception:
                bad += 1
        self.union_keys = sorted(union)
        self._rebuild_keys_list()
        self._fill_table_rows()
        self._refresh_preview()


    def _pick_dest(self):
        start = self.dest_edit.text().strip() or self.src_edit.text().strip()
        d = QFileDialog.getExistingDirectory(self, "Choose Destination Folder", start or "")
        if not d: return
        self.dest_edit.setText(d)
        self._save_settings()

    def _autosize_combo(self, combo: QComboBox, base_padding: int = 36):
        """
        Resize a QComboBox so its line edit shows the longest item without clipping,
        and widen the popup to match. Call after adding items.
        """
        if combo.count() == 0:
            combo.setMinimumWidth(160)
            return

        fm = QFontMetrics(combo.font())
        maxw = 0
        for i in range(combo.count()):
            w = fm.horizontalAdvance(combo.itemText(i))
            if not combo.itemIcon(i).isNull():
                w += combo.iconSize().width() + 8
            if w > maxw:
                maxw = w

        # + padding for left/right margins + arrow
        width = maxw + base_padding
        combo.setMinimumWidth(width)
        # also widen the popup list
        if combo.view() is not None:
            combo.view().setMinimumWidth(width)
        combo.updateGeometry()

    # ---------- keys & template insertion ----------
    def _rebuild_keys_list(self):
        self.keys_list.clear()
        for k in self.union_keys:
            self.keys_list.addItem(QListWidgetItem(k))
        # (Re)build the token combo based on self.union_keys
        self._populate_token_keywords()


    def _insert_key_from_list(self, item: QListWidgetItem):
        if not item: return
        self._insert_text("{"+item.text()+"}")

    def _insert_token(self, token: str):
        # token is like "{FILTER}" or "{#03}"
        if not token: return
        self._insert_text(token)

    def _populate_token_keywords(self):
        """
        Rebuild the token dropdown from current union_keys.
        Always includes special tokens first.
        """
        tokens = ["{#}", "{#03}", "{ext}"] + [f"{{{k}}}" for k in self.union_keys]

        self.token_combo.blockSignals(True)
        self.token_combo.clear()
        # sort for stability; keeps the specials at top if you prefer not to sort them
        self.token_combo.addItems(sorted(tokens, key=str.lower))
        self.token_combo.blockSignals(False)

        # Let layout settle, then autosize the combo and its popup
        QTimer.singleShot(0, lambda: self._autosize_combo(self.token_combo))

    def _insert_text(self, text: str):
        e = self.pattern_edit
        pos = e.cursorPosition()
        s = e.text()
        e.setText(s[:pos] + text + s[pos:])
        e.setCursorPosition(pos + len(text))
        self._refresh_preview()

    # ---------- preview/rename ----------
    def _fill_table_rows(self):
        self.table.setRowCount(len(self.files))
        for r, p in enumerate(self.files):
            self.table.setItem(r, 0, QTableWidgetItem(p))
            self.table.setItem(r, 1, QTableWidgetItem("→"))
            self.table.setItem(r, 2, QTableWidgetItem(""))
            self.table.setItem(r, 3, QTableWidgetItem(""))

    def _refresh_preview(self):
        pat = self.pattern_edit.text().strip()
        if not pat: return
        dest = (self.dest_edit.text().strip() or None)
        start_idx = self.index_start.value()
        lower = self.lower_cb.isChecked()
        slug  = self.slug_cb.isChecked()
        keep_ext = self.keep_ext_cb.isChecked()

        # generate names
        names = []
        for i, p in enumerate(self.files):
            hdr = self.headers.get(p, fits.Header())
            base = self._render_pattern(pat, hdr, i, start_idx, p)
            if keep_ext and "{ext}" not in pat:
                # append original ext if user forgot
                ext = os.path.splitext(p)[1]
                if ext:
                    base = f"{base}{ext}"
            if lower: base = base.lower()
            if slug:  base = self._slugify(base)
            # target path
            folder = dest if dest else os.path.dirname(p)
            target = os.path.join(folder, base)
            names.append(target)

        # collisions
        seen = defaultdict(int)
        for t in names: seen[t] += 1

        # fill table
        for r, p in enumerate(self.files):
            newp = names[r]
            self._set_table_preview_row(r, p, newp, seen[newp])

    def _set_table_preview_row(self, r: int, old: str, new: str, count: int):
        self.table.item(r, 0).setText(old)
        self.table.item(r, 2).setText(new)
        status = ""
        conflict = (count > 1)
        if conflict: status = "name collision"
        elif os.path.exists(new): status = "will overwrite"
        else: status = "ok"
        it = QTableWidgetItem(status)
        if conflict or status == "will overwrite":
            it.setForeground(Qt.GlobalColor.red)
        self.table.setItem(r, 3, it)
        # after setting items
        it_old = self.table.item(r, 0)
        it_new = self.table.item(r, 2)
        if it_old:
            it_old.setToolTip(old)   # full original path
        if it_new:
            it_new.setToolTip(new)   # full new path        



    def _do_rename(self):
        # check collisions first
        n = self.table.rowCount()
        targets = [self.table.item(r, 2).text() for r in range(n)]
        counts = defaultdict(int)
        for t in targets: counts[t] += 1
        collisions = [t for t,c in counts.items() if c > 1]
        if collisions:
            QMessageBox.warning(self, "Collisions",
                "Two or more files would map to the same name. Adjust your pattern.")
            return

        # go
        failures = []
        for r in range(n):
            oldp = self.table.item(r, 0).text()
            newp = self.table.item(r, 2).text()
            if oldp == newp:  # nothing to do
                continue
            os.makedirs(os.path.dirname(newp), exist_ok=True)
            try:
                shutil.move(oldp, newp)
                self.table.item(r, 3).setText("renamed")
            except Exception as e:
                self.table.item(r, 3).setText(f"ERROR: {e}")
                self.table.item(r, 3).setForeground(Qt.GlobalColor.red)
                failures.append((oldp, str(e)))

        if failures:
            QMessageBox.warning(self, "Done with errors",
                f"Some files could not be renamed ({len(failures)} errors).")
        else:
            QMessageBox.information(self, "Done", "All files renamed.")
        self._save_settings()
        # rescan to refresh paths if we renamed in place
        src = self.src_edit.text().strip()
        if src and not self.dest_edit.text().strip():
            self._scan_existing(src)

    # ---------- helpers ----------
    @staticmethod
    def _slugify(s: str) -> str:
        # replace spaces with underscores, keep alnum, dash, underscore, dot
        s = s.replace(" ", "_")
        return re.sub(r"[^A-Za-z0-9._-]+", "", s)

    def _render_pattern(self, pat: str, hdr: fits.Header, i: int, start_idx: int, file_path: str) -> str:
        import re
        def apply_filters(text: str, filters: list[str]) -> str:
            out = str(text)
            for f in filters:
                f = f.strip()
                if f.startswith("re:"):
                    pattern = f[3:]
                    m = re.search(pattern, out)
                    if not m:
                        out = ""  # no match => empty (or keep original if you prefer)
                    else:
                        if m.lastindex:           # has capture groups
                            out = m.group(1)      # first capturing group
                        else:
                            out = m.group(0)      # whole match
                elif f == "lower":
                    out = out.lower()
                elif f == "upper":
                    out = out.upper()
                elif f.startswith("slice:"):
                    # usage: |slice:start:stop   (like Python slicing)
                    try:
                        _, a, b = f.split(":", 2)
                        a = int(a) if a else None
                        b = int(b) if b else None
                        out = out[a:b]
                    except Exception:
                        pass

                elif f == "strip":
                    out = out.strip()                    
                # you can add more filters like 'strip', 'title', 'slice:a:b', etc.
            return out

        def _split_top_level_pipes(s: str) -> List[str]:
            parts, buf = [], []
            depth = 0
            esc = False
            for ch in s:
                if esc:
                    buf.append(ch); esc = False; continue
                if ch == '\\':
                    buf.append(ch); esc = True; continue
                if ch in '([{':
                    depth += 1
                elif ch in ')]}':
                    depth = max(0, depth-1)
                if ch == '|' and depth == 0:
                    parts.append(''.join(buf)); buf = []
                else:
                    buf.append(ch)
            parts.append(''.join(buf))
            return parts

        def repl(m):
            body = m.group(1)  # e.g. "INSTRUME|re:(\d{4}\S{2})" or "DATE-OBS:%Y%m%d|lower"
            parts = _split_top_level_pipes(body)
            key_fmt = parts[0]
            filters = parts[1:] if len(parts) > 1 else []

            # counter?
            if key_fmt.startswith("#"):
                w = key_fmt[1:]
                try:
                    pad = int(w) if w else 0
                except Exception:
                    pad = 0
                num = i + start_idx
                return f"{num:0{pad}d}" if pad else str(num)

            # extension?
            if key_fmt.lower() == "ext":
                ext = os.path.splitext(file_path)[1]
                return ext.lstrip(".")

            # key[:fmt]
            if ":" in key_fmt:
                key, fmt = key_fmt.split(":", 1)
            else:
                key, fmt = key_fmt, ""
            key_up = key.upper()
            val = hdr.get(key_up, "")
            if val is None:
                val = ""

            # DATE-like with datetime fmt
            if fmt and key_up in ("DATE-OBS", "DATE"):
                s = str(val).strip().replace("Z", "+00:00")
                try:
                    dt = datetime.fromisoformat(s)
                    if dt.tzinfo is None:
                        dt = dt.replace(tzinfo=timezone.utc)
                    out = dt.strftime(fmt)
                except Exception:
                    out = str(val)
                return apply_filters(out, filters)

            # TIME-only keys with time fmt
            if fmt and key_up in ("TIME-OBS", "UTSTART", "UTC-START"):
                s = str(val).strip()
                try:
                    tt = datetime.strptime(s, "%H:%M:%S").time() if s.count(":") == 2 else datetime.strptime(s, "%H:%M").time()
                    out = tt.strftime(fmt)
                except Exception:
                    # try fromisoformat for fractional seconds
                    try:
                        tt = datetime.fromisoformat(f"1970-01-01T{s}").time()
                        out = tt.strftime(fmt)
                    except Exception:
                        out = str(val)
                return apply_filters(out, filters)

            # numeric with fmt (e.g. .1f)
            if fmt:
                try:
                    out = format(float(val), fmt)
                    return apply_filters(out, filters)
                except Exception:
                    pass

            # default: string value + filters
            return apply_filters(str(val), filters)

        token_re = re.compile(r"\{((?:[^{}]|\{[^{}]*\})+)\}")
        return token_re.sub(repl, pat)


class HistoryExplorerDialog(QDialog):
    def __init__(self, image_manager, slot, parent=None):
        super().__init__(parent)
        self.setWindowTitle(f"History Explorer - Slot {slot}")
        self.image_manager = image_manager
        self.slot = slot

        self.setMinimumSize(600, 400)
        layout = QVBoxLayout(self)

        self.history_list = QListWidget()
        undo_stack = self.image_manager._undo_stacks.get(slot, [])
        self.history_images = []

        # Step history based on undo_stack
        for i in range(len(undo_stack)):
            img, meta = undo_stack[i][:2]

            # Step name is derived from the *next* entry in the stack
            if i == 0:
                label = "1. Original Image"
            else:
                if len(undo_stack[i - 1]) == 3:
                    label = f"{i + 1}. {undo_stack[i - 1][2]}"
                else:
                    label = f"{i + 1}. Unnamed"

            self.history_list.addItem(label)
            self.history_images.append((img, meta))

        # Add the current image as the final step
        current_img = image_manager._images.get(slot)
        current_meta = image_manager._metadata.get(slot, {})
        final_step_name = (
            undo_stack[-1][2] if len(undo_stack) > 0 and len(undo_stack[-1]) == 3 else "Current Image"
        )
        self.history_list.addItem(f"{len(undo_stack)+1}. {final_step_name} (Current)")
        self.history_images.append((current_img, current_meta))

        # Connect interaction
        self.history_list.itemDoubleClicked.connect(self.preview_selected_history_step)
        layout.addWidget(self.history_list)

        # Close button
        self.close_button = QPushButton("Close")
        self.close_button.clicked.connect(self.close)
        layout.addWidget(self.close_button)

    def preview_selected_history_step(self, item):
        row = self.history_list.row(item)

        if 0 <= row < len(self.history_images):
            img, meta = self.history_images[row]
            if img is not None:
                preview = HistoryImagePreview(img, meta, self.slot, image_manager=self.image_manager)
                preview.setWindowTitle(item.text())
                preview.show()
                return

        QMessageBox.warning(self, "Preview Failed", "Could not retrieve image for this step.")

class HistoryImagePreview(QWidget):
    def __init__(self, image_data, metadata, slot, image_manager=None, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        self.setWindowTitle("History Preview")
        self.image_data = image_data
        self.image_manager = image_manager
        self.metadata = metadata
        self.slot = slot
        self.parent_ref = parent
        self.zoom_factor = 1.0
        self.is_autostretched = False
        self.stretched_image_data = None
        self._panning = False
        self._pan_start = QPointF()
        

        # QLabel setup
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.viewport().installEventFilter(self)

        # Zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)
        self.zoom_slider.setValue(100)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        zoom_in = QPushButton("Zoom In")
        zoom_in.clicked.connect(lambda: self.adjust_zoom(10))
        zoom_out = QPushButton("Zoom Out")
        zoom_out.clicked.connect(lambda: self.adjust_zoom(-10))
        fit = QPushButton("Fit to Preview")
        fit.clicked.connect(self.fit_to_preview)

        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.clicked.connect(self.apply_autostretch)

        compare_btn = QPushButton("Compare to Current")
        compare_btn.clicked.connect(self.launch_comparison_slider)

        # Restore Button
        restore_btn = QPushButton("Restore This Version")
        restore_btn.clicked.connect(self.restore_version)

        # Layout
        zoom_layout = QHBoxLayout()
        zoom_layout.addWidget(zoom_out)
        zoom_layout.addWidget(self.zoom_slider)
        zoom_layout.addWidget(zoom_in)
        zoom_layout.addWidget(fit)
        zoom_layout.addWidget(self.autostretch_button)

        main_layout = QVBoxLayout(self)
        main_layout.addWidget(self.scroll_area)
        main_layout.addLayout(zoom_layout)
        main_layout.addWidget(compare_btn)
        main_layout.addWidget(restore_btn)
        self.setLayout(main_layout)

        self.update_image_display()

    def eventFilter(self, source, event):
        if source == self.scroll_area.viewport():
            if (event.type() == QEvent.Type.Wheel and
                    event.modifiers() & Qt.KeyboardModifier.ControlModifier):
                # Ctrl + wheel for zooming
                step = 1.25 if event.angleDelta().y() > 0 else 0.8
                new_zoom = self.zoom_factor * step
                self.zoom_slider.setValue(
                    max(1, min(400, int(new_zoom * 100)))
                )
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseButtonPress and \
                    event.button() == Qt.MouseButton.LeftButton:
                # Start panning
                self._panning = True
                self._pan_start = event.position()
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseMove and self._panning:
                # Pan scrollbars
                delta = event.position() - self._pan_start
                hbar = self.scroll_area.horizontalScrollBar()
                vbar = self.scroll_area.verticalScrollBar()
                hbar.setValue(hbar.value() - int(delta.x()))
                vbar.setValue(vbar.value() - int(delta.y()))
                self._pan_start = event.position()
                event.accept()
                return True

            if event.type() == QEvent.Type.MouseButtonRelease and \
                    event.button() == Qt.MouseButton.LeftButton:
                # End panning
                self._panning = False
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                event.accept()
                return True

        return super().eventFilter(source, event)


    def launch_comparison_slider(self):
        """Open the before/after slider in its own pop‑up."""
        current_img = self.image_manager.image
        if current_img is None:
            QMessageBox.warning(self, "Unavailable",
                                "No current image available.")
            return

        slider_window = QWidget(self, Qt.WindowType.Window)
        slider_window.setWindowTitle("Compare with Current")
        slider_window.resize(900, 700)

        win_layout = QVBoxLayout(slider_window)

        # ---- the slider widget itself ----
        self.slider_widget = ComparisonSlider(self.image_data,
                                            current_img,
                                            slider_window)
        win_layout.addWidget(self.slider_widget)

        # ---- control‑bar (zoom + autostretch) ----
        ctrl_bar = QHBoxLayout()

        zoom_in_btn  = QPushButton("Zoom In")
        zoom_in_btn.clicked.connect(self.slider_widget.zoom_in)
        ctrl_bar.addWidget(zoom_in_btn)

        zoom_out_btn = QPushButton("Zoom Out")
        zoom_out_btn.clicked.connect(self.slider_widget.zoom_out)
        ctrl_bar.addWidget(zoom_out_btn)

        stretch_btn  = QPushButton("Toggle AutoStretch")
        stretch_btn.clicked.connect(self.slider_widget.toggle_autostretch)
        ctrl_bar.addWidget(stretch_btn)

        # (optional) add more buttons later – e.g. blink‑mode toggle
        # blink_btn = QPushButton("Toggle Blink")
        # blink_btn.clicked.connect(self.slider_widget.toggle_blink_mode)
        # ctrl_bar.addWidget(blink_btn)

        # push the buttons to the left and leave the rest empty
        ctrl_bar.addStretch(1)

        win_layout.addLayout(ctrl_bar)

        slider_window.show()


    def restore_version(self):
        """Push this image into the active slot via image manager."""
        if self.image_manager:
            self.image_manager.set_image(
                self.image_data.copy(),
                self.metadata.copy(),
                step_name="Restored from History"
            )
            self.close()
        else:
            QMessageBox.critical(self, "Error", "Parent does not have an image manager.")

    def stretch_image(self, image):
        target_median = 0.25
        if image.ndim == 2:
            return stretch_mono_image(image, target_median)
        elif image.ndim == 3:
            return stretch_color_image(image, target_median, linked=False)
        return image

    def apply_autostretch(self):
        self.is_autostretched = not self.is_autostretched
        if self.is_autostretched:
            self.stretched_image_data = self.stretch_image(self.image_data)
        self.update_image_display()

    def update_image_display(self):
        display_image = self.stretched_image_data if self.is_autostretched else self.image_data
        display_image = np.clip(display_image * 255, 0, 255).astype(np.uint8)

        if display_image.ndim == 2:
            h, w = display_image.shape
            qimg = QImage(display_image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            h, w, _ = display_image.shape
            qimg = QImage(display_image.data, w, h, w * 3, QImage.Format.Format_RGB888)

        pixmap = QPixmap.fromImage(qimg)
        scaled = pixmap.scaled(
            pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled)

    def on_zoom_changed(self, value):
        self.zoom_factor = value / 100.0
        self.update_image_display()

    def adjust_zoom(self, delta):
        self.zoom_slider.setValue(max(1, min(400, self.zoom_slider.value() + delta)))

    def fit_to_preview(self):
        if self.image_label.pixmap() is None:
            return
        available = self.scroll_area.viewport().size()
        pixmap = self.image_label.pixmap()
        if pixmap:
            factor = min(available.width() / pixmap.width(), available.height() / pixmap.height())
            self.zoom_factor = factor
            self.zoom_slider.setValue(int(factor * 100))
            self.update_image_display()

class ComparisonSlider(QWidget):
    def __init__(self, before_image: np.ndarray, after_image: np.ndarray, parent=None):
        super().__init__(parent)
        self.before_image = before_image
        self.after_image = after_image
        self.slider_position = 0.5
        self.zoom_factor = 1.0
        self.autostretch = False
        self.setMouseTracking(True)
        self.setMinimumSize(400, 300)

    def set_zoom_factor(self, zoom):
        self.zoom_factor = max(0.1, min(zoom, 5.0))  # Clamp zoom
        self.update()

    def zoom_in(self):
        self.set_zoom_factor(self.zoom_factor * 1.25)

    @announce_zoom
    def zoom_out(self):
        self.set_zoom_factor(self.zoom_factor / 1.25)

    def toggle_autostretch(self):
        self.autostretch = not self.autostretch
        self.update()

    def paintEvent(self, _ev):
        painter   = QPainter(self)
        W, H      = self.width(), self.height()

        before_q  = self.prepare_image(self.before_image)
        after_q   = self.prepare_image(self.after_image)

        # centre the zoomed image inside the widget
        ox = (W - before_q.width())  // 2
        oy = (H - before_q.height()) // 2

        divider_x = int(W * self.slider_position)

        # ---- LEFT half : BEFORE ------------------------------------
        painter.save()
        painter.setClipRect(0, 0, divider_x, H)
        painter.drawImage(ox, oy, before_q)
        painter.restore()

        # ---- RIGHT half : AFTER ------------------------------------
        painter.save()
        painter.setClipRect(divider_x, 0, W - divider_x, H)
        painter.drawImage(ox, oy, after_q)
        painter.restore()

        # ---- Divider line ------------------------------------------
        painter.setPen(Qt.GlobalColor.red)
        painter.drawLine(divider_x, 0, divider_x, H)

    def mousePressEvent(self, event):
        self.update_slider(event.position().x())

    def mouseMoveEvent(self, event):
        if event.buttons() & Qt.MouseButton.LeftButton:
            self.update_slider(event.position().x())

    def update_slider(self, x):
        self.slider_position = min(max(x / self.width(), 0.0), 1.0)
        self.update()

    def prepare_image(self, image):
        if self.autostretch:
            image = self.stretch_image(image)

        image = np.clip(image * 255, 0, 255).astype(np.uint8)

        if image.ndim == 2:
            h, w = image.shape
            qimg = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            h, w, _ = image.shape
            qimg = QImage(image.data, w, h, w * 3, QImage.Format.Format_RGB888)

        # Apply zoom and scale to widget size
        target_size = QSize(int(self.width() * self.zoom_factor), int(self.height() * self.zoom_factor))
        return qimg.scaled(target_size, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

    def stretch_image(self, image):
        p = np.percentile(image, 99.5)
        return np.clip(image / p, 0, 1)



class MaskManager(QObject):
    """
    Manages masks and tracks whether a mask is applied to the image.
    """
    mask_changed = pyqtSignal(int, np.ndarray)  # Signal to notify mask changes (slot, mask)
    applied_mask_changed = pyqtSignal(int, np.ndarray)  # Signal for applied mask updates

    def __init__(self, max_slots=5):
        super().__init__()
        self.max_slots = max_slots
        self._masks = {i: None for i in range(max_slots)}  # Store masks for each slot
        self.applied_mask_slot = None  # Slot from which the mask is applied
        self.applied_mask = None  # Currently applied mask (numpy array)

    def set_mask(self, slot, mask):
        """
        Sets the mask for a specific slot.
        """
        if 0 <= slot < self.max_slots:
            self._masks[slot] = mask
            self.mask_changed.emit(slot, mask)

    def get_mask(self, slot):
        """
        Retrieves the mask from a specific slot.
        """
        return self._masks.get(slot, None)

    def clear_applied_mask(self):
        """
        Clears the currently applied mask and emits an empty mask.
        """
        self.applied_mask_slot = None
        self.applied_mask = None

        # Emit an empty mask instead of None
        empty_mask = np.zeros((1, 1), dtype=np.uint8)  
        self.applied_mask_changed.emit(-1, empty_mask)  # Signal that no mask is applied

        print("Applied mask cleared.")



    def apply_mask_from_slot(self, slot):
        """
        Applies the mask from the specified slot.
        """
        if slot in self._masks and self._masks[slot] is not None:
            self.applied_mask_slot = slot
            self.applied_mask = self._masks[slot]
            self.applied_mask_changed.emit(slot, self.applied_mask)
            print(f"Mask from slot {slot} applied.")
        else:
            print(f"Mask from slot {slot} cannot be applied (empty).")

    def get_applied_mask(self):
        """
        Retrieves the currently applied mask.
        """
        return self.applied_mask

    def get_applied_mask_slot(self):
        """
        Retrieves the slot from which the currently applied mask originated.
        """
        return self.applied_mask_slot


class MaskSlotPreviewDialog(QDialog):
    """
    Dialog for displaying, zooming, inverting, and applying a mask from a specific slot with scroll bars.
    Automatically closes after saving the mask.
    """
    # Define a custom signal if needed (e.g., to notify the main window)
    mask_applied = pyqtSignal(int, np.ndarray)  # (slot, mask)

    def __init__(self, mask, slot, parent=None):
        super().__init__(parent)
        # If the parent has a 'mask_slot_names' dictionary, use it
        if parent is not None and hasattr(parent, 'mask_slot_names'):
            custom_name = parent.mask_slot_names.get(slot, f"Mask Slot {slot}")
        else:
            custom_name = f"Mask Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.mask = mask.copy()  # The mask to display (ensure a copy is made)
        self.slot = slot  # Mask slot number
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Store reference to the main window
        self.parent_window = parent

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)

        # Action buttons
        action_layout = QHBoxLayout()
        invert_button = QPushButton("Invert Mask")
        invert_button.clicked.connect(self.invert_mask)
        apply_button = QPushButton(f"Apply Mask from Slot {self.slot}")
        apply_button.clicked.connect(self.apply_mask)

        action_layout.addWidget(invert_button)
        action_layout.addWidget(apply_button)

        # Add action buttons to main layout
        main_layout.addLayout(action_layout)

        # Set the layout
        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods
    @announce_zoom
    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def invert_mask(self):
        """
        Inverts the current mask and updates the display and mask slot,
        while preserving the current zoom and scroll positions.
        """

        try:
            # Invert the mask (assuming the mask is normalized between 0 and 1)
            inverted_mask = 1.0 - self.mask
            print("Mask inversion performed.")
            
            # Update the internal mask and create a new pixmap
            self.mask = inverted_mask.copy()
            self.pixmap = self.convert_to_pixmap(self.mask)
            
            # Call update_image() to rescale and reposition the image, preserving zoom/scroll.
            self.update_image()
            print("Mask display updated with inverted mask while preserving zoom and scroll positions.")
            
            
        except Exception as e:
            QMessageBox.critical(self, "Inversion Failed", f"Failed to invert the mask:\n{e}")
            print(f"Failed to invert the mask: {e}")


    def apply_mask(self):
        """
        Applies the current mask to the parent through the MaskManager.
        Automatically closes the dialog after successful application.
        """
        if not self.parent_window or not hasattr(self.parent_window, "mask_manager"):
            QMessageBox.warning(self, "Error", "Unable to apply mask: Mask Manager not found.")
            return

        # Apply mask from the given slot using apply_mask_from_slot to emit the correct signal
        try:
            self.parent_window.mask_manager.set_mask(self.slot, self.mask)
            self.parent_window.mask_manager.apply_mask_from_slot(self.slot)
            QMessageBox.information(self, "Mask Applied", f"Mask from Slot {self.slot} has been applied successfully.")
            # Emit the custom signal if connected
            self.mask_applied.emit(self.slot, self.mask.copy())
            self.accept()  # Close the dialog
            print(f"Mask from Slot {self.slot} applied and dialog closed.")
        except Exception as e:
            QMessageBox.critical(self, "Application Failed", f"Failed to apply mask:\n{e}")
            print(f"Failed to apply mask from Slot {self.slot}: {e}")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            # Schedule fit_to_window to be called after the dialog is fully shown
            QTimer.singleShot(0, self.fit_to_window)
            self.fitted = True

class HandleItem(QGraphicsRectItem):
    SIZE = 8

    def __init__(self, role, parent_ellipse):
        # parent‐ellipse tells Qt that this item’s coords are local to the ellipse
        super().__init__(-self.SIZE/2, -self.SIZE/2, self.SIZE, self.SIZE, parent_ellipse)
        self.role = role
        self.parent_ellipse = parent_ellipse

        # just a red box
        self.setBrush(QColor(255, 0, 0))

        # we only want left‐button drags
        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton)
        # don’t let Qt move this item for us
        self.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIsMovable, False)
        self.setFlag(QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges, False)

        cursors = {
            'top':    Qt.CursorShape.SizeVerCursor,
            'bottom': Qt.CursorShape.SizeVerCursor,
            'left':   Qt.CursorShape.SizeHorCursor,
            'right':  Qt.CursorShape.SizeHorCursor,
            'rotate': Qt.CursorShape.OpenHandCursor
        }
        self.setCursor(cursors[role])

        # will hold last mouse‐pos during a drag
        self._lastScenePos = None

        self.setFlag(
            QGraphicsItem.GraphicsItemFlag.ItemIgnoresTransformations,
            True
        )

    def mousePressEvent(self, event):
        # record starting point in scene coords
        self._lastScenePos = event.scenePos()
        event.accept()

    def mouseMoveEvent(self, event):
        newScenePos = event.scenePos()
        dx = newScenePos.x() - self._lastScenePos.x()
        dy = newScenePos.y() - self._lastScenePos.y()

        # hand off the delta to the ellipse
        self.parent_ellipse.interactiveResize(self.role, dx, dy)

        # ellipse.itemChange + QTimer will re-position all handles for us
        self._lastScenePos = newScenePos
        event.accept()

    def mouseReleaseEvent(self, event):
        self._lastScenePos = None
        event.accept()

class InteractiveEllipseItem(QGraphicsEllipseItem):
    """Ellipse with draggable handles for resizing/rotation."""
    def __init__(self, rect):
        super().__init__(rect)
        self._resizing = False
        self.setTransformOriginPoint(self.rect().center())

        self.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges
        )
        self.handles = {
            role: HandleItem(role, self)
            for role in ('top','bottom','left','right','rotate')
        }
        self.updateHandles()

    def updateHandles(self):
        r = self.rect()
        cx, cy = r.center().x(), r.center().y()

        # temporarily disable handle->ellipse resize callbacks
        for h in self.handles.values():
            h.setFlag(QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges, False)

        # reposition them in *local* coords
        for role, h in self.handles.items():
            if role == 'top':
                scene_pt = self.mapToScene(QPointF(cx, r.top()))
            elif role == 'bottom':
                scene_pt = self.mapToScene(QPointF(cx, r.bottom()))
            elif role == 'left':
                scene_pt = self.mapToScene(QPointF(r.left(), cy))
            elif role == 'right':
                scene_pt = self.mapToScene(QPointF(r.right(), cy))
            else:
                scene_pt = self.mapToScene(QPointF(cx, r.top() - 20))

            local_pt = self.mapFromScene(scene_pt)
            h.setPos(local_pt)

        # re-enable resize callbacks
        for h in self.handles.values():
            h.setFlag(QGraphicsItem.GraphicsItemFlag.ItemSendsGeometryChanges, True)

    def itemChange(self, change, value):
        if change in (
            QGraphicsItem.GraphicsItemChange.ItemPositionChange,
            QGraphicsItem.GraphicsItemChange.ItemTransformChange,
            QGraphicsItem.GraphicsItemChange.ItemSelectedHasChanged,
        ):
            # schedule handle reposition once Qt is done
            QTimer.singleShot(0, self.updateHandles)
        return super().itemChange(change, value)

    def interactiveResize(self, role, dx, dy):
        if self._resizing:
            return        
        r = self.rect()
        if role == 'top':
            r.setTop(r.top() + dy)
        elif role == 'bottom':
            r.setBottom(r.bottom() + dy)
        elif role == 'left':
            r.setLeft(r.left() + dx)
        elif role == 'right':
            r.setRight(r.right() + dx)
        elif role == 'rotate':
            new_angle = self.rotation() + dx
            self.setRotation(new_angle)
            return
        self._resizing = True
        self.prepareGeometryChange()
        self.setRect(r)
        self.updateHandles()
        self._resizing = False        
        # (no updateHandles() here — Qt will call itemChange → updateHandles)

class MaskCanvas(QGraphicsView):
    """Canvas supporting freehand polygons and interactive ellipses."""
    def __init__(self, image, parent=None):
        super().__init__(parent)
        self.scene = QGraphicsScene(self)
        self.setScene(self.scene)
        self.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.temp_ellipse = None
        self.ellipse_origin = None
        pix = self._to_pixmap(image)
        self.bg_item = QGraphicsPixmapItem(pix)
        self.scene.addItem(self.bg_item)

        self.mode = 'polygon'
        self.temp_path = None
        self.poly_points = []
        self.shapes = []

    def set_mode(self, mode):
        assert mode in ('polygon','ellipse','select')
        self.mode = mode

    def mousePressEvent(self, ev):
        pt = self.mapToScene(ev.pos())

        # 1) if you're in ellipse‐mode but clicked on an existing ellipse or handle, let Qt
        #    handle selection/moving instead of starting a new rubber‐band
        if self.mode == 'ellipse' and ev.button() == Qt.MouseButton.LeftButton:
            clicked_items = self.items(ev.pos())
            for it in clicked_items:
                if isinstance(it, (InteractiveEllipseItem, HandleItem)):
                    # pass through to default QGraphicsView logic
                    super().mousePressEvent(ev)
                    return

        # 2) polygon‐mode start
        if self.mode == 'polygon' and ev.button() == Qt.MouseButton.LeftButton:
            self.poly_points = [pt]
            path = QPainterPath(pt)
            self.temp_path = QGraphicsPathItem(path)
            self.temp_path.setPen(QPen(QColor(255,0,0), 2, Qt.PenStyle.DashLine))
            self.scene.addItem(self.temp_path)
            return

        # 3) ellipse‐mode start (and you didn’t click an existing handle/ellipse)
        if self.mode == 'ellipse' and ev.button() == Qt.MouseButton.LeftButton:
            self.ellipse_origin = pt
            self.temp_ellipse = QGraphicsEllipseItem(QRectF(pt, pt))
            self.temp_ellipse.setPen(QPen(QColor(0,255,0), 2, Qt.PenStyle.DashLine))
            self.scene.addItem(self.temp_ellipse)
            return

        # 4) any other case: fall back to default (selection, pan, etc.)
        super().mousePressEvent(ev)


    def mouseMoveEvent(self, ev):
        pt = self.mapToScene(ev.pos())
        if self.mode == 'ellipse' and self.temp_ellipse is not None:
            # update the dash ellipse’s geometry
            rect = QRectF(self.ellipse_origin, pt).normalized()
            self.temp_ellipse.setRect(rect)
        elif self.mode=='polygon' and self.temp_path:
            self.poly_points.append(pt)
            p=QPainterPath(self.poly_points[0])
            for q in self.poly_points[1:]: p.lineTo(q)
            self.temp_path.setPath(p)
        else: super().mouseMoveEvent(ev)

    def mouseReleaseEvent(self, ev):
        pt = self.mapToScene(ev.pos())
        if self.mode == 'ellipse' and self.temp_ellipse is not None:
            final_rect = self.temp_ellipse.rect().normalized()
            self.scene.removeItem(self.temp_ellipse)
            self.temp_ellipse = None

            if final_rect.width() > 4 and final_rect.height() > 4:
                w, h = final_rect.width(), final_rect.height()

                # build local rect
                local_rect = QRectF(0, 0, w, h)

                ell = InteractiveEllipseItem(local_rect)
                ell.setPen(QPen(QColor(0,255,0), 2))
                ell.setBrush(QBrush(Qt.BrushStyle.NoBrush))
                ell.setZValue(1)
                ell.setPos(final_rect.topLeft())
                self.scene.addItem(ell)
                self.shapes.append(ell)
            return
        elif self.mode=='polygon' and self.temp_path:
            poly=QGraphicsPolygonItem(QPolygonF(self.poly_points))
            poly.setBrush(QColor(0,255,0,50)); poly.setPen(QPen(QColor(0,255,0),2))
            poly.setFlags(
                    QGraphicsItem.GraphicsItemFlag.ItemIsSelectable
                | QGraphicsItem.GraphicsItemFlag.ItemIsMovable
                )
            self.scene.removeItem(self.temp_path); self.temp_path=None
            self.scene.addItem(poly); self.shapes.append(poly)
        else: super().mouseReleaseEvent(ev)

    def _to_pixmap(self, image):
        h,w = image.shape[:2]
        if image.ndim==3:
            data=(image*255).astype(np.uint8)
            fmt=QImage.Format.Format_RGB888; stride=3*w
        else:
            data=(image*255).astype(np.uint8)
            fmt=QImage.Format.Format_Grayscale8; stride=w
        img=QImage(data.data,w,h,stride,fmt)
        return QPixmap.fromImage(img)

    def create_mask(self):
        h = self.bg_item.pixmap().height()
        w = self.bg_item.pixmap().width()
        mask = np.zeros((h, w), dtype=np.uint8)

        for s in self.shapes:
            if isinstance(s, QGraphicsPolygonItem):
                pts = s.polygon()
                arr = np.array([[p.x(), p.y()] for p in pts], np.int32)
                cv2.fillPoly(mask, [arr], 1)

            elif isinstance(s, InteractiveEllipseItem):
                # 1) get the ellipse’s local rect
                r = s.rect()

                # 2) map its center into scene coordinates
                scenep = s.mapToScene(r.center())
                cx, cy = int(scenep.x()), int(scenep.y())

                # 3) axes are half the width/height
                rx = int(r.width()  / 2)
                ry = int(r.height() / 2)

                # 4) rotation in degrees (Qt is CCW-positive; OpenCV draws CCW too)
                angle = s.rotation()

                # finally draw it into the mask
                cv2.ellipse(
                    mask,
                    (cx, cy),
                    (rx, ry),
                    angle,
                    0, 360,
                    1,
                    -1
                )

        return mask.astype(bool)
    
    def select_entire_image(self):
        # 1) remove any existing shapes
        for item in list(self.shapes):
            self.scene.removeItem(item)
        self.shapes.clear()

        # 2) build a polygon the size of the background pixmap
        rect = self.bg_item.boundingRect()
        pts = [
            rect.topLeft(),
            rect.topRight(),
            rect.bottomRight(),
            rect.bottomLeft()
        ]
        poly = QGraphicsPolygonItem(QPolygonF(pts))
        poly.setBrush(QColor(0, 255, 0, 50))
        poly.setPen(QPen(QColor(0, 255, 0), 2))
        poly.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable
        )

        # 3) add it to the scene & record it
        self.scene.addItem(poly)
        self.shapes.append(poly)

class LivePreviewDialog(QDialog):
    def __init__(self, original_image: np.ndarray, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Live Mask Preview")
        self.label = QLabel(alignment=Qt.AlignmentFlag.AlignCenter)
        self.setLayout(QVBoxLayout())
        self.layout().addWidget(self.label)
        self.resize(300, 300)

        # 1) build and store your base pixmap once
        img8 = (original_image * 255).astype(np.uint8)
        h, w = img8.shape[:2]
        if original_image.ndim == 3:
            fmt, stride = QImage.Format.Format_RGB888, 3*w
        else:
            fmt, stride = QImage.Format.Format_Grayscale8, w
        qimg = QImage(img8.data, w, h, stride, fmt)
        self.base_pixmap = QPixmap.fromImage(qimg)
        self.max_alpha = 150  # adjust global maximum opacity here

    def update_mask(self, mask: np.ndarray):
        """
        mask: float array [0..1], same shape as original_image
        """
        h, w = mask.shape
        # 2) create an (h×w×4) RGBA array: R=255, G=B=0, A = mask*max_alpha
        alpha = (mask * self.max_alpha).clip(0,255).astype(np.uint8)
        rgba = np.zeros((h, w, 4), dtype=np.uint8)
        rgba[...,1] = 255        # red channel
        rgba[...,3] = alpha      # alpha channel

        # 3) one-shot conversion to QImage/QPixmap
        overlay_qimg = QImage(rgba.data, w, h, 4*w, QImage.Format.Format_RGBA8888)
        overlay_pix = QPixmap.fromImage(overlay_qimg)

        # 4) paint overlay onto a copy of the base
        canvas = QPixmap(self.base_pixmap)
        painter = QPainter(canvas)
        
        painter.drawPixmap(0, 0, overlay_pix)
        painter.end()

        # 5) show it scaled into your label
        self.label.setPixmap(
            canvas.scaled(
                self.label.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
        )


class MaskCreationDialog(QDialog):
    """
    Dialog for creating masks with various types and customizations,
    backed by MaskCanvas (QGraphicsView).
    """
    def __init__(self, image, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Creation")
        self.image = image.copy()
        self.mask = None
        self.live_preview = LivePreviewDialog(self.image, parent=self)

        # Mask parameters
        self.mask_type = "Binary"
        self.blur_amount = 0

        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)

        # ── Mode toolbar ────────────────────────────────────────────
        mode_bar = QHBoxLayout()
        self.free_btn    = QPushButton("Freehand");            self.free_btn.setCheckable(True)
        self.ellipse_btn = QPushButton("Ellipse");             self.ellipse_btn.setCheckable(True)
        self.select_btn  = QPushButton("Select Entire Image"); self.select_btn.setCheckable(True)

        # Make them mutually exclusive
        group = QButtonGroup(self)
        group.setExclusive(True)
        for btn in (self.free_btn, self.ellipse_btn, self.select_btn):
            btn.setAutoExclusive(True)
            group.addButton(btn)

            # **ADD THIS STYLE SHEET** so the checked button lights up
            btn.setStyleSheet("""
                QPushButton {
                    padding: 6px;
                    border: 1px solid #888;
                    border-radius: 4px;
                    background: transparent;
                }
                QPushButton:checked {
                    background-color: #0078d4;
                    color: white;
                    border-color: #005a9e;
                }
            """)

        # Wire up mode changes
        for btn, mode in [
            (self.free_btn,    'polygon'),
            (self.ellipse_btn, 'ellipse'),
            (self.select_btn,  'select'),
        ]:
            btn.clicked.connect(lambda checked, m=mode: self._set_mode(m))
            mode_bar.addWidget(btn)

        # Default to Freehand
        self.free_btn.setChecked(True)
        layout.addLayout(mode_bar)



        # ── The unified canvas ──────────────────────────────────────
        self.canvas = MaskCanvas(self.image)
        layout.addWidget(self.canvas)

        # ── Zoom toolbar ────────────────────────────────────────────
        zoom_bar = QHBoxLayout()
        zoom_in_btn = QPushButton("Zoom In")
        zoom_in_btn.clicked.connect(lambda: self.canvas.scale(1.2, 1.2))
        zoom_out_btn = QPushButton("Zoom Out")
        zoom_out_btn.clicked.connect(lambda: self.canvas.scale(1/1.2, 1/1.2))
        fit_btn = QPushButton("Fit to View")
        fit_btn.clicked.connect(
            lambda: self.canvas.fitInView(
                self.canvas.sceneRect(),
                Qt.AspectRatioMode.KeepAspectRatio
            )
        )
        for b in (zoom_in_btn, zoom_out_btn, fit_btn):
            zoom_bar.addWidget(b)
        layout.addLayout(zoom_bar)

        # ── Mask type & blur ────────────────────────────────────────
        controls = QHBoxLayout()
        controls.addWidget(QLabel("Mask Type:"))
        self.type_dd = QComboBox()
        self.type_dd.addItems([
            "Binary","Range Selection","Lightness","Chrominance","Star Mask",
            "Color: Red","Color: Orange","Color: Yellow",
            "Color: Green","Color: Cyan","Color: Blue","Color: Magenta"
        ])
        self.type_dd.currentTextChanged.connect(lambda t: setattr(self, 'mask_type', t))
        controls.addWidget(self.type_dd)

        controls.addWidget(QLabel("Blur:"))
        self.blur_slider = QSlider(Qt.Orientation.Horizontal)
        self.blur_slider.setRange(0, 300)
        self.blur_slider.valueChanged.connect(lambda v: setattr(self, 'blur_amount', v))
        controls.addWidget(self.blur_slider)

        self.blur_label = QLabel("0")
        self.blur_slider.valueChanged.connect(lambda v: self.blur_label.setText(str(v)))
        controls.addWidget(self.blur_label)

        layout.addLayout(controls)

        # ── RangeSelection controls (hidden by default) ────────────
        self.range_box = QGroupBox("Range Selection")
        g = QGridLayout(self.range_box)

        # helper to build a slider+label
        def make_slider(row, name, maxv):
            g.addWidget(QLabel(name+":"), row,0)
            s = QSlider(Qt.Orientation.Horizontal)
            s.setRange(0, maxv)
            s.setValue(0 if name!="Upper" else maxv)
            lbl = QLabel(f"{0.0:.2f}" if name!="Upper" else f"{1.0:.2f}")
            g.addWidget(s, row,1)
            g.addWidget(lbl, row,2)
            return s,lbl

        self.lower_sl, self.lower_lbl = make_slider(0, "Lower",   100)
        self.upper_sl, self.upper_lbl = make_slider(1, "Upper",   100)
        self.fuzz_sl,  self.fuzz_lbl  = make_slider(2, "Fuzziness",100)
        self.smooth_sl,self.smooth_lbl= make_slider(3, "Smoothness",50)

        # link checkbox
        self.link_cb  = QCheckBox("Link limits")
        g.addWidget(self.link_cb, 0,3,2,1)

        # screening / light / invert
        self.screen_cb = QCheckBox("Screening")
        self.light_cb  = QCheckBox("Lightness")
        self.invert_cb = QCheckBox("Invert")
        for i,cb in enumerate((self.screen_cb,self.light_cb,self.invert_cb),4):
            g.addWidget(cb, i, 0,1,4)

        layout.addWidget(self.range_box)
        self.range_box.hide()


        # ── Preview & Clear ─────────────────────────────────────────
        buttons = QHBoxLayout()
        preview_btn = QPushButton("Preview Mask")
        preview_btn.clicked.connect(self.preview_mask)
        clear_btn = QPushButton("Clear All Shapes")
        clear_btn.clicked.connect(self.clear_all)
        buttons.addWidget(preview_btn)
        buttons.addWidget(clear_btn)
        layout.addLayout(buttons)

        # sliders → labels + live preview
        for sl, lbl in (
            (self.lower_sl,  self.lower_lbl),
            (self.upper_sl,  self.upper_lbl),
            (self.fuzz_sl,   self.fuzz_lbl),
            (self.smooth_sl, self.smooth_lbl),
        ):
            # read the slider’s own maximum() at runtime
            sl.valueChanged.connect(
                lambda v, l=lbl, s=sl: l.setText(f"{v/s.maximum():.2f}")
            )
            sl.valueChanged.connect(self._update_live_preview)

        # link lower/upper
        self.lower_sl.valueChanged.connect(self._on_linked)
        self.link_cb.toggled.connect(self._on_link_switch)
        self.type_dd.currentTextChanged.connect(self._on_type_changed)

        self.setLayout(layout)
        self.resize(900, 600)

    def _set_mode(self, mode):
        # toggle the toolbar buttons
        self.free_btn.setChecked(mode == 'polygon')
        self.ellipse_btn.setChecked(mode == 'ellipse')
        self.select_btn.setChecked(mode == 'select')
        # tell the canvas which tool to use
        self.canvas.set_mode(mode)

        # **NEW**: select-entire-image behavior
        if mode == 'select':
            self.canvas.select_entire_image()

    def _on_type_changed(self, txt):
        if txt=="Range Selection":
            self.range_box.show()
            # bring up live preview
            if not self.live_preview:
                self.live_preview = LivePreviewDialog(self.image, parent=self)
                self.live_preview.show()
            self._update_live_preview()
        else:
            self.range_box.hide()
            if self.live_preview:
                self.live_preview.close()
                self.live_preview = None

    def _on_link_switch(self, checked):
        # if linking, immediately sync upper to lower
        if checked:
            self.upper_sl.setValue(self.lower_sl.value())

    def _on_linked(self, v):
        if self.link_cb.isChecked():
            self.upper_sl.setValue(v)


    def _update_live_preview(self, *_):
        m = self.generate_mask()
        if m is None:
            return
        if not self.live_preview.isVisible():
            self.live_preview.show()
        self.live_preview.update_mask(m)

    def closeEvent(self, event):
        # ensure live‐preview is closed when this dialog is closed
        if getattr(self, 'live_preview', None) is not None and self.live_preview.isVisible():
            self.live_preview.close()
        super().closeEvent(event)

    def _range_selection_mask(self, comp, L, U, fuzz, smooth, screening, invert):
        # comp: single‐channel image normalized to [0..1]
        mask = np.zeros_like(comp, dtype=np.float32)

        # 1) Hard clip region
        inside = (comp >= L) & (comp <= U)
        mask[inside] = 1.0

        # 2) Fuzziness ramps
        if fuzz > 0:
            # ramp‑up below L
            ramp = (comp - (L - fuzz)) / fuzz
            mask += np.clip(ramp, 0, 1)
            # ramp‑down above U
            ramp2 = ((U + fuzz) - comp) / fuzz
            mask *= np.clip(ramp2, 0, 1)

        # 3) Screening
        if screening:
            mask *= comp

        # 4) Gaussian smooth
        if smooth > 0:
            mask = cv2.GaussianBlur(mask, (0,0), smooth)

        # 5) Invert
        if invert:
            mask = 1.0 - mask

        return np.clip(mask, 0, 1)

    def update_mask_type(self, mask_type):
        """
        Updates the selected mask type.
        """
        self.mask_type = mask_type

    def update_blur_amount(self, value):
        """
        Updates the blur amount.
        """
        self.blur_amount = value


    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to File", "Save to Mask Slot"],
            0,
            False
        )

        if not ok:  # User canceled the dialog
            return

        if choice == "Save to File":
            # Save to a file
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                save_image(self.mask, filename)
        elif choice == "Save to Mask Slot":
            # Save to a mask slot
            slot, ok = QInputDialog.getInt(
                self,
                "Save to Mask Slot",
                f"Enter slot number (0-{self.parent().mask_manager.max_slots - 1}):",
                0,
                0,
                self.parent().mask_manager.max_slots - 1,
            )
            if ok:
                self.parent().mask_manager.set_mask(slot, self.mask)

    def apply_mask(self):
        """
        Applies the current mask to the parent.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to apply.")
            return
        self.parent().mask_manager.set_mask(0, self.mask)

    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        # Convert the mask to an 8-bit image for display
        mask_8bit = (mask * 255).astype(np.uint8)
        q_image = QImage(
            mask_8bit.data,
            mask_8bit.shape[1],
            mask_8bit.shape[0],
            mask_8bit.strides[0],
            QImage.Format_Grayscale8
        )
        mask_pixmap = QPixmap.fromImage(q_image)
        self.image_label.setPixmap(mask_pixmap)

    # Mask Generation and Preview
    def generate_mask(self):
        if not self.canvas.shapes:
            QMessageBox.warning(self, "No Shapes", "Draw at least one shape first.")
            return None

        base_mask = self.canvas.create_mask().astype(np.float32)

        # apply mask‐type logic
        if self.mask_type == "Binary":
            mask = base_mask
        elif self.mask_type == "Range Selection":
            # 1) pick component
            if self.light_cb.isChecked():
                comp = self.generate_lightness_mask()
            else:
                # grayscale luminance
                if self.image.ndim == 3:
                    comp = (self.image[...,0]*0.2989 +
                            self.image[...,1]*0.5870 +
                            self.image[...,2]*0.1140)
                else:
                    comp = self.image.copy()

            # 2) normalize to [0,1]
            #comp = (comp - comp.min())/(comp.max() - comp.min() + 1e-12)

            # 3) read slider values as fractions
            L     = self.lower_sl.value()  / self.lower_sl.maximum()
            U     = self.upper_sl.value()  / self.upper_sl.maximum()
            fuzz  = self.fuzz_sl.value()   / self.fuzz_sl.maximum()
            smooth= self.smooth_sl.value() / (self.smooth_sl.maximum()/10)  # tweak scale as you like

            # 4) build the range‐selection mask
            rs = self._range_selection_mask(
                comp=comp,
                L=L, U=U,
                fuzz=fuzz,
                smooth=smooth,
                screening=self.screen_cb.isChecked(),
                invert=self.invert_cb.isChecked()
            )

            # 5) combine with your shape‐based base_mask
            mask = base_mask * rs
                 
        elif self.mask_type == "Lightness":
            L = self.generate_lightness_mask()
            mask = np.where(base_mask, L, 0.0)
        elif self.mask_type == "Chrominance":
            C = self.generate_chrominance_mask()
            mask = np.where(base_mask, C, 0.0)
        elif self.mask_type == "Star Mask":
            S = self.create_star_mask(self.image, None)
            mask = np.where(base_mask, S, 0.0)
        elif self.mask_type.startswith("Color:"):
            color = self.mask_type.split(":",1)[1].strip()
            C = self.generate_color_mask(color)
            mask = np.where(base_mask, C, 0.0)
        else:
            mask = base_mask

        # blur if requested
        if self.blur_amount > 0:
            k = self.blur_amount * 2 + 1
            mask = cv2.GaussianBlur(mask, (k,k), 0)

        return np.clip(mask, 0.0, 1.0)
    
    def clear_all(self):
        # wipe canvas shapes and restore background image
        self.canvas.shapes.clear()
        self.canvas.scene.clear()
        pix = self.canvas._to_pixmap(self.image)
        self.canvas.bg_item = QGraphicsPixmapItem(pix)
        self.canvas.scene.addItem(self.canvas.bg_item)

    def preview_mask(self):
        m = self.generate_mask()
        if m is None:
            return
        self.mask = m
        dlg = MaskPreviewDialog(self.mask, self)
        dlg.exec()

    # Mask Creation and Generation Helpers
    def get_adjusted_position(self, event_pos):
        """
        Adjusts the mouse position based on the current zoom level.

        Args:
            event_pos: The position of the mouse event (QPointF).

        Returns:
            QPoint: Adjusted position.
        """
        # Calculate the position relative to the pixmap without adding scroll offsets
        adjusted_x = event_pos.x() / self.scale_factor
        adjusted_y = event_pos.y() / self.scale_factor

        return QPoint(int(adjusted_x), int(adjusted_y))


    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with True in exclusion areas and False elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                x_original = point.x()
                y_original = point.y()
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Fill polygons
        cv2.fillPoly(mask, polygons, 1)  # Fill the polygons with 1
        return mask.astype(bool)
    
    def generate_lightness_mask(self):
        """
        Generates a lightness mask based on the luminance of the image.
        """
        if self.image.ndim == 3:  # RGB image
            luminance = np.dot(self.image[..., :3], [0.2989, 0.5870, 0.1140])
            return luminance
        else:
            return self.image  # Grayscale image

    def generate_color_mask(self, color):
        """
        Generates a mask for a specific color range using the HSL color model.

        Args:
            color: The name of the color (e.g., "Red", "Orange", "Yellow", etc.).
        
        Returns:
            A mask for the selected color range.
        """
        # Define color ranges in HSL (Hue in degrees)
        color_ranges = {
            "Red": [(0, 10), (350, 360)],  # Red spans from 0-10 and 350-360 degrees
            "Orange": [(10, 40)],
            "Yellow": [(40, 70)],
            "Green": [(70, 170)],
            "Cyan": [(170, 200)],
            "Blue": [(200, 270)],
            "Magenta": [(270, 350)],
        }

        if color not in color_ranges:
            QMessageBox.warning(self, "Invalid Color", f"Color '{color}' is not supported.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

        if self.image.ndim == 3:  # RGB image
            # Convert RGB to HSL
            rgb_image = (self.image * 255).astype(np.uint8)
            hsl_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HLS)

            # Extract the Hue channel
            hue = hsl_image[:, :, 0].astype(np.float32)  # Hue is the first channel in OpenCV HLS

            # Normalize hue to [0, 360] for calculations
            hue = (hue / 180) * 360

            # Create the mask for the selected color range
            mask = np.zeros_like(hue, dtype=np.float32)
            for hue_range in color_ranges[color]:
                lower, upper = hue_range
                if lower < upper:
                    mask = np.maximum(mask, ((hue >= lower) & (hue <= upper)).astype(np.float32))
                else:  # Handle wraparound for red (e.g., 350-360 and 0-10)
                    mask = np.maximum(mask, ((hue >= lower) | (hue <= upper)).astype(np.float32))

            return mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Color mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

    def generate_chrominance_mask(self):
        """
        Generates a chrominance mask based on the chroma components of the image.
        """
        if self.image.ndim == 3:  # RGB image
            # Convert RGB to YCbCr color space
            rgb_image = (self.image * 255).astype(np.uint8)
            ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)

            # Extract the Cb and Cr channels
            cb = ycbcr_image[:, :, 1].astype(np.float32) / 255.0
            cr = ycbcr_image[:, :, 2].astype(np.float32) / 255.0

            # Compute the chrominance mask as the sum of the absolute differences from the mean
            cb_mean = np.mean(cb)
            cr_mean = np.mean(cr)
            chrominance_mask = np.sqrt((cb - cb_mean) ** 2 + (cr - cr_mean) ** 2)

            # Normalize the mask to [0, 1] range
            chrominance_mask = (chrominance_mask - np.min(chrominance_mask)) / (
                np.max(chrominance_mask) - np.min(chrominance_mask)
            )
            return chrominance_mask
        else:
            QMessageBox.warning(self, "Invalid Image", "Chrominance mask requires a color image.")
            return np.zeros(self.image.shape[:2], dtype=np.float32)

    def create_star_mask(self, image, exclusion_mask=None):
        # 1) Build a grayscale detection image
        if image.ndim == 3:
            data = (0.2126*image[...,0] + 0.7152*image[...,1] + 0.0722*image[...,2]).astype(np.float32)
        else:
            data = image.astype(np.float32)

        # 2) Background subtraction
        bkg = sep.Background(data)
        data_sub = data - bkg.back()

        # 3) Extract objects
        objects = sep.extract(data_sub, thresh=self.blur_amount or 3.0, err=bkg.globalrms)

        h, w = image.shape[:2]
        star_mask = np.zeros((h, w), dtype=np.float32)

        # define a maximum “true star” radius in pixels
        MAX_RADIUS = 10

        for obj in objects:
            x, y = int(obj['x']), int(obj['y'])
            # use 1.5× the half‐light radius as your mask radius
            raw_radius = max(obj['a'], obj['b']) * 1.5
            radius = int(raw_radius)

            # skip anything that’s too big to be a star
            if radius > MAX_RADIUS:
                continue

            # if we have an exclusion_mask, only accept stars inside it
            if exclusion_mask is not None and not exclusion_mask[y, x]:
                continue

            # draw a filled circle
            cv2.circle(star_mask,
                    center=(x, y),
                    radius=radius,
                    color=1.0,
                    thickness=-1)

        return star_mask


    def show_mask_preview(self, mask):
        """
        Displays a preview of the generated mask.
        """
        mask_pixmap = self.convert_to_pixmap(mask)
        self.image_label.setPixmap(mask_pixmap)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    # Zoom Methods

    def zoom_in(self):
        """Zoom in on the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()


    def zoom_out(self):
        """Zoom out of the image."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_preview(self):
        """Fit the image to the preview area."""
        # Calculate the required scale factor to fit the image within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        img_width = self.image_pixmap.width()
        img_height = self.image_pixmap.height()

        scale_w = viewport_size.width() / img_width
        scale_h = viewport_size.height() / img_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.convert_to_pixmap(self.image).scaled(
            self.image_pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

        # Redraw polygons with the new scale
        self.update_selection()



class MaskPreviewDialog(QDialog):
    """
    Dialog for displaying and zooming the mask with scroll bars.
    """
    
    def __init__(self, mask, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Mask Preview")
        self.mask = mask.copy()  # Ensure a copy is made to prevent unintended side effects
        self.scale_factor = 1.0
        self.previous_scale_factor = 1.0  # Track previous scale factor for scroll adjustments
        self.fitted = False  # Flag to ensure fit_to_window is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Create a scrollable area for the mask
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)  # Similar to MaskCreationDialog
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Mask display within Scroll Area
        self.image_label = QLabel()  # No parent to avoid layout conflicts
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.image_label.setPixmap(self.pixmap)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.image_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.image_label.setScaledContents(False)  # Maintain aspect ratio

        # Add image label to scroll area
        self.scroll_area.setWidget(self.image_label)

        # Add scroll area to main layout
        main_layout.addWidget(self.scroll_area)

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_to_window_button = QPushButton("Fit to Window")
        fit_to_window_button.clicked.connect(self.fit_to_window)
        invert_mask_button = QPushButton("Invert Mask")
        invert_mask_button.clicked.connect(self.invert_mask)        
        save_mask_button = QPushButton("Save Mask")
        save_mask_button.clicked.connect(self.save_mask)

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_to_window_button)

        # Add zoom buttons to main layout
        main_layout.addLayout(zoom_layout)
        main_layout.addWidget(invert_mask_button)
        main_layout.addWidget(save_mask_button)

        self.setLayout(main_layout)
        self.setMinimumSize(600, 400)

    def invert_mask(self):
        """
        Inverts the current mask and updates the display.
        """
        self.mask = 1.0 - self.mask
        self.pixmap = self.convert_to_pixmap(self.mask)
        self.update_image()

    def convert_to_pixmap(self, mask):
        """
        Converts the mask (numpy array) to a QPixmap for display.
        """
        # Ensure mask is in [0, 1] range
        mask_normalized = np.clip(mask, 0, 1)

        # Convert mask to 8-bit for display
        mask_8bit = (mask_normalized * 255).astype(np.uint8)

        # If mask has multiple channels, convert to RGB for display purposes
        if mask_8bit.ndim == 3 and mask_8bit.shape[2] == 3:
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_RGB888
            )
        else:
            # Use Grayscale8 format for single-channel masks
            q_image = QImage(
                mask_8bit.data,
                mask_8bit.shape[1],
                mask_8bit.shape[0],
                mask_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    # Zoom Methods

    def zoom_in(self):
        """Zoom in on the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor *= 1.2
        self.update_image()


    def zoom_out(self):
        """Zoom out of the mask."""
        self.previous_scale_factor = self.scale_factor
        self.scale_factor /= 1.2
        self.update_image()

    def fit_to_window(self):
        """Fit the mask to the preview area."""
        # Calculate the required scale factor to fit the mask within the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap_width = self.pixmap.width()
        pixmap_height = self.pixmap.height()

        scale_w = viewport_size.width() / pixmap_width
        scale_h = viewport_size.height() / pixmap_height

        self.previous_scale_factor = self.scale_factor
        self.scale_factor = min(scale_w, scale_h)
        self.update_image()

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor and preserves scroll position.
        """
        # Calculate the center point before scaling
        center_x = self.scroll_area.horizontalScrollBar().value() + self.scroll_area.viewport().width() / 2
        center_y = self.scroll_area.verticalScrollBar().value() + self.scroll_area.viewport().height() / 2

        # Scale the pixmap while maintaining aspect ratio
        scaled_pixmap = self.pixmap.scaled(
            self.pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)

        # Resize the image_label to fit the scaled pixmap
        self.image_label.resize(scaled_pixmap.size())

        # Calculate the scale ratio based on previous and current scale_factor
        scale_ratio = self.scale_factor / self.previous_scale_factor

        # Set the new scroll positions to keep the center consistent
        new_scroll_x = int(center_x * scale_ratio - self.scroll_area.viewport().width() / 2)
        new_scroll_y = int(center_y * scale_ratio - self.scroll_area.viewport().height() / 2)

        self.scroll_area.horizontalScrollBar().setValue(new_scroll_x)
        self.scroll_area.verticalScrollBar().setValue(new_scroll_y)

        # Update the previous_scale_factor
        self.previous_scale_factor = self.scale_factor

    def save_mask(self):
        """
        Saves the current mask either to a file or to a mask slot.
        """
        if self.mask is None:
            QMessageBox.warning(self, "No Mask", "No mask to save.")
            return

        # Ask the user whether they want to save to a file or a mask slot
        choice, ok = QInputDialog.getItem(
            self,
            "Save Mask",
            "Choose save destination:",
            ["Save to Mask Slot", "Save to File"],
            0,
            False
        )
        if not ok:
            return

        if choice == "Save to File":
            filename, _ = QFileDialog.getSaveFileName(
                self, "Save Mask", "", "Images (*.png *.tiff *.fits)"
            )
            if filename:
                self.save_image(self.mask, filename)
                QMessageBox.information(self, "Mask Saved", f"Mask saved to {filename}.")
                self.accept()

        elif choice == "Save to Mask Slot":
            # Traverse parent hierarchy until we find the main window with a mask_manager.
            parent = self.parent()
            while parent and not hasattr(parent, 'mask_manager'):
                parent = parent.parent()

            if parent and hasattr(parent, 'mask_manager'):
                max_slot = parent.mask_manager.max_slots - 1

                # Create a small dialog with your CustomSpinBox
                dlg = QDialog(self)
                dlg.setWindowTitle("Save to Mask Slot")
                layout = QVBoxLayout(dlg)

                # Prompt
                prompt = QLabel(f"Enter slot number (0–4):", dlg)
                layout.addWidget(prompt)

                # Custom spin box for slot selection
                slot_spin = CustomSpinBox(
                    minimum=0,
                    maximum=4,
                    initial=0,
                    step=1,
                    parent=dlg
                )
                layout.addWidget(slot_spin)

                # OK / Cancel buttons
                buttons = QDialogButtonBox(
                    QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel,
                    parent=dlg
                )
                buttons.accepted.connect(dlg.accept)
                buttons.rejected.connect(dlg.reject)
                layout.addWidget(buttons)

                if dlg.exec() == QDialog.DialogCode.Accepted.value:
                    slot = slot_spin.value
                    parent.mask_manager.set_mask(slot, self.mask)

                    # Update the toolbar highlight if available
                    if hasattr(parent, 'update_mask_slot_toolbar_highlight'):
                        parent.update_mask_slot_toolbar_highlight()

                    QMessageBox.information(self, "Mask Saved", f"Mask saved to Slot {slot}.")
                    self.accept()

            else:
                QMessageBox.warning(self, "No Mask Manager", "Parent does not have a mask_manager.")



    def save_image(self, mask, filename):
        """
        Saves the mask to a file.
        """
        # Convert mask to 8-bit for saving
        mask_8bit = (mask * 255).astype(np.uint8)
        # Save using QPixmap
        pixmap = self.convert_to_pixmap(mask)
        pixmap.save(filename)
        print(f"Mask saved to {filename}.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            self.fit_to_window()
            self.fitted = True

class MaskDisplayWindow(QDialog):
    """
    A separate window to display the luminance mask for debugging purposes.
    Includes Zoom In, Zoom Out, and Fit to Preview controls.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Luminance Mask")
        self.setMinimumSize(300, 300)

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the mask display area (QGraphicsView in a scrollable region)
        self._create_mask_display_area()

        # 2) Create the zoom controls
        self._create_zoom_controls()

    # -------------------------------------------------------------------------
    # 1) MASK DISPLAY AREA
    # -------------------------------------------------------------------------
    def _create_mask_display_area(self):
        """Create a QGraphicsView & QGraphicsScene for the mask display."""
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        # Add the graphics view to the main layout
        self.main_layout.addWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) ZOOM CONTROLS
    # -------------------------------------------------------------------------
    def _create_zoom_controls(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_controls_group = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_controls_group.setLayout(zoom_layout)

        # Add the zoom controls to the main layout
        self.main_layout.addWidget(self.zoom_controls_group)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def _zoom_in(self):
        """Zoom in the mask display."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed in to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")
            print("MaskDisplayWindow: Maximum zoom level reached.")

    def _zoom_out(self):
        """Zoom out the mask display."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
            print(f"MaskDisplayWindow: Zoomed out to {self.zoom_factor}x.")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")
            print("MaskDisplayWindow: Minimum zoom level reached.")

    def _fit_to_preview(self):
        """Fit the entire mask within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No mask to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0
        print("MaskDisplayWindow: Fitted mask to preview and reset zoom factor to 1.0.")

    def _apply_zoom(self):
        """Apply the current zoom factor to the graphics view."""
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)
        print(f"MaskDisplayWindow: Applied zoom factor of {self.zoom_factor}x.")

    # -------------------------------------------------------------------------
    # MASK UPDATE METHOD
    # -------------------------------------------------------------------------
    def update_mask(self, mask_array):
        """
        Update the mask display with the given mask array.
        
        Args:
            mask_array (np.ndarray): 2D array with values in [0, 1].
        """
        try:
            # Convert mask array to grayscale image [0..255]
            mask_uint8 = (np.clip(mask_array, 0, 1) * 255).astype(np.uint8)

            # Ensure it's single-channel
            if mask_uint8.ndim == 3 and mask_uint8.shape[2] == 3:
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)
            elif mask_uint8.ndim == 2:
                pass  # Already single-channel
            else:
                # Handle unexpected formats
                mask_uint8 = np.mean(mask_uint8, axis=2).astype(np.uint8)

            # Convert to QImage
            h, w = mask_uint8.shape[:2]
            qimage = QImage(
                mask_uint8.data, w, h, w, QImage.Format.Format_Grayscale8
            )
            pixmap = QPixmap.fromImage(qimage)

            # Update the pixmap item
            self.pixmap_item.setPixmap(pixmap)
            self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

            # Reset zoom to fit the new mask
            self._fit_to_preview()

            print("MaskDisplayWindow: Mask updated and fitted to preview.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")
            print(f"MaskDisplayWindow: Error updating mask - {e}")

class HistogramDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        """
        Initialize the histogram dialog.

        Args:
            image_manager (ImageManager): The manager providing the current image.
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Histogram")
        self.image_manager = image_manager
        # Start with the active slot’s image:
        self.image = image_manager.image  # image_manager.image returns the current slot's image.
        self.zoom_factor = 1.0  # 1.0 means 100%
        self.log_scale = False  # Default: linear x-axis
        self.log_y     = False
        self._connected  = False    # track our connection state
        self.initUI()


    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Create a horizontal layout to hold the histogram and statistics table.
        top_layout = QHBoxLayout()
        
        # Create a scroll area for the histogram.
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        
        # Create the histogram label.
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)
        
        # Create the statistics table.
        self.stats_table = QTableWidget(self)
        self.stats_table.setRowCount(4)  # Min, Max, Median, StdDev
        self.stats_table.setColumnCount(1)  # Default for mono; updated later if RGB.
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)
        
        main_layout.addLayout(top_layout)
        
        # Controls for zoom and log toggle.
        controls_layout = QHBoxLayout()
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)  # 50% to 1000%
        self.zoom_slider.setValue(100)
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(QLabel("Zoom:"))
        controls_layout.addWidget(self.zoom_slider)
        
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis scaling.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)

        self.log_y_button = QPushButton("Toggle Log Y-Axis", self)
        self.log_y_button.setCheckable(True)
        self.log_y_button.setToolTip("Toggle between linear & logarithmic Y-axis")
        self.log_y_button.toggled.connect(self.toggleLogYScale)
        controls_layout.addWidget(self.log_y_button)

        main_layout.addLayout(controls_layout)
        
        # Close button.
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        self.drawHistogram()

    def toggleLogYScale(self, checked: bool):
        self.log_y = checked
        self.drawHistogram()

    def showEvent(self, event):
        super().showEvent(event)
        if not self._connected:
            self.image_manager.image_changed.connect(self.on_image_changed)
            self._connected = True

    def hideEvent(self, event):
        if self._connected:
            try:
                self.image_manager.image_changed.disconnect(self.on_image_changed)
            except (TypeError, RuntimeError):
                pass
            self._connected = False
        super().hideEvent(event)

    def on_image_changed(self, slot, image, metadata):
        if slot == self.image_manager.current_slot:
            self.image = image
            self.drawHistogram()

    def updateHistogram(self, new_image):
        """ Update the histogram with a new image. """
        self.image = new_image
        self.drawHistogram()

    def updateZoom(self, value):
        self.zoom_factor = value / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked):
        self.log_scale = checked
        self.drawHistogram()

    def drawHistogram(self):
        """
        Computes and draws the histogram.
        In linear mode, it uses equally spaced bins.
        In log mode, it uses logarithmically spaced bins (with a small epsilon to avoid log(0)).
        Also draws an x-axis with tick marks and labels.
        """
        # Base dimensions.
        base_width = 512
        height = 300
        width = int(base_width * self.zoom_factor)

        
        bin_count = 512
        
        # Choose bin edges based on the log_scale toggle.
        if self.log_scale:
            # Compute a small positive epsilon
            raw_min = float(np.min(self.image))
            eps     = max(raw_min, 1e-4)
            self._hist_eps     = eps
            self._hist_log_min = log_min = np.log10(eps)
            self._hist_log_max = log_max = 0.0  # because log10(1)=0

            if abs(log_max - log_min) < 1e-6:
                # no dynamic range → fallback to a tiny linear stretch from eps→1
                bin_edges = np.linspace(eps, 1.0, bin_count + 1)
                def x_pos(edge):
                    # if eps==1, everything collapses → draw at left
                    if eps >= 1.0:
                        return 0
                    return int((edge - eps) / (1.0 - eps) * width)

            else:
                # proper log spacing
                bin_edges = np.logspace(log_min, log_max, bin_count + 1)
                def x_pos(edge):
                    return int((np.log10(edge) - log_min) / (log_max - log_min) * width)
        else:
            # Linear mode is unchanged
            bin_edges = np.linspace(0, 1, bin_count + 1)
            def x_pos(edge):
                return int(edge * width)
        
        
        # Create a pixmap with the computed dimensions.
        pixmap = QPixmap(width, height)
        pixmap.fill(Qt.GlobalColor.white)
        painter = QPainter(pixmap)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # Draw histogram bars.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # For RGB images, draw each channel histogram.
            channel_colors = [
                QColor(255, 0, 0, 120),
                QColor(0, 255, 0, 120),
                QColor(0, 0, 255, 120)
            ]
            for ch in range(3):
                hist, _ = np.histogram(self.image[..., ch].ravel(), bins=bin_edges)
                hist = hist.astype(np.float32)
                if self.log_y:
                    # log-scale the Y axis: log(count+1) → avoid log(0)
                    hist = np.log10(hist + 1.0)
                # now normalize to [0,1] for drawing
                maxv = hist.max()
                hist = hist / maxv if maxv > 0 else hist
                painter.setPen(QPen(channel_colors[ch]))
                for i in range(bin_count):
                    x0 = x_pos(bin_edges[i])
                    x1 = x_pos(bin_edges[i+1])
                    bar_width = x1 - x0
                    bar_height = hist[i] * height
                    painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        else:
            # Mono: if image is 3D with one channel, squeeze.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                gray = self.image.squeeze()
            else:
                gray = self.image
            hist, _ = np.histogram(gray.ravel(), bins=bin_edges)
            hist = hist.astype(np.float32)
            if self.log_y:
                # log-scale the Y axis: log(count+1) → avoid log(0)
                hist = np.log10(hist + 1.0)
            # now normalize to [0,1] for drawing
            maxv = hist.max()
            hist = hist / maxv if maxv > 0 else hist
            painter.setPen(QPen(QColor(0, 0, 0)))
            for i in range(bin_count):
                x0 = x_pos(bin_edges[i])
                x1 = x_pos(bin_edges[i+1])
                bar_width = x1 - x0
                bar_height = hist[i] * height
                painter.drawRect(x0, int(height - bar_height), bar_width, int(bar_height))
        
        # Draw x-axis.
        painter.setPen(QPen(QColor(0, 0, 0), 2))
        painter.drawLine(0, height - 1, width, height - 1)
        
        # Draw tick marks and labels.
        painter.setFont(QFont("Arial", 10))
        if self.log_scale:
            tick_values = np.logspace(np.log10(eps), 0, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.3f}")
        else:
            tick_values = np.linspace(0, 1, 11)
            for tick in tick_values:
                x = x_pos(tick)
                painter.drawLine(x, height - 1, x, height - 6)
                painter.drawText(x - 10, height - 10, f"{tick:.1f}")
        
        painter.end()
        self.hist_label.setPixmap(pixmap)
        self.hist_label.resize(pixmap.size())
        
        # Update the statistics table.
        self.updateStatistics()

    def updateStatistics(self):
        """
        Computes statistics for the current image and updates the table.
        For an RGB image, computes per-channel min, max, median, and standard deviation.
        For a mono image, computes statistics for the first channel.
        """
        # Determine if the image is color or mono.
        if self.image.ndim == 3 and self.image.shape[2] == 3:
            # Color image: 3 columns.
            self.stats_table.setColumnCount(3)
            self.stats_table.setHorizontalHeaderLabels(["R", "G", "B"])
            channels = [self.image[..., i] for i in range(3)]
        else:
            # Mono: 1 column.
            self.stats_table.setColumnCount(1)
            self.stats_table.setHorizontalHeaderLabels(["Gray"])
            # If the image is 3D with 1 channel, squeeze it.
            if self.image.ndim == 3 and self.image.shape[2] == 1:
                channels = [self.image.squeeze()]
            else:
                channels = [self.image]
        
        # Compute statistics for each channel.
        stats = {"Min": [], "Max": [], "Median": [], "StdDev": []}
        for ch in channels:
            stats["Min"].append(np.min(ch))
            stats["Max"].append(np.max(ch))
            stats["Median"].append(np.median(ch))
            stats["StdDev"].append(np.std(ch))
        
        # Update the table cells.
        row_labels = ["Min", "Max", "Median", "StdDev"]
        for row, label in enumerate(row_labels):
            for col in range(self.stats_table.columnCount()):
                val = stats[label][col]
                item = QTableWidgetItem(f"{val:.3f}")
                item.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(row, col, item)

class PreviewPane(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.zoom_factor = 1.0
        self.is_autostretched = False
        self._image_array     = None
        self.original_image = None    # QImage
        self.stretched_image = None   # QImage
        self._panning = False
        self._pan_start = QPoint()
        self._h_scroll_start = 0
        self._v_scroll_start = 0

        # the scrollable image area
        self.image_label  = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area  = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setMinimumSize(450, 450)
        self.scroll_area.viewport().installEventFilter(self)

        # zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)
        self.zoom_slider.setValue(100)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        self.zoom_in_btn  = QPushButton("＋")
        self.zoom_in_btn.clicked .connect(lambda: self.adjust_zoom(10))
        self.zoom_out_btn = QPushButton("－")
        self.zoom_out_btn.clicked.connect(lambda: self.adjust_zoom(-10))
        self.fit_btn      = QPushButton("Fit")
        self.fit_btn.clicked .connect(self.fit_to_view)
        self.stretch_btn  = QPushButton("AutoStretch")
        self.stretch_btn.clicked.connect(self.toggle_stretch)

        zl = QHBoxLayout()
        zl.addWidget(self.zoom_out_btn)
        zl.addWidget(self.zoom_slider)
        zl.addWidget(self.zoom_in_btn)
        zl.addWidget(self.fit_btn)
        zl.addWidget(self.stretch_btn)

        layout = QVBoxLayout(self)
        layout.addWidget(self.scroll_area, 1)
        layout.addLayout(zl)

        self.fit_to_view()

    def load_qimage(self, img: QImage):
        """
        Call this to (re)load a fresh image.
        We immediately convert it to a numpy array once
        so we never have to touch the QImage bits again.
        """
        # keep a local copy of the QImage (for fast redisplay)
        self.original_image   = img.copy()

        # one & only time we go QImage→numpy
        self._image_array     = self.qimage_to_numpy(self.original_image)

        # reset any existing stretch state
        self.stretched_image  = None
        self.is_autostretched = False
        self.zoom_factor      = 1.0
        self.zoom_slider.setValue(100)

        self._update_display()

    def set_overlay(self, overlays):
        """ Store and repaint overlays on top of the image. """
        self._overlays = overlays
        self._update_display()

    def toggle_stretch(self):
        if self._image_array is None:
            return

        self.is_autostretched = not self.is_autostretched

        if self.is_autostretched:
            # stretch the stored numpy array
            arr = self._image_array.copy()
            if arr.ndim == 2:
                stretched = stretch_mono_image(
                    arr,
                    target_median=0.25,
                    normalize=True,
                    apply_curves=False
                )
            else:
                stretched = stretch_color_image(
                    arr,
                    target_median=0.25,
                    linked=False,
                    normalize=True,
                    apply_curves=False
                )

            # convert back to a QImage for display
            self.stretched_image = self.numpy_to_qimage(stretched).copy()
        else:
            # go back to the original QImage
            self.stretched_image = self.original_image.copy()

        self._update_display()

    def qimage_to_numpy(self, qimg: QImage) -> np.ndarray:
        """
        Safely copy a QImage into a contiguous numpy array,
        and return float32 data normalized to [0.0, 1.0].
        Supports Grayscale8 and RGB888.
        """
        # force a copy & right format
        if qimg.format() == QImage.Format.Format_Grayscale8:
            img = qimg.convertToFormat(QImage.Format.Format_Grayscale8).copy()
            w, h = img.width(), img.height()
            ptr   = img.bits()
            ptr.setsize(h * w)
            buf   = ptr.asstring()
            arr   = np.frombuffer(buf, np.uint8).reshape((h, w))
        else:
            img = qimg.convertToFormat(QImage.Format.Format_RGB888).copy()
            w, h = img.width(), img.height()
            bpl   = img.bytesPerLine()
            ptr   = img.bits()
            ptr.setsize(h * bpl)
            buf   = ptr.asstring()
            raw   = np.frombuffer(buf, np.uint8).reshape((h, bpl))
            raw   = raw[:, : 3*w]
            arr   = raw.reshape((h, w, 3))

        # **normalize to float32 [0..1]**
        return (arr.astype(np.float32) / 255.0)

    def numpy_to_qimage(self, arr: np.ndarray) -> QImage:
        """
        Convert a H×W or H×W×3 numpy array (float in [0..1] or uint8 in [0..255])
        into a QImage (copying the buffer).
        """
        # If floating point, assume 0..1 and scale up:
        if np.issubdtype(arr.dtype, np.floating):
            arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)
        # Otherwise convert any other integer type to uint8
        elif arr.dtype != np.uint8:
            arr = np.clip(arr, 0, 255).astype(np.uint8)

        h, w = arr.shape[:2]
        if arr.ndim == 2:
            img = QImage(arr.data, w, h, w, QImage.Format.Format_Grayscale8)
            return img.copy()
        elif arr.ndim == 3 and arr.shape[2] == 3:
            bytes_per_line = 3 * w
            img = QImage(arr.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
            return img.copy()
        else:
            raise ValueError(f"Cannot convert array of shape {arr.shape} to QImage")

    def on_zoom_changed(self, val):
        self.zoom_factor = val/100
        self._update_display()

    def adjust_zoom(self, delta):
        v = self.zoom_slider.value() + delta
        self.zoom_slider.setValue(min(max(v,1),400))

    def fit_to_view(self):
        if not self.original_image:
            return
        avail = self.scroll_area.viewport().size()
        iw, ih = self.original_image.width(), self.original_image.height()
        f = min(avail.width()/iw, avail.height()/ih)
        self.zoom_factor = f
        self.zoom_slider.setValue(int(f*100))
        self._update_display()

    def _update_display(self):
        """
        Chooses original vs stretched image and repaints.
        """
        img = self.stretched_image or self.original_image
        if img is None:
            return

        pix = QPixmap.fromImage(self.stretched_image or self.original_image)
        painter = QPainter(pix)
        painter.setPen(QPen(Qt.GlobalColor.red, 2))
        # draw any overlays
        for ov in getattr(self, "_overlays", []):
            x, y, p3, p4 = ov
            # if p3 is an integer / we intended an ellipse
            if isinstance(p3, (int,)) and isinstance(p4, (int, float)):
                w = int(p3)
                h = w
                painter.drawEllipse(x, y, w, h)
                painter.drawText(x, y, f"{p4:.2f}")
            else:
                # treat as vector overlay: (angle, length)
                angle = float(p3)
                length_um = float(p4)
                # convert length from µm → pixels if necessary;
                # here we assume overlays were built in pixels:
                dx = math.cos(angle) * length_um
                dy = -math.sin(angle) * length_um
                x2 = x + dx
                y2 = y + dy
                painter.drawLine(int(x), int(y), int(x2), int(y2))
                # optional: draw a simple arrowhead
                # (two short lines at ±20° from the vector)
                ah = 5  # arrow‐head pixel length
                for sign in (+1, -1):
                    ang2 = angle + sign * math.radians(20)
                    ax = x2 - ah * math.cos(ang2)
                    ay = y2 + ah * math.sin(ang2)
                    painter.drawLine(int(x2), int(y2), int(ax), int(ay))
        painter.end()
        scaled = pix.scaled(
            pix.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled)

    def eventFilter(self, source, evt):
        if source is self.scroll_area.viewport():
            if evt.type() == QEvent.Type.MouseButtonPress and evt.button() == Qt.MouseButton.LeftButton:
                self._panning = True
                self._pan_start = evt.position().toPoint()
                self._h_scroll_start = self.scroll_area.horizontalScrollBar().value()
                self._v_scroll_start = self.scroll_area.verticalScrollBar().value()
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                return True

            elif evt.type() == QEvent.Type.MouseMove and self._panning:
                delta = evt.position().toPoint() - self._pan_start
                self.scroll_area.horizontalScrollBar().setValue(self._h_scroll_start - delta.x())
                self.scroll_area.verticalScrollBar().setValue(self._v_scroll_start - delta.y())
                return True

            elif evt.type() == QEvent.Type.MouseButtonRelease and evt.button() == Qt.MouseButton.LeftButton:
                self._panning = False
                self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                return True

        return super().eventFilter(source, evt)

    def load_numpy(self, arr: np.ndarray):
        """
        Convenience wrapper: take an H×W or H×W×3 NumPy array (float in [0..1] or uint8),
        convert it to a QImage and display.
        """
        # Convert to QImage
        qimg = self.numpy_to_qimage(arr)
        # Delegate to your existing loader
        self.load_qimage(qimg)


def field_curvature_analysis(
    img: np.ndarray,
    grid: int,
    panel: int,
    pixel_scale: float,
    snr_thresh: float = 5.0
) -> Tuple[np.ndarray, List[Tuple[int,int,float,float]]]:
    """
    1) Estimate background + detect stars via SEP.
    2) Compute per‐star FWHM (≈2*a), eccentricity, and orientation theta.
    3) Bin the FWHM into a grid×grid mosaic (median per cell) → FWHM_um heatmap.
    4) Normalize that heatmap to [0..1] for display.
    5) Build an overlay list of (x_pix,y_pix,angle_rad,elongation_um) for each star.
    """
    H, W = img.shape[:2]
    # grayscale float32
    if img.ndim == 3 and img.shape[2] == 3:
        gray = (0.2126*img[...,0] + 0.7152*img[...,1] + 0.0722*img[...,2]).astype(np.float32)
    else:
        gray = img.astype(np.float32)

    # background / stats
    mean, med, std = sigma_clipped_stats(gray, sigma=3.0)
    data = gray - med

    # detect
    objs = sep.extract(data, thresh=snr_thresh, err=std)
    if objs is None or len(objs)==0:
        # empty mosaic + no overlays
        blank = np.zeros((H,W), dtype=float)
        return blank, []

    x, y = objs['x'], objs['y']
    a, b, theta = objs['a'], objs['b'], objs['theta']

    # FWHM ≈ 2 * a  (in pixels) → µm
    fwhm_um = 2.0 * a * pixel_scale

    # eccentricity → elongation factor e = a/b - 1
    e = np.clip(a / np.where(b>0, b, 1.0) - 1.0, 0.0, None)
    elongation_um = e * pixel_scale

    # --- build mosaic of median‐FWHM in each grid cell ---
    cell_w, cell_h = W/grid, H/grid
    fmap = np.zeros((H,W), dtype=float)
    heat = np.full((grid, grid), np.nan, dtype=float)
    for j in range(grid):
        for i in range(grid):
            mask = (
                (x>= i*cell_w) & (x< (i+1)*cell_w) &
                (y>= j*cell_h) & (y< (j+1)*cell_h)
            )
            if np.any(mask):
                mval = np.median(fwhm_um[mask])
            else:
                mval = np.nan
            heat[j,i] = mval
            # fill that block
            y0, y1 = int(j*cell_h), int((j+1)*cell_h)
            x0, x1 = int(i*cell_w), int((i+1)*cell_w)
            fmap[y0:y1, x0:x1] = mval if not np.isnan(mval) else 0.0

    # replace empty with global median
    med_heat = np.nanmedian(heat)
    fmap = np.where(fmap==0, med_heat, fmap)

    # normalize to [0..1]
    mn, mx = fmap.min(), fmap.max()
    if mx>mn:
        norm = (fmap - mn) / (mx - mn)
    else:
        norm = np.zeros_like(fmap)

    # --- build elongation‐arrow overlays ---
    overlays: List[Tuple[int,int,float,float]] = []
    for xi, yi, ang, el in zip(x, y, theta, elongation_um):
        overlays.append((int(xi), int(yi), float(ang), float(el)))

    return norm, overlays

def tilt_analysis(
    img: np.ndarray,
    pixel_size_um: float,
    focal_length_mm: float,
    aperture_mm: float,
    sigma_clip: float = 2.0,
    thresh_sigma: float = 5.0,
) -> Tuple[np.ndarray, Tuple[float,float,float], Tuple[int,int]]:
    """
    Robust sensor‐tilt measurement via direct plane fit, with a thin‐lens defocus model.

    1) Convert to 2-D luminance if needed.
    2) Detect stars & measure half-light radius via SEP → rad (pixels).
    3) Compute blur diameter d_um = 2*a_px * pixel_size_um.
    4) Convert blur → defocus via thin‐lens: Δz_um = d_um * (focal_length_mm / aperture_mm).
    5) Fit plane Δz = a x + b y + c to all stars (sigma‐clipped).
    6) Return that best‐fit plane evaluated over every pixel, normalized 0–1 for display.
    """
    # 0) grayscale float32
    if img.ndim == 3 and img.shape[2] == 3:
        gray = (0.2126*img[...,0] + 0.7152*img[...,1] + 0.0722*img[...,2]).astype(np.float32)
    else:
        gray = img.astype(np.float32)
    H, W = gray.shape

    # 1) SEP star detection
    data = np.ascontiguousarray(gray, dtype=np.float32)
    bkg  = sep.Background(data)
    stars = sep.extract(data - bkg.back(),
                        thresh=thresh_sigma,
                        err=bkg.globalrms)
    if stars is None or len(stars) < 10:
        return np.zeros((H,W), dtype=float), (0.0,0.0,0.0), (H,W)

    x     = stars['x']
    y     = stars['y']
    a_pix = stars['a']   # semi-major axis
    flags = stars['flag'] if 'flag' in stars.dtype.names else np.zeros_like(a_pix, dtype=int)

    # 2) map to defocus distance (µm) via thin-lens:
    #    blur diameter ≈ 2*a_pix * px_size_um
    #    Δz_um = blur_um * (focal_length_mm / aperture_mm)
    blur_um     = 2.0 * a_pix * pixel_size_um
    f_number    = focal_length_mm / aperture_mm
    defocus_um  = blur_um * f_number

    # 3) initial least‐squares plane fit
    A     = np.vstack([x, y, np.ones_like(x)]).T  # (N,3)
    sol, *_ = np.linalg.lstsq(A, defocus_um, rcond=None)
    a, b, c = sol

    # 4) sigma‐clip outliers and re-fit
    z_pred = A.dot(sol)
    resid  = defocus_um - z_pred
    mask   = np.abs(resid) < sigma_clip * np.std(resid)
    if mask.sum() > 10:
        sol, *_ = np.linalg.lstsq(A[mask], defocus_um[mask], rcond=None)
        a, b, c = sol

    # 5) build full‐frame plane
    Y, X      = np.mgrid[0:H, 0:W]
    plane_full = a*X + b*Y + c

    # 6) normalize to [0..1] for display
    pmin, pmax = plane_full.min(), plane_full.max()
    if pmax > pmin:
        norm_plane = (plane_full - pmin) / (pmax - pmin)
    else:
        norm_plane = np.zeros_like(plane_full)

    return norm_plane, (a, b, c), (H, W)

def focal_plane_curvature_overlay(img: np.ndarray, grid: int, panel: int):
    """
    Compute the best-fit sphere radius through each local panel,
    return a list of QPainter-friendly overlay primitives,
    e.g. [(x,y,radius,quality), …].
    """
    overlays = []
    h, w = img.shape[:2]
    xs = np.linspace(0, w-panel, grid, dtype=int)
    ys = np.linspace(0, h-panel, grid, dtype=int)
    for y in ys:
        for x in xs:
            patch = img[y:y+panel, x:x+panel]
            # Fit a circle to the intensity → radius
            radius = fit_circle_radius(patch)
            overlays.append((x, y, panel, radius))
    return overlays



def build_mosaic_numpy(
    arr: np.ndarray,
    grid: int,
    panel: int,
    sep: int = 4,
    background: float = 0.0
) -> np.ndarray:
    """
    Tile `arr` into a grid×grid mosaic of size `panel` each, separated by `sep` pixels.
    If arr is 2D, result is 2D; if 3D (H×W×3), result is 3D.
    """
    h, w = arr.shape[:2]
    out_h = grid * panel + (grid - 1) * sep
    out_w = grid * panel + (grid - 1) * sep
    if arr.ndim == 2:
        mosaic = np.full((out_h, out_w), background, dtype=arr.dtype)
    else:
        c = arr.shape[2]
        mosaic = np.full((out_h, out_w, c), background, dtype=arr.dtype)

    # evenly spaced top-left corners
    xs = [int((w - panel) * i / (grid - 1)) for i in range(grid)]
    ys = [int((h - panel) * j / (grid - 1)) for j in range(grid)]

    for row, y in enumerate(ys):
        for col, x in enumerate(xs):
            patch = arr[y : y + panel, x : x + panel]
            dy = row * (panel + sep)
            dx = col * (panel + sep)
            mosaic[dy:dy + panel, dx:dx + panel, ...] = patch

    return mosaic




def fit_circle_radius(patch: np.ndarray) -> float:
    """
    Very rough radius estimate by thresholding + edge points + circle fit.
    Returns radius in pixels (caller scales to physical units).
    """
    # 1) threshold at ~50% max:
    thr = patch.max() * 0.5
    mask = patch > thr
    ys, xs = np.nonzero(mask)
    if len(xs) < 5:
        return 0.0

    # 2) algebraic circle fit (Taubin)
    x = xs.astype(float)
    y = ys.astype(float)
    x_m = x.mean();  y_m = y.mean()
    u = x - x_m;   v = y - y_m
    Suu = (u*u).sum();  Suv = (u*v).sum();  Svv = (v*v).sum()
    Suuu = (u*u*u).sum();  Svvv = (v*v*v).sum()
    Suvv = (u*v*v).sum();  Svuu = (v*u*u).sum()
    # Solved system:
    A = np.array([[Suu, Suv], [Suv, Svv]])
    B = np.array([(Suuu + Suvv)/2.0, (Svvv + Svuu)/2.0])
    try:
        uc, vc = np.linalg.solve(A, B)
    except np.linalg.LinAlgError:
        return 0.0
    radius = math.hypot(uc, vc)
    return radius

def focal_plane_curvature_overlay(
    img: np.ndarray,
    grid: int,
    panel: int,
    pixel_size_um: Optional[float] = None
) -> List[Tuple[int,int,int,float]]:
    """
    Divide `img` into grid×grid panels, estimate per-panel best-focus radius,
    and return overlay tuples (x, y, panel, radius_um).
    If pixel_size_um is given, radius is returned in microns; else in pixels.
    """
    overlays: List[Tuple[int,int,int,float]] = []
    h, w = img.shape[:2]
    xs = [int((w - panel) * i / (grid - 1)) for i in range(grid)]
    ys = [int((h - panel) * j / (grid - 1)) for j in range(grid)]

    for y in ys:
        for x in xs:
            patch = img[y : y + panel, x : x + panel]
            r_px = fit_circle_radius(patch)
            r = (r_px * pixel_size_um) if pixel_size_um else r_px
            overlays.append((x, y, panel, r))

    return overlays


class TiltDialog(QDialog):
    def __init__(self,
                 title: str,
                 img: np.ndarray,
                 plane: Optional[Tuple[float,float,float]] = None,
                 img_shape: Optional[Tuple[int,int]]    = None,
                 pixel_size_um: float                   = 1.0,
                 overlays: Optional[List[Tuple]]        = None,
                 parent=None):
        super().__init__(parent)
        self.setWindowTitle(title)
        self.pixel_size_um = pixel_size_um

        # ––––– Create the view and load the image –––––
        self.view = PreviewPane()
        self.view.load_numpy(img)
        if overlays:
            self.view.set_overlay(overlays)

        # ––––– Corner tilt table –––––
        table = None
        if plane and img_shape:
            a, b, c = plane
            H, W = img_shape
            cx, cy = W/2, H/2
            corners = {
                "Top Left":    (0,   0),
                "Top Right":   (W,   0),
                "Bottom Left": (0,   H),
                "Bottom Right":(W,   H),
            }
            rows = []
            corner_deltas = []
            for name,(x,y) in corners.items():
                delta = a*(x - cx) + b*(y - cy)
                corner_deltas.append(delta)

            min_d, max_d = min(corner_deltas), max(corner_deltas)

            # 2) now build a more meaningful label:
            range_label = QLabel(f"Tilt span: {min_d:.1f} µm … {max_d:.1f} µm")            
            for name, (x, y) in corners.items():
                # how far above/below the center plane
                delta = a*(x - cx) + b*(y - cy)
                rows.append((name, f"{delta:.1f}"))

            table = QTableWidget(len(rows), 2, self)
            table.setHorizontalHeaderLabels(["Corner", "Δ µm"])
            # hide the vertical header
            table.verticalHeader().setVisible(False)
            for i, (name, val) in enumerate(rows):
                table.setItem(i, 0, QTableWidgetItem(name))
                table.setItem(i, 1, QTableWidgetItem(val))
            table.resizeColumnsToContents()

        # ––––– Layout everything –––––
        layout = QVBoxLayout(self)
        layout.addWidget(self.view,        1)  # stretch = 1
        layout.addWidget(range_label,     0)  # stretch = 0
        if table:
            layout.addWidget(table,       0)
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        layout.addWidget(close_btn,       0)

        self.view.fit_to_view()

def compute_fwhm_heatmap_full(
    img: np.ndarray,
    pixel_scale: float,
    thresh_sigma: float = 5.0
) -> np.ndarray:
    """
    1) Detect stars with SEP, measure fwhm_um = 2*a*pixel_scale
    2) Interpolate fwhm_um onto the full H×W grid with cubic+nearest
    3) Normalize to [0..1] and return that heatmap
    """
    gray = img.mean(axis=2).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
    H, W = gray.shape
    data = np.ascontiguousarray(gray, dtype=np.float32)
    bkg  = sep.Background(data)
    objs = sep.extract(data - bkg.back(), thresh=thresh_sigma, err=bkg.globalrms)
    if objs is None or len(objs) < 5:
        return np.zeros((H,W),dtype=float)

    x = objs['x']; y = objs['y']
    fwhm_um = 2.0 * objs['a'] * pixel_scale

    # create interpolation grid
    grid_x, grid_y = np.meshgrid(np.arange(W), np.arange(H))
    points = np.vstack([x, y]).T

    # first cubic, then nearest for NaNs
    heat = griddata(points, fwhm_um, (grid_x, grid_y), method='cubic')
    mask = np.isnan(heat)
    if mask.any():
        heat[mask] = griddata(points, fwhm_um, (grid_x, grid_y), method='nearest')[mask]

    # normalize
    mn, mx = heat.min(), heat.max()
    return (heat - mn)/max(mx-mn,1e-9)



def fit_2d_poly(x, y, z, deg=2, sigma_clip=3.0, max_iter=3):
    """
    Fit z(x,y) = Σ_{i+j≤deg} c_{ij} x^i y^j
    by linear least squares + sigma-clipping.
    Returns the flattened coeff array.
    """
    # Build list of (i,j) exponents
    exps = [(i, j) for total in range(deg+1)
                  for i in range(total+1)
                  for j in [total - i]]
    # Design matrix
    A = np.vstack([ (x**i)*(y**j) for (i,j) in exps ]).T  # shape (N,len(exps))
    mask = np.ones_like(z, bool)

    for _ in range(max_iter):
        sol, *_ = np.linalg.lstsq(A[mask], z[mask], rcond=None)
        zfit    = A.dot(sol)
        resid   = z - zfit
        std     = np.std(resid[mask])
        newm    = np.abs(resid) < sigma_clip*std
        if newm.sum() == mask.sum():
            break
        mask = newm

    return sol, exps

def eval_2d_poly(sol, exps, X, Y):
    """
    Evaluate the polynomial with coeffs sol and exponents exps
    on a full grid X,Y.
    """
    Z = np.zeros_like(X, float)
    for c,(i,j) in zip(sol, exps):
        Z += c * (X**i) * (Y**j)
    return Z

def compute_fwhm_surface(img, pixel_scale, thresh_sigma=5.0, deg=3):
    # grayscale
    gray = img.mean(axis=2).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
    H, W = gray.shape
    data = np.ascontiguousarray(gray, np.float32)
    bkg  = sep.Background(data)
    stars = sep.extract(data - bkg.back(), thresh=thresh_sigma, err=bkg.globalrms)
    if stars is None or len(stars)<10:
        return np.zeros((H,W), float)

    x = stars['x']; y = stars['y']
    fwhm_um = 2.0 * stars['a'] * pixel_scale

    # 1) fit
    sol, exps = fit_2d_poly(x, y, fwhm_um, deg=deg)

    # 2) evaluate
    Y, X     = np.mgrid[0:H, 0:W]
    surf     = eval_2d_poly(sol, exps, X, Y)

    # 3) normalize
    mn, mx = surf.min(), surf.max()
    heat = (surf - mn)/max(mx-mn,1e-9)
    return heat, (mn, mx)


def compute_eccentricity_surface(
    img: np.ndarray,
    pixel_scale: float,
    thresh_sigma: float = 5.0,
    deg: int = 3
) -> Tuple[np.ndarray, Tuple[float,float]]:
    """
    1) SEP → x,y,a,b
    2) e = clip(1 - b/a)
    3) Fit e(x,y) with a 2D poly of degree 'deg' + sigma-clip
    4) Evaluate on full H×W grid, normalize to [0..1]
    """
    gray = img.mean(axis=2).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
    H, W = gray.shape
    data = np.ascontiguousarray(gray, np.float32)
    bkg  = sep.Background(data)
    stars = sep.extract(data - bkg.back(), thresh=thresh_sigma, err=bkg.globalrms)
    if stars is None or len(stars)<6:
        return np.zeros((H,W),dtype=float), (0.0, 0.0)

    x = stars['x']; y = stars['y']
    a = stars['a']; b = stars['b']
    e = np.clip(1.0 - b/a, 0.0, 1.0)
    e_min, e_max = float(e.min()), float(e.max())

    # fit polynomial
    sol, exps = fit_2d_poly(x, y, e, deg=deg)
    Y, X = np.mgrid[0:H,0:W]
    surf = eval_2d_poly(sol, exps, X, Y)

    mn, mx = surf.min(), surf.max()
    norm = (surf - mn)/max(mx-mn,1e-9)
    return norm, (e_min, e_max)


def compute_orientation_surface(
    img: np.ndarray,
    thresh_sigma: float = 5.0,
    deg: int = 1,            # for pure tilt a plane is enough
    sigma_clip: float = 3.0,
    max_iter: int = 3
) -> Tuple[np.ndarray, Tuple[float,float]]:
    """
    Fits a smooth orientation surface θ(x,y) via circular least squares.

    Returns
    -------
    norm_hue : H×W array
      Hue = (θ_fit + π/2)/π in [0..1], ready for display.
    (h_min, h_max) :
      min/max of the raw hue samples at star positions.
    """
    # → 1) make a 2D grayscale
    gray = img.mean(axis=2).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
    H, W = gray.shape

    # → 2) SEP detect
    data = np.ascontiguousarray(gray, np.float32)
    bkg  = sep.Background(data)
    stars = sep.extract(data - bkg.back(), thresh=thresh_sigma, err=bkg.globalrms)
    if stars is None or len(stars) < 6:
        return np.zeros((H, W), dtype=float), (0.0, 0.0)

    x     = stars['x']
    y     = stars['y']
    theta = stars['theta']  # in radians

    # → 3) form double‐angle sine/cosine
    s = np.sin(2*theta)
    c = np.cos(2*theta)

    # compute raw hue range for legend
    # compute **actual** θ range for legend (in radians)
    theta_min, theta_max = float(theta.min()), float(theta.max())

    # → 4) build design matrix for deg‐th 2D poly
    exps = [(i,j) for total in range(deg+1)
                  for i in range(total+1)
                  for j in [total-i]]
    A    = np.vstack([ (x**i)*(y**j) for (i,j) in exps ]).T  # shape (N, M)

    # → 5) sigma‐clip loops on residual length
    mask = np.ones_like(s, bool)
    for _ in range(max_iter):
        sol_s, *_ = np.linalg.lstsq(A[mask], s[mask], rcond=None)
        sol_c, *_ = np.linalg.lstsq(A[mask], c[mask], rcond=None)
        fit_s = A.dot(sol_s)
        fit_c = A.dot(sol_c)
        resid = np.hypot(s - fit_s, c - fit_c)
        std   = np.std(resid[mask])
        newm  = resid < sigma_clip*std
        if newm.sum() == mask.sum():
            break
        mask = newm

    # → 6) evaluate both polys on the full image grid
    Y, X = np.mgrid[0:H, 0:W]
    surf_s = sum(coeff*(X**i)*(Y**j) for coeff,(i,j) in zip(sol_s, exps))
    surf_c = sum(coeff*(X**i)*(Y**j) for coeff,(i,j) in zip(sol_c, exps))

    # → 7) recover the smooth θ_fit and map to hue [0..1]
    theta_fit = 0.5 * np.arctan2(surf_s, surf_c)       # in [−π/2..π/2]
    hue       = (theta_fit + np.pi/2) / np.pi          # now [0..1]

    return hue, (theta_min, theta_max)

class SurfaceDialog(QDialog):
    def __init__(self, title, heatmap, vmin, vmax, units:str="", cmap="gray", parent=None):
        super().__init__(parent)
        self.setWindowTitle(title)

        # image
        # image (apply the chosen colormap if it’s a 2D heatmap,
        # and load RGB directly if it’s already color)
        from matplotlib import cm
        import matplotlib.pyplot as plt

        view = PreviewPane()
        if heatmap.ndim == 2:
            # 1) map to RGBA via colormap
            cmap_obj = cm.get_cmap(cmap)
            rgba = cmap_obj(heatmap)            # shape H×W×4, floats 0–1
            rgb  = (rgba[...,:3] * 255).astype(np.uint8)
            view.load_numpy(rgb)
        else:
            # assume already float32 [0..1] RGB or uint8 RGB
            view.load_numpy(heatmap)
        view.fit_to_view()

        # colorbar pixmap
        cb = self._make_colorbar(cmap, vmin, vmax, units)
        lbl_cb = QLabel()
        lbl_cb.setPixmap(cb)

        # layout
        h = QHBoxLayout()
        h.addWidget(view, 1)
        h.addWidget(lbl_cb, 0)

        btn = QPushButton("Close")
        btn.clicked.connect(self.accept)
        lbl_span = QLabel(f"Span: {vmin:.2f} … {vmax:.2f} {units}")

        v = QVBoxLayout(self)
        v.addLayout(h)
        v.addWidget(lbl_span)
        v.addWidget(btn)

    def _make_colorbar(self, cmap_name, vmin, vmax, units):
        # build a 256×20 gradient in RGBA
        import numpy as np
        import matplotlib.pyplot as plt
        from matplotlib import cm
        grad = np.linspace(0,1,256)[:,None]
        bar  = cm.get_cmap(cmap_name)(grad)
        bar  = (bar[:,:,:3]*255).astype(np.uint8)
        # make a QImage
        H,W,_ = bar.shape
        img = QImage(bar.data, 1, 256, 3*1, QImage.Format.Format_RGB888)
        # rotate to vertical
        return QPixmap.fromImage(img.mirrored(False, True).scaled(20,256))

def distortion_vectors_sip(x_pix, y_pix, sip, pixel_size_um):
    """
    Evaluate the SIP Δ‐pixels at the given star positions,
    return (dx_um, dy_um) and also the raw dx_pix,dy_pix arrays.
    """
    A = sip.a
    B = sip.b
    order = A.shape[0] - 1

    # pull off CRPIX so u,v are relative to the SIP origin
    crpix1, crpix2 = sip.forward_origin   # equivalent to wcs.wcs.crpix
    u = x_pix - crpix1
    v = y_pix - crpix2

    dx_pix = np.zeros_like(u)
    dy_pix = np.zeros_like(u)

    # vectorized polynomial evaluation
    for i in range(order+1):
        for j in range(order+1-i):
            a_ij = A[i, j]
            b_ij = B[i, j]
            if a_ij:
                dx_pix += a_ij * (u**i) * (v**j)
            if b_ij:
                dy_pix += b_ij * (u**i) * (v**j)

    dx_um = dx_pix * pixel_size_um
    dy_um = dy_pix * pixel_size_um

    return dx_pix, dy_pix, dx_um, dy_um

def distortion_vectors(img: np.ndarray,
                       sip_meta: dict,
                       pixel_size_um: float):
    """
    1) SEP detect stars → x_pix,y_pix
    2) extract A,B,crpix from sip_meta
    3) eval dx_pix,dy_pix → dx_um,dy_um
    4) return overlays
    """
    # 1) detect stars
    gray = img.mean(-1).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
    data = np.ascontiguousarray(gray, np.float32)
    bkg  = sep.Background(data)
    stars = sep.extract(data - bkg.back(),
                        thresh=5.0, err=bkg.globalrms)
    if stars is None:
        return []

    x_pix = stars['x']; y_pix = stars['y']

    # 2) pull SIP from meta (now robust to missing A_ORDER)
    A, B, crpix1, crpix2 = extract_sip_from_meta(sip_meta)

    # 3) vector‐polynomial evaluation
    u = x_pix - crpix1
    v = y_pix - crpix2
    dx_pix = np.zeros_like(u)
    dy_pix = np.zeros_like(u)
    order  = A.shape[0] - 1
    for i in range(order+1):
        for j in range(order+1-i):
            a_ij = A[i, j]
            b_ij = B[i, j]
            if a_ij:
                dx_pix += a_ij * (u**i) * (v**j)
            if b_ij:
                dy_pix += b_ij * (u**i) * (v**j)

    # 4) to microns & pack
    dx_um = dx_pix * pixel_size_um
    dy_um = dy_pix * pixel_size_um

    overlays = []
    for x,y,dx,dy in zip(x_pix, y_pix, dx_um, dy_um):
        ang    = math.atan2(dy, dx)
        length = math.hypot(dx, dy)
        overlays.append((int(x), int(y), ang, length))
    return overlays

def eval_sip(A, B, u, v):
    """
    Vectorized SIP evaluation: given coefficient arrays A,B and 
    coordinate offsets u=x-crpix1, v=y-crpix2, returns dx_pix, dy_pix.
    """
    dx = np.zeros_like(u)
    dy = np.zeros_like(u)
    order = A.shape[0]-1
    for i in range(order+1):
        for j in range(order+1-i):
            a = A[i, j]
            b = B[i, j]
            if a:
                dx += a * (u**i)*(v**j)
            if b:
                dy += b * (u**i)*(v**j)
    return dx, dy

def extract_sip_from_meta(sm: dict):
    """
    Given the metadata dict that ASTAP wrote into your slot,
    pull out the forward SIP polynomials A and B (and the reference pixel).
    We no longer rely on A_ORDER existing; we infer it from the A_i_j keys.
    """
    # 1) find all the A_i_j keys that actually made it into sm
    a_keys = [k for k in sm.keys() if re.match(r"A_\d+_\d+", k)]
    if not a_keys:
        raise ValueError("No SIP A_?_? coefficients found in metadata!")

    # 2) parse out all the (i,j) pairs and infer the polynomial order as max(i+j)
    pairs = [tuple(map(int, k.split("_")[1:])) for k in a_keys]
    order = max(i+j for i,j in pairs)

    # 3) allocate forward‐SIP coefficient arrays
    A = np.zeros((order+1, order+1), float)
    B = np.zeros((order+1, order+1), float)

    for i, j in pairs:
        A[i, j] = float(sm[f"A_{i}_{j}"])
        B[i, j] = float(sm[f"B_{i}_{j}"])

    # 4) pull the reference pixel
    crpix1 = float(sm["CRPIX1"])
    crpix2 = float(sm["CRPIX2"])

    return A, B, crpix1, crpix2

class DistortionGridDialog(QDialog):
    def __init__(self,
                img: np.ndarray,
                sip_meta: dict,
                arcsec_per_pix: float,
                n_grid_lines: int = 10,
                amplify: float    = 20.0,
                parent=None):
        super().__init__(parent)
        self.setWindowTitle("Astrometric Distortion & Histogram")

        # — 1) detect stars —
        gray = img.mean(-1).astype(np.float32) if img.ndim==3 else img.astype(np.float32)
        data = np.ascontiguousarray(gray, np.float32)
        bkg  = sep.Background(data)
        stars = sep.extract(data - bkg.back(), thresh=5.0, err=bkg.globalrms)
        if stars is None or len(stars) < 10:
            QMessageBox.warning(self, "Distortion", "Not enough stars found.")
            self.reject()
            return

        x_pix = stars['x']
        y_pix = stars['y']

        # — 2) extract SIP A,B and reference pixel from metadata dict —
        A, B, crpix1, crpix2 = extract_sip_from_meta(sip_meta)

        # — 4) per-star residuals in pixels → arc-sec —
        u_star = x_pix - crpix1
        v_star = y_pix - crpix2
        dx_star_pix, dy_star_pix = eval_sip(A, B, u_star, v_star)
        disp_star_pix    = np.hypot(dx_star_pix, dy_star_pix)
        disp_star_arcsec = disp_star_pix * arcsec_per_pix

        # — 5) full‐image warp maps (pixels) for drawing grid —
        H, W = data.shape
        YY, XX = np.mgrid[0:H, 0:W]
        U = XX - crpix1
        V = YY - crpix2
        DX_pix, DY_pix = eval_sip(A, B, U, V)
        DX = DX_pix * amplify
        DY = DY_pix * amplify

        # — 6) build the distortion grid scene —
        scene = QGraphicsScene(self)
        scene.setBackgroundBrush(QColor(30,30,30))
        pen  = QPen(QColor(255,100,100), 1)
        label_font = QFont("Arial", 12, QFont.Weight.Bold)

        # title above the grid
        title = QLabel("Astrometric Distortion Grid")
        title.setFont(QFont("Arial", 16, QFont.Weight.Bold))
        title.setAlignment(Qt.AlignmentFlag.AlignCenter)
        title.setStyleSheet("color: white;")

        # draw horizontal + vertical lines
        for i in range(n_grid_lines+1):
            y0  = i*(H-1)/n_grid_lines
            xs  = np.linspace(0, W-1, 200)
            ys  = np.full_like(xs, y0)
            xi  = np.clip(xs.astype(int), 0, W-1)
            yi  = np.clip(ys.astype(int), 0, H-1)
            warped = np.column_stack([ xs + DX[yi,xi], ys + DY[yi,xi] ])
            path = QPainterPath(QPointF(*warped[0]))
            for px,py in warped[1:]:
                path.lineTo(QPointF(px,py))
            scene.addPath(path, pen)

        for j in range(n_grid_lines+1):
            x0  = j*(W-1)/n_grid_lines
            ys  = np.linspace(0, H-1, 200)
            xs  = np.full_like(ys, x0)
            xi  = np.clip(xs.astype(int), 0, W-1)
            yi  = np.clip(ys.astype(int), 0, H-1)
            warped = np.column_stack([ xs + DX[yi,xi], ys + DY[yi,xi] ])
            path = QPainterPath(QPointF(*warped[0]))
            for px,py in warped[1:]:
                path.lineTo(QPointF(px,py))
            scene.addPath(path, pen)

        # annotate each grid‐intersection
        for i in range(n_grid_lines+1):
            for j in range(n_grid_lines+1):
                y0 = i*(H-1)/n_grid_lines
                x0 = j*(W-1)/n_grid_lines
                xi, yi = int(round(x0)), int(round(y0))

                # local distortion in pixels → arcsec
                d_pix    = math.hypot(DX_pix[yi, xi], DY_pix[yi, xi])
                d_arcsec = d_pix * arcsec_per_pix

                px = x0 + DX[yi, xi]
                py = y0 + DY[yi, xi]

                txt = QGraphicsTextItem(f"{d_arcsec:.1f}\"")
                txt.setFont(label_font)
                txt.setScale(5.0)
                txt.setDefaultTextColor(QColor(200,200,200))
                txt.setPos(px + 4, py + 4)
                scene.addItem(txt)

        view = QGraphicsView(scene)
        view.setRenderHint(QPainter.RenderHint.Antialiasing)
        view.fitInView(scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)

        # pack title + view vertically
        left_layout = QVBoxLayout()
        left_layout.addWidget(title)
        left_layout.addWidget(view, 1)

        # — 7) histogram of per-star residuals (arcsec) —
        fig    = Figure(figsize=(4,4))
        canvas = FigureCanvas(fig)
        ax     = fig.add_subplot(111)
        ax.hist(disp_star_arcsec, bins=30, edgecolor='black')
        ax.set_xlabel("Distortion (″)")
        ax.set_ylabel("Number of stars")
        ax.set_title("Residual histogram")
        fig.tight_layout()

        # side-by-side layout
        hl = QHBoxLayout()
        hl.addLayout(left_layout, 1)
        hl.addWidget(canvas, 1)

        # close button
        btn = QPushButton("Close")
        btn.clicked.connect(self.accept)

        # final
        v = QVBoxLayout(self)
        v.addLayout(hl)
        v.addWidget(btn, 0)

def make_header_from_xisf_meta(meta: dict) -> fits.Header:
    """
    meta is the dict you returned as original_header for XISF:
      {
        'file_meta': ...,
        'image_meta': ...,
        'astrometry': {
           'CD1_1', 'CD1_2', 'CD2_1', 'CD2_2',
           'crpix1', 'crpix2',
           'sip': {'order', 'A', 'B'}
        }
      }
    This builds a real fits.Header with WCS+SIP cards.
    """
    hdr = fits.Header()
    ast = meta['astrometry']

    # WCS linear part
    hdr['CTYPE1'] = 'RA---TAN-SIP'
    hdr['CTYPE2'] = 'DEC--TAN-SIP'
    hdr['CRPIX1'] = ast['crpix1']
    hdr['CRPIX2'] = ast['crpix2']
    hdr['CD1_1']  = ast['CD1_1']
    hdr['CD1_2']  = ast['CD1_2']
    hdr['CD2_1']  = ast['CD2_1']
    hdr['CD2_2']  = ast['CD2_2']

    # SIP coefficients
    sip = ast['sip']
    order = sip['order']
    hdr['A_ORDER'] = order
    hdr['B_ORDER'] = order

    for i in range(order+1):
        for j in range(order+1-i):
            hdr[f'A_{i}_{j}'] = float(sip['A'][i,j])
            hdr[f'B_{i}_{j}'] = float(sip['B'][i,j])

    # If you have file_meta FITSKeywords you can also copy those here:
    # for kw, vals in meta['file_meta'].get('FITSKeywords', {}).items():
    #     for entry in vals:
    #         hdr[kw] = entry['value']

    return hdr

def plate_solve_current_image(image_manager, settings, parent=None):
    """
    Plate-solve the current slot image *including* SIP terms,
    and return the updated metadata dict (with all the A_*, B_* SIP cards).
    """

    # 1) grab pixel data + original header
    arr, meta = image_manager.get_current_image_and_metadata()
    orig_hdr  = meta.get("original_header", fits.Header())


    # if it's our XISF‐dict, turn it into a real Header
    if isinstance(orig_hdr, dict) and 'astrometry' in orig_hdr:
        orig_hdr = make_header_from_xisf_meta(orig_hdr)

    # 2) dump to a temp FITS so ASTAP can read & inject SIP
    tmp = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
    tmpname = tmp.name; tmp.close()
    fits.writeto(tmpname, arr.astype(np.float32), orig_hdr, overwrite=True)

    # 3) run ASTAP in “slot-only” mode so it updates meta in place
    solver            = PlateSolver(settings, parent=parent)
    solver._from_slot = True
    solver._slot_meta = meta
    solver.image_path = tmpname

    if not solver.run_astap(tmpname):
        solver.run_astrometry_net(tmpname)

    # 4) grab the updated metadata dict
    slot       = image_manager.current_slot
    solved_meta = image_manager._metadata[slot]

    # 5) clean up and return
    os.remove(tmpname)
    return solved_meta

class ImagePeekerDialog(QDialog):
    def __init__(self, parent=None, image_manager=None, settings=None):
        super().__init__(parent)
        self.setWindowTitle("Image Peaker")
        self.image_manager = image_manager
        self.settings = settings

        self._build_ui()
        self._connect_signals()

    def _build_ui(self):
        # left: parameter controls
        params = QGroupBox("Grid parameters")
        params.setMinimumWidth(180)
        params.setSizePolicy(QSizePolicy.Policy.Fixed, QSizePolicy.Policy.Preferred)        
        gl = QGridLayout(params)
        # — Grid size
        # — Grid size (use our global CustomSpinBox)
        gl.addWidget(QLabel("Grid size:"), 0, 0)
        self.grid_spin = CustomSpinBox(minimum=2, maximum=10, initial=3, step=1)
        gl.addWidget(self.grid_spin, 0, 1)

        # — Panel size + live value
        gl.addWidget(QLabel("Panel size:"), 1, 0)
        panel_row = QHBoxLayout()
        self.panel_slider = QSlider(Qt.Orientation.Horizontal)
        self.panel_slider.setRange(32, 512)
        self.panel_slider.setValue(256)
        # numeric label:
        self.panel_value_label = QLabel(str(self.panel_slider.value()))
        self.panel_value_label.setFixedWidth(40)
        panel_row.addWidget(self.panel_slider, 1)
        panel_row.addWidget(self.panel_value_label)
        gl.addLayout(panel_row, 1, 1)

        # — Separation + live value
        gl.addWidget(QLabel("Separation:"), 2, 0)
        sep_row = QHBoxLayout()
        self.sep_slider = QSlider(Qt.Orientation.Horizontal)
        self.sep_slider.setRange(0, 50)
        self.sep_slider.setValue(4)
        self.sep_value_label = QLabel(str(self.sep_slider.value()))
        self.sep_value_label.setFixedWidth(40)
        sep_row.addWidget(self.sep_slider, 1)
        sep_row.addWidget(self.sep_value_label)
        gl.addLayout(sep_row, 2, 1)

        # — Pixel size
        gl.addWidget(QLabel("Pixel size (µm):"), 3, 0)
        self.pixel_size_input = QDoubleSpinBox()
        self.pixel_size_input.setRange(0.01, 50.0)
        self.pixel_size_input.setSingleStep(0.1)
        # try to prefill from settings or leave at a sane default:
        px = self.settings.value("pixel_size_um", 4.8, type=float)
        self.pixel_size_input.setValue(px)
        gl.addWidget(self.pixel_size_input, 3, 1)

        # — Focal length
        gl.addWidget(QLabel("Focal length (mm):"), 4, 0)
        self.focal_length_input = QDoubleSpinBox()
        self.focal_length_input.setRange(10.0, 5000.0)
        self.focal_length_input.setSingleStep(10.0)
        fl = self.settings.value("focal_length_mm", 800.0, type=float)
        self.focal_length_input.setValue(fl)
        gl.addWidget(self.focal_length_input, 4, 1)

        # — Aperture diameter —
        gl.addWidget(QLabel("Aperture (mm):"), 5, 0)
        self.aperture_input = QDoubleSpinBox()
        self.aperture_input.setRange(1, 5000)
        self.aperture_input.setSingleStep(1)
        self.aperture_input.setValue(
            self.settings.value("aperture_mm", 100.0, type=float)
        )
        gl.addWidget(self.aperture_input, 5, 1)

        # right: the preview pane
        self.preview_pane = PreviewPane()
        analysis_label      = QLabel("Analysis:")
        self.analysis_combo = QComboBox()
        self.analysis_combo.addItems([
        "None",
        "Tilt Analysis",
        "Focal Plane Analysis",
        "Astrometric Distortion Analysis",
        ])
        self.analysis_combo.currentTextChanged.connect(self._run_analysis)

        combo_layout = QHBoxLayout()
        combo_layout.addWidget(analysis_label)
        combo_layout.addWidget(self.analysis_combo)
        combo_layout.addStretch(1)

        # buttons
        btns = QHBoxLayout()
        btns.addStretch(1)
        self.ok_btn     = QPushButton("Save Settings && Exit")
        self.cancel_btn = QPushButton("Exit without Saving")
        btns.addWidget(self.ok_btn)
        btns.addWidget(self.cancel_btn)

        # main layout
        main_layout = QHBoxLayout(self)
        main_layout.addWidget(params)  # your existing “params” widget

        right_layout = QVBoxLayout()
        right_layout.addLayout(combo_layout)      # first the combo
        right_layout.addWidget(self.preview_pane, 1)  # then the preview pane (expands)
        right_layout.addLayout(btns)              # then the buttons

        main_layout.addLayout(right_layout, 1)    # make it stretchable on the right

        self.setLayout(main_layout)



    def accept(self):
        self.settings.setValue("pixel_size_um",   self.pixel_size_input.value())
        self.settings.setValue("focal_length_mm", self.focal_length_input.value())
        self.settings.setValue("aperture_mm",     self.aperture_input.value())
        super().accept()

    def _connect_signals(self):
        self.grid_spin.valueChanged.connect(self._refresh_mosaic)
        self.panel_slider.valueChanged.connect(self._refresh_mosaic)
        self.sep_slider.valueChanged.connect(self._refresh_mosaic)
        self.panel_slider.valueChanged.connect(self._on_panel_changed)
        self.sep_slider.valueChanged.connect(self._on_sep_changed)        
        self.ok_btn.clicked.connect(self.accept)
        self.cancel_btn.clicked.connect(self.reject)

        # build once on show
        QTimer.singleShot(0, self._refresh_mosaic)

    def _run_analysis(self, *_):
        mode = self.analysis_combo.currentText()
        arr, meta = self.image_manager.get_current_image_and_metadata()
        if arr is None:
            return

        ps = meta.get("pixel_size_um", self.pixel_size_input.value())
        fl = meta.get("focal_length_mm", self.focal_length_input.value())
        ap = self.aperture_input.value()
        thresh = meta.get("snr_threshold", 5.0)

        if mode == "Tilt Analysis":
            # define a simple calibration: defocus_um = fwhm_px * pixel_size_um
            def fwhm_to_defocus_um(fwhm_px: np.ndarray) -> np.ndarray:
                return fwhm_px * ps

            norm_plane, (a,b,c), (H,W) = tilt_analysis(
                arr,
                pixel_size_um    = ps,
                focal_length_mm  = fl,
                aperture_mm      = ap,
                sigma_clip       = 2.5,
                thresh_sigma     = meta.get("snr_threshold",5.0)
            )
            dlg = TiltDialog(
            title       = "Sensor Tilt (µm)",
            img         = norm_plane,
            plane       = (a,b,c),
            img_shape   = (H,W),
            pixel_size_um = ps,
            parent      = self
            )
            dlg.show()


        elif mode == "Focal Plane Analysis":
            # -- FWHM surface (units µm) --
            fwhm_heat, (mn_f, mx_f) = compute_fwhm_surface(arr, ps, thresh_sigma=thresh, deg=3)
            fwhm_dlg = SurfaceDialog(
                title       = "FWHM Heatmap",
                heatmap     = fwhm_heat,
                vmin        = mn_f,
                vmax        = mx_f,
                units       = "µm",
                cmap        = "viridis",
                parent      = self
            )
            fwhm_dlg.show()

            # 2) Eccentricity magnitude
            ecc_heat, (mn_e, mx_e) = compute_eccentricity_surface(arr, ps, thresh_sigma=thresh, deg=3)
            SurfaceDialog(
                title   = "Eccentricity Map",
                heatmap = ecc_heat,
                vmin    = mn_e,
                vmax    = mx_e,
                units   = "e = 1−b/a",
                cmap    = "magma",
                parent  = self
            ).show()

            # 3) Orientation (phase)
            ori_heat, (mn_o, mx_o) = compute_orientation_surface(arr, thresh_sigma=thresh, deg=3)
            SurfaceDialog(
                title   = "Orientation Map",
                heatmap = ori_heat,
                vmin    = mn_o,
                vmax    = mx_o,
                units   = "rad",
                cmap    = "hsv",
                parent  = self
            ).show()

        elif mode == "Astrometric Distortion Analysis":
            arr, meta = self.image_manager.get_current_image_and_metadata()
            hdr = meta.get("original_header", None)

            # if we don’t already have SIP in original_header, plate‑solve
            if hdr is None or "A_0_0" not in hdr:
                wcs = plate_solve_current_image(
                    self.image_manager,
                    self.settings,
                    parent=self
                )
                # after solving, re‑grab the updated header
                _, meta = self.image_manager.get_current_image_and_metadata()
                hdr = meta.get("original_header", None)

            if hdr is None or "A_0_0" not in hdr:
                QMessageBox.warning(
                    self,
                    "No Distortion Data",
                    "Plate solve completed, but no SIP distortion matrices were found.\n\n"
                    "For best results please install ASTAP with the D80 catalog, then retry."
                )
                return

            # 2) Compute the overlays directly from the ASTAP‑injected SIP
            

            # 3) Show your new dialog
            try:
                arcsec_per_pix = abs(hdr["CDELT1"]) * 3600.0
            except KeyError:
                try:
                    cd11 = hdr["CD1_1"]
                    cd12 = hdr.get("CD1_2", 0.0)
                    cd21 = hdr.get("CD2_1", 0.0)
                    cd22 = hdr["CD2_2"]
                    scale_deg = np.sqrt(abs(cd11 * cd22 - cd12 * cd21))
                    arcsec_per_pix = scale_deg * 3600.0
                except KeyError:
                    QMessageBox.critical(self, "WCS Error", "Cannot determine pixel scale from FITS header.")
                    return

            dlg = DistortionGridDialog(
                img              = arr,
                sip_meta         = hdr,
                arcsec_per_pix   = arcsec_per_pix,  # pass this directly
                n_grid_lines     = 10,
                amplify          = 60.0,
                parent           = self
            )
            dlg.show()
    
        else:
            self._refresh_mosaic()
            
    def _on_panel_changed(self, v):
        self.panel_value_label.setText(str(v))
        self._refresh_mosaic()

    def _on_sep_changed(self, v):
        self.sep_value_label.setText(str(v))
        self._refresh_mosaic()

    def _update_sep_color_button(self):
        # show current color
        pix = QIcon().pixmap(16,16)
        pix.fill(self._sep_color)
        self.sep_color_btn.setIcon(QIcon(pix))

    def _choose_sep_color(self):
        col = QColorDialog.getColor(self._sep_color, self, "Choose separation color")
        if col.isValid():
            self._sep_color = col
            self._update_sep_color_button()

    def _refresh_mosaic(self):
        # 1) Grab the current numpy image from your manager
        img_np, metadata = self.image_manager.get_current_image_and_metadata()
        if img_np is None:
            return

        # 2) Turn it into a QImage
        try:
            qimg = self._to_qimage(img_np)
        except Exception as e:
            QMessageBox.warning(self, "Conversion Error", f"Could not convert image to display: {e}")
            return

        # 3) Build your mosaic from that QImage
        n   = self.grid_spin.value
        ps  = self.panel_slider.value()
        sep = self.sep_slider.value()
        sep_col = QColor(0,0,0)   # or store user‐chosen color

        mosaic = self._build_mosaic(qimg, n, ps, sep, sep_col)

        # 4) Send it into your scrollable PreviewPane
        self.preview_pane.load_qimage(mosaic)

    def _on_ok(self):
        # user clicked OK → generate & display the mosaic
        n        = self.grid_spin.value
        panel_sz = self.panel_slider.value()
        sep      = self.sep_slider.value()
        sep_col  = self._sep_color

        # fetch the currently loaded image (you’ll adapt to your image_manager API)
        img = self.image_manager.current_qimage()
        if img is None:
            QMessageBox.warning(self, "No image", "No image loaded to peek at!")
            return

        mosaic = self._build_mosaic(img, n, panel_sz, sep, sep_col)
        self.preview.setPixmap(QPixmap.fromImage(mosaic))
        # keep dialog open so user can tweak parameters

    def _build_mosaic(self, img, n, panel_sz, sep, sep_col):
        """
        Returns a QImage that is an n×n grid of clipped regions
        sampled evenly across img, with given panel size, separation,
        and background color.
        """
        # compute output size
        W = n*panel_sz + (n-1)*sep
        H = n*panel_sz + (n-1)*sep
        mosaic = QImage(W, H, img.format())
        painter = QPainter(mosaic)
        painter.fillRect(0,0,W,H, sep_col)

        # sample positions
        src_w, src_h = img.width(), img.height()
        # evenly spaced centers
        xs = [int((src_w - panel_sz) * i / (n-1)) for i in range(n)]
        ys = [int((src_h - panel_sz) * j / (n-1)) for j in range(n)]

        for row, y in enumerate(ys):
            for col, x in enumerate(xs):
                patch = img.copy(x, y, panel_sz, panel_sz)
                dx = col * (panel_sz + sep)
                dy = row * (panel_sz + sep)
                painter.drawImage(dx, dy, patch)

        painter.end()
        return mosaic

    def _to_qimage(self, arr: np.ndarray) -> QImage:
        """
        Convert a 2D or 3-channel H×W numpy array in [0..1] or [0..255]
        to a QImage.  Keeps the underlying buffer alive on self.
        """
        # 1) normalize dtype
        if arr.dtype in (np.float32, np.float64):
            arr8 = np.clip(arr * 255, 0, 255).astype(np.uint8)
        elif arr.dtype != np.uint8:
            arr8 = arr.astype(np.uint8)
        else:
            arr8 = arr

        h, w = arr8.shape[:2]

        # 2) dump to bytes so QImage() sees a bytes object, not a memoryview
        buf = arr8.tobytes()
        # keep a reference so Python doesn’t free it
        self._last_qimage_buffer = buf

        # 3) construct the QImage
        if arr8.ndim == 2:
            # grayscale
            bytes_per_line = w
            return QImage(buf, w, h, bytes_per_line, QImage.Format.Format_Grayscale8)

        elif arr8.ndim == 3 and arr8.shape[2] == 3:
            # RGB
            bytes_per_line = 3 * w
            return QImage(buf, w, h, bytes_per_line, QImage.Format.Format_RGB888)

        else:
            raise ValueError(f"Cannot convert array of shape {arr.shape} to QImage")


# --------------------------------------------------
# Stacking Suite
# --------------------------------------------------
class BatchSettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Set Type, Exposure, and Filter for All Files")

        layout = QVBoxLayout(self)

        # 1) IMAGETYP Combo
        type_layout = QHBoxLayout()
        type_layout.addWidget(QLabel("Image Type (IMAGETYP):"))
        self.type_combo = QComboBox()
        self.type_combo.addItems(["LIGHT", "DARK", "FLAT", "BIAS", "UNKNOWN"])
        type_layout.addWidget(self.type_combo)
        layout.addLayout(type_layout)

        # 2) Exposure Time
        exp_layout = QHBoxLayout()
        exp_layout.addWidget(QLabel("Exposure Time (seconds):"))
        self.exptime_edit = QLineEdit()
        self.exptime_edit.setText("Unknown")  # default
        exp_layout.addWidget(self.exptime_edit)
        layout.addLayout(exp_layout)

        # 3) Filter
        filt_layout = QHBoxLayout()
        filt_layout.addWidget(QLabel("Filter:"))
        self.filter_edit = QLineEdit()
        self.filter_edit.setText("None")  # default
        filt_layout.addWidget(self.filter_edit)
        layout.addLayout(filt_layout)

        # Buttons
        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("OK")
        cancel_btn = QPushButton("Cancel")
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)
        layout.addLayout(btn_layout)

        ok_btn.clicked.connect(self.accept)
        cancel_btn.clicked.connect(self.reject)

        # Final layout
        self.setLayout(layout)

    def get_values(self):
        """
        Returns (imagetyp, exptime_str, filter_str)
        after the dialog is accepted.
        """
        return (
            self.type_combo.currentText(),
            self.exptime_edit.text(),
            self.filter_edit.text()
        )

class ReferenceFrameReviewDialog(QDialog):
    def __init__(self, ref_frame_path, stats, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Reference Frame Review")
        self.ref_frame_path = ref_frame_path
        self.stats = stats  # e.g., {"star_count": 250, "eccentricity": 0.12, "mean": 0.45}
        self.autostretch_enabled = False
        self.original_image = None  # Will store the loaded image array
        self.target_median = self.stats.get("mean", 0.25)
        self.user_choice = None  # Will be set to 'use' or 'select_other'
        self.zoom_factor = 1.0
        self.current_preview_image = None  # Store the image array currently shown in preview

        # For panning functionality
        self._panning = False
        self._last_mouse_pos = QPoint()

        self.initUI()
        self.loadImageArray()  # Load the image into self.original_image
        if self.original_image is not None:
            self.updatePreview(self.original_image)  # Ensure the first image is shown
        if self.original_image is not None:
            QTimer.singleShot(0, self.zoomIn)            


    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # Create a scroll area for the preview image
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setMinimumSize(QSize(600, 400))
        self.previewLabel = QLabel("Reference Preview", self)
        self.previewLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.previewLabel)
        main_layout.addWidget(self.scrollArea)
        self.scrollArea.viewport().installEventFilter(self)
        
        # Zoom control buttons
        zoom_layout = QHBoxLayout()
        self.zoomInButton = QPushButton("Zoom In", self)
        self.zoomInButton.clicked.connect(self.zoomIn)
        zoom_layout.addWidget(self.zoomInButton)
        self.zoomOutButton = QPushButton("Zoom Out", self)
        self.zoomOutButton.clicked.connect(self.zoomOut)
        zoom_layout.addWidget(self.zoomOutButton)
        main_layout.addLayout(zoom_layout)
        
        # Stats display
        stats_text = (
            f"Star Count: {self.stats.get('star_count', 'N/A')}\n"
            f"Eccentricity: {self.stats.get('eccentricity', 'N/A'):.4f}\n"
            f"Mean: {self.stats.get('mean', 'N/A'):.4f}"
        )
        self.statsLabel = QLabel(stats_text, self)
        main_layout.addWidget(self.statsLabel)
        
        # Buttons layout for reference selection and autostretch toggle
        button_layout = QHBoxLayout()
        self.toggleAutoStretchButton = QPushButton("Enable Autostretch", self)
        self.toggleAutoStretchButton.clicked.connect(self.toggleAutostretch)
        button_layout.addWidget(self.toggleAutoStretchButton)
        
        # New button to let the user select a new reference frame file
        self.selectNewRefButton = QPushButton("Select New Reference Frame", self)
        self.selectNewRefButton.clicked.connect(self.selectNewReferenceFrame)
        button_layout.addWidget(self.selectNewRefButton)
        
        self.useRefButton = QPushButton("Use This Reference Frame", self)
        self.useRefButton.clicked.connect(self.useReference)
        button_layout.addWidget(self.useRefButton)
        
        self.selectOtherButton = QPushButton("Cancel", self)
        self.selectOtherButton.clicked.connect(self.reject)
        button_layout.addWidget(self.selectOtherButton)
        
        main_layout.addLayout(button_layout)
        self.setLayout(main_layout)
        self.zoomIn()
    
    def fitToPreview(self):
        """Calculate and set the zoom factor so that the image fills the preview area."""
        if self.original_image is None:
            return
        # Get the available size from the scroll area's viewport.
        available_size = self.scrollArea.viewport().size()
        # Determine the original image dimensions.
        if self.original_image.ndim == 2:
            orig_height, orig_width = self.original_image.shape
        elif self.original_image.ndim == 3:
            orig_height, orig_width = self.original_image.shape[:2]
        else:
            return
        # Calculate the zoom factor that will allow the image to fit.
        factor = min(available_size.width() / orig_width,
                    available_size.height() / orig_height)
        self.zoom_factor = factor
        # Choose the current preview image if available, otherwise use the original image.
        if self.current_preview_image is not None:
            image = self.current_preview_image
        else:
            image = self.original_image
        self.updatePreview(image)



    def loadImageArray(self):
        """
        Load the image from the reference frame file using the global load_image function.
        """
        image_data, header, _, _ = load_image(self.ref_frame_path)
        if image_data is not None:
            if image_data.ndim == 3 and image_data.shape[-1] == 1:
                image_data = np.squeeze(image_data, axis=-1)
            self.original_image = image_data
        else:
            QMessageBox.critical(self, "Error", "Failed to load the reference image.")
    
    def updatePreview(self, image):
        """
        Convert a given image array to a QPixmap and update the preview label.
        """
        self.current_preview_image = image
        pixmap = self.convertArrayToPixmap(image)
        if pixmap is None or pixmap.isNull():
            self.previewLabel.setText("Unable to load preview.")
        else:
            available_size = self.scrollArea.viewport().size()
            new_size = QSize(int(available_size.width() * self.zoom_factor),
                             int(available_size.height() * self.zoom_factor))
            scaled_pixmap = pixmap.scaled(new_size, Qt.AspectRatioMode.KeepAspectRatio,
                                          Qt.TransformationMode.SmoothTransformation)
            self.previewLabel.setPixmap(scaled_pixmap)
    
    def convertArrayToPixmap(self, image):
        if image is None:
            return None
        display_image = (image * 255).clip(0, 255).astype(np.uint8)
        if display_image.ndim == 2:
            h, w = display_image.shape
            bytes_per_line = w
            q_image = QImage(display_image.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)
        elif display_image.ndim == 3 and display_image.shape[2] == 3:
            h, w, _ = display_image.shape
            bytes_per_line = 3 * w
            q_image = QImage(display_image.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            return None
        return QPixmap.fromImage(q_image)
    
    def toggleAutostretch(self):
        if self.original_image is None:
            QMessageBox.warning(self, "Error", "Reference image not loaded.")
            return
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            if self.original_image.ndim == 2:
                new_image = stretch_mono_image(self.original_image, target_median=0.3,
                                               normalize=True, apply_curves=False)
            elif self.original_image.ndim == 3 and self.original_image.shape[2] == 3:
                new_image = stretch_color_image(self.original_image, target_median=0.3,
                                                linked=False, normalize=True, apply_curves=False)
            else:
                new_image = self.original_image
            self.toggleAutoStretchButton.setText("Disable Autostretch")
        else:
            new_image = self.original_image
            self.toggleAutoStretchButton.setText("Enable Autostretch")
        self.updatePreview(new_image)
    
    def zoomIn(self):
        self.zoom_factor *= 1.2
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
    
    def zoomOut(self):
        self.zoom_factor /= 1.2
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
    
    def eventFilter(self, source, event):
        if source is self.scrollArea.viewport():
            if event.type() == QEvent.Type.Wheel:
                if event.angleDelta().y() > 0:
                    self.zoomIn()
                else:
                    self.zoomOut()
                return True
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = True
                    self._last_mouse_pos = event.pos()
                    self.scrollArea.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                    return True
            if event.type() == QEvent.Type.MouseMove:
                if self._panning:
                    delta = event.pos() - self._last_mouse_pos
                    self._last_mouse_pos = event.pos()
                    h_bar = self.scrollArea.horizontalScrollBar()
                    v_bar = self.scrollArea.verticalScrollBar()
                    h_bar.setValue(h_bar.value() - delta.x())
                    v_bar.setValue(v_bar.value() - delta.y())
                    return True
            if event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = False
                    self.scrollArea.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                    return True
        return super().eventFilter(source, event)
    
    def resizeEvent(self, event):
        if self.current_preview_image is not None:
            self.updatePreview(self.current_preview_image)
        super().resizeEvent(event)
    
    def selectNewReferenceFrame(self):
        """Open a file dialog to select a new reference frame, update preview accordingly."""
        new_file, _ = QFileDialog.getOpenFileName(
            self,
            "Select New Reference Frame",
            "",
            "FITS Files (*.fits *.fit);;All Files (*)"
        )
        if new_file:
            self.ref_frame_path = new_file
            self.loadImageArray()          # Reload the new image
            self.updatePreview(self.original_image)  # Update the preview
            # Optionally, you could also update stats if needed.
    
    def useReference(self):
        self.user_choice = "use"
        self.accept()
    
    def selectOtherReference(self):
        self.user_choice = "select_other"
        self.reject()
    
    def getUserChoice(self):
        return self.user_choice

def bytes_available():
    vm = psutil.virtual_memory()
    # Keep a safety margin (e.g. leave 10% free)
    return int(vm.available * 0.9)


def compute_safe_chunk(height, width, N, channels, dtype, pref_h, pref_w):
    vm    = psutil.virtual_memory()
    avail = vm.free * 0.9
    bpe64 = np.dtype(dtype).itemsize      # 8 bytes
    workers = os.cpu_count() or 1

    # budget *all* float64 copies (master + per-thread)
    bytes_per_pixel = (N + workers) * channels * bpe64
    max_pixels      = int(avail // bytes_per_pixel)
    if max_pixels < 1:
        raise MemoryError("Not enough RAM for even a 1×1 tile")

    raw_side = int(math.sqrt(max_pixels))
    # **shrink by √workers to be super-safe**
    fudge    = int(math.sqrt(workers)) or 1
    safe_side = max(1, raw_side // fudge)

    # clamp to user prefs and image dims
    ch = min(pref_h, height, safe_side)
    cw = min(pref_w, width,  safe_side)

    # final area clamp
    if ch * cw > max_pixels // fudge**2:
        # extra safety: adjust cw so area ≤ max_pixels/fudge²
        cw = max(1, (max_pixels // (fudge**2)) // ch)

    if ch < 1 or cw < 1:
        raise MemoryError(f"Chunk too small after fudge: {ch}×{cw}")

    print(f"[DEBUG] raw_side={raw_side}, workers={workers} ⇒ safe_side={safe_side}")
    print(f"[DEBUG] final chunk: {ch}×{cw}")
    return ch, cw

class StackingSuiteDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Stacking Suite")
        self.setGeometry(300, 200, 800, 600)
        self.per_group_drizzle = {}
        self.manual_dark_overrides = {}  
        self.manual_flat_overrides = {}
        self.conversion_output_directory = None
        self.reg_files = {}
        self.session_tags = {}  # 🔑 file_path => session_tag (e.g., "Session1", "Blue Flats", etc.)
        self.deleted_calibrated_files = []
        self._norm_map = {}


        # QSettings for your app
        self.settings = QSettings() 

        self.star_trail_mode = self.settings.value("stacking/star_trail_mode", False, type=bool)        

        # Load or default these
        self.stacking_directory = self.settings.value("stacking/dir", "", type=str)
        self.sigma_high = self.settings.value("stacking/sigma_high", 3.0, type=float)
        self.sigma_low = self.settings.value("stacking/sigma_low", 3.0, type=float)
        self.rejection_algorithm = self.settings.value(
            "stacking/rejection_algorithm",
            "Weighted Windsorized Sigma Clipping",
            type=str
        )
        self.kappa = self.settings.value("stacking/kappa", 2.5, type=float)
        self.iterations = self.settings.value("stacking/iterations", 3, type=int)
        self.esd_threshold = self.settings.value("stacking/esd_threshold", 3.0, type=float)
        self.biweight_constant = self.settings.value("stacking/biweight_constant", 6.0, type=float)
        self.trim_fraction = self.settings.value("stacking/trim_fraction", 0.1, type=float)
        self.modz_threshold = self.settings.value("stacking/modz_threshold", 3.5, type=float)
        self.chunk_height = self.settings.value("stacking/chunk_height", 2048, type=int)
        self.chunk_width = self.settings.value("stacking/chunk_width", 2048, type=int)        

        # Dictionaries to store file paths
        self.conversion_files = {}
        self.dark_files = {}
        self.flat_files = {}
        self.light_files = {}
        self.master_files = {}
        self.master_sizes = {}

        layout = QVBoxLayout(self)
        self.tabs = QTabWidget()
        layout.addWidget(self.tabs)
        self.dir_path_edit = QLineEdit(self.stacking_directory)  # Add this here
        # Create the new Conversion tab.
        self.conversion_tab = self.create_conversion_tab()
        # Existing tabs...
        self.dark_tab = self.create_dark_tab()
        self.flat_tab = self.create_flat_tab()
        self.light_tab = self.create_light_tab()
        self.image_integration_tab = self.create_image_registration_tab()

        # Add the tabs in desired order. (Conversion first)
        self.tabs.addTab(self.conversion_tab, "Convert Non-FITS Formats")
        self.tabs.addTab(self.dark_tab, "Darks")
        self.tabs.addTab(self.flat_tab, "Flats")
        self.tabs.addTab(self.light_tab, "Lights")
        self.tabs.addTab(self.image_integration_tab, "Image Integration")
        self.tabs.setCurrentIndex(1)  # Default to Darks tab

        # Wrench button, status bar, etc.
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))
        self.wrench_button.setToolTip("Set Stacking Directory & Sigma Clipping")
        self.wrench_button.clicked.connect(self.open_stacking_settings)
        self.wrench_button.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        header_row = QHBoxLayout()
        header_row.addWidget(self.wrench_button)

        self.stacking_path_display = QLineEdit(self.stacking_directory or "")
        self.stacking_path_display.setReadOnly(True)
        self.stacking_path_display.setPlaceholderText("No stacking folder selected")
        self.stacking_path_display.setFrame(False)  # nicer, label-like look
        self.stacking_path_display.setToolTip(self.stacking_directory or "No stacking folder selected")
        header_row.addWidget(self.stacking_path_display, 1)  # stretch

        layout.addLayout(header_row)
        self.setup_status_bar(layout)
        self.tabs.currentChanged.connect(self.on_tab_changed)
        self.restore_saved_master_calibrations()
        self._update_stacking_path_display()

    def _update_stacking_path_display(self):
        txt = self.stacking_directory or ""
        self.stacking_path_display.setText(txt)
        self.stacking_path_display.setToolTip(txt or "No stacking folder selected")

    def restore_saved_master_calibrations(self):
        saved_darks = self.settings.value("stacking/master_darks", [], type=list)
        saved_flats = self.settings.value("stacking/master_flats", [], type=list)

        if saved_darks:
            self.add_master_files(self.master_dark_tree, "DARK", saved_darks)

        if saved_flats:
            self.add_master_files(self.master_flat_tree, "FLAT", saved_flats)

    def create_conversion_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.addWidget(QLabel("Batch Convert Files to Debayered FITS (.fit)"))

        # 1) Create the tree
        self.conversion_tree = QTreeWidget()
        self.conversion_tree.setColumnCount(2)
        self.conversion_tree.setHeaderLabels(["File", "Status"])

        # 2) Make columns user-resizable (Interactive)
        header = self.conversion_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After populating the tree, do an initial auto-resize
        self.conversion_tree.resizeColumnToContents(0)
        self.conversion_tree.resizeColumnToContents(1)
        layout.addWidget(self.conversion_tree)

        # Buttons for adding files, adding a directory,
        # selecting an output directory, and clearing the list.
        btn_layout = QHBoxLayout()
        self.add_conversion_files_btn = QPushButton("Add Conversion Files")
        self.add_conversion_files_btn.clicked.connect(self.add_conversion_files)
        self.add_conversion_dir_btn = QPushButton("Add Conversion Directory")
        self.add_conversion_dir_btn.clicked.connect(self.add_conversion_directory)
        self.select_conversion_output_btn = QPushButton("Select Output Directory")
        self.select_conversion_output_btn.clicked.connect(self.select_conversion_output_dir)
        self.clear_conversion_btn = QPushButton("Clear List")
        self.clear_conversion_btn.clicked.connect(self.clear_conversion_list)
        btn_layout.addWidget(self.add_conversion_files_btn)
        btn_layout.addWidget(self.add_conversion_dir_btn)
        btn_layout.addWidget(self.select_conversion_output_btn)
        btn_layout.addWidget(self.clear_conversion_btn)
        layout.addLayout(btn_layout)

        # Convert All button (converts all files in the tree).
        self.convert_btn = QPushButton("Convert All Files to FITS")
        self.convert_btn.clicked.connect(self.convert_all_files)
        layout.addWidget(self.convert_btn)

        return tab

    def add_conversion_files(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files for Conversion", last_dir,
                                                "Supported Files (*.fits *.fit *.fz *.fz *.fits.gz *.fit.gz *.tiff *.tif *.png *.jpg *.jpeg *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef *.xisf)")
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            for file in files:
                item = QTreeWidgetItem([os.path.basename(file), "Pending"])
                item.setData(0, 1000, file)  # store full path in role 1000
                self.conversion_tree.addTopLevelItem(item)

    def add_conversion_directory(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, "Select Directory for Conversion", last_dir)
        if directory:
            self.settings.setValue("last_opened_folder", directory)
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit", ".fz", ".fz", ".fit.gz", ".fits.gz", ".tiff", ".tif", ".png", ".jpg", ".jpeg", 
                                           ".cr2", ".cr3", ".nef", ".arw", ".dng", ".orf", ".rw2", ".pef", ".xisf")):
                    full_path = os.path.join(directory, file)
                    item = QTreeWidgetItem([file, "Pending"])
                    item.setData(0, 1000, full_path)
                    self.conversion_tree.addTopLevelItem(item)

    def select_conversion_output_dir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Conversion Output Directory")
        if directory:
            self.conversion_output_directory = directory
            self.update_status(f"Conversion output directory set to: {directory}")

    def clear_conversion_list(self):
        self.conversion_tree.clear()
        self.update_status("Conversion list cleared.")

    def convert_all_files(self):
        # If no output directory is set, ask the user if they want to set it now.
        if not self.conversion_output_directory:
            reply = QMessageBox.question(
                self,
                "No Output Directory",
                "No output directory is set. Do you want to select one now?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if reply == QMessageBox.StandardButton.Yes:
                self.select_conversion_output_dir()  # Let them pick a folder
            else:
                # They chose 'No' → just stop
                return

            # If it's still empty after that, bail out
            if not self.conversion_output_directory:
                QMessageBox.warning(self, "No Output Directory", "Please select a conversion output directory first.")
                return

        count = self.conversion_tree.topLevelItemCount()
        if count == 0:
            QMessageBox.information(self, "No Files", "There are no files to convert.")
            return

        # 1) Show the batch settings dialog
        dialog = BatchSettingsDialog(self)
        result = dialog.exec()
        if result == int(QDialog.DialogCode.Rejected):
            # user canceled
            return
        # user pressed OK => get the values
        imagetyp_user, exptime_user, filter_user = dialog.get_values()

        for i in range(count):
            item = self.conversion_tree.topLevelItem(i)
            file_path = item.data(0, 1000)
            result = load_image(file_path)
            if result[0] is None:
                item.setText(1, "Failed to load")
                self.update_status(f"Failed to load {os.path.basename(file_path)}")
                continue

            image, header, bit_depth, is_mono = result

            if image is None:
                item.setText(1, "Failed to load")
                self.update_status(f"Failed to load {os.path.basename(file_path)}")
                continue

            # 🔹 If the file has no header (TIFF, PNG, JPG, etc.), create a minimal one
            if header is None:
                header = fits.Header()
                header["SIMPLE"]   = True
                header["BITPIX"]   = 16  # Or 16, depending on your preference
                header["CREATOR"]  = "SetiAstroSuite"
                header["IMAGETYP"] = "UNKNOWN"  # We'll set it properly below
                header["EXPTIME"]  = "Unknown"  # Just a placeholder
                # You can add more default keywords as needed

            # Debayer if needed:
            image = self.debayer_image(image, file_path, header)
            if image.ndim == 3:
                is_mono = False

            # If it's a RAW format, definitely treat as color
            if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                is_mono = False

                # Try extracting EXIF metadata
                try:
                    with open(file_path, 'rb') as f:
                        tags = exifread.process_file(f, details=False)

                    exptime_tag = tags.get("EXIF ExposureTime")  # e.g. "1/125"
                    iso_tag = tags.get("EXIF ISOSpeedRatings")
                    date_obs_tag = tags.get("EXIF DateTimeOriginal")

                    # Create or replace with a fresh header, but keep some existing fields if desired
                    new_header = fits.Header()
                    new_header['SIMPLE'] = True
                    new_header['BITPIX'] = 16
                    new_header['IMAGETYP'] = header.get('IMAGETYP', "UNKNOWN")

                    # Attempt to parse exptime. If fraction or numeric fails, store 'Unknown'.
                    if exptime_tag:
                        exptime_str = str(exptime_tag.values)  # or exptime_tag.printable
                        # Attempt fraction or float
                        try:
                            if '/' in exptime_str:  
                                # e.g. "1/125"
                                top, bot = exptime_str.split('/', 1)
                                fexp = float(top) / float(bot)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                            else:
                                # e.g. "0.008" or "8"
                                fexp = float(exptime_str)
                                new_header['EXPTIME'] = (fexp, "Exposure Time in seconds")
                        except (ValueError, ZeroDivisionError):
                            new_header['EXPTIME'] = 'Unknown'
                    # If no exptime_tag, set Unknown
                    else:
                        new_header['EXPTIME'] = 'Unknown'

                    if iso_tag:
                        new_header['ISO'] = str(iso_tag.values)
                    if date_obs_tag:
                        new_header['DATE-OBS'] = str(date_obs_tag.values)

                    # Replace old header with new
                    header = new_header

                except Exception as e:
                    # If exif extraction fails for any reason, we just keep the existing header
                    # but ensure we set EXPTIME if missing
                    self.update_status(f"Warning: Failed to extract RAW header from {os.path.basename(file_path)}: {e}")

            header['IMAGETYP'] = imagetyp_user
            header['FILTER'] = filter_user

            # For exptime_user, try to parse float or fraction
            try:
                if '/' in exptime_user:
                    top, bot = exptime_user.split('/', 1)
                    exptime_val = float(top) / float(bot)
                    header['EXPTIME'] = (exptime_val, "User-specified exposure (s)")
                else:
                    exptime_val = float(exptime_user)
                    header['EXPTIME'] = (exptime_val, "User-specified exposure (s)")
            except (ValueError, ZeroDivisionError):
                # If user typed "Unknown" or something non-numeric
                header['EXPTIME'] = exptime_user

            # Remove any existing NAXIS keywords
            for key in ["NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
                header.pop(key, None)

            if image.ndim == 2:
                header['NAXIS'] = 2
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
            elif image.ndim == 3:
                header['NAXIS'] = 3
                header['NAXIS1'] = image.shape[1]
                header['NAXIS2'] = image.shape[0]
                header['NAXIS3'] = image.shape[2]

            # -- Ensure EXPTIME is defined --
            if 'EXPTIME' not in header:
                # If the camera or exif didn't provide it, we set it to 'Unknown'
                header['EXPTIME'] = 'Unknown'

            # Build output filename and save
            base = os.path.basename(file_path)
            name, _ = os.path.splitext(base)
            output_filename = os.path.join(self.conversion_output_directory, f"{name}.fit")
            image=image/np.max(image)

            try:
                save_image(
                    img_array=image,
                    filename=output_filename,
                    original_format="fit",
                    bit_depth="16-bit",
                    original_header=header,
                    is_mono=is_mono
                )
                item.setText(1, "Converted")
                self.update_status(
                    f"Converted {os.path.basename(file_path)} to FITS with "
                    f"IMAGETYP={header['IMAGETYP']}, EXPTIME={header['EXPTIME']}."
                )
            except Exception as e:
                item.setText(1, f"Error: {e}")
                self.update_status(f"Error converting {os.path.basename(file_path)}: {e}")

            QApplication.processEvents()

        self.update_status("Conversion complete.")



    def debayer_image(self, image, file_path, header):
        if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            print(f"Debayering RAW image: {file_path}")
            return debayer_raw_fast(image)
        elif file_path.lower().endswith(('.fits', '.fit', '.fz')):
            bayer_pattern = header.get('BAYERPAT')
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                return debayer_fits_fast(image, bayer_pattern)
        return image

    def setup_status_bar(self, layout):
        """ Sets up a scrollable status log at the bottom of the UI. """
        self.status_text = QTextEdit()
        self.status_text.setReadOnly(True)
        self.status_text.setMaximumHeight(100)  # Limits visible lines (~5 lines)
        self.status_text.setStyleSheet("background-color: black; color: white; font-family: Monospace; padding: 4px;")
        
        # Wrap in a scroll area for scrolling
        self.status_scroll = QScrollArea()
        self.status_scroll.setWidgetResizable(True)
        self.status_scroll.setWidget(self.status_text)
        
        # Add to the main layout
        layout.addWidget(self.status_scroll)

    def update_status(self, message: str):
        """
        Append a new status line, except if it's a '🔄 Normalizing…' message
        and the last line was also '🔄 Normalizing…', in which case overwrite it.
        """
        # Temporarily block signals so we don't recurse
        old_state = self.status_text.blockSignals(True)
        
        # Grab existing lines
        lines = self.status_text.toPlainText().splitlines()

        # If both this and the last message are normalization updates, overwrite
        if (
            message.startswith("🔄 Normalizing")
            and lines
            and lines[-1].startswith("🔄 Normalizing")
        ):
            lines[-1] = message
        else:
            lines.append(message)

        # Rebuild the text in one go
        self.status_text.setPlainText("\n".join(lines))

        # Scroll to bottom
        vsb = self.status_text.verticalScrollBar()
        vsb.setValue(vsb.maximum())

        # Restore signals
        self.status_text.blockSignals(old_state)


    def open_stacking_settings(self):
        """ Opens a dialog to set the stacking directory, sigma values, rejection algorithm, and algorithm parameters. """
        dialog = QDialog(self)
        dialog.setWindowTitle("Stacking Settings")
        layout = QVBoxLayout(dialog)

        # Stacking directory selection
        dir_layout = QHBoxLayout()
        dir_label = QLabel("Stacking Directory:")
        self.dir_path_edit = QLineEdit(self.stacking_directory)
        dir_button = QPushButton("Browse")
        dir_button.clicked.connect(self.select_stacking_directory)
        dir_layout.addWidget(dir_label)
        dir_layout.addWidget(self.dir_path_edit)
        dir_layout.addWidget(dir_button)
        layout.addLayout(dir_layout)

        # Sigma High & Low settings
        sigma_layout = QHBoxLayout()
        sigma_layout.addWidget(QLabel("Sigma High:"))
        self.sigma_high_spinbox = QDoubleSpinBox()
        self.sigma_high_spinbox.setRange(0.1, 10.0)
        self.sigma_high_spinbox.setDecimals(2)
        self.sigma_high_spinbox.setValue(self.sigma_high)
        sigma_layout.addWidget(self.sigma_high_spinbox)
        sigma_layout.addWidget(QLabel("Sigma Low:"))
        self.sigma_low_spinbox = QDoubleSpinBox()
        self.sigma_low_spinbox.setRange(0.1, 10.0)
        self.sigma_low_spinbox.setDecimals(2)
        self.sigma_low_spinbox.setValue(self.sigma_low)
        sigma_layout.addWidget(self.sigma_low_spinbox)
        layout.addLayout(sigma_layout)

        chunk_layout = QHBoxLayout()
        chunk_layout.addWidget(QLabel("Chunk Height:"))
        self.chunkHeightSpinBox = QSpinBox()
        self.chunkHeightSpinBox.setRange(128, 8192)  # or whatever range you want
        self.chunkHeightSpinBox.setValue(self.settings.value("stacking/chunk_height", 2048, type=int))
        chunk_layout.addWidget(self.chunkHeightSpinBox)

        chunk_layout.addWidget(QLabel("Chunk Width:"))
        self.chunkWidthSpinBox = QSpinBox()
        self.chunkWidthSpinBox.setRange(128, 8192)
        self.chunkWidthSpinBox.setValue(self.settings.value("stacking/chunk_width", 2048, type=int))
        chunk_layout.addWidget(self.chunkWidthSpinBox)

        layout.addLayout(chunk_layout)

        # Rejection algorithm selection
        algo_layout = QHBoxLayout()
        algo_label = QLabel("Rejection Algorithm:")
        self.rejection_algo_combo = QComboBox()
        self.rejection_algo_combo.addItems([
            "Weighted Windsorized Sigma Clipping",
            "Kappa-Sigma Clipping",
            "Simple Average (No Rejection)",
            "Simple Median (No Rejection)",
            "Trimmed Mean",
            "Extreme Studentized Deviate (ESD)",
            "Biweight Estimator",
            "Modified Z-Score Clipping",
            "Max Value"
        ])
        saved_algo = self.settings.value("stacking/rejection_algorithm", "Weighted Windsorized Sigma Clipping")
        index = self.rejection_algo_combo.findText(saved_algo)
        if index >= 0:
            self.rejection_algo_combo.setCurrentIndex(index)
        algo_layout.addWidget(algo_label)
        algo_layout.addWidget(self.rejection_algo_combo)
        layout.addLayout(algo_layout)

        # --- Additional Parameters ---

        # Kappa-Sigma Clipping: Kappa Value
        kappa_layout = QHBoxLayout()
        kappa_label = QLabel("Kappa Value:")
        self.kappa_spinbox = QDoubleSpinBox()
        self.kappa_spinbox.setRange(0.1, 10.0)
        self.kappa_spinbox.setDecimals(2)
        self.kappa_spinbox.setValue(self.settings.value("stacking/kappa", 2.5, type=float))
        kappa_help = QPushButton("?")
        kappa_help.setFixedSize(20, 20)
        kappa_help.clicked.connect(lambda: QMessageBox.information(self, "Kappa Value", 
            "Kappa determines how many standard deviations away from the median are considered outliers. Higher values are more lenient."))
        kappa_layout.addWidget(kappa_label)
        kappa_layout.addWidget(self.kappa_spinbox)
        kappa_layout.addWidget(kappa_help)
        layout.addLayout(kappa_layout)

        # Kappa-Sigma Clipping: Iterations
        iterations_layout = QHBoxLayout()
        iterations_label = QLabel("Iterations:")
        self.iterations_spinbox = QSpinBox()
        self.iterations_spinbox.setRange(1, 10)
        self.iterations_spinbox.setValue(self.settings.value("stacking/iterations", 3, type=int))
        iterations_help = QPushButton("?")
        iterations_help.setFixedSize(20, 20)
        iterations_help.clicked.connect(lambda: QMessageBox.information(self, "Iterations", 
            "The number of iterations to perform kappa-sigma clipping. More iterations may remove more outliers."))
        iterations_layout.addWidget(iterations_label)
        iterations_layout.addWidget(self.iterations_spinbox)
        iterations_layout.addWidget(iterations_help)
        layout.addLayout(iterations_layout)

        # ESD: ESD Threshold
        esd_layout = QHBoxLayout()
        esd_label = QLabel("ESD Threshold:")
        self.esd_spinbox = QDoubleSpinBox()
        self.esd_spinbox.setRange(0.1, 10.0)
        self.esd_spinbox.setDecimals(2)
        self.esd_spinbox.setValue(self.settings.value("stacking/esd_threshold", 3.0, type=float))
        esd_help = QPushButton("?")
        esd_help.setFixedSize(20, 20)
        esd_help.clicked.connect(lambda: QMessageBox.information(self, "ESD Threshold", 
            "Threshold for the Extreme Studentized Deviate test. Lower values are more aggressive in rejecting outliers."))
        esd_layout.addWidget(esd_label)
        esd_layout.addWidget(self.esd_spinbox)
        esd_layout.addWidget(esd_help)
        layout.addLayout(esd_layout)

        # Biweight Estimator: Tuning Constant
        biweight_layout = QHBoxLayout()
        biweight_label = QLabel("Biweight Tuning Constant:")
        self.biweight_spinbox = QDoubleSpinBox()
        self.biweight_spinbox.setRange(1.0, 10.0)
        self.biweight_spinbox.setDecimals(2)
        self.biweight_spinbox.setValue(self.settings.value("stacking/biweight_constant", 6.0, type=float))
        biweight_help = QPushButton("?")
        biweight_help.setFixedSize(20, 20)
        biweight_help.clicked.connect(lambda: QMessageBox.information(self, "Biweight Tuning Constant", 
            "Tuning constant for the biweight estimator; it controls the aggressiveness of down-weighting outliers."))
        biweight_layout.addWidget(biweight_label)
        biweight_layout.addWidget(self.biweight_spinbox)
        biweight_layout.addWidget(biweight_help)
        layout.addLayout(biweight_layout)

        # Trimmed Mean: Trim Fraction
        trim_layout = QHBoxLayout()
        trim_label = QLabel("Trim Fraction:")
        self.trim_spinbox = QDoubleSpinBox()
        self.trim_spinbox.setRange(0.0, 0.5)
        self.trim_spinbox.setDecimals(2)
        self.trim_spinbox.setValue(self.settings.value("stacking/trim_fraction", 0.1, type=float))
        trim_help = QPushButton("?")
        trim_help.setFixedSize(20, 20)
        trim_help.clicked.connect(lambda: QMessageBox.information(self, "Trim Fraction", 
            "Fraction of values to trim from each end before averaging. For example, 0.1 will trim 10% from each end."))
        trim_layout.addWidget(trim_label)
        trim_layout.addWidget(self.trim_spinbox)
        trim_layout.addWidget(trim_help)
        layout.addLayout(trim_layout)

        # Modified Z-Score Clipping: Threshold
        modz_layout = QHBoxLayout()
        modz_label = QLabel("Modified Z-Score Threshold:")
        self.modz_spinbox = QDoubleSpinBox()
        self.modz_spinbox.setRange(0.1, 10.0)
        self.modz_spinbox.setDecimals(2)
        self.modz_spinbox.setValue(self.settings.value("stacking/modz_threshold", 3.5, type=float))
        modz_help = QPushButton("?")
        modz_help.setFixedSize(20, 20)
        modz_help.clicked.connect(lambda: QMessageBox.information(self, "Modified Z-Score Threshold", 
            "Threshold for the modified z-score clipping using the median absolute deviation. Lower values are more aggressive."))
        modz_layout.addWidget(modz_label)
        modz_layout.addWidget(self.modz_spinbox)
        modz_layout.addWidget(modz_help)
        layout.addLayout(modz_layout)

        # Save button
        save_button = QPushButton("Save Settings")
        save_button.clicked.connect(lambda: self.save_stacking_settings(dialog))
        layout.addWidget(save_button)

        dialog.exec()

    def save_stacking_settings(self, dialog):
        """ Saves stacking directory, sigma values, rejection algorithm, and algorithm parameters to QSettings. """
        self.stacking_directory = self.dir_path_edit.text()
        self.sigma_high = self.sigma_high_spinbox.value()
        self.sigma_low = self.sigma_low_spinbox.value()
        self.rejection_algorithm = self.rejection_algo_combo.currentText()
        self.kappa = self.kappa_spinbox.value()
        self.iterations = self.iterations_spinbox.value()
        self.esd_threshold = self.esd_spinbox.value()
        self.biweight_constant = self.biweight_spinbox.value()
        self.trim_fraction = self.trim_spinbox.value()
        self.modz_threshold = self.modz_spinbox.value()
        self.chunk_height = self.chunkHeightSpinBox.value()
        self.chunk_width = self.chunkWidthSpinBox.value()

        # Store in QSettings
        self.settings.setValue("stacking/dir", self.stacking_directory)
        self.settings.setValue("stacking/sigma_high", self.sigma_high)
        self.settings.setValue("stacking/sigma_low", self.sigma_low)
        self.settings.setValue("stacking/rejection_algorithm", self.rejection_algorithm)
        self.settings.setValue("stacking/kappa", self.kappa)
        self.settings.setValue("stacking/iterations", self.iterations)
        self.settings.setValue("stacking/esd_threshold", self.esd_threshold)
        self.settings.setValue("stacking/biweight_constant", self.biweight_constant)
        self.settings.setValue("stacking/trim_fraction", self.trim_fraction)
        self.settings.setValue("stacking/modz_threshold", self.modz_threshold)
        self.settings.setValue("stacking/chunk_height", self.chunk_height)
        self.settings.setValue("stacking/chunk_width", self.chunk_width)
        self.settings.setValue("stacking/autocrop_enabled", self.autocrop_cb.isChecked())
        self.settings.setValue("stacking/autocrop_pct", float(self.autocrop_pct.value()))        

        print(f"✅ Saved settings - Directory: {self.stacking_directory}, Sigma High: {self.sigma_high}, Sigma Low: {self.sigma_low}, Algorithm: {self.rejection_algorithm}")
        print(f"    Kappa: {self.kappa}, Iterations: {self.iterations}, ESD Threshold: {self.esd_threshold}, Biweight Constant: {self.biweight_constant}, Trim Fraction: {self.trim_fraction}, Modified Z-Score Threshold: {self.modz_threshold}")
        self.update_status("✅ Saved stacking settings.")
        self._update_stacking_path_display()
        dialog.accept()

    def select_stacking_directory(self):
        """ Opens a dialog to choose a stacking directory. """
        directory = QFileDialog.getExistingDirectory(self, "Select Stacking Directory")
        if directory:
            self.stacking_directory = directory
            self.dir_path_edit.setText(directory)  # No more AttributeError
            self.settings.setValue("stacking/dir", directory)  # Save the new directory
            self._update_stacking_path_display()



    def create_dark_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Vertical layout to separate sections

        # --- DARK FRAMES TREEBOX (TOP) ---
        darks_layout = QHBoxLayout()  # Left = Dark Tree, Right = Controls

        # Left Side - Dark Frames
        dark_frames_layout = QVBoxLayout()
        dark_frames_layout.addWidget(QLabel("Dark Frames"))
        # 1) Create the tree
        self.dark_tree = QTreeWidget()
        self.dark_tree.setColumnCount(2)
        self.dark_tree.setHeaderLabels(["Exposure Time", "Metadata"])
        self.dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # 2) Make columns user-resizable
        header = self.dark_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Interactive)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.Interactive)

        # 3) After you fill the tree with items, auto-resize
        self.dark_tree.resizeColumnToContents(0)
        self.dark_tree.resizeColumnToContents(1)

        # Then add it to the layout
        dark_frames_layout.addWidget(self.dark_tree)

        # Buttons to Add Dark Files & Directories
        btn_layout = QHBoxLayout()
        self.add_dark_files_btn = QPushButton("Add Dark Files")
        self.add_dark_files_btn.clicked.connect(self.add_dark_files)
        self.add_dark_dir_btn = QPushButton("Add Dark Directory")
        self.add_dark_dir_btn.clicked.connect(self.add_dark_directory)
        btn_layout.addWidget(self.add_dark_files_btn)
        btn_layout.addWidget(self.add_dark_dir_btn)
        dark_frames_layout.addLayout(btn_layout)

        self.clear_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_dark_selection_btn.clicked.connect(lambda: self.clear_tree_selection(self.dark_tree, self.dark_files))
        dark_frames_layout.addWidget(self.clear_dark_selection_btn)

        darks_layout.addLayout(dark_frames_layout, 2)  # Dark Frames Tree takes more space


        # --- RIGHT SIDE: Exposure Tolerance & Master Darks Button ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.exposure_tolerance_spinbox = QSpinBox()
        self.exposure_tolerance_spinbox.setRange(0, 30)  # Acceptable range
        self.exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)

        # --- "Turn Those Darks Into Master Darks" Button ---
        self.create_master_dark_btn = QPushButton("Turn Those Darks Into Master Darks")
        self.create_master_dark_btn.clicked.connect(self.create_master_dark)

        # Apply a bold font, padding, and a highlighted effect
        self.create_master_dark_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)

        right_controls_layout.addWidget(self.create_master_dark_btn)


        darks_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(darks_layout)

        # --- MASTER DARKS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Darks"))
        self.master_dark_tree = QTreeWidget()
        self.master_dark_tree.setColumnCount(2)
        self.master_dark_tree.setHeaderLabels(["Exposure Time", "Master File"])
        self.master_dark_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        main_layout.addWidget(self.master_dark_tree)

        # Master Dark Selection Button
        self.master_dark_btn = QPushButton("Load Master Dark")
        self.master_dark_btn.clicked.connect(self.load_master_dark)
        main_layout.addWidget(self.master_dark_btn)

        # Add "Clear Selection" button for Master Darks
        self.clear_master_dark_selection_btn = QPushButton("Clear Selection")
        self.clear_master_dark_selection_btn.clicked.connect(
            lambda: self.clear_tree_selection(self.master_dark_tree, self.master_files)
        )
        self.clear_master_dark_selection_btn.clicked.connect(
            lambda: (self.clear_tree_selection(self.master_dark_tree, self.master_files),
                    self.save_master_paths_to_settings())
        )        
        main_layout.addWidget(self.clear_master_dark_selection_btn)

        return tab



    def create_flat_tab(self):
        tab = QWidget()
        main_layout = QVBoxLayout(tab)  # Main layout to organize sections

        # --- FLAT FRAMES TREEBOX (TOP) ---
        flats_layout = QHBoxLayout()  # Left = Flat Tree, Right = Controls

        # Left Side - Flat Frames
        flat_frames_layout = QVBoxLayout()
        flat_frames_layout.addWidget(QLabel("Flat Frames"))

        self.flat_tree = QTreeWidget()
        self.flat_tree.setColumnCount(3)  # Added 3rd column for Master Dark Used
        self.flat_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark Used"])
        self.flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.flat_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.flat_tree.customContextMenuRequested.connect(self.flat_tree_context_menu)
        flat_frames_layout.addWidget(self.flat_tree)

        # Buttons to Add Flat Files & Directories
        btn_layout = QHBoxLayout()
        self.add_flat_files_btn = QPushButton("Add Flat Files")
        self.add_flat_files_btn.clicked.connect(self.add_flat_files)
        self.add_flat_dir_btn = QPushButton("Add Flat Directory")
        self.add_flat_dir_btn.clicked.connect(self.add_flat_directory)
        btn_layout.addWidget(self.add_flat_files_btn)
        btn_layout.addWidget(self.add_flat_dir_btn)
        flat_frames_layout.addLayout(btn_layout)
        # 🔧 Session Tag Hint
        session_hint_label = QLabel("Right Click to Assign Session Keys if desired")
        session_hint_label.setStyleSheet("color: #888; font-style: italic; font-size: 11px; margin-left: 4px;")
        flat_frames_layout.addWidget(session_hint_label)

        # Add "Clear Selection" button for Flat Frames
        self.clear_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_flat_selection_btn.clicked.connect(lambda: self.clear_tree_selection_flat(self.flat_tree, self.flat_files))
        flat_frames_layout.addWidget(self.clear_flat_selection_btn)

        flats_layout.addLayout(flat_frames_layout, 2)  # Left side takes more space

        # --- RIGHT SIDE: Exposure Tolerance & Master Dark Selection ---
        right_controls_layout = QVBoxLayout()

        # Exposure Tolerance
        exposure_tolerance_layout = QHBoxLayout()
        exposure_tolerance_label = QLabel("Exposure Tolerance (seconds):")
        self.flat_exposure_tolerance_spinbox = QSpinBox()
        self.flat_exposure_tolerance_spinbox.setRange(0, 30)  # Allow ±0 to 30 seconds
        self.flat_exposure_tolerance_spinbox.setValue(5)  # Default: ±5 sec
        exposure_tolerance_layout.addWidget(exposure_tolerance_label)
        exposure_tolerance_layout.addWidget(self.flat_exposure_tolerance_spinbox)
        right_controls_layout.addLayout(exposure_tolerance_layout)
        self.flat_exposure_tolerance_spinbox.valueChanged.connect(self.rebuild_flat_tree)


        # Auto-Select Master Dark
        self.auto_select_dark_checkbox = QCheckBox("Auto-Select Closest Master Dark")
        self.auto_select_dark_checkbox.setChecked(True)  # Default enabled
        right_controls_layout.addWidget(self.auto_select_dark_checkbox)

        # Manual Override: Select a Master Dark
        self.override_dark_combo = QComboBox()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.currentIndexChanged.connect(self.override_selected_master_dark)
        right_controls_layout.addWidget(QLabel("Override Master Dark Selection"))
        right_controls_layout.addWidget(self.override_dark_combo)

        self.create_master_flat_btn = QPushButton("Turn Those Flats Into Master Flats")
        self.create_master_flat_btn.clicked.connect(self.create_master_flat)

        # Apply a bold font, padding, and a glowing effect
        self.create_master_flat_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;  /* Dark gray */
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;  /* Subtle yellow border */
            }
            QPushButton:hover {
                border: 2px solid #FFD700;  /* Brighter yellow on hover */
            }
            QPushButton:pressed {
                background-color: #222;  /* Darker gray on press */
                border: 2px solid #FFA500;  /* Orange border when pressed */
            }
        """)


        right_controls_layout.addWidget(self.create_master_flat_btn)

        flats_layout.addLayout(right_controls_layout, 1)  # Right side takes less space

        main_layout.addLayout(flats_layout)

        # --- MASTER FLATS TREEBOX (BOTTOM) ---
        main_layout.addWidget(QLabel("Master Flats"))
        self.master_flat_tree = QTreeWidget()
        self.master_flat_tree.setColumnCount(2)
        self.master_flat_tree.setHeaderLabels(["Filter", "Master File"])
        self.master_flat_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        
        main_layout.addWidget(self.master_flat_tree)

        # Master Flat Selection Button
        self.master_flat_btn = QPushButton("Load Master Flat")
        self.master_flat_btn.clicked.connect(self.load_master_flat)
        main_layout.addWidget(self.master_flat_btn)

        self.clear_master_flat_selection_btn = QPushButton("Clear Selection")
        self.clear_master_flat_selection_btn.clicked.connect(
            lambda: (self.clear_tree_selection(self.master_flat_tree, self.master_files),
                    self.save_master_paths_to_settings())
        )
        main_layout.addWidget(self.clear_master_flat_selection_btn)
        return tab

    def flat_tree_context_menu(self, position):
        item = self.flat_tree.itemAt(position)
        if item:
            menu = QMenu()
            set_session_action = menu.addAction("Set Session Tag")
            action = menu.exec(self.flat_tree.viewport().mapToGlobal(position))
            if action == set_session_action:
                self.prompt_set_session(item, "flat")

    def create_light_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # Tree widget for light frames
        self.light_tree = QTreeWidget()
        self.light_tree.setColumnCount(5)  # Added columns for Master Dark and Flat
        self.light_tree.setHeaderLabels(["Filter & Exposure", "Metadata", "Master Dark", "Master Flat", "Corrections"])
        self.light_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        layout.addWidget(QLabel("Light Frames"))
        layout.addWidget(self.light_tree)

        # Buttons for adding files and directories
        btn_layout = QHBoxLayout()
        self.add_light_files_btn = QPushButton("Add Light Files")
        self.add_light_files_btn.clicked.connect(self.add_light_files)
        self.add_light_dir_btn = QPushButton("Add Light Directory")
        self.add_light_dir_btn.clicked.connect(self.add_light_directory)
        btn_layout.addWidget(self.add_light_files_btn)
        btn_layout.addWidget(self.add_light_dir_btn)
        layout.addLayout(btn_layout)
        session_hint_label = QLabel("Right Click to Assign Session Keys if desired")
        session_hint_label.setStyleSheet("color: #888; font-style: italic; font-size: 11px; margin-left: 4px;")
        layout.addWidget(session_hint_label)

        clear_selection_btn = QPushButton("Remove Selected")
        clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection_light(self.light_tree))
        layout.addWidget(clear_selection_btn)

        # Cosmetic Correction & Pedestal Controls
        correction_layout = QHBoxLayout()

        self.cosmetic_checkbox = QCheckBox("Enable Cosmetic Correction")
        self.pedestal_checkbox = QCheckBox("Apply Pedestal")
        self.bias_checkbox = QCheckBox("Apply Bias Subtraction (For CCD Users)")

        # Pedestal Value (0-1000, converted to 0-1)
        pedestal_layout = QHBoxLayout()
        self.pedestal_spinbox = QSpinBox()
        self.pedestal_spinbox.setRange(0, 1000)
        self.pedestal_spinbox.setValue(50)  # Default pedestal
        pedestal_layout.addWidget(QLabel("Pedestal (0-1000):"))
        pedestal_layout.addWidget(self.pedestal_spinbox)
        layout.addLayout(pedestal_layout)        

        # Tooltip for Bias Checkbox
        self.bias_checkbox.setToolTip(
            "CMOS users: Bias Subtraction is not needed.\n"
            "Modern CMOS cameras use Correlated Double Sampling (CDS),\n"
            "meaning bias is already subtracted at the sensor level."
        )

        # Connect checkboxes to update function
        self.cosmetic_checkbox.stateChanged.connect(self.update_light_corrections)
        self.pedestal_checkbox.stateChanged.connect(self.update_light_corrections)
        self.bias_checkbox.stateChanged.connect(self.update_light_corrections)

        # Add checkboxes to layout
        correction_layout.addWidget(self.cosmetic_checkbox)
        correction_layout.addWidget(self.pedestal_checkbox)
        correction_layout.addWidget(self.bias_checkbox)

        layout.addLayout(correction_layout)        

        # --- RIGHT SIDE CONTROLS: Override Dark & Flat ---
        override_layout = QHBoxLayout()

        self.override_dark_btn = QPushButton("Override Dark Frame")
        self.override_dark_btn.clicked.connect(self.override_selected_master_dark)
        override_layout.addWidget(self.override_dark_btn)

        self.override_flat_btn = QPushButton("Override Flat Frame")
        self.override_flat_btn.clicked.connect(self.override_selected_master_flat)
        override_layout.addWidget(self.override_flat_btn)

        layout.addLayout(override_layout)

        # Calibrate Lights Button
        self.calibrate_lights_btn = QPushButton("🚀 Calibrate Light Frames 🚀")
        self.calibrate_lights_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        self.calibrate_lights_btn.clicked.connect(self.calibrate_lights)
        layout.addWidget(self.calibrate_lights_btn)

        # Enable Context Menu
        self.light_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.light_tree.customContextMenuRequested.connect(self.light_tree_context_menu)

        return tab



    def prompt_set_session(self, item, frame_type):
        text, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session name:")
        if not (ok and text.strip()):
            return

        session_name = text.strip()
        is_flat = frame_type.upper() == "FLAT"
        tree = self.flat_tree if is_flat else self.light_tree
        target_dict = self.flat_files if is_flat else self.light_files

        selected_items = tree.selectedItems()

        def update_file_session(filename, widget_item):
            for key in list(target_dict.keys()):
                if isinstance(key, tuple) and len(key) == 2:
                    group_key, old_session = key
                else:
                    continue  # Skip malformed keys

                files = target_dict.get(key, [])
                for f in list(files):
                    if os.path.basename(f) == filename:
                        if old_session != session_name:
                            new_key = (group_key, session_name)
                            if new_key not in target_dict:
                                target_dict[new_key] = []
                            target_dict[new_key].append(f)
                            target_dict[key].remove(f)
                            if not target_dict[key]:
                                del target_dict[key]

                        # Update internal session tag
                        self.session_tags[f] = session_name

                        # Update leaf's metadata column
                        old_meta = widget_item.text(1)
                        if "Session:" in old_meta:
                            new_meta = re.sub(r"Session: [^|]*", f"Session: {session_name}", old_meta)
                        else:
                            new_meta = f"{old_meta} | Session: {session_name}"
                        widget_item.setText(1, new_meta)
                        return

        def recurse_all_leaf_items(parent_item):
            for i in range(parent_item.childCount()):
                child = parent_item.child(i)
                if child.childCount() == 0:
                    update_file_session(child.text(0), child)
                else:
                    recurse_all_leaf_items(child)

        # Case 1: Multi-leaf selection (e.g. Shift/Ctrl-click)
        if selected_items and any(i.childCount() == 0 for i in selected_items):
            for leaf in selected_items:
                if leaf.childCount() == 0:
                    update_file_session(leaf.text(0), leaf)

        # Case 2: Right-clicked on a group (e.g. filter+exposure node)
        elif item and item.childCount() > 0:
            recurse_all_leaf_items(item)

        # ✅ Reassign matching master flats/darks per leaf
        self.assign_best_master_files()

    def _quad_coverage_add(self, cov: np.ndarray, quad: np.ndarray):
        """
        Rasterize a convex quad (4x2 float array of (x,y) in aligned coords) into 'cov' by +1 filling.
        Bounds/clipping are handled. Small, robust scanline fill.
        """
        H, W = cov.shape
        pts = quad.astype(np.float32)

        ymin = max(int(np.floor(np.min(pts[:,1]))), 0)
        ymax = min(int(np.ceil (np.max(pts[:,1]))), H-1)
        if ymin > ymax: return

        # Edges (x0,y0)->(x1,y1), 4 of them
        edges = []
        for i in range(4):
            x0, y0 = pts[i]
            x1, y1 = pts[(i+1) % 4]
            edges.append((x0, y0, x1, y1))

        for y in range(ymin, ymax+1):
            xs = []
            yf = float(y) + 0.5  # sample at pixel center
            for (x0, y0, x1, y1) in edges:
                # Skip horizontal edges
                if (y0 <= yf < y1) or (y1 <= yf < y0):
                    # Linear interpolate X at scanline yf
                    t = (yf - y0) / (y1 - y0)
                    xs.append(x0 + t * (x1 - x0))

            if len(xs) < 2:
                continue
            xs.sort()
            # Fill between pairs
            for i in range(0, len(xs), 2):
                xL = int(np.floor(min(xs[i], xs[i+1])))
                xR = int(np.ceil (max(xs[i], xs[i+1])))
                if xR < 0 or xL > W-1: 
                    continue
                xL = max(xL, 0); xR = min(xR, W)
                if xR > xL:
                    cov[y, xL:xR] += 1


    def _max_rectangle_in_binary(self, mask: np.ndarray):
        """
        Largest axis-aligned rectangle of 1s in a binary mask (H×W, dtype=bool).
        Returns (x0, y0, x1, y1) where x1,y1 are exclusive, or None if empty.
        O(H*W) using 'largest rectangle in histogram' per row.
        """
        H, W = mask.shape
        heights = np.zeros(W, dtype=np.int32)
        best = (0, 0, 0, 0, 0)  # (area, x0, y0, x1, y1)

        for y in range(H):
            row = mask[y]
            heights[row] += 1
            heights[~row] = 0

            # Largest rectangle in histogram 'heights'
            stack = []
            i = 0
            while i <= W:
                h = heights[i] if i < W else 0
                if not stack or h >= heights[stack[-1]]:
                    stack.append(i); i += 1
                else:
                    top = stack.pop()
                    height = heights[top]
                    left = stack[-1] + 1 if stack else 0
                    right = i
                    area = height * (right - left)
                    if area > best[0]:
                        # rectangle spans rows [y-height+1 .. y], columns [left .. right-1]
                        y0 = y - height + 1
                        y1 = y + 1
                        best = (area, left, y0, right, y1)

        if best[0] == 0:
            return None
        _, x0, y0, x1, y1 = best
        return (x0, y0, x1, y1)


    def _compute_autocrop_rect(self, file_list: List[str], transforms_path: str, coverage_pct: float):
        """
        Build a coverage-count image (aligned canvas), threshold at pct, and extract largest rectangle.e
        Returns (x0, y0, x1, y1) or None.
        """
        if not file_list:
            return None

        # Load aligned reference to get canvas size
        ref_img, ref_hdr, _, _ = load_image(file_list[0])
        if ref_img is None:
            return None
        if ref_img.ndim == 2:
            H, W = ref_img.shape
        else:
            H, W = ref_img.shape[:2]

        # Load transforms (raw _n path -> 2x3 matrix mapping raw->aligned)
        if not os.path.exists(transforms_path):
            return None
        transforms = self.load_alignment_matrices_custom(transforms_path)

        # We need the raw (normalized) image size for each file to transform its corners
        # From aligned name "..._n_r.fit" get raw name "..._n.fit" (like in your drizzle code)
        cov = np.zeros((H, W), dtype=np.uint16)
        for aligned_path in file_list:
            base = os.path.basename(aligned_path)
            if base.endswith("_n_r.fit"):
                raw_base = base.replace("_n_r.fit", "_n.fit")
            elif base.endswith("_r.fit"):
                raw_base = base.replace("_r.fit", ".fit")  # fallback
            else:
                raw_base = base  # fallback

            raw_path = os.path.join(self.stacking_directory, "Normalized_Images", raw_base)
            # Fallback if normalized folder differs:
            raw_key = os.path.normpath(raw_path)
            M = transforms.get(raw_key, None)
            if M is None:
                # Try direct key (some pipelines use normalized path equal to aligned key)
                M = transforms.get(os.path.normpath(aligned_path), None)
            if M is None:
                continue

            # Determine raw size
            raw_img, _, _, _ = load_image(raw_key) if os.path.exists(raw_key) else (None, None, None, None)
            if raw_img is None:
                # last resort: assume same canvas; still yields a conservative crop
                h_raw, w_raw = H, W
            else:
                if raw_img.ndim == 2:
                    h_raw, w_raw = raw_img.shape
                else:
                    h_raw, w_raw = raw_img.shape[:2]

            # Transform raw rectangle corners into aligned coords
            corners = np.array([
                [0,       0      ],
                [w_raw-1, 0      ],
                [w_raw-1, h_raw-1],
                [0,       h_raw-1]
            ], dtype=np.float32)

            # Apply affine: [x' y']^T = A*[x y]^T + t
            A = M[:, :2]; t = M[:, 2]
            quad = (corners @ A.T) + t  # shape (4,2)

            # Rasterize into coverage
            self._quad_coverage_add(cov, quad)

        # Threshold at requested coverage
        N = len(file_list)
        need = int(np.ceil((coverage_pct / 100.0) * N))
        mask = (cov >= need)

        # Largest rectangle of 1s
        rect = self._max_rectangle_in_binary(mask)
        return rect


    def create_image_registration_tab(self):
        """
        Creates an Image Registration tab that mimics how the Light tab handles
        cosmetic corrections—i.e., we have global Drizzle controls (checkbox, combo, spin),
        and we update a text column in the QTreeWidget to show each group's drizzle state.
        """
        tab = QWidget()
        layout = QVBoxLayout(tab)

        # ─────────────────────────────────────────
        # 1) QTreeWidget
        # ─────────────────────────────────────────
        self.reg_tree = QTreeWidget()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels([
            "Filter - Exposure - Size",
            "Metadata",
            "Drizzle"  # We'll display "Drizzle: True, Scale: 2x, Drop:0.65" here
        ])
        self.reg_tree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Optional: make columns resize nicely
        header = self.reg_tree.header()
        header.setSectionResizeMode(0, QHeaderView.ResizeMode.Stretch)
        header.setSectionResizeMode(1, QHeaderView.ResizeMode.ResizeToContents)
        header.setSectionResizeMode(2, QHeaderView.ResizeMode.Stretch)

        layout.addWidget(QLabel("Calibrated Light Frames"))
        layout.addWidget(self.reg_tree)

        tol_layout = QHBoxLayout()
        tol_layout.addWidget(QLabel("Exposure Tolerance (sec):"))
        self.exposure_tolerance_spin = QSpinBox()
        self.exposure_tolerance_spin.setRange(0, 900)
        self.exposure_tolerance_spin.setValue(0)
        self.exposure_tolerance_spin.setSingleStep(5)
        tol_layout.addWidget(self.exposure_tolerance_spin)
        tol_layout.addStretch()
        self.split_dualband_cb = QCheckBox("Split dual-band OSC before integration")
        self.split_dualband_cb.setToolTip("For OSC dual-band data: SII/OIII → R=SII, G=OIII; Ha/OIII → R=Ha, G=OIII")
        tol_layout.addWidget(self.split_dualband_cb)
        layout.addLayout(tol_layout)

        self.exposure_tolerance_spin.valueChanged.connect(lambda _: self.populate_calibrated_lights())

        # Populate the tree from your calibrated folder
        self.populate_calibrated_lights()


        # ─────────────────────────────────────────
        # 2) Buttons for Managing Files
        # ─────────────────────────────────────────
        btn_layout = QHBoxLayout()
        self.add_reg_files_btn = QPushButton("Add Light Files")
        self.add_reg_files_btn.clicked.connect(self.add_light_files_to_registration)
        btn_layout.addWidget(self.add_reg_files_btn)

        self.clear_selection_btn = QPushButton("Remove Selected")
        self.clear_selection_btn.clicked.connect(lambda: self.clear_tree_selection_registration(self.reg_tree))

        btn_layout.addWidget(self.clear_selection_btn)

        layout.addLayout(btn_layout)

        # ─────────────────────────────────────────
        # 3) Global Drizzle Controls
        # ─────────────────────────────────────────
        drizzle_layout = QHBoxLayout()

        self.drizzle_checkbox = QCheckBox("Enable Drizzle (beta)")
        self.drizzle_checkbox.stateChanged.connect(self.update_drizzle_settings)  # <─ connect signal
        drizzle_layout.addWidget(self.drizzle_checkbox)

        drizzle_layout.addWidget(QLabel("Scale:"))
        self.drizzle_scale_combo = QComboBox()
        self.drizzle_scale_combo.addItems(["1x", "2x", "3x"])
        self.drizzle_scale_combo.currentIndexChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_scale_combo)

        drizzle_layout.addWidget(QLabel("Drop Shrink:"))
        self.drizzle_drop_shrink_spin = QDoubleSpinBox()
        self.drizzle_drop_shrink_spin.setRange(0.0, 1.0)
        self.drizzle_drop_shrink_spin.setSingleStep(0.05)
        self.drizzle_drop_shrink_spin.setValue(0.65)
        self.drizzle_drop_shrink_spin.valueChanged.connect(self.update_drizzle_settings)  # <─ connect
        drizzle_layout.addWidget(self.drizzle_drop_shrink_spin)

        layout.addLayout(drizzle_layout)

        # ─────────────────────────────────────────
        # 4) Reference Frame Selection
        # ─────────────────────────────────────────
        self.ref_frame_label = QLabel("Select Reference Frame:")
        self.ref_frame_path = QLabel("No file selected")
        self.ref_frame_path.setWordWrap(True)
        self.select_ref_frame_btn = QPushButton("Select Reference Frame")
        self.select_ref_frame_btn.clicked.connect(self.select_reference_frame)

        ref_layout = QHBoxLayout()
        ref_layout.addWidget(self.ref_frame_label)
        ref_layout.addWidget(self.ref_frame_path)
        ref_layout.addWidget(self.select_ref_frame_btn)
        layout.addLayout(ref_layout)

        crop_row = QHBoxLayout()
        self.autocrop_cb = QCheckBox("Auto-crop output")
        self.autocrop_cb.setToolTip("Crop the final image to pixels covered by ≥ Coverage % of frames")
        self.autocrop_pct = QDoubleSpinBox()
        self.autocrop_pct.setRange(50.0, 100.0)
        self.autocrop_pct.setSingleStep(1.0)
        self.autocrop_pct.setSuffix(" %")
        self.autocrop_pct.setValue(self.settings.value("stacking/autocrop_pct", 95.0, type=float))
        self.autocrop_cb.setChecked(self.settings.value("stacking/autocrop_enabled", True, type=bool))
        crop_row.addWidget(self.autocrop_cb)
        crop_row.addWidget(QLabel("Coverage:"))
        crop_row.addWidget(self.autocrop_pct)
        crop_row.addStretch(1)
        layout.addLayout(crop_row)

        # ★★ Star-Trail Mode ★★
        trail_layout = QHBoxLayout()
        self.trail_cb = QCheckBox("★★ Star-Trail Mode ★★ (Max-Value Stack)")
        self.trail_cb.setChecked(self.star_trail_mode)
        self.trail_cb.setToolTip(
            "Skip registration/alignment and use Maximum-Intensity projection for star trails"
        )
        self.trail_cb.stateChanged.connect(self._on_star_trail_toggled)
        trail_layout.addWidget(self.trail_cb)
        layout.addLayout(trail_layout)
        # ─────────────────────────────────────────
        # 5) Register & Integrate Buttons
        # ─────────────────────────────────────────

        self.register_images_btn = QPushButton("🔥🚀Register and Integrate Images🔥🚀")
        self.register_images_btn.clicked.connect(self.register_images)
        self.register_images_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #FF6347;
            }
        """)
        layout.addWidget(self.register_images_btn)

        self.integrate_registered_btn = QPushButton("Integrate Previously Registered Images")
        self.integrate_registered_btn.clicked.connect(self.integrate_registered_images)
        self.integrate_registered_btn.setStyleSheet("""
            QPushButton {
                background-color: #333;
                color: white;
                font-size: 14px;
                padding: 8px;
                border-radius: 5px;
                border: 2px solid yellow;
            }
            QPushButton:hover {
                border: 2px solid #FFD700;
            }
            QPushButton:pressed {
                background-color: #222;
                border: 2px solid #FFA500;
            }
        """)
        layout.addWidget(self.integrate_registered_btn)

        tab.setLayout(layout)
        return tab

    def _on_star_trail_toggled(self, state):
        self.star_trail_mode = bool(state)
        self.settings.setValue("stacking/star_trail_mode", self.star_trail_mode)
        # if they turn it on, immediately override the rejection combo:
        if self.star_trail_mode:
            self.rejection_algorithm = "Maximum Value"
        else:
            # reload whatever the user picked
            self.rejection_algorithm = self.settings.value("stacking/rejection_algorithm",
                                                          self.rejection_algorithm,
                                                          type=str)

    def select_reference_frame(self):
        """ Opens a file dialog to select the reference frame. """
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Frame", "", 
                                                "FITS Images (*.fits *.fit);;All Files (*)")
        if file_path:
            self.reference_frame = file_path
            self.ref_frame_path.setText(os.path.basename(file_path))

    def save_master_paths_to_settings(self):
        """Save current master dark and flat paths to QSettings using their actual trees."""

        # Master Darks
        dark_paths = []
        for i in range(self.master_dark_tree.topLevelItemCount()):
            group = self.master_dark_tree.topLevelItem(i)
            for j in range(group.childCount()):
                fname = group.child(j).text(0)
                for path in self.master_files.values():
                    if os.path.basename(path) == fname:
                        dark_paths.append(path)

        # Master Flats
        flat_paths = []
        for i in range(self.master_flat_tree.topLevelItemCount()):
            group = self.master_flat_tree.topLevelItem(i)
            for j in range(group.childCount()):
                fname = group.child(j).text(0)
                for path in self.master_files.values():
                    if os.path.basename(path) == fname:
                        flat_paths.append(path)

        self.settings.setValue("stacking/master_darks", dark_paths)
        self.settings.setValue("stacking/master_flats", flat_paths)

    def clear_tree_selection(self, tree, file_dict):
        """Clears selected items from a simple (non-tuple-keyed) tree like Master Darks or Darks tab."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()
            if parent is None:
                # Top-level group item
                key = item.text(0)
                if key in file_dict:
                    del file_dict[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))
            else:
                # Child item
                key = parent.text(0)
                filename = item.text(0)
                if key in file_dict:
                    file_dict[key] = [f for f in file_dict[key] if os.path.basename(f) != filename]
                    if not file_dict[key]:
                        del file_dict[key]
                parent.removeChild(item)


    def clear_tree_selection_light(self, tree):
        """Clears the selection in the light tree and updates self.light_files accordingly."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()
            if parent is None:
                # Top-level filter node selected
                filter_name = item.text(0)
                # Remove all composite keys whose group_key starts with filter_name
                keys_to_remove = [key for key in list(self.light_files.keys())
                                if isinstance(key, tuple) and key[0].startswith(f"{filter_name} - ")]
                for key in keys_to_remove:
                    del self.light_files[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))
            else:
                if parent.parent() is None:
                    # Exposure node selected (child)
                    filter_name = parent.text(0)
                    exposure_text = item.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                    keys_to_remove = [key for key in list(self.light_files.keys())
                                    if isinstance(key, tuple) and key[0] == group_key]
                    for key in keys_to_remove:
                        del self.light_files[key]
                    parent.removeChild(item)
                else:
                    # Grandchild file node selected
                    filter_name = parent.parent().text(0)
                    exposure_text = parent.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                    filename = item.text(0)

                    keys_to_check = [key for key in list(self.light_files.keys())
                                    if isinstance(key, tuple) and key[0] == group_key]

                    for key in keys_to_check:
                        self.light_files[key] = [
                            f for f in self.light_files[key] if os.path.basename(f) != filename
                        ]
                        if not self.light_files[key]:
                            del self.light_files[key]
                    parent.removeChild(item)

    def clear_tree_selection_flat(self, tree, file_dict):
        """Clears the selection in the given tree widget and removes items from the corresponding dictionary."""
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()

            if parent:
                # Grandchild level (actual file)
                if parent.parent() is not None:
                    filter_name = parent.parent().text(0)
                    exposure_text = parent.text(0)
                    group_key = f"{filter_name} - {exposure_text}"
                else:
                    # Exposure level
                    filter_name = parent.text(0)
                    exposure_text = item.text(0)
                    group_key = f"{filter_name} - {exposure_text}"

                filename = item.text(0)

                # Remove from all matching (group_key, session) tuples
                keys_to_check = [key for key in list(file_dict.keys())
                                if isinstance(key, tuple) and key[0] == group_key]

                for key in keys_to_check:
                    file_dict[key] = [f for f in file_dict[key] if os.path.basename(f) != filename]
                    if not file_dict[key]:
                        del file_dict[key]

                parent.removeChild(item)
            else:
                # Top-level (filter group) selected
                filter_name = item.text(0)
                keys_to_remove = [key for key in list(file_dict.keys())
                                if isinstance(key, tuple) and key[0].startswith(f"{filter_name} - ")]
                for key in keys_to_remove:
                    del file_dict[key]
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))

    def _sync_group_userrole(self, top_item: QTreeWidgetItem):
        paths = []
        for i in range(top_item.childCount()):
            child = top_item.child(i)
            fp = child.data(0, Qt.ItemDataRole.UserRole)
            if fp:
                paths.append(fp)
        top_item.setData(0, Qt.ItemDataRole.UserRole, paths)

    def clear_tree_selection_registration(self, tree):
        selected_items = tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            parent = item.parent()

            if parent is None:
                # Remove entire group
                group_key = item.text(0)
                # Track deleted files (optional)
                full_paths = item.data(0, Qt.ItemDataRole.UserRole) or []
                self.deleted_calibrated_files.extend(p for p in full_paths
                                                    if p not in self.deleted_calibrated_files)
                # Remove from dict + tree
                self.reg_files.pop(group_key, None)
                tree.takeTopLevelItem(tree.indexOfTopLevelItem(item))

            else:
                # Remove a single child
                group_key = parent.text(0)
                filename = item.text(0)

                if group_key in self.reg_files:
                    self.reg_files[group_key] = [
                        f for f in self.reg_files[group_key]
                        if os.path.basename(f) != filename
                    ]
                    if not self.reg_files[group_key]:
                        del self.reg_files[group_key]

                # Track deleted path (optional)
                fp = item.data(0, Qt.ItemDataRole.UserRole)
                if fp and fp not in self.deleted_calibrated_files:
                    self.deleted_calibrated_files.append(fp)

                # Remove child from tree
                parent.removeChild(item)

                # 🔑 keep parent’s stored list in sync
                self._sync_group_userrole(parent)

    def rebuild_flat_tree(self):
        """Regroup flat frames in the flat_tree based on the exposure tolerance."""
        self.flat_tree.clear()

        if not self.flat_files:
            return

        tolerance = self.flat_exposure_tolerance_spinbox.value()

        # Flatten all flats into a list
        all_flats = []
        for (filter_exp_size, session_tag), files in self.flat_files.items():
            for file in files:
                all_flats.append((filter_exp_size, session_tag, file))

        # Group the flats
        grouped = {}

        for (filter_exp_size, session_tag, file_path) in all_flats:
            try:
                header = fits.getheader(file_path, ext=0)
                filter_name = header.get("FILTER", "Unknown")
                filter_name     = self._sanitize_name(filter_name)
                exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))
                width = header.get("NAXIS1", 0)
                height = header.get("NAXIS2", 0)
                image_size = f"{width}x{height}" if width and height else "Unknown"
                exposure = float(exposure)

                found_group = None
                for group_key in grouped.keys():
                    g_filter, g_min_exp, g_max_exp, g_size = group_key
                    if (
                        filter_name == g_filter and
                        image_size == g_size and
                        g_min_exp - tolerance <= exposure <= g_max_exp + tolerance
                    ):
                        found_group = group_key
                        break

                if found_group:
                    grouped[found_group].append((file_path, exposure))
                else:
                    new_key = (filter_name, exposure, exposure, image_size)
                    grouped[new_key] = [(file_path, exposure)]

            except Exception as e:
                print(f"⚠️ Failed reading {file_path}: {e}")

        # Now create the tree
        for (filter_name, min_exp, max_exp, image_size), files in grouped.items():
            top_item = QTreeWidgetItem()
            expmin = np.floor(min_exp)
            tolerance = self.flat_exposure_tolerance_spinbox.value()

            if len(files) > 1:
                exposure_str = f"{expmin:.1f}s–{(expmin + tolerance):.1f}s"
            else:
                exposure_str = f"{min_exp:.1f}s"

            top_item.setText(0, f"{filter_name} - {exposure_str} ({image_size})")
            top_item.setText(1, f"{len(files)} files")
            top_item.setText(2, "Auto-Selected Dark" if self.auto_select_dark_checkbox.isChecked() else "None")

            self.flat_tree.addTopLevelItem(top_item)

            for file_path, _ in files:
                session_tag = self.session_tags.get(file_path, "Default")
                leaf_item = QTreeWidgetItem([
                    os.path.basename(file_path),
                    f"Size: {image_size} | Session: {session_tag}"
                ])
                top_item.addChild(leaf_item)


    def exposures_within_tolerance(self, exp1, exp2, tolerance):
        try:
            return abs(float(exp1) - float(exp2)) <= tolerance
            
        except Exception:
            return False

    def parse_group_key(self, group_key):
        """
        Parses a group key string like 'Luminance - 90s (3000x2000)'
        into filter_name, exposure (float), and image_size (str).
        """
        try:
            parts = group_key.split(' - ')
            filter_name = parts[0]
            exp_size_part = parts[1] if len(parts) > 1 else ""

            # Separate exposure and size correctly
            if '(' in exp_size_part and ')' in exp_size_part:
                exposure_str, size_part = exp_size_part.split('(', 1)
                exposure = exposure_str.replace('s', '').strip()
                size = size_part.strip(') ').strip()
            else:
                exposure = exp_size_part.replace('s', '').strip()
                size = "Unknown"

            
            return filter_name, float(exposure), size

        except Exception as e:
            
            return "Unknown", 0.0, "Unknown"

    def _get_image_size(self, fp):
        ext = os.path.splitext(fp)[1].lower()
        # first try FITS
        if ext in (".fits", ".fit"):
            hdr0 = fits.getheader(fp, ext=0)
            data0 = fits.getdata(fp, ext=0)
            h, w = data0.shape[-2:]
        else:
            # try Pillow
            try:
                with Image.open(fp) as img:
                    w, h = img.size
            except Exception:
                # Pillow failed on TIFF or exotic format → try tifffile
                try:
                    arr = tiff.imread(fp)
                    h, w = arr.shape[:2]
                except Exception:
                    # last resort: OpenCV
                    arr = cv2.imread(fp, cv2.IMREAD_UNCHANGED)
                    if arr is None:
                        raise IOError(f"Cannot read image size for {fp}")
                    h, w = arr.shape[:2]
        return w, h


    def populate_calibrated_lights(self):
        """
        Reads both the Calibrated folder and any manually-added files,
        groups them by FILTER, EXPOSURE±tol, SIZE, and fills self.reg_tree.
        Now supports non-FITS images too.
        """
        from PIL import Image

        # 1) clear out the tree
        self.reg_tree.clear()
        self.reg_tree.setColumnCount(3)
        self.reg_tree.setHeaderLabels(["Filter - Exposure - Size", "Metadata", "Drizzle"])
        hdr = self.reg_tree.header()
        for col in (0, 1, 2):
            hdr.setSectionResizeMode(col, QHeaderView.ResizeMode.Interactive)

        # 2) gather all files
        calibrated_folder = os.path.join(self.stacking_directory or "", "Calibrated")
        files = []
        if os.path.isdir(calibrated_folder):
            for fn in os.listdir(calibrated_folder):
                files.append(os.path.join(calibrated_folder, fn))
        files += getattr(self, "manual_light_files", [])

        if not files:
            return

        # 3) group by header (or defaults)
        grouped = {}
        tol = self.exposure_tolerance_spin.value()
        for fp in files:
            ext = os.path.splitext(fp)[1].lower()
            filt = "Unknown"
            exp = 0.0
            size = "Unknown"
            # try FITS first
            if ext in (".fits", ".fit"):
                try:
                    hdr0 = fits.getheader(fp, ext=0)
                    filt = hdr0.get("FILTER", "Unknown")
                    filt = self._sanitize_name(filt)
                    exp_raw = hdr0.get("EXPOSURE", hdr0.get("EXPTIME", None))
                    try:
                        exp = float(exp_raw)
                    except (TypeError, ValueError):
                        print(f"⚠️ Exposure invalid in {fp}, defaulting to 0.0s")
                        exp = 0.0
                    data0 = fits.getdata(fp, ext=0)
                    h, w = data0.shape[-2:]
                    size = f"{w}x{h}"
                except Exception as e:
                    print(f"⚠️ Could not read FITS {fp}: {e}; treating as generic image")
                    # fall through to generic
            if filt == "Unknown" and ext not in (".fits", ".fit"):
                # generic image: try PIL
                try:
                    w, h = self._get_image_size(fp)
                    size = f"{w}x{h}"
                except Exception as e:
                    print(f"⚠️ Cannot read image size for {fp}: {e}")
                    continue

            # now we have filt, exp, size
            # find existing group
            match = None
            for key in grouped:
                f2, e2, s2 = self.parse_group_key(key)
                if filt == f2 and s2 == size and abs(exp - e2) <= tol:
                    match = key
                    break
            if match:
                key = match
            else:
                key = f"{filt} - {exp:.1f}s ({size})"
                grouped[key] = []
            grouped[key].append((fp, exp))

        # 4) populate the tree & store in self.light_files
        self.light_files = {}
        for key, lst in grouped.items():
            paths = [p for p, _ in lst]
            exps  = [e for _, e in lst]

            top = QTreeWidgetItem()
            top.setText(0, key)
            if len(exps) > 1:
                mn, mx = min(exps), max(exps)
                top.setText(1, f"{len(paths)} files, {mn:.0f}s–{mx:.0f}s")
            else:
                top.setText(1, f"{len(paths)} file")
            top.setText(2, "Drizzle: False")
            top.setData(0, Qt.ItemDataRole.UserRole, paths)
            self.reg_tree.addTopLevelItem(top)

            for fp, _ in lst:
                # leaf row: show basename + size
                # re-use the size we computed above
                leaf = QTreeWidgetItem([os.path.basename(fp), f"Size: {size}"])
                leaf.setData(0, Qt.ItemDataRole.UserRole, fp)
                top.addChild(leaf)

            top.setExpanded(True)
            self.light_files[key] = paths



    def update_drizzle_settings(self):
        """
        Called whenever the user toggles the 'Enable Drizzle' checkbox,
        changes the scale combo, or changes the drop shrink spinbox.
        Applies to all *selected* top-level items in the reg_tree.
        """
        # Current states from global controls
        drizzle_enabled = self.drizzle_checkbox.isChecked()
        scale_str = self.drizzle_scale_combo.currentText()  # e.g. "1x","2x","3x"
        drop_val = self.drizzle_drop_shrink_spin.value()    # e.g. 0.65

        # Gather selected items
        selected_items = self.reg_tree.selectedItems()
        if not selected_items:
            return

        for item in selected_items:
            # If the user selected a child row, go up to its parent group
            if item.parent() is not None:
                item = item.parent()

            group_key = item.text(0)

            if drizzle_enabled:
                # Show scale + drop shrink
                drizzle_text = (f"Drizzle: True, "
                                f"Scale: {scale_str}, "
                                f"Drop: {drop_val:.2f}")
            else:
                # Just show "Drizzle: False"
                drizzle_text = "Drizzle: False"

            # Update column 2 with the new text
            item.setText(2, drizzle_text)

            # If you also store it in a dictionary:
            self.per_group_drizzle[group_key] = {
                "enabled": drizzle_enabled,
                "scale": float(scale_str.replace("x","", 1)),
                "drop": drop_val
            }


    def gather_drizzle_settings_from_tree(self):
        """
        Returns: { group_key: {files:[...], drizzle_enabled:bool,
                            scale_factor:float, drop_shrink:float} }
        """
        dd = {}
        for i in range(self.reg_tree.topLevelItemCount()):
            item = self.reg_tree.topLevelItem(i)
            key  = item.text(0)
            files= item.data(0, Qt.ItemDataRole.UserRole) or []
            txt  = item.text(2).lower()

            ena = txt.startswith("drizzle: true")
            sf  = 1.0
            ds  = 0.65
            if ena:
                m = re.search(r"scale\s*:\s*([\d\.]+)x?", txt)
                if m: sf = float(m.group(1))
                m = re.search(r"drop\s*:\s*([\d\.]+)", txt)
                if m: ds = float(m.group(1))

            dd[key] = {
                "files": files,
                "drizzle_enabled": ena,
                "scale_factor": sf,
                "drop_shrink": ds
            }

        # backfill any group that lived only in self.light_files
        for key, fl in self.light_files.items():
            if key not in dd:
                dd[key] = {
                    "files": fl,
                    "drizzle_enabled": False,
                    "scale_factor": 1.0,
                    "drop_shrink": 0.65
                }

        return dd



    def add_light_files_to_registration(self):
        """
        Let the user pick some new LIGHT frames, then
        immediately re-populate the tree so they show up
        in the same Filter–Exposure–Size groups as everything else.
        """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(
            self,
            "Select Light Frames",
            last_dir,
            "FITS Files (*.fits *.fit *.fz *.fz *.xisf *.tif *.tiff *.png *.jpg *.jpeg)"
        )
        if not files:
            return

        # remember for next time
        self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))

        # store these in a manual list, then rebuild the tree
        if not hasattr(self, "manual_light_files"):
            self.manual_light_files = []
        self.manual_light_files.extend(files)

        # rebuild the registration tree (it reads manual_light_files + calibrated folder)
        self.populate_calibrated_lights()





    def on_tab_changed(self, index):
        """ Detects when user switches to the Flats tab and triggers auto-assign. """
        if self.tabs.tabText(index) == "Flats":
            print("🔄 Auto-checking best Master Darks for Flats...")
            self.assign_best_master_dark()


    def add_dark_files(self):
        self.add_files(self.dark_tree, "Select Dark Files", "DARK")
    
    def add_dark_directory(self):
        self.add_directory(self.dark_tree, "Select Dark Directory", "DARK")

    def add_flat_files(self):
        self.prompt_session_before_adding("FLAT")


    def add_flat_directory(self):
        self.prompt_session_before_adding("FLAT", directory_mode=True)


    
    def add_light_files(self):
        self.prompt_session_before_adding("LIGHT")

    
    def add_light_directory(self):
        self.prompt_session_before_adding("LIGHT", directory_mode=True)


    def prompt_session_before_adding(self, frame_type, directory_mode=False):
        # 🔥 Prompt user first
        text, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session name:", text="Default")
        if not (ok and text.strip()):
            return

        session_name = text.strip()

        # 🔥 Set it globally before adding
        self.current_session_tag = session_name

        # 🔥 Then add files or directory
        if frame_type.upper() == "FLAT":
            if directory_mode:
                self.add_directory(self.flat_tree, "Select Flat Directory", "FLAT")
            else:
                self.add_files(self.flat_tree, "Select Flat Files", "FLAT")
            self.assign_best_master_dark()
            self.rebuild_flat_tree()

        elif frame_type.upper() == "LIGHT":
            if directory_mode:
                self.add_directory(self.light_tree, "Select Light Directory", "LIGHT")
            else:
                self.add_files(self.light_tree, "Select Light Files", "LIGHT")
            self.assign_best_master_files()

    def load_master_dark(self):
        """ Loads a Master Dark and updates the UI. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)  # Get last folder
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Dark", last_dir, "FITS Files (*.fits *.fit)")
        
        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last used folder
            self.add_master_files(self.master_dark_tree, "DARK", files)
            self.save_master_paths_to_settings() 

        self.update_override_dark_combo()
        self.assign_best_master_dark()
        self.assign_best_master_files()
        print("DEBUG: Loaded Master Darks and updated assignments.")


    def load_master_flat(self):
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, "Select Master Flat", last_dir, "FITS Files (*.fits *.fit)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))
            self.add_master_files(self.master_flat_tree, "FLAT", files)
            self.save_master_paths_to_settings() 


    def add_files(self, tree, title, expected_type):
        """ Adds FITS files and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        files, _ = QFileDialog.getOpenFileNames(self, title, last_dir, "FITS Files (*.fits *.fit *.fz *.fz)")

        if files:
            self.settings.setValue("last_opened_folder", os.path.dirname(files[0]))  # Save last opened folder
            for file in files:
                self.process_fits_header(file, tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()



    def add_directory(self, tree, title, expected_type):
        """ Adds all FITS files from a directory and assigns best master files if needed. """
        last_dir = self.settings.value("last_opened_folder", "", type=str)
        directory = QFileDialog.getExistingDirectory(self, title, last_dir)

        if directory:
            self.settings.setValue("last_opened_folder", directory)  # Save last opened folder
            for file in os.listdir(directory):
                if file.lower().endswith((".fits", ".fit", ".fz", ".fz")):
                    self.process_fits_header(os.path.join(directory, file), tree, expected_type)

            # 🔥 Auto-assign Master Dark & Flat **if adding LIGHTS**
            if expected_type == "LIGHT":
                self.assign_best_master_files()

    def _sanitize_name(self, name: str) -> str:
        """
        Replace any character that isn’t a letter, digit, space, dash or underscore
        with an underscore so it’s safe to use in filenames, dict-keys, tree labels, etc.
        """
        return re.sub(r"[^\w\s\-]", "_", name)
    
    def process_fits_header(self, file_path, tree, expected_type):
        try:
            # Read only the FITS header (fast)
            header, _ = get_valid_header(file_path)

            try:
                width = int(header.get("NAXIS1"))
                height = int(header.get("NAXIS2"))
            except Exception as e:
                self.update_status(f"Warning: Could not convert dimensions to int for {file_path}: {e}")
                width, height = None, None

            if width is not None and height is not None:
                image_size = f"{width}x{height}"
            else:
                image_size = "Unknown"

            # Retrieve IMAGETYP (default to "UNKNOWN" if not present)
            imagetyp = header.get("IMAGETYP", "UNKNOWN").lower()

            # Retrieve exposure from either EXPOSURE or EXPTIME
            exposure_val = header.get("EXPOSURE")
            if not exposure_val:
                exposure_val = header.get("EXPTIME")
            if not exposure_val:
                exposure_val = "Unknown"  # fallback if neither keyword is present

            # Define forbidden keywords per expected type.
            if expected_type.upper() == "DARK":
                forbidden = ["light", "flat"]
            elif expected_type.upper() == "FLAT":
                forbidden = ["dark", "light"]
            elif expected_type.upper() == "LIGHT":
                forbidden = ["dark", "flat"]
            else:
                forbidden = []

            # Determine attribute name for auto-confirm decision (per expected type)
            decision_attr = f"auto_confirm_{expected_type.lower()}"
            # If a decision has already been made, use it.
            if hasattr(self, decision_attr):
                decision = getattr(self, decision_attr)
                if decision is False:
                    # Skip this file automatically.
                    return
                # If decision is True, then add without prompting.
            elif any(word in imagetyp for word in forbidden):
                # Prompt the user with Yes, Yes to All, No, and No to All options.
                msgBox = QMessageBox(self)
                msgBox.setWindowTitle("Mismatched Image Type")
                msgBox.setText(
                    f"The file:\n{os.path.basename(file_path)}\n"
                    f"has IMAGETYP = {header.get('IMAGETYP')} "
                    f"which does not match the expected type ({expected_type}).\n\n"
                    f"Do you want to add it anyway?"
                )
                yesButton = msgBox.addButton("Yes", QMessageBox.ButtonRole.YesRole)
                yesToAllButton = msgBox.addButton("Yes to All", QMessageBox.ButtonRole.YesRole)
                noButton = msgBox.addButton("No", QMessageBox.ButtonRole.NoRole)
                noToAllButton = msgBox.addButton("No to All", QMessageBox.ButtonRole.NoRole)
                msgBox.exec()
                clicked = msgBox.clickedButton()
                if clicked == yesToAllButton:
                    setattr(self, decision_attr, True)
                elif clicked == noToAllButton:
                    setattr(self, decision_attr, False)
                    return
                elif clicked == noButton:
                    return

            # Now handle each expected type
            if expected_type.upper() == "DARK":
                key = f"{exposure_val} ({image_size})"
                if key not in self.dark_files:
                    self.dark_files[key] = []
                self.dark_files[key].append(file_path)

                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    exposure_item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(exposure_item)
                else:
                    exposure_item = items[0]
                metadata = f"Size: {image_size}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

            elif expected_type.upper() == "FLAT":
                filter_name = header.get("FILTER", "Unknown")
                filter_name = self._sanitize_name(filter_name)
                flat_key = f"{filter_name} - {exposure_val} ({image_size})"
                session_tag = getattr(self, "current_session_tag", "Default")
                composite_key = (flat_key, session_tag)

                if composite_key not in self.flat_files:
                    self.flat_files[composite_key] = []
                self.flat_files[composite_key].append(file_path)

                # ✅ Also store session tag internally
                self.session_tags[file_path] = session_tag

                # Tree UI update
                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]

                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)

                metadata = f"Size: {image_size} | Session: {session_tag}"
                exposure_item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))


            elif expected_type.upper() == "LIGHT":
                filter_name = header.get("FILTER", "Unknown")
                filter_name = self._sanitize_name(filter_name)
                session_tag = getattr(self, "current_session_tag", "Default")  # ⭐️ Step 1: Get session label

                light_key = f"{filter_name} - {exposure_val} ({image_size})"
                composite_key = (light_key, session_tag)

                if composite_key not in self.light_files:
                    self.light_files[composite_key] = []
                self.light_files[composite_key].append(file_path)

                # Update Tree UI
                filter_items = tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)
                if not filter_items:
                    filter_item = QTreeWidgetItem([filter_name])
                    tree.addTopLevelItem(filter_item)
                else:
                    filter_item = filter_items[0]

                exposure_items = [filter_item.child(i) for i in range(filter_item.childCount())]
                exposure_item = next((item for item in exposure_items
                                    if item.text(0) == f"{exposure_val} ({image_size})"), None)
                if not exposure_item:
                    exposure_item = QTreeWidgetItem([f"{exposure_val} ({image_size})"])
                    filter_item.addChild(exposure_item)

                leaf_item = QTreeWidgetItem([os.path.basename(file_path), f"Size: {image_size} | Session: {session_tag}"])
                exposure_item.addChild(leaf_item)
                self.session_tags[file_path] = session_tag  # ✅ Store per-file session tag here


            self.update_status(f"✅ Added {os.path.basename(file_path)} as {expected_type}")
            QApplication.processEvents()

        except Exception as e:
            self.update_status(f"❌ ERROR: Could not read FITS header for {file_path} - {e}")
            QApplication.processEvents()


    def add_master_files(self, tree, file_type, files):
        """ 
        Adds multiple master calibration files to the correct treebox with metadata including image dimensions.
        This version only reads the FITS header to extract image dimensions, making it much faster.
        """
        for file_path in files:
            try:
                # Read only the FITS header (fast)
                header = fits.getheader(file_path)
                
                # Check for both EXPOSURE and EXPTIME
                exposure = header.get("EXPOSURE", header.get("EXPTIME", "Unknown"))
                filter_name = header.get("FILTER", "Unknown")
                filter_name     = self._sanitize_name(filter_name)
                # Extract image dimensions from header keywords NAXIS1 and NAXIS2
                width = header.get("NAXIS1")
                height = header.get("NAXIS2")
                if width is not None and height is not None:
                    image_size = f"{width}x{height}"
                else:
                    image_size = "Unknown"
                
                # Construct key based on file type
                if file_type.upper() == "DARK":
                    key = f"{exposure}s ({image_size})"
                    self.master_files[key] = file_path  # Store master dark
                    self.master_sizes[file_path] = image_size  # Store size
                elif file_type.upper() == "FLAT":
                    # Attempt to extract session name from filename
                    session_name = "Default"
                    filename = os.path.basename(file_path)
                    if filename.lower().startswith("masterflat_"):
                        parts = filename.split("_")
                        if len(parts) > 1:
                            session_name = parts[1]

                    key = f"{filter_name} ({image_size}) [{session_name}]"
                    self.master_files[key] = file_path
                    self.master_sizes[file_path] = image_size

                # Extract additional metadata from header.
                sensor_temp = header.get("CCD-TEMP", "N/A")
                date_obs = header.get("DATE-OBS", "Unknown")
                metadata = f"Size: {image_size}, Temp: {sensor_temp}°C, Date: {date_obs}"

                # Check if category item already exists in the tree.
                items = tree.findItems(key, Qt.MatchFlag.MatchExactly, 0)
                if not items:
                    item = QTreeWidgetItem([key])
                    tree.addTopLevelItem(item)
                else:
                    item = items[0]

                # Add the master file as a child node with metadata.
                item.addChild(QTreeWidgetItem([os.path.basename(file_path), metadata]))

                print(f"✅ DEBUG: Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                self.update_status(f"✅ Added Master {file_type} -> {file_path} under {key} with metadata: {metadata}")
                print(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                self.update_status(f"📂 DEBUG: Master Files Stored: {self.master_files}")
                QApplication.processEvents()
                self.assign_best_master_files()

            except Exception as e:
                print(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                self.update_status(f"❌ ERROR: Failed to load master file {file_path} - {e}")
                QApplication.processEvents()



    def create_master_dark(self):
        """ Creates master darks with minimal RAM usage by loading frames in small tiles. """

        if not self.stacking_directory:
            self.select_stacking_directory()
            if not self.stacking_directory:
                QMessageBox.warning(self, "Error", "Output directory is not set.")
                return

        exposure_tolerance = self.exposure_tolerance_spinbox.value()
        dark_files_by_group = {}

        # 1) Group dark files by exposure time & image size within tolerance
        for exposure_key, file_list in self.dark_files.items():
            exposure_time_str, image_size = exposure_key.split(" (")
            image_size = image_size.rstrip(")")
            exposure_time = float(exposure_time_str.replace("s", "")) if "Unknown" not in exposure_time_str else 0

            matched_group = None
            for (existing_exposure, existing_size) in dark_files_by_group.keys():
                if abs(existing_exposure - exposure_time) <= exposure_tolerance and existing_size == image_size:
                    matched_group = (existing_exposure, existing_size)
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size)
                dark_files_by_group[matched_group] = []

            dark_files_by_group[matched_group].extend(file_list)

        # 2) Create Master Calibration Directory
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # 3) Stack Each Group in a Chunked Manner
        chunk_height = self.chunk_height
        chunk_width  = self.chunk_width

        for (exposure_time, image_size), file_list in dark_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) - Not enough frames to stack.")
                QApplication.processEvents()
                continue

            self.update_status(f"🟢 Processing {len(file_list)} darks for {exposure_time}s ({image_size}) exposure...")
            QApplication.processEvents()

            # (A) Identify reference shape from the first file
            ref_file = file_list[0]
            ref_data, ref_header, bit_depth, is_mono = load_image(ref_file)
            if ref_data is None:
                self.update_status(f"❌ Failed to load reference {os.path.basename(ref_file)}")
                continue

            height, width = ref_data.shape[:2]
            channels = 1 if (ref_data.ndim == 2) else 3

            # (B) Create a memmap for the final stacked result
            # shape=(height, width, channels)
            memmap_path = os.path.join(master_dir, f"temp_dark_{exposure_time}_{image_size}.dat")
            final_stacked = np.memmap(
                memmap_path,
                dtype=np.float64,
                mode='w+',
                shape=(height, width, channels)
            )

            # (C) For each tile, load that tile from all frames, do outlier rejection, store in final_stacked
            num_frames = len(file_list)

            for y_start in range(0, height, chunk_height):
                y_end = min(y_start + chunk_height, height)
                tile_h = y_end - y_start

                for x_start in range(0, width, chunk_width):
                    x_end = min(x_start + chunk_width, width)
                    tile_w = x_end - x_start

                    # tile_stack shape => (num_frames, tile_h, tile_w, channels)
                    tile_stack = np.zeros((num_frames, tile_h, tile_w, channels), dtype=np.float32)


                    num_cores = os.cpu_count() or 4
                    with ThreadPoolExecutor(max_workers=num_cores) as executor:
                        future_to_index = {}
                        # 1) Submit each file’s tile load in parallel
                        for i, fpath in enumerate(file_list):
                            future = executor.submit(load_fits_tile, fpath, y_start, y_end, x_start, x_end)
                            future_to_index[future] = i

                        # 2) Collect results as they complete
                        for future in as_completed(future_to_index):
                            i = future_to_index[future]
                            sub_img = future.result()
                            if sub_img is None:
                                continue

                            # --- shape handling (same as before) ---
                            # If sub_img is (H,W) & channels=3 => expand
                            if sub_img.ndim == 2 and channels == 3:
                                sub_img = np.repeat(sub_img[:, :, np.newaxis], 3, axis=2)
                            elif sub_img.ndim == 2 and channels == 1:
                                sub_img = sub_img[:, :, np.newaxis]

                            # If sub_img is (3,H,W) but we want (H,W,3), transpose
                            if sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                                sub_img = sub_img.transpose(1, 2, 0)

                            sub_img = sub_img.astype(np.float32, copy=False)
                            tile_stack[i] = sub_img

                    # (D) Outlier rejection => tile_result
                    # Use your existing 3D or 4D Windsorized Sigma Clip depending on channels
                    if channels == 3:
                        # tile_stack => shape (F,H,W,3)
                        tile_result = windsorized_sigma_clip_4d(
                            tile_stack,
                            lower=self.sigma_low,
                            upper=self.sigma_high
                        )
                        # If the function returns a tuple, extract the first element.
                        if isinstance(tile_result, tuple):
                            tile_result = tile_result[0]
                    else:
                        # tile_stack => shape (F,H,W,1) or (F,H,W)
                        # If shape=(F,H,W,1), we can squeeze or just call 3D version
                        tile_stack_3d = tile_stack[..., 0] if tile_stack.ndim == 4 else tile_stack
                        tile_result_3d = windsorized_sigma_clip_3d(tile_stack_3d, lower=self.sigma_low, upper=self.sigma_high)
                        # If the function returns a tuple, extract the first element.
                        if isinstance(tile_result_3d, tuple):
                            tile_result_3d = tile_result_3d[0]
                        # Now, ensure the result has shape (H, W, 1)
                        tile_result = tile_result_3d[..., np.newaxis]

                    # (E) Store tile_result in final_stacked
                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

            # Convert final_stacked to a normal array
            master_dark_data = np.array(final_stacked)
            del final_stacked

            # (F) Save Master Dark
            master_dark_path = os.path.join(master_dir, f"MasterDark_{int(exposure_time)}s_{image_size}.fit")

            # Build a minimal header
            # Possibly store EXPTIME, IMAGETYP="DARK", etc.
            master_header = fits.Header()
            master_header["IMAGETYP"] = "DARK"
            master_header["EXPTIME"]  = (exposure_time, "User-specified or from grouping")
            # plus any other fields you want

            # Remove NAXIS from the old ref_header if you want
            # or define them fresh
            master_header["NAXIS"] = 3 if channels==3 else 2
            master_header["NAXIS1"] = master_dark_data.shape[1]
            master_header["NAXIS2"] = master_dark_data.shape[0]
            if channels==3:
                master_header["NAXIS3"] = 3

            save_image(
                img_array=master_dark_data,
                filename=master_dark_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=master_header,
                is_mono=(channels==1)
            )

            # (G) Add to tree, status, etc.
            self.add_master_dark_to_tree(f"{exposure_time}s ({image_size})", master_dark_path)
            self.update_status(f"✅ Master Dark saved: {master_dark_path}")
            self.assign_best_master_files()
            self.save_master_paths_to_settings()

        # Finally, assign best master dark, etc.
        self.assign_best_master_dark()
        self.update_override_dark_combo()
        self.assign_best_master_files()



    def save_master_dark(self, master_dark, output_path, exposure_time, is_mono):
        """Saves the master dark as 32-bit floating point FITS while maintaining OSC structure."""
        if is_mono:
            # Mono => shape (H, W)
            h, w = master_dark.shape
            # Wrap in an HDU
            hdu_data = master_dark.astype(np.float32)
            hdu = fits.PrimaryHDU(hdu_data)
            image_size = f"{w}x{h}"  # Width x Height
        else:
            # Color => shape (H, W, C)
            h, w, c = master_dark.shape
            # Transpose to (C, H, W)
            hdu_data = master_dark.transpose(2, 0, 1).astype(np.float32)
            hdu = fits.PrimaryHDU(hdu_data)
            image_size = f"{w}x{h}"

        # Now 'hdu' is a fits.PrimaryHDU in both branches
        hdr = hdu.header
        hdr["SIMPLE"]   = True
        hdr["BITPIX"]   = -32
        hdr["NAXIS"]    = 3 if not is_mono else 2
        hdr["NAXIS1"]   = w  # Width
        hdr["NAXIS2"]   = h  # Height
        if not is_mono:
            hdr["NAXIS3"] = c
        hdr["BSCALE"]   = 1.0
        hdr["BZERO"]    = 0.0
        hdr["IMAGETYP"] = "MASTER DARK"
        hdr["EXPOSURE"] = exposure_time
        hdr["DATE-OBS"] = datetime.utcnow().isoformat()
        hdr["CREATOR"]  = "SetiAstroSuite"

        # Write the FITS file
        hdu.writeto(output_path, overwrite=True)

        # Store Master Dark path with correct key
        key = f"{exposure_time}s ({image_size})"
        self.master_files[key] = output_path
        self.master_sizes[output_path] = image_size

        print(f"✅ Master Dark FITS saved: {output_path}")
        self.update_status(f"✅ Stored Master Dark -> {key}: {output_path}")



            
    def add_master_dark_to_tree(self, exposure_time, master_dark_path):
        """ Adds the newly created Master Dark to the Master Dark TreeBox and updates the dropdown. """

        exposure_key = f"{exposure_time}s"

        # ✅ Store in the dictionary
        self.master_files[exposure_key] = master_dark_path  # Store master dark
        print(f"📝 DEBUG: Stored Master Dark -> {exposure_key}: {master_dark_path}")

        # ✅ Update UI Tree
        existing_items = self.master_dark_tree.findItems(exposure_key, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            exposure_item = existing_items[0]
        else:
            exposure_item = QTreeWidgetItem([exposure_key])
            self.master_dark_tree.addTopLevelItem(exposure_item)

        master_item = QTreeWidgetItem([os.path.basename(master_dark_path)])
        exposure_item.addChild(master_item)

        # ✅ Refresh the override dropdown
        self.update_override_dark_combo()
        self.assign_best_master_dark()  # 🔥 Ensure auto-selection works

        self.update_status(f"✅ Master Dark saved and added to UI: {master_dark_path}")



    def assign_best_master_dark(self):
        """ Assigns the closest matching master dark based on exposure & image size. """
        print("\n🔍 DEBUG: Assigning best master darks to flats...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Darks available.")
            self.update_status("⚠️ WARNING: No Master Darks available.")
            return  # Exit early if there are no master darks

        print(f"📂 Loaded Master Darks ({len(self.master_files)} total):")
        for key, value in self.master_files.items():
            print(f"   📌 {key} -> {value}")

        # Iterate through all flat filters
        for i in range(self.flat_tree.topLevelItemCount()):
            filter_item = self.flat_tree.topLevelItem(i)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)  # Example: "0.0007s (8288x5644)"

                # Extract exposure time
                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue  # Skip if exposure is invalid

                exposure_time = float(match.group(1))  # Extracted number
                print(f"🟢 Checking Flat Group: {exposure_text} (Parsed: {exposure_time}s)")

                # Extract image size from metadata
                if exposure_item.childCount() > 0:
                    metadata_text = exposure_item.child(0).text(1)  # Metadata column
                    size_match = re.search(r"Size: (\d+x\d+)", metadata_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                else:
                    image_size = "Unknown"

                print(f"✅ Parsed Flat Size: {image_size}")

                # Find the best matching master dark
                best_match = None
                best_diff = float("inf")

                for master_dark_exposure, master_dark_path in self.master_files.items():
                    master_dark_exposure_match = re.match(r"([\d.]+)s?", master_dark_exposure)
                    if not master_dark_exposure_match:
                        continue  # Skip if master dark exposure is invalid

                    master_dark_exposure_time = float(master_dark_exposure_match.group(1))
                    master_dark_size = self.master_sizes.get(master_dark_path, "Unknown")
                    if master_dark_size == "Unknown":
                        with fits.open(master_dark_path) as hdul:
                            master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                            self.master_sizes[master_dark_path] = master_dark_size  # ✅ Store it

                    print(f"🔎 Comparing with Master Dark: {master_dark_exposure_time}s ({master_dark_size})")

                    # Match both image size and exposure time
                    if image_size == master_dark_size:
                        diff = abs(master_dark_exposure_time - exposure_time)
                        if diff < best_diff:
                            best_match = master_dark_path
                            best_diff = diff

                # Assign best match in column 3
                if best_match:
                    exposure_item.setText(2, os.path.basename(best_match))
                    print(f"🔵 Assigned Master Dark: {os.path.basename(best_match)}")
                else:
                    exposure_item.setText(2, "None")
                    print(f"⚠️ No matching Master Dark found for {exposure_text}")

        # 🔥 Force UI update to reflect changes
        self.flat_tree.viewport().update()

        print("\n✅ DEBUG: Finished assigning best matching Master Darks to Flats.\n")



    def update_override_dark_combo(self):
        """ Populates the dropdown with available Master Darks and prevents duplicate entries. """
        self.override_dark_combo.clear()
        self.override_dark_combo.addItem("None (Use Auto-Select)")
        self.override_dark_combo.addItem("None (Use no Dark to Calibrate)")

        seen_files = set()
        for exposure, path in self.master_files.items():
            file_name = os.path.basename(path)
            if file_name not in seen_files:
                self.override_dark_combo.addItem(f"{file_name} ({exposure})")
                seen_files.add(file_name)

        print("✅ DEBUG: Updated Override Master Dark dropdown with unique entries.")


    def override_selected_master_dark(self):
        """ Overrides the selected master dark for the currently highlighted flat group. """
        selected_items = self.flat_tree.selectedItems()
        if not selected_items:
            return

        new_dark = self.override_dark_combo.currentText()

        # ✅ Handle "None (Use no Dark to Calibrate)" explicitly
        if new_dark == "None (Use no Dark to Calibrate)":
            new_dark = "No Calibration"  # Show "No Calibration" in the UI
        elif new_dark == "None (Use Auto-Select)":
            new_dark = None  # Auto-select behavior

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, new_dark if new_dark else "Auto")

        print(f"✅ DEBUG: Override Master Dark set to: {new_dark}")

    def create_master_flat(self):
        """ Creates master flats using per-frame dark subtraction before stacking. """

        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first using the wrench button.")
            return

        exposure_tolerance = self.flat_exposure_tolerance_spinbox.value()
        flat_files_by_group = {}  # Group by (Exposure, Image Size, Filter, Session)

        # Group Flats by Filter, Exposure & Size within Tolerance
        for (filter_exposure, session), file_list in self.flat_files.items():
            try:
                filter_name, exposure_size = filter_exposure.split(" - ")
                exposure_time_str, image_size = exposure_size.split(" (")
                image_size = image_size.rstrip(")")
            except ValueError:
                self.update_status(f"⚠️ ERROR: Could not parse {filter_exposure}")
                continue

            match = re.match(r"([\d.]+)s?", exposure_time_str)
            exposure_time = float(match.group(1)) if match else -10.0

            matched_group = None
            for key in flat_files_by_group:
                existing_exposure, existing_size, existing_filter, existing_session = key
                if (
                    abs(existing_exposure - exposure_time) <= exposure_tolerance
                    and existing_size == image_size
                    and existing_filter == filter_name
                    and existing_session == session
                ):
                    matched_group = key
                    break

            if matched_group is None:
                matched_group = (exposure_time, image_size, filter_name, session)
                flat_files_by_group[matched_group] = []

            flat_files_by_group[matched_group].extend(file_list)

        # Create output folder
        master_dir = os.path.join(self.stacking_directory, "Master_Calibration_Files")
        os.makedirs(master_dir, exist_ok=True)

        # Stack each grouped flat set
        for (exposure_time, image_size, filter_name, session), file_list in flat_files_by_group.items():
            if len(file_list) < 2:
                self.update_status(f"⚠️ Skipping {exposure_time}s ({image_size}) [{filter_name}] [{session}] - Not enough frames to stack.")
                continue

            self.update_status(f"🟢 Processing {len(file_list)} flats for {exposure_time}s ({image_size}) [{filter_name}] in session '{session}'...")
            QApplication.processEvents()

            # Load master dark
            best_diff = float("inf")
            selected_master_dark = None
            for key, path in self.master_files.items():
                match = re.match(r"([\d.]+)s", key)
                if not match:
                    continue
                dark_exposure = float(match.group(1))
                dark_size = self.master_sizes.get(path, "Unknown")
                if dark_size == image_size:
                    diff = abs(dark_exposure - exposure_time)
                    if diff < best_diff:
                        best_diff = diff
                        selected_master_dark = path

            if selected_master_dark:
                dark_data, _, _, _ = load_image(selected_master_dark)
            else:
                dark_data = None
                self.update_status("DEBUG: No matching Master Dark found.")

            # Load reference image
            ref_data, _, _, _ = load_image(file_list[0])
            if ref_data is None:
                self.update_status(f"❌ Failed to load reference {os.path.basename(file_list[0])}")
                continue

            height, width = ref_data.shape[:2]
            channels = 1 if ref_data.ndim == 2 else 3
            memmap_path = os.path.join(master_dir, f"temp_flat_{session}_{exposure_time}_{image_size}_{filter_name}.dat")
            final_stacked = np.memmap(memmap_path, dtype=np.float64, mode="w+", shape=(height, width, channels))
            num_frames = len(file_list)

            for y_start in range(0, height, self.chunk_height):
                y_end = min(y_start + self.chunk_height, height)
                tile_h = y_end - y_start
                for x_start in range(0, width, self.chunk_width):
                    x_end = min(x_start + self.chunk_width, width)
                    tile_w = x_end - x_start
                    tile_stack = np.zeros((num_frames, tile_h, tile_w, channels), dtype=np.float32)

                    with ThreadPoolExecutor() as executor:
                        
                        futures = {
                            executor.submit(load_fits_tile, f, y_start, y_end, x_start, x_end): idx
                            for idx, f in enumerate(file_list)
                        }

                        for future in as_completed(futures):
                            i = futures[future]
                            sub_img = future.result()
                            if sub_img is None:
                                self.update_status(f"⚠️ Skipping tile {i} due to load failure.")
                                continue

                            # Ensure correct shape
                            if sub_img.ndim == 2:
                                sub_img = sub_img[:, :, np.newaxis]
                                if channels == 3:
                                    sub_img = np.repeat(sub_img, 3, axis=2)
                            elif sub_img.shape[0] == 3:
                                sub_img = sub_img.transpose(1, 2, 0)

                            tile_stack[i] = sub_img


                    if dark_data is not None:
                        dark_tile = dark_data[y_start:y_end, x_start:x_end]
                        if dark_tile.ndim == 2:
                            dark_tile = dark_tile[..., np.newaxis]
                            if channels == 3:
                                dark_tile = np.repeat(dark_tile, 3, axis=2)
                        elif dark_tile.shape[0] == 3:
                            dark_tile = dark_tile.transpose(1, 2, 0)

                        if dark_tile.shape == (tile_h, tile_w, channels):
                            tile_stack = subtract_dark(tile_stack, dark_tile)

                    if channels == 3:
                        tile_result = windsorized_sigma_clip_4d(tile_stack, lower=self.sigma_low, upper=self.sigma_high)[0]
                    else:
                        stack_3d = tile_stack[..., 0]
                        tile_result = windsorized_sigma_clip_3d(stack_3d, lower=self.sigma_low, upper=self.sigma_high)[0]
                        tile_result = tile_result[..., np.newaxis]

                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

            master_flat_data = np.array(final_stacked)
            del final_stacked

            master_flat_path = os.path.join(
                master_dir,
                f"MasterFlat_{session}_{int(exposure_time)}s_{image_size}_{filter_name}.fit"
            )

            header = fits.Header()
            header["IMAGETYP"] = "FLAT"
            header["EXPTIME"] = (exposure_time, "grouped exposure")
            header["FILTER"] = filter_name
            header["NAXIS"] = 3 if channels == 3 else 2
            header["NAXIS1"] = width
            header["NAXIS2"] = height
            if channels == 3:
                header["NAXIS3"] = 3

            save_image(
                img_array=master_flat_data,
                filename=master_flat_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=header,
                is_mono=(channels == 1)
            )

            key = f"{filter_name} ({image_size}) [{session}]"
            self.master_files[key] = master_flat_path
            self.master_sizes[master_flat_path] = image_size
            self.add_master_flat_to_tree(filter_name, master_flat_path)
            self.update_status(f"✅ Master Flat saved: {master_flat_path}")
            self.save_master_paths_to_settings()

        self.assign_best_master_dark()
        self.assign_best_master_files()



    def save_master_flat(self, master_flat, output_path, exposure_time, filter_name):
        """ Saves master flat as both a 32-bit floating point FITS and TIFF while ensuring no unintended normalization. """

        # ✅ Retrieve FITS header from a sample flat (to check if it's mono or color)
        original_header = None
        is_mono = True  # Default to mono

        if self.flat_files:
            sample_flat = next(iter(self.flat_files.values()))[0]  # Get the first flat file
            try:
                with fits.open(sample_flat) as hdul:
                    original_header = hdul[0].header

                    # **🔍 Detect if the flat is color by checking NAXIS3**
                    if original_header.get("NAXIS", 2) == 3 and original_header.get("NAXIS3", 1) == 3:
                        is_mono = False  # ✅ It's a color flat

            except Exception as e:
                print(f"⚠️ Warning: Could not retrieve FITS header from {sample_flat}: {e}")

        # ✅ Explicitly ensure we are saving raw values (NO normalization)
        fits_header = original_header if original_header else fits.Header()
        fits_header["BSCALE"] = 1.0  # 🔹 Prevent rescaling
        fits_header["BZERO"] = 0.0   # 🔹 Prevent offset

        # ✅ Save as FITS
        save_image(
            img_array=master_flat,
            filename=output_path,
            original_format="fit",
            bit_depth="32-bit floating point",
            original_header=fits_header,
            is_mono=is_mono
        )

        print(f"✅ Master Flat FITS saved: {output_path}")




    def add_master_flat_to_tree(self, filter_name, master_flat_path):
        """ Adds the newly created Master Flat to the Master Flat TreeBox and stores it. """

        key = f"{filter_name} ({self.master_sizes[master_flat_path]})"
        self.master_files[key] = master_flat_path  # ✅ Store the flat file for future use
        print(f"📝 DEBUG: Stored Master Flat -> {key}: {master_flat_path}")

        existing_items = self.master_flat_tree.findItems(filter_name, Qt.MatchFlag.MatchExactly, 0)

        if existing_items:
            filter_item = existing_items[0]
        else:
            filter_item = QTreeWidgetItem([filter_name])
            self.master_flat_tree.addTopLevelItem(filter_item)

        master_item = QTreeWidgetItem([os.path.basename(master_flat_path)])
        filter_item.addChild(master_item)

    def assign_best_master_files(self):
        """ Assign best matching Master Dark and Flat to each Light Frame (per leaf). """
        print("\n🔍 DEBUG: Assigning best Master Darks & Flats to Lights...\n")

        if not self.master_files:
            print("⚠️ WARNING: No Master Calibration Files available.")
            self.update_status("⚠️ WARNING: No Master Calibration Files available.")
            return

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            filter_name = filter_item.text(0)
            filter_name     = self._sanitize_name(filter_name)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)

                match = re.match(r"([\d.]+)s?", exposure_text)
                if not match:
                    print(f"⚠️ WARNING: Could not parse exposure time from {exposure_text}")
                    continue

                exposure_time = float(match.group(1))

                for k in range(exposure_item.childCount()):
                    leaf_item = exposure_item.child(k)
                    meta_text = leaf_item.text(1)

                    size_match = re.search(r"Size: (\d+x\d+)", meta_text)
                    session_match = re.search(r"Session: ([^|]+)", meta_text)
                    image_size = size_match.group(1) if size_match else "Unknown"
                    session_name = session_match.group(1).strip() if session_match else "Default"

                    print(f"🧠 Leaf: {leaf_item.text(0)} | Size: {image_size} | Session: {session_name}")

                    # 🔍 Match Dark
                    best_dark_match = None
                    best_dark_diff = float("inf")

                    for master_key, master_path in self.master_files.items():
                        # ✅ Only consider keys that start with an exposure (i.e. darks)
                        dark_match = re.match(r"^([\d.]+)s\b", master_key)
                        if not dark_match:
                            continue
                        master_dark_exposure_time = float(dark_match.group(1))

                        # Ensure we know the dark’s size
                        master_dark_size = self.master_sizes.get(master_path, "Unknown")
                        if master_dark_size == "Unknown":
                            with fits.open(master_path) as hdul:
                                master_dark_size = f"{hdul[0].data.shape[1]}x{hdul[0].data.shape[0]}"
                                self.master_sizes[master_path] = master_dark_size

                        # Only compare if sizes match
                        if master_dark_size == image_size:
                            diff = abs(master_dark_exposure_time - exposure_time)
                            if diff < best_dark_diff:
                                best_dark_match = master_path
                                best_dark_diff = diff

                    # 🔍 Match Flat
                    best_flat_match = None
                    for flat_key, flat_path in self.master_files.items():
                        if filter_name not in flat_key or f"({image_size})" not in flat_key:
                            continue
                        if session_name in flat_key:
                            best_flat_match = flat_path
                            break
                    if not best_flat_match:
                        fallback_key = f"{filter_name} ({image_size})"
                        best_flat_match = self.master_files.get(fallback_key)

                    # 🔄 Assign to leaf
                    leaf_item.setText(2, os.path.basename(best_dark_match) if best_dark_match else "None")
                    leaf_item.setText(3, os.path.basename(best_flat_match) if best_flat_match else "None")

                    print(f"📌 Assigned to {leaf_item.text(0)} -> Dark: {leaf_item.text(2)}, Flat: {leaf_item.text(3)}")

        self.light_tree.viewport().update()
        print("\n✅ DEBUG: Finished assigning Master Files per leaf.\n")

    def update_light_corrections(self):
        """ Updates the light frame corrections when checkboxes change. """
        corrections = []
        if self.cosmetic_checkbox.isChecked():
            corrections.append("Cosmetic: True")
        else:
            corrections.append("Cosmetic: False")

        if self.pedestal_checkbox.isChecked():
            corrections.append("Pedestal: True")
        else:
            corrections.append("Pedestal: False")

        if self.bias_checkbox.isChecked():
            # Show file dialog to select a Master Bias
            bias_file, _ = QFileDialog.getOpenFileName(self, "Select Master Bias Frame", "", "FITS Files (*.fits *.fit)")
            if bias_file:
                self.master_files["Bias"] = bias_file  # ✅ Store bias path
                corrections.append(f"Bias: {os.path.basename(bias_file)}")
            else:
                self.bias_checkbox.setChecked(False)  # If no file selected, uncheck
                return

        # Update all rows
        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_item.setText(4, ", ".join(corrections))

    def light_tree_context_menu(self, pos):
        item = self.light_tree.itemAt(pos)
        if not item:
            return

        menu = QMenu(self.light_tree)
        override_dark_action = menu.addAction("Override Dark Frame")
        override_flat_action = menu.addAction("Override Flat Frame")
        set_session_action = menu.addAction("Set Session Tag...")

        action = menu.exec(self.light_tree.viewport().mapToGlobal(pos))

        if action == override_dark_action:
            self.override_selected_master_dark()
        elif action == override_flat_action:
            self.override_selected_master_flat()
        elif action == set_session_action:
            self.prompt_set_session(item, "LIGHT")


    def set_session_tag_for_group(self, item):
        """
        Prompt the user to assign a session tag to all frames in this group.
        """
        session_name, ok = QInputDialog.getText(self, "Set Session Tag", "Enter session label (e.g., Night1, RedFilterSet2):")
        if not ok or not session_name.strip():
            return

        session_name = session_name.strip()
        filter_name = item.text(0)

        for i in range(item.childCount()):
            exposure_item = item.child(i)
            exposure_label = exposure_item.text(0)

            # Update metadata text
            if exposure_item.childCount() > 0:
                metadata_item = exposure_item.child(0)
                metadata_text = metadata_item.text(1)
                metadata_text = re.sub(r"Session: [^|]+", f"Session: {session_name}", metadata_text)
                if "Session:" not in metadata_text:
                    metadata_text += f" | Session: {session_name}"
                metadata_item.setText(1, metadata_text)

            # Update internal session tag mapping
            composite_key = (f"{filter_name} - {exposure_label}", session_name)
            original_key = f"{filter_name} - {exposure_label}"

            if original_key in self.light_files:
                self.light_files[composite_key] = self.light_files.pop(original_key)

                for path in self.light_files[composite_key]:
                    self.session_tags[path] = session_name

        self.update_status(f"🟢 Assigned session '{session_name}' to group '{filter_name}'")


    def override_selected_master_dark(self):
        """ Opens a file dialog to manually select a Master Dark for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for dark frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Dark", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(2, os.path.basename(file_path))  # Update tree UI
                self.manual_dark_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Dark for {item.text(0)} with {file_path}")



    def override_selected_master_flat(self):
        """ Opens a file dialog to manually select a Master Flat for the selected group and stores it. """
        selected_items = self.light_tree.selectedItems()
        if not selected_items:
            print("⚠️ No light group selected for flat frame override.")
            return

        file_path, _ = QFileDialog.getOpenFileName(self, "Select Master Flat", "", "FITS Files (*.fits *.fit)")
        if not file_path:
            return  # User canceled

        for item in selected_items:
            if item.parent():  # Ensure it's an exposure group, not the top filter name
                item.setText(3, os.path.basename(file_path))  # Update tree UI
                self.manual_flat_overrides[item.text(0)] = file_path  # Store override

        print(f"✅ DEBUG: Overrode Master Flat for {item.text(0)} with {file_path}")


    def toggle_group_correction(self, group_item, which):
        """
        group_item: a top-level item in the light_tree
        which: either "cosmetic" or "pedestal"
        """
        old_text = group_item.text(4)  # e.g. "Cosmetic: True, Pedestal: False"
        # If there's nothing, default them to False
        if not old_text:
            old_text = "Cosmetic: False, Pedestal: False"

        # Parse
        # old_text might be "Cosmetic: True, Pedestal: False"
        # split by comma
        # part[0] => "Cosmetic: True"
        # part[1] => " Pedestal: False"
        parts = old_text.split(",")
        cosmetic_str = "False"
        pedestal_str = "False"
        if len(parts) == 2:
            # parse cosmetic
            cos_part = parts[0].split(":")[-1].strip()  # "True" or "False"
            cosmetic_str = cos_part
            # parse pedestal
            ped_part = parts[1].split(":")[-1].strip()
            pedestal_str = ped_part

        # Convert to bool
        cosmetic_bool = (cosmetic_str.lower() == "true")
        pedestal_bool = (pedestal_str.lower() == "true")

        # Toggle whichever was requested
        if which == "cosmetic":
            cosmetic_bool = not cosmetic_bool
        elif which == "pedestal":
            pedestal_bool = not pedestal_bool

        # Rebuild the new text
        new_text = f"Cosmetic: {str(cosmetic_bool)}, Pedestal: {str(pedestal_bool)}"
        group_item.setText(4, new_text)


    def calibrate_lights(self):
        """Performs calibration on selected light frames using Master Darks and Flats, considering overrides."""
        if not self.stacking_directory:
            QMessageBox.warning(self, "Error", "Please set the stacking directory first.")
            return

        calibrated_dir = os.path.join(self.stacking_directory, "Calibrated")
        os.makedirs(calibrated_dir, exist_ok=True)

        total_files = sum(len(files) for files in self.light_files.values())
        processed_files = 0

        master_bias_path = self.master_files.get("Bias", None)
        master_bias = None
        if master_bias_path:
            with fits.open(master_bias_path) as bias_hdul:
                master_bias = bias_hdul[0].data.astype(np.float32)
            self.update_status(f"Using Master Bias: {os.path.basename(master_bias_path)}")

        for i in range(self.light_tree.topLevelItemCount()):
            filter_item = self.light_tree.topLevelItem(i)
            filter_name = filter_item.text(0)

            for j in range(filter_item.childCount()):
                exposure_item = filter_item.child(j)
                exposure_text = exposure_item.text(0)

                # Get default corrections
                correction_text = exposure_item.text(4)
                apply_cosmetic = False
                apply_pedestal = False
                if correction_text:
                    parts = correction_text.split(",")
                    if len(parts) == 2:
                        apply_cosmetic = parts[0].split(":")[-1].strip().lower() == "true"
                        apply_pedestal = parts[1].split(":")[-1].strip().lower() == "true"

                pedestal_value = self.pedestal_spinbox.value() / 65535 if apply_pedestal else 0

                for k in range(exposure_item.childCount()):
                    leaf = exposure_item.child(k)
                    filename = leaf.text(0)
                    meta = leaf.text(1)

                    # Get session from metadata
                    session_name = "Default"
                    match = re.search(r"Session: ([^|]+)", meta)
                    if match:
                        session_name = match.group(1).strip()

                    # Look up the light file from session-specific group
                    composite_key = (f"{filter_name} - {exposure_text}", session_name)
                    light_file_list = self.light_files.get(composite_key, [])
                    light_file = next((f for f in light_file_list if os.path.basename(f) == filename), None)
                    if not light_file:
                        continue

                    # Determine size from header
                    header, _ = get_valid_header(light_file)
                    width = int(header.get("NAXIS1", 0))
                    height = int(header.get("NAXIS2", 0))
                    image_size = f"{width}x{height}"

                    # Determine Master Dark (manual override or best match)
                    manual_dark_key = f"{filter_name} - {exposure_text}"
                    master_dark_path = self.manual_dark_overrides.get(manual_dark_key)
                    if not master_dark_path:
                        for key, path in self.master_files.items():
                            if os.path.basename(path) == exposure_item.text(2):
                                master_dark_path = path
                                break

                    # Determine Master Flat (manual override or best session match)
                    manual_flat_key = f"{filter_name} - {exposure_text}"
                    master_flat_path = self.manual_flat_overrides.get(manual_flat_key)
                    if not master_flat_path:
                        flat_key = f"{filter_name} ({image_size}) [{session_name}]"
                        master_flat_path = self.master_files.get(flat_key)

                    self.update_status(f"Processing: {os.path.basename(light_file)}")
                    QApplication.processEvents()

                    light_data, hdr, bit_depth, is_mono = load_image(light_file)
                    if light_data is None or hdr is None:
                        self.update_status(f"❌ ERROR: Failed to load {os.path.basename(light_file)}")
                        continue

                    if not is_mono and light_data.shape[-1] == 3:
                        light_data = light_data.transpose(2, 0, 1)

                    if master_bias is not None:
                        if is_mono:
                            light_data -= master_bias
                        else:
                            light_data -= master_bias[np.newaxis, :, :]
                        self.update_status("Bias Subtracted")
                        QApplication.processEvents()

                    if master_dark_path:
                        dark_data, _, _, dark_is_mono = load_image(master_dark_path)
                        if dark_data is not None:
                            if not dark_is_mono and dark_data.shape[-1] == 3:
                                dark_data = dark_data.transpose(2, 0, 1)
                            light_data = subtract_dark_with_pedestal(
                                light_data[np.newaxis, :, :], dark_data, pedestal_value
                            )[0]
                            self.update_status(f"Dark Subtracted: {os.path.basename(master_dark_path)}")
                            QApplication.processEvents()

                    if master_flat_path:
                        flat_data, _, _, flat_is_mono = load_image(master_flat_path)
                        if flat_data is not None:
                            if not flat_is_mono and flat_data.shape[-1] == 3:
                                flat_data = flat_data.transpose(2, 0, 1)
                            flat_data[flat_data == 0] = 1.0
                            light_data = apply_flat_division_numba(light_data, flat_data)
                            self.update_status(f"Flat Applied: {os.path.basename(master_flat_path)}")
                            QApplication.processEvents()

                    if apply_cosmetic:
                        if hdr.get("BAYERPAT"):
                            light_data = bulk_cosmetic_correction_bayer(light_data)
                            self.update_status("Cosmetic Correction Applied for Bayer Pattern")
                        else:
                            light_data = bulk_cosmetic_correction_numba(light_data)
                            self.update_status("Cosmetic Correction Applied")
                        QApplication.processEvents()

                    if not is_mono and light_data.shape[0] == 3:
                        light_data = light_data.transpose(1, 2, 0)

                    min_val = light_data.min()
                    max_val = light_data.max()
                    self.update_status(f"Before saving: min = {min_val:.4f}, max = {max_val:.4f}")
                    print(f"Before saving: min = {min_val:.4f}, max = {max_val:.4f}")
                    QApplication.processEvents()

                    calibrated_filename = os.path.join(
                        calibrated_dir, os.path.basename(light_file).replace(".fit", "_c.fit")
                    )

                    save_image(
                        img_array=light_data,
                        filename=calibrated_filename,
                        original_format="fit",
                        bit_depth=bit_depth,
                        original_header=hdr,
                        is_mono=is_mono
                    )

                    processed_files += 1
                    self.update_status(f"Saved: {os.path.basename(calibrated_filename)} ({processed_files}/{total_files})")
                    QApplication.processEvents()

        self.update_status("✅ Calibration Complete!")
        QApplication.processEvents()
        self.populate_calibrated_lights()

    def extract_light_files_from_tree(self):
        """
        Walks self.reg_tree and rebuilds self.light_files as
        { group_key: [abs_path1, abs_path2, ...], ... }
        """
        new = {}
        for i in range(self.reg_tree.topLevelItemCount()):
            group = self.reg_tree.topLevelItem(i)
            key   = group.text(0)
            files = []

            # dive into exposure → leaf or direct leaf
            for j in range(group.childCount()):
                sub = group.child(j)
                leaves = []
                if sub.childCount()>0:
                    for k in range(sub.childCount()):
                        leaves.append(sub.child(k))
                else:
                    leaves.append(sub)

                for leaf in leaves:
                    fp = leaf.data(0, Qt.ItemDataRole.UserRole)
                    if fp and os.path.exists(fp):
                        files.append(fp)
                    else:
                        self.update_status(f"⚠️ WARNING: File not found: {fp}")
            if files:
                new[key] = files

        self.light_files = new
        total = sum(len(v) for v in new.values())
        self.update_status(f"✅ Extracted Light Files: {total} total")


    def select_reference_frame_robust(self, frame_weights, sigma_threshold=1.0):
        """
        Instead of sigma filtering, pick the frame at the 75th percentile of frame weights.
        This assumes that higher weights are better and that the 75th percentile represents
        a good-quality frame.
        
        Parameters
        ----------
        frame_weights : dict
            Mapping { file_path: weight_value } for each frame.
        
        Returns
        -------
        best_frame : str or None
            The file path of the chosen reference frame, or None if no frames are available.
        """
        items = list(frame_weights.items())  # List of (file_path, weight) pairs
        if not items:
            return None

        # Sort frames by weight in ascending order.
        items.sort(key=lambda x: x[1])
        n = len(items)
        # Get the index corresponding to the 75th percentile.
        index = int(0.75 * (n - 1))
        best_frame = items[index][0]
        return best_frame

    def prompt_for_reference_frame(self):
        new_ref, _ = QFileDialog.getOpenFileName(
            self,
            "Select New Reference Frame",
            "",  # default directory
            "FITS Files (*.fit *.fits);;All Files (*)"
        )
        return new_ref if new_ref else None

    def extract_light_files_from_tree(self, *, debug: bool = False):
        """
        Rebuild self.light_files from what's *currently shown* in reg_tree.
        - Only uses leaf items (childCount()==0)
        - Repairs missing leaf UserRole by matching basename against parent's cached list
        - Filters non-existent paths
        """
        light_files: dict[str, list[str]] = {}
        total_leafs = 0
        total_paths = 0

        for i in range(self.reg_tree.topLevelItemCount()):
            top = self.reg_tree.topLevelItem(i)
            group_key = top.text(0)
            repaired_from_parent = 0

            # Parent's cached list (may be stale but useful for repairing)
            parent_cached = top.data(0, Qt.ItemDataRole.UserRole) or []

            paths: list[str] = []
            for j in range(top.childCount()):
                leaf = top.child(j)
                # Only accept real leaf rows (no grandchildren expected in this tree)
                if leaf.childCount() != 0:
                    continue

                total_leafs += 1

                fp = leaf.data(0, Qt.ItemDataRole.UserRole)
                if not fp:
                    # Try to repair by basename match against parent's cached list
                    name = leaf.text(0).lstrip("⚠️ ").strip()
                    match = next((p for p in parent_cached if os.path.basename(p) == name), None)
                    if match:
                        leaf.setData(0, Qt.ItemDataRole.UserRole, match)
                        fp = match
                        repaired_from_parent += 1

                if fp and isinstance(fp, str) and os.path.exists(fp):
                    paths.append(fp)

            if paths:
                light_files[group_key] = paths
                # keep the parent cache in sync for future repairs
                top.setData(0, Qt.ItemDataRole.UserRole, paths)
                total_paths += len(paths)

            if debug:
                self.update_status(
                    f"⤴ {group_key}: {len(paths)} files"
                    + (f" (repaired {repaired_from_parent})" if repaired_from_parent else "")
                )

        self.light_files = light_files
        if debug:
            self.update_status(f"🧭 Tree snapshot → groups: {len(light_files)}, leaves seen: {total_leafs}, paths kept: {total_paths}")
        return light_files

    def _norm_filter_key(self, s: str) -> str:
        s = (s or "").lower()
        # map greek letters to ascii
        s = s.replace("α", "a").replace("β", "b")
        return re.sub(r"[^a-z0-9]+", "", s)

    def _classify_filter(self, filt_str: str) -> str:
        """
        Return one of:
        'DUAL_HA_OIII', 'DUAL_SII_OIII', 'DUAL_SII_HB',
        'MONO_HA', 'MONO_SII', 'MONO_OIII', 'MONO_HB',
        'UNKNOWN'
        """
        k = self._norm_filter_key(filt_str)
        comps = set()

        if "ha"   in k or "halpha" in k: comps.add("ha")
        if "sii"  in k or "s2" in k:     comps.add("sii")
        if "oiii" in k or "o3" in k:     comps.add("oiii")
        if "hb"   in k or "hbeta" in k:  comps.add("hb")   # NEW

        # common vendor aliases → Ha/OIII
        for alias in ("lextreme", "lenhance", "lultimate", "nbz", "alpt", "alp", "nbzu"):
            if alias in k:
                comps.update({"ha", "oiii"})

        if {"ha","oiii"}.issubset(comps):  return "DUAL_HA_OIII"
        if {"sii","oiii"}.issubset(comps): return "DUAL_SII_OIII"
        if {"sii","hb"}.issubset(comps):   return "DUAL_SII_HB"   # NEW

        if comps == {"ha"}:   return "MONO_HA"
        if comps == {"sii"}:  return "MONO_SII"
        if comps == {"oiii"}: return "MONO_OIII"
        if comps == {"hb"}:   return "MONO_HB"                   # NEW
        return "UNKNOWN"

    def _get_filter_name(self, path: str) -> str:
        # Prefer FITS header 'FILTER'; fall back to filename tokens
        try:
            hdr = fits.getheader(path, ext=0)
            for key in ("FILTER", "FILTER1", "HIERARCH INDI FILTER", "HIERARCH ESO INS FILT1 NAME"):
                if key in hdr and str(hdr[key]).strip():
                    return str(hdr[key]).strip()
        except Exception:
            pass
        return os.path.basename(path)

    def _current_global_drizzle(self):
        # read from the “global” controls (used as a template)
        return {
            "enabled": self.drizzle_checkbox.isChecked(),
            "scale": float(self.drizzle_scale_combo.currentText().replace("x","", 1)),
            "drop": float(self.drizzle_drop_shrink_spin.value())
        }

    def _split_dual_band_osc(self, selected_groups=None):
        """
        Create mono Ha/SII/OIII frames from dual-band OSC files and
        update self.light_files so integration sees separate channels.
        """
        selected_groups = selected_groups or set()
        out_dir = os.path.join(self.stacking_directory, "DualBand_Split")
        os.makedirs(out_dir, exist_ok=True)

        ha_files, sii_files, oiii_files, hb_files = [], [], [], []
        inherit_map = {}                      # gk -> set(parent_group names)   # <<< NEW
        parent_of = {}                        # path -> parent_group            # <<< NEW

        # Walk all groups/files you already collected
        old_groups = list(self.light_files.items())
        old_drizzle = dict(self.per_group_drizzle)
        for group, files in old_groups:
            for fp in files:
                try:
                    img, hdr, _, _ = load_image(fp)
                    if img is None:
                        self.update_status(f"⚠️ Cannot load {fp}; skipping.")
                        continue

                    if hdr and hdr.get("BAYERPAT"):
                        img = self.debayer_image(img, fp, hdr)

                    # 3-channel split; otherwise treat mono via classifier
                    if img.ndim != 3 or img.shape[-1] < 2:
                        filt = self._get_filter_name(fp)
                        cls  = self._classify_filter(filt)
                        if cls == "MONO_HA":
                            ha_files.append(fp);   parent_of[fp] = group        # <<< NEW
                        elif cls == "MONO_SII":
                            sii_files.append(fp);  parent_of[fp] = group        # <<< NEW
                        elif cls == "MONO_OIII":
                            oiii_files.append(fp); parent_of[fp] = group        # <<< NEW
                        elif cls == "MONO_HB":   hb_files.append(fp);  parent_of[fp] = group        # <<< NEW
                        # else: leave in original groups
                        continue

                    filt = self._get_filter_name(fp)
                    cls  = self._classify_filter(filt)

                    R = img[..., 0]; G = img[..., 1]
                    base = os.path.splitext(os.path.basename(fp))[0]

                    if cls == "DUAL_HA_OIII":
                        ha_path   = os.path.join(out_dir, f"{base}_Ha.fit")
                        oiii_path = os.path.join(out_dir, f"{base}_OIII.fit")
                        self._write_band_fit(ha_path,  R, hdr, "Ha",  src_filter=filt)
                        self._write_band_fit(oiii_path, G, hdr, "OIII", src_filter=filt)
                        ha_files.append(ha_path);     parent_of[ha_path]   = group   # <<< NEW
                        oiii_files.append(oiii_path); parent_of[oiii_path] = group   # <<< NEW

                    elif cls == "DUAL_SII_OIII":
                        sii_path  = os.path.join(out_dir, f"{base}_SII.fit")
                        oiii_path = os.path.join(out_dir, f"{base}_OIII.fit")
                        self._write_band_fit(sii_path, R, hdr, "SII",  src_filter=filt)
                        self._write_band_fit(oiii_path, G, hdr, "OIII", src_filter=filt)
                        sii_files.append(sii_path);    parent_of[sii_path]  = group  # <<< NEW
                        oiii_files.append(oiii_path);  parent_of[oiii_path] = group  # <<< NEW

                    elif cls == "DUAL_SII_HB":  # NEW → R=SII, G=Hb  (G works well; we can add G+B later if you want)
                        sii_path = os.path.join(out_dir, f"{base}_SII.fit")
                        hb_path  = os.path.join(out_dir, f"{base}_Hb.fit")
                        self._write_band_fit(sii_path, R, hdr, "SII", src_filter=filt)
                        self._write_band_fit(hb_path,  G, hdr, "Hb",  src_filter=filt)
                        sii_files.append(sii_path); parent_of[sii_path] = group
                        hb_files.append(hb_path);   parent_of[hb_path]  = group

                    else:
                        pass

                except Exception as e:
                    self.update_status(f"⚠️ Split error on {os.path.basename(fp)}: {e}")

        # Group the new files
        def _group_key(band: str, path: str) -> str:
            try:
                h = fits.getheader(path, ext=0)
                exp = h.get("EXPTIME") or h.get("EXPOSURE") or ""
                w   = h.get("NAXIS1","?"); hgt = h.get("NAXIS2","?")
                exp_str = f"{float(exp):.1f}s" if isinstance(exp, (int,float)) else str(exp)
                return f"{band} - {exp_str} - {w}x{hgt}"
            except Exception:
                return f"{band} - ? - ?x?"

        new_groups = {}
        for band, flist in (("Ha", ha_files), ("SII", sii_files), ("OIII", oiii_files), ("Hb", hb_files)):  # NEW Hb
            for p in flist:
                gk = _group_key(band, p)
                new_groups.setdefault(gk, []).append(p)
                parent = parent_of.get(p)
                if parent:
                    inherit_map.setdefault(gk, set()).add(parent)

        if new_groups:
            self.light_files = new_groups

            # Seed drizzle for the new groups based on parents
            seeded = 0
            global_template = self._current_global_drizzle()   # make sure this helper exists
            self.per_group_drizzle = {}  # rebuild for the new groups

            for gk, parents in inherit_map.items():
                parent_cfgs = [old_drizzle.get(pg) for pg in parents if old_drizzle.get(pg)]
                chosen = None
                for cfg in parent_cfgs:
                    if cfg.get("enabled"):
                        chosen = cfg
                        break
                if not chosen and parent_cfgs:
                    chosen = parent_cfgs[0]

                if not chosen and (parents & selected_groups) and global_template.get("enabled"):
                    chosen = global_template

                if chosen:
                    self.per_group_drizzle[gk] = dict(chosen)
                    seeded += 1


            self.update_status(
                f"✅ Dual-band split complete: Ha={len(ha_files)}, SII={len(sii_files)}, "
                f"OIII={len(oiii_files)}, Hb={len(hb_files)} (drizzle seeded on {seeded} new group(s))"
            )
        else:
            self.update_status("ℹ️ No dual-band frames detected or split.")

    def _write_band_fit(self, out_path: str, data: np.ndarray, src_header: Optional[fits.Header],
                        band: str, src_filter: str):

        arr = np.ascontiguousarray(data.astype(np.float32))

        hdr = (src_header.copy() if isinstance(src_header, fits.Header) else fits.Header())

        # --- strip CFA/Bayer-related cards so we never try to debayer these ---
        cfa_like = (
            "BAYERPAT", "BAYER_PATTERN", "DEBAYER", "DEBAYERING", "DEMAT", "DEMOSAIC",
            "XBAYROFF", "YBAYROFF", "COLORTYP", "COLORSPACE", "HIERARCH CFA", "HIERARCH OSC",
            "HIERARCH ASI BAYERPATTERN", "HIERARCH DNG CFA", "HIERARCH ZWO CFA"
        )
        for k in list(hdr.keys()):
            kk = str(k).upper()
            if any(token in kk for token in ("BAYER", "CFA", "DEMOSA")) or kk in cfa_like:
                try:
                    del hdr[k]
                except Exception:
                    pass

        # Mark these as mono split files & set the band as the filter
        hdr["FILTER"] = (band, "Channel from dual-band split")
        hdr["SPLITDB"] = (True, "This frame was generated by dual-band splitting")
        hdr.add_history(f"Dual-band split: {band} from {src_filter}")

        fits.PrimaryHDU(data=arr, header=hdr).writeto(out_path, overwrite=True)

    def _drizzle_text_for_group(self, group_key: str) -> str:
        d = self.per_group_drizzle.get(group_key)
        if not d:
            return ""
        return f"Drizzle: {d.get('enabled', False)}, Scale: {d.get('scale','1x')}, Drop:{d.get('drop',0.65)}"

    def _refresh_reg_tree_from_light_files(self):
        self.reg_tree.clear()
        for group, files in self.light_files.items():
            top = QTreeWidgetItem([group, f"{len(files)} file(s)", self._drizzle_text_for_group(group)])
            self.reg_tree.addTopLevelItem(top)
            for fp in files:
                # Optional: show some header metadata
                meta = ""
                try:
                    hdr = fits.getheader(fp, ext=0)
                    filt = hdr.get("FILTER", "")
                    exp  = hdr.get("EXPTIME") or hdr.get("EXPOSURE") or ""
                    if isinstance(exp, (int, float)): exp = f"{exp:.1f}s"
                    meta = f"Filter={filt}  Exp={exp}"
                except Exception:
                    pass
                child = QTreeWidgetItem([os.path.basename(fp), meta, ""])
                top.addChild(child)
        self.reg_tree.expandAll()

    def register_images(self):
        """ 
        Measures all frames in small batches (to find a reference frame and weights),
        then normalizes each entire frame (again in small batches) using the Numba
        normalize_images function, saves them with a '_n.fit' suffix, and finally
        starts the alignment thread on those normalized files.
        """
        if self.star_trail_mode:
            self.update_status("🌠 Star-Trail Mode enabled: skipping registration & using max-value stack")
            QApplication.processEvents()
            return self._make_star_trail()
                
        self.update_status("🔄 Image Registration Started...")
        self.extract_light_files_from_tree(debug=True)
        # optional: assert leaf count matches flattened file count
       


        if not self.light_files:
            self.update_status("⚠️ No light files to register!")
            return

        # ── 1) bail if still nothing
        if not self.light_files:
            self.update

        selected_groups = set()
        for it in self.reg_tree.selectedItems():
            top = it if it.parent() is None else it.parent()
            selected_groups.add(top.text(0))

        if self.split_dualband_cb.isChecked():
            self.update_status("🌈 Splitting dual-band OSC frames into Ha / SII / OIII...")
            self._split_dual_band_osc(selected_groups=selected_groups)
            self._refresh_reg_tree_from_light_files()

        # Flatten to get all files
        all_files = [f for lst in self.light_files.values() for f in lst]
        leaf_count = sum(len(lst) for lst in self.light_files.values())
        self.update_status(f"📊 Found {len(all_files)} total frames. Now measuring in parallel batches...")

        self.frame_weights = {}
        mean_values = {}
        star_counts = {}
        measured_frames = []

        max_workers = os.cpu_count() or 4
        chunk_size = max_workers  # or bigger if you prefer

        def chunk_list(lst, size):
            for i in range(0, len(lst), size):
                yield lst[i : i + size]

        chunked_files = list(chunk_list(all_files, chunk_size))
        total_chunks = len(chunked_files)

        # ---------------------------------------------------------------------
        # PHASE 1: Load & Measure Each Chunk (to pick reference frame & weights)
        # ---------------------------------------------------------------------
        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"📦 Measuring chunk {chunk_index}/{total_chunks} ({len(chunk)} frames)")

            chunk_images = []
            chunk_valid_files = []

            # -------------------------------
            # Multi-threaded loading of chunk
            # -------------------------------
            self.update_status(f"🌍 Loading {len(chunk)} images in parallel (up to {max_workers} threads)...")

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Build the dictionary mapping futures to file names
                future_to_file = {}
                for file in chunk:
                    future = executor.submit(load_image, file)
                    future_to_file[future] = file

                for future in as_completed(future_to_file):
                    file = future_to_file[future]
                    try:
                        image_data, header, _, _ = future.result()
                        if image_data is not None:
                            # First check for Bayer pattern in the header
                            if header and header.get('BAYERPAT'):
                                should_debayer = (
                                    header
                                    and header.get('BAYERPAT')
                                    and not header.get('SPLITDB', False)
                                    and (image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[-1] == 1))
                                )
                                if should_debayer:
                                    image_data = self.debayer_image(image_data, file, header)
                                    self.update_status("📦 Bayer pattern detected, Debayering...")
                                QApplication.processEvents()
                            else:
                                # If the image is 3D but has only one channel (e.g. HxWx1), squeeze it to 2D
                                if image_data.ndim == 3 and image_data.shape[-1] == 1:
                                    image_data = np.squeeze(image_data, axis=-1)
                            chunk_images.append(image_data)
                            chunk_valid_files.append(file)
                            self.update_status(f"  Loaded {file}")
                            QApplication.processEvents()
                    except Exception as e:
                        self.update_status(f"⚠️ Error loading {file}: {e}")
                        QApplication.processEvents()



            if not chunk_images:
                self.update_status("⚠️ No valid images in this chunk.")
                continue

            # measure means in parallel
            self.update_status("🌍 Measuring global means in parallel...")
            means = parallel_measure_frames(chunk_images)

            # star counts
            for i, file in enumerate(chunk_valid_files):
                mean_val = means[i]
                mean_values[file] = mean_val

                c, ecc = compute_star_count(chunk_images[i])
                star_counts[file] = {"count": c, "eccentricity": ecc}

                measured_frames.append(file)

            del chunk_images

        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status(f"✅ All chunks complete! Measured {len(measured_frames)} frames total.")

        # ------------------------------------------------
        # 2) Compute Weights & Pick Reference
        # ------------------------------------------------
        self.update_status("⚖️ Computing frame weights...")
        debug_log = "\n📊 **Frame Weights Debug Log:**\n"
        for file in measured_frames:
            c = star_counts[file]["count"]
            ecc = star_counts[file]["eccentricity"]
            m = mean_values[file]

            c = max(c, 1)
            m = max(m, 1e-6)
            raw_w = (c * min(1, max(1.0 - ecc, 0.0))) / m
            self.frame_weights[file] = raw_w

            debug_log += (
                f"📂 {os.path.basename(file)} → "
                f"StarCount={c}, Ecc={ecc:.4f}, Mean={m:.4f}, Weight={raw_w:.4f}\n"
            )

        self.update_status(debug_log)

        max_w = max(self.frame_weights.values()) if self.frame_weights else 0
        if max_w > 0:
            for k in self.frame_weights:
                self.frame_weights[k] /= max_w

        # Choose reference
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference: {self.reference_frame}")
        else:
            self.reference_frame = self.select_reference_frame_robust(self.frame_weights, sigma_threshold=2.0)
            self.update_status(f"📌 Auto-selected robust reference frame: {self.reference_frame}")

        # ------------------------------------------------
        # 3) Load the reference, get ref_median
        # ------------------------------------------------
        ref_data, _, _, _ = load_image(self.reference_frame)
        if ref_data is None:
            self.update_status(f"🚨 Could not load reference {self.reference_frame}. Aborting.")
            return
        ref_median = np.median(ref_data)
        self.update_status(f"📊 Reference median: {ref_median:.4f}")

        stats = {
            "star_count": c,         # Replace with the actual star count
            "eccentricity": ecc,        # Replace with the computed eccentricity
            "mean": ref_median
        }


        # Show the review dialog (pausing further processing until user responds)
        dialog = ReferenceFrameReviewDialog(self.reference_frame, stats, parent=self)
        result = dialog.exec()
        user_choice = dialog.getUserChoice()  # This returns "use", "select_other", or None

        if result == QDialog.DialogCode.Accepted:
            # User chose to use the auto-selected reference via the "Use This Reference Frame" button.
            self.update_status("User accepted the auto-selected reference frame.")
        elif user_choice == "select_other":
            # User actively clicked "Select Other Reference Frame"
            new_ref = self.prompt_for_reference_frame()  # Open a file dialog or list of frames
            if new_ref:
                self.reference_frame = new_ref
                self.update_status(f"User selected a new reference frame: {new_ref}")
            else:
                self.update_status("No new reference frame selected. Using auto-selected frame.")
        else:
            # The dialog was closed (e.g. via the window’s close button) without an active selection.
            self.update_status("Dialog closed without selection. Using auto-selected frame.")

        # ------------------------------------------------
        # 4) Normalize Each Frame to ref_median in Batches
        # ------------------------------------------------
        norm_dir = os.path.join(self.stacking_directory, "Normalized_Images")
        os.makedirs(norm_dir, exist_ok=True)

        chunked_files = list(chunk_list(measured_frames, chunk_size))
        total_chunks = len(chunked_files)
        normalized_files = []

        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"🌀 Normalizing chunk {chunk_index}/{total_chunks} ({len(chunk)} frames)...")
            QApplication.processEvents()

            # --------------
            # Multi-threaded loading again
            # --------------
            loaded_images = []
            valid_paths = []

            self.update_status(f"🌍 Loading {len(chunk)} images in parallel for normalization (up to {max_workers} threads)...")

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_file = {}
                for file in chunk:
                    future = executor.submit(load_image, file)
                    future_to_file[future] = file

                for future in as_completed(future_to_file):
                    file = future_to_file[future]
                    try:
                        img, hdr, _, _ = future.result()
                        if img is not None:
                            # Check for Bayer pattern first – debayer if needed
                            if hdr and hdr.get('BAYERPAT'):
                                img = self.debayer_image(img, file, hdr)
                            else:
                                # Only squeeze if the image has an extra singleton dimension
                                if img.ndim == 3 and img.shape[-1] == 1:
                                    img = np.squeeze(img, axis=-1)
                            loaded_images.append(img)
                            valid_paths.append(file)
                        else:
                            self.update_status(f"⚠️ No data for {file}")
                    except Exception as e:
                        self.update_status(f"⚠️ Error loading {file} for normalization: {e}")
                    QApplication.processEvents()


            if not loaded_images:
                continue

            # shape=(F,H,W) or (F,H,W,C)
            stack = np.array(loaded_images, dtype=np.float32)
            normalized_stack = normalize_images(stack, ref_median)

            # Save each with "_n.fit"
            for i, orig_file in enumerate(valid_paths):
                base = os.path.basename(orig_file)
                if base.endswith("_n.fit"):
                    base = base.replace("_n.fit", ".fit")
                out_name = base.replace(".fit", "_n.fit")
                out_path = os.path.join(norm_dir, out_name)

                frame_data = normalized_stack[i]
                is_mono = (frame_data.ndim == 2)

                # Reuse original header but don't load image data again
                try:
                    orig_header = fits.getheader(orig_file, ext=0)
                except:
                    orig_header = fits.Header()

                hdu = fits.PrimaryHDU(data=frame_data.astype(np.float32), header=orig_header)
                hdu.writeto(out_path, overwrite=True)
                normalized_files.append(out_path)

            del loaded_images, stack, normalized_stack

        # ---------------------------------------------------------
        # 5) ***Update self.light_files to reference *_n.fit***
        # ---------------------------------------------------------
        for group, file_list in self.light_files.items():
            new_list = []
            for old_path in file_list:
                base = os.path.basename(old_path)
                if base.endswith("_n.fit"):
                    # It's already _n
                    new_list.append(os.path.join(norm_dir, base))
                else:
                    n_name = base.replace(".fit", "_n.fit")
                    new_path = os.path.join(norm_dir, n_name)
                    new_list.append(new_path)

            self.light_files[group] = new_list

        self.update_status("✅ Updated self.light_files to use _n.fit paths for all frames.")

        # ------------------------------------------------
        # 6) Start Alignment on the normalized files
        # ------------------------------------------------
        align_dir = os.path.join(self.stacking_directory, "Aligned_Images")
        os.makedirs(align_dir, exist_ok=True)

        self.alignment_thread = StarRegistrationThread(
            self.reference_frame,
            normalized_files,  # the entire list of _n.fit files
            align_dir
        )
        self.alignment_thread.progress_update.connect(self.update_status)
        self.alignment_thread.registration_complete.connect(self.on_registration_complete)
        self.align_progress = QProgressDialog("Aligning stars…", None, 0, 0, self)
        self.align_progress.setWindowModality(Qt.WindowModality.WindowModal)
        self.align_progress.setMinimumDuration(0)
        self.align_progress.setCancelButton(None)
        self.align_progress.setWindowTitle("Stellar Alignment")
        self.align_progress.setValue(0)
        self.align_progress.show()

        self.alignment_thread.progress_step.connect(self._on_align_progress)
        self.alignment_thread.registration_complete.connect(self._on_align_done)        
        self.alignment_thread.start()
        
    @pyqtSlot(int, int)
    def _on_align_progress(self, done, total):
        self.align_progress.setLabelText(f"Aligning stars… ({done}/{total})")
        self.align_progress.setMaximum(total)
        self.align_progress.setValue(done)
        QApplication.processEvents()

    @pyqtSlot(bool, str)
    def _on_align_done(self, success, message):
        if hasattr(self, "align_progress"):
            self.align_progress.close()
            del self.align_progress
        self.update_status(message)

    def save_alignment_matrices_sasd(self, transforms_dict):
        out_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        try:
            with open(out_path, "w") as f:
                for norm_path, matrix in transforms_dict.items():
                    # Use the original normalized input path (e.g., *_n.fit)
                    orig_path = os.path.normpath(norm_path)

                    a, b, tx = matrix[0]
                    c, d, ty = matrix[1]

                    f.write(f"FILE: {orig_path}\n")
                    f.write("MATRIX:\n")
                    f.write(f"{a:.4f}, {b:.4f}, {tx:.4f}\n")
                    f.write(f"{c:.4f}, {d:.4f}, {ty:.4f}\n")
                    f.write("\n")  # blank line
            self.update_status(f"✅ Transform file saved as {os.path.basename(out_path)}")
        except Exception as e:
            self.update_status(f"⚠️ Failed to save transform file: {e}")



    def load_alignment_matrices_custom(self, file_path):

        transforms = {}
        with open(file_path, "r") as f:
            content = f.read()

        blocks = re.split(r"\n\s*\n", content.strip())

        for block in blocks:
            lines = [line.strip() for line in block.splitlines() if line.strip()]
            if not lines:
                continue
            if lines[0].startswith("FILE:"):
                raw_file_path = lines[0].replace("FILE:", "").strip()
                # *** KEY FIX: normalize here
                curr_file = os.path.normpath(raw_file_path)
            else:
                continue
            
            if len(lines) < 4 or not lines[1].startswith("MATRIX:"):
                continue

            row0 = lines[2].split(",")
            row1 = lines[3].split(",")
            a, b, tx = [float(x) for x in row0]
            c, d, ty = [float(x) for x in row1]

            transforms[curr_file] = np.array([[a, b, tx],
                                            [c, d, ty]], dtype=np.float32)
        return transforms

    def _make_star_trail(self):
        # 1) collect all your calibrated light frames
        all_files = [f for flist in self.light_files.values() for f in flist]
        n_frames = len(all_files)
        if not all_files:
            self.update_status("⚠️ No calibrated lights available for star trails.")
            return

        # 2) load every frame (once), compute its median, and remember its header
        frames: list[tuple[np.ndarray, fits.Header]] = []
        medians: list[float] = []

        for fn in all_files:
            img, hdr, _, _ = load_image(fn)
            if img is None:
                self.update_status(f"⚠️ Failed to load {os.path.basename(fn)}; skipping")
                QApplication.processEvents()
                continue

            arr = img.astype(np.float32)
            medians.append(float(np.median(arr)))
            frames.append((arr, hdr))

        if not frames:
            self.update_status("⚠️ No valid frames to compute reference median; aborting star-trail.")
            return

        # reference median is the median of per-frame medians
        ref_median = float(np.median(medians))

        # grab the header from the first valid frame, strip out extra NAXIS keywords
        first_hdr = frames[0][1]
        if first_hdr is not None:
            hdr_to_use = first_hdr.copy()
            for key in list(hdr_to_use):
                if key.startswith("NAXIS") and key not in ("NAXIS", "NAXIS1", "NAXIS2"):
                    hdr_to_use.pop(key, None)
        else:
            hdr_to_use = None

        # 3) normalize each frame and write to a temp dir
        with tempfile.TemporaryDirectory(prefix="startrail_norm_") as norm_dir:
            normalized_paths = []
            for idx, (arr, hdr) in enumerate(frames, start=1):
                self.update_status(f"🔄 Normalizing frame {idx}/{len(frames)}")
                QApplication.processEvents()

                # guard against divide-by-zero
                m = float(np.median(arr))
                scale = ref_median / (m + 1e-12)
                img_norm = arr * scale

                stem = Path(all_files[idx-1]).stem
                out_path = os.path.join(norm_dir, f"{stem}_st.fit")
                fits.PrimaryHDU(data=img_norm, header=hdr).writeto(out_path, overwrite=True)
                normalized_paths.append(out_path)

            # 4) stack and do max-value projection
            self.update_status(f"📊 Stacking {len(normalized_paths)} frames")
            QApplication.processEvents()
            stack = np.stack([fits.getdata(p).astype(np.float32) for p in normalized_paths], axis=0)
            trail_img, _ = max_value_stack(stack)

            # 5) stretch final image and prompt user for save location & format
            trail_img = trail_img.astype(np.float32)
            # normalize to [0–1] for our save helper
            trail_norm = trail_img / (trail_img.max() + 1e-12)

            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            default_name = f"StarTrail_{n_frames:03d}frames_{ts}"
            filters = "TIFF (*.tif);;PNG (*.png);;JPEG (*.jpg *.jpeg);;FITS (*.fits);;XISF (*.xisf')"
            path, chosen_filter = QFileDialog.getSaveFileName(
                self,
                "Save Star-Trail Image",
                os.path.join(self.stacking_directory, default_name),
                filters
            )
            if not path:
                self.update_status("✖ Star-trail save cancelled.")
                return

            # figure out extension
            ext = os.path.splitext(path)[1].lower().lstrip('.')
            if not ext:
                ext = chosen_filter.split('(')[1].split(')')[0].lstrip('*.').lower()
                path += f".{ext}"

            # if user picked FITS, supply the first frame’s header; else None
            use_hdr = hdr_to_use if ext in ('fits', 'fit') else None

            # 16-bit everywhere
            save_image(
                img_array=trail_norm,
                filename=path,
                original_format=ext,
                bit_depth="16-bit",
                original_header=use_hdr,
                is_mono=False
            )

        # once we exit the with-block, all the _st.fit files are deleted
        self.update_status(f"✅ Star‐Trail image written to {path}")
        return


    def _apply_autocrop(self, arr, file_list, header, scale=1.0):
        """
        Crop 'arr' to the largest rectangle covered by ≥ coverage% of frames.
        'file_list' must be the aligned (_r) files used for this integration.
        'scale' = 1.0 for normal; = drizzle scale for drizzle images.
        Preserves mono vs color shape (mono stays (H,W); color stays (H,W,3)).
        """
        # Is it enabled?
        try:
            enabled = self.autocrop_cb.isChecked()
            pct = float(self.autocrop_pct.value())
        except Exception:
            enabled = self.settings.value("stacking/autocrop_enabled", False, type=bool)
            pct = float(self.settings.value("stacking/autocrop_pct", 95.0, type=float))

        if not enabled or not file_list:
            return arr, header

        transforms_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        rect = self._compute_autocrop_rect(file_list, transforms_path, pct)
        if not rect:
            self.update_status("✂️ Auto-crop: no common area found; skipping.")
            return arr, header

        x0, y0, x1, y1 = rect
        if scale != 1.0:
            # scale rect to drizzle resolution
            x0 = int(math.floor(x0 * scale))
            y0 = int(math.floor(y0 * scale))
            x1 = int(math.ceil (x1 * scale))
            y1 = int(math.ceil (y1 * scale))

        # Clamp to image bounds
        H, W = arr.shape[:2]
        x0 = max(0, min(W, x0)); x1 = max(x0, min(W, x1))
        y0 = max(0, min(H, y0)); y1 = max(y0, min(H, y1))

        # --- Crop while preserving channels ---
        if arr.ndim == 2:
            arr = arr[y0:y1, x0:x1]
        else:
            arr = arr[y0:y1, x0:x1, :]
            # If this is actually mono stored as (H,W,1), squeeze back to (H,W)
            if arr.shape[-1] == 1:
                arr = arr[..., 0]

        # Update header dims (+ shift CRPIX if present)
        if header is None:
            header = fits.Header()

        # NAXIS / sizes consistent with the new array
        if arr.ndim == 2:
            header["NAXIS"]  = 2
            header["NAXIS1"] = arr.shape[1]
            header["NAXIS2"] = arr.shape[0]
            # Remove any stale NAXIS3
            if "NAXIS3" in header:
                del header["NAXIS3"]
        else:
            header["NAXIS"]  = 3
            header["NAXIS1"] = arr.shape[1]
            header["NAXIS2"] = arr.shape[0]
            header["NAXIS3"] = arr.shape[2]

        if "CRPIX1" in header:
            header["CRPIX1"] = float(header["CRPIX1"]) - x0
        if "CRPIX2" in header:
            header["CRPIX2"] = float(header["CRPIX2"]) - y0

        self.update_status(f"✂️ Auto-cropped to [{x0}:{x1}]×[{y0}:{y1}] (scale {scale}×)")
        return arr, header


    def on_registration_complete(self, success, msg):
        self.update_status(msg)

        alignment_thread = self.alignment_thread
        if alignment_thread is None:
            self.update_status("⚠️ Error: No alignment data available.")
            return

        # Copy the final transforms
        all_transforms = alignment_thread.alignment_matrices.copy()

        # Get final shift values
        if not alignment_thread.transform_deltas:
            self.update_status("⚠️ No shift data available. Skipping filtering.")
            final_shifts = [0.0] * len(all_transforms)
        else:
            final_shifts = alignment_thread.transform_deltas[-1]

        # Pair filenames with shift values
        file_shift_pairs = list(zip(all_transforms.keys(), final_shifts))

        # 1) Build numeric transforms for valid frames
        valid_matrices = {
            orig_path: all_transforms[orig_path]
            for orig_path, shift in zip(all_transforms.keys(), final_shifts)
            if all_transforms[orig_path] is not None and shift <= 2.0
        }

        # 2) Build dictionary from the normalized `_n.fit` or `_n.fits` → final aligned `_n_r.fit`
        self.valid_transforms = {}
        for norm_path, shift in file_shift_pairs:
            transform = all_transforms[norm_path]
            if transform is not None and shift <= 2.0:
                base = os.path.basename(norm_path)
                # Check for both .fits and .fit extensions for normalized files.
                if base.endswith("_n.fits"):
                    aligned_name = base.replace("_n.fits", "_n_r.fit")
                elif base.endswith("_n.fit"):
                    aligned_name = base.replace("_n.fit", "_n_r.fit")
                elif base.endswith(".fits"):
                    aligned_name = base.replace(".fits", "_r.fit")
                elif base.endswith(".fit"):
                    aligned_name = base.replace(".fit", "_r.fit")
                else:
                    # Fallback if unexpected extension
                    aligned_name = base + "_r"

                aligned_path = os.path.join(
                    self.stacking_directory, "Aligned_Images", aligned_name
                )
                # Key the dictionary by the *same* normalized path used by the alignment
                self.valid_transforms[os.path.normpath(norm_path)] = aligned_path

        # Identify rejected
        rejected_files = [path for path, shift in file_shift_pairs if shift > 2.0]
        self.alignment_thread = None  # done with the thread

        # Status
        n_valid = len(self.valid_transforms)
        n_total = len(all_transforms)
        self.update_status(f"Alignment summary: {n_valid} succeeded, {n_total - n_valid} rejected.")

        if n_valid == 0:
            self.update_status("⚠️ No frames to stack; aborting.")
            return

        if rejected_files:
            self.update_status(f"🚨 Rejected {len(rejected_files)} frames due to shift > 2px.")
            for rf in rejected_files:
                self.update_status(f"  ❌ {os.path.basename(rf)}")

        # 3) Save numeric transforms
        self.save_alignment_matrices_sasd(valid_matrices)

        # Gather drizzle settings
        drizzle_dict = self.gather_drizzle_settings_from_tree()

        # ===========================
        # DEBUG PRINTS BEFORE FILTER
        # ===========================

        # 4) Filter `light_files`
        filtered_light_files = {}
        for group, file_list in self.light_files.items():
            filtered_light_files[group] = [
                f for f in file_list if os.path.normpath(f) in self.valid_transforms
            ]
            self.update_status(
                f"Group '{group}' has {len(filtered_light_files[group])} file(s) after filtering."
            )

        # 5) **Build a second dict** that replaces each normalized file with its aligned counterpart.
        aligned_light_files = {}
        for group, file_list in filtered_light_files.items():
            
            new_list = []
            for f in file_list:
                normed_f = os.path.normpath(f)
                aligned_f = self.valid_transforms.get(normed_f, None)
                
                if aligned_f and os.path.exists(aligned_f):
                    new_list.append(aligned_f)
                else:
                    self.update_status(f"DEBUG: File '{aligned_f}' does not exist on disk.")
            aligned_light_files[group] = new_list

        # Finally, pass the aligned_light_files to stacking
        self.stack_images_mixed_drizzle(
            grouped_files=aligned_light_files,  # Now we pass the aligned _r.fit paths
            frame_weights=self.frame_weights,
            transforms_dict=self.valid_transforms,
            drizzle_dict=drizzle_dict
        )

    def save_rejection_map_sasr(self, rejection_map, out_file):
        """
        Writes the per-file rejection map to a custom text file.
        Format:
            FILE: path/to/file1
            x1, y1
            x2, y2

            FILE: path/to/file2
            ...
        """
        with open(out_file, "w") as f:
            for fpath, coords_list in rejection_map.items():
                f.write(f"FILE: {fpath}\n")
                for (x, y) in coords_list:
                    # Convert to Python int in case they're NumPy int64
                    f.write(f"{int(x)}, {int(y)}\n")
                f.write("\n")  # blank line to separate blocks

    def load_rejection_map_sasr(self, in_file):
        """
        Reads a .sasr text file and rebuilds the rejection map dictionary.
        Returns a dict { fpath: [(x, y), (x, y), ...], ... }
        """
        rejections = {}
        with open(in_file, "r") as f:
            content = f.read().strip()

        # Split on blank lines
        blocks = re.split(r"\n\s*\n", content)
        for block in blocks:
            lines = [line.strip() for line in block.splitlines() if line.strip()]
            if not lines:
                continue

            # First line should be 'FILE: <path>'
            if lines[0].startswith("FILE:"):
                raw_path = lines[0].replace("FILE:", "").strip()
                coords = []
                for line in lines[1:]:
                    # Each subsequent line is "x, y"
                    parts = line.split(",")
                    if len(parts) == 2:
                        x_str, y_str = parts
                        x = int(x_str.strip())
                        y = int(y_str.strip())
                        coords.append((x, y))
                rejections[raw_path] = coords
        return rejections

    def stack_images_mixed_drizzle(self, grouped_files, frame_weights, transforms_dict, drizzle_dict):
        self.update_status("🔄 Running normal integration to record rejected pixel positions...")
        QApplication.processEvents()
        group_integration_data = {}
        summary_lines = []
        # NEW: where we collect any saved _autocrop files
        autocrop_outputs = []
        # let drizzle push into this from inside its method
        self._autocrop_outputs = []
        for group_key, file_list in grouped_files.items():
            self.update_status(f"Integration for group '{group_key}' with {len(file_list)} file(s): {file_list}")
            integrated_image, rejection_map, ref_header = self.normal_integration_with_rejection(
                group_key, file_list, frame_weights
            )

            # --- SAVE ORIGINAL (no crop yet) ---
            if integrated_image is None:
                continue

            if ref_header is None:
                ref_header = fits.Header()

            # Common header keys
            hdr_orig = ref_header.copy()
            hdr_orig["IMAGETYP"] = "MASTER STACK"
            hdr_orig["BITPIX"]   = -32
            hdr_orig["STACKED"]  = (True, "Stacked using normal_integration_with_rejection")
            hdr_orig["CREATOR"]  = "SetiAstroSuite"
            hdr_orig["DATE-OBS"] = datetime.utcnow().isoformat()

            is_mono_orig = (integrated_image.ndim == 2)
            if is_mono_orig:
                hdr_orig["NAXIS"]  = 2
                hdr_orig["NAXIS1"] = integrated_image.shape[1]
                hdr_orig["NAXIS2"] = integrated_image.shape[0]
                if "NAXIS3" in hdr_orig: del hdr_orig["NAXIS3"]
            else:
                hdr_orig["NAXIS"]  = 3
                hdr_orig["NAXIS1"] = integrated_image.shape[1]
                hdr_orig["NAXIS2"] = integrated_image.shape[0]
                hdr_orig["NAXIS3"] = integrated_image.shape[2]

            n_frames = len(file_list)
            base_name = f"MasterLight_{group_key}_{n_frames}stacked"
            out_path_orig = os.path.join(self.stacking_directory, f"{base_name}.fit")

            save_image(
                img_array=integrated_image,
                filename=out_path_orig,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=hdr_orig,
                is_mono=is_mono_orig
            )
            self.update_status(f"✅ Saved integrated image (original) for '{group_key}': {out_path_orig}")
            QApplication.processEvents()

            # --- OPTIONAL: AUTOCROP SECOND COPY ---
            cropped_img, hdr_crop = self._apply_autocrop(
                integrated_image, file_list, ref_header.copy(), scale=1.0
            )

            # If auto-crop is disabled, _apply_autocrop returns the input unchanged;
            # only write a second file when auto-crop actually changed bounds or is enabled.
            autocrop_enabled = False
            try:
                autocrop_enabled = self.autocrop_cb.isChecked()
            except Exception:
                autocrop_enabled = self.settings.value("stacking/autocrop_enabled", False, type=bool)

            if autocrop_enabled:
                # _apply_autocrop already fixed NAXIS*, CRPIX*; ensure mono flag matches final array
                is_mono_crop = (cropped_img.ndim == 2)
                out_path_crop = os.path.join(self.stacking_directory, f"{base_name}_autocrop.fit")
                save_image(
                    img_array=cropped_img,
                    filename=out_path_crop,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=hdr_crop,
                    is_mono=is_mono_crop
                )
                self.update_status(f"✂️ Saved auto-cropped image for '{group_key}': {out_path_crop}")
                QApplication.processEvents()
                autocrop_outputs.append((group_key, out_path_crop))

            # Keep bookkeeping as before
            dconf = drizzle_dict.get(group_key, {})
            if dconf.get("drizzle_enabled", False):
                sasr_path = os.path.join(self.stacking_directory, f"{group_key}_rejections.sasr")
                self.save_rejection_map_sasr(rejection_map, sasr_path)
                self.update_status(f"✅ Saved rejection map to {sasr_path}")
                group_integration_data[group_key] = {
                    "integrated_image": integrated_image,
                    "rejection_map": rejection_map,
                    "n_frames": n_frames,
                    "drizzled": True
                }
            else:
                group_integration_data[group_key] = {
                    "integrated_image": integrated_image,
                    "rejection_map": None,
                    "n_frames": n_frames,
                    "drizzled": False
                }
                self.update_status(f"ℹ️ Skipping rejection map save for '{group_key}' (drizzle disabled).")

        for group_key, file_list in grouped_files.items():
            dconf = drizzle_dict.get(group_key, None)
            if dconf and dconf.get("drizzle_enabled", False):
                scale_factor = dconf["scale_factor"]
                drop_shrink = dconf["drop_shrink"]
                rejections_for_group = group_integration_data[group_key]["rejection_map"]
                n_frames = group_integration_data[group_key]["n_frames"]

                self.update_status(f"📐 Drizzle for '{group_key}' at {scale_factor}× (drop={drop_shrink}) using {n_frames} frame(s).")
                QApplication.processEvents()

                self.drizzle_stack_one_group(
                    group_key=group_key,
                    file_list=file_list,
                    transforms_dict=transforms_dict,
                    frame_weights=frame_weights,
                    scale_factor=scale_factor,
                    drop_shrink=drop_shrink,
                    rejection_map=rejections_for_group
                )
                
            else:
                self.update_status(f"✅ Group '{group_key}' not set for drizzle. Integrated image already saved.")
                QApplication.processEvents()

        autocrop_outputs.extend(getattr(self, "_autocrop_outputs", []))

        # 🧾 Summary message box
        for group_key, info in group_integration_data.items():
            n_frames = info["n_frames"]
            drizzled = info["drizzled"]
            summary_lines.append(f"• {group_key}: {n_frames} stacked{' + drizzle' if drizzled else ''}")

        # NEW: list auto-cropped outputs if any
        if autocrop_outputs:
            summary_lines.append("")  # blank line separator
            summary_lines.append("Auto-cropped files saved:")
            for g, p in autocrop_outputs:
                summary_lines.append(f"  • {g} → {p}")

        summary_text = "\n".join(summary_lines)
        QMessageBox.information(
            self,
            "Integration Summary",
            f"The following groups were successfully integrated:\n\n{summary_text}"
        )

    def save_registered_images(self, success, msg, frame_weights):
        if not success:
            self.update_status(f"⚠️ Image registration failed: {msg}")
            return

        self.update_status("✅ All frames registered successfully!")
        
        # Use the grouped files already stored from the tree view.
        if not self.light_files:
            self.update_status("⚠️ No light frames available for stacking!")
            return
        
        self.update_status(f"📂 Preparing to stack {sum(len(v) for v in self.light_files.values())} frames in {len(self.light_files)} groups.")
        
        # Pass the dictionary (grouped by filter, exposure, dimensions) to the stacking function.
        self.stack_registered_images(self.light_files, frame_weights)


    def stack_registered_images_chunked(
        self,
        grouped_files,           # dict of { group_key: [list_of_aligned_and_already_normalized_file_paths] }
        frame_weights,           # dict of { file_path: weight }
        chunk_height=2048,
        chunk_width=2048
    ):
        """
        Chunked stacking of already-aligned and pre-normalized FITS images.
        Reads small tiles from each image, applies outlier rejection (using the new rejection-map output),
        writes the result into a memory-mapped array, and saves a final stacked FITS.
        """
        self.update_status(f"✅ Chunked stacking {len(grouped_files)} group(s)...")

        # We'll also accumulate a list of rejected pixel positions (global coordinates)
        all_rejection_coords = []

        for group_key, file_list in grouped_files.items():
            num_files = len(file_list)
            self.update_status(f"📊 Group '{group_key}' has {num_files} aligned file(s).")
            QApplication.processEvents()

            if num_files < 2:
                self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to stack.")
                continue

            # 1) Identify the reference file to get shape and header
            ref_file = file_list[0]
            if not os.path.exists(ref_file):
                self.update_status(f"⚠️ Reference file '{ref_file}' not found, skipping group.")
                continue

            ref_data, ref_header, _, _ = load_image(ref_file)
            if ref_data is None:
                self.update_status(f"⚠️ Could not load reference '{ref_file}', skipping group.")
                continue

            is_color = (ref_data.ndim == 3 and ref_data.shape[2] == 3)
            height, width = ref_data.shape[:2]
            channels = 3 if is_color else 1

            # 2) Prepare a memmap for the final stacked image.
            memmap_path = os.path.join(self.stacking_directory, f"chunked_{group_key}.dat")
            final_stacked = np.memmap(
                memmap_path,
                dtype=np.float32,
                mode='w+',
                shape=(height, width, channels)
            )

            # Build list of valid files and corresponding weights.
            aligned_paths = []
            weights_list = []
            for fpath in file_list:
                if os.path.exists(fpath):
                    aligned_paths.append(fpath)
                    w = frame_weights.get(fpath, 1.0)
                    weights_list.append(w)
                else:
                    self.update_status(f"⚠️ File not found: {fpath}, skipping.")

            if len(aligned_paths) < 2:
                self.update_status(f"⚠️ Not enough valid frames in group '{group_key}' to stack.")
                continue

            weights_list = np.array(weights_list, dtype=np.float32)
            self.update_status(f"📊 Stacking group '{group_key}' with {self.rejection_algorithm}")
            QApplication.processEvents()

            # Initialize a list to collect rejected pixel coordinates for this group.
            rejection_coords = []
            N = len(aligned_paths)
            DTYPE    = np.float64
            pref_h   = self.chunk_height
            pref_w   = self.chunk_width

            # 3) Compute a safe chunk size once, up front
            try:
                chunk_h, chunk_w = compute_safe_chunk(
                    height, width, N, channels, DTYPE, pref_h, pref_w
                )
                self.update_status(f"🔧 Using chunk size {chunk_h}×{chunk_w} for float64")
            except MemoryError as e:
                self.update_status(f"⚠️ {e}")
                return None, {}, None

            # 3) Loop over tiles
            from concurrent.futures import ThreadPoolExecutor, as_completed
            for y_start in range(0, height, chunk_height):
                y_end = min(y_start + chunk_height, height)
                tile_h = y_end - y_start

                for x_start in range(0, width, chunk_width):
                    x_end = min(x_start + chunk_width, width)
                    tile_w = x_end - x_start

                    # Build tile stack: shape (N, tile_h, tile_w, channels)
                    N = len(aligned_paths)
                 
                    tile_stack = np.zeros((N, tile_h, tile_w, channels), dtype=np.float32)
                    num_cores = os.cpu_count() or 4
                    with ThreadPoolExecutor(max_workers=num_cores) as executor:
                        future_to_index = {}
                        for i, path in enumerate(aligned_paths):
                            future = executor.submit(load_fits_tile, path, y_start, y_end, x_start, x_end)
                            future_to_index[future] = i

                        for future in as_completed(future_to_index):
                            i = future_to_index[future]
                            sub_img = future.result()
                            if sub_img is None:
                                continue
                            # Ensure sub_img is shaped (tile_h, tile_w, channels)
                            if sub_img.ndim == 2:
                                sub_img = sub_img[:, :, np.newaxis]
                                if channels == 3:
                                    sub_img = np.repeat(sub_img, 3, axis=2)
                            elif sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                                sub_img = sub_img.transpose(1, 2, 0)
                            sub_img = sub_img.astype(np.float32, copy=False)
                            tile_stack[i] = sub_img

                    # 4) Apply the chosen rejection algorithm and get the rejection map.
                    algo = self.rejection_algorithm
                    if algo == "Simple Median (No Rejection)":
                        tile_result = np.median(tile_stack, axis=0)
                        tile_rej_map = np.zeros(tile_stack.shape[1:], dtype=np.bool_)
                    elif algo == "Simple Average (No Rejection)":
                        tile_result = np.average(tile_stack, axis=0, weights=weights_list)
                        tile_rej_map = np.zeros(tile_stack.shape[1:], dtype=np.bool_)
                    elif algo == "Weighted Windsorized Sigma Clipping":
                        tile_result, tile_rej_map = windsorized_sigma_clip_weighted(tile_stack, weights_list,
                            lower=self.sigma_low, upper=self.sigma_high)
                    elif algo == "Kappa-Sigma Clipping":
                        tile_result, tile_rej_map = kappa_sigma_clip_weighted(tile_stack, weights_list,
                            kappa=self.kappa, iterations=self.iterations)
                    elif algo == "Trimmed Mean":
                        tile_result, tile_rej_map = trimmed_mean_weighted(tile_stack, weights_list,
                            trim_fraction=self.trim_fraction)
                    elif algo == "Extreme Studentized Deviate (ESD)":
                        tile_result, tile_rej_map = esd_clip_weighted(tile_stack, weights_list,
                            threshold=self.esd_threshold)
                    elif algo == "Biweight Estimator":
                        tile_result, tile_rej_map = biweight_location_weighted(tile_stack, weights_list,
                            tuning_constant=self.biweight_constant)
                    elif algo == "Modified Z-Score Clipping":
                        tile_result, tile_rej_map = modified_zscore_clip_weighted(tile_stack, weights_list,
                            threshold=self.modz_threshold)
                    elif algo == "Max Value":
                        tile_result, tile_rej_map = max_value_stack(tile_stack, weights_list)
                    else:
                        tile_result, tile_rej_map = windsorized_sigma_clip_weighted(tile_stack, weights_list,
                            lower=self.sigma_low, upper=self.sigma_high)

                    # 5) Insert integrated tile into final image.
                    final_stacked[y_start:y_end, x_start:x_end, :] = tile_result

                    # 6) Use the returned tile_rej_map to record rejected pixel positions.
                    # For rejection maps with per-frame output, combine along the frame axis.
                    if tile_rej_map.ndim == 3:  # mono: (N, tile_h, tile_w)
                        combined_rej = np.any(tile_rej_map, axis=0)  # shape: (tile_h, tile_w)
                    elif tile_rej_map.ndim == 4:  # color: (N, tile_h, tile_w, channels)
                        # First combine along the frame axis, then across channels.
                        combined_rej = np.any(tile_rej_map, axis=0)  # shape: (tile_h, tile_w, channels)
                        combined_rej = np.any(combined_rej, axis=-1)  # shape: (tile_h, tile_w)
                    else:
                        combined_rej = np.zeros(tile_stack.shape[1:3], dtype=np.bool_)

                    ys_tile, xs_tile = np.where(combined_rej)
                    for dx, dy in zip(xs_tile, ys_tile):
                        global_x = x_start + dx
                        global_y = y_start + dy
                        rejection_coords.append((global_x, global_y))

            # 7) After processing all tiles, finish up the integrated image.
            final_array = np.array(final_stacked)
            del final_stacked

            # Apply a black-point offset and scale if needed.
            flat_array = final_array.ravel()
            nonzero_indices = np.where(flat_array > 0)[0]
            if nonzero_indices.size > 0:
                first_nonzero = flat_array[nonzero_indices[0]]
                final_array -= first_nonzero

            new_max = final_array.max()
            if new_max > 1.0:
                new_min = final_array.min()
                range_val = new_max - new_min
                if range_val != 0:
                    final_array = (final_array - new_min) / range_val
                else:
                    final_array = np.zeros_like(final_array, dtype=np.float32)

            if final_array.ndim == 3 and final_array.shape[-1] == 1:
                final_array = final_array[..., 0]
            is_mono = (final_array.ndim == 2)

            # 8) Save the final stacked image.
            if ref_header is None:
                ref_header = fits.Header()

            ref_header["IMAGETYP"] = "MASTER STACK"
            ref_header["BITPIX"] = -32
            ref_header["STACKED"] = (True, "Stacked using chunked approach")
            ref_header["CREATOR"] = "SetiAstroSuite"
            ref_header["DATE-OBS"] = datetime.utcnow().isoformat()

            if is_mono:
                ref_header["NAXIS"] = 2
                ref_header["NAXIS1"] = final_array.shape[1]
                ref_header["NAXIS2"] = final_array.shape[0]
            else:
                ref_header["NAXIS"] = 3
                ref_header["NAXIS1"] = final_array.shape[1]
                ref_header["NAXIS2"] = final_array.shape[0]
                ref_header["NAXIS3"] = 3

            output_filename = f"MasterLight_{group_key}_{len(aligned_paths)}stacked.fit"
            output_path = os.path.join(self.stacking_directory, output_filename)
            save_image(
                img_array=final_array,
                filename=output_path,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=ref_header,
                is_mono=is_mono
            )

            self.update_status(f"✅ Group '{group_key}' stacked {len(aligned_paths)} frame(s)! Saved: {output_path}")

            print(f"✅ Master Light saved for group '{group_key}': {output_path}")

            # Optionally, you might want to store or log 'rejection_coords' (here appended to all_rejection_coords)
            all_rejection_coords.extend(rejection_coords)

            # Clean up memmap file
            try:
                os.remove(memmap_path)
            except OSError:
                pass

        # Optionally, you could return the global rejection coordinate list.
        return all_rejection_coords

        QMessageBox.information(
            self,
            "Stacking Complete",
            f"All stacking finished successfully.\n"
            f"Frames per group:\n" +
            "\n".join([f"{group_key}: {len(files)} frame(s)" for group_key, files in grouped_files.items()])
        )



    def integrate_registered_images(self):
        """ 
        Integrates previously registered images (already aligned) without re-aligning them,
        but uses a chunked measurement approach so we don't load all frames at once.
        """
        self.update_status("🔄 Integrating Previously Registered Images...")

        # 1) Extract files from the registration tree
        self.extract_light_files_from_tree()
        if not self.light_files:
            self.update_status("⚠️ No registered images found!")
            return

        # Flatten the dictionary to get all registered files
        all_files = [f for file_list in self.light_files.values() for f in file_list]
        if not all_files:
            self.update_status("⚠️ No frames found in the registration tree!")
            return

        # 2) We'll measure means + star counts in chunks, so we don't load everything at once
        self.update_status(f"📊 Found {len(all_files)} total aligned frames. Measuring in parallel batches...")

        self.frame_weights = {}
        mean_values = {}
        star_counts = {}
        measured_frames = []

        # Decide how many images to load at once. Typically # of CPU cores:
        max_workers = os.cpu_count() or 4
        chunk_size = max_workers  # or a custom formula if you prefer

        def chunk_list(lst, size):
            for i in range(0, len(lst), size):
                yield lst[i : i + size]

        chunked_files = list(chunk_list(all_files, chunk_size))
        total_chunks = len(chunked_files)

        # 3) Process each chunk
        chunk_index = 0
        for chunk in chunked_files:
            chunk_index += 1
            self.update_status(f"📦 Loading and measuring chunk {chunk_index}/{total_chunks} with {len(chunk)} frames...")
            QApplication.processEvents()

            # Load this chunk of images
            images = []
            valid_files_for_this_chunk = []
            for file in chunk:
                image_data, _, _, _ = load_image(file)
                if image_data is not None:
                    images.append(image_data)
                    valid_files_for_this_chunk.append(file)
                else:
                    self.update_status(f"⚠️ Could not load {file}, skipping.")

            if not images:
                self.update_status("⚠️ No valid images in this chunk.")
                continue

            # Parallel measure the mean pixel value
            self.update_status("🌍 Measuring global statistics (mean) in parallel...")
            QApplication.processEvents()
            means = parallel_measure_frames(images)

            # Now measure star counts
            for i, file in enumerate(valid_files_for_this_chunk):
                mean_signal = means[i]
                mean_values[file] = mean_signal
                measured_frames.append(file)

                self.update_status(f"⭐ Measuring star stats for {file}...")
                QApplication.processEvents()
                count, ecc = compute_star_count(images[i])
                star_counts[file] = {"count": count, "eccentricity": ecc}

            # Clear the images from memory before moving on
            del images

        # If we never measured any frames at all
        if not measured_frames:
            self.update_status("⚠️ No frames could be measured!")
            return

        self.update_status(f"✅ All chunks complete! Measured {len(measured_frames)} frames total.")
        QApplication.processEvents()

        # 4) Compute Weights
        self.update_status("⚖️ Computing frame weights...")

        debug_weight_log = "\n📊 **Frame Weights Debug Log:**\n"
        QApplication.processEvents()
        for file in measured_frames:
            c = star_counts[file]["count"]
            ecc = star_counts[file]["eccentricity"]
            mean_val = mean_values[file]

            star_weight = max(c, 1e-6)
            mean_weight = max(mean_val, 1e-6)

            # Basic ratio-based weight: star_count / mean
            raw_weight = star_weight / mean_weight
            self.frame_weights[file] = raw_weight

            debug_weight_log += (
                f"📂 {os.path.basename(file)} → "
                f"Star Count: {c}, Mean: {mean_val:.4f}, Final Weight: {raw_weight:.4f}\n"
            )
            QApplication.processEvents()

        self.update_status(debug_weight_log)
        self.update_status("✅ Frame weights computed!")
        QApplication.processEvents()

        # 5) Pick the best reference frame if not user-specified
        if hasattr(self, "reference_frame") and self.reference_frame:
            self.update_status(f"📌 Using user-specified reference frame: {self.reference_frame}")
            QApplication.processEvents()
        else:
            self.reference_frame = max(self.frame_weights, key=self.frame_weights.get)
            self.update_status(f"📌 Auto-selected reference frame: {self.reference_frame} (Best Weight)")
            
        chunk_h = self.chunk_height  # or self.settings.value("stacking/chunk_height", 1024, type=int)
        chunk_w = self.chunk_width   # or self.settings.value("stacking/chunk_width", 1024, type=int)

        # 6) Finally, call the chunked stacking method using the already registered images
        self.stack_registered_images_chunked(self.light_files, self.frame_weights, chunk_height=chunk_h, chunk_width=chunk_w)

    @staticmethod
    def invert_affine_transform(matrix):
        """
        Inverts a 2x3 affine transformation matrix.
        Given matrix = [[a, b, tx],
                        [c, d, ty]],
        returns the inverse matrix.
        """
        A = matrix[:, :2]
        t = matrix[:, 2]
        A_inv = np.linalg.inv(A)
        t_inv = -A_inv @ t
        inv = np.hstack([A_inv, t_inv.reshape(2, 1)])
        return inv

    @staticmethod
    def apply_affine_transform_point(matrix, x, y):
        """
        Applies a 2x3 affine transformation to a point (x, y).
        Returns the transformed (x, y) coordinates.
        """
        point = np.array([x, y])
        result = matrix[:, :2] @ point + matrix[:, 2]
        return result[0], result[1]

    def drizzle_stack_one_group(
        self,
        group_key,
        file_list,
        transforms_dict,
        frame_weights,
        scale_factor=2.0,
        drop_shrink=0.65,
        rejection_map=None
    ):
        """
        Drizzle a single group. Now, we only skip the pixels that are actually rejected for
        each file (based on the per-file rejection_map).
        
        'rejection_map' is a dict: { file_path: [(x_r, y_r), (x_r, y_r), ...], ... }
        where (x_r, y_r) are coordinates in the aligned (_n_r) space that were rejected
        for THAT particular file.
        """
        # Count how many total rejections across all files (for debug)
        total_rej = 0
        if rejection_map is not None:
            total_rej = sum(len(v) for v in rejection_map.values())
        self.update_status(
            f"🔭 Drizzle stacking for group '{group_key}' with {total_rej} total rejected pixels across files."
        )
        QApplication.processEvents()

        # 1) Check we have enough frames
        if len(file_list) < 2:
            self.update_status(f"⚠️ Group '{group_key}' does not have enough frames to drizzle.")
            return

        # 2) Load transforms from disk
        transforms_path = os.path.join(self.stacking_directory, "alignment_transforms.sasd")
        if not os.path.exists(transforms_path):
            self.update_status(f"⚠️ No alignment_transforms.sasd found at {transforms_path}!")
            return

        new_transforms_dict = self.load_alignment_matrices_custom(transforms_path)
        self.update_status(f"✅ Loaded {len(new_transforms_dict)} transforms from disk for drizzle.")
        QApplication.processEvents()

        # 3) Load the first file to determine shape + color/mono
        first_file = file_list[0]
        first_img, hdr, _, _ = load_image(first_file)
        if first_img is None:
            self.update_status(f"⚠️ Could not load {first_file} to determine drizzle shape!")
            return

        if first_img.ndim == 2:
            is_mono = True
            h, w = first_img.shape
        else:
            is_mono = False
            h, w, c = first_img.shape

        # 4) Decide deposit function (naive vs footprint)
        if drop_shrink >= 0.99:
            if is_mono:
                deposit_func = drizzle_deposit_numba_naive
                self.update_status("Using naive drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_naive
                self.update_status("Using naive drizzle deposit (color).")
        else:
            if is_mono:
                deposit_func = drizzle_deposit_numba_footprint
                self.update_status("Using footprint drizzle deposit (mono).")
            else:
                deposit_func = drizzle_deposit_color_footprint
                self.update_status("Using footprint drizzle deposit (color).")
        QApplication.processEvents()

        # 5) Prepare drizzle buffers
        out_h = int(h * scale_factor)
        out_w = int(w * scale_factor)
        if is_mono:
            drizzle_buffer = np.zeros((out_h, out_w), dtype=np.float64)
            coverage_buffer = np.zeros((out_h, out_w), dtype=np.float64)
            finalize_func = finalize_drizzle_2d
        else:
            drizzle_buffer = np.zeros((out_h, out_w, c), dtype=np.float64)
            coverage_buffer = np.zeros((out_h, out_w, c), dtype=np.float64)
            finalize_func = finalize_drizzle_3d

        # 6) For each aligned file, deposit raw pixels—skipping only that file's rejections
        for aligned_file in file_list:
            aligned_base = os.path.basename(aligned_file)
            if aligned_base.endswith("_n_r.fit"):
                raw_base = aligned_base.replace("_n_r.fit", "_n.fit")
            else:
                raw_base = aligned_base

            raw_file = os.path.join(self.stacking_directory, "Normalized_Images", raw_base)
            raw_img_data, _, _, _ = load_image(raw_file)
            if raw_img_data is None:
                self.update_status(f"⚠️ Could not load raw file '{raw_file}' for drizzle!")
                continue

            # Look up transform
            raw_key = os.path.normpath(raw_file)
            transform = new_transforms_dict.get(raw_key, None)
            if transform is None:
                self.update_status(f"⚠️ No transform found for raw '{raw_base}'! Skipping drizzle.")
                continue

            self.update_status(f"🧩 Drizzling (raw): {raw_base}")
            self.update_status(
                f"    Matrix: [[{transform[0,0]:.4f}, {transform[0,1]:.4f}, {transform[0,2]:.4f}], "
                f"[{transform[1,0]:.4f}, {transform[1,1]:.4f}, {transform[1,2]:.4f}]]"
            )
            QApplication.processEvents()

            weight = frame_weights.get(aligned_file, 1.0)
            if transform.dtype != np.float32:
                transform = transform.astype(np.float32)

            # Only skip rejections for THIS file
            coords_for_this_file = []
            if rejection_map is not None:
                coords_for_this_file = rejection_map.get(aligned_file, [])

            # Mask out those pixels in the raw image
            if coords_for_this_file:
                inv_transform = self.invert_affine_transform(transform)
                for (x_r, y_r) in coords_for_this_file:
                    x_raw, y_raw = self.apply_affine_transform_point(inv_transform, x_r, y_r)
                    x_raw = int(round(x_raw))
                    y_raw = int(round(y_raw))
                    if 0 <= x_raw < raw_img_data.shape[1] and 0 <= y_raw < raw_img_data.shape[0]:
                        raw_img_data[y_raw, x_raw] = 0.0

            # Deposit raw pixels using the transform
            drizzle_buffer, coverage_buffer = deposit_func(
                raw_img_data,
                transform,
                drizzle_buffer,
                coverage_buffer,
                scale_factor,
                drop_shrink,
                weight
            )

        # 7) Finalize drizzle
        final_drizzle = np.zeros_like(drizzle_buffer, dtype=np.float32)
        final_drizzle = finalize_func(drizzle_buffer, coverage_buffer, final_drizzle)



        # 8) Save final drizzle image
        # 8) Save final drizzle image (original first)
        base_name = f"MasterLight_{group_key}_{len(file_list)}stacked_drizzle"
        out_path_orig = os.path.join(self.stacking_directory, f"{base_name}.fit")

        hdr_orig = hdr.copy() if hdr is not None else fits.Header()
        hdr_orig["IMAGETYP"]   = "MASTER STACK - DRIZZLE"
        hdr_orig["DRIZFACTOR"] = (scale_factor, "Drizzle scale factor")
        hdr_orig["DROPFRAC"]   = (drop_shrink,  "Drizzle drop shrink/pixfrac")
        hdr_orig["CREATOR"]    = "SetiAstroSuite"
        hdr_orig["DATE-OBS"]   = datetime.utcnow().isoformat()

        is_mono_orig = not (final_drizzle.ndim == 3 and final_drizzle.shape[-1] == 3)
        if is_mono_orig:
            hdr_orig["NAXIS"]  = 2
            hdr_orig["NAXIS1"] = final_drizzle.shape[1]
            hdr_orig["NAXIS2"] = final_drizzle.shape[0]
            if "NAXIS3" in hdr_orig: del hdr_orig["NAXIS3"]
        else:
            hdr_orig["NAXIS"]  = 3
            hdr_orig["NAXIS1"] = final_drizzle.shape[1]
            hdr_orig["NAXIS2"] = final_drizzle.shape[0]
            hdr_orig["NAXIS3"] = final_drizzle.shape[2]

        save_image(
            img_array=final_drizzle,
            filename=out_path_orig,
            original_format="fit",
            bit_depth="32-bit floating point",
            original_header=hdr_orig,
            is_mono=is_mono_orig
        )
        self.update_status(f"✅ Drizzle (original) saved: {out_path_orig}")

        # 9) Optional auto-crop copy (scaled rect)
        autocrop_enabled = False
        try:
            autocrop_enabled = self.autocrop_cb.isChecked()
        except Exception:
            autocrop_enabled = self.settings.value("stacking/autocrop_enabled", False, type=bool)

        if autocrop_enabled:
            cropped_drizzle, hdr_crop = self._apply_autocrop(
                final_drizzle, file_list, hdr.copy() if hdr is not None else fits.Header(),
                scale=scale_factor
            )
            is_mono_crop = (cropped_drizzle.ndim == 2)
            out_path_crop = os.path.join(self.stacking_directory, f"{base_name}_autocrop.fit")
            save_image(
                img_array=cropped_drizzle,
                filename=out_path_crop,
                original_format="fit",
                bit_depth="32-bit floating point",
                original_header=hdr_crop,
                is_mono=is_mono_crop
            )
            if not hasattr(self, "_autocrop_outputs"):
                self._autocrop_outputs = []
            self._autocrop_outputs.append((group_key, out_path_crop))
            self.update_status(f"✂️ Drizzle (auto-cropped) saved: {out_path_crop}")



    def normal_integration_with_rejection(self, group_key, file_list, frame_weights):
        """
        Performs chunked stacking integration of aligned (_n_r) images using the current
        rejection algorithm. Returns:
        - integrated_image: Final integrated (stacked) image as a NumPy array.
        - per_file_rejections: dict mapping each file in 'file_list' to a list of (x,y)
            coordinates that were rejected for THAT file only.
        - ref_header: the header from the reference file (or a new one if missing)
        """
        # 0) Initial status
        self.update_status(f"Starting integration for group '{group_key}' with {len(file_list)} files.")
        QApplication.processEvents()

        # 1) Sanity checks
        if not file_list:
            self.update_status(f"DEBUG: Empty file_list for group '{group_key}'.")
            return None, {}, None

        # 2) Load a reference image to determine dimensions and channels
        ref_file = file_list[0]
        if not os.path.exists(ref_file):
            self.update_status(f"⚠️ Reference file '{ref_file}' not found for group '{group_key}'.")
            return None, {}, None
        ref_data, ref_header, _, _ = load_image(ref_file)
        if ref_data is None:
            self.update_status(f"⚠️ Could not load reference '{ref_file}' for group '{group_key}'.")
            return None, {}, None
        if ref_header is None:
            ref_header = fits.Header()

        is_color = (ref_data.ndim == 3 and ref_data.shape[2] == 3)
        height, width = ref_data.shape[:2]
        channels = 3 if is_color else 1

        self.update_status(f"📊 Stacking group '{group_key}' with {self.rejection_algorithm}")
        QApplication.processEvents()

        # 3) Allocate output and rejections dict
        N = len(file_list)
        integrated_image = np.zeros((height, width, channels), dtype=np.float64)
        per_file_rejections = {f: [] for f in file_list}

        # 4) Compute chunk size
        DTYPE  = np.float64
        pref_h = self.chunk_height
        pref_w = self.chunk_width
        try:
            chunk_h, chunk_w = compute_safe_chunk(
                height, width, N, channels, DTYPE, pref_h, pref_w
            )
            self.update_status(f"🔧 Using chunk size {chunk_h}×{chunk_w} for float64")
            QApplication.processEvents()
        except MemoryError as e:
            self.update_status(f"⚠️ {e}")
            return None, {}, None

        # 5) Precompute total tile count for progress
        n_rows     = math.ceil(height / chunk_h)
        n_cols     = math.ceil(width  / chunk_w)
        total_tiles = n_rows * n_cols
        tile_idx    = 0

        # 6) Loop over tiles
        for y_start in range(0, height, chunk_h):
            y_end  = min(y_start + chunk_h, height)
            tile_h = y_end - y_start

            for x_start in range(0, width, chunk_w):
                x_end  = min(x_start + chunk_w, width)
                tile_w = x_end - x_start

                # --- Update progress ---
                tile_idx += 1
                self.update_status(f"Integrating tile {tile_idx}/{total_tiles}...")
                QApplication.processEvents()

                # 6a) Build tile stack
                tile_stack    = np.zeros((N, tile_h, tile_w, channels), dtype=np.float64)
                weights_list  = []
                num_cores     = os.cpu_count() or 4

                with ThreadPoolExecutor(max_workers=num_cores) as executor:
                    future_to_i = {}
                    for i, fpath in enumerate(file_list):
                        future = executor.submit(load_fits_tile, fpath, y_start, y_end, x_start, x_end)
                        future_to_i[future] = i
                        weights_list.append(frame_weights.get(fpath, 1.0))

                    for fut in as_completed(future_to_i):
                        i       = future_to_i[fut]
                        sub_img = fut.result()
                        if sub_img is None:
                            self.update_status(f"DEBUG: Tile load returned None for file: {file_list[i]}")
                            continue
                        # Normalize shape → (tile_h, tile_w, channels)
                        if sub_img.ndim == 2:
                            sub_img = sub_img[:, :, np.newaxis]
                            if channels == 3:
                                sub_img = np.repeat(sub_img, 3, axis=2)
                        elif sub_img.ndim == 3 and sub_img.shape[0] == 3 and channels == 3:
                            sub_img = sub_img.transpose(1, 2, 0)
                        tile_stack[i] = sub_img.astype(np.float32, copy=False)

                weights_array = np.array(weights_list, dtype=np.float32)

                # 6b) Apply rejection algorithm
                algo = self.rejection_algorithm
                if algo == "Simple Median (No Rejection)":
                    tile_result  = np.median(tile_stack, axis=0)
                    tile_rej_map = np.zeros((N, tile_h, tile_w), dtype=bool)
                elif algo == "Simple Average (No Rejection)":
                    tile_result  = np.average(tile_stack, axis=0, weights=weights_array)
                    tile_rej_map = np.zeros((N, tile_h, tile_w), dtype=bool)
                elif algo == "Weighted Windsorized Sigma Clipping":
                    tile_result, tile_rej_map = windsorized_sigma_clip_weighted(
                        tile_stack, weights_array,
                        lower=self.sigma_low, upper=self.sigma_high
                    )
                elif algo == "Kappa-Sigma Clipping":
                    tile_result, tile_rej_map = kappa_sigma_clip_weighted(
                        tile_stack, weights_array,
                        kappa=self.kappa, iterations=self.iterations
                    )
                elif algo == "Trimmed Mean":
                    tile_result, tile_rej_map = trimmed_mean_weighted(
                        tile_stack, weights_array,
                        trim_fraction=self.trim_fraction
                    )
                elif algo == "Extreme Studentized Deviate (ESD)":
                    tile_result, tile_rej_map = esd_clip_weighted(
                        tile_stack, weights_array,
                        threshold=self.esd_threshold
                    )
                elif algo == "Biweight Estimator":
                    tile_result, tile_rej_map = biweight_location_weighted(
                        tile_stack, weights_array,
                        tuning_constant=self.biweight_constant
                    )
                elif algo == "Modified Z-Score Clipping":
                    tile_result, tile_rej_map = modified_zscore_clip_weighted(
                        tile_stack, weights_array,
                        threshold=self.modz_threshold
                    )
                elif algo == "Max Value":
                    tile_result, tile_rej_map = max_value_stack(
                        tile_stack, weights_array
                    )
                else:
                    tile_result, tile_rej_map = windsorized_sigma_clip_weighted(
                        tile_stack, weights_array,
                        lower=self.sigma_low, upper=self.sigma_high
                    )

                # 7) Place the integrated tile into the final image
                integrated_image[y_start:y_end, x_start:x_end, :] = tile_result

                # 8) Record per-file rejections
                if tile_rej_map.ndim == 4:
                    tile_rej_map = np.any(tile_rej_map, axis=-1)
                for i, fpath in enumerate(file_list):
                    ys, xs = np.where(tile_rej_map[i])
                    for dy, dx in zip(ys, xs):
                        per_file_rejections[fpath].append((x_start + dx, y_start + dy))

        # 9) If mono, squeeze away channel axis
        if channels == 1:
            integrated_image = integrated_image[..., 0]


        # 10) Final status
        self.update_status(f"Integration complete for group '{group_key}'.")
        QApplication.processEvents()

        return integrated_image, per_file_rejections, ref_header



    def outlier_rejection_with_mask(self, tile_stack, weights_array):
        """
        Example outlier rejection routine that computes the weighted median of the tile stack
        and returns both the integrated tile and a rejection mask.
        
        Parameters:
        tile_stack: numpy array of shape (N, H, W, C)
        weights_array: numpy array of shape (N,)
        
        Returns:
        tile_result: numpy array of shape (H, W, C)
        rejection_mask: boolean numpy array of shape (H, W) where True indicates a rejected pixel.
        
        This is a simple example. Replace this logic with your actual rejection algorithm.
        """
        # Compute the weighted median along axis 0.
        # For simplicity, we'll use the unweighted median here.
        tile_result = np.median(tile_stack, axis=0)
        
        # Compute the absolute deviation for each frame and take the median deviation.
        # Then mark as rejected any pixel in any frame that deviates by more than a threshold.
        # Here we define a threshold factor (this value may need tuning).
        threshold_factor = 1.5
        abs_deviation = np.abs(tile_stack - tile_result)
        # Compute the median deviation per pixel over the frames.
        median_deviation = np.median(abs_deviation, axis=0)
        # Define a rejection mask: True if the median deviation exceeds a threshold.
        # (For demonstration, assume threshold = threshold_factor * some constant; here we choose 0.05.)
        rejection_mask = median_deviation[..., 0] > (threshold_factor * 0.05)
        # If color, you might combine channels or process each channel separately.
        
        return tile_result, rejection_mask

class LiveStackSettingsDialog(QDialog):
    """
    Combined dialog for:
      • Live‐stack parameters (bootstrap frames, σ‐clip threshold)
      • Culling thresholds (max FWHM, max eccentricity, min star count)
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.setWindowTitle("Live Stack & Culling Settings")

        # — Live Stack Settings —
        # Bootstrap frames (int)
        self.bs_spin = CustomSpinBox(
            minimum=1,
            maximum=100,
            initial=parent.bootstrap_frames,
            step=1
        )
        self.bs_spin.valueChanged.connect(lambda v: None)

        # Sigma threshold (float)
        self.sigma_spin = CustomDoubleSpinBox(
            minimum=0.1,
            maximum=10.0,
            initial=parent.clip_threshold,
            step=0.1,
            suffix="σ"
        )
        self.sigma_spin.valueChanged.connect(lambda v: None)

        # — Culling Thresholds —
        # Max FWHM (float)
        self.fwhm_spin = CustomDoubleSpinBox(
            minimum=0.1,
            maximum=50.0,
            initial=parent.max_fwhm,
            step=0.1,
            suffix=" px"
        )
        self.fwhm_spin.valueChanged.connect(lambda v: None)

        # Max eccentricity (float)
        self.ecc_spin = CustomDoubleSpinBox(
            minimum=0.0,
            maximum=1.0,
            initial=parent.max_ecc,
            step=0.01
        )
        self.ecc_spin.valueChanged.connect(lambda v: None)

        # Min star count (int)
        self.star_spin = CustomSpinBox(
            minimum=0,
            maximum=5000,
            initial=parent.min_star_count,
            step=1
        )
        self.star_spin.valueChanged.connect(lambda v: None)

        # Build form layout
        form = QFormLayout()
        form.addRow("Switch to μ–σ clipping after:", self.bs_spin)
        form.addRow("Clip threshold:", self.sigma_spin)
        form.addRow(QLabel(""))  # blank row for separation
        form.addRow("Max FWHM (px):", self.fwhm_spin)
        form.addRow("Max Eccentricity:", self.ecc_spin)
        form.addRow("Min Star Count:", self.star_spin)

        self.mapping_combo = QComboBox()
        opts = ["Natural", "SHO", "HSO", "OSH", "SOH", "HOS", "OHS"]
        self.mapping_combo.addItems(opts)
        # preselect current
        idx = opts.index(parent.narrowband_mapping) \
              if parent.narrowband_mapping in opts else 0
        self.mapping_combo.setCurrentIndex(idx)
        form.addRow("Narrowband Mapping:", self.mapping_combo)

        # OK / Cancel buttons
        btns = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel
        )
        btns.accepted.connect(self.accept)
        btns.rejected.connect(self.reject)

        # Assemble dialog layout
        layout = QVBoxLayout()
        layout.addLayout(form)
        layout.addWidget(btns)
        self.setLayout(layout)

    def getValues(self):
        """
        Returns a tuple of five values in order:
          (bootstrap_frames, clip_threshold,
           max_fwhm, max_ecc, min_star_count)
        """
        bs      = self.bs_spin.value
        sigma   = self.sigma_spin.value()
        fwhm    = self.fwhm_spin.value()
        ecc     = self.ecc_spin.value()
        stars   = self.star_spin.value
        mapping = self.mapping_combo.currentText()
        return bs, sigma, fwhm, ecc, stars, mapping



class LiveMetricsPanel(QWidget):
    """
    A simple 2×2 grid of PyQtGraph plots to show, in real time:
      [0,0] → FWHM (px) vs. frame index
      [0,1] → Eccentricity vs. frame index
      [1,0] → Star Count vs. frame index
      [1,1] → (μ–ν)/σ (∝SNR) vs. frame index
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        titles = ["FWHM (px)", "Eccentricity", "Star Count", "(μ–ν)/σ (∝SNR)"]

        layout = QVBoxLayout(self)
        grid = pg.GraphicsLayoutWidget()
        layout.addWidget(grid)

        self.plots = []
        self.scats = []
        self._data_x = [[], [], [], []]
        self._data_y = [[], [], [], []]
        self._flags  = [[], [], [], []]  # track if each point was “bad” (True) or “good” (False)

        for row in range(2):
            for col in range(2):
                pw = grid.addPlot(row=row, col=col)
                idx = row * 2 + col
                pw.setTitle(titles[idx])
                pw.showGrid(x=True, y=True, alpha=0.3)
                pw.setLabel('bottom', "Frame #")
                pw.setLabel('left', titles[idx])

                scat = pg.ScatterPlotItem(pen=pg.mkPen(None),
                                          brush=pg.mkBrush(100, 100, 255, 200),
                                          size=6)
                pw.addItem(scat)
                self.plots.append(pw)
                self.scats.append(scat)

    def add_point(self, frame_idx: int, fwhm: float, ecc: float, star_cnt: int, snr_val: float, flagged: bool):
        """
        Append one new data point to each metric.  
        If flagged == True, draw that single point in red; else blue.  
        But keep all previously-plotted points at their original colors.
        """
        values = [fwhm, ecc, star_cnt, snr_val]
        for i in range(4):
            self._data_x[i].append(frame_idx)
            self._data_y[i].append(values[i])
            self._flags[i].append(flagged)

            # Now build a brush list for *all* points up to index i,
            # coloring each point according to its own flag.
            brushes = [
                pg.mkBrush(255, 0, 0, 200) if self._flags[i][j]
                else pg.mkBrush(100, 100, 255, 200)
                for j in range(len(self._data_x[i]))
            ]

            self.scats[i].setData(
                self._data_x[i],
                self._data_y[i],
                brush=brushes,
                pen=pg.mkPen(None),
                size=6
            )

    def clear_all(self):
        """Clear data from all four plots."""
        for i in range(4):
            self._data_x[i].clear()
            self._data_y[i].clear()
            self._flags[i].clear()
            self.scats[i].clear()

class LiveMetricsWindow(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Live Stack Metrics")
        self.resize(600, 400)

        layout = QVBoxLayout(self)
        self.metrics_panel = LiveMetricsPanel(self)
        layout.addWidget(self.metrics_panel)

def compute_frame_star_metrics(image_2d):
    """
    Runs SEP on a normalized 2D image to estimate:
      - star_count (int)
      - avg_fwhm    (float)
      - avg_ecc     (float)
    
    This replaces the DAOStarFinder version, because DAOStarFinder
    does not always produce an 'fwhm' column.  SEP will give us 'a', 'b',
    from which FWHM = 2.3548 * sqrt(a * b), and ecc = sqrt(1 - (b/a)^2).
    """
    # 1) estimate background & global RMS
    mean, median, std = sigma_clipped_stats(image_2d)
    data = image_2d - median

    try:
        # 2) run SEP extract (threshold = 5σ)
        objects = sep.extract(data, thresh=5.0, 
                              err=std, 
                              minarea=16,   # adjust if needed
                              deblend_nthresh=32,
                              clean=True)
    except Exception:
        # if SEP fails (e.g. “internal pixel buffer full”), just return zeros
        return 0, 0.0, 0.0

    if objects is None or len(objects) == 0:
        return 0, 0.0, 0.0

    # 3) star count
    star_count = len(objects)

    # 4) compute FWHM and eccentricity for each detected source
    #    SEP’s "a" and "b" columns are the RMS ellipse axes
    #    FWHM = 2.3548 * sqrt(a * b)
    a_vals = objects['a']
    b_vals = objects['b']
    # Avoid negative or zero values:
    a_vals = np.clip(a_vals, 1e-3, None)
    b_vals = np.clip(b_vals, 1e-3, None)

    fwhm_vals = 2.3548 * np.sqrt(a_vals * b_vals)
    avg_fwhm = float(np.nanmean(fwhm_vals)) if len(fwhm_vals) > 0 else 0.0

    # 5) compute eccentricity: e = sqrt(1 − (b/a)^2)
    ratios = np.clip(b_vals / a_vals, 0.0, 1.0)
    ecc_vals = np.sqrt(1.0 - ratios * ratios)
    avg_ecc = float(np.nanmean(ecc_vals)) if len(ecc_vals) > 0 else 0.0

    return star_count, avg_fwhm, avg_ecc

def estimate_global_snr(
    stack_image: np.ndarray,
    bkg_box_size: int = 200
) -> float:
    """
    “Hybrid” global SNR ≔ (μ_patch − median_patch) / σ_central,
    where:
      • μ_patch    and median_patch come from a small bkg_box_size×bkg_box_size patch
        centered inside the middle 50% of the image.
      • σ_central  is the standard deviation computed over the entire “middle 50%” region.

    Steps:
      1) Collapse to grayscale (H×W) if needed.
      2) Identify the middle 50% rectangle of the image.
      3) Within that, center a patch of size up to bkg_box_size×bkg_box_size.
      4) Compute μ_patch = mean(patch), median_patch = median(patch).
      5) Compute σ_central = std(middle50_region).
      6) If σ_central ≤ 0, return 0. Otherwise return (μ_patch − median_patch) / σ_central.
    """

    # 1) Collapse to simple 2D float array (grayscale)
    if stack_image.ndim == 3 and stack_image.shape[2] == 3:
        # RGB → grayscale by averaging channels
        gray = stack_image.mean(axis=2).astype(np.float32)
    else:
        # Already mono: just cast to float32
        gray = stack_image.astype(np.float32)

    H, W = gray.shape

    # 2) Compute coordinates of the “middle 50%” rectangle
    y0 = H // 4
    y1 = y0 + (H // 2)
    x0 = W // 4
    x1 = x0 + (W // 2)

    # Extract that central50 region as a view (no copy)
    central50 = gray[y0:y1, x0:x1]

    # 3) Within that central50, choose a patch of up to bkg_box_size×bkg_box_size, centered
    center_h = (y1 - y0)
    center_w = (x1 - x0)

    # Clamp box size so it does not exceed central50 dimensions
    box_h = min(bkg_box_size, center_h)
    box_w = min(bkg_box_size, center_w)

    # Compute top-left corner of that patch so it’s centered in central50
    cy0 = y0 + (center_h - box_h) // 2
    cx0 = x0 + (center_w - box_w) // 2

    patch = gray[cy0 : cy0 + box_h, cx0 : cx0 + box_w]

    # 4) Compute patch statistics
    mu_patch = float(np.mean(patch))
    med_patch = float(np.median(patch))
    min_patch = float(np.min(patch))

    # 5) Compute σ over the entire central50 region
    sigma_central = float(np.std(central50))
    if sigma_central <= 0.0:
        return 0.0

    nu = med_patch - 3.0 * sigma_central * med_patch

    # 6) Return (mean − nu) / σ
    return (mu_patch - nu) / sigma_central
    #return (mu_patch) / sigma_central

class LiveStackWindow(QDialog):
    """
    Live Stacking dialog:
     - Watch a directory for new frames
     - Apply dark/flat calibration
     - Debayer if needed
     - Align, stretch, and running-average stack
     - Show the live preview
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.setWindowTitle("Live Stacking")
        self.resize(900, 600)

        # ─── State Variables ─────────────────────────────────────
        self.watch_folder = None
        self.processed_files = set()
        self.master_dark = None
        self.master_flat = None
        self.master_flats  = {}

        self.filter_stacks = {}       # key → np.ndarray (float32)
        self.filter_counts = {}       # key → int
        self.filter_buffers  = {}  # key → list of bootstrap frames [H×W arrays]
        self.filter_mus      = {}  # key → µ array after bootstrap (H×W)
        self.filter_m2s      = {}  # key → M2 array after bootstrap (H×W)

        self.cull_folder = None

        self.is_running = False
        self.frame_count = 0
        self.current_stack = None

        # ── Load persisted settings ───────────────────────────────
        s = QSettings()
        self.bootstrap_frames    = s.value("LiveStack/bootstrap_frames",    24,     type=int)
        self.clip_threshold      = s.value("LiveStack/clip_threshold",      3.5,    type=float)
        self.max_fwhm            = s.value("LiveStack/max_fwhm",            15.0,   type=float)
        self.max_ecc             = s.value("LiveStack/max_ecc",             0.9,    type=float)
        self.min_star_count      = s.value("LiveStack/min_star_count",      5,      type=int)
        self.narrowband_mapping  = s.value("LiveStack/narrowband_mapping",  "Natural", type=str)
        self.star_trail_mode = s.value("LiveStack/star_trail_mode", False, type=bool)


        self.total_exposure = 0.0  # seconds
        self.exposure_label = QLabel("Total Exp: 00:00:00")
        self.exposure_label.setStyleSheet("color: #cccccc; font-weight: bold;")

        self.brightness = 0.0   # [-1.0..+1.0]
        self.contrast   = 1.0   # [0.1..3.0]


        self._buffer = []    # store up to bootstrap_frames normalized frames
        self._mu = None      # per-pixel mean (after bootstrap)
        self._m2 = None      # per-pixel sum of squares differences (for Welford)

        # ─── Create Separate Metrics Window (initially hidden) ─────
        # We do NOT embed this in the stacking dialog’s layout!
        self.metrics_window = LiveMetricsWindow(None)
        self.metrics_window.hide()

        # ─── UI ELEMENTS FOR STACKING DIALOG ───────────────────────
        # 1) Folder selection
        self.folder_label = QLabel("Folder: (none)")
        self.select_folder_btn = QPushButton("Select Folder…")
        self.select_folder_btn.clicked.connect(self.select_folder)

        # 2) Load master dark/flat
        self.load_darks_btn = QPushButton("Load Master Dark…")
        self.load_darks_btn.clicked.connect(self.load_masters)
        self.load_flats_btn = QPushButton("Load Master Flat…")
        self.load_flats_btn.clicked.connect(self.load_masters)
        self.load_filter_flats_btn = QPushButton("Load MonoFilter Flats…")
        self.load_filter_flats_btn.clicked.connect(self.load_filter_flats)        

        # 2b) Cull folder selection
        self.cull_folder_label = QLabel("Cull Folder: (none)")
        self.select_cull_btn = QPushButton("Select Cull Folder…")
        self.select_cull_btn.clicked.connect(self.select_cull_folder)

        self.dark_status_label = QLabel("Dark: ❌")
        self.flat_status_label = QLabel("Flat: ❌")
        for lbl in (self.dark_status_label, self.flat_status_label):
            lbl.setStyleSheet("color: #cccccc; font-weight: bold;")
        # 3) “Process & Monitor” / “Monitor Only” / “Stop” / “Reset”
        self.mono_color_checkbox = QCheckBox("Mono → Color Stacking")
        self.mono_color_checkbox.setToolTip(
            "When checked, bucket mono frames by FILTER and composite R, G, B, Ha, OIII, SII."
        )
        # **Connect the toggled(bool) signal** before we ever call it
        self.mono_color_checkbox.toggled.connect(self._on_mono_color_toggled)

        # ** new: Star-Trail mode checkbox **
        self.star_trail_checkbox = QCheckBox("★★ Star-Trail Mode ★★")
        self.star_trail_checkbox.setChecked(self.star_trail_mode)
        self.star_trail_checkbox.setToolTip("If checked, build a max-value trail instead of a running stack")
        self.star_trail_checkbox.toggled.connect(self._on_star_trail_toggled)

        self.process_and_monitor_btn = QPushButton("Process && Monitor")
        self.process_and_monitor_btn.clicked.connect(self.start_and_process)
        self.monitor_only_btn = QPushButton("Monitor Only")
        self.monitor_only_btn.clicked.connect(self.start_monitor_only)
        self.stop_btn = QPushButton("Stop")
        self.stop_btn.clicked.connect(self.stop_live)
        self.reset_btn = QPushButton("Reset")
        self.reset_btn.clicked.connect(self.reset_live)

        self.frame_count_label = QLabel("Frames: 0")

        # 4) Live‐stack preview area (QGraphicsView)
        self.scene = QGraphicsScene(self)
        self.view = QGraphicsView(self.scene, self)
        self.view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)
        self.view.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)
        self._did_initial_fit = False

        # 5) Zoom toolbar + Settings icon
        tb = QToolBar()

        zi = QAction(QIcon.fromTheme("zoom-in"), "Zoom In", self)
        zo = QAction(QIcon.fromTheme("zoom-out"), "Zoom Out", self)
        fit = QAction(QIcon.fromTheme("zoom-fit-best"), "Fit to Window", self)

        tb.addAction(zi)
        tb.addAction(zo)
        tb.addAction(fit)

        spacer = QWidget()
        spacer.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Preferred)
        tb.addWidget(spacer)
        # — Replace the QAction “wrench” with a styled QToolButton —
        self.wrench_button = QToolButton()
        self.wrench_button.setIcon(QIcon(wrench_path))
        self.wrench_button.setToolTip("Settings")
        # Apply your stylesheet to the QToolButton
        self.wrench_button.setStyleSheet("""
            QToolButton {
                background-color: #FF4500;
                color: white;
                font-size: 16px;
                padding: 8px;
                border-radius: 5px;
                font-weight: bold;
            }
            QToolButton:hover {
                background-color: #FF6347;
            }
        """)
        # Connect the clicked signal to open_settings()
        self.wrench_button.clicked.connect(self.open_settings)

        # Add the styled QToolButton into the toolbar
        tb.addWidget(self.wrench_button)

        zi.triggered.connect(self.zoom_in)
        zo.triggered.connect(self.zoom_out)
        fit.triggered.connect(self.fit_to_window)


        # 6) Brightness & Contrast sliders
        bright_slider = QSlider(Qt.Orientation.Horizontal)
        bright_slider.setRange(-100, 100)
        bright_slider.setValue(0)
        bright_slider.setToolTip("Brightness")
        bright_slider.valueChanged.connect(self.on_brightness_changed)

        contrast_slider = QSlider(Qt.Orientation.Horizontal)
        contrast_slider.setRange(10, 1000)
        contrast_slider.setValue(100)
        contrast_slider.setToolTip("Contrast")
        contrast_slider.valueChanged.connect(self.on_contrast_changed)

        bc_layout = QHBoxLayout()
        bc_layout.addWidget(QLabel("Brightness"))
        bc_layout.addWidget(bright_slider)
        bc_layout.addWidget(QLabel("Contrast"))
        bc_layout.addWidget(contrast_slider)

        # 7) “Send to Slot” button
        send_btn = QPushButton("Send to Slot ▶")
        send_btn.clicked.connect(self.send_to_slot)

        # 8) “Show Metrics” button
        self.show_metrics_btn = QPushButton("Show Metrics")
        self.show_metrics_btn.clicked.connect(self.show_metrics_window)

        # ─── ASSEMBLE MAIN LAYOUT (exactly one setLayout call!) ─────
        main_layout = QVBoxLayout()

        # A) Top‐row controls
        controls = QHBoxLayout()
        controls.addWidget(self.select_folder_btn)
        controls.addWidget(self.load_darks_btn)
        controls.addWidget(self.load_flats_btn)
        controls.addWidget(self.load_filter_flats_btn)
        controls.addWidget(self.select_cull_btn)
        controls.addStretch()
        controls.addWidget(self.mono_color_checkbox)
        controls.addWidget(self.star_trail_checkbox)
        controls.addWidget(self.process_and_monitor_btn)
        controls.addWidget(self.monitor_only_btn)
        controls.addWidget(self.stop_btn)
        controls.addWidget(self.reset_btn)
        main_layout.addLayout(controls)

        # B) Status line: folder label + frame count
        status_line = QHBoxLayout()
        status_line.addWidget(self.folder_label)
        status_line.addWidget(self.dark_status_label)
        status_line.addWidget(self.flat_status_label)
        status_line.addWidget(self.cull_folder_label)
        status_line.addStretch()        
        status_line.addWidget(self.frame_count_label)
        status_line.addWidget(self.exposure_label)
        main_layout.addLayout(status_line)

        # C) Zoom toolbar
        main_layout.addWidget(tb)

        # D) Show Metrics button (separate window)
        main_layout.addWidget(self.show_metrics_btn)

        # E) Live‐stack preview area
        main_layout.addWidget(self.view)

        # F) Brightness/Contrast sliders
        main_layout.addLayout(bc_layout)

        # G) “Send to Slot” + mode/idle labels
        main_layout.addWidget(send_btn)
        self.mode_label = QLabel("Mode: Linear Average")
        self.mode_label.setStyleSheet("color: #a0a0a0;")
        main_layout.addWidget(self.mode_label)
        self.status_label = QLabel("Idle")
        self.status_label.setStyleSheet("color: #a0a0a0;")
        main_layout.addWidget(self.status_label)

        # Finalize
        self.setLayout(main_layout)

        # Timer for polling new files
        self.poll_timer = QTimer(self)
        self.poll_timer.setInterval(1500)
        self.poll_timer.timeout.connect(self.check_for_new_frames)
        self._on_mono_color_toggled(self.mono_color_checkbox.isChecked())


    # ─────────────────────────────────────────────────────────────────────────
    def _on_star_trail_toggled(self, checked: bool):
        """Enable/disable star-trail mode."""
        self.star_trail_mode = checked
        QSettings().setValue("LiveStack/star_trail_mode", checked)
        self.mode_label.setText("Mode: Star-Trail" if checked else "Mode: Linear Average")
        # if you want, disable mono/color checkbox when star-trail is on:
        self.mono_color_checkbox.setEnabled(not checked)

    def _on_mono_color_toggled(self, checked: bool):
        self.mono_color_mode = checked
        self.filter_stacks.clear()
        self.filter_counts.clear()

        msg = "Enabled" if checked else "Disabled"
        self.status_label.setText(f"Mono→Color Mode {msg}")

    def show_metrics_window(self):
        """Pop up the separate metrics window (never embed it here)."""
        self.metrics_window.show()
        self.metrics_window.raise_()


    def select_cull_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cull Folder")
        if folder:
            self.cull_folder = folder
            self.cull_folder_label.setText(f"Cull: {os.path.basename(folder)}")

    def _cull_frame(self, path: str):
        """
        Move a flagged frame into the cull folder (if set), 
        or just update the status label if not.
        """
        name = os.path.basename(path)
        if self.cull_folder:
            try:
                os.makedirs(self.cull_folder, exist_ok=True)
                dst = os.path.join(self.cull_folder, name)
                shutil.move(path, dst)
                self.status_label.setText(f"⚠ Culled {name} → {self.cull_folder}")
            except Exception:
                self.status_label.setText(f"⚠ Failed to cull {name}")
        else:
            self.status_label.setText(f"⚠ Flagged (not stacked): {name}")
        QApplication.processEvents()

    def open_settings(self):
        dlg = LiveStackSettingsDialog(self)
        if dlg.exec() == QDialog.DialogCode.Accepted:
            bs, sigma, fwhm, ecc, stars, mapping = dlg.getValues()

            # 1) Persist into QSettings
            s = QSettings()
            s.setValue("LiveStack/bootstrap_frames",   bs)
            s.setValue("LiveStack/clip_threshold",     sigma)
            s.setValue("LiveStack/max_fwhm",           fwhm)
            s.setValue("LiveStack/max_ecc",            ecc)
            s.setValue("LiveStack/min_star_count",     stars)
            s.setValue("LiveStack/narrowband_mapping", mapping)

            # 2) Apply to this live‐stack session
            self.bootstrap_frames   = bs
            self.clip_threshold     = sigma
            self.max_fwhm           = fwhm
            self.max_ecc            = ecc
            self.min_star_count     = stars
            self.narrowband_mapping = mapping

            self.status_label.setText(
                f"↺ Settings saved: BS={bs}, σ={sigma:.1f}, "
                f"FWHM≤{fwhm:.1f}, ECC≤{ecc:.2f}, Stars≥{stars}, "
                f"Mapping={mapping}"
            )
            QApplication.processEvents()

    def zoom_in(self):
        self.view.scale(1.2, 1.2)

    def zoom_out(self):
        self.view.scale(1/1.2, 1/1.2)

    def fit_to_window(self):
        self.view.fitInView(self.scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)

    # — Brightness / Contrast —

    def _refresh_preview(self):
        """
        Recompute the current preview array (stack vs. composite)
        and call update_preview on it.
        """
        if self.mono_color_mode:
            # build the composite from filter_stacks
            preview = self._build_color_composite()
        else:
            # use the normal running stack
            preview = self.current_stack

        if preview is not None:
            self.update_preview(preview)

    def on_brightness_changed(self, val: int):
        self.brightness = val / 100.0  # map to [-1,1]
        self._refresh_preview()

    def on_contrast_changed(self, val: int):
        self.contrast = val / 100.0   # map to [0.1,10.0]
        self._refresh_preview()

    # — Sending out —

    def send_to_slot(self):
        # 1) Pick the image to send
        if self.mono_color_mode:
            img = self._build_color_composite()
        else:
            img = self.current_stack

        # 2) Bail if there's nothing ready
        if img is None:
            self.status_label.setText("⚠ Nothing to send")
            return

        # 3) Ask the user which slot
        mgr = self.parent.image_manager
        slots = [str(i) for i in range(mgr.max_slots)]
        current = str(mgr.current_slot)
        slot_str, ok = QInputDialog.getItem(
            self, "Select Slot", "Slot:", slots,
            current=slots.index(current),
            editable=False
        )
        if not ok:
            return
        slot_index = int(slot_str)

        # 4) Send the image (make a copy so LiveStack can keep running)
        metadata = {
            "source": "LiveStack",
            "frames_stacked": self.frame_count
        }
        mgr.set_image_for_slot(
            slot_index,
            img.copy(),
            metadata,
            step_name="Live Stack"
        )
        if hasattr(self.parent, "set_active_slot"):
            self.parent.set_active_slot(slot_index)
        else:
            mgr.set_current_slot(slot_index)

        # 5) Update status
        self.status_label.setText(f"Sent to slot {slot_index}")

    # ── New helper: map header["FILTER"] to a single letter key
    def _get_filter_key(self, header):
        """
        Map a FITS header FILTER string to one of:
        'L' (luminance),
        'R','G','B',
        'H' (H-alpha),
        'O' (OIII),
        'S' (SII),
        or return None if it doesn’t match.
        """
        raw = header.get('FILTER', '')
        fn = raw.strip().upper()
        if not fn:
            return None

        # H-alpha
        if fn in ('H', 'HA', 'HALPHA', 'H-ALPHA'):
            return 'H'
        # OIII
        if fn in ('O', 'O3', 'OIII'):
            return 'O'
        # SII
        if fn in ('S', 'S2', 'SII'):
            return 'S'
        # Red
        if fn in ('R', 'RED', 'RD'):
            return 'R'
        # Green
        if fn in ('G', 'GREEN', 'GRN'):
            return 'G'
        # Blue
        if fn in ('B', 'BLUE', 'BL'):
            return 'B'
        # Luminance
        if fn in ('L', 'LUM', 'LUMI', 'LUMINANCE'):
            return 'L'

        return None

    # ── New helper: stack a single mono frame under filter key
    def _stack_mono_channel(self, key, img, delta=None):
        # img: 2D or 3D array; we convert to 2D mono always
        mono = img if img.ndim==2 else np.mean(img,axis=2)
        # align if you need (use same logic as color branch)
        if hasattr(self, 'reference_image_2d'):
            d = delta or StarRegistrationWorker.compute_affine_transform_astroalign(
                        mono, self.reference_image_2d)
            if d is not None:
                mono = StarRegistrationThread.apply_affine_transform_static(mono, d)
        # normalize
        norm = stretch_mono_image(mono, target_median=0.3)
        # first frame?
        if key not in self.filter_stacks:
            self.filter_stacks[key] = norm.copy()
            self.filter_counts[key] = 1
            # set reference on first good channel frame
            if not hasattr(self, 'reference_image_2d'):
                self.reference_image_2d = norm.copy()
        else:
            cnt = self.filter_counts[key]
            self.filter_stacks[key] = (cnt/self.filter_counts[key]+1)*self.filter_stacks[key] \
                                      + (1.0/(cnt+1))*norm
            self.filter_counts[key] += 1

    # ── New helper: build an RGB preview from whatever channels we have
    def _build_color_composite(self):
        """
        Composite filters into an RGB preview according to self.narrowband_mapping:

        • "Natural":
            – If SII present:
                R = 0.5*(Ha + SII)
                G = 0.5*(SII + OIII)
                B = OIII
            – Elif any R/G/B loaded:
                R = R_filter
                G = G_filter + OIII
                B = B_filter + OIII
            – Else (no SII, no R/G/B):
                R = Ha
                G = OIII
                B = OIII

        • Any 3-letter code (e.g. "SHO", "OHS"):
            R = filter_stacks[mapping[0]]
            G = filter_stacks[mapping[1]]
            B = filter_stacks[mapping[2]]

        Missing channels default to zero.
        """
        # 1) Determine H, W
        if self.filter_stacks:
            first = next(iter(self.filter_stacks.values()))
            H, W = first.shape
        elif getattr(self, 'current_stack', None) is not None:
            H, W = self.current_stack.shape[:2]
        else:
            return None

        # helper: get stack or zeros
        def getf(k):
            return self.filter_stacks.get(k, np.zeros((H, W), np.float32))

        mode = self.narrowband_mapping.upper()
        if mode == "NATURAL":
            Ha = getf('H')
            O3 = getf('O')
            S2 = self.filter_stacks.get('S', None)
            Rf = self.filter_stacks.get('R', None)
            Gf = self.filter_stacks.get('G', None)
            Bf = self.filter_stacks.get('B', None)

            if S2 is not None:
                # narrowband SII branch
                R = 0.5 * (Ha + S2)
                G = 0.5 * (S2 + O3)
                B = O3.copy()

            elif any(x is not None for x in (Rf, Gf, Bf)):
                # broadband branch: Rf/Gf/Bf with OIII boost
                R = Rf if Rf is not None else np.zeros((H, W), np.float32)
                G = (Gf if Gf is not None else np.zeros((H, W), np.float32)) + O3
                B = (Bf if Bf is not None else np.zeros((H, W), np.float32)) + O3

            else:
                # fallback HOO
                R = Ha
                G = O3
                B = O3

        else:
            # direct mapping: e.g. "SHO" → R=S, G=H, B=O
            letters = list(mode)
            if len(letters) != 3 or any(l not in ("S","H","O") for l in letters):
                # invalid code → fallback to natural
                return self._build_color_composite.__wrapped__(self)

            R = getf(letters[0])
            G = getf(letters[1])
            B = getf(letters[2])

        return np.stack([R, G, B], axis=2)


    def select_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Folder to Watch")
        if folder:
            self.watch_folder = folder
            self.folder_label.setText(f"Folder: {os.path.basename(folder)}")

    def load_masters(self):
        """
        When the user picks “Load Master Dark…” or “Load Master Flat…”, we load exactly one file
        (the first in the dialog).  We simply store it in `self.master_dark` or `self.master_flat`,
        but we also check its dimensions against any existing master so that the user can’t load
        a 2D flat while the dark is 3D (for example).
        """
        sender = self.sender()
        dlg = QFileDialog(self, "Select Master Files",
                         filter="FITS TIFF or XISF (*.fit *.fits *.tif *.tiff *.xisf)")
        dlg.setFileMode(QFileDialog.FileMode.ExistingFiles)
        if not dlg.exec():
            return

        chosen = dlg.selectedFiles()[0]
        img, hdr, bit_depth, is_mono = load_image(chosen)
        if img is None:
            QMessageBox.warning(self, "Load Error",
                                f"Failed to load master file:\n{chosen}")
            return

        # Convert everything to float32 for consistency
        img = img.astype(np.float32)

        if "Dark" in sender.text():
            # If a flat is already loaded, ensure shape‐compatibility
            if self.master_flat is not None:
                if not self._shapes_compatible(master=img, other=self.master_flat):
                    QMessageBox.warning(
                        self, "Shape Mismatch",
                        "Cannot load this master dark: it has incompatible shape "
                        "vs. the already‐loaded master flat."
                    )
                    return

            self.master_dark = img
            self.dark_status_label.setText("Dark: ✅")
            self.dark_status_label.setStyleSheet("color: #00cc66; font-weight: bold;")            
            QMessageBox.information(
                self, "Master Dark Loaded",
                f"Loaded master dark:\n{os.path.basename(chosen)}"
            )
        else:
            # "Flat" was clicked
            if self.master_dark is not None:
                if not self._shapes_compatible(master=self.master_dark, other=img):
                    QMessageBox.warning(
                        self, "Shape Mismatch",
                        "Cannot load this master flat: it has incompatible shape "
                        "vs. the already‐loaded master dark."
                    )
                    return

            self.master_flat = img
            self.flat_status_label.setText("Flat: ✅")
            self.flat_status_label.setStyleSheet("color: #00cc66; font-weight: bold;")            
            QMessageBox.information(
                self, "Master Flat Loaded",
                f"Loaded master flat:\n{os.path.basename(chosen)}"
            )

    def load_filter_flats(self):
        """
        Let the user pick one or more flat files.
        We try to read the FITS header FILTER key to decide which filter
        each flat belongs to; otherwise fall back to the filename.
        """
        dlg = QFileDialog(self, "Select Filter Flats",
                          filter="FITS or TIFF (*.fit *.fits *.tif *.tiff)")
        dlg.setFileMode(QFileDialog.FileMode.ExistingFiles)
        if not dlg.exec():
            return

        files = dlg.selectedFiles()
        loaded = []
        for path in files:
            img, hdr, bit_depth, is_mono = load_image(path)
            if img is None:
                continue
            # guess filter key from header, else from filename
            key = None
            if hdr and hdr.get("FILTER"):
                key = self._get_filter_key(hdr)
            if not key:
                # fallback: basename before extension
                key = os.path.splitext(os.path.basename(path))[0]

            # store it
            self.master_flats[key] = img.astype(np.float32)
            loaded.append(key)

        # update the flat status label to list loaded filters
        if loaded:
            names = ", ".join(loaded)
            self.flat_status_label.setText(f"Flats: {names}")
            self.flat_status_label.setStyleSheet("color: #00cc66; font-weight: bold;")
            QMessageBox.information(
                self, "Filter Flats Loaded",
                f"Loaded flats for filters: {names}"
            )
        else:
            QMessageBox.warning(self, "No Flats Loaded",
                                "No flats could be loaded.")

    def _shapes_compatible(self, master: np.ndarray, other: np.ndarray) -> bool:
        """
        Return True if `master` and `other` can be used together in calibration:
          - Exactly the same shape, OR
          - master is 2D (H×W) and other is 3D (H×W×3), OR
          - vice versa.
        """
        if master.shape == other.shape:
            return True

        # If one is 2D and the other is H×W×3, check the first two dims
        if master.ndim == 2 and other.ndim == 3 and other.shape[:2] == master.shape:
            return True
        if other.ndim == 2 and master.ndim == 3 and master.shape[:2] == other.shape:
            return True

        return False

    def _average_images(self, paths):
        # stub: load each via load_image(), convert to float32, accumulate & divide
        return None

    def _normalized_average(self, paths):
        # stub: load each, divide by its mean, average them, then renormalize
        return None

    def start_and_process(self):
        """Process everything currently in folder, then begin monitoring."""
        if not self.watch_folder:
            self.status_label.setText("❗ No folder selected")
            return
        # Clear any old record so existing files are re-processed
        self.processed_files.clear()
        # Process all current files once
        self.check_for_new_frames()
        # Now start monitoring
        self.is_running = True
        self.poll_timer.start()
        self.status_label.setText(f"▶ Processing & Monitoring: {os.path.basename(self.watch_folder)}")

    def start_monitor_only(self):
        """Mark existing files as seen and only process new arrivals."""
        if not self.watch_folder:
            self.status_label.setText("❗ No folder selected")
            return
        # Populate processed_files with all existing files so they won't be re-processed
        exts = (
            "*.fit", "*.fits", "*.tif", "*.tiff",
            "*.cr2", "*.cr3", "*.nef", "*.arw",
            "*.dng", "*.orf", "*.rw2", "*.pef", "*.xisf", "*.png", "*.jpg", "*.jpeg"
        )
        all_paths = []
        for ext in exts:
            all_paths += glob.glob(os.path.join(self.watch_folder, ext))
        self.processed_files = set(all_paths)

        # Start monitoring
        self.is_running = True
        self.poll_timer.start()
        self.status_label.setText(f"▶ Monitoring Only: {os.path.basename(self.watch_folder)}")

    def start_live(self):
        if not self.watch_folder:
            self.status_label.setText("❗ No folder selected")
            return
        self.is_running = True
        self.poll_timer.start()
        self.status_label.setText(f"▶ Monitoring: {os.path.basename(self.watch_folder)}")
        self.mode_label.setText("Mode: Linear Average")

    def stop_live(self):
        if self.is_running:
            self.is_running = False
            self.poll_timer.stop()
            self.status_label.setText("■ Stopped")
        else:
            self.status_label.setText("■ Already stopped")

    def reset_live(self):
        if self.is_running:
            self.is_running = False
            self.poll_timer.stop()
            self.status_label.setText("■ Stopped")
        else:
            self.status_label.setText("■ Already stopped")

        # Clear all state
        self.processed_files.clear()
        self.frame_count = 0
        self.current_stack = None

        self.total_exposure = 0.0
        self.exposure_label.setText("Total Exp: 00:00:00")

        self.filter_stacks.clear()
        self.filter_counts.clear()
        self.filter_buffers.clear()
        self.filter_mus.clear()
        self.filter_m2s.clear()

        if hasattr(self, 'reference_image_2d'):
            del self.reference_image_2d

        # Re-initialize bootstrapping stats
        self._buffer = []
        self._mu = None
        self._m2 = None

        # NEW: clear the metrics panel
        self.metrics_window.metrics_panel.clear_all()

        # Update labels
        self.frame_count_label.setText("Frames: 0")
        self.status_label.setText("↺ Reset")
        self.mode_label.setText("Mode: Linear Average")

        # Clear the displayed image
        self.pixmap_item.setPixmap(QPixmap())

        # Reset zoom/pan fit flag
        self._did_initial_fit = False
        #self.master_dark = None
        #self.master_flat = None
        #self.dark_status_label.setText("Dark: ❌")
        #self.flat_status_label.setText("Flat: ❌")
        #self.dark_status_label.setStyleSheet("color: #cccccc; font-weight: bold;")
        #self.flat_status_label.setStyleSheet("color: #cccccc; font-weight: bold;")        




    def check_for_new_frames(self):
        if not self.is_running or not self.watch_folder:
            return

        # build the list of files with supported extensions
        exts = (
            "*.fit", "*.fits", "*.tif", "*.tiff",
            "*.cr2", "*.cr3", "*.nef", "*.arw",
            "*.dng", "*.orf", "*.rw2", "*.pef", "*.xisf",
            "*.png", "*.jpg", "*.jpeg"
        )
        all_paths = []
        for ext in exts:
            all_paths += glob.glob(os.path.join(self.watch_folder, ext))

        # only pick the ones we haven’t seen yet
        new = [p for p in sorted(all_paths) if p not in self.processed_files]
        if not new:
            return

        # update status
        first = os.path.basename(new[0])
        self.status_label.setText(f"➜ New frame: {first}")

        for path in new:
            self.processed_files.add(path)
            self.process_frame(path)

    def process_frame(self, path):
        # if star-trail mode is on, bypass the normal pipeline entirely:
        if self.star_trail_mode:
            return self._process_star_trail(path)
                
        # 1) Load
        # ─── 1) RAW‐file check ────────────────────────────────────────────
        lower = path.lower()
        raw_exts = ('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')
        if lower.endswith(raw_exts):
            # Attempt to decode using rawpy
            try:
                with rawpy.imread(path) as raw:
                    # Postprocess into an 8‐bit RGB array
                    # (you could tweak postprocess params if desired)
                    img_rgb8 = raw.postprocess(
                        use_camera_wb=True,
                        no_auto_bright=True,
                        output_bps=16
                    )  # shape (H, W, 3), dtype=uint8

                # Convert to float32 [0..1] so it matches load_image() behavior
                img = img_rgb8.astype(np.float32) / 65535.0

                # Build a minimal FITS header and attempt to extract EXIF tags
                header = fits.Header()
                header["SIMPLE"] = True
                header["BITPIX"] = 16
                header["CREATOR"] = "LiveStack(RAW)"
                header["IMAGETYP"] = "RAW"
                # Default EXPTIME/ISO/DATE-OBS in case EXIF fails
                header["EXPTIME"] = "Unknown"
                header["ISO"]     = "Unknown"
                header["DATE-OBS"] = "Unknown"

                try:
                    with open(path, 'rb') as f:
                        tags = exifread.process_file(f, details=False)
                    # EXIF: ExposureTime
                    exp_tag = tags.get("EXIF ExposureTime") or tags.get("EXIF ShutterSpeedValue")
                    if exp_tag:
                        exp_str = str(exp_tag.values)
                        if '/' in exp_str:
                            top, bot = exp_str.split('/', 1)
                            header["EXPTIME"] = (float(top)/float(bot), "Exposure Time (s)")
                        else:
                            header["EXPTIME"] = (float(exp_str), "Exposure Time (s)")
                    # ISO
                    iso_tag = tags.get("EXIF ISOSpeedRatings")
                    if iso_tag:
                        header["ISO"] = str(iso_tag.values)
                    # Date/time original
                    date_obs = tags.get("EXIF DateTimeOriginal")
                    if date_obs:
                        header["DATE-OBS"] = str(date_obs.values)
                except Exception:
                    # If EXIF parsing fails, just leave defaults
                    pass

                bit_depth = 16
                is_mono = False

            except Exception as e:
                # If rawpy fails, bail out early
                self.status_label.setText(f"⚠ Failed to decode RAW: {os.path.basename(path)}")
                QApplication.processEvents()
                return

        else:
            # ─── 2) Not RAW → call your existing load_image()
            img, header, bit_depth, is_mono = load_image(path)
            if img is None:
                self.status_label.setText(f"⚠ Failed to load {os.path.basename(path)}")
                QApplication.processEvents()
                return

        # ——— 2) CALIBRATION (once) ————————————————————————
        # ——— 2a) DETECT MONO→COLOR MODE ————————————————————
        mono_key = None
        if self.mono_color_mode and is_mono and header.get('FILTER') and 'BAYERPAT' not in header:
            mono_key = self._get_filter_key(header)

        # ——— 2b) CALIBRATION (once) ————————————————————————
        if self.master_dark is not None:
            img = img.astype(np.float32) - self.master_dark
        # prefer per-filter flat if we’re in mono→color and have one
        if mono_key and mono_key in self.master_flats:
            img = apply_flat_division_numba(img, self.master_flats[mono_key])
        elif self.master_flat is not None:
            img = apply_flat_division_numba(img, self.master_flat)

        # ——— 3) DEBAYER if BAYERPAT ——————————————————————
        if is_mono and header.get('BAYERPAT'):
            pat = header['BAYERPAT'][0] if isinstance(header['BAYERPAT'], tuple) else header['BAYERPAT']
            img = debayer_fits_fast(img, pat)
            is_mono = False

        # ——— 5) PROMOTION TO 3-CHANNEL if NOT in mono-mode —————
        if mono_key is None and img.ndim == 2:
            img = np.stack([img, img, img], axis=2)

        # ——— 6) BUILD PLANE for alignment & metrics —————————
        plane = img if (mono_key and img.ndim == 2) else np.mean(img, axis=2)

        # ——— 7) ALIGN to reference_image_2d ——————————————————
        if hasattr(self, 'reference_image_2d'):
            delta = StarRegistrationWorker.compute_affine_transform_astroalign(
                plane, self.reference_image_2d
            )
            if delta is None:
                delta = IDENTITY_2x3
            # apply to full img (if color) and to plane
            if mono_key is None:
                img = StarRegistrationThread.apply_affine_transform_static(img, delta)
            plane = StarRegistrationThread.apply_affine_transform_static(
                plane if plane.ndim == 2 else plane[:, :, None], delta
            ).squeeze()

        # ——— 8) NORMALIZE —————————————————————————————
        if mono_key:
            norm_plane = stretch_mono_image(plane, target_median=0.3)
            norm_color = None
        else:
            norm_color = stretch_color_image(img, target_median=0.3, linked=False)
            norm_plane = np.mean(norm_color, axis=2)

        # ——— 9) METRICS & SNR —————————————————————————
        sc, fwhm, ecc = compute_frame_star_metrics(norm_plane)
        # instead, use the cumulative stack (or composite) for SNR:
        if mono_key:
            # once we have any filter_stacks, build the composite;
            # fall back to this frame’s plane if it’s the first one
            if self.filter_stacks:
                stack_img = self._build_color_composite()
            else:
                stack_img = norm_plane
        else:
            # for color‐only, use the running‐average stack once it exists,
            # else fall back to this frame’s normalized color
            if self.current_stack is not None:
                stack_img = self.current_stack
            else:
                stack_img = norm_color
        snr_val = estimate_global_snr(stack_img)

        # ——— 10) CULLING? ————————————————————————————
        flagged = (
            (fwhm > self.max_fwhm) or
            (ecc > self.max_ecc)     or
            (sc < self.min_star_count)
        )
        if flagged:
            self._cull_frame(path)
            self.metrics_window.metrics_panel.add_point(
                self.frame_count + 1, fwhm, ecc, sc, snr_val, True
            )
            return

        # ─── 11) FIRST-FRAME INITIALIZATION ──────────────────────────────
        if self.frame_count == 0:
            # set reference on the very first good frame
            self.reference_image_2d = norm_plane.copy()
            self.frame_count = 1
            self.frame_count_label.setText("Frames: 1")
            # always start in linear‐average mode
            if mono_key:
                self.mode_label.setText(f"Mode: Linear Average ({mono_key})")
                self.status_label.setText(f"Started {mono_key}-filter linear stack")
            else:
                self.mode_label.setText("Mode: Linear Average")
                self.status_label.setText("Started linear stack")
            QApplication.processEvents()

            if mono_key:
                # start the filter stack
                self.filter_stacks[mono_key]  = norm_plane.copy()
                self.filter_counts[mono_key]  = 1
                self.filter_buffers[mono_key] = [norm_plane.copy()]
            else:
                # start the normal running stack
                self.current_stack = norm_color.copy()
                self._buffer = [norm_color.copy()]
            # ─── accumulate exposure ─────────────────────
            exp_val = header.get("EXPOSURE", header.get("EXPTIME", None))
            if exp_val is not None:
                try:
                    secs = float(exp_val)
                    self.total_exposure += secs
                    hrs  = int(self.total_exposure // 3600)
                    mins = int((self.total_exposure % 3600) // 60)
                    secs_rem = int(self.total_exposure % 60)
                    self.exposure_label.setText(
                        f"Total Exp: {hrs:02d}:{mins:02d}:{secs_rem:02d}"
                    )
                except:
                    pass
            QApplication.processEvents()


        else:
            # ─── 12) RUNNING–AVERAGE or CLIP-σ UPDATE ────────────────────
            if mono_key is None:
                # — Color-only stacking —
                if self.frame_count < self.bootstrap_frames:
                    # 12a) Linear bootstrap
                    n = self.frame_count + 1
                    self.current_stack = (
                        (self.frame_count / n) * self.current_stack
                        + (1.0 / n) * norm_color
                    )
                    self._buffer.append(norm_color.copy())

                    # hit the bootstrap threshold?
                    if n == self.bootstrap_frames:
                        # init Welford stats
                        buf = np.stack(self._buffer, axis=0)
                        self._mu = np.mean(buf, axis=0)
                        diffs = buf - self._mu[np.newaxis, ...]
                        self._m2 = np.sum(diffs * diffs, axis=0)
                        self._buffer = None

                        # switch to clipping mode
                        self.mode_label.setText("Mode: μ-σ Clipping Average")
                        self.status_label.setText("Switched to μ–σ clipping (color)")
                        QApplication.processEvents()
                    else:
                        # still linear
                        self.mode_label.setText("Mode: Linear Average")
                        self.status_label.setText(f"Processed color frame #{n} (linear)")
                        QApplication.processEvents()
                else:
                    # 12b) μ–σ clipping
                    sigma = np.sqrt(self._m2 / (self.frame_count - 1))
                    mask = np.abs(norm_color - self._mu) <= (self.clip_threshold * sigma)
                    clipped = np.where(mask, norm_color, self._mu)

                    n = self.frame_count + 1
                    self.current_stack = (
                        (self.frame_count / n) * self.current_stack
                        + (1.0 / n) * clipped
                    )

                    # Welford update
                    delta_mu = clipped - self._mu
                    self._mu += delta_mu / n
                    delta2 = clipped - self._mu
                    self._m2 += delta_mu * delta2

                    # stay in clipping mode
                    self.mode_label.setText("Mode: μ-σ Clipping Average")
                    self.status_label.setText(f"Processed color frame #{n} (clipped)")
                    QApplication.processEvents()

                # bump global frame count
                self.frame_count = n
                # ─── accumulate exposure ─────────────────────
                exp_val = header.get("EXPOSURE", header.get("EXPTIME", None))
                if exp_val is not None:
                    try:
                        secs = float(exp_val)
                        self.total_exposure += secs
                        hrs  = int(self.total_exposure // 3600)
                        mins = int((self.total_exposure % 3600) // 60)
                        secs_rem = int(self.total_exposure % 60)
                        self.exposure_label.setText(
                            f"Total Exp: {hrs:02d}:{mins:02d}:{secs_rem:02d}"
                        )
                    except:
                        pass
                QApplication.processEvents()


            else:
                # — Mono→color (per-filter) stacking —
                count = self.filter_counts.get(mono_key, 0)
                buf   = self.filter_buffers.setdefault(mono_key, [])

                if count < self.bootstrap_frames:
                    # 12c) Linear bootstrap per-filter
                    new_count = count + 1
                    if count == 0:
                        self.filter_stacks[mono_key] = norm_plane.copy()
                    else:
                        self.filter_stacks[mono_key] = (
                            (count / new_count) * self.filter_stacks[mono_key]
                            + (1.0 / new_count) * norm_plane
                        )
                    buf.append(norm_plane.copy())
                    self.filter_counts[mono_key] = new_count

                    if new_count == self.bootstrap_frames:
                        # init Welford
                        stacked = np.stack(buf, axis=0)
                        mu    = np.mean(stacked, axis=0)
                        diffs = stacked - mu[np.newaxis, ...]
                        m2    = np.sum(diffs * diffs, axis=0)
                        self.filter_mus[mono_key] = mu
                        self.filter_m2s[mono_key] = m2

                        self.mode_label.setText(f"Mode: μ-σ Clipping Average ({mono_key})")
                        self.status_label.setText(f"Switched to μ–σ clipping ({mono_key})")
                        QApplication.processEvents()
                    else:
                        # still linear
                        self.mode_label.setText(f"Mode: Linear Average ({mono_key})")
                        self.status_label.setText(
                            f"Processed {mono_key}-filter frame #{new_count} (linear)"
                        )
                        QApplication.processEvents()

                else:
                    # 12d) μ–σ clipping per-filter
                    mu = self.filter_mus[mono_key]
                    m2 = self.filter_m2s[mono_key]
                    sigma = np.sqrt(m2 / (count - 1))
                    mask   = np.abs(norm_plane - mu) <= (self.clip_threshold * sigma)
                    clipped = np.where(mask, norm_plane, mu)

                    new_count = count + 1
                    self.filter_stacks[mono_key] = (
                        (count / new_count) * self.filter_stacks[mono_key]
                        + (1.0 / new_count) * clipped
                    )

                    # Welford update on µ and m2
                    delta   = clipped - mu
                    new_mu  = mu + delta / new_count
                    delta2  = clipped - new_mu
                    new_m2  = m2 + delta * delta2
                    self.filter_mus[mono_key] = new_mu
                    self.filter_m2s[mono_key] = new_m2
                    self.filter_counts[mono_key] = new_count

                    self.mode_label.setText(f"Mode: μ-σ Clipping Average ({mono_key})")
                    self.status_label.setText(
                        f"Processed {mono_key}-filter frame #{new_count} (clipped)"
                    )
                    QApplication.processEvents()

                # bump global frame count
                self.frame_count += 1
                self.frame_count_label.setText(f"Frames: {self.frame_count}")
                # ─── accumulate exposure ─────────────────────
                exp_val = header.get("EXPOSURE", header.get("EXPTIME", None))
                if exp_val is not None:
                    try:
                        secs = float(exp_val)
                        self.total_exposure += secs
                        hrs  = int(self.total_exposure // 3600)
                        mins = int((self.total_exposure % 3600) // 60)
                        secs_rem = int(self.total_exposure % 60)
                        self.exposure_label.setText(
                            f"Total Exp: {hrs:02d}:{mins:02d}:{secs_rem:02d}"
                        )
                    except:
                        pass
                QApplication.processEvents()

            # ─── 13) Update UI ─────────────────────────────────────────
            self.frame_count_label.setText(f"Frames: {self.frame_count}")
            QApplication.processEvents()

        # ——— 13) METRICS PANEL for good frame —————————————
        self.metrics_window.metrics_panel.add_point(
            self.frame_count, fwhm, ecc, sc, snr_val, False
        )

        # ——— 14) PREVIEW & STATUS LABEL —————————————————————
        if mono_key:
            preview = self._build_color_composite()
            self.status_label.setText(f"Stacked {mono_key}-filter frame {os.path.basename(path)}")
            QApplication.processEvents()
        else:
            preview = self.current_stack
            self.status_label.setText(f"✔ processed {os.path.basename(path)}")
            QApplication.processEvents()

        self.update_preview(preview)
        QApplication.processEvents()

    def _process_star_trail(self, path: str):
        """
        Load/calibrate a single frame (RAW or FITS/TIFF), debayer if needed,
        normalize, then build a max‐value “star trail” in self.current_stack.
        """
        # ─── 1) Load (RAW vs FITS) ─────────────────────────────
        lower = path.lower()
        raw_exts = ('.cr2', '.cr3', '.nef', '.arw', '.dng',
                    '.orf', '.rw2', '.pef')
        if lower.endswith(raw_exts):
            try:
                with rawpy.imread(path) as raw:
                    img_rgb8 = raw.postprocess(use_camera_wb=True,
                                               no_auto_bright=True,
                                               output_bps=16)
                img = img_rgb8.astype(np.float32) / 65535.0
                header = fits.Header()
                header["SIMPLE"]   = True
                header["BITPIX"]   = 16
                header["CREATOR"]  = "LiveStack(RAW)"
                header["IMAGETYP"] = "RAW"
                header["EXPTIME"]  = "Unknown"
                # attempt EXIF, same as process_frame…
                try:
                    with open(path,'rb') as f:
                        tags = exifread.process_file(f, details=False)
                    exp_tag = tags.get("EXIF ExposureTime") \
                              or tags.get("EXIF ShutterSpeedValue")
                    if exp_tag:
                        ev = str(exp_tag.values)
                        if '/' in ev:
                            n,d = ev.split('/',1)
                            header["EXPTIME"] = (float(n)/float(d),
                                                 "Exposure Time (s)")
                        else:
                            header["EXPTIME"] = (float(ev),
                                                 "Exposure Time (s)")
                except:
                    pass
                bit_depth = 16
                is_mono   = False
            except Exception:
                self.status_label.setText(
                    f"⚠ Failed to decode RAW: {os.path.basename(path)}"
                )
                QApplication.processEvents()
                return
        else:
            # FITS / TIFF / XISF
            img, header, bit_depth, is_mono = load_image(path)
            if img is None:
                self.status_label.setText(
                    f"⚠ Failed to load {os.path.basename(path)}"
                )
                QApplication.processEvents()
                return

        # ─── 2) Calibration ─────────────────────────────────────
        mono_key = None
        if (self.mono_color_mode
            and is_mono
            and header.get('FILTER')
            and 'BAYERPAT' not in header):
            mono_key = self._get_filter_key(header)

        if self.master_dark is not None:
            img = img.astype(np.float32) - self.master_dark

        if mono_key and mono_key in self.master_flats:
            img = apply_flat_division_numba(img,
                                            self.master_flats[mono_key])
        elif self.master_flat is not None:
            img = apply_flat_division_numba(img,
                                            self.master_flat)

        # ─── 3) Debayer ─────────────────────────────────────────
        if is_mono and header.get('BAYERPAT'):
            pat = (header['BAYERPAT'][0]
                   if isinstance(header['BAYERPAT'], tuple)
                   else header['BAYERPAT'])
            img = debayer_fits_fast(img, pat)
            is_mono = False

        # ─── 4) Force 3-channel if still mono ───────────────────
        if not mono_key and img.ndim == 2:
            img = np.stack([img, img, img], axis=2)

        # ─── 5) Normalize ───────────────────────────────────────
        # for star-trail we want a visible, stretched version:
        if img.ndim == 2:
            plane = stretch_mono_image(img, target_median=0.3)
            norm_color = np.stack([plane]*3, axis=2)
        else:
            norm_color = stretch_color_image(img,
                                             target_median=0.3,
                                             linked=False)

        # ─── 6) Build max-value stack ───────────────────────────
        if self.frame_count == 0:
            self.current_stack = norm_color.copy()
        else:
            # elementwise max over all frames so far
            self.current_stack = np.maximum(self.current_stack,
                                            norm_color)

        # ─── 7) Update counters and labels ──────────────────────
        self.frame_count += 1
        self.frame_count_label.setText(f"Frames: {self.frame_count}")

        exp_val = header.get("EXPOSURE", header.get("EXPTIME", None))
        if exp_val is not None:
            try:
                secs = float(exp_val)
                self.total_exposure += secs
                h = int(self.total_exposure // 3600)
                m = int((self.total_exposure % 3600)//60)
                s = int(self.total_exposure % 60)
                self.exposure_label.setText(
                    f"Total Exp: {h:02d}:{m:02d}:{s:02d}")
            except:
                pass

        self.status_label.setText(
            f"★ Star-Trail frame {self.frame_count}: "
            f"{os.path.basename(path)}"
        )
        self.update_preview(self.current_stack)
        QApplication.processEvents()



    def update_preview(self, array: np.ndarray):
        """
        Apply brightness/contrast, convert to QImage, and display in QGraphicsView
        without resetting zoom/pan after the first fit.
        """
        # 1) normalize array [0..1] → adjust contrast & brightness
        arr = np.clip(array, 0.0, 1.0).astype(np.float32)
        pivot = 0.3
        arr = ((arr - pivot) * self.contrast + pivot) + self.brightness
        arr = np.clip(arr, 0.0, 1.0)

        # 2) convert to uint8
        arr8 = (arr * 255).astype(np.uint8)
        h, w = arr8.shape[:2]

        # 3) build QImage
        if arr8.ndim == 2:
            fmt = QImage.Format.Format_Grayscale8
            bytespp = w
        else:
            fmt = QImage.Format.Format_RGB888
            bytespp = 3 * w
        qimg = QImage(arr8.data, w, h, bytespp, fmt)

        # 4) update the existing pixmap item
        pix = QPixmap.fromImage(qimg)
        self.pixmap_item.setPixmap(pix)

        # 5) update scene rectangle so scrollbars know the new size
        self.scene.setSceneRect(0, 0, w, h)

        # 6) initial fit only once
        if not self._did_initial_fit:
            self.view.fitInView(self.scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
            self._did_initial_fit = True

def load_fits_tile(filepath, y_start, y_end, x_start, x_end):
    """
    Loads a sub-region from a FITS file, detecting which axes are spatial vs. color.
    
    * If the data is 2D, it might be (height, width) or (width, height).
    * If the data is 3D, it might be:
        - (height, width, 3)
        - (3, height, width)
        - (width, height, 3)
        - (3, width, height)
      We only slice the two spatial dimensions; the color axis remains intact.
    
    The returned tile will always have the shape:
      - (tile_height, tile_width) for mono
      - (tile_height, tile_width, 3) for color
    (though the color dimension may still be first if it was first in the file).
    It's up to the caller to reorder if needed.
    """
    with fits.open(filepath, memmap=False) as hdul:
        data = hdul[0].data
        if data is None:
            return None

        # Save the original data type for normalization later.
        orig_dtype = data.dtype

        shape = data.shape
        ndim = data.ndim

        if ndim == 2:
            # Data is 2D; shape could be (height, width) or (width, height)
            dim0, dim1 = shape
            if (y_end <= dim0) and (x_end <= dim1):
                tile_data = data[y_start:y_end, x_start:x_end]
            else:
                tile_data = data[x_start:x_end, y_start:y_end]
        elif ndim == 3:
            # Data is 3D; could be (height, width, 3) or (3, height, width), etc.
            dim0, dim1, dim2 = shape

            def do_slice_spatial(data3d, spat0, spat1, color_axis):
                slicer = [slice(None)] * 3
                slicer[spat0] = slice(y_start, y_end)
                slicer[spat1] = slice(x_start, x_end)
                tile = data3d[tuple(slicer)]
                return tile

            # Identify the color axis (assumed to have size 3)
            color_axis = None
            spat_axes = []
            for idx, d in enumerate((dim0, dim1, dim2)):
                if d == 3:
                    color_axis = idx
                else:
                    spat_axes.append(idx)

            if color_axis is None:
                # No axis with size 3; assume the image is mono and use the first two dims.
                tile_data = data[y_start:y_end, x_start:x_end]
            else:
                # Ensure we have two spatial axes.
                if len(spat_axes) != 2:
                    spat_axes = [0, 1]
                spat0, spat1 = spat_axes
                d0 = shape[spat0]
                d1 = shape[spat1]
                if (y_end <= d0) and (x_end <= d1):
                    tile_data = do_slice_spatial(data, spat0, spat1, color_axis)
                else:
                    tile_data = do_slice_spatial(data, spat1, spat0, color_axis)
        else:
            return None

        # Normalize based on the original data type.
        if orig_dtype == np.uint8:
            tile_data = tile_data.astype(np.float32) / 255.0
        elif orig_dtype == np.uint16:
            tile_data = tile_data.astype(np.float32) / 65535.0
        elif orig_dtype == np.uint32:
            # 32-bit data: convert to float32 but leave values as is.
            tile_data = tile_data.astype(np.float32)
        elif orig_dtype == np.float32:
            # Already 32-bit float; assume it's in the desired range.
            tile_data = tile_data
        else:
            tile_data = tile_data.astype(np.float32)

    return tile_data



# --------------------------------------------------
# MosaicMasterDialog with blending/normalization integrated
# --------------------------------------------------
def get_wcs_from_header(header):
    """Attempt to create a WCS from a FITS header."""
    if not header:
        return None
    try:
        # First, try normally:
        wcs = WCS(header)
        if wcs.is_celestial:
            return wcs
        # If not celestial and header has more than 2 axes, force naxis=2.
        if header.get('NAXIS', 0) > 2:
            wcs = WCS(header, naxis=2)
            if wcs.is_celestial:
                return wcs
        return None
    except Exception:
        return None
    
def robust_api_request(method, url, data=None, files=None, prompt_on_failure=False):
    """
    Sends an API request without automatic retries. If the request fails (network error or invalid JSON response),
    prompts the user if they want to start completely over. If the user chooses to try again,
    the function calls itself recursively.
    """
    try:
        if method == "GET":
            response = requests.get(url, timeout=600)
        elif method == "POST":
            response = requests.post(url, data=data, files=files, timeout=600)
        else:
            raise ValueError("Unsupported request method: " + method)

        response.raise_for_status()  # Raise HTTP errors (e.g., 500, 404)

        try:
            return response.json()  # Attempt to parse JSON
        except json.JSONDecodeError:
            error_message = f"Invalid JSON response from {url}."
            print(error_message)
            if prompt_on_failure:
                user_choice = QMessageBox.question(
                    None,
                    "Invalid Response",
                    f"{error_message}\nDo you want to start over?",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
                )
                if user_choice == QMessageBox.StandardButton.Yes:
                    return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
                else:
                    return None
            else:
                return None

    except requests.exceptions.RequestException as e:
        error_message = f"Network error when contacting {url}: {e}."
        print(error_message)
        if prompt_on_failure:
            user_choice = QMessageBox.question(
                None,
                "Network Error",
                f"{error_message}\nDo you want to start over?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if user_choice == QMessageBox.StandardButton.Yes:
                return robust_api_request(method, url, data, files, prompt_on_failure=prompt_on_failure)
            else:
                return None
        else:
            return None


def scale_image_for_display(image):
    """
    Scales a floating point image (0-1) to 8-bit (0-255) for display.
    """
    if np.max(image) == np.min(image):
        return np.zeros_like(image, dtype=np.uint8)  # Prevent division by zero
    scaled = (255 * (image - np.min(image)) / (np.max(image) - np.min(image))).astype(np.uint8)
    return scaled

def generate_minimal_fits_header(image):
    header = Header()
    header['SIMPLE'] = True
    # Set BITPIX according to the image’s data type.
    if np.issubdtype(image.dtype, np.integer):
        header['BITPIX'] = 16  # For 16-bit integer data.
    elif np.issubdtype(image.dtype, np.floating):
        header['BITPIX'] = -32  # For 32-bit float data.
    else:
        raise ValueError("Unsupported image data type for FITS header generation.")
    header['NAXIS'] = 2
    header['NAXIS1'] = image.shape[1]  # width
    header['NAXIS2'] = image.shape[0]  # height
    header['COMMENT'] = "Minimal header generated for blind solve"
    return header


class MosaicPreviewWindow(QDialog):
    def __init__(self, image_array, title="", parent=None):
        super().__init__(parent)
        self.setWindowTitle(title if title else "Preview")

        # Keep the original array around for re-stretch or reset
        self.original_array = image_array.copy()
        # Current displayed array (8-bit or whatever you want)
        self.image_array = image_array.copy()

        # Zoom state
        self.zoom_factor = 1.0

        # Variables for panning (dragging)
        self.dragging = False
        self.last_mouse_pos = QPoint()
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # 1) QScrollArea to enable scrollbars for large images
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # 2) Label inside the scroll area
        self.preview_label = QLabel("No image yet.")
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)
        self.scroll_area.viewport().installEventFilter(self)

        # 3) Auto-Stretch Toggle
        self.stretch_toggle = QCheckBox("Auto-Stretch for Display")
        self.stretch_toggle.setChecked(True)
        self.stretch_toggle.stateChanged.connect(self.update_display)
        layout.addWidget(self.stretch_toggle)

        # 4) Button row (Zoom, Fit, etc.)
        button_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        self.fit_button = QPushButton("Fit to Preview")
        self.fit_button.clicked.connect(self.fit_to_preview)
        button_layout.addWidget(self.fit_button)

        self.autostretch_button = QPushButton("Reapply Stretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        button_layout.addWidget(self.autostretch_button)

        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.close)
        button_layout.addWidget(close_btn)

        layout.addLayout(button_layout)

        self.setLayout(layout)
        # Finally, display the initial image
        self.display_image(self.image_array)

    def display_image(self, arr):
        """
        Convert array to QPixmap and display in preview_label.
        We'll respect self.zoom_factor to scale the pixmap.
        """
        if arr is None or arr.size == 0:
            print("WARNING: Trying to display an empty image.")
            return

        # Possibly apply auto-stretch
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr)
        else:
            # If it's already 8-bit or float, just convert to 8-bit safely
            arr_display = self.to_8bit(arr)
        
        # Convert single-channel => 3 channels if needed
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        # Make QImage => QPixmap
        h, w, c = arr_3ch.shape
        bytes_per_line = w * c
        qimg = QImage(arr_3ch.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(qimg)

        # Apply zoom factor
        new_w = int(w * self.zoom_factor)
        new_h = int(h * self.zoom_factor)
        if new_w < 1: new_w = 1
        if new_h < 1: new_h = 1

        scaled_pixmap = pixmap.scaled(
            new_w, new_h,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # Set the label to the scaled pixmap
        self.preview_label.setPixmap(scaled_pixmap)
        # Important: set the label size so the scroll area can scroll if it's bigger
        self.preview_label.resize(scaled_pixmap.size())

    def stretch_for_display(self, arr):
        """
        Applies an auto-stretch to improve visualization:
          1) Compute 0.5 and 99.5 percentiles
          2) Rescale to [0..255]
        """
        arr = arr.astype(np.float32, copy=False)
        mn, mx = np.percentile(arr, (0.5, 99.5))
        if mx > mn:
            arr = (arr - mn) / (mx - mn)
        else:
            arr = np.zeros_like(arr)
        arr = (arr * 255).clip(0, 255).astype(np.uint8)
        return arr

    def eventFilter(self, source, event):
        """
        Capture mouse events on the scroll_area.viewport():
          - Left-button press => start dragging
          - Mouse move => if dragging, pan
          - Left-button release => stop dragging
          - Wheel => zoom in/out
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = True
                    self.last_mouse_pos = event.pos()
                    return True  # We handled it
            elif event.type() == QEvent.Type.MouseMove:
                if self.dragging:
                    # Compute how far we moved
                    delta = event.pos() - self.last_mouse_pos
                    self.last_mouse_pos = event.pos()

                    # Adjust scrollbars
                    h_bar = self.scroll_area.horizontalScrollBar()
                    v_bar = self.scroll_area.verticalScrollBar()
                    h_bar.setValue(h_bar.value() - delta.x())
                    v_bar.setValue(v_bar.value() - delta.y())

                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.dragging = False
                    return True
            elif event.type() == QEvent.Type.Wheel:
                # Zoom in or out
                if event.angleDelta().y() > 0:
                    self.zoom_in()
                else:
                    self.zoom_out()
                event.accept()
                return True
        return super().eventFilter(source, event)

    def to_8bit(self, arr):
        """
        Simple fallback if not using auto-stretch:
        - If float in [0..1], multiply by 255
        - If already 8-bit, do nothing
        """
        if arr.dtype == np.uint8:
            return arr
        # else assume float [0..1]
        return (arr*255).clip(0,255).astype(np.uint8)

    def update_display(self):
        """
        Called when toggling the stretch checkbox. Re-display the image.
        """
        self.display_image(self.image_array)

    def autostretch_image(self):
        """
        Auto-stretch the original image and update preview.
        If the image has multiple channels, we do the same approach as stretch_for_display
        but typically you'd do something more advanced for color.
        """
        arr = self.original_array.copy()
        # e.g., if color, you might do a channel-by-channel approach
        # For simplicity, let's do a grayscale approach using the mean:
        if arr.ndim == 3:
            # we create a single channel for stretch
            g = np.mean(arr, axis=-1)
            arr_stretched = self.stretch_for_display(g)
            # Then broadcast back to 3 channels
            arr_stretched = np.stack([arr_stretched]*3, axis=-1)
        else:
            arr_stretched = self.stretch_for_display(arr)
        self.image_array = arr_stretched
        self.display_image(self.image_array)

    # ---------------------
    # ZOOM Methods
    # ---------------------
    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.display_image(self.image_array)

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        if self.zoom_factor < 0.05:
            self.zoom_factor = 0.05
        self.display_image(self.image_array)

    def fit_to_preview(self):
        """
        Scale the image so it fits inside the scroll_area's viewport.
        We'll measure the image's actual size, compare to the viewport,
        and adjust zoom_factor accordingly.
        """
        if self.image_array is None or self.image_array.size == 0:
            return

        # We'll figure out the image's *unzoomed* dimensions
        arr_display = self.image_array
        if self.stretch_toggle.isChecked():
            arr_display = self.stretch_for_display(arr_display)
        else:
            arr_display = self.to_8bit(arr_display)

        # Convert single-channel => 3 channels if needed, to find w,h
        if arr_display.ndim == 2:
            arr_3ch = np.stack([arr_display]*3, axis=-1)
        elif arr_display.ndim == 3 and arr_display.shape[2] == 1:
            arr_3ch = np.concatenate([arr_display, arr_display, arr_display], axis=2)
        else:
            arr_3ch = arr_display

        h, w, c = arr_3ch.shape

        # The scroll area viewport size
        viewport_size = self.scroll_area.viewport().size()
        vw, vh = viewport_size.width(), viewport_size.height()

        # Compute the scale factor to fit image inside viewport
        scale_w = vw / w if w else 1.0
        scale_h = vh / h if h else 1.0
        new_zoom = min(scale_w, scale_h)
        if new_zoom <= 0:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.display_image(self.image_array)

    def resizeEvent(self, event):
        """
        Refresh displayed pixmap when window is resized,
        only if we want the displayed image to keep fitting automatically.
        But typically, we won't auto-fit on window resize if user is controlling zoom.
        """
        super().resizeEvent(event)
        # Optionally do:
        # self.fit_to_preview()
        # or if you want to keep the user-chosen zoom, just re-display:
        self.display_image(self.image_array)

class MosaicSettingsDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Mosaic Master Settings")
        self.initUI()

    def initUI(self):
        layout = QFormLayout(self)

        # Number of Stars to Attempt to Use
        self.starCountSpin = CustomSpinBox(minimum=1, maximum=1000,
                                        initial=self.settings.value("mosaic/num_stars", 150, type=int),
                                        step=1)
        layout.addRow("Number of Stars:", self.starCountSpin)

        # Translation Max Tolerance
        self.transTolSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/translation_max_tolerance", 3.0, type=float),
                                                step=0.1)
        layout.addRow("Translation Max Tolerance:", self.transTolSpin)

        # Scale Min Tolerance
        self.scaleMinSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_min_tolerance", 0.8, type=float),
                                                step=0.1)
        layout.addRow("Scale Min Tolerance:", self.scaleMinSpin)

        # Scale Max Tolerance
        self.scaleMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                                initial=self.settings.value("mosaic/scale_max_tolerance", 1.25, type=float),
                                                step=0.1)
        layout.addRow("Scale Max Tolerance:", self.scaleMaxSpin)

        # Rotation Max Tolerance
        self.rotationMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=180.0,
                                                initial=self.settings.value("mosaic/rotation_max_tolerance", 45.0, type=float),
                                                step=0.1)
        # Force two decimals in display
        self.rotationMaxSpin.lineEdit.setText(f"{self.rotationMaxSpin.value():.2f}")
        layout.addRow("Rotation Max Tolerance (°):", self.rotationMaxSpin)

        # Skew Max Tolerance
        self.skewMaxSpin = CustomDoubleSpinBox(minimum=0.0, maximum=1.0,
                                            initial=self.settings.value("mosaic/skew_max_tolerance", 0.1, type=float),
                                            step=0.01)
        layout.addRow("Skew Max Tolerance:", self.skewMaxSpin)

        # FWHM for Star Detection
        self.fwhmSpin = CustomDoubleSpinBox(minimum=0.0, maximum=20.0,
                                            initial=self.settings.value("mosaic/star_fwhm", 3.0, type=float),
                                            step=0.1)
        self.fwhmSpin.lineEdit.setText(f"{self.fwhmSpin.value():.2f}")
        layout.addRow("FWHM for Star Detection:", self.fwhmSpin)

        # Sigma for Star Detection
        self.sigmaSpin = CustomDoubleSpinBox(minimum=0.0, maximum=10.0,
                                            initial=self.settings.value("mosaic/star_sigma", 3.0, type=float),
                                            step=0.1)
        self.sigmaSpin.lineEdit.setText(f"{self.sigmaSpin.value():.2f}")
        layout.addRow("Sigma for Star Detection:", self.sigmaSpin)

        # Polynomial Degree
        self.polyDegreeSpin = CustomSpinBox(minimum=1, maximum=6,
                                            initial=self.settings.value("mosaic/poly_degree", 3, type=int),
                                            step=1)
        layout.addRow("Polynomial Degree:", self.polyDegreeSpin)

        buttons = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel,
            parent=self
        )
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addRow(buttons)

    def accept(self):
        # Save the values to QSettings
        self.settings.setValue("mosaic/num_stars", self.starCountSpin.value)
        self.settings.setValue("mosaic/translation_max_tolerance", self.transTolSpin.value())
        self.settings.setValue("mosaic/scale_min_tolerance", self.scaleMinSpin.value())
        self.settings.setValue("mosaic/scale_max_tolerance", self.scaleMaxSpin.value())
        self.settings.setValue("mosaic/rotation_max_tolerance", self.rotationMaxSpin.value())
        self.settings.setValue("mosaic/skew_max_tolerance", self.skewMaxSpin.value())
        self.settings.setValue("mosaic/star_fwhm", self.fwhmSpin.value())
        self.settings.setValue("mosaic/star_sigma", self.sigmaSpin.value())
        self.settings.setValue("mosaic/poly_degree", self.polyDegreeSpin.value)
        super().accept()


class MosaicMasterDialog(QDialog):
    def __init__(self, settings: QSettings, parent=None, image_manager=None):
        super().__init__(parent)
        self.settings = settings
        self.image_manager = image_manager
        self.setWindowTitle("Mosaic Master")
        self.resize(600, 400)
        self.loaded_images = []  
        self.final_mosaic = None
        self.weight_mosaic = None
        self.wcs_metadata = None  # To store mosaic WCS header
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        # Variables to store stretching parameters:
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        instructions = QLabel(
            "Mosaic Master:\n"
            "1) Add images - Highly Recommend Images be Linear FITS\n"
            "2) Choose Transformation Type:\n"
            "....Partial Affine - Great for Images with Translation, Rotation, and Scaling Needs\n"
            "....Affine - Great for Images that also have skew distortions\n"
            "....Homography - Great for Images that also have lens or perspective distortion\n"
            "....Polynomial Warp - Useful in large mosaics to bend the images together\n"
            "3) Align & Create Mosaic\n"
            "4) Save to Image Manager"
        )
        instructions.setWordWrap(True)
        layout.addWidget(instructions)

        btn_layout = QHBoxLayout()
        # Button to add image from disk
        add_btn = QPushButton("Add Image")
        add_btn.clicked.connect(self.add_image)
        btn_layout.addWidget(add_btn)

        # New button to add an image from one of the ImageManager slots
        add_from_slot_btn = QPushButton("Add from Slot")
        add_from_slot_btn.clicked.connect(self.add_image_from_slot)
        btn_layout.addWidget(add_from_slot_btn)

        remove_btn = QPushButton("Remove Selected")
        remove_btn.clicked.connect(self.remove_selected)
        btn_layout.addWidget(remove_btn)

        preview_btn = QPushButton("Preview Selected")
        preview_btn.clicked.connect(self.preview_selected)
        btn_layout.addWidget(preview_btn)

        align_btn = QPushButton("Align and Create Mosaic")
        align_btn.clicked.connect(self.align_images)
        btn_layout.addWidget(align_btn)

        save_btn = QPushButton("Save to Image Manager")
        save_btn.clicked.connect(self.create_mosaic)
        btn_layout.addWidget(save_btn)

        layout.addLayout(btn_layout)

        # Add the wrench button for settings.
        wrench_btn = QPushButton()
        wrench_btn.setIcon(QIcon(wrench_path))
        wrench_btn.setToolTip("Mosaic Settings")
        wrench_btn.clicked.connect(self.openSettings)
        btn_layout.addWidget(wrench_btn)

        layout.addLayout(btn_layout)

        # Horizontal sizer for checkboxes.
        checkbox_layout = QHBoxLayout()
        self.forceBlindCheckBox = QCheckBox("Force Blind Solve (ignore existing WCS)")
        checkbox_layout.addWidget(self.forceBlindCheckBox)
        # New Seestar Mode checkbox:
        self.seestarCheckBox = QCheckBox("Seestar Mode")
        self.seestarCheckBox.setToolTip("When enabled, images are aligned iteratively using astroalign without plate solving.")
        checkbox_layout.addWidget(self.seestarCheckBox)
        layout.addLayout(checkbox_layout)

        self.transform_combo = QComboBox()
        self.transform_combo.addItems([
            "Partial Affine Transform",
            "Affine Transform",
            "Homography Transform",
            "Polynomial Warp Based Transform"
        ])
        # Set the default selection to "Affine Transform" (index 1)
        self.transform_combo.setCurrentIndex(1)
        layout.addWidget(QLabel("Select Transformation Method:"))
        layout.addWidget(self.transform_combo)

        self.images_list = QListWidget()
        self.images_list.setSelectionMode(self.images_list.SelectionMode.SingleSelection)
        layout.addWidget(self.images_list)

        self.status_label = QLabel("Status: no images")
        layout.addWidget(self.status_label)

        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide() 
        layout.addWidget(self.spinnerLabel)

        self.setLayout(layout)

    def openSettings(self):
        dlg = MosaicSettingsDialog(self.settings, self)
        if dlg.exec():
            self.status_label.setText("Mosaic settings updated.")

    # ---------- Add / Remove ----------
    def add_image(self):
        paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Add Image(s)",
            "",
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.fz *.fz *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if paths:
            for path in paths:
                arr, header, bitdepth, ismono = load_image(path)
                wcs_obj = get_wcs_from_header(header) if header else None
                d = {
                    "path": path,
                    "image": arr,
                    "header": header,
                    "wcs": wcs_obj,
                    "bit_depth": bitdepth,
                    "is_mono": ismono,
                    "transform": None
                }
                self.loaded_images.append(d)

                text = os.path.basename(path)
                if wcs_obj is not None:
                    text += " [WCS]"
                item = QListWidgetItem(text)
                item.setToolTip(path)
                self.images_list.addItem(item)
            self.update_status()


    # ---------- New Method: Add Image From a Slot ----------
    def add_image_from_slot(self):
        """
        Allow the user to add an image from one of the ImageManager’s slots.
        The dropdown will list only slots that contain an image, showing the renamed name
        (if available via metadata['display_name']), or else falling back to the file basename.
        """
        available_slots = []
        # Iterate through all slots managed by ImageManager
        for slot, img in self.image_manager._images.items():
            if img is not None:
                metadata = self.image_manager._metadata[slot]
                # Use a renamed name if available, otherwise use the file path basename or a default
                display_name = metadata.get("display_name")
                if not display_name:
                    file_path = metadata.get("file_path")
                    display_name = os.path.basename(file_path) if file_path else f"Slot {slot}"
                available_slots.append((slot, display_name))
        
        if not available_slots:
            QMessageBox.information(self, "Add Image", "No images available in slots.")
            return

        # Create a list of strings for the dropdown, e.g., "Slot 0: MyRenamedImage"
        items = [f"Slot {slot}: {name}" for slot, name in available_slots]

        # Let the user choose from the available slots
        item, ok = QInputDialog.getItem(self, "Select Image", "Select an image from slots:", items, 0, False)
        if not ok or not item:
            return

        # Parse the selected slot number. We assume the string format "Slot X: <name>"
        selected_slot = int(item.split(":")[0].split()[1])
        metadata = self.image_manager._metadata[selected_slot]
        image = self.image_manager._images[selected_slot]
        wcs_obj = get_wcs_from_header(metadata.get("original_header", None)) if metadata.get("original_header") else None

        # Create a dictionary similar to that used for loaded images
        d = {
            "path": metadata.get("file_path", f"Slot {selected_slot} image"),
            "image": image,
            "header": metadata.get("original_header"),
            "wcs": wcs_obj,
            "bit_depth": metadata.get("bit_depth"),
            "is_mono": metadata.get("is_mono", False),
            "transform": None
        }
        self.loaded_images.append(d)

        # Determine the text to display. Use the renamed name if available.
        text = metadata.get("display_name")
        if not text:
            file_path = metadata.get("file_path")
            text = os.path.basename(file_path) if file_path else f"Slot {selected_slot} image"
        if wcs_obj is not None:
            text += " [WCS]"
        list_item = QListWidgetItem(text)
        list_item.setToolTip(metadata.get("file_path", ""))
        self.images_list.addItem(list_item)
        self.update_status()

    def remove_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Remove", "No item selected.")
            return
        for itm in s:
            row = self.images_list.row(itm)
            self.images_list.takeItem(row)
            p = itm.toolTip()
            self.loaded_images = [x for x in self.loaded_images if x["path"] != p]
        self.update_status()

    def update_status(self):
        c = len(self.loaded_images)
        self.status_label.setText(f"{c} images loaded.")

    # ---------- Preview ----------
    def preview_selected(self):
        s = self.images_list.selectedItems()
        if not s:
            QMessageBox.information(self, "Preview", "No item selected.")
            return
        path = s[0].toolTip()
        for d in self.loaded_images:
            if d["path"] == path:
                preview_image = d["image"]
                if np.all(preview_image == 0):
                    print(f"WARNING: Preview for {path} is completely black!")
                print(f"Previewing {path}, shape={preview_image.shape}, max={np.max(preview_image)}")
                win = MosaicPreviewWindow(preview_image, title=f"Preview - {os.path.basename(path)}", parent=self)
                win.show()
                break

    # ---------- Align (Entry Point) ----------
    def align_images(self):
        if self.seestarCheckBox.isChecked():
            self.align_images_seestar_mode()
        else:
            if len(self.loaded_images) == 0:
                QMessageBox.warning(self, "Align", "No images to align.")
                return

            # Show spinner and start animation.
            self.spinnerLabel.show()
            self.spinnerMovie.start()
            QApplication.processEvents()

            # Step 1: Force blind solve if requested.
            force_blind = self.forceBlindCheckBox.isChecked()
            images_to_process = (self.loaded_images if force_blind 
                                else [item for item in self.loaded_images if item.get("wcs") is None])

            # Process each image for plate solving.
            for item in images_to_process:
                # Check if ASTAP is set.
                if not self.astap_exe or not os.path.exists(self.astap_exe):
                    executable_filter = "Executables (*.exe);;All Files (*)" if sys.platform.startswith("win") else "Executables (astap);;All Files (*)"
                    new_path, _ = QFileDialog.getOpenFileName(self, "Select ASTAP Executable", "", executable_filter)
                    if new_path:
                        self.astap_exe = new_path
                        self.settings.setValue("astap/exe_path", self.astap_exe)
                        QMessageBox.information(self, "Mosaic Master", "ASTAP path updated successfully.")
                    else:
                        QMessageBox.warning(self, "Mosaic Master", "ASTAP path not provided. Falling back to blind solve.")
                        solved_header = self.perform_blind_solve(item)
                        if solved_header:
                            item["wcs"] = WCS(solved_header)
                        continue  # Move to next image

                # Attempt ASTAP solve.
                self.status_label.setText(f"Attempting ASTAP solve for {item['path']}...")
                QApplication.processEvents()
                solved_header = self.attempt_astap_solve(item)

                if solved_header is None:
                    self.status_label.setText(f"ASTAP failed for {item['path']}. Falling back to blind solve...")
                    QApplication.processEvents()
                    solved_header = self.perform_blind_solve(item)
                else:
                    self.status_label.setText(f"Plate solve successful using ASTAP for {item['path']}.")

                if solved_header:
                    # Remove unnecessary 3D-related keywords.
                    for k in list(solved_header.keys()):
                        if (k.startswith("NAXIS3") or k.startswith("CTYPE3") or k.startswith("CUNIT3") or
                            k.startswith("CRVAL3") or k.startswith("CRPIX3") or k.startswith("CDELT3") or
                            k.startswith("CD3_") or k.startswith("PC3_") or k.startswith("PC_3")):
                            del solved_header[k]
                    for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]:
                        if key in solved_header:
                            try:
                                solved_header[key] = int(solved_header[key])
                            except ValueError:
                                print(f"Warning: {key} value '{solved_header[key]}' could not be converted to int.")
                                del solved_header[key]   
                    # Fix for malformed SIP distortion headers
                    # Fix for malformed SIP distortion headers
                    sip_keys = ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
                    sip_orders = {}

                    # Parse and coerce to int
                    for k in sip_keys:
                        if k in solved_header:
                            try:
                                sip_orders[k] = int(solved_header[k])
                            except Exception:
                                print(f"Warning: SIP keyword {k} has invalid value {solved_header[k]}, removing.")
                                del solved_header[k]

                    # Patch missing A/B or AP/BP if needed
                    if "A_ORDER" in sip_orders and "B_ORDER" not in sip_orders:
                        solved_header["B_ORDER"] = sip_orders["A_ORDER"]
                        print("Patched B_ORDER to match A_ORDER:", sip_orders["A_ORDER"])
                    elif "B_ORDER" in sip_orders and "A_ORDER" not in sip_orders:
                        solved_header["A_ORDER"] = sip_orders["B_ORDER"]
                        print("Patched A_ORDER to match B_ORDER:", sip_orders["B_ORDER"])

                    if "AP_ORDER" in sip_orders and "BP_ORDER" not in sip_orders:
                        solved_header["BP_ORDER"] = sip_orders["AP_ORDER"]
                        print("Patched BP_ORDER to match AP_ORDER:", sip_orders["AP_ORDER"])
                    elif "BP_ORDER" in sip_orders and "AP_ORDER" not in sip_orders:
                        solved_header["AP_ORDER"] = sip_orders["BP_ORDER"]
                        print("Patched AP_ORDER to match BP_ORDER:", sip_orders["BP_ORDER"])


                    # Force SIP orders to be int if still present
                    for key in sip_keys:
                        if key in solved_header:
                            try:
                                solved_header[key] = int(solved_header[key])
                            except ValueError:
                                print(f"Warning: {key} = {solved_header[key]} could not be converted to int. Removing.")
                                del solved_header[key]                                                         
                    # Ensure mandatory WCS keys are present.
                    solved_header.setdefault("CTYPE1", "RA---TAN")
                    solved_header.setdefault("CTYPE2", "DEC--TAN")
                    solved_header.setdefault("RADECSYS", "ICRS")
                    solved_header.setdefault("WCSAXES", 2)
                    item["wcs"] = WCS(solved_header)
                else:
                    print(f"Plate solving failed for {item['path']}.")

            # After processing, get all images with valid WCS.
            wcs_items = [x for x in self.loaded_images if x.get("wcs") is not None]
            if not wcs_items:
                print("No images have WCS, skipping WCS alignment.")
                self.spinnerMovie.stop()
                self.spinnerLabel.hide()
                return

            # Use the first image's WCS as reference and compute the mosaic bounding box.
            reference_wcs = wcs_items[0]["wcs"].deepcopy()
            min_x, min_y, max_x, max_y = self.compute_mosaic_bounding_box(wcs_items, reference_wcs)
            mosaic_width = int(max_x - min_x)
            mosaic_height = int(max_y - min_y)

            if mosaic_width < 1 or mosaic_height < 1:
                print("ERROR: Computed mosaic size is invalid. Check WCS or inputs.")
                return

            # Adjust the reference WCS so that (min_x, min_y) becomes (0,0).
            mosaic_wcs = reference_wcs.deepcopy()
            mosaic_wcs.wcs.crpix[0] -= min_x
            mosaic_wcs.wcs.crpix[1] -= min_y
            self.wcs_metadata = mosaic_wcs.to_header()

            # Set up accumulators.
            is_color = any(not item["is_mono"] for item in wcs_items)
            if is_color:
                self.final_mosaic = np.zeros((mosaic_height, mosaic_width, 3), dtype=np.float32)
            else:
                self.final_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)
            self.weight_mosaic = np.zeros((mosaic_height, mosaic_width), dtype=np.float32)

            first_image = True
            for idx, itm in enumerate(wcs_items):
                arr = itm["image"]
                self.status_label.setText(f"Projecting {itm['path']} onto the celestial sphere...")
                QApplication.processEvents()

                # Pre-stretch the image.
                stretched_arr = self.stretch_image(arr)
                # Use the first channel for alignment.
                if not itm["is_mono"]:
                    red_stretched = stretched_arr[..., 0]
                else:
                    red_stretched = stretched_arr[..., 0] if stretched_arr.ndim == 3 else stretched_arr

                # Reproject the image.
                if not itm["is_mono"]:
                    channels = []
                    for c in range(3):
                        channel = stretched_arr[..., c]
                        reproj, _ = reproject_interp((channel, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                        reproj = np.nan_to_num(reproj, nan=0.0).astype(np.float32)
                        channels.append(reproj)
                    reprojected = np.stack(channels, axis=-1)
                    reproj_red = reprojected[..., 0]
                else:
                    reproj_red, _ = reproject_interp((red_stretched, itm["wcs"]), mosaic_wcs, shape_out=(mosaic_height, mosaic_width))
                    reproj_red = np.nan_to_num(reproj_red, nan=0.0).astype(np.float32)
                    reprojected = np.stack([reproj_red, reproj_red, reproj_red], axis=-1)

                self.status_label.setText(f"WCS Reproject: {itm['path']} processed.")
                QApplication.processEvents()

                # --- Stellar Alignment ---
                num_stars = self.settings.value("mosaic/num_stars", 150, type=int)
                if not first_image:
                    transform_method = self.transform_combo.currentText()
                    # Use the current mosaic as reference.
                    mosaic_gray = (self.final_mosaic if self.final_mosaic.ndim == 2 
                                else np.mean(self.final_mosaic, axis=-1))
                    print("Mosaic gray shape:", mosaic_gray.shape)
                        
                    self.status_label.setText("Detecting stars in overlap region...")
                    QApplication.processEvents()
                        
                    overlap_mask = (mosaic_gray > 0) & (reproj_red > 0)
                        
                    # (Optional: You can still detect stars if needed, but here we opt to use astroalign directly.)
                    try:
                        # reproj_red is already a grayscale version from the reprojected image.
                        reproj_gray = reproj_red  
                        self.status_label.setText("Computing affine transform with astroalign...")
                        QApplication.processEvents()
                            
                        # Use astroalign to find a transform that maps reproj_gray (target) to mosaic_gray (reference).
                        transform_obj, (src_pts, dst_pts) = astroalign.find_transform(reproj_gray, mosaic_gray)
                        # Extract a 2x3 affine matrix and ensure its type.
                        transform_matrix = transform_obj.params[0:2, :].astype(np.float32)
                        self.status_label.setText("Astroalign computed transform successfully.")
                    except Exception as e:
                        self.status_label.setText(f"Astroalign failed: {e}. Using identity transform.")
                        transform_matrix = np.eye(2, 3, dtype=np.float32)
                        
                    print("Computed affine transform matrix:\n", transform_matrix)
                    # Compute the effective scales.
                    A = transform_matrix[:, :2]
                    scale1 = np.linalg.norm(A[:, 0])
                    scale2 = np.linalg.norm(A[:, 1])
                    print("Computed scales: {:.6f}, {:.6f}".format(scale1, scale2))
                                            
                    self.status_label.setText("Affine alignment computed. Warping image...")
                    QApplication.processEvents()
                    # Warp the reprojected image with the computed 2x3 transform.
                    affine_aligned = cv2.warpAffine(reprojected, transform_matrix, (mosaic_width, mosaic_height), flags=cv2.INTER_LANCZOS4)
                    print("Affine aligned image shape:", affine_aligned.shape)
                    print("Affine aligned image mean:", np.mean(affine_aligned))
                    aligned = affine_aligned

                    # If a refined method is selected, further refine the alignment.
                    if transform_method in ["Homography Transform", "Polynomial Warp Based Transform"]:
                        self.status_label.setText(f"Starting refined alignment using {transform_method}...")
                        print("Refined alignment using method:", transform_method)
                        QApplication.processEvents()                    
                        refined_result = self.refined_alignment(affine_aligned, mosaic_gray, method=transform_method)
                        if refined_result is not None:
                            aligned, best_inliers2 = refined_result
                            self.status_label.setText(f"Refined alignment succeeded with {best_inliers2} inliers.")
                            print("Refined alignment inliers:", best_inliers2)
                        else:
                            self.status_label.setText("Refined alignment failed; falling back to affine alignment.")
                            print("Refined alignment failed; using affine alignment.")
                            aligned = affine_aligned
                    else:
                        aligned = affine_aligned

                    gray_aligned = aligned[..., 0] if aligned.ndim == 3 else aligned
                    print("Final aligned image shape:", aligned.shape)
                else:
                    # For the first image, use the reprojected image as is.
                    aligned = reprojected
                    gray_aligned = (np.mean(aligned, axis=-1) if not itm["is_mono"] else aligned[..., 0])
                    first_image = False

                # Compute weight mask from the grayscale aligned image.
                binary_mask = (gray_aligned > 0).astype(np.uint8)
                smooth_mask = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 5)
                if np.max(smooth_mask) > 0:
                    smooth_mask = smooth_mask / np.max(smooth_mask)
                else:
                    smooth_mask = binary_mask.astype(np.float32)
                smooth_mask = cv2.GaussianBlur(smooth_mask, (15, 15), 0)

                # Accumulate the aligned image.
                if is_color:
                    self.final_mosaic += aligned * smooth_mask[..., np.newaxis]
                else:
                    self.final_mosaic += aligned[..., 0] * smooth_mask
                self.weight_mosaic += smooth_mask

                self.status_label.setText(f"Processed: {itm['path']}")
                QApplication.processEvents()

            # Final blending.
            nonzero_mask = (self.weight_mosaic > 0)
            if is_color:
                self.final_mosaic = np.where(self.weight_mosaic[..., None] > 0,
                                            self.final_mosaic / self.weight_mosaic[..., None],
                                            self.final_mosaic)
            else:
                self.final_mosaic[nonzero_mask] = self.final_mosaic[nonzero_mask] / self.weight_mosaic[nonzero_mask]

            print("WCS + Star Alignment Complete.")
            self.status_label.setText("WCS + Star Alignment Complete. De-Normalizing Mosaic...")
            self.final_mosaic = self.unstretch_image(self.final_mosaic)
            self.status_label.setText("Final Mosaic Ready.")
            QApplication.processEvents()

            if self.final_mosaic.ndim == 2:
                display_image = np.stack([self.final_mosaic] * 3, axis=-1)
            else:
                display_image = self.stretch_for_display(self.final_mosaic)
            mosaic_win = MosaicPreviewWindow(display_image, title="Incremental Mosaic", parent=self)
            mosaic_win.show()

            self.spinnerMovie.stop()
            self.spinnerLabel.hide()
            QApplication.processEvents()
            pass        

    def debayer_image(self, image, file_path, header):
        if file_path.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            print(f"Debayering RAW image: {file_path}")
            return debayer_raw_fast(image)
        elif file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
            bayer_pattern = header.get('BAYERPAT')
            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                return debayer_fits_fast(image, bayer_pattern)
        return image

    def refine_via_overlap(self, new_gray, mosaic_gray, rough_matrix):
        """
        1) Warp new_gray into mosaic coords using rough_matrix.
        2) Compute overlap region by checking where both warped_new_gray and mosaic_gray > 0.
        3) Restrict astroalign.find_transform() to that overlap only.
        4) Combine the refinement transform with rough_matrix so you have a single final 2×3 matrix
        mapping the original new_gray -> mosaic_gray coordinates.

        Returns the final 2×3 transform matrix for cv2.warpAffine, or None if no overlap or alignment fails.
        """

        # ------------------------------------------
        # A) Warp new_gray with rough_matrix
        # ------------------------------------------
        h_m, w_m = mosaic_gray.shape
        warped_new_gray = cv2.warpAffine(
            new_gray,
            rough_matrix,
            (w_m, h_m),   # (width, height)
            flags=cv2.INTER_LANCZOS4
        )

        # ------------------------------------------
        # B) Determine overlap region (both > 0)
        # ------------------------------------------
        mask_warped = (warped_new_gray > 0)
        mask_mosaic = (mosaic_gray > 0)
        overlap_mask = mask_warped & mask_mosaic

        overlap_pixels = np.count_nonzero(overlap_mask)
        print(f"[DEBUG] Overlap region has {overlap_pixels} pixels.")

        # If there’s not enough overlap, bail out
        if overlap_pixels < 50:
            # Not enough area for star matching
            return None

        # ------------------------------------------
        # C) Mask out everything except the overlap
        # ------------------------------------------
        # We'll use numpy.ma arrays so astroalign sees "valid" data only in overlap region
        warped_new_ma = ma.array(warped_new_gray, mask=~overlap_mask)
        mosaic_ma = ma.array(mosaic_gray, mask=~overlap_mask)

        # ------------------------------------------
        # D) Attempt astroalign on that overlap
        #    Note: the transform we get is from warped_new_gray -> mosaic_gray,
        #    i.e., in "mosaic coordinate space." So it should be *almost* identity
        #    if the rough transform was close, but with some tweak for rotation/translation.
        # ------------------------------------------
        try:
            refine_obj, (src_pts, dst_pts) = astroalign.find_transform(
                warped_new_ma, mosaic_ma,
                max_control_points=50,
                detection_sigma=2
            )
            print(f"[DEBUG] Overlap-limited astroalign success with {len(src_pts)} stars.")
        except Exception as e:
            print(f"[DEBUG] Overlap-limited astroalign failed: {e}")
            return None

        # ------------------------------------------
        # E) Combine refine_obj with the original rough_matrix
        # ------------------------------------------
        # refine_obj.params is typically a 3×3 (similarity).
        # rough_matrix is 2×3 for warpAffine.
        # We'll promote rough_matrix to 3×3, multiply, then convert back.
        refine_mat_3x3 = refine_obj.params  # e.g. a 3×3
        rough_mat_3x3 = np.eye(3, dtype=np.float32)
        rough_mat_3x3[:2, :] = rough_matrix

        # The final transform is refine_mat_3x3 * rough_mat_3x3
        #   (in linear-algebra order, the right-hand transform applies first)
        combined_3x3 = refine_mat_3x3 @ rough_mat_3x3

        # Convert that back to 2×3 for cv2
        final_transform = combined_3x3[:2, :].astype(np.float32)
        return final_transform

    def align_images_seestar_mode(self):
        """ 
        Align images in Seestar Mode by first selecting the center-most image (based on WCS centers)
        as the initial mosaic. Then, sort and add images by increasing distance from the mosaic center.
        If WCS information is present in the header, a rough pre-alignment is computed before refining
        with astroalign.find_transform. After processing all images, failed images are reattempted.

        Final image is produced by summing all warped images and dividing by the pixel counts 
        (sum-then-divide approach).
        """

        if len(self.loaded_images) == 0:
            QMessageBox.warning(self, "Align", "No images to align.")
            return

        self.status_label.setText("🔄 Image Registration Started...")
        self.spinnerLabel.show()
        self.spinnerMovie.start()
        QApplication.processEvents()

        total_files = len(self.loaded_images)  # how many images in total
        if total_files == 0:
            QMessageBox.warning(self, "Align", "No images to align.")
            return

        # Create a QProgressDialog
        progress = QProgressDialog("Aligning images...", "Cancel", 0, total_files, self)
        progress.setWindowTitle("Seestar Alignment")
        progress.setWindowModality(Qt.WindowModality.WindowModal)
        progress.setAutoClose(False)
        progress.setAutoReset(False)
        progress.setMinimumDuration(0)
        progress.show()

        # We define how many pixels to zero out on each edge AFTER warp
        POST_WARP_BORDER = 10
        THRESHOLD_RATIO = 0.9  # if new pixel < 0.5 * mosaic pixel, skip it

        # -----------------------------------------------------
        # Helper: Extract the world-coordinate center from an image header
        # -----------------------------------------------------
        def get_wcs_center(item):
            header = item.get("header", None)
            if header is None:
                print(f"[DEBUG] No header for {item.get('path','')}")
                return None
            try:
                wcs = WCS(header)
                naxis1 = int(header.get("NAXIS1", 0))
                naxis2 = int(header.get("NAXIS2", 0))
                center_pix = np.array([naxis1 / 2.0, naxis2 / 2.0])
                center_world = wcs.all_pix2world(center_pix[None, :], 1)[0]
                print(f"[DEBUG] {item.get('path','')} center_world: {center_world}")
                return center_world
            except Exception as e:
                print(f"[DEBUG] Failed to get WCS center for {item.get('path','')}: {e}")
                return None

        # -----------------------------------------------------
        # Helper: Count how many stars appear in an image (2D or 3D)
        # -----------------------------------------------------
        def count_stars_in_image(image):
            """
            Use DAOStarFinder to return number of detected stars.
            Expects a 2D image; if 3D, we average over channels.
            You might need to tweak fwhm/threshold for your data.
            """
            if image.ndim == 3:
                image = np.mean(image, axis=2)

            mean_val, median_val, std_val = sigma_clipped_stats(image, sigma=3.0)
            daofind = DAOStarFinder(fwhm=3.0, threshold=5.0 * std_val)
            sources = daofind(image - median_val)

            if sources is None:
                return 0
            else:
                return len(sources)

        # -----------------------------------------------------
        # 1) Gather all images with valid WCS and compute average center
        # -----------------------------------------------------
        centers = []
        valid_items = []
        for item in self.loaded_images:
            center = get_wcs_center(item)
            if center is not None:
                centers.append(center)
                valid_items.append(item)

        if not centers:
            QMessageBox.warning(self, "Align", "No images with valid WCS found.")
            return

        centers = np.array(centers)
        avg_center = np.mean(centers, axis=0)  # or np.median if you prefer

        # -----------------------------------------------------
        # Sort valid items by distance from average center
        # -----------------------------------------------------
        def distance_from_avg(item):
            center = get_wcs_center(item)
            dist = np.linalg.norm(center - avg_center) if center is not None else np.inf
            print(f"[DEBUG] {item['path']} distance from avg: {dist}")
            return dist

        valid_items.sort(key=distance_from_avg)
        for item in valid_items:
            print(f"[DEBUG] Sorted valid item: {item['path']}")

        # -----------------------------------------------------
        # Select from the top few “closest to center,” pick the one with the most stars as the base.
        # -----------------------------------------------------
        top_n = 5
        candidate_subset = valid_items[:top_n]

        best_item = None
        best_star_count = 0
        for candidate in candidate_subset:
            star_count = count_stars_in_image(candidate["image"])
            print(f"[DEBUG] {candidate['path']} star count: {star_count}")
            if star_count > best_star_count:
                best_star_count = star_count
                best_item = candidate

        if best_item is None:
            best_item = valid_items[0]

        base_item = best_item
        print(f"[DEBUG] Selected base image: {base_item['path']} with star count = {best_star_count}")

        # -----------------------------------------------------
        # Reorder loaded_images so that valid (WCS) items come first
        # -----------------------------------------------------
        remaining_items = []
        valid_paths = {v["path"] for v in valid_items}  # set of valid item paths

        for item in self.loaded_images:
            if item["path"] not in valid_paths:
                remaining_items.append(item)

        self.loaded_images = valid_items + remaining_items


        # -----------------------------------------------------
        # Helper: Crop a 5-pixel border from each edge
        # -----------------------------------------------------
        def crop_5px_border(img):
            if img.ndim == 3:
                h, w, c = img.shape
                if h <= 10 or w <= 10:
                    return np.empty((0, 0, c), dtype=img.dtype)
                return img[10:-10, 10:-10, :]
            else:
                h, w = img.shape
                if h <= 10 or w <= 10:
                    return np.empty((0, 0), dtype=img.dtype)
                return img[10:-10, 10:-10]

        # -----------------------------------------------------
        # Helper: Convert image to float32 and normalize if needed
        # -----------------------------------------------------
        def ensure_float32_in_01(img):
            img = img.astype(np.float32, copy=False)
            mx = np.max(img)
            if mx <= 1.0:
                return img
            elif mx <= 255.0:
                return img / 255.0
            elif mx <= 65535.0:
                return img / 65535.0
            else:
                return img / mx if mx > 0 else img

        # -----------------------------------------------------
        # Helper: Compute a rough transform (rotation+translation) using WCS
        # -----------------------------------------------------
        def compute_rough_transform(new_header, ref_header):
            """Compute a rough transformation (rotation and translation) using WCS."""
            try:
                new_wcs = WCS(new_header)
                ref_wcs = WCS(ref_header)
                ref_naxis1 = int(ref_header.get('NAXIS1', 0))
                ref_naxis2 = int(ref_header.get('NAXIS2', 0))
                ref_center = np.array([ref_naxis1 / 2.0, ref_naxis2 / 2.0])
                world_center = ref_wcs.all_pix2world(ref_center[None, :], 1)
                new_center = new_wcs.all_world2pix(world_center, 1)[0]
                ref_offset = ref_center + np.array([1, 0])
                world_offset = ref_wcs.all_pix2world(ref_offset[None, :], 1)[0]
                new_offset = new_wcs.all_world2pix(world_offset[None, :], 1)[0]
                vector = new_offset - new_center
                angle = np.arctan2(vector[1], vector[0])
                cos_a = np.cos(angle)
                sin_a = np.sin(angle)
                R = np.array([[cos_a, -sin_a],
                            [sin_a,  cos_a]])
                t = ref_center - R @ new_center
                rough = np.hstack([R, t.reshape(2, 1)]).astype(np.float32)
                return rough
            except Exception as e:
                print(f"Rough transform skipped: {e}")
                return None

        def compute_rough_transform_seestar(new_header, ref_header):
            """
            Builds a 2×3 transform matrix (rotation + translation) that
            roughly aligns an image with RA/DEC, pixel scale, and focal length
            to a reference image with the same kind of data.

            Required header fields (example):
            new_header["RA"]       (degrees)
            new_header["DEC"]      (degrees)
            new_header["XPIXSZ"]   (microns)
            new_header["YPIXSZ"]   (microns)
            new_header["FOCALLEN"] (mm)
            Similarly for ref_header.

            Returns:
            A 2×3 np.float32 array suitable for cv2.warpAffine,
            or None if missing data or something fails.
            """

            # 1) Parse required fields from new_header
            try:
                ra_new_deg = float(new_header["RA"])       # degrees
                dec_new_deg = float(new_header["DEC"])     # degrees
                xpixsz_new = float(new_header["XPIXSZ"])   # microns
                ypixsz_new = float(new_header["YPIXSZ"])   # microns
                flen_new   = float(new_header["FOCALLEN"]) # mm
            except KeyError as e:
                print(f"[DEBUG] new_header missing key {e}. No rough transform.")
                return None
            except Exception as e:
                print(f"[DEBUG] parse error in new_header => {e}")
                return None

            # 2) Parse required fields from ref_header
            try:
                ra_ref_deg = float(ref_header["RA"])
                dec_ref_deg = float(ref_header["DEC"])
                xpixsz_ref = float(ref_header["XPIXSZ"])
                ypixsz_ref = float(ref_header["YPIXSZ"])
                flen_ref   = float(ref_header["FOCALLEN"])
            except KeyError as e:
                print(f"[DEBUG] ref_header missing key {e}. No rough transform.")
                return None
            except Exception as e:
                print(f"[DEBUG] parse error in ref_header => {e}")
                return None

            # 3) Compute average arcsec/pixel for each image
            #    arcsec_per_pix = 206265 * (XPIXSZ [um]) / (FOCALLEN [mm])
            #    (assuming 1 mm = 1000 um)
            #    If you want to be more precise, you might average XPIXSZ and YPIXSZ,
            #    or handle them separately if the camera has rectangular pixels.
            def arcsec_per_pixel(xpixsz, flen):
                return 206265.0 * (xpixsz / 1000.0) / flen

            scale_new = arcsec_per_pixel(xpixsz_new, flen_new)
            scale_ref = arcsec_per_pixel(xpixsz_ref, flen_ref)

            # For simplicity, let's assume the "reference" image defines the final scale.
            # If the images have different scales, we can do a ratio of scales => ~some "zoom."
            # Here we assume they are close enough, or you can do scale = scale_ref / scale_new
            # to get a small difference in pixel scale if needed.
            scale_ratio = scale_ref / scale_new  # how many ref pixels = 1 new pixel

            # 4) Compute difference in RA/DEC in arcseconds
            #    RA/DEC difference in degrees => multiply by 3600 to get arcseconds
            #    Then convert to pixel shift in reference coordinates.
            d_ra_deg  = (ra_new_deg  - ra_ref_deg)
            d_dec_deg = (dec_new_deg - dec_ref_deg)

            # For small fields, we can do a simple approximation ignoring spherical geometry:
            d_ra_arcsec  = d_ra_deg  * 3600.0 * np.cos(np.radians(dec_ref_deg))  # cos(dec) if you want
            d_dec_arcsec = d_dec_deg * 3600.0

            # If you want a more precise approach, you'd do a spherical trig approach,
            # but for small fields, this is usually good enough.

            # 5) Convert arcseconds => pixel shift in "reference" image coords
            dx_pix = d_ra_arcsec  / scale_ref
            dy_pix = - d_dec_arcsec / scale_ref
            # Note: we do "dy_pix = -d_dec_arcsec" if we assume +DEC => "up" in the image.
            # You may need to invert or swap RA/DEC sign depending on your orientation.

            # 6) Combine the scale ratio (if needed) and shift into a 2×3 transform.
            #    If you want to guess rotation from the difference in rotation angles,
            #    you can do that here. For now, we do no rotation => angle=0 => cos=1, sin=0.
            angle_rad = 0.0
            cos_a = np.cos(angle_rad)
            sin_a = np.sin(angle_rad)

            # scale_ratio is for "zoom," if you want to handle that.
            # If you prefer no scale difference, set scale_ratio = 1.0
            # or if the difference is small, ignore it.
            # scale_ratio = 1.0

            M = np.array([
                [scale_ratio*cos_a, -scale_ratio*sin_a, dx_pix],
                [scale_ratio*sin_a,  scale_ratio*cos_a, dy_pix]
            ], dtype=np.float32)

            print(f"[DEBUG] Seestar rough transform => dx_pix={dx_pix:.2f}, dy_pix={dy_pix:.2f}, scale={scale_ratio:.3f}")
            return M

        # -----------------------------------------------------
        # 1) Initialize mosaic_sum/mosaic_count from the base image
        # -----------------------------------------------------
        base_img = ensure_float32_in_01(base_item["image"])
        if base_item["path"].lower().endswith(('.fits', '.fit', '.fz')):
            if (base_img.ndim == 2 
                and "header" in base_item 
                and base_item["header"] is not None 
                and base_item["header"].get('BAYERPAT')):
                self.status_label.setText(f"Debayering {base_item['path']}")
                QApplication.processEvents()
                base_img = self.debayer_image(base_img, base_item["path"], base_item["header"])
                print(f"[DEBUG] Finished debayering base image: {base_item['path']}")

        base_img = crop_5px_border(base_img)
        if base_img.size == 0:
            QMessageBox.warning(self, "Crop Error", "Initial image is too small after cropping.")
            return
    
        base_median = np.median(base_img)

        # mosaic_sum holds the sum of pixel intensities
        mosaic_sum = base_img.astype(np.float32, copy=True)
        # mosaic_count tracks how many images contributed at each pixel
        if mosaic_sum.ndim == 3:
            # For color: count “contributed” if any channel is >0
            contrib_mask = np.any(mosaic_sum > 0, axis=2)
            mosaic_count = np.zeros_like(mosaic_sum, dtype=np.float32)
            for c in range(mosaic_sum.shape[2]):
                mosaic_count[..., c][contrib_mask] = 1.0
        else:
            contrib_mask = (mosaic_sum > 0)
            mosaic_count = np.zeros_like(mosaic_sum, dtype=np.float32)
            mosaic_count[contrib_mask] = 1.0

        # We’ll use a helper that returns a mono “view” for alignment:
        def get_current_mosaic_gray():
            """Return current mosaic as a float32 array in [0..1], averaged if color."""
            with np.errstate(divide='ignore', invalid='ignore'):
                stacked = mosaic_sum / np.maximum(mosaic_count, 1e-6)
            # If color, reduce to mono for astroalign
            if stacked.ndim == 3:
                return np.mean(stacked, axis=2).astype(np.float32)
            else:
                return stacked

        self.status_label.setText("Starting alignment of subsequent images...")
        QApplication.processEvents()

        # --- Helper: Process alignment for one image, then accumulate into mosaic_sum/count ---
        def process_alignment(item):
            nonlocal mosaic_sum, mosaic_count

            print(f"[DEBUG] Aligning image: {item['path']}")

            try:
                new_img = item["image"].astype(np.float32)
                print(f"[DEBUG] new_img initial shape={new_img.shape}, dtype={new_img.dtype}, "
                    f"min={np.min(new_img):.3f}, max={np.max(new_img):.3f}")

                # Debayer if needed
                if item["path"].lower().endswith(('.fits', '.fit')):
                    if (new_img.ndim == 2 
                        and "header" in item 
                        and item["header"] is not None 
                        and item["header"].get('BAYERPAT')):
                        print(f"[DEBUG] Debayering image: {item['path']}")
                        new_img = self.debayer_image(new_img, item["path"], item["header"])
                        print(f"[DEBUG] debayered new_img shape={new_img.shape}, dtype={new_img.dtype}, "
                            f"min={np.min(new_img):.3f}, max={np.max(new_img):.3f}")

                new_img = crop_5px_border(new_img)
                if new_img.size == 0:
                    print(f"[DEBUG] new_img is empty after cropping => skip.")
                    self.status_label.setText(f"Skipping {item['path']} (too small after crop).")
                    QApplication.processEvents()
                    return False

                self.status_label.setText(f"Removing linear gradient from {item['path']}...")
                QApplication.processEvents()
                # Create an instance of PolyGradientRemoval with degree 1.
                poly_remover = PolyGradientRemoval(new_img, poly_degree=2, downsample_scale=5, num_sample_points=100)
                # Process the image to remove the gradient
                new_img = poly_remover.process()
                print("[DEBUG] Finished polynomial gradient removal on subframe.")

                # If mono:
                self.status_label.setText(f"Normalizing {item['path']}.")
                QApplication.processEvents()
                new_img = new_img-np.min(new_img)
                if new_img.ndim == 2:
                    new_img = stretch_mono_image(new_img, target_median=base_median, normalize=False, apply_curves=False, curves_boost=0.0)

                else:
                    # color approach - you might do a single ratio or call your stretch_color_image
                    new_img = stretch_color_image(new_img, target_median=base_median, linked=False, normalize=False, apply_curves=False, curves_boost=0.0)


                # If mosaic is color and new_img is mono, expand new_img
                # But remember, mosaic_sum is our "canvas"
                if mosaic_sum.ndim == 3 and new_img.ndim == 2:
                    print("[DEBUG] Expanding new_img from 2D => 3D to match mosaic channels.")
                    new_img = np.repeat(new_img[:, :, np.newaxis], mosaic_sum.shape[2], axis=2)
                elif mosaic_sum.ndim == 2 and new_img.ndim == 3:
                    print("[DEBUG] new_img is color but mosaic is mono => average new_img channels.")
                    new_img = np.mean(new_img, axis=2, dtype=np.float32)

                # Create the grayscale for astroalign from mosaic_sum/mosaic_count
                mosaic_gray = get_current_mosaic_gray()

                new_gray = new_img
                if new_gray.ndim == 3:
                    new_gray = np.mean(new_gray, axis=2)

                # Optional: mild stretch to help astroalign
                mosaic_gray = stretch_mono_image(mosaic_gray, target_median=0.1, normalize=False, apply_curves=False, curves_boost=0.0)
                new_gray = stretch_mono_image(new_gray, target_median=0.1, normalize=False, apply_curves=False, curves_boost=0.0)

                # Attempt rough transform via WCS
                rough_matrix = None
                if ("header" in item and item["header"] is not None
                    and "CTYPE1" in item["header"] and "CTYPE2" in item["header"]):
                    # Normal WCS approach
                    rough_matrix = compute_rough_transform(item["header"], base_item["header"])
                    if rough_matrix is not None:
                        print("[DEBUG] WCS-based rough transform:\n", rough_matrix)
                else:
                    # Fallback: check if we have RA,DEC,XPIXSZ,FOCALLEN, etc.
                    rough_matrix = compute_rough_transform_seestar(item["header"], base_item["header"])
                    if rough_matrix is not None:
                        print("[DEBUG] Seestar rough transform:\n", rough_matrix)

                self.status_label.setText(f"Astroaligning for {item['path']}...")
                QApplication.processEvents()

                # Find transform
                transform_matrix = None
                try:
                    # astroalign wants double precision
                    transform_obj, (src_pts, dst_pts) = astroalign.find_transform(
                        new_gray,
                        mosaic_gray,
                        max_control_points=50,
                        detection_sigma=4,
                        min_area=5
                    )
                    transform_matrix = transform_obj.params[0:2, :].astype(np.float32)
                    print(f"[DEBUG] Astroalign success with {len(src_pts)} stars. transform_matrix:\n{transform_matrix}")

                except Exception as e:
                    print(f"[DEBUG] astroalign.find_transform failed: {e}")
                    self.status_label.setText(f"Alignment failed: {e}")
                    QApplication.processEvents()

                    # Fallback if rough_matrix is available
                    if rough_matrix is not None:
                        print("[DEBUG] Attempting refine_via_overlap fallback with rough_matrix.")
                        transform_matrix = self.refine_via_overlap(new_gray, mosaic_gray, rough_matrix)
                        if transform_matrix is None:
                            print("[DEBUG] Overlap approach also failed => skip this image.")
                            return False
                        print("[DEBUG] Overlap-based refinement succeeded. transform_matrix:\n", transform_matrix)
                    else:
                        print("[DEBUG] No rough transform => skipping image.")
                        return False

                if transform_matrix is None:
                    self.status_label.setText("No transform found; skipping image.")
                    print("[DEBUG] transform_matrix is None => returning False")
                    return False

                self.status_label.setText(f"Astroalign success for {item['path']}")
                QApplication.processEvents()

                # Warp the new image onto mosaic_sum's coordinate system
                h_m, w_m = mosaic_sum.shape[:2]
                new_h, new_w = new_img.shape[:2]

                mosaic_corners = np.array([[0, 0], [w_m, 0], [0, h_m], [w_m, h_m]], dtype=np.float32)
                new_img_corners = np.array([[0, 0], [new_w, 0], [0, new_h], [new_w, new_h]], dtype=np.float32)
                ones = np.ones((4, 1), dtype=np.float32)
                new_img_corners_hom = np.hstack([new_img_corners, ones])

                warped_corners = (transform_matrix @ new_img_corners_hom.T).T
                all_corners = np.vstack([mosaic_corners, warped_corners])
                min_xy = np.min(all_corners, axis=0)
                max_xy = np.max(all_corners, axis=0)

                margin = 10
                new_canvas_width = int(np.ceil(max_xy[0] - min_xy[0])) + margin
                new_canvas_height = int(np.ceil(max_xy[1] - min_xy[1])) + margin
                shift = -min_xy + np.array([margin / 2, margin / 2])
                shift_int = np.round(shift).astype(int)
                y0, x0 = shift_int[1], shift_int[0]

                print(f"[DEBUG] new_canvas_width={new_canvas_width}, new_canvas_height={new_canvas_height}")
                print(f"[DEBUG] shift={shift}, shift_int={shift_int}, y0={y0}, x0={x0}")

                # Expand mosaic_sum/mosaic_count to fit new canvas if needed
                expanded_sum = None
                expanded_count = None

                if mosaic_sum.ndim == 3:
                    channels = mosaic_sum.shape[2]
                    expanded_sum = np.zeros((new_canvas_height, new_canvas_width, channels), dtype=np.float32)
                    expanded_count = np.zeros_like(expanded_sum, dtype=np.float32)
                    # Copy existing mosaic_sum/mosaic_count
                    expanded_sum[y0:y0+h_m, x0:x0+w_m, :] = mosaic_sum
                    expanded_count[y0:y0+h_m, x0:x0+w_m, :] = mosaic_count
                else:
                    expanded_sum = np.zeros((new_canvas_height, new_canvas_width), dtype=np.float32)
                    expanded_count = np.zeros_like(expanded_sum, dtype=np.float32)
                    expanded_sum[y0:y0+h_m, x0:x0+w_m] = mosaic_sum
                    expanded_count[y0:y0+h_m, x0:x0+w_m] = mosaic_count

                # Adjust transform for the shift
                new_transform = transform_matrix.copy()
                new_transform[0, 2] += shift[0]
                new_transform[1, 2] += shift[1]

                # Warp the new_img
                try:
                    warped_new = cv2.warpAffine(
                        new_img,
                        new_transform,
                        (new_canvas_width, new_canvas_height),
                        flags=cv2.INTER_LANCZOS4
                    )
                except cv2.error as cv2_err:
                    print(f"[OpenCV] warpAffine error => {cv2_err}")
                    return False

                # 1) Build the "border_mask" that excludes the outer POST_WARP_BORDER region
                h_w, w_w = warped_new.shape[:2]
                border_mask = np.ones((h_w, w_w), dtype=bool)
                b = POST_WARP_BORDER
                border_mask[:b, :] = False
                border_mask[-b:, :] = False
                border_mask[:, :b] = False
                border_mask[:, -b:] = False

                # 2) Build a "valid_mask" by warping an image of ones using INTER_NEAREST.
                ones_img = np.ones(new_img.shape[:2], dtype=np.uint8)
                warped_mask = cv2.warpAffine(
                    ones_img,
                    new_transform,
                    (new_canvas_width, new_canvas_height),
                    flags=cv2.INTER_NEAREST
                )
                valid_mask = (warped_mask == 1)

                # 2b) Compute a feathering weight from the valid_mask:
                # Compute the distance transform of the valid_mask.
                # This gives, for each pixel inside the valid region, its distance (in pixels)
                # from the nearest 0 (i.e. from the border of the valid region).
                FEATHER_RADIUS = 20  # adjust as needed; this is the maximum distance for feathering
                # Convert valid_mask to uint8 for distance transform.
                valid_uint8 = valid_mask.astype(np.uint8)
                dist = cv2.distanceTransform(valid_uint8, cv2.DIST_L2, 5)
                # Compute weights: linear ramp from 0 (at distance=0) to 1 (at distance>=FEATHER_RADIUS).
                feather_weights = np.clip(dist / FEATHER_RADIUS, 0, 1)

                # 3) Build "mosaic_gray" = the grayscale of (expanded_sum / expanded_count)
                mosaic_gray = np.zeros((new_canvas_height, new_canvas_width), dtype=np.float32)
                if expanded_sum.ndim == 2:
                    nonzero_mask = (expanded_count > 0)
                    mosaic_gray[nonzero_mask] = expanded_sum[nonzero_mask] / expanded_count[nonzero_mask]
                else:
                    sum_channels = np.sum(expanded_sum, axis=2)
                    sum_counts = np.sum(expanded_count, axis=2)
                    nonzero_mask = (sum_counts > 0)
                    mosaic_gray[nonzero_mask] = sum_channels[nonzero_mask] / sum_counts[nonzero_mask]

                # 4) Build new_gray for the warped image
                if warped_new.ndim == 2:
                    new_gray = warped_new
                else:
                    new_gray = np.mean(warped_new, axis=2)

                # 5) Build the brightness_mask: accept pixels where new_gray >= THRESHOLD_RATIO * mosaic_gray.
                brightness_mask = (new_gray >= THRESHOLD_RATIO * mosaic_gray)

                # 6) Combine masks.
                # Here we combine border_mask, brightness_mask, and valid_mask.
                # The final effective weight will be the feathering weight from within the valid_mask,
                # applied only where the other masks also pass.
                combined_mask = border_mask & valid_mask & brightness_mask

                # 7) Add only those pixels, using the feathering weights.
                if warped_new.ndim == 2:
                    # MONO: weight each pixel accordingly.
                    expanded_sum[combined_mask] += warped_new[combined_mask] * feather_weights[combined_mask]
                    expanded_count[combined_mask] += feather_weights[combined_mask]
                else:
                    # COLOR: do it per channel.
                    for c in range(warped_new.shape[2]):
                        expanded_sum[..., c][combined_mask] += warped_new[..., c][combined_mask] * feather_weights[combined_mask]
                        expanded_count[..., c][combined_mask] += feather_weights[combined_mask]

                # 8) Update mosaic_sum/mosaic_count.
                mosaic_sum = expanded_sum
                mosaic_count = expanded_count


                self.status_label.setText(f"Integrated image: {item['path']}")
                QApplication.processEvents()

                print("[DEBUG] process_alignment done successfully for this image.")
                return True

            except Exception as e:
                print(f"[DEBUG] process_alignment error => {e}")
                traceback.print_exc()
                return False

        # ---------------------------------------------------------
        # Process each subsequent image once
        # ---------------------------------------------------------
        failed_items = []
        # We'll do a normal for-loop with enumerate so we can pass index to progress
        for i, item in enumerate(self.loaded_images):
            # If user cancels
            if progress.wasCanceled():
                self.status_label.setText("Alignment canceled by user.")
                break

            # Update the progress label
            progress.setLabelText(f"Aligning image {i+1}/{total_files}: {item['path']}")
            progress.setValue(i)  # update the progress bar

            if item is base_item:
                continue

            success = process_alignment(item)
            if not success:
                failed_items.append(item)

            QApplication.processEvents()  # allow UI updates

        # Final step: mark progress done
        progress.setValue(total_files)

        # ---------------------------------------------------------
        # Reattempt failed images (max 1 additional attempt)
        # ---------------------------------------------------------
        max_retries = 1
        attempt = 1
        while failed_items and attempt <= max_retries:
            reattempt_count = len(failed_items)
            self.status_label.setText(f"Reattempting alignment for {reattempt_count} images (Attempt {attempt})")
            print(f"Reattempting alignment for {reattempt_count} images (Attempt {attempt})")
            QApplication.processEvents()

            # 2) Reset the existing progress bar to track the reattempt pass
            progress.setRange(0, reattempt_count)
            progress.setValue(0)
            progress.setLabelText(f"Reattempt pass {attempt}...")

            current_failures = []
            for i, item in enumerate(failed_items):
                if progress.wasCanceled():
                    self.status_label.setText("Reattempt canceled by user.")
                    break

                progress.setLabelText(f"Reattempting {item['path']} ({i+1}/{reattempt_count})")
                progress.setValue(i)
                QApplication.processEvents()

                success = process_alignment(item)
                if not success:
                    current_failures.append(item)

            progress.setValue(reattempt_count)  # done reattempt pass

            failed_items = current_failures
            attempt += 1

        # All passes complete
        progress.close()
        self.status_label.setText("All alignment attempts complete.")
        QApplication.processEvents()

        # ---------------------------------------------------------
        # Finally, build the average mosaic = mosaic_sum / mosaic_count
        # ---------------------------------------------------------
        with np.errstate(divide='ignore', invalid='ignore'):
            final_mosaic = np.zeros_like(mosaic_sum, dtype=np.float32)
            if final_mosaic.ndim == 2:
                nonzero = (mosaic_count > 0)
                final_mosaic[nonzero] = mosaic_sum[nonzero] / mosaic_count[nonzero]
            else:
                # color
                for c in range(final_mosaic.shape[2]):
                    chan_nonzero = (mosaic_count[..., c] > 0)
                    final_mosaic[..., c][chan_nonzero] = (
                        mosaic_sum[..., c][chan_nonzero] 
                        / mosaic_count[..., c][chan_nonzero]
                    )

        # Optional: you could do a final normalization
        max_val = np.max(final_mosaic)
        if max_val > 0:
            final_mosaic /= max_val

        self.final_mosaic = final_mosaic
        self.spinnerMovie.stop()
        self.spinnerLabel.hide()
        self.status_label.setText("Seestar Mode alignment (sum/divide) complete.")
        QApplication.processEvents()

        display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Robot Telescope Mosaic", parent=self)
        mosaic_win.show()

    # ---------- Star alignment using triangle matching ----------

    def refined_alignment(self, affine_aligned, mosaic_img, method="Homography Transform"):
        """
        Refined alignment that assumes affine_aligned is the result of the affine alignment step.
        It re-detects stars in the candidate (overlap) region and computes a refined transform from
        affine_aligned to mosaic_img. Then it applies the refined transform to affine_aligned and
        returns the fully warped image.
        
        Returns:
        - For "Homography Transform": (warped_image, inlier_count)
        - For "Polynomial Warp Based Transform": (warped_image, inlier_count)
        - If refinement fails, returns None.
        """
        print("\n--- Starting Refined Alignment ---")
        poly_degree = self.settings.value("mosaic/poly_degree", 3, type=int)
        self.status_label.setText("Refinement: Converting images to grayscale...")
        QApplication.processEvents()
        
        # Convert images to grayscale
        if affine_aligned.ndim == 3:
            affine_aligned_gray = np.mean(affine_aligned, axis=-1)
        else:
            affine_aligned_gray = affine_aligned
        if mosaic_img.ndim == 3:
            mosaic_gray = np.mean(mosaic_img, axis=-1)
        else:
            mosaic_gray = mosaic_img

        print("Grayscale conversion done.")
        
        # Compute overlap mask
        self.status_label.setText("Refinement: Computing overlap mask...")
        QApplication.processEvents()
        overlap_mask = (mosaic_gray > 0) & (affine_aligned_gray > 0)

        # Detect stars
        self.status_label.setText("Refinement: Detecting stars in mosaic and affine-aligned images...")
        QApplication.processEvents()
        # Increase max_stars to 50 for debugging purposes.
        mosaic_stars_masked = self.detect_stars(np.where(overlap_mask, mosaic_gray, 0), max_stars=300)
        new_stars_aligned = self.detect_stars(np.where(overlap_mask, affine_aligned_gray, 0), max_stars=300)

        # Debug: Print out the star lists.
        print("Mosaic stars (refined alignment):")
        for s in mosaic_stars_masked:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")
        print("New stars (refined alignment):")
        for s in new_stars_aligned:
            print(f"({s[0]:.2f}, {s[1]:.2f}) flux: {s[2]:.2f}")

        self.status_label.setText(f"Refinement: Detected {len(mosaic_stars_masked)} mosaic stars and {len(new_stars_aligned)} new stars.")
        QApplication.processEvents()

        if len(mosaic_stars_masked) < 4 or len(new_stars_aligned) < 4:
            self.status_label.setText("Refinement: Not enough stars detected in candidate region.")
            return None

        # Match stars using position and flux.
        self.status_label.setText("Refinement: Matching stars...")
        QApplication.processEvents()
        # For debugging, you might try a higher threshold.
        matches = self.match_stars(new_stars_aligned, mosaic_stars_masked, distance_thresh=10.0, flux_thresh=1.0)
        print(f"Matched stars: {len(matches)}")
        self.status_label.setText(f"Refinement: {len(matches)} matches found.")
        if len(matches) < 4:
            self.status_label.setText("Refinement: Not enough matched stars for refined transform.")
            return None

        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)

        if method == "Homography Transform":
            self.status_label.setText("Refinement: Computing homography transform...")
            QApplication.processEvents()
            H_refined, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
            inliers = int(np.count_nonzero(mask)) if mask is not None else 0
            self.status_label.setText(f"Refinement: Homography computed with {inliers} inliers. Warping image...")
            QApplication.processEvents()
            if H_refined is None:
                self.status_label.setText("Refinement: Homography estimation failed.")
                return None
            warped_image = cv2.warpPerspective(affine_aligned, H_refined,
                                                (affine_aligned.shape[1], affine_aligned.shape[0]),
                                                flags=cv2.INTER_LANCZOS4)
            return (warped_image, inliers)
        elif method == "Polynomial Warp Based Transform":
            self.status_label.setText("Refinement: Computing Polynomial Warp based transform...")
            QApplication.processEvents()
            # Extract control points from matches.
            src_pts = np.float32([match[0][:2] for match in matches])
            dst_pts = np.float32([match[1][:2] for match in matches])
            # Call the static Polynomial Warp warp function.
            try:
                warped_image = MosaicMasterDialog.poly_warp(affine_aligned, src_pts, dst_pts, degree=poly_degree, status_label=self.status_label)
                inliers = len(matches)
                self.status_label.setText(f"Refinement: Polynomial Warp warp applied with {inliers} matched points.")
                return (warped_image, inliers)
            except Exception as e:
                self.status_label.setText(f"Refinement: Polynomial Warp warp failed: {e}")
                return None
        else:
            self.status_label.setText("Refinement: Unexpected transformation method.")
            return None

    @staticmethod
    def poly_warp(image, src_pts, dst_pts, degree=3, status_label=None):
        """
        Warp `image` using a polynomial transformation of the specified degree.
        
        The transformation is defined as:
        u = sum_{i+j<=degree} a_{ij} * x^i * y^j
        v = sum_{i+j<=degree} b_{ij} * x^i * y^j
        
        where the coefficients are solved via least squares using the control points.
        
        Parameters:
        image: Input image.
        src_pts: numpy array of shape (N,2) with control points in the source image.
        dst_pts: numpy array of shape (N,2) with corresponding control points in the destination.
        degree: Degree of the polynomial transformation (allowed 1 to 6, default=3).
        status_label: If provided, a Qt widget where progress messages are displayed.
        
        Returns:
        The warped image.
        """
        h, w = image.shape[:2]
        
        # Function to build the design matrix for points given a degree.
        def build_design_matrix(pts, degree):
            # pts: (N,2) array, where each row is (x, y)
            N = pts.shape[0]
            terms = []
            x = pts[:, 0]
            y = pts[:, 1]
            # Loop over exponents i and j with i+j <= degree.
            for i in range(degree + 1):
                for j in range(degree + 1 - i):
                    terms.append((x**i) * (y**j))
            X = np.vstack(terms).T  # shape: (N, number_of_terms)
            return X

        # Build the design matrix for the control points.
        if status_label is not None:
            status_label.setText("Polynomial warp: Building design matrix for control points...")
            QApplication.processEvents()
        X = build_design_matrix(src_pts, degree)
        
        # Destination coordinates.
        U = dst_pts[:, 0]
        V = dst_pts[:, 1]
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Solving for polynomial coefficients...")
            QApplication.processEvents()
        
        # Solve the least-squares problem.
        coeffs_u, _, _, _ = np.linalg.lstsq(X, U, rcond=None)
        coeffs_v, _, _, _ = np.linalg.lstsq(X, V, rcond=None)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Computing full mapping for image...")
            QApplication.processEvents()
        
        # Build a full grid of coordinates.
        grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
        flat_x = grid_x.ravel()
        flat_y = grid_y.ravel()
        pts_full = np.vstack([flat_x, flat_y]).T  # shape: (h*w, 2)
        
        # Build design matrix for the full grid.
        X_full = build_design_matrix(pts_full, degree)
        
        # Evaluate the polynomial mappings.
        map_u = np.dot(X_full, coeffs_u).reshape(h, w).astype(np.float32)
        map_v = np.dot(X_full, coeffs_v).reshape(h, w).astype(np.float32)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Full mapping computed. Remapping image...")
            QApplication.processEvents()
        
        # Remap the image.
        warped = cv2.remap(image, map_u, map_v, interpolation=cv2.INTER_LANCZOS4, borderMode=cv2.BORDER_CONSTANT)
        
        if status_label is not None:
            status_label.setText("Polynomial warp: Image warped.")
            QApplication.processEvents()
        
        return warped



    def estimate_homography_from_stars(self, mosaic_stars, new_stars):
        self.status_label.setText("Matching stars for homography...")
        QApplication.processEvents()
        matches = self.match_stars(new_stars, mosaic_stars, distance_thresh=20.0, flux_thresh=0.5)
        if len(matches) < 4:
            self.status_label.setText("Not enough matched stars for homography.")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} matched stars. Computing homography...")
        QApplication.processEvents()
        src_pts = np.float32([match[0][:2] for match in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([match[1][:2] for match in matches]).reshape(-1, 1, 2)
        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        inliers = int(np.count_nonzero(mask)) if mask is not None else 0
        self.status_label.setText(f"Homography computed with {inliers} inliers.")
        return H, inliers

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, image_width, settings, ransac_iter=500, inlier_thresh=3.0, norm_trans_thresh=0.2, update_callback=None):
        """
        Runs RANSAC to estimate an affine transform between source and target star coordinates.
        Failsafe checks for translation, scale, rotation, and skew use values from the provided QSettings.
        
        The translation tolerance is a percentage of the image width.
        """
        # Retrieve settings values.
        translation_tolerance_percent = settings.value("mosaic/translation_max_tolerance", 0.1, type=float)
        # Compute the absolute translation tolerance in pixels.
        translation_tolerance = translation_tolerance_percent * image_width

        scale_min = settings.value("mosaic/scale_min_tolerance", 0.85, type=float)
        scale_max = settings.value("mosaic/scale_max_tolerance", 1.15, type=float)
        rotation_max_deg = settings.value("mosaic/rotation_max_tolerance", 45.0, type=float)
        rotation_tolerance = np.radians(rotation_max_deg)
        skew_max = settings.value("mosaic/skew_max_tolerance", 0.05, type=float)  # default: 0.1
        axis_ratio_threshold = settings.value("mosaic/axis_ratio_tolerance", 1.15, type=float)


        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(
                pts_src.reshape(-1, 1, 2), pts_tgt.reshape(-1, 1, 2),
                method=cv2.LMEDS)
            if transform is None:
                continue
            full_mat = np.eye(3, dtype=np.float32)
            full_mat[:2] = transform
            
            # Failsafe: scaling check.
            A = full_mat[:2, :2]
            scale1 = np.linalg.norm(A[:, 0])
            scale2 = np.linalg.norm(A[:, 1])
            scale = (scale1 + scale2) / 2.0
            if scale > scale_max or scale < scale_min:
                continue
            
            # Failsafe: translation check.
            t = full_mat[:2, 2]
            if abs(t[0]) > translation_tolerance or abs(t[1]) > translation_tolerance:
                continue
            
            # New failsafe: check ratio between scales to avoid squashed images.
            if (max(scale1, scale2) / (min(scale1, scale2) + 1e-8)) > axis_ratio_threshold:
                continue

            # Failsafe: rotation angle check.
            angle = np.arctan2(A[1, 0], A[0, 0])
            if abs(angle) > rotation_tolerance: #(np.pi / 4):
                continue
            
            # Failsafe: skew check.
            # For a pure rotation plus uniform scale, the columns of A should be orthogonal.
            v1 = A[:, 0] / (np.linalg.norm(A[:, 0]) + 1e-8)
            v2 = A[:, 1] / (np.linalg.norm(A[:, 1]) + 1e-8)
            skew = abs(np.dot(v1, v2))  # 0 means perfectly orthogonal.
            if skew > skew_max:
                continue

            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars, mosaic_width):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        
        # Compute a normalization factor based on the source coordinate range.
        range_x = np.max(src_coords[:, 0]) - np.min(src_coords[:, 0])
        range_y = np.max(src_coords[:, 1]) - np.min(src_coords[:, 1])
        norm_factor = max(range_x, range_y)
        if norm_factor == 0:
            norm_factor = 1.0
        print("Normalization factor:", norm_factor)
        
        # Normalize coordinates.
        src_norm = src_coords / norm_factor
        tgt_norm = tgt_coords / norm_factor

        self.status_label.setText("Computing Delaunay triangulation (normalized)...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_norm)
        tgt_tri_dict = self.build_triangle_dict(tgt_norm)
        self.status_label.setText("Matching triangles (normalized)...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform_norm, best_inliers = self.ransac_affine(src_norm, tgt_norm, matches, image_width=mosaic_width, settings=self.settings, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        
        if best_transform_norm is None:
            return None, best_inliers

        # Unnormalize the transform.
        # If T_norm is:
        #    y_norm = A_norm * x_norm + t_norm
        # and x_norm = x / norm_factor, then
        #    y = norm_factor * y_norm = A_norm * x + norm_factor * t_norm.
        # Thus, T_full = [A_norm, norm_factor * t_norm].
        best_transform = np.eye(3, dtype=np.float32)
        best_transform[:2, :2] = best_transform_norm[:2, :2]
        best_transform[:2, 2] = best_transform_norm[:2, 2] * norm_factor
        print("Unnormalized transform matrix:\n", best_transform)
        return best_transform, best_inliers



    def stretch_for_display(self, arr):
        """
        Uses your global stretch_mono_image or stretch_color_image to produce
        a display-ready 8-bit image. For color images, uses unlinked stretching.
        """
        arr = arr.astype(np.float32)

        # Decide if it's mono or color based on shape
        if arr.ndim == 3 and arr.shape[2] == 3:
            # Color image => use stretch_color_image with unlinked stretching
            stretched = stretch_color_image(
                image=arr,
                target_median=0.25,   # Adjust if you prefer a different default
                linked=False,         # "unlinked" mode
                normalize=True,       # Ensures final values are in [0,1]
                apply_curves=False,   # Adjust if needed
                curves_boost=0.0
            )
        else:
            # Mono image => use stretch_mono_image
            stretched = stretch_mono_image(
                image=arr,
                target_median=0.25,
                normalize=True,
                apply_curves=False,
                curves_boost=0.0
            )

        # Convert [0,1] => [0,255]
        disp = (stretched * 255.0).clip(0, 255).astype(np.uint8)
        return disp


    def detect_stars(self, image2d, max_stars=50):
        # Retrieve user-defined values for sigma and fwhm.
        sigma_val = self.settings.value("mosaic/star_sigma", 3.0, type=float)
        fwhm_val = self.settings.value("mosaic/star_fwhm", 3.0, type=float)
        
        mean_val, median_val, std_val = sigma_clipped_stats(image2d, sigma=3.0)
        # Use the user-defined fwhm and scale the threshold by the standard deviation.
        daofind = DAOStarFinder(threshold=sigma_val * std_val, fwhm=fwhm_val)
        sources = daofind(image2d - median_val)
        if sources is None or len(sources) == 0:
            return []
        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        # Sort stars by brightness (flux) and select the top ones.
        sorted_indices = np.argsort(-flux)
        top_indices = sorted_indices[:max_stars]
        stars = [(x_coords[i], y_coords[i], flux[i]) for i in top_indices]
        return stars


    def match_stars(self, new_stars, mosaic_stars, distance_thresh=10.0, flux_thresh=0.2):
        """
        Matches stars between two lists.
        new_stars and mosaic_stars should be lists of (x, y, flux).
        
        This version normalizes the flux values in each list by dividing by the median flux.
        
        distance_thresh: maximum distance (in pixels) allowed for a match.
        flux_thresh: allowed absolute difference in normalized flux.
                    For example, if set to 0.2, then the normalized flux difference must be less than 0.2.
                    
        Returns a list of matched pairs: [(new_star, mosaic_star), ...]
        """
        # If either list is empty, return an empty match list.
        if not new_stars or not mosaic_stars:
            return []
        
        # Compute median fluxes.
        new_fluxes = [s[2] for s in new_stars]
        mosaic_fluxes = [s[2] for s in mosaic_stars]
        new_median = np.median(new_fluxes) if new_fluxes else 1.0
        mosaic_median = np.median(mosaic_fluxes) if mosaic_fluxes else 1.0

        # Normalize the flux for each star.
        norm_new_stars = [(s[0], s[1], s[2] / new_median) for s in new_stars]
        norm_mosaic_stars = [(s[0], s[1], s[2] / mosaic_median) for s in mosaic_stars]

        matches = []
        for ns in norm_new_stars:
            best_match = None
            best_distance = float('inf')
            for ms in norm_mosaic_stars:
                dx = ns[0] - ms[0]
                dy = ns[1] - ms[1]
                dist = np.hypot(dx, dy)
                # Check spatial proximity.
                if dist < distance_thresh and dist < best_distance:
                    # Check if the normalized fluxes are similar.
                    # Here, flux_thresh is an absolute threshold on the difference.
                    if abs(ns[2] - ms[2]) < flux_thresh:
                        best_match = ms
                        best_distance = dist
            if best_match is not None:
                matches.append((ns, best_match))
        return matches

    def estimate_transform(self, source_stars, dest_stars):
        min_len = min(len(source_stars), len(dest_stars))
        if min_len < 3:
            return None
        src_pts = np.float32(source_stars[:min_len])
        dst_pts = np.float32(dest_stars[:min_len])
        matrix, inliers = cv2.estimateAffinePartial2D(
            src_pts, dst_pts,
            method=cv2.RANSAC, ransacReprojThreshold=3.0
        )
        if matrix is None:
            return None
        full_mat = np.eye(3, dtype=np.float32)
        full_mat[:2] = matrix
        return full_mat


    def compute_mosaic_bounding_box(self, wcs_items, reference_wcs):
        """
        Compute the mosaic bounding box in pixel coordinates relative to a shared WCS frame,
        properly accounting for rotation and orientation dynamically.
        """
        all_pixels = []

        for itm in wcs_items:
            wcs = itm["wcs"]
            H, W = itm["image"].shape[:2]  # Use only the height and width

            # Get image corner coordinates in world coordinates (RA/Dec)
            pixel_corners = np.array([
                [0, 0],         # Top-left
                [W - 1, 0],     # Top-right
                [0, H - 1],     # Bottom-left
                [W - 1, H - 1]  # Bottom-right
            ])

            # Convert pixel to world coordinates (RA, Dec)
            world_coords = np.column_stack(wcs.pixel_to_world_values(pixel_corners[:, 0], pixel_corners[:, 1]))

            # Convert RA/Dec to pixel coordinates in the reference WCS
            sky_coords = SkyCoord(ra=world_coords[:, 0] * u.deg, dec=world_coords[:, 1] * u.deg, frame='icrs')
            pixel_coords = skycoord_to_pixel(sky_coords, reference_wcs)

            # Ensure we're only using the first two values (x, y)
            all_pixels.append(np.column_stack(pixel_coords[:2]))

        # Stack all pixel coordinates and compute bounding box
        all_pixels = np.vstack(all_pixels)

        min_x, max_x = np.min(all_pixels[:, 0]), np.max(all_pixels[:, 0])
        min_y, max_y = np.min(all_pixels[:, 1]), np.max(all_pixels[:, 1])

        # **Determine whether the mosaic is wider or taller dynamically**
        width = max_x - min_x
        height = max_y - min_y

        print(f"Detected Bounding Box (X={min_x} to {max_x}, Y={min_y} to {max_y})")
        print(f"Calculated Mosaic Size: Width={width}, Height={height}")
        self.status_label.setText(f"Detected Bounding Box: X={min_x} to {max_x}, Y={min_y} to {max_y}")
        self.status_label.setText(f"Calculated Mosaic Size: Width={width}, Height={height}")
        QApplication.processEvents()

        return int(np.floor(min_x)), int(np.floor(min_y)), int(np.ceil(max_x)), int(np.ceil(max_y))

    def create_mosaic(self):
        """Finalize the mosaic (including blending/normalization) and push it to the image manager."""
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        self.finalize_mosaic()
        display_image = self.stretch_for_display(self.final_mosaic)
        mosaic_win = MosaicPreviewWindow(display_image, title="Final Mosaic", parent=self)
        mosaic_win.show()

    def finalize_mosaic(self):
        """Push the final mosaic (and its WCS metadata) to the image manager."""
        if self.final_mosaic is None:
            print("No mosaic to finalize.")
            return
        print("🔹 Pushing mosaic to image manager...")

        # Check if self.wcs_metadata exists and is nonempty.
        if not self.wcs_metadata or not any(self.wcs_metadata.values()):
            print("WCS metadata not available; creating minimal header.")
            # Determine if the final mosaic is mono.
            is_mono = (self.final_mosaic.ndim == 2 or (self.final_mosaic.ndim == 3 and self.final_mosaic.shape[2] == 1))
            minimal_header = self.create_minimal_fits_header(self.final_mosaic, is_mono)
            meta = dict(minimal_header)
        else:
            meta = dict(self.wcs_metadata)

        # If the final mosaic is 2D (grayscale), replicate it across three channels.
        final_img = self.final_mosaic
        if final_img.ndim == 2:
            final_img = np.stack([final_img, final_img, final_img], axis=-1)

        self.image_manager.set_image(final_img, metadata=meta, step_name="Mosaic Creation   ")
        print("✅ Mosaic pushed successfully.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.08

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # If the image is 2D, treat it as a single channel.
        if image.ndim == 2:
            # Process as a single channel:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")

            # Add back the original minimum
            image += original_min

            # Clip to [0, 1]
            image = np.clip(image, 0, 1)
            # Optionally, if you want to keep it 2D (since it was originally mono), just return image.
            # If you want to convert to a 3-channel image for display later, you can do that later.
            return image

        # Otherwise, if the image is 3D, process each channel
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel but has 3 dimensions now, convert it back.
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)

        return image


    # ---------- Blind Solve via Astrometry.net ----------
    def perform_blind_solve(self, item):
        """
        Performs a blind solve using Astrometry.net and constructs the WCS header directly.
        If any step fails (e.g. network error), prompts the user to try again.
        """
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return None

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine the file extension of the original image.
            ext = os.path.splitext(item["path"])[1].lower()
            # If the image is not already FITS or TIFF, convert it.
            if ext not in ('.fits', '.fit'):
                # Create a temporary file with a .fit extension.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close it so that save_image can write to it.

                # Generate a minimal FITS header from the image array.
                minimal_header = generate_minimal_fits_header(item["image"])

                # Save the image as a FITS file using the minimal header.
                # (Adjust bit_depth as needed.)
                save_image(
                    img_array=item["image"],
                    filename=temp_file.name,
                    original_format="fit",
                    bit_depth="16-bit",
                    original_header=minimal_header,
                    is_mono=item.get("is_mono", False)
                )
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return None

            # If we created a temporary file (i.e. the original file wasn’t FITS or TIFF), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)

            # Exit the loop once all steps have succeeded.
            break

        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        item["wcs"] = WCS(wcs_header)
        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    # ---------- Blind Solve via ASTAP ----------
    def attempt_astap_solve(self, item):
        """
        Attempt to plate-solve the image using ASTAP.
        Returns a solved header (as a dict) on success or None on failure.
        """
        # 1) Normalize the image (using your stretch_image).
        normalized_image = self.stretch_image(item["image"])
        
        # 2) Save normalized image to a temporary FITS file for ASTAP.
        try:
            tmp_path = self.save_temp_fits_image(normalized_image, item["path"])
        except Exception as e:
            print("Failed to save temporary FITS file:", e)
            return None

        # 3) Run ASTAP on the temporary file.
        process = QProcess(self)
        args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs", "-sip"]
        print("Running ASTAP with arguments:", args)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            os.remove(tmp_path)
            return None
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            os.remove(tmp_path)
            return None

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return None

        # 4) Retrieve updated header from the temporary file.
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove some extraneous keywords
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
        except Exception as e:
            print("Error reading solved header:", e)
            os.remove(tmp_path)
            return None

        # 5) Merge .wcs file (if ASTAP wrote one) into the solved_header.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                with open(wcs_path, "r") as f:
                    content = f.read()
                pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                for match in re.finditer(pattern, content):
                    key = match.group(1).strip().upper()
                    val = match.group(2).strip()
                    if val.startswith("'") and val.endswith("'"):
                        val = val[1:-1].strip()
                    solved_header[key] = val
            except Exception as e:
                print("Error reading .wcs file:", e)
            finally:
                try:
                    os.remove(wcs_path)
                except Exception as e:
                    print("Error removing .wcs file:", e)

        # Remove the END keyword if present
        solved_header.pop("END", None)
        # Remove any unneeded keywords
        for keyword in ["RANGE_LOW", "RANGE_HIGH", "HISTORY"]:
            solved_header.pop(keyword, None)

        # --- Ensure required WCS keys are present ---
        if "CTYPE1" not in solved_header or not solved_header["CTYPE1"].strip():
            solved_header["CTYPE1"] = "RA---TAN"
        if "CTYPE2" not in solved_header or not solved_header["CTYPE2"].strip():
            solved_header["CTYPE2"] = "DEC--TAN"
        if "RADECSYS" not in solved_header:
            solved_header["RADECSYS"] = "ICRS"
        if "WCSAXES" not in solved_header:
            solved_header["WCSAXES"] = 2

        # Convert known WCS keys to float or int
        expected_float_keys = {"CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2"}
        expected_int_keys = {"NAXIS", "WCSAXES"}

        for key in expected_float_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to float.")

        for key in expected_int_keys:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key}='{solved_header[key]}' to int.")

        try:
            save_image(
                img_array=normalized_image,
                filename=item["path"],  # Overwrite the original file
                original_format="fit",
                bit_depth="32",
                original_header=solved_header,  # Updated WCS header
                is_mono=False
            )
            print(f"✅ Updated FITS header with full WCS solution for {item['path']}.")
        except Exception as e:
            print("Error saving updated FITS file using save_image():", e)
            raise e


        # Remove the temporary FITS
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling


        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image



# --------------------------------------------------
# Star Stuff
# --------------------------------------------------      
class StellarAlignmentDialog(QDialog):
    def __init__(self, parent, settings, image_manager):
        """
        Parameters:
          parent: reference to the main window (AstroEditingSuite) so that helper methods
                  (e.g. detect_stars, estimate_transform_from_triangles) can be called.
          settings: QSettings instance (for working directory, etc.)
          image_manager: the ImageManager instance.
        """
        super().__init__(parent)
        self.setWindowTitle("Stellar Alignment")
        self.settings = settings
        self.image_manager = image_manager
        self.parent_window = parent  # for calling helper methods from the main window
        self.stellar_source = None
        self.stellar_target = None
        self.aligned_image = None
        self.autostretch_enabled = False  # Default: No autostretch
        self.source_was_mono = False
        self.target_was_mono = False
        self.initUI()

    def initUI(self):
        main_layout = QHBoxLayout(self)  # Use horizontal layout for side-by-side arrangement

        # ------------------------
        # Left Panel (Selection Controls)
        # ------------------------
        controls_layout = QVBoxLayout()

        # ------------------------
        # Source Image Group
        # ------------------------
        source_group = QGroupBox("Source Image (Reference)")
        source_layout = QVBoxLayout()

        # Radio buttons for selection type.
        source_radio_layout = QHBoxLayout()
        self.source_from_file_radio = QRadioButton("From File")
        self.source_from_slot_radio = QRadioButton("From Slot")
        self.source_from_slot_radio.setChecked(True)
        source_radio_layout.addWidget(self.source_from_file_radio)
        source_radio_layout.addWidget(self.source_from_slot_radio)
        source_layout.addLayout(source_radio_layout)

        # File selection controls for source.
        file_source_layout = QHBoxLayout()
        self.source_file_button = QPushButton("Select from File")
        self.source_file_button.clicked.connect(self.select_source_file)
        self.source_file_label = QLabel("No file selected")
        file_source_layout.addWidget(self.source_file_button)
        file_source_layout.addWidget(self.source_file_label)
        source_layout.addLayout(file_source_layout)

        # Slot selection controls for source.
        slot_source_layout = QHBoxLayout()
        self.source_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.source_slot_combo.addItem(slot_name, i)
        self.source_slot_button = QPushButton("Load from Slot")
        self.source_slot_button.clicked.connect(self.load_source_from_slot)
        slot_source_layout.addWidget(self.source_slot_combo)
        slot_source_layout.addWidget(self.source_slot_button)
        source_layout.addLayout(slot_source_layout)

        source_group.setLayout(source_layout)
        controls_layout.addWidget(source_group)

        # ------------------------
        # Target Image Group
        # ------------------------
        target_group = QGroupBox("Target Image (To be Aligned)")
        target_layout = QVBoxLayout()

        # Radio buttons for selection type.
        target_radio_layout = QHBoxLayout()
        self.target_from_file_radio = QRadioButton("From File")
        self.target_from_slot_radio = QRadioButton("From Slot")
        self.target_from_slot_radio.setChecked(True)
        target_radio_layout.addWidget(self.target_from_file_radio)
        target_radio_layout.addWidget(self.target_from_slot_radio)
        target_layout.addLayout(target_radio_layout)

        # File selection controls for target.
        file_target_layout = QHBoxLayout()
        self.target_file_button = QPushButton("Select from File")
        self.target_file_button.clicked.connect(self.select_target_file)
        self.target_file_label = QLabel("No file selected")
        file_target_layout.addWidget(self.target_file_button)
        file_target_layout.addWidget(self.target_file_label)
        target_layout.addLayout(file_target_layout)

        # Slot selection controls for target.
        slot_target_layout = QHBoxLayout()
        self.target_slot_combo = QComboBox()
        for i in range(self.image_manager.max_slots):
            slot_name = self.parent_window.slot_names.get(i, f"Slot {i}") if hasattr(self.parent_window, 'slot_names') else f"Slot {i}"
            self.target_slot_combo.addItem(slot_name, i)
        self.target_slot_button = QPushButton("Load from Slot")
        self.target_slot_button.clicked.connect(self.load_target_from_slot)
        slot_target_layout.addWidget(self.target_slot_combo)
        slot_target_layout.addWidget(self.target_slot_button)
        target_layout.addLayout(slot_target_layout)

        target_group.setLayout(target_layout)
        controls_layout.addWidget(target_group)

        # ------------------------
        # Run Alignment Button
        # ------------------------
        self.run_alignment_button = QPushButton("Run Alignment")
        self.run_alignment_button.clicked.connect(self.run_alignment)
        controls_layout.addWidget(self.run_alignment_button)

        # ------------------------
        # Status Label
        # ------------------------
        self.status_label = QLabel("Status: Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        controls_layout.addWidget(self.status_label)

        main_layout.addLayout(controls_layout)

        # ------------------------
        # Right Panel (Result Preview)
        # ------------------------
        result_layout = QVBoxLayout()
        result_group = QGroupBox("Aligned Image")

        # Preview label
        self.result_preview_label = QLabel()
        self.result_preview_label.setFixedSize(400, 400)
        self.result_preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        result_layout.addWidget(self.result_preview_label)

        # AutoStretch Button
        self.autostretch_button = QPushButton("AutoStretch: OFF")
        self.autostretch_button.clicked.connect(self.toggle_autostretch)
        result_layout.addWidget(self.autostretch_button)

        # Push to Active Slot Button
        self.push_active_button = QPushButton("Push to Active Slot")
        self.push_active_button.clicked.connect(self.push_aligned_to_active)
        result_layout.addWidget(self.push_active_button)

        result_group.setLayout(result_layout)
        main_layout.addWidget(result_group)

        self.setLayout(main_layout)

    def toggle_autostretch(self):
        if self.aligned_image is None:
            QMessageBox.warning(self, "Warning", "No aligned image available to apply autostretch.")
            return

        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.aligned_image  # Reset to the original image if stretch is disabled

        self.update_preview(self.result_preview_label, self.stretched_image)


    def apply_autostretch(self):
        if self.aligned_image is None:
            return  # or handle it as needed
        if len(self.aligned_image.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.aligned_image, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.aligned_image, target_median=0.25, linked=False, normalize=False)

    def update_preview(self, label, image):
        """
        Updates the QLabel to display a preview of the given image with optional autostretch.
        """
        if self.autostretch_enabled:
            image = np.clip(image * 255 / np.max(image), 0, 255).astype(np.uint8)  # Auto-stretch

        if image.ndim == 3 and image.shape[2] == 3:
            h, w, _ = image.shape
            qimg = QImage(image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif image.ndim == 2:
            h, w = image.shape
            qimg = QImage(image.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def detect_stars_by_grid(self, image, stars_per_region=4):
        # Convert to grayscale if needed.
        if image.ndim == 3 and image.shape[2] == 3:
            image_gray = np.mean(image, axis=2)
        else:
            image_gray = image

        H, W = image_gray.shape
        grid_rows, grid_cols = 3, 3
        cell_height, cell_width = H // grid_rows, W // grid_cols

        all_selected_stars = []

        # Precompute global statistics once.
        mean_val, median_val, std_val = sigma_clipped_stats(image_gray, sigma=3.0)
        daofind = DAOStarFinder(threshold=3 * std_val, fwhm=3.0)
        sources = daofind(image_gray - median_val)
        if sources is None or len(sources) == 0:
            return []

        x_coords = sources['xcentroid'].data
        y_coords = sources['ycentroid'].data
        flux = sources['flux'].data
        regions_used = 0
        # Package stars together (initially as 3-element tuples).
        stars = list(zip(x_coords, y_coords, flux))

        for i in range(grid_rows):
            for j in range(grid_cols):
                x_min = j * cell_width
                x_max = (j+1) * cell_width if j < grid_cols - 1 else W
                y_min = i * cell_height
                y_max = (i+1) * cell_height if i < grid_rows - 1 else H

                # Select stars in this region and attach the cell ID.
                cell_stars = [
                    (star[0], star[1], star[2], (i, j))
                    for star in stars
                    if (x_min <= star[0] < x_max and y_min <= star[1] < y_max)
                ]
                # Sort by brightness (flux) descending.
                cell_stars.sort(key=lambda s: s[2], reverse=True)
                if cell_stars:
                    regions_used += 1
                all_selected_stars.extend(cell_stars[:stars_per_region])
                # Update status for this region:
                self.status_label.setText(f"Region ({i},{j}): Found {len(cell_stars)} stars.")
                QApplication.processEvents()             

        # Optionally, remove duplicates and sort by brightness globally.
        all_selected_stars = list(set(all_selected_stars))
        all_selected_stars.sort(key=lambda s: s[2], reverse=True)
        return all_selected_stars

    # -----------------------------
    # RANSAC with Delaunay Triangulation for Alignment
    # -----------------------------
    @staticmethod
    def compute_triangle_invariant(tri_points):
        # tri_points: 3x2 array
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])

    @staticmethod
    def build_triangle_dict(coords):
        """
        coords: Nx2 array of (x,y) coordinates.
        Returns a dict mapping rounded invariant to list of triangles (vertex indices).
        """
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]  # 3x2 array
            inv = StellarAlignmentDialog.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    @staticmethod
    def match_triangles(src_dict, tgt_dict, tol=0.1):
        matches = []
        for inv_src, src_tris in src_dict.items():
            for inv_tgt, tgt_tris in tgt_dict.items():
                if abs(inv_src[0] - inv_tgt[0]) < tol and abs(inv_src[1] - inv_tgt[1]) < tol:
                    for s in src_tris:
                        for t in tgt_tris:
                            matches.append((s, t))
        return matches

    @staticmethod
    def ransac_affine(src_coords, tgt_coords, matches, ransac_iter=500, inlier_thresh=3.0, update_callback=None):
        best_inliers = 0
        best_transform = None
        tgt_tree = KDTree(tgt_coords)
        total = ransac_iter
        for i in range(ransac_iter):
            src_tri, tgt_tri = random.choice(matches)
            pts_src = np.float32([src_coords[j] for j in src_tri])
            pts_tgt = np.float32([tgt_coords[j] for j in tgt_tri])
            transform, _ = cv2.estimateAffine2D(pts_src.reshape(-1,1,2), pts_tgt.reshape(-1,1,2), method=cv2.LMEDS)
            if transform is None:
                continue
            src_aug = np.hstack([src_coords, np.ones((src_coords.shape[0], 1))])
            transformed = (transform @ src_aug.T).T
            inliers = 0
            for pt in transformed:
                dist, _ = tgt_tree.query(pt)
                if dist < inlier_thresh:
                    inliers += 1
            if inliers > best_inliers:
                best_inliers = inliers
                best_transform = np.eye(3, dtype=np.float32)
                best_transform[:2] = transform

            # Update progress if a callback is provided.
            if update_callback is not None and (i % 10 == 0 or i == total - 1):
                progress = int(100 * i / total)
                update_callback(f"RANSAC progress: {progress}% (Best inliers: {best_inliers})")
                QApplication.processEvents()
        return best_transform, best_inliers
    
    def estimate_transform_ransac(self, source_stars, target_stars):
        # Extract (x,y) from 4-tuples.
        src_coords = np.array([[s[0], s[1]] for s in source_stars])
        tgt_coords = np.array([[s[0], s[1]] for s in target_stars])
        self.status_label.setText("Computing Delaunay triangulation...")
        QApplication.processEvents()
        src_tri_dict = self.build_triangle_dict(src_coords)
        tgt_tri_dict = self.build_triangle_dict(tgt_coords)
        self.status_label.setText("Matching triangles...")
        QApplication.processEvents()
        matches = self.match_triangles(src_tri_dict, tgt_tri_dict, tol=0.1)
        if len(matches) == 0:
            self.status_label.setText("No triangle matches found!")
            return None, 0
        self.status_label.setText(f"Found {len(matches)} candidate triangle matches. Running RANSAC...")
        QApplication.processEvents()
        # Provide a callback to update status during RANSAC.
        update_callback = lambda msg: self.status_label.setText(msg)
        best_transform, best_inliers = self.ransac_affine(src_coords, tgt_coords, matches, ransac_iter=1000, inlier_thresh=3.0, update_callback=update_callback)
        return best_transform, best_inliers
    
    def select_source_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Source Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            self.source_was_mono = bool(is_mono)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load source image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_source = image
            self.source_file_label.setText(path)


    def select_target_file(self):
        default_dir = self.settings.value("working_directory", "")
        path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Target Image", 
            default_dir,
            "Images (*.fits *.fit *.xisf *.tif *.tiff *.png *.jpg);;All Files (*)"
        )
        if path:
            image, header, bit_depth, is_mono = load_image(path)
            self.target_was_mono = bool(is_mono)
            if image is None:
                QMessageBox.warning(self, "Error", "Failed to load target image.")
                return
            if image.ndim == 2:
                image = np.stack([image]*3, axis=-1)
            self.stellar_target = image
            self.target_file_label.setText(path)


    def load_source_from_slot(self):
        index = self.source_slot_combo.currentData()
        image = self.image_manager._images.get(index)

        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            self.source_was_mono = True
            image = np.stack([image]*3, axis=-1)
        self.stellar_source = image
        self.source_file_label.setText(f"Loaded from Slot {index}")

    def load_target_from_slot(self):
        index = self.target_slot_combo.currentData()
        image = self.image_manager._images.get(index)
        if image is None:
            QMessageBox.warning(self, "Error", f"Slot {index} is empty.")
            return
        if image.ndim == 2:
            self.target_was_mono = True
            image = np.stack([image]*3, axis=-1)
        self.stellar_target = image
        self.target_file_label.setText(f"Loaded from Slot {index}")

    def update_preview(self, label, image):
        """
        Update a QLabel to display a preview of the given image.
        For display purposes, convert to 8-bit if needed.
        """
        # For display only, convert float32 in [0,1] to 8-bit.
        if image.dtype == np.float32:
            disp = np.clip(image * 255, 0, 255).astype(np.uint8)
        else:
            disp = image
        if disp.ndim == 3 and disp.shape[2] == 3:
            h, w, _ = disp.shape
            qimg = QImage(disp.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        elif disp.ndim == 2:
            h, w = disp.shape
            qimg = QImage(disp.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            return
        scaled = qimg.scaled(label.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        label.setPixmap(QPixmap.fromImage(scaled))

    def select_corner_stars(self, stars, image_shape, margin=0.15):
        """
        Selects stars that are near the corners (or edges) of the image.
        stars: list of tuples (x, y, flux, cell_id)
        image_shape: (H, W)
        margin: fractional distance from the border
        """
        H, W = image_shape
        selected = []
        for star in stars:
            x, y, _, _ = star
            # Choose stars near left/right and top/bottom margins.
            if (x < margin * W or x > (1 - margin) * W) and (y < margin * H or y > (1 - margin) * H):
                selected.append((x, y))
        return selected

    def _aa_find_transform_with_backoff(self, tgt_gray: np.ndarray,
                                        src_gray: np.ndarray):
        """Robust wrapper around astroalign.find_transform with fallbacks."""
        # SEP is happiest with float32 & C-contiguous arrays
        tgt32 = np.ascontiguousarray(tgt_gray.astype(np.float32))
        src32 = np.ascontiguousarray(src_gray.astype(np.float32))

        # Optional: increase SEP's pixel stack once up front for crowded fields
        try:
            curr = sep.get_extract_pixstack()  # default ~300_000
            if curr < 1_500_000:
                sep.set_extract_pixstack(1_500_000)
        except Exception:
            pass

        # Try normal settings first; then progressively stricter detection
        tries = [
            dict(detection_sigma=5,  min_area=7,  max_control_points=75),
            dict(detection_sigma=12, min_area=9,  max_control_points=75),
            dict(detection_sigma=20, min_area=9, max_control_points=75),
            dict(detection_sigma=30, min_area=11, max_control_points=75),
            dict(detection_sigma=50, min_area=11, max_control_points=75),  # your request
        ]

        last_exc = None
        for kw in tries:
            try:
                return astroalign.find_transform(tgt32, src32, **kw)
            except Exception as e:
                last_exc = e
                # If SEP still overflows, try bumping the pixstack more and continue
                if "internal pixel buffer full" in str(e).lower():
                    try:
                        sep.set_extract_pixstack(int(sep.get_extract_pixstack() * 2))
                    except Exception:
                        pass
                continue
        raise last_exc

    def run_alignment(self):
        # Ensure both source and target images are loaded.
        if self.source_from_slot_radio.isChecked() and self.stellar_source is None:
            self.load_source_from_slot()
        if self.target_from_slot_radio.isChecked() and self.stellar_target is None:
            self.load_target_from_slot()
        if self.stellar_source is None:
            QMessageBox.warning(self, "Error", "Please select a source image.")
            return
        if self.stellar_target is None:
            QMessageBox.warning(self, "Error", "Please select a target image.")
            return

        # Convert images to grayscale for astroalign computations.
        src = self.stellar_source
        tgt = self.stellar_target
        if src.ndim == 3:
            src_gray = np.mean(src, axis=2)
        else:
            src_gray = src
        if tgt.ndim == 3:
            tgt_gray = np.mean(tgt, axis=2)
        else:
            tgt_gray = tgt

        self.status_label.setText("Computing alignment with astroalign...")
        QApplication.processEvents()

        try:
            # Compute the transform to align the target image to the source.
            # Note: The order of arguments matters: here we find a transform that maps tgt_gray to src_gray.
            transform_obj, (src_pts, tgt_pts) = self._aa_find_transform_with_backoff(tgt_gray, src_gray)
            # Extract the 3x3 matrix and convert it to a 2x3 affine matrix.
            mat_3x3 = transform_obj.params
            affine_transform = mat_3x3[0:2, :]
        except Exception as e:
            QMessageBox.warning(self, "Alignment Error", f"Astroalign failed: {e}")
            return

        self.status_label.setText("Warping target image with astroalign transform...")
        QApplication.processEvents()

        H, W = src.shape[:2]
        # Apply the computed transform to the target image.
        if tgt.ndim == 2:
            warped_target = cv2.warpAffine(tgt, affine_transform, (W, H), flags=cv2.INTER_LANCZOS4)
        else:
            channels = []
            for i in range(tgt.shape[2]):
                warped_channel = cv2.warpAffine(
                    tgt[:, :, i],
                    affine_transform,
                    (W, H),
                    flags=cv2.INTER_LANCZOS4
                )
                channels.append(warped_channel)
            warped_target = np.stack(channels, axis=2)

        self.aligned_image = warped_target
        self.status_label.setText("Alignment complete with astroalign.")
        self.update_preview(self.result_preview_label, warped_target)

        # Optionally, display the transformation matrix details.
        transform_3x3 = np.eye(3, dtype=np.float32)
        transform_3x3[:2] = affine_transform
        self.show_transform_info(transform_3x3)

        QMessageBox.information(self, "Alignment Complete", "Alignment completed using astroalign.")



    def show_transform_info(self, matrix):
        """
        Decomposes the 3x3 affine matrix and displays its translation, scaling,
        rotation (in degrees), and skew (shear) in a pop-up dialog.
        """
        # Assuming matrix is of the form:
        # [[a, b, tx],
        #  [c, d, ty],
        #  [0, 0, 1]]
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]

        # Compute translation directly.
        translation = (tx, ty)

        # Compute scale in x as the length of the first column.
        scale_x = np.sqrt(a * a + c * c)
        # The rotation angle (in degrees) is the arctan of (c/a)
        rotation_rad = np.arctan2(c, a)
        rotation_deg = np.degrees(rotation_rad)

        # Compute shear (skew). One common formula is:
        shear = (a * b + c * d) / (a * a + c * c)
        # Compute scale_y using the formula:
        # det(A) = a*d - b*c = scale_x * scale_y  => scale_y = det / scale_x
        det = a * d - b * c
        scale_y = det / scale_x

        # Alternatively, you can compute scale_y with a method that accounts for shear:
        # scale_y_alt = np.sqrt(b * b + d * d - shear * shear * (a * a + c * c))
        # (Usually the two values should be similar for well-behaved transforms.)

        info_text = (
            f"Transformation Matrix:\n\n"
            f"[{a:.3f}  {b:.3f}  {tx:.3f}]\n"
            f"[{c:.3f}  {d:.3f}  {ty:.3f}]\n"
            f"[0.000  0.000  1.000]\n\n"
            f"Translation: (tx, ty) = ({tx:.3f}, {ty:.3f})\n"
            f"Scaling: scale_x = {scale_x:.3f}, scale_y = {scale_y:.3f}\n"
            f"Rotation: {rotation_deg:.2f}°\n"
            f"Skew (shear): {shear:.3f}\n"
        )

        # Create a dialog to display the transformation details.
        info_dialog = QDialog(self)
        info_dialog.setWindowTitle("Transformation Matrix Details")
        layout = QVBoxLayout(info_dialog)

        text_edit = QTextEdit(info_dialog)
        text_edit.setReadOnly(True)
        text_edit.setText(info_text)
        layout.addWidget(text_edit)

        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok, info_dialog)
        button_box.accepted.connect(info_dialog.accept)
        layout.addWidget(button_box)

        info_dialog.show()

    def push_aligned_to_active(self):
        """
        Push the aligned image (if available) to the active slot in the image manager.
        """
        if self.aligned_image is None:
            QMessageBox.warning(self, "Error", "No aligned image available. Run alignment first.")
            return
        # If the target was mono, collapse back to 2D
        img_to_push = self.aligned_image
        if self.target_was_mono and img_to_push.ndim == 3 and img_to_push.shape[2] == 3:
            img_to_push = img_to_push[..., 0]

        metadata = {
            "description": "Stellar aligned image",
            "is_mono": bool(self.target_was_mono)
        }
        # Push through the undo-aware API:
        self.image_manager.set_image(new_image=img_to_push,
                                     metadata=metadata,
                                     step_name="Stellar Alignment")
        QMessageBox.information(self, "Pushed", "Aligned image pushed to the active slot.")
        self.accept()

#############################################
# Worker Signals for Registration Workers
#############################################
class RegistrationWorkerSignals(QObject):
    progress = pyqtSignal(str)           # e.g., "Loaded image X"
    result = pyqtSignal(str)             # e.g., "Saved aligned file path"
    error = pyqtSignal(str)              # e.g., error message
    result_transform = pyqtSignal(str, object)  
    #          ^^^^^^^^^^^^^^^^^^^^^^^
    #  We'll emit (orig_file_path, transform_matrix)

#############################################
# Worker to Process One Image Registration
#############################################
class StarRegistrationWorker(QRunnable):
    def __init__(self, file_path, original_file, current_transform,
                 ref_stars, ref_triangles, output_directory, 
                 use_triangle=False, use_astroalign=False, reference_image=None, downsample_factor: int = 2):
        super().__init__()
        # file_path is used for naming only; always load the raw image from original_file.
        self.file_path = file_path  
        self.original_file = original_file  # persistent key (raw image path)
        self.current_transform = current_transform if current_transform is not None else IDENTITY_2x3
        self.ref_stars = ref_stars
        self.ref_triangles = ref_triangles
        self.output_directory = output_directory
        self.use_triangle = use_triangle
        self.use_astroalign = use_astroalign
        self.reference_image = reference_image  # 2D reference image
        self.downsample_factor = downsample_factor
        self.signals = RegistrationWorkerSignals()

    def run(self):
        try:
            # 1) Load the raw image
            raw_img, img_header, img_bit_depth, img_is_mono = load_image(self.original_file)
            if raw_img is None:
                self.signals.error.emit(f"Could not load {self.original_file}")
                return

            # 2) Apply current cumulative transform to get the candidate image
            candidate_img = StarRegistrationThread.apply_affine_transform_static(raw_img, self.current_transform)
            if candidate_img is None:
                self.signals.error.emit(f"Failed to apply current transform to {self.original_file}")
                return

            # 3) Flatten to 2D if needed
            if candidate_img.ndim == 3:
                img_for_alignment = np.mean(candidate_img, axis=2)
            else:
                img_for_alignment = candidate_img

            # 4) Clean up any NaNs/infs
            if np.isnan(img_for_alignment).any() or np.isinf(img_for_alignment).any():
                img_for_alignment = np.nan_to_num(img_for_alignment, nan=0.0, posinf=0.0, neginf=0.0)

            # 5) Downsample both reference & target
            f = getattr(self, "downsample_factor", 1)
            h, w = img_for_alignment.shape[:2]
            if f > 1:
                small = lambda im: cv2.resize(im, (w // f, h // f), interpolation=cv2.INTER_AREA)
                use_ref = small(self.reference_image)
                use_img = small(img_for_alignment)
            else:
                use_ref, use_img = self.reference_image, img_for_alignment

            # 6) Try astroalign *on the downsampled images* first
            # 6) Try Astroalign (no fallback)
            transform = None
            if use_ref is not None and use_ref.ndim == 2:
                transform = self.compute_affine_transform_astroalign(use_img, use_ref)

            if transform is None:
                # if Astroalign fails, bail out immediately
                self.signals.error.emit(
                    f"Astroalign failed for {os.path.basename(self.file_path)} – skipping"
                )
                return

            # report success
            self.signals.progress.emit(
                f"Astroalign delta for {os.path.basename(self.file_path)}: "
                f"dx={transform[0,2]:.2f}, dy={transform[1,2]:.2f}"
            )

            # 8) Upscale the small-image translation back to full resolution
            transform = np.array(transform, dtype=np.float64).reshape(2, 3)
            if f > 1:
                transform[0, 2] *= f
                transform[1, 2] *= f

            # 9) Build the cumulative full-res transform
            current_transform = np.array(self.current_transform, dtype=np.float64).reshape(2, 3)
            new_3x3 = np.vstack([transform, [0, 0, 1]])
            curr_3x3 = np.vstack([current_transform, [0, 0, 1]])
            T_total = (new_3x3 @ curr_3x3)[:2, :]

            # 10) Emit the delta so parent updates its record
            self.signals.result_transform.emit(self.original_file, transform)

            # 11) Apply the full-resolution cumulative transform
            aligned_image = StarRegistrationThread.apply_affine_transform_static(raw_img, T_total)
            if aligned_image is None:
                self.signals.error.emit(f"Transform application failed for {self.original_file}")
                return
            if np.isnan(aligned_image).any() or np.isinf(aligned_image).any():
                self.signals.error.emit(f"Aligned image for {self.original_file} contains NaNs/Infs")
                return

            # 12) Save the final aligned frame
            base = os.path.basename(self.file_path)
            name, ext = os.path.splitext(base)
            if not (name.endswith("_r") or name.endswith("_n_r")):
                name += "_r"
            output_filename = os.path.join(self.output_directory, f"{name}.fit")

            save_image(
                img_array=aligned_image,
                filename=output_filename,
                original_format="fit",
                bit_depth=img_bit_depth,
                original_header=img_header,
                is_mono=img_is_mono
            )
            self.signals.result.emit(output_filename)
            self.signals.progress.emit(f"Registered {os.path.basename(self.file_path)}")

        except Exception as e:
            self.signals.error.emit(f"Error processing {self.original_file}: {e}")

    @staticmethod
    def compute_affine_transform_astroalign(source_img, reference_img):
        try:
            transform_obj, _ = astroalign.find_transform(source_img, reference_img)
            return transform_obj.params[0:2, :]
        except Exception as e:
            print(f"DEBUG: astroalign failed: {e}")
            return None

      


#############################################
# Main Star Registration Thread (Concurrent)
#############################################
# Identity transform (2x3)
IDENTITY_2x3 = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float64)

class StarRegistrationThread(QThread):
    progress_update = pyqtSignal(str)
    registration_complete = pyqtSignal(bool, str)
    progress_step = pyqtSignal(int, int)  # (done, total)

    def __init__(self, reference_image_path, files_to_align, output_directory, 
                 max_refinement_passes=3, shift_tolerance=0.2):
        super().__init__()
        self.reference_image_path = os.path.normpath(reference_image_path)
        # First, assign original_files.
        self.original_files = [os.path.normpath(f) for f in files_to_align]
        # Copy original_files to files_to_align.
        self.files_to_align = self.original_files.copy()
        self.output_directory = os.path.normpath(output_directory)
        self.max_refinement_passes = max_refinement_passes
        self.shift_tolerance = shift_tolerance
        # Mapping: persistent key (raw file) -> current working file.
        self.file_key_to_current_path = {f: f for f in self.original_files}
        # Store cumulative transforms keyed by the persistent (raw) file path.
        self.alignment_matrices = {}
        self.transform_deltas = []  # List of shift arrays per pass.
        self._done = 0
        self._total = len(self.original_files) * self.max_refinement_passes        

    def run(self):
        try:
            # Load reference image.
            ref_image, _, _, _ = load_image(self.reference_image_path)
            if ref_image is None:
                self.registration_complete.emit(False, "Reference image failed to load!")
                return

            # Convert to 2D if needed.
            if ref_image.ndim == 3:
                ref_image = np.mean(ref_image, axis=2)
            ref_image = np.nan_to_num(ref_image, nan=0.0, posinf=0.0, neginf=0.0)
            self.reference_image_2d = ref_image    

            # Detect reference stars.
            ref_stars = self.detect_stars(ref_image)
            if len(ref_stars) < 10:
                self.registration_complete.emit(False, "Insufficient stars in reference image!")
                return
            ref_triangles = self.build_triangle_dict(ref_stars)

            # --- Pre-save all files with the _n_r suffix ---
            pre_saved_files = []
            for fpath in self.files_to_align:
                image, header, fmt, bit_depth = load_image(fpath)
                if image is None:
                    self.progress_update.emit(f"Error loading {fpath} during pre-save.")
                    continue
                base = os.path.basename(fpath)
                name, ext = os.path.splitext(base)
                # Remove trailing _n if present.
                if name.endswith("_n"):
                    name = name[:-2]
                if not name.endswith("_n_r"):
                    name += "_n_r"
                pre_saved = os.path.join(self.output_directory, f"{name}.fit")
                save_image(
                    img_array=image,
                    filename=pre_saved,
                    original_format="fit",
                    bit_depth=bit_depth,
                    original_header=header,
                    is_mono=(image.ndim == 2)
                )
                pre_saved_files.append(pre_saved)
                self.progress_update.emit(f"Pre-saved {base} as {os.path.basename(pre_saved)}")
            self.files_to_align = pre_saved_files

            # --- Registration Passes ---
            for pass_idx in range(self.max_refinement_passes):
                self.progress_update.emit(
                    f"⏳ Refinement Pass {pass_idx+1}/{self.max_refinement_passes}..."
                )
                success, msg = self.run_one_registration_pass(ref_stars, ref_triangles, pass_idx)
                if not success:
                    any_aligned = any(x is not None for x in self.alignment_matrices.values())
                    if not any_aligned:
                        self.registration_complete.emit(False, "No frames could be aligned. Aborting.")
                        return
                    else:
                        self.progress_update.emit("Partial success: some frames permanently failed.")
                        break

                if self.transform_deltas and max(self.transform_deltas[-1]) < self.shift_tolerance:
                    self.progress_update.emit("✅ Convergence reached! Stopping refinement.")
                    break

            # Final rejection check using delta shifts only.
            final_shifts = self.transform_deltas[-1]  # Delta shifts from the last pass.
            old_files = self.files_to_align
            new_files = []
            rejected_files = []
            for f, delta in zip(old_files, final_shifts):
                # If the delta shift (the correction computed in the final pass)
                # exceeds 2 pixels, reject the frame.
                if delta > 2.0:
                    rejected_files.append(f)
                else:
                    new_files.append(f)
            self.files_to_align = new_files

            if rejected_files:
                self.progress_update.emit(
                    f"🚨 Rejected {len(rejected_files)} frame(s) due to shift >2px or rotation >2°."
                )

            aligned_count = sum(1 for v in self.alignment_matrices.values() if v is not None)
            total_count = len(self.alignment_matrices)
            summary = f"Registration complete. Valid frames: {aligned_count}/{total_count}."
            self.registration_complete.emit(True, summary)

        except Exception as e:
            self.registration_complete.emit(False, f"Error: {e}")

    def _increment_progress(self):
        self._done += 1
        self.progress_step.emit(self._done, self._total)


    def run_one_registration_pass(self, ref_stars, ref_triangles, pass_index):
        pool = QThreadPool.globalInstance()
        num_cores = os.cpu_count() or 4
        pool.setMaxThreadCount(num_cores)
        self.progress_update.emit(f"Using {num_cores} cores for pass {pass_index+1}.")

        # New mappings for this pass.
        transformed_files = {}
        remaining_files = {}
        skipped_files = []  # List to track skipped images

        use_astroalign = (pass_index < 4)
        for original_file, current_file in self.file_key_to_current_path.items():
            # Get current cumulative transform for persistent key.
            current_transform = self.alignment_matrices.get(original_file, IDENTITY_2x3)
            worker = StarRegistrationWorker(
                file_path=current_file,
                original_file=original_file,
                current_transform=current_transform,
                ref_stars=ref_stars,
                ref_triangles=ref_triangles,
                output_directory=self.output_directory,
                use_triangle=False,
                use_astroalign=True,
                reference_image=self.reference_image_2d,
                downsample_factor=2
            )
            worker.signals.progress.connect(self.on_worker_progress)
            worker.signals.error.connect(self.on_worker_error)
            worker.signals.result.connect(self._increment_progress)
            worker.signals.result_transform.connect(self.on_worker_result_transform)

            pool.start(worker)
        
        pool.waitForDone()
        
        pass_deltas = []
        aligned_count = 0

        # Iterate over the persistent mapping using the delta shift computed in this pass.
        for original_file, current_file in self.file_key_to_current_path.items():
            # Use the delta shift from the current pass; default to 0 if none.
            delta_shift = self.delta_transforms.get(original_file, 0.0)
            pass_deltas.append(delta_shift)
            # If the delta is above threshold (e.g., 0.2 pixels), update the file.
            if delta_shift > 0.2:
                # Load current working file and re-apply cumulative transform.
                image, original_header, original_format, bit_depth = load_image(current_file)
                transformed_image = self.apply_affine_transform_static(image, self.alignment_matrices.get(original_file))
                if transformed_image is not None and (np.isnan(transformed_image).any() or np.isinf(transformed_image).any()):
                    transformed_image = np.nan_to_num(transformed_image, nan=0.0)
                base = os.path.basename(current_file)
                name, ext = os.path.splitext(base)
                if not (name.endswith("_r") or name.endswith("_n_r")):
                    name += "_r"
                transformed_path = os.path.join(self.output_directory, f"{name}.fit")
                save_image(
                    img_array=transformed_image,
                    filename=transformed_path,
                    original_format="fit",
                    bit_depth=bit_depth,
                    original_header=original_header,
                    is_mono=False
                )
                transformed_files[original_file] = transformed_path

            else:
                # Delta is small, so we consider this frame converged.
                remaining_files[original_file] = current_file
                aligned_count += 1
                skipped_files.append(os.path.basename(current_file))  # Log the filename
                
        self.transform_deltas.append(pass_deltas)
        # Update the persistent mapping for the next pass.
        self.file_key_to_current_path = {**transformed_files, **remaining_files}

        preview = ", ".join([f"{d:.2f}" for d in pass_deltas[:10]])
        if len(pass_deltas) > 10:
            preview += f" ... ({len(pass_deltas)} total)"
        self.progress_update.emit(f"Pass {pass_index+1} delta shifts: [{preview}]")
        
        # Emit a message listing skipped images if any.
        if skipped_files:
            self.progress_update.emit(f"Skipped images (delta shift < 0.2px): {', '.join(skipped_files)}")

        if aligned_count == 0:
            return False, "All frames already aligned within tolerance."
        failed_count = len(self.file_key_to_current_path) - aligned_count
        if failed_count > 0:
            return True, f"Pass complete. {failed_count} frame(s) failed."
        return True, "Pass complete (all succeeded)."

    def on_worker_result_transform(self, persistent_key, new_transform):
        persistent_key = os.path.normpath(persistent_key)
        # Ensure new_transform is a float64 array with shape (2,3)
        new_transform = np.array(new_transform, dtype=np.float64).reshape(2, 3)
        # Compute the delta shift (from the delta transform)
        delta_shift = np.sqrt(new_transform[0,2]**2 + new_transform[1,2]**2)
        # Record the delta shift in a new dictionary.
        if not hasattr(self, 'delta_transforms'):
            self.delta_transforms = {}
        self.delta_transforms[persistent_key] = delta_shift

        # Now update the cumulative transform.
        prev_transform = self.alignment_matrices.get(persistent_key)
        if prev_transform is not None:
            prev_transform = np.array(prev_transform, dtype=np.float64).reshape(2, 3)
            prev_3x3 = np.vstack([prev_transform, [0, 0, 1]])
            new_3x3 = np.vstack([new_transform, [0, 0, 1]])
            combined = new_3x3 @ prev_3x3
            self.alignment_matrices[persistent_key] = combined[0:2, :]
        else:
            self.alignment_matrices[persistent_key] = new_transform

        print(f"Persistent key: {persistent_key}")
        print(f"T_delta:\n{new_transform}")
        print(f"Delta shift: {delta_shift}")


    
    def on_worker_progress(self, msg):
        self.progress_update.emit(msg)

    def on_worker_error(self, msg):
        self.progress_update.emit("Error: " + msg)

    def on_worker_result(self, out):
        print("Saved: " + out)


    def detect_stars(self, image):
        """
        Run DAOStarFinder multiple times with different FWHMs,
        then combine (deduplicate) the results.
        """
        self.progress_update.emit(f"✨ Detecting all stars in reference frame")
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        mean, median, std = sigma_clipped_stats(image)
        
        # A range of FWHMs you want to try
        fwhm_list = [2.5, 3, 3.5, 4, 5, 6, 7]
        
        all_sources = []
        for fwhm in fwhm_list:
            daofind = DAOStarFinder(fwhm=fwhm, threshold=4 * std)
            sources = daofind(image - median)
            if sources is not None and len(sources) > 0:
                all_sources.append(sources)

        # If we never found any stars, return empty
        if not all_sources:
            return np.empty((0, 2), dtype=np.float32)

        # 1) Combine them all into a single table
        combined_sources = vstack(all_sources)  # Astropy Table vertical stack

        # 2) Optionally remove duplicates
        #    E.g. we can round the (x,y) to 1 decimal place and do a unique operation.
        #    This helps if the same star is found at slightly different coords in different FWHM passes.
        x_rounded = np.round(combined_sources['xcentroid'], 1)
        y_rounded = np.round(combined_sources['ycentroid'], 1)
        xy_rounded = np.array([x_rounded, y_rounded]).T
        
        # We'll build a dictionary to track unique (x_rounded, y_rounded)
        seen = {}
        unique_rows = []
        for i, (rx, ry) in enumerate(xy_rounded):
            key = (rx, ry)
            if key not in seen:
                seen[key] = True
                unique_rows.append(i)

        final_sources = combined_sources[unique_rows]
        
        # Convert to Nx2 NumPy array
        star_coords = np.vstack([final_sources['xcentroid'], final_sources['ycentroid']]).T
        return star_coords.astype(np.float32)

    def build_triangle_dict(self, coords):
        tri = Delaunay(coords)
        tri_dict = {}
        for simplex in tri.simplices:
            pts = coords[simplex]
            inv = self.compute_triangle_invariant(pts)
            if inv is None:
                continue
            inv_key = (round(inv[0], 2), round(inv[1], 2))
            tri_dict.setdefault(inv_key, []).append(simplex)
        return tri_dict

    def compute_triangle_invariant(self, tri_points):
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        
        if sides[0] == 0:
            return None  # Prevent division by zero
        
        # Use higher precision (4 decimal places instead of 2)
        return (round(sides[1] / sides[0], 4), round(sides[2] / sides[0], 4))

    @staticmethod
    def compute_triangle_invariant_static(tri_points):
        """
        Compute the invariant for a triangle defined by three points.
        Returns a tuple (side2/side1, side3/side1) if valid, otherwise None.
        This invariant is independent of scale and rotation.
        """
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1] / sides[0], sides[2] / sides[0])



        


    @staticmethod
    def detect_grid_stars_static_fast(
        image,
        blur_size=9,
        threshold_factor=0.6,
        min_area=1,
        max_area=10000
    ):
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        h, w = image.shape
        margin_x = int(w * 0.05)
        margin_y = int(h * 0.05)
        valid_x_min, valid_x_max = margin_x, w - margin_x
        valid_y_min, valid_y_max = margin_y, h - margin_y

        # Divide the image into a 4x4 grid
        grid_x = np.linspace(valid_x_min, valid_x_max, 4, dtype=int)
        grid_y = np.linspace(valid_y_min, valid_y_max, 4, dtype=int)

        stars = []
        for i in range(len(grid_x) - 1):
            for j in range(len(grid_y) - 1):
                x_min, x_max = grid_x[i], grid_x[i+1]
                y_min, y_max = grid_y[j], grid_y[j+1]
                sub_img = image[y_min:y_max, x_min:x_max]
                if sub_img.size == 0:
                    continue

                # Check if there's enough variance to detect stars
                if np.std(sub_img) > 0:
                    # Detect stars in this subregion
                    local_stars = fast_star_detect(
                        sub_img,
                        blur_size=blur_size,
                        threshold_factor=threshold_factor,
                        min_area=min_area,
                        max_area=max_area
                    )

                    shifted_stars = []
                    for (sx, sy) in local_stars:
                        # Skip any star coordinates that are NaN
                        if np.isnan(sx) or np.isnan(sy):
                            continue
                        gx = np.clip(sx + x_min, valid_x_min, valid_x_max - 1)
                        gy = np.clip(sy + y_min, valid_y_min, valid_y_max - 1)
                        shifted_stars.append((gx, gy))

                    # Optionally filter again (just in case)
                    filtered_stars = [s for s in shifted_stars if not (np.isnan(s[0]) or np.isnan(s[1]))]

                    # Sort by brightness in the global image (casting to int for indexing)
                    sorted_stars = sorted(
                        filtered_stars,
                        key=lambda s: image[int(s[1]), int(s[0])],
                        reverse=True
                    )
                    # Keep only the top 50 stars from this subregion
                    stars.extend(sorted_stars[:20])

        if len(stars) == 0:
            return np.empty((0,2), dtype=np.float32)

        return np.array(stars, dtype=np.float32)

    @staticmethod
    def detect_grid_stars_static(
        image,
        fwhm_list=[2.5, 3, 3.5, 4, 5],
        threshold_factor=4,  # multiplied by std
        min_area=1,
        max_area=10000
    ):

        # If the image is color, average it to produce a single channel.
        print("detecting grid stars dao")
        if image.ndim == 3:
            image = np.mean(image, axis=2)

        h, w = image.shape
        margin_x = int(w * 0.05)
        margin_y = int(h * 0.05)
        valid_x_min, valid_x_max = margin_x, w - margin_x
        valid_y_min, valid_y_max = margin_y, h - margin_y

        # Divide the image into a 4x4 grid.
        grid_x = np.linspace(valid_x_min, valid_x_max, 4, dtype=int)
        grid_y = np.linspace(valid_y_min, valid_y_max, 4, dtype=int)

        stars = []
        for i in range(len(grid_x) - 1):
            for j in range(len(grid_y) - 1):
                x_min, x_max = grid_x[i], grid_x[i+1]
                y_min, y_max = grid_y[j], grid_y[j+1]
                sub_img = image[y_min:y_max, x_min:x_max]
                if sub_img.size == 0:
                    continue

                # Only process subregions with sufficient variance.
                if np.std(sub_img) > 0:
                    # Compute sigma-clipped stats for thresholding.
                    mean, median, std = sigma_clipped_stats(sub_img)
                    # Try each FWHM value.
                    for fwhm in fwhm_list:
                        daofind = DAOStarFinder(fwhm=fwhm, threshold=threshold_factor * std)
                        sources = daofind(sub_img - median)
                        if sources is not None and len(sources) > 0:
                            # Convert the astropy Table to a NumPy array of (x, y) coordinates.
                            local_stars = np.column_stack((sources['xcentroid'], sources['ycentroid']))
                            shifted_stars = []
                            for (sx, sy) in local_stars:
                                # Skip any NaN values.
                                if np.isnan(sx) or np.isnan(sy):
                                    continue
                                # Shift to global image coordinates.
                                gx = np.clip(sx + x_min, valid_x_min, valid_x_max - 1)
                                gy = np.clip(sy + y_min, valid_y_min, valid_y_max - 1)
                                shifted_stars.append((gx, gy))
                            # Optionally, filter out any remaining NaNs.
                            filtered_stars = [s for s in shifted_stars if not (np.isnan(s[0]) or np.isnan(s[1]))]
                            # Sort by brightness using the pixel value in the global image.
                            sorted_stars = sorted(
                                filtered_stars,
                                key=lambda s: image[int(s[1]), int(s[0])],
                                reverse=True
                            )
                            # Keep the top 20 stars from this subregion for this FWHM.
                            stars.extend(sorted_stars[:20])
        if len(stars) == 0:
            return np.empty((0, 2), dtype=np.float32)
        return np.array(stars, dtype=np.float32)


    @staticmethod
    def compute_affine_transform_with_ransac_static(img_stars, ref_stars, ref_triangles, max_attempts=20, max_iter=20, convergence_thresh=0.2):
        print("DEBUG: Starting compute_affine_transform_with_ransac_static")
        attempt = 0
        transform = None
        while attempt < max_attempts:
            attempt += 1
            print(f"DEBUG: Initial RANSAC attempt {attempt}")
            matches = []
            for img_star in img_stars:
                distances = np.linalg.norm(ref_stars - img_star, axis=1)
                closest_idx = np.argmin(distances)
                #if distances[closest_idx] < 20:
                #    matches.append((img_star, ref_stars[closest_idx]))
                matches.append((img_star, ref_stars[closest_idx]))
            print(f"DEBUG: Found {len(matches)} matches on attempt {attempt}")
            if len(matches) < 5:
                print("DEBUG: Not enough matches; continuing to next attempt.")
                continue
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            rough_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=3.0
            )
            # -----------------------------
            # CHECK for NaN => fallback
            # -----------------------------
            if rough_transform is not None:
                if np.isnan(rough_transform).any() or np.isinf(rough_transform).any():
                    print("DEBUG: Rough transform has NaN => trying triangles fallback.")
                    fallback = StarRegistrationThread.compute_affine_transform_from_triangles(
                        img_stars, ref_stars, ref_triangles
                    )
                    if fallback is not None:
                        print("DEBUG: Fallback worked; using triangle-based transform.")
                        transform = fallback
                        break
                    else:
                        rough_transform = None  # Force next attempt
                else:
                    # No NaN => check validity
                    if StarRegistrationThread.is_valid_transform_static(rough_transform):
                        transform = rough_transform
                        print("DEBUG: Rough transform computed successfully.")
                        break
                    else:
                        print("DEBUG: Rough transform invalid; retrying.")
        if transform is None:
            print("DEBUG: Failed to compute initial rough transform.")
            return None
        for iter_num in range(max_iter):
            transformed_img_stars = cv2.transform(img_stars.reshape(-1, 1, 2), transform).reshape(-1, 2)
            matches = []
            for idx, t_star in enumerate(transformed_img_stars):
                distances = np.linalg.norm(ref_stars - t_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 20:
                    matches.append((img_stars[idx], ref_stars[closest_idx]))
            print(f"DEBUG: Refinement iteration {iter_num+1}: found {len(matches)} matches.")
            if len(matches) < 5:
                print("DEBUG: Not enough matches during refinement; aborting transform.")
                return None
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            new_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=3.0
            )
            if new_transform is None:
                print("DEBUG: Refinement failed to compute a new transform; aborting.")
                return None
            delta = np.linalg.norm(new_transform[:, 2] - transform[:, 2])
            print(f"DEBUG: Iteration {iter_num+1}: translation delta = {delta:.3f} pixels")
            transform = new_transform
            if delta < convergence_thresh:
                print("DEBUG: Convergence reached.")
                break
        if not StarRegistrationThread.is_valid_transform_static(transform):
            print("DEBUG: Final transform failed validation.")
            return None
        print("DEBUG: Final transform computed successfully.")
        return transform

    @staticmethod
    def is_valid_transform_static(matrix):
        a, b, tx = matrix[0]
        c, d, ty = matrix[1]
        scale_x = np.sqrt(a**2 + c**2)
        scale_y = np.sqrt(b**2 + d**2)
        skew = np.abs((a * b + c * d) / (a**2 + c**2))
        if not (0.9 <= scale_x <= 1.1 and 0.9 <= scale_y <= 1.1):
            return False
        return True

    @staticmethod
    def apply_affine_transform_static(image, transform_matrix):
        # Ensure the transform matrix is a NumPy array of shape (2,3) and type float32.
        transform_matrix = np.array(transform_matrix, dtype=np.float32).reshape(2, 3)
        
        h, w = image.shape[:2]
        # If grayscale, use warpAffine directly.
        if image.ndim == 2:
            aligned = cv2.warpAffine(
                image,
                transform_matrix,
                (w, h),
                flags=cv2.INTER_LANCZOS4,
                borderMode=cv2.BORDER_CONSTANT,
                borderValue=0
            )
        else:
            # For color images, apply warpAffine on each channel.
            channels = []
            for i in range(image.shape[2]):
                warped_channel = cv2.warpAffine(
                    image[:, :, i],
                    transform_matrix,
                    (w, h),
                    flags=cv2.INTER_LANCZOS4,
                    borderMode=cv2.BORDER_CONSTANT,
                    borderValue=0
                )
                channels.append(warped_channel)
            aligned = np.stack(channels, axis=2)
        
        return aligned


    @staticmethod
    def compute_affine_transform_from_triangles(img_stars, ref_stars, ref_triangles, method='auto', max_stars=100):
        """
        Compute an affine transform by matching triangles using side–side–side invariants.
        
        If the target image has few stars (e.g. fewer than 30), this function computes invariants for 
        all combinations of three stars; otherwise, it uses Delaunay triangulation to generate triangles.
        
        The 'ref_triangles' is assumed to be built from the reference stars using your build_triangle_dict() method.
        
        The 'method' parameter can be:
        - 'all'    : always compute all combinations (useful if you have very few stars)
        - 'delaunay': always use Delaunay triangulation
        - 'auto'   : use 'all' if len(img_stars) < 30, otherwise 'delaunay'
        
        Returns an affine transform (2x3 matrix) or None if matching fails.
        """
        
        from scipy.spatial import Delaunay

        if len(img_stars) < 3:
            print("DEBUG: Too few stars in target for triangle matching.")
            return None

        # Decide on method automatically if 'auto'
        if method == 'auto':
            method = 'all' if len(img_stars) < 30 else 'delaunay'
        
        # Option 1: Compute all combinations if method=='all'
        if method == 'all':
            img_triangle_invariants = {}
            # Compute invariants for every combination of 3 stars.
            for comb in combinations(range(len(img_stars)), 3):
                pts = img_stars[list(comb)]
                inv = StarRegistrationThread.compute_triangle_invariant_static(pts)
                if inv is None:
                    continue
                inv_key = (round(inv[0], 2), round(inv[1], 2))
                img_triangle_invariants.setdefault(inv_key, []).append(comb)
            target_tri_dict = img_triangle_invariants
        else:
            # Option 2: Use Delaunay triangulation
            # Optionally limit the star set if it's huge:
            if len(img_stars) > max_stars:
                img_stars = img_stars[:max_stars]
            try:
                tri = Delaunay(img_stars)
            except Exception as e:
                print("DEBUG: Delaunay triangulation failed:", e)
                return None
            target_tri_dict = {}
            for simplex in tri.simplices:
                pts = img_stars[simplex]
                inv = StarRegistrationThread.compute_triangle_invariant_static(pts)
                if inv is None:
                    continue
                inv_key = (round(inv[0], 2), round(inv[1], 2))
                target_tri_dict.setdefault(inv_key, []).append(simplex)

        # Cross-match: For each triangle invariant in the target dictionary,
        # if a matching invariant exists in the reference triangles, add the point pairs.
        matches = []
        for inv_key, sim_list in target_tri_dict.items():
            if inv_key in ref_triangles:
                ref_simplices = ref_triangles[inv_key]
                for s in sim_list:
                    # 's' is either a tuple (if computed from all combinations) or an array (from Delaunay)
                    pts_img = img_stars[list(s)] if isinstance(s, tuple) else img_stars[s]
                    for rs in ref_simplices:
                        pts_ref = ref_stars[rs]
                        # Each triangle yields three matches.
                        for i in range(3):
                            matches.append((pts_img[i], pts_ref[i]))
        if len(matches) < 6:
            print("DEBUG: Not enough triangle matches to run RANSAC.")
            return None

        src_pts = np.array([m[0] for m in matches], dtype=np.float32).reshape(-1, 1, 2)
        dst_pts = np.array([m[1] for m in matches], dtype=np.float32).reshape(-1, 1, 2)

        transform, inliers = cv2.estimateAffinePartial2D(
            src_pts,
            dst_pts,
            method=cv2.RANSAC,
            ransacReprojThreshold=3.0
        )

        if transform is not None:
            if np.isnan(transform).any() or np.isinf(transform).any():
                print("DEBUG: Triangle fallback transform has NaN/Inf.")
                return None
            if not StarRegistrationThread.is_valid_transform_static(transform):
                print("DEBUG: Triangle fallback transform not valid by scale check.")
                return None
            print("DEBUG: Triangle-based transform succeeded.")
            return transform

        return None


    @staticmethod
    def compute_affine_transform_triangle_then_ransac(img_stars, ref_stars, ref_triangles, max_iter=100, convergence_thresh=0.2, ransac_thresh=3.0, max_stars=300):
        """
        First, compute an initial transform using triangle matching.
        Then, refine the transform using nearest-star RANSAC.
        To avoid freezing, only use the top 'max_stars' (if available) from img_stars.
        """
        if len(img_stars) < 3:
            print("DEBUG: Too few stars in target for triangle matching.")
            return None

        # Limit the number of stars to process.
        if len(img_stars) > max_stars:
            img_stars = img_stars[:max_stars]
        
        # Compute the initial transform from triangles.
        initial_transform = StarRegistrationThread.compute_affine_transform_from_triangles(img_stars, ref_stars, ref_triangles)
        if initial_transform is None:
            print("DEBUG: Triangle matching did not yield an initial transform.")
            return None
        print("DEBUG: Initial triangle-based transform computed.")

        # Refine using nearest-star RANSAC starting from the triangle transform.
        transform = initial_transform
        for iter_num in range(max_iter):
            transformed_img_stars = cv2.transform(img_stars.reshape(-1, 1, 2), transform).reshape(-1, 2)
            matches = []
            for idx, t_star in enumerate(transformed_img_stars):
                distances = np.linalg.norm(ref_stars - t_star, axis=1)
                closest_idx = np.argmin(distances)
                if distances[closest_idx] < 20:
                    matches.append((img_stars[idx], ref_stars[closest_idx]))
            print(f"DEBUG (triangle→ransac): Refinement iteration {iter_num+1}: found {len(matches)} matches.")
            if len(matches) < 5:
                print("DEBUG: Not enough matches during refinement; aborting transform.")
                return None
            src_pts = np.array([m[0] for m in matches], dtype=np.float32)
            dst_pts = np.array([m[1] for m in matches], dtype=np.float32)
            new_transform, inliers = cv2.estimateAffinePartial2D(
                src_pts.reshape(-1, 1, 2),
                dst_pts.reshape(-1, 1, 2),
                method=cv2.RANSAC,
                ransacReprojThreshold=ransac_thresh
            )
            if new_transform is None:
                print("DEBUG: Refinement failed to compute a new transform; aborting.")
                return None
            delta = np.linalg.norm(new_transform[:, 2] - transform[:, 2])
            print(f"DEBUG (triangle→ransac): Iteration {iter_num+1}: translation delta = {delta:.3f} pixels.")
            transform = new_transform
            if delta < convergence_thresh:
                print("DEBUG (triangle→ransac): Convergence reached.")
                break
        if not StarRegistrationThread.is_valid_transform_static(transform):
            print("DEBUG: Final transform (triangle→ransac) failed validation.")
            return None
        print("DEBUG: Final transform (triangle→ransac) computed successfully.")
        return transform

    @staticmethod
    def compute_triangle_invariant_static(tri_points):
        # same logic as compute_triangle_invariant
        d1 = np.linalg.norm(tri_points[0] - tri_points[1])
        d2 = np.linalg.norm(tri_points[1] - tri_points[2])
        d3 = np.linalg.norm(tri_points[2] - tri_points[0])
        sides = sorted([d1, d2, d3])
        if sides[0] == 0:
            return None
        return (sides[1]/sides[0], sides[2]/sides[0])        
    
class StarRegistrationWindow(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the Image Manager
        self.reference_image_path = None
        self.files_to_align = []
        self.output_directory = None
        self.thread = None  # Store thread reference

        self.initUI()

    def initUI(self):
        self.setWindowTitle("Star Registration")
        self.setGeometry(200, 200, 600, 450)
        main_layout = QVBoxLayout(self)

        # ─────────────────────────────────────────
        # Reference Image Selection
        # ─────────────────────────────────────────
        ref_layout = QHBoxLayout()
        self.ref_label = QLabel("Reference Image:")
        self.ref_path_label = QLabel("No reference selected")
        self.ref_path_label.setWordWrap(True)

        self.select_ref_slot_button = QPushButton("From Slot")
        self.select_ref_slot_button.clicked.connect(self.select_reference_from_slot)

        self.select_ref_file_button = QPushButton("From File")
        self.select_ref_file_button.clicked.connect(self.select_reference_from_file)

        ref_layout.addWidget(self.ref_label)
        ref_layout.addWidget(self.ref_path_label)
        ref_layout.addWidget(self.select_ref_slot_button)
        ref_layout.addWidget(self.select_ref_file_button)

        # ─────────────────────────────────────────
        # Image Selection Section
        # ─────────────────────────────────────────
        file_selection_layout = QHBoxLayout()

        self.add_files_button = QPushButton("Select Files")
        self.add_files_button.clicked.connect(self.select_files_to_align)

        self.add_directory_button = QPushButton("Select Directory")
        self.add_directory_button.clicked.connect(self.select_directory_to_align)

        file_selection_layout.addWidget(self.add_files_button)
        file_selection_layout.addWidget(self.add_directory_button)

        # ─────────────────────────────────────────
        # TreeBox for Selected Files
        # ─────────────────────────────────────────
        self.tree_widget = QTreeWidget()
        self.tree_widget.setColumnCount(1)
        self.tree_widget.setHeaderLabels(["Files to Align"])
        self.tree_widget.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)

        # Buttons for managing the TreeBox
        tree_buttons_layout = QHBoxLayout()
        self.remove_selected_button = QPushButton("Remove Selected")
        self.remove_selected_button.clicked.connect(self.remove_selected_files)

        self.clear_tree_button = QPushButton("Clear All")
        self.clear_tree_button.clicked.connect(self.clear_tree)

        tree_buttons_layout.addWidget(self.remove_selected_button)
        tree_buttons_layout.addWidget(self.clear_tree_button)

        # ─────────────────────────────────────────
        # Output Directory Selection
        # ─────────────────────────────────────────
        output_layout = QHBoxLayout()
        self.output_label = QLabel("Output Directory:")
        self.output_path_label = QLabel("No directory selected")
        self.output_path_label.setWordWrap(True)

        self.select_output_button = QPushButton("Select Output Folder")
        self.select_output_button.clicked.connect(self.select_output_directory)

        output_layout.addWidget(self.output_label)
        output_layout.addWidget(self.output_path_label)
        output_layout.addWidget(self.select_output_button)

        # ─────────────────────────────────────────
        # Progress Display
        # ─────────────────────────────────────────
        self.progress_label = QLabel("Status: Waiting...")
        self.progress_label.setStyleSheet("color: blue; font-weight: bold;")
        
        # ─────────────────────────────────────────
        # Start Button
        # ─────────────────────────────────────────
        self.start_button = QPushButton("Start Registration")
        self.start_button.setStyleSheet("font-weight: bold; font-size: 14px;")
        self.start_button.clicked.connect(self.start_registration)

        # ─────────────────────────────────────────
        # Add widgets to main layout
        # ─────────────────────────────────────────
        main_layout.addLayout(ref_layout)
        main_layout.addLayout(file_selection_layout)
        main_layout.addWidget(self.tree_widget)
        main_layout.addLayout(tree_buttons_layout)
        main_layout.addLayout(output_layout)
        main_layout.addWidget(self.progress_label)
        main_layout.addWidget(self.start_button)

    # ─────────────────────────────────────────
    # Slot/File Selection for Reference Image
    # ─────────────────────────────────────────
    def select_reference_from_slot(self):
        if self.image_manager:
            available_slots = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
            slot, ok = QInputDialog.getItem(self, "Select Reference Slot", "Choose a reference image slot:", list(available_slots.values()), 0, False)
            if ok:
                slot_index = list(available_slots.values()).index(slot)
                self.reference_image_path = f"Slot {slot_index}"
                self.ref_path_label.setText(self.reference_image_path)

    def select_reference_from_file(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if file_path:
            self.reference_image_path = file_path
            self.ref_path_label.setText(os.path.basename(file_path))

    # ─────────────────────────────────────────
    # File Selection for Alignment
    # ─────────────────────────────────────────
    def select_files_to_align(self):
        files, _ = QFileDialog.getOpenFileNames(self, "Select Files to Align", "", "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fits *.fit *.xisf);;All Files (*)")
        if files:
            for file in files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    def select_directory_to_align(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            supported_extensions = ('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.fits', '.fit', '.xisf')
            new_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.lower().endswith(supported_extensions)]
            for file in new_files:
                if file not in self.files_to_align:
                    self.files_to_align.append(file)
                    self.tree_widget.addTopLevelItem(QTreeWidgetItem([os.path.basename(file)]))

    # ─────────────────────────────────────────
    # Managing Files in TreeBox
    # ─────────────────────────────────────────
    def remove_selected_files(self):
        selected_items = self.tree_widget.selectedItems()
        for item in selected_items:
            file_name = item.text(0)
            for file_path in self.files_to_align:
                if os.path.basename(file_path) == file_name:
                    self.files_to_align.remove(file_path)
                    break
            index = self.tree_widget.indexOfTopLevelItem(item)
            self.tree_widget.takeTopLevelItem(index)

    def clear_tree(self):
        self.tree_widget.clear()
        self.files_to_align.clear()

    # ─────────────────────────────────────────
    # Output Directory Selection
    # ─────────────────────────────────────────
    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory", "")
        if directory:
            self.output_directory = directory
            self.output_path_label.setText(directory)

    # ─────────────────────────────────────────
    # Start Registration with Signal Handling
    # ─────────────────────────────────────────
    def start_registration(self):
        if not self.reference_image_path:
            QMessageBox.warning(self, "Missing Reference", "Please select a reference image before starting.")
            return
        if not self.files_to_align:
            QMessageBox.warning(self, "No Files", "Please add files to align before starting.")
            return
        if not self.output_directory:
            QMessageBox.warning(self, "No Output Directory", "Please select an output directory before starting.")
            return

        self.progress_label.setText("Status: Running...")
        self.progress_label.setStyleSheet("color: green; font-weight: bold;")

        self.thread = StarRegistrationThread(self.reference_image_path, self.files_to_align, self.output_directory)
        self.thread.progress_update.connect(self.update_progress)
        self.thread.registration_complete.connect(self.registration_finished)
        self.thread.start()

    def update_progress(self, message):
        """Update the progress label with the latest status."""
        self.progress_label.setText(f"Status: {message}")
        QApplication.processEvents()

    def registration_finished(self, success, message):
        """Handle the completion of the registration process."""
        color = "green" if success else "red"
        self.progress_label.setText(f"Status: {message}")
        self.progress_label.setStyleSheet(f"color: {color}; font-weight: bold;")

        if success:
            QMessageBox.information(self, "Registration Complete", message)
        else:
            QMessageBox.warning(self, "Registration Error", message)


class PlateSolver(QDialog):
    """
    A dialog class to handle plate solving.
    
    This class lets the user choose either an image file or a slot image,
    then attempts to run ASTAP on the image (if the ASTAP executable is available),
    falls back to astrometry.net if needed, and finally updates the image metadata/FITS header.
    """
    def __init__(self, settings: QSettings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Plate Solver")
        self.setMinimumWidth(400)
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        self.starnet_exe = self.settings.value("starnet/exe_path", "", type=str)
        self.debug_mode = False
        
        self.image_path = ""  # Will hold the selected image path
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        # Instruction Label
        instr_label = QLabel("Select an image source for plate solving:")
        layout.addWidget(instr_label)
        
        # Selection mode combo box (Slot shown first by default)
        self.mode_combo = QComboBox()
        # Reorder items so that "Slot" is default.
        self.mode_combo.addItems(["Slot", "File"])
        self.mode_combo.currentIndexChanged.connect(self.change_mode)
        layout.addWidget(self.mode_combo)
        
        # Stacked widget to hold different UIs
        self.stacked = QStackedWidget()
        layout.addWidget(self.stacked)
        
        # Page 0: Slot selection UI
        slot_page = QWidget()
        slot_layout = QVBoxLayout(slot_page)
        slot_instr = QLabel("Select a slot from which to use the image:")
        slot_layout.addWidget(slot_instr)
        self.slot_combo = QComboBox()
        # Populate with slot names from parent if available
        if self.parent() and hasattr(self.parent(), "slot_names"):
            # Assume slot_names is a dict: {slot_index: "Slot N"}
            for index, name in self.parent().slot_names.items():
                self.slot_combo.addItem(name, index)
        else:
            self.slot_combo.addItems(["Slot 0", "Slot 1", "Slot 2"])
        slot_layout.addWidget(self.slot_combo)
        self.choose_slot_btn = QPushButton("Select Slot")
        self.choose_slot_btn.clicked.connect(self.choose_slot)
        slot_layout.addWidget(self.choose_slot_btn)
        self.slot_status_label = QLabel("No slot selected.")
        slot_layout.addWidget(self.slot_status_label)
        self.stacked.addWidget(slot_page)
        
        # Page 1: File selection UI
        file_page = QWidget()
        file_layout = QVBoxLayout(file_page)
        self.choose_file_btn = QPushButton("Choose Image File")
        self.choose_file_btn.clicked.connect(self.choose_file)
        file_layout.addWidget(self.choose_file_btn)
        self.file_status_label = QLabel("No file selected.")
        file_layout.addWidget(self.file_status_label)
        self.stacked.addWidget(file_page)

        # Add a dedicated status label for overall status messages.
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)        

        # Solve button
        self.solve_btn = QPushButton("Start Plate Solving")
        self.solve_btn.clicked.connect(self.start_plate_solving)
        layout.addWidget(self.solve_btn)

        # --- NEW: Batch Plate Solve button ---
        self.batch_solve_btn = QPushButton("Batch Plate Solve with ASTAP")
        self.batch_solve_btn.clicked.connect(self.openBatchPlateSolver)
        layout.addWidget(self.batch_solve_btn)        
        
        # Close button
        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.reject)
        layout.addWidget(close_btn)
        
        # Set the default mode to Slot (index 0)
        self.mode_combo.setCurrentIndex(0)
        self.stacked.setCurrentIndex(0)
        self.image_path = ""

    def _coerce_header_types(self, hdr_like) -> fits.Header:
        """
        Build a clean astropy.io.fits.Header from a dict/Header,
        forcing correct numeric types for WCS/SIP keys.
        """
        import re
        h = fits.Header()
        it = dict(hdr_like).items() if not isinstance(hdr_like, fits.Header) else hdr_like.items()

        int_keys = {
            "NAXIS", "NAXIS1", "NAXIS2", "NAXIS3",
            "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER",
            "WCSAXES"
        }
        float_prefixes = ("CRPIX", "CRVAL", "CDELT", "CD", "PC", "CROTA", "LATPOLE", "LONPOLE", "EQUINOX", "EPOCH")
        str_keys = {"RADECSYS", "CTYPE1", "CTYPE2", "CUNIT1", "CUNIT2"}
        sip_re = re.compile(r"^(A|B|AP|BP)_(\d+)_(\d+)$", re.IGNORECASE)

        for k, v in it:
            key = k.upper()

            # Integer-only keys
            if key in int_keys:
                s = str(v).strip().strip("'\"")
                try:
                    h[key] = int(s)
                except Exception:
                    try:
                        h[key] = int(float(s))
                    except Exception:
                        continue
                continue

            # SIP coefficients
            if sip_re.match(key):
                try:
                    h[key] = float(str(v).strip())
                except Exception:
                    pass
                continue

            # Common float keys/prefixes
            if any(key.startswith(p) for p in float_prefixes):
                try:
                    h[key] = float(str(v).strip())
                except Exception:
                    pass
                continue

            # Common string keys
            if key in str_keys or key.startswith("CTYPE") or key.startswith("CUNIT"):
                h[key] = str(v).strip().strip("'\"")
                continue

            # Anything else (copy if astropy accepts)
            try:
                h[key] = v
            except Exception:
                pass

        # Mirror SIP order if only one present
        if "A_ORDER" in h and "B_ORDER" not in h:
            h["B_ORDER"] = int(h["A_ORDER"])
        if "B_ORDER" in h and "A_ORDER" not in h:
            h["A_ORDER"] = int(h["B_ORDER"])

        return h


    def openBatchPlateSolver(self):
        # Directly create an instance of BatchPlateSolverDialog
        dialog = BatchPlateSolverDialog(self.settings, parent=self)
        dialog.show()

    def change_mode(self, index):
        """Change the stacked widget page based on the selection mode."""
        self.stacked.setCurrentIndex(index)
        # Clear any previous selection status
        if index == 0:  # Slot mode
            self.slot_status_label.setText("No slot selected.")
            self.image_path = ""
        elif index == 1:  # File mode
            self.file_status_label.setText("No file selected.")
            self.image_path = ""

    def choose_file(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Image for Plate Solving",
            "", "Image Files (*.fit *.fits *.png *.tif *.tiff *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.image_path = file_path
            self.file_status_label.setText(f"Selected: {os.path.basename(file_path)}")
        else:
            self.file_status_label.setText("No file selected.")

    def choose_slot(self):
        """Select an image from a slot."""
        # Check if parent's image_manager is available
        if not (self.parent() and hasattr(self.parent(), "image_manager")):
            QMessageBox.warning(self, "Slot Selection", "Slot images are not available.")
            return

        slot_index = self.slot_combo.currentData()
        img_manager = self.parent().image_manager
        image = img_manager._images.get(slot_index, None)

        # Check if there is image data in the slot.
        if image is not None and hasattr(image, "size") and image.size > 0:
            metadata = img_manager._metadata.get(slot_index, {})
            # Set flag to indicate that we're using slot data.
            self._from_slot = True
            # Use the stored file path if available; otherwise, store a dummy value.
            if "file_path" in metadata and metadata["file_path"]:
                self.image_path = metadata["file_path"]
            else:
                self.image_path = f"slot:{slot_index}"
            self.slot_status_label.setText(
                f"Selected: {self.parent().slot_names.get(slot_index, f'Slot {slot_index}')}"
            )
            # Save slot metadata for later merging.
            self._slot_meta = metadata
        else:
            self.slot_status_label.setText("No image in the selected slot.")
            QMessageBox.warning(self, "Slot Selection", "No image available in the selected slot.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def start_plate_solving(self):
        if not self.image_path:
            QMessageBox.warning(self, "Plate Solver", "Please select an image source first.")
            return

        # Determine the appropriate filter for the ASTAP executable.
        if sys.platform.startswith("win"):
            executable_filter = "Executables (*.exe);;All Files (*)"
        else:
            executable_filter = "Executables (astap);;All Files (*)"

        # Check if ASTAP path is set and valid.
        if not self.astap_exe or not os.path.exists(self.astap_exe):
            # Prompt the user to locate the ASTAP executable.
            new_path, _ = QFileDialog.getOpenFileName(
                self,
                "Select ASTAP Executable",
                "",
                executable_filter
            )
            if new_path:
                self.astap_exe = new_path
                # Save the new ASTAP path in settings.
                self.settings.setValue("astap/exe_path", self.astap_exe)
                QMessageBox.information(self, "Plate Solver", "ASTAP path updated successfully.")
            else:
                # If no ASTAP is provided, skip directly to blind solving via astrometry.net.
                QMessageBox.information(self, "Plate Solver", "ASTAP executable not provided; falling back to astrometry.net blind solve.")
                solved = self.run_astrometry_net(self.image_path)
                if solved:
                    QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
                    self.update_metadata()
                    self.accept()
                else:
                    QMessageBox.critical(self, "Plate Solve", "Plate solve failed with astrometry.net.")
                return

        # Try ASTAP first.
        self.update_status("Running ASTAP plate solving...")
        solved = self.run_astap(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using ASTAP!")
            self.accept()
            return
        else:
            QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Trying astrometry.net...")

        # Fall back to astrometry.net.
        solved = self.run_astrometry_net(self.image_path)
        if solved:
            QMessageBox.information(self, "Plate Solve", "Plate solve successful using astrometry.net!")
            self.update_metadata()
            self.accept()
        else:
            QMessageBox.critical(self, "Plate Solve", "Plate solve failed with both ASTAP and astrometry.net.")

    def update_status(self, message: str):
        idx = self.stacked.currentIndex()
        if idx == 0:   # Slot page
            self.slot_status_label.setText(message)
        else:          # File page
            self.file_status_label.setText(message)

    def save_temp_fits_image(self, normalized_image: np.ndarray, image_path: str, header_override: fits.Header = None) -> str:
        """
        Save `normalized_image` as a FITS file to a temporary path.

        If the original image is FITS, it will try to pull its header (or use
        `header_override` if provided).  Otherwise, it creates a minimal header.

        Before writing, it strips any WCS/CD/CROTA/CDELT/CTYPE/etc. keywords so
        that ASTAP can write a completely fresh solution.

        Returns the full path to the temporary FITS file.
        """
        # Always write out as FITS with 32-bit float pixels.
        selected_format = "fits"
        bit_depth = "32-bit floating point"

        # Determine if this is truly a mono image:
        is_mono = (normalized_image.ndim == 2 or
                (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))

        # === 1) Decide which header to use: override vs. slot‐metadata vs. disk‐file vs. minimal
        if header_override is not None:
            # If caller gave us a cleaned header, use that exactly.
            clean_header = header_override.copy()
        else:
            # Otherwise, attempt to load the original header from ImageManager (slot) or disk.
            original_header = None

            if image_path.lower().endswith((".fits", ".fit")):
                # 1a) Try slot‐based header if ImageManager is present:
                if self.parent() and hasattr(self.parent(), "image_manager"):
                    _, meta = self.parent().image_manager.get_current_image_and_metadata()
                    original_header = meta.get("original_header", None)

                # 1b) If that failed (or batch mode), read directly from disk:
                if original_header is None:
                    try:
                        with fits.open(image_path, memmap=False) as hdul:
                            original_header = hdul[0].header.copy()
                        print("Original FITS header loaded from file.")
                    except Exception as e:
                        print("Failed to load header from FITS file; will create minimal header. Error:", e)

                # 1c) If still no header, fallback to minimal:
                if original_header is None:
                    print("No stored FITS header found; creating a minimal header.")
                    original_header = self.create_minimal_fits_header(normalized_image, is_mono)

                clean_header = original_header.copy()
            else:
                # Non‐FITS images: create a minimal header
                clean_header = self.create_minimal_fits_header(normalized_image, is_mono)

        # === 2) Strip any WCS/CD/CTYPE/CROTA/CDELT/etc. keywords from clean_header ===
        for key in list(clean_header.keys()):
            for prefix in (
                "CRPIX", "CRVAL", "CDELT", "CROTA",
                "CD1_", "CD2_", "CTYPE", "CUNIT",
                "WCSAXES", "LATPOLE", "LONPOLE",
                "EQUINOX", "PV1_", "PV2_",
                "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER",
                "SIP", "PLTSOLVD"
            ):
                if key.upper().startswith(prefix):
                    clean_header.pop(key, None)
                    break

        # === 3) Write out the temp FITS using save_image() ===
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()

        try:
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=clean_header,
                is_mono=is_mono
            )
            print(f"Temporary cleaned FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e

        return tmp_path


    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        Assumes channel-last if 3D (H, W, C).
        """
        H = int(img_array.shape[0]) if img_array.ndim >= 2 else 1
        W = int(img_array.shape[1]) if img_array.ndim >= 2 else 1
        C = int(img_array.shape[2]) if (img_array.ndim == 3) else 1

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32                       # float32
        header['NAXIS']  = 2 if is_mono else 3
        header['NAXIS1'] = W                         # X width
        header['NAXIS2'] = H                         # Y height
        if not is_mono:
            header['NAXIS3'] = C                     # channels (usually 3)
        header['BZERO']  = 0.0
        header['BSCALE'] = 1.0
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")
        return header

    def _first_float(self, v):
        """Return the first float found in v (str/int/float). None if not found."""
        if v is None:
            return None
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v)
        m = re.search(r"[+-]?\d*\.?\d+(?:[eE][+-]?\d+)?", s)
        return float(m.group(0)) if m else None

    def _first_int(self, v):
        """Return the first int found in v (str/int/float). None if not found."""
        if v is None:
            return None
        if isinstance(v, (int,)):
            return int(v)
        if isinstance(v, float):
            return int(round(v))
        s = str(v)
        m = re.search(r"[+-]?\d+", s)
        return int(m.group(0)) if m else None

    def _parse_ra_deg(self, h):
        """
        RA in degrees.
        Try CRVAL1 (deg) -> RA (maybe deg) -> OBJCTRA/RA sexagesimal (hh:mm:ss or variants).
        """
        # CRVAL1 in degrees
        ra = self._first_float(h.get("CRVAL1"))
        if ra is not None:
            return ra

        # RA in degrees if clearly numeric degrees (0..360)
        ra = self._first_float(h.get("RA"))
        if ra is not None and 0.0 <= ra < 360.0:
            return ra

        # Sexagesimal RA (hours)
        for key in ("OBJCTRA", "RA"):
            val = h.get(key)
            if not val:
                continue
            s = str(val).strip()
            # Accept forms like HH:MM:SS.s, HH MM SS.s
            parts = re.split(r"[:\s]+", s)
            try:
                if len(parts) >= 3:
                    hh = float(parts[0]); mm = float(parts[1]); ss = float(parts[2])
                    ra_h = abs(hh) + mm/60.0 + ss/3600.0
                    return ra_h * 15.0  # hours -> degrees
                elif len(parts) == 2:
                    hh = float(parts[0]); mm = float(parts[1]); ss = 0.0
                    return (abs(hh) + mm/60.0) * 15.0
                elif len(parts) == 1:
                    # If single token but > 24, probably already degrees
                    x = float(parts[0])
                    return x if x > 24.0 else x * 15.0
            except Exception:
                pass
        return None

    def _parse_dec_deg(self, h):
        """
        Dec in degrees.
        Try CRVAL2 (deg) -> DEC (maybe deg) -> OBJCTDEC/DEC sexagesimal (±dd:mm:ss).
        """
        dec = self._first_float(h.get("CRVAL2"))
        if dec is not None:
            return dec

        dec = self._first_float(h.get("DEC"))
        if dec is not None and -90.0 <= dec <= 90.0:
            return dec

        for key in ("OBJCTDEC", "DEC"):
            val = h.get(key)
            if not val:
                continue
            s = str(val).strip()
            # Handle leading sign and sexagesimal
            sign = -1.0 if s.startswith("-") else 1.0
            s_clean = s.lstrip("+-")
            parts = re.split(r"[:\s]+", s_clean)
            try:
                if len(parts) >= 3:
                    dd = float(parts[0]); mm = float(parts[1]); ss = float(parts[2])
                    return sign * (abs(dd) + mm/60.0 + ss/3600.0)
                elif len(parts) == 2:
                    dd = float(parts[0]); mm = float(parts[1]); ss = 0.0
                    return sign * (abs(dd) + mm/60.0)
                elif len(parts) == 1:
                    return sign * float(parts[0])
            except Exception:
                pass
        return None

    def _compute_scale_arcsec_per_pix(self, h):
        """
        Prefer CD matrix; else pixel size (μm) + focal length (mm) [+ binning].
        """
        cd11 = self._first_float(h.get("CD1_1"))
        cd21 = self._first_float(h.get("CD2_1"))
        if cd11 is None and cd21 is None:
            # try CDELT
            cd11 = self._first_float(h.get("CDELT1"))
            cd21 = self._first_float(h.get("CDELT2"))
        if cd11 is not None or cd21 is not None:
            cd11 = cd11 or 0.0
            cd21 = cd21 or 0.0
            # degrees/pixel -> arcsec/pixel
            return ( (cd11**2 + cd21**2) ** 0.5 ) * 3600.0

        # Pixel size / focal length path
        px_um_x = self._first_float(h.get("XPIXSZ"))
        px_um_y = self._first_float(h.get("YPIXSZ"))
        focal_mm = self._first_float(h.get("FOCALLEN"))
        if focal_mm and (px_um_x or px_um_y):
            px_um = px_um_x if (px_um_x and px_um_y is None) else px_um_y if (px_um_y and px_um_x is None) else None
            if px_um is None:
                px_um = (px_um_x + px_um_y) / 2.0
            bx = self._first_int(h.get("XBINNING")) or self._first_int(h.get("XBIN")) or 1
            by = self._first_int(h.get("YBINNING")) or self._first_int(h.get("YBIN")) or 1
            bin_factor = (bx + by) / 2.0
            px_um_eff = px_um * bin_factor
            # arcsec/px ≈ 206.265 * pixel_size(μm) / focal_length(mm)
            return 206.264806 * px_um_eff / focal_mm

        return None

    def _build_astap_seed(self, h):
        """
        Returns (seed_args, debug_str). If cannot seed, returns ([], reason).
        """
        ra_deg  = self._parse_ra_deg(h)
        dec_deg = self._parse_dec_deg(h)
        scale   = self._compute_scale_arcsec_per_pix(h)

        dbg = []

        if ra_deg is None:
            dbg.append("RA unknown")
        if dec_deg is None:
            dbg.append("Dec unknown")
        if scale is None or not np.isfinite(scale) or scale <= 0:
            dbg.append("scale unknown")

        if dbg:
            return [], " / ".join(dbg)

        ra_h  = ra_deg / 15.0
        spd   = dec_deg + 90.0  # ASTAP wants SPD = Dec + 90

        seed_args = [
            "-ra",    f"{ra_h:.6f}",
            "-spd",   f"{spd:.6f}",
            "-scale", f"{scale:.3f}",
        ]
        dbg.append(f"RA={ra_h:.6f} h, SPD={spd:.6f}°, scale={scale:.3f}\"/px")
        return seed_args, " | ".join(dbg)


    def run_astap(self, image_path: str, update_manager=True) -> bool:
        if getattr(self, "debug_mode", False):
            print("DEBUG MODE: Skipping ASTAP processing.")
            return False

        # --- Load image data + headers ---
        if getattr(self, "_from_slot", False):
            # 1) from slot, get image + metadata
            image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
            if image_data is None:
                print("No image in selected slot.")
                return False

            # raw_header = the full FITS header you saved in slot meta (camera + binning info)
            raw_header = meta.get("original_header")
            if not isinstance(raw_header, fits.Header):
                print("⚠️ Slot metadata missing a full FITS.Header; seeding disabled.")
                raw_header = None


            # DEBUG: dump every key/value in raw_header
            if isinstance(raw_header, fits.Header):
                print(">>> DEBUG raw_header contents:")
                for k, v in raw_header.items():
                    print(f"    {k} = {v}")
            else:
                print(">>> DEBUG no raw_header available")

            # original_header = your pruned WCS header for saving later
            original_header = meta.get("wcs_header") or raw_header.copy() if raw_header else None

            # stash for later merging
            self._slot_meta = meta
            print("Using slot image; raw header keys:", list(raw_header.keys()) if raw_header else None)

        else:
            # 2) from disk, load image + WCS
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False

            # raw_header = full FITS header on disk
            with fits.open(image_path, memmap=False) as hdul:
                raw_header = hdul[0].header.copy()
            print("Loaded file image; raw header keys:", list(raw_header.keys()))

        # Keep a copy of the original pixel data for final save
        original_image_data = image_data.copy()

        # Normalize/stretch for ASTAP
        image_data = image_data.astype(np.float32)
        normalized_image = self.stretch_image(image_data)

        # --- Write a clean FITS for ASTAP (stripping old WCS only) ---
        if original_header is None:
            clean_header = self.create_minimal_fits_header(normalized_image,
                normalized_image.ndim == 2 or (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        else:
            clean_header = original_header.copy()
        for key in list(clean_header.keys()):
            for p in ("CRPIX","CRVAL","CDELT","CROTA","CD1_","CD2_","CTYPE","CUNIT","WCSAXES"):
                if key.upper().startswith(p):
                    clean_header.pop(key, None)
                    break

        tmp_path = self.save_temp_fits_image(normalized_image, image_path, header_override=clean_header)

        # --- Build ASTAP seed arguments, applying binning to scale ---

        seed_args = []
        hdr = raw_header if isinstance(raw_header, fits.Header) else None

        if hdr is not None:
            try:
                seed_args, dbg = self._build_astap_seed(hdr)
                if seed_args:
                    print(f"🔸 Seeding ASTAP: {dbg}")
                else:
                    print(f"⚠️ Not seeding ASTAP: {dbg}")
            except Exception as e:
                print("Error computing seed args (robust):", e)
        else:
            print("No raw_header → skipping seed")

        print("Seed arguments for ASTAP:", seed_args)

        # --- Launch ASTAP ---
        args = ["-f", tmp_path] + (seed_args or ["-r", "179", "-fov", "0", "-z", "0"]) + ["-wcs", "-sip"]
        print("Running ASTAP with arguments:", args)
        process = QProcess(self)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            print("Failed to start ASTAP process:", process.errorString())
            return False
        if not process.waitForFinished(300000):  # wait up to 5 minutes
            print("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)

        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                print("Error removing temporary file:", e)
            return False

        # --- Retrieve updated header data from the temporary file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            # Remove problematic COMMENT and HISTORY keys.
            solved_header.pop("COMMENT", None)
            solved_header.pop("HISTORY", None)
            solved_header.pop("END", None)

            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            print("Error reading updated FITS header after ASTAP:", e)
            return False

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Regular expression to match a FITS header keyword and its value.
                    # It assumes a format like: KEY  =  value / comment
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)        
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2: ideally provided by ASTAP's INI file.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Ensure required WCS keys are present with proper numeric types ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # Convert the value to float. If it's meant to be an integer (like WCSAXES),
                    # you can use int(float(...)) if needed.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Compute CROTA1 and CROTA2 if not present ---
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                print(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                print("CD matrix elements not available; cannot compute CROTA values.")


        print("Final solved header to be used:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        solved_header = self._coerce_header_types(solved_header)

        # --- Directly update the metadata dictionary for the current slot ---
        # --- Directly update the metadata dictionary for the current slot ---
        # inside run_astap(), after you’ve built solved_header:
        if update_manager and getattr(self, "_from_slot", False):
            img_mgr = self.parent().image_manager
            slot    = img_mgr.current_slot

            # ensure we have both A_ORDER and B_ORDER
            if "B_ORDER" in solved_header and "A_ORDER" not in solved_header:
                solved_header["A_ORDER"] = solved_header["B_ORDER"]
            if "A_ORDER" in solved_header and "B_ORDER" not in solved_header:
                solved_header["B_ORDER"] = solved_header["A_ORDER"]

            # Which keywords we actually want
            int_keys = {"A_ORDER","B_ORDER","AP_ORDER","BP_ORDER","WCSAXES"}
            sip_coef = re.compile(r"^(?:A|B|AP|BP)_(?:\d+_\d+)$")
            linear   = re.compile(r"^(?:CRPIX|CRVAL|CDELT|CD|PC)\d?_?\d*$")
            ctype    = re.compile(r"^(?:CTYPE|CUNIT)\d?$")

            full_hdr = fits.Header()
            for k, v in solved_header.items():
                # skip everything but SIP + linear WCS + axis types
                if k in int_keys:
                    # grab first integer in the string
                    m = re.match(r"\s*([+-]?\d+)", str(v))
                    full_hdr[k] = int(m.group(1)) if m else int(float(v))

                elif sip_coef.match(k):
                    # floating‐point SIP coefficients
                    m = re.match(r"\s*([+-]?\d*\.?\d+(?:[eE][+-]?\d+)?)", str(v))
                    full_hdr[k] = float(m.group(1)) if m else float(v)

                elif linear.match(k):
                    # CRPIX, CRVAL, CDELT, CD, PC
                    m = re.match(r"\s*([+-]?\d*\.?\d+(?:[eE][+-]?\d+)?)", str(v))
                    full_hdr[k] = float(m.group(1)) if m else float(v)

                elif ctype.match(k):
                    full_hdr[k] = str(v).strip("'\"")

                else:
                    # everything else gets dropped
                    continue

            # stash the cleaned FITS header + SIP‐aware WCS
            img_mgr._metadata[slot]["original_header"] = full_hdr
            img_mgr._metadata[slot]["wcs"]             = WCS(full_hdr)

            print(f"✔ stored just the WCS+SIP keywords in slot {slot}")
        else:
            print("Batch mode: Skipping image manager metadata update.")

        # --- If the image was loaded from file (not a slot) and is a FITS file, update that file with the new header ---
        if not getattr(self, "_from_slot", False) and image_path.lower().endswith((".fits", ".fit")):
            try:
                with fits.open(image_path, mode="update", memmap=False) as hdul:
                    hdr = hdul[0].header
                    # Remove problematic keys before updating.
                    solved_header.pop("COMMENT", None)
                    solved_header.pop("HISTORY", None)
                    for key, value in solved_header.items():
                        hdr[key] = value
                    hdul.flush()
                print("Original FITS file updated with solved header (inline).")
            except Exception as e:
                print("Error updating original FITS file with solved header:", e)
                # Optionally, do not treat this as fatal.

        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                # Determine if the image is mono.
                if original_image_data.ndim == 2 or (original_image_data.ndim == 3 and original_image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False

                # If mono, expand it to 3-channel
                if is_mono:
                    original_image_data = np.stack([original_image_data] * 3, axis=-1)  # Convert to RGB-equivalent format
                    is_mono = False  # Mark as non-mono since we expanded it

                if "file_path" in solved_header:
                    del solved_header["file_path"]                    
                # Save the original image data with the solved header.

                # Print the final header before saving
                print("\n✅ FINAL HEADER BEFORE SAVING:")
                for key, value in solved_header.items():
                    print(f"{key} = {value}")                
                save_image(
                    img_array=original_image_data,
                    filename=save_path,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
            # --- Prompt the user to open the newly saved FITS file ---
            reply = QMessageBox.question(
                self, 
                "Open Plate Solved FITS?", 
                "Do you want to open the newly saved plate-solved FITS file?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            if reply == QMessageBox.StandardButton.Yes:
                try:
                    # Load the newly saved FITS file using the global load_image() method.
                    new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                    if new_image is None:
                        QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                    else:
                        # Build a metadata dictionary as in your AstroEditingSuite.
                        metadata = {
                            'file_path': save_path,
                            'original_header': new_header,
                            'bit_depth': new_bit_depth,
                            'is_mono': new_is_mono
                        }
                        # Add the new image and metadata to the ImageManager in the current slot.
                        self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                        print("Plate-solved FITS image loaded and added to ImageManager.")
                except Exception as e:
                    print("Error loading plate-solved FITS file:", e)
                    QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
            else:
                print("User chose not to open the plate-solved FITS file.")
                    
        # --- Clean up temporary files ---
        try:
            os.remove(tmp_path)
        except Exception as e:
            print("Error removing temporary file:", e)
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            print("Error removing INI file:", e)

        return True

    def run_astrometry_net(self, image_path: str):
        """
        Performs a blind solve via Astrometry.net following these steps:
        1. Log in to Astrometry.net using an API key.
        2. Upload the image (converting it to FITS if necessary).
        3. Poll for a job ID.
        4. Poll for calibration data.
        5. Construct a WCS header from the calibration data.
        6. If the image was originally FITS, update that file with the new header.
        7. Store the WCS in the item dictionary.
        
        Returns the constructed WCS header (a FITS Header) on success, or False on failure.
        """
        # Build an item dictionary from the image data.
        if getattr(self, "_from_slot", False):
            # Retrieve from ImageManager.
            if self.parent() and hasattr(self.parent(), "image_manager"):
                image_data, meta = self.parent().image_manager.get_current_image_and_metadata()
                if image_data is None:
                    print("No image data found in the selected slot.")
                    return False
                original_header = meta.get("original_header", meta)
                item = {
                    "path": meta.get("file_path", image_path),
                    "image": image_data,
                    "is_mono": meta.get("is_mono", False)
                }
                self._slot_meta = meta  # Save slot metadata for later merging.
                print("Using image data and metadata from slot for blind solve.")
            else:
                print("No ImageManager found in parent!")
                return False
        else:
            # Load from file using load_image().
            image_data, original_header, bit_depth, is_mono = load_image(image_path)
            if image_data is None:
                print("Failed to load image from file.")
                return False
            item = {
                "path": image_path,
                "image": image_data,
                "is_mono": is_mono
            }
            print("Loaded image data and header from file for blind solve.")

        # --- Begin blind solve loop ---
        while True:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()
            api_key = load_api_key()
            if not api_key:
                api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
                if ok and api_key:
                    save_api_key(api_key)
                else:
                    QMessageBox.warning(self, "API Key Required", "Blind solve canceled (no API key).")
                    return False

            session_key = self.login_to_astrometry(api_key)
            if session_key is None:
                if QMessageBox.question(self, "Login Failed",
                                        "Could not log in to Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()

            # Determine file extension.
            ext = os.path.splitext(item["path"])[1].lower()
            if ext not in ('.fits', '.fit'):
                # Convert non-FITS image to a temporary FITS file.
                temp_file = tempfile.NamedTemporaryFile(suffix=".fit", delete=False)
                temp_file.close()  # Close so save_image can write.
                try:
                    minimal_header = generate_minimal_fits_header(item["image"])
                    save_image(
                        img_array=item["image"],
                        filename=temp_file.name,
                        original_format="fit",
                        bit_depth="16-bit",
                        original_header=minimal_header,
                        is_mono=item.get("is_mono", False)
                    )
                except Exception as e:
                    QMessageBox.critical(self, "Conversion Error", f"Failed to convert image to FITS:\n{e}")
                    return False
                upload_path = temp_file.name
            else:
                upload_path = item["path"]

            subid = self.upload_image_to_astrometry(upload_path, session_key)
            if not subid:
                if QMessageBox.question(self, "Upload Failed",
                                        "Image upload failed or no subid returned. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            job_id = self.poll_submission_status(subid)
            if not job_id:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Failed to retrieve job ID from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            self.status_label.setText("Status: Retrieving calibration data...")
            QApplication.processEvents()
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                if QMessageBox.question(self, "Blind Solve Failed",
                                        "Calibration data did not arrive from Astrometry.net. Try again?",
                                        QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No) == QMessageBox.StandardButton.Yes:
                    continue
                else:
                    return False

            # If a temporary file was created (for non-FITS images), remove it.
            if ext not in ('.fits', '.fit', '.tif', '.tiff'):
                try:
                    os.remove(upload_path)
                except Exception as e:
                    print("Could not remove temporary file:", e)
            break  # Exit loop once all steps succeed.

        # --- Construct the WCS header ---
        wcs_header = self.construct_wcs_header(calibration_data, item["image"].shape)
        if item["path"].lower().endswith(('.fits', '.fit')):
            self.update_fits_with_wcs(item["path"], calibration_data, wcs_header)
        self.status_label.setText("Blind Solve Complete: Astrometric solution applied successfully.")
        # Store the WCS in the item.
        item["wcs"] = WCS(wcs_header)

        # --- (Optional) Update the metadata of the slot if applicable ---
        if getattr(self, "_from_slot", False):
            img_mgr = self.parent().image_manager
            slot    = img_mgr.current_slot

            # save the blind‐solve header as your new "original_header"
            img_mgr._metadata[slot]["original_header"] = wcs_header.copy()

            # build & stash the SIP‐aware WCS too
            img_mgr._metadata[slot]["wcs"] = WCS(wcs_header)

            print(f"✔ saved blind‐solve header + WCS in slot {slot}")

        # --- Now prompt the user to save the new plate-solved FITS file ---
        save_path, _ = QFileDialog.getSaveFileName(self, "Save Plate-Solved FITS", "", "FITS files (*.fits *.fit)")
        if save_path:
            try:
                if image_data.ndim == 2 or (image_data.ndim == 3 and image_data.shape[2] == 1):
                    is_mono = True
                else:
                    is_mono = False
                # Save the original (unsqueezed) image data with the solved header.
                save_image(
                    img_array=image_data,
                    filename=save_path,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=wcs_header,
                    is_mono=is_mono
                )
                print("Plate-solved FITS file saved to:", save_path)
                QMessageBox.information(self, "Save Successful", f"Plate-solved FITS file saved to:\n{save_path}")
            except Exception as e:
                print("Error saving plate-solved FITS file:", e)
                QMessageBox.critical(self, "Save Error", f"Failed to save plate-solved FITS file:\n{e}")
        else:
            print("User cancelled saving the plate-solved FITS file.")

        # --- Prompt the user to open the new plate-solved FITS file ---
        reply = QMessageBox.question(
            self,
            "Open Plate Solved FITS?",
            "Do you want to open the newly saved plate-solved FITS file?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            try:
                new_image, new_header, new_bit_depth, new_is_mono = load_image(save_path)
                if new_image is None:
                    QMessageBox.warning(self, "Load Error", "Failed to load the plate-solved FITS image.")
                else:
                    metadata = {
                        'file_path': save_path,
                        'original_header': new_header,
                        'bit_depth': new_bit_depth,
                        'is_mono': new_is_mono
                    }
                    self.parent().image_manager.add_image(self.parent().image_manager.current_slot, new_image, metadata)
                    print("Plate-solved FITS image loaded and added to ImageManager.")
            except Exception as e:
                print("Error loading plate-solved FITS file:", e)
                QMessageBox.critical(self, "Load Error", f"Failed to load the plate-solved FITS image:\n{e}")
        else:
            print("User chose not to open the plate-solved FITS file.")

        return wcs_header

    def login_to_astrometry(self, api_key):
        url = ASTROMETRY_API_URL + "login"
        data = {'request-json': json.dumps({"apikey": api_key})}
        response = robust_api_request("POST", url, data=data, prompt_on_failure=True)
        if response and response.get("status") == "success":
            return response["session"]
        print("Login failed after multiple attempts.")
        QMessageBox.critical(self, "Login Failed", "Could not log in to Astrometry.net. Check your API key or internet connection.")
        return None

    def upload_image_to_astrometry(self, image_path, session_key):
        url = ASTROMETRY_API_URL + "upload"
        with open(image_path, 'rb') as f:
            files = {'file': f}
            data = {
                'request-json': json.dumps({
                    "publicly_visible": "y",
                    "allow_modifications": "d",
                    "session": session_key,
                    "allow_commercial_use": "d"
                })
            }
            response = robust_api_request("POST", url, data=data, files=files)
        if response and response.get("status") == "success":
            return response["subid"]
        QMessageBox.critical(self, "Upload Failed", "Image upload failed after multiple attempts.")
        return None

    def poll_submission_status(self, subid):
        url = ASTROMETRY_API_URL + f"submissions/{subid}"
        for attempt in range(90):  # up to ~15 minutes
            response = robust_api_request("GET", url)
            if response:
                jobs = response.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
            print(f"Polling attempt {attempt+1}: Job ID not ready yet.")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Failed to retrieve job ID from Astrometry.net after multiple attempts.")
        return None

    def poll_calibration_data(self, job_id):
        url = ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/"
        for attempt in range(90):
            response = robust_api_request("GET", url)
            if response and 'ra' in response and 'dec' in response:
                print("Calibration data retrieved:", response)
                return response
            print(f"Calibration data not available yet (attempt {attempt+1})")
            time.sleep(10)
        QMessageBox.critical(self, "Blind Solve Failed", "Calibration data did not complete in the expected timeframe.")
        return None

    def construct_wcs_header(self, calibration_data, image_shape):
        h = fits.Header()
        h['CTYPE1'] = 'RA---TAN'
        h['CTYPE2'] = 'DEC--TAN'
        h['CRPIX1'] = image_shape[1] / 2
        h['CRPIX2'] = image_shape[0] / 2
        h['CRVAL1'] = calibration_data['ra']
        h['CRVAL2'] = calibration_data['dec']
        scale = calibration_data['pixscale'] / 3600.0  # degrees/pixel
        orientation = math.radians(calibration_data['orientation'])
        h['CD1_1'] = -scale * np.cos(orientation)
        h['CD1_2'] = scale * np.sin(orientation)
        h['CD2_1'] = -scale * np.sin(orientation)
        h['CD2_2'] = -scale * np.cos(orientation)
        h['RADECSYS'] = 'ICRS'
        h['WCSAXES'] = 2
        print("Generated WCS header from calibration data.")
        return h

    def update_fits_with_wcs(self, filepath, calibration_data, wcs_header):
        if not filepath.lower().endswith(('.fits','.fit')):
            print("Not a FITS, skipping WCS update.")
            return
        try:
            with fits.open(filepath, mode='update') as hdul:
                hdr = hdul[0].header
                if 'NAXIS3' in hdr:
                    del hdr['NAXIS3']
                hdr['NAXIS'] = 2
                hdr['CTYPE1'] = 'RA---TAN'
                hdr['CTYPE2'] = 'DEC--TAN'
                hdr['CRVAL1'] = calibration_data['ra']
                hdr['CRVAL2'] = calibration_data['dec']
                # Determine H and W based on the data's dimensionality.
                if hdul[0].data.ndim == 3:
                    # Assume data are stored as (channels, height, width)
                    _, H, W = hdul[0].data.shape
                else:
                    H, W = hdul[0].data.shape[:2]
                hdr['CRPIX1'] = W/2.0
                hdr['CRPIX2'] = H/2.0
                scale = calibration_data['pixscale']/3600.0
                orientation = math.radians(calibration_data.get('orientation', 0.0))
                hdr['CD1_1'] = -scale * np.cos(orientation)
                hdr['CD1_2'] = scale * np.sin(orientation)
                hdr['CD2_1'] = -scale * np.sin(orientation)
                hdr['CD2_2'] = -scale * np.cos(orientation)
                hdr['WCSAXES'] = 2
                hdr['RADECSYS'] = 'ICRS'
                hdul.flush()
                print("WCS updated in FITS.")
            # Re-open to verify changes:
            with fits.open(filepath) as hdul_verify:
                print("Updated header keys:", hdul_verify[0].header.keys())
        except Exception as e:
            print(f"Error updating FITS with WCS: {e}")

    def update_metadata(self):
        """
        Placeholder method to update the metadata or FITS header
        with the plate solving results.
        Extend this method to:
          - Read the .wcs or .ini output files from the plate solver
          - Update the image metadata accordingly.
        """
        print("Updating metadata/FITS header... (this is a placeholder)")
        # TODO: Implement metadata update logic here.

class BatchPlateSolverDialog(QDialog):
    def __init__(self, settings, parent=None):
        super().__init__(parent)
        self.settings = settings
        self.setWindowTitle("Batch Plate Solve")
        self.astap_exe = self.settings.value("astap/exe_path", "", type=str)
        self.setMinimumWidth(500)
        self.init_ui()

    def init_ui(self):
        layout = QVBoxLayout(self)
        
        self.inputDirLineEdit = QLineEdit()
        self.outputDirLineEdit = QLineEdit()
        inputBrowseButton = QPushButton("Browse Input Directory")
        outputBrowseButton = QPushButton("Browse Output Directory")
        self.startButton = QPushButton("Start Batch Plate Solve")
        self.statusTextEdit = QTextEdit()
        self.statusTextEdit.setReadOnly(True)
        
        layout.addWidget(QLabel("Input Directory:"))
        layout.addWidget(self.inputDirLineEdit)
        layout.addWidget(inputBrowseButton)
        layout.addWidget(QLabel("Output Directory:"))
        layout.addWidget(self.outputDirLineEdit)
        layout.addWidget(outputBrowseButton)
        layout.addWidget(self.startButton)
        layout.addWidget(QLabel("Status:"))
        layout.addWidget(self.statusTextEdit)
        
        inputBrowseButton.clicked.connect(self.browseInputDir)
        outputBrowseButton.clicked.connect(self.browseOutputDir)
        self.startButton.clicked.connect(self.startBatchPlateSolve)
        
    def browseInputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.inputDirLineEdit.setText(directory)
        
    def browseOutputDir(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.outputDirLineEdit.setText(directory)
            
    def logStatus(self, message):
        self.statusTextEdit.append(message)
        QApplication.processEvents()
        
    def run_astap_batch(self, image_path: str):
        """
        Batch‐mode version of ASTAP processing.
        Loads an image, normalizes it, saves a temporary FITS file,
        builds either seeded or blind‐solve arguments from the header,
        runs ASTAP, retrieves the solved header, and returns True/False.
        """
        # 1) Load image + header
        image_data, original_header, bit_depth, is_mono = load_image(image_path)
        if image_data is None:
            self.logStatus(f"❌ Failed to load image: {image_path}")
            return False

        # Keep a copy of the original for later if you need it
        original_image_data = image_data.copy()

        # 2) Normalize/stretch (you can swap in your stretch_image if you like)
        image_data = image_data.astype(np.float32)
        normalized_image = image_data  # or self.stretch_image(image_data)

        # 3) Write a clean FITS for ASTAP (strip old WCS)
        #    (reuse your save_temp_fits_image helper)
        tmp_path = self.save_temp_fits_image(normalized_image, image_path)

        # 4) Pull out a “raw” header to seed ASTAP
        if isinstance(original_header, fits.Header):
            raw_hdr = original_header
        else:
            # fallback: read directly from disk
            with fits.open(image_path, memmap=False) as hdul:
                raw_hdr = hdul[0].header

        # DEBUG: dump every header key/value
        self.logStatus("🔍 Raw header contents:")
        for k, v in raw_hdr.items():
            self.logStatus(f"    {k} = {v}")

        # 5) Build seed_args from header WCS or fallback RA/DEC → scale
        # 5) Build seed_args from header WCS or fallback keywords
        seed_args = []

        if isinstance(raw_hdr, fits.Header):
            try:
                # —— RA & Dec in degrees ——
                if "CRVAL1" in raw_hdr and "CRVAL2" in raw_hdr:
                    ra_deg  = float(raw_hdr["CRVAL1"])
                    dec_deg = float(raw_hdr["CRVAL2"])

                elif "RA" in raw_hdr and "DEC" in raw_hdr:
                    # could be stored as numbers *or* sexagesimal
                    ra_val  = raw_hdr["RA"]
                    dec_val = raw_hdr["DEC"]
                    if isinstance(ra_val, (int, float)):
                        ra_deg = float(ra_val)
                    else:
                        from astropy.coordinates import Angle
                        ra_deg = Angle(str(ra_val), unit="hourangle").degree

                    if isinstance(dec_val, (int, float)):
                        dec_deg = float(dec_val)
                    else:
                        from astropy.coordinates import Angle
                        dec_deg = Angle(str(dec_val), unit="deg").degree

                else:
                    raise KeyError("no RA/Dec in header")

                ra_h = ra_deg / 15.0
                spd  = dec_deg + 90.0

                # —— pixel scale in ″/pixel ——
                if "CD1_1" in raw_hdr or "CDELT1" in raw_hdr:
                    cd11 = float(raw_hdr.get("CD1_1", raw_hdr.get("CDELT1", 0)))
                    cd21 = float(raw_hdr.get("CD2_1", raw_hdr.get("CDELT2", 0)))
                    pix  = np.hypot(cd11, cd21) * 3600.0

                elif "PIXSCALE" in raw_hdr:
                    pix = float(raw_hdr["PIXSCALE"])

                elif "XPIXSZ" in raw_hdr and "FOCALLEN" in raw_hdr:
                    # XPIXSZ in µm, FOCALLEN in mm → arcsec/pixel = 206.265 * (pix_size_mm / focal_mm)
                    px_mm    = float(raw_hdr["XPIXSZ"])
                    focal_mm = float(raw_hdr["FOCALLEN"])
                    pix = 206.265 * px_mm / focal_mm

                else:
                    raise KeyError("no pixel-scale in header")

                # —— apply binning if present ——
                bx = int(raw_hdr.get("XBINNING", 1))
                by = int(raw_hdr.get("YBINNING", bx))
                if bx != by:
                    self.logStatus(f"⚠️ Unequal binning {bx}×{by}, using average")
                bin_factor = (bx + by) / 2.0
                pix *= bin_factor

                seed_args = [
                    "-ra",    f"{ra_h:.6f}",
                    "-spd",   f"{spd:.6f}",
                    "-scale", f"{pix:.3f}",
                ]
                self.logStatus(
                    f"🔸 Seeding ASTAP: RA={ra_h:.6f}h, SPD={spd:.6f}°, "
                    f"scale={pix:.3f}\"/px (×{bin_factor} bin)"
                )

            except KeyError as e:
                self.logStatus(f"⚠️ Missing key ({e}); falling back to blind solve.")
            except Exception as e:
                self.logStatus(f"⚠️ Error computing seed args: {e}; falling back to blind solve.")

        else:
            self.logStatus("⚠️ No FITS header; falling back to blind solve.")

        # 6) Build the final ASTAP argument list
        if seed_args:
            args = ["-f", tmp_path] + seed_args + ["-wcs", "-sip"]
        else:
            args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs", "-sip"]

        self.logStatus(f"▶️ Running ASTAP: {' '.join(args)}")
        self.logStatus(f"Running ASTAP with arguments: {args}")
        process = QProcess(self)
        process.start(self.astap_exe, args)
        if not process.waitForStarted(5000):
            self.logStatus("Failed to start ASTAP process: " + process.errorString())
            return False
        if not process.waitForFinished(300000):
            self.logStatus("ASTAP process timed out.")
            return False

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        self.logStatus(f"ASTAP exit code: {exit_code}")
        self.logStatus("ASTAP STDOUT: " + stdout)
        self.logStatus("ASTAP STDERR: " + stderr)
        if exit_code != 0:
            try:
                os.remove(tmp_path)
            except Exception as e:
                self.logStatus("Error removing temporary file: " + str(e))
            return False

        # Retrieve solved header from temporary FITS file
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            self.logStatus("Initial solved header retrieved:")
            for key, value in solved_header.items():
                self.logStatus(f"{key} = {value}")
        except Exception as e:
            self.logStatus("Error reading solved header after ASTAP: " + str(e))
            return False

        # Check for a corresponding .wcs file and merge its header if present.
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                self.logStatus("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    self.logStatus(f"{key} = {value}")
                solved_header.update(wcs_header)
            except Exception as e:
                self.logStatus("Error reading .wcs file: " + str(e))
        else:
            self.logStatus("No .wcs file found; using header from temporary FITS.")

        # Add missing required keys
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                self.logStatus(f"Added missing key {key} with default value {default}.")

        # Convert expected numeric keys
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    self.logStatus(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # Compute CROTA1 and CROTA2 if missing
        if 'CROTA1' not in solved_header or 'CROTA2' not in solved_header:
            if 'CD1_1' in solved_header and 'CD1_2' in solved_header:
                rotation = math.degrees(math.atan2(solved_header['CD1_2'], solved_header['CD1_1']))
                solved_header['CROTA1'] = rotation
                solved_header['CROTA2'] = rotation
                self.logStatus(f"Computed CROTA1 and CROTA2 as {rotation:.2f} degrees.")
            else:
                self.logStatus("CD matrix elements not available; cannot compute CROTA values.")

        self.logStatus("Final solved header:")
        for key, value in solved_header.items():
            self.logStatus(f"{key} = {value}")

        try:
            os.remove(tmp_path)
        except Exception as e:
            self.logStatus("Error removing temporary file: " + str(e))
        try:
            if os.path.exists(wcs_path):
                os.remove(wcs_path)
        except Exception as e:
            self.logStatus("Error removing .wcs file: " + str(e))
        return solved_header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def save_temp_fits_image(self, normalized_image: np.ndarray, image_path: str, header_override: fits.Header = None) -> str:
        """
        Save `normalized_image` as a FITS file to a temporary path.

        If the original image is FITS, it will try to pull its header (or use
        `header_override` if provided).  Otherwise, it creates a minimal header.

        Before writing, it strips any WCS/CD/CROTA/CDELT/CTYPE/etc. keywords so
        that ASTAP can write a completely fresh solution.

        Returns the full path to the temporary FITS file.
        """
        # Always write out as FITS with 32-bit float pixels.
        selected_format = "fits"
        bit_depth = "32-bit floating point"

        # Determine if this is truly a mono image:
        is_mono = (normalized_image.ndim == 2 or
                (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))

        # === 1) Decide which header to use: override vs. slot‐metadata vs. disk‐file vs. minimal
        if header_override is not None:
            # If caller gave us a cleaned header, use that exactly.
            clean_header = header_override.copy()
        else:
            # Otherwise, attempt to load the original header from ImageManager (slot) or disk.
            original_header = None

            if image_path.lower().endswith((".fits", ".fit")):
                # 1a) Try slot‐based header if ImageManager is present:
                if self.parent() and hasattr(self.parent(), "image_manager"):
                    _, meta = self.parent().image_manager.get_current_image_and_metadata()
                    original_header = meta.get("original_header", None)

                # 1b) If that failed (or batch mode), read directly from disk:
                if original_header is None:
                    try:
                        with fits.open(image_path, memmap=False) as hdul:
                            original_header = hdul[0].header.copy()
                        print("Original FITS header loaded from file.")
                    except Exception as e:
                        print("Failed to load header from FITS file; will create minimal header. Error:", e)

                # 1c) If still no header, fallback to minimal:
                if original_header is None:
                    print("No stored FITS header found; creating a minimal header.")
                    original_header = self.create_minimal_fits_header(normalized_image, is_mono)

                clean_header = original_header.copy()
            else:
                # Non‐FITS images: create a minimal header
                clean_header = self.create_minimal_fits_header(normalized_image, is_mono)

        # === 2) Strip any WCS/CD/CTYPE/CROTA/CDELT/etc. keywords from clean_header ===
        for key in list(clean_header.keys()):
            for prefix in (
                "CRPIX", "CRVAL", "CDELT", "CROTA",
                "CD1_", "CD2_", "CTYPE", "CUNIT",
                "WCSAXES", "LATPOLE", "LONPOLE",
                "EQUINOX", "PV1_", "PV2_",
                "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER",
                "SIP", "PLTSOLVD"
            ):
                if key.upper().startswith(prefix):
                    clean_header.pop(key, None)
                    break

        # === 3) Write out the temp FITS using save_image() ===
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()

        try:
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=clean_header,
                is_mono=is_mono
            )
            print(f"Temporary cleaned FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e

        return tmp_path


    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header


    def startBatchPlateSolve(self):
        inputDir = self.inputDirLineEdit.text().strip()
        outputDir = self.outputDirLineEdit.text().strip()
        if not inputDir or not outputDir:
            QMessageBox.warning(self, "Missing Directories", "Please select both input and output directories.")
            return
        
        acceptable_exts = ['.xisf', '.fits', '.fit', '.tif', '.tiff', '.png', '.jpg', '.jpeg']
        files = [os.path.join(inputDir, f) for f in os.listdir(inputDir)
                 if os.path.splitext(f)[1].lower() in acceptable_exts]
        
        if not files:
            QMessageBox.information(self, "No Files", "No acceptable image files found in the input directory.")
            return
        
        self.logStatus(f"Found {len(files)} files. Starting batch processing...")
        
        for file in files:
            self.logStatus(f"Processing: {file}")
            try:
                # Load image data
                image_data, original_header, bit_depth, is_mono = load_image(file)
                if image_data is None:
                    self.logStatus(f"Failed to load image: {file}")
                    continue

                # Run our batch ASTAP routine (which does not update the ImageManager)
                solved_header = self.run_astap_batch(file)
                if not solved_header:
                    self.logStatus(f"Plate solving failed for: {file}")
                    continue
                
                base_name = os.path.splitext(os.path.basename(file))[0]
                output_file = os.path.join(outputDir, base_name + "_plate_solved.fits")
                
                # Save the image with the solved header
                save_image(
                    img_array=image_data,
                    filename=output_file,
                    original_format="fit",
                    bit_depth="32-bit floating point",
                    original_header=solved_header,
                    is_mono=is_mono
                )
                self.logStatus(f"Saved plate-solved image to: {output_file}")
            except Exception as e:
                self.logStatus(f"Error processing {file}: {e}")
        
        self.logStatus("Batch plate solving completed.")



class PSFViewer(QDialog):
    def __init__(self, image, parent=None):
        """
        Initialize the PSF Viewer dialog using SEP for star detection.
        """
        super().__init__(parent)
        self.setWindowTitle("PSF Viewer")
        self.image = image
        self.zoom_factor = 1.0
        self.log_scale = False
        self.star_list = None
        self.histogram_mode = 'PSF'  # or 'Flux'
        # Default detection threshold in sigma
        self.detection_threshold = 5  

        # Debounce timer for threshold slider
        self.threshold_timer = QTimer(self)
        self.threshold_timer.setSingleShot(True)
        self.threshold_timer.setInterval(500)  # 500 ms
        self.threshold_timer.timeout.connect(self._applyThreshold)

        self.initUI()
        # Defer the first catalog compute until the dialog is shown
        QTimer.singleShot(0, self._applyThreshold)

    def initUI(self):
        main_layout = QVBoxLayout(self)
        
        # ─── Top: histogram + stats ────────────────────────────────
        top_layout = QHBoxLayout()
        # Histogram scroll area
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setFixedSize(520, 310)
        self.scroll_area.setWidgetResizable(False)
        self.hist_label = QLabel(self)
        self.hist_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.hist_label)
        top_layout.addWidget(self.scroll_area)
        # Stats table
        self.stats_table = QTableWidget(self)
        self.stats_table.setRowCount(4)
        self.stats_table.setColumnCount(1)  # will adjust dynamically
        self.stats_table.setVerticalHeaderLabels(["Min", "Max", "Median", "StdDev"])
        self.stats_table.setFixedWidth(360)
        top_layout.addWidget(self.stats_table)
        main_layout.addLayout(top_layout)
        
        # Status label
        self.status_label = QLabel("Status: Ready", self)
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout.addWidget(self.status_label)
        
        # ─── Controls: zoom, log, mode ─────────────────────────────
        controls_layout = QHBoxLayout()
        # Zoom slider
        controls_layout.addWidget(QLabel("Zoom:"))
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.zoom_slider.setRange(50, 1000)
        self.zoom_slider.setValue(100)
        self.zoom_slider.setTickInterval(10)
        self.zoom_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.zoom_slider.valueChanged.connect(self.updateZoom)
        controls_layout.addWidget(self.zoom_slider)
        # Log scale toggle
        self.log_toggle_button = QPushButton("Toggle Log X-Axis", self)
        self.log_toggle_button.setCheckable(True)
        self.log_toggle_button.setToolTip("Toggle between linear and logarithmic x-axis.")
        self.log_toggle_button.toggled.connect(self.toggleLogScale)
        controls_layout.addWidget(self.log_toggle_button)
        # PSF/Flux toggle
        self.mode_toggle_button = QPushButton("Show Flux Histogram", self)
        self.mode_toggle_button.setToolTip("Switch between PSF (FWHM) and Flux histograms.")
        self.mode_toggle_button.clicked.connect(self.toggleHistogramMode)
        controls_layout.addWidget(self.mode_toggle_button)
        main_layout.addLayout(controls_layout)
        
        # Detection threshold slider + label
        thresh_layout = QHBoxLayout()
        thresh_layout.addWidget(QLabel("Detection Threshold (σ):", self))
        self.threshold_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.threshold_slider.setRange(1, 20)
        self.threshold_slider.setValue(self.detection_threshold)
        self.threshold_slider.setTickInterval(1)
        self.threshold_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.threshold_slider.valueChanged.connect(self.onThresholdChange)
        thresh_layout.addWidget(self.threshold_slider)

        self.threshold_value_label = QLabel(str(self.detection_threshold), self)
        thresh_layout.addWidget(self.threshold_value_label)
        main_layout.addLayout(thresh_layout)
        
        # Close button
        close_btn = QPushButton("Close", self)
        close_btn.clicked.connect(self.accept)
        main_layout.addWidget(close_btn)
        
        self.setLayout(main_layout)
        # Draw an initial (empty) histogram
        self.drawHistogram()

    def onThresholdChange(self, value: int):
        """Update label and restart debounce timer."""
        self.detection_threshold = value
        self.threshold_value_label.setText(str(value))
        # Restart debounce timer
        if self.threshold_timer.isActive():
            self.threshold_timer.stop()
        self.threshold_timer.start()

    def _applyThreshold(self):
        """
        Called after the debounce timer fires — actually re-run extraction
        and redraw the histogram.
        """
        self.compute_star_list()
        self.drawHistogram()


    def updateImage(self, new_image):
        """
        Replace the image, re-run detection, and redraw.
        """
        self.image = new_image
        self.compute_star_list()
        self.drawHistogram()

    def compute_star_list(self):
        """
        Use SEP to detect stars with the current threshold.
        """
        # Convert to grayscale
        if self.image.ndim == 3:
            image_gray = np.mean(self.image, axis=2)
        else:
            image_gray = self.image
        data = image_gray.astype(np.float32)
        
        # Background estimation
        bkg = sep.Background(data)
        data_sub = data - bkg.back()
        
        # Use the slider’s value
        threshold = float(self.detection_threshold)
        
        # Estimate error
        try:
            err_val = bkg.globalrms
        except Exception:
            err_val = np.median(bkg.rms())
        
        # Update status
        self.status_label.setText("Status: Starting star extraction...")
        QApplication.processEvents()
        
        # Run SEP
        try:
            sources = sep.extract(data_sub, threshold, err=err_val)
            n = len(sources) if sources is not None else 0
            self.status_label.setText(f"Status: Extraction completed — {n} sources.")
        except Exception as e:
            self.status_label.setText(f"Status: Extraction failed: {e}")
            sources = None
        QApplication.processEvents()

        # avoid ambiguous truth check on ndarray:
        if sources is None or len(sources) == 0:
            self.star_list = None
            return

        # Compute HFR = 2 * a
        try:
            a = sources['a']
            r = 2 * a
        except Exception:
            r = np.zeros(len(sources))
        
        # Build Astropy table
        tbl = Table()
        tbl['xcentroid'] = sources['x']
        tbl['ycentroid'] = sources['y']
        tbl['flux']      = sources['flux']
        tbl['HFR']       = r
        tbl['a']         = sources['a']
        tbl['b']         = sources['b']
        tbl['theta']     = sources['theta']
        self.star_list = tbl

    def updateZoom(self, val: int):
        self.zoom_factor = val / 100.0
        self.drawHistogram()

    def toggleLogScale(self, checked: bool):
        self.log_scale = checked
        self.drawHistogram()

    def toggleHistogramMode(self):
        if self.histogram_mode == 'PSF':
            self.histogram_mode = 'Flux'
            self.mode_toggle_button.setText("Show PSF Histogram")
        else:
            self.histogram_mode = 'PSF'
            self.mode_toggle_button.setText("Show Flux Histogram")
        self.drawHistogram()

    def drawHistogram(self):
        """
        Paints the histogram of the current catalog (PSF or flux).
        """
        # Create pixmap
        base_w, h = 512, 300
        w = int(base_w * self.zoom_factor)
        pix = QPixmap(w, h)
        pix.fill(Qt.GlobalColor.white)
        painter = QPainter(pix)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)
        
        # Prepare data & bins
        if not self.star_list:
            data = np.array([])
            edges = np.linspace(0, 1, 51)
        else:
            if self.histogram_mode == 'PSF':
                data = np.array(self.star_list['HFR'], float)
                edges = np.linspace(0, 7.5, 51)
            else:
                data = np.array(self.star_list['flux'], float)
                if data.size:
                    edges = np.linspace(data.min(), data.max(), 51)
                else:
                    edges = np.linspace(0, 1, 51)
        
        # Log or linear bin positions
        if self.log_scale and edges[-1] > 0:
            low, high = max(edges[0],1e-4), edges[-1]
            edges = np.logspace(np.log10(low), np.log10(high), 51)
            xfun = lambda v: int((np.log10(v) - np.log10(low)) / (np.log10(high)-np.log10(low)) * w)
        else:
            low, high = edges[0], edges[-1]
            xfun = lambda v: int((v - low) / (high - low) * w) if high>low else 0
        
        # Histogram
        hist = np.histogram(data, bins=edges)[0].astype(float)
        if hist.max()>0:
            hist /= hist.max()
        
        # Draw bars
        pen = QPen(Qt.GlobalColor.black)
        painter.setPen(pen)
        for i in range(len(hist)):
            x0 = xfun(edges[i])
            x1 = xfun(edges[i+1])
            bw = max(x1-x0, 1)
            bh = hist[i] * h
            painter.drawRect(x0, int(h-bh), bw, int(bh))
        
        # X-axis & ticks
        painter.setPen(QPen(Qt.GlobalColor.black, 2))
        painter.drawLine(0, h-1, w, h-1)
        painter.setFont(QFont("Arial", 10))
        ticks = (np.logspace(np.log10(low), np.log10(high), 6)
                 if self.log_scale and high>low
                 else np.linspace(low, high, 6))
        for t in ticks:
            x = xfun(t)
            painter.drawLine(x, h-1, x, h-6)
            painter.drawText(x-20, h-10, f"{t:.2f}" if not self.log_scale else f"{t:.3f}")
        
        painter.end()
        self.hist_label.setPixmap(pix)
        self.hist_label.resize(pix.size())
        self.updateStatistics()

    def updateStatistics(self):
        """
        Fill the stats table with Min/Max/Median/StdDev for each chosen column.
        """
        if not self.star_list:
            cols = []
        else:
            # desired columns
            cols = ['HFR','eccentricity','a','b','theta','flux']
            # compute eccentricity
            a = np.array(self.star_list['a'], float)
            b = np.array(self.star_list['b'], float)
            ecc = np.nan_to_num(np.sqrt(1 - (b/a)**2))
            # insert into table representation
            data_map = {
                'eccentricity': ecc,
                **{c: np.array(self.star_list[c], float) for c in self.star_list.colnames}
            }
        
        # Filter out missing
        cols = [c for c in cols if c in data_map]
        self.stats_table.setColumnCount(len(cols))
        self.stats_table.setHorizontalHeaderLabels(cols)
        self.stats_table.setRowCount(4)
        self.stats_table.setVerticalHeaderLabels(["Min","Max","Median","StdDev"])
        
        for ci, col in enumerate(cols):
            arr = data_map.get(col, np.zeros(0))
            if arr.size:
                vals = [arr.min(), arr.max(), np.median(arr), np.std(arr)]
            else:
                vals = [0,0,0,0]
            for ri, v in enumerate(vals):
                it = QTableWidgetItem(f"{v:.3f}")
                it.setTextAlignment(Qt.AlignmentFlag.AlignCenter)
                self.stats_table.setItem(ri, ci, it)

class SupernovaAsteroidHunterTab(QWidget):
    def __init__(self):
        super().__init__()
        # Parameters for the hunter
        self.parameters = {
            "referenceImagePath": "",
            "searchImagePaths": [],
            "threshold": 0.10  # Default threshold value
        }
        # Preprocessed images will be stored here
        self.preprocessed_reference = None
        self.preprocessed_search = []  # List of dicts: {"path": str, "image": np.array}
        # Detected anomaly data for each search image
        self.anomalyData = []
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout(self)

        # Instruction Label
        instructions = QLabel("Select the reference image and search images. Then click Process to hunt for anomalies.")
        layout.addWidget(instructions)

        # --- Reference Image Selection ---
        ref_layout = QHBoxLayout()
        self.ref_line_edit = QLineEdit(self)
        self.ref_line_edit.setPlaceholderText("No reference image selected")
        self.ref_button = QPushButton("Select Reference Image", self)
        self.ref_button.clicked.connect(self.selectReferenceImage)
        ref_layout.addWidget(self.ref_line_edit)
        ref_layout.addWidget(self.ref_button)
        layout.addLayout(ref_layout)

        # --- Search Images Selection ---
        search_layout = QHBoxLayout()
        self.search_list = QListWidget(self)
        self.search_button = QPushButton("Select Search Images", self)
        self.search_button.clicked.connect(self.selectSearchImages)
        search_layout.addWidget(self.search_list)
        search_layout.addWidget(self.search_button)
        layout.addLayout(search_layout)

        # --- Cosmetic Correction Checkbox ---
        self.cosmetic_checkbox = QCheckBox("Apply Cosmetic Correction before Preprocessing", self)
        layout.addWidget(self.cosmetic_checkbox)

        # --- Threshold Slider ---
        thresh_layout = QHBoxLayout()
        self.thresh_label = QLabel("Anomaly Detection Threshold: 0.10", self)
        self.thresh_slider = QSlider(Qt.Orientation.Horizontal, self)
        self.thresh_slider.setMinimum(1)
        self.thresh_slider.setMaximum(50)  # Represents 0.01 to 0.50
        self.thresh_slider.setValue(10)      # 10 => 0.10 threshold
        self.thresh_slider.valueChanged.connect(self.updateThreshold)
        thresh_layout.addWidget(self.thresh_label)
        thresh_layout.addWidget(self.thresh_slider)
        layout.addLayout(thresh_layout)

        # --- Process Button ---
        self.process_button = QPushButton("Process (Cosmetic Correction, Preprocess, and Search)", self)
        self.process_button.clicked.connect(self.process)
        layout.addWidget(self.process_button)

        # --- Progress Labels ---
        self.preprocess_progress_label = QLabel("Preprocessing progress: 0 / 0", self)
        self.search_progress_label = QLabel("Processing progress: 0 / 0", self)
        layout.addWidget(self.preprocess_progress_label)
        layout.addWidget(self.search_progress_label)

        # -- Add a new status label --
        self.status_label = QLabel("Status: Idle", self)
        layout.addWidget(self.status_label)

        # --- New Instance Button ---
        self.new_instance_button = QPushButton("New Instance", self)
        self.new_instance_button.clicked.connect(self.newInstance)
        layout.addWidget(self.new_instance_button)

        self.setLayout(layout)
        self.setWindowTitle("Supernova/Asteroid Hunter")

    def updateThreshold(self, value):
        threshold = value / 100.0  # e.g. slider value 10 becomes 0.10
        self.parameters["threshold"] = threshold
        self.thresh_label.setText(f"Anomaly Detection Threshold: {threshold:.2f}")

    def selectReferenceImage(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Reference Image", "",
                                                   "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_path:
            self.parameters["referenceImagePath"] = file_path
            self.ref_line_edit.setText(os.path.basename(file_path))

    def selectSearchImages(self):
        file_paths, _ = QFileDialog.getOpenFileNames(self, "Select Search Images", "",
                                                     "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if file_paths:
            self.parameters["searchImagePaths"] = file_paths
            self.search_list.clear()
            for path in file_paths:
                self.search_list.addItem(os.path.basename(path))

    def process(self):
        self.status_label.setText("Process started...")
        QApplication.processEvents()

        # If cosmetic correction is enabled, run it first
        if self.cosmetic_checkbox.isChecked():
            self.status_label.setText("Running Cosmetic Correction...")
            QApplication.processEvents()
            self.runCosmeticCorrectionIfNeeded()

        self.status_label.setText("Preprocessing images...")
        QApplication.processEvents()
        self.preprocessImages()

        self.status_label.setText("Analyzing anomalies...")
        QApplication.processEvents()
        self.runSearch()

        self.status_label.setText("Process complete.")
        QApplication.processEvents()


    def runCosmeticCorrectionIfNeeded(self):
        """
        Runs cosmetic correction on each search image...
        """
        # Dictionary to hold corrected images
        self.cosmetic_images = {}

        for idx, image_path in enumerate(self.parameters["searchImagePaths"]):
            try:
                # Update status label to show which image is being handled
                self.status_label.setText(f"Cosmetic Correction: {idx+1}/{len(self.parameters['searchImagePaths'])} => {os.path.basename(image_path)}")
                QApplication.processEvents()

                img, header, bit_depth, is_mono = load_image(image_path)
                if img is None:
                    print(f"Unable to load image: {image_path}")
                    continue

                # Numba correction
                corrected = bulk_cosmetic_correction_numba(
                    img,
                    hot_sigma=5.0,
                    cold_sigma=5.0,
                    window_size=3
                )
                self.cosmetic_images[image_path] = corrected
                print(f"Cosmetic correction (Numba) applied to: {image_path}")

            except Exception as e:
                print(f"Error in cosmetic correction for {image_path}: {e}")


    def preprocessImages(self):
        # Update status label for reference image
        self.status_label.setText("Preprocessing reference image...")
        QApplication.processEvents()

        ref_path = self.parameters["referenceImagePath"]
        if not ref_path:
            QMessageBox.warning(self, "Error", "No reference image selected.")
            return

        try:
            ref_img, header, bit_depth, is_mono = load_image(ref_path)

            # Create a debug prefix from the reference path (e.g. "C:/data/ref_debug")
            debug_prefix_ref = os.path.splitext(ref_path)[0] + "_debug_ref"

            self.status_label.setText("Applying background neutralization & ABE on reference...")
            QApplication.processEvents()

            # Pass debug_prefix_ref to preprocessImage
            ref_processed = self.preprocessImage(ref_img, debug_prefix=debug_prefix_ref)
            self.preprocessed_reference = ref_processed
            self.preprocess_progress_label.setText("Preprocessing reference image... Done.")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to preprocess reference image: {e}")
            return

        self.preprocessed_search = []
        search_paths = self.parameters["searchImagePaths"]
        for i, path in enumerate(search_paths):
            try:
                self.status_label.setText(f"Preprocessing search image {i+1}/{len(search_paths)} => {os.path.basename(path)}")
                QApplication.processEvents()

                # Create a debug prefix from the search path
                debug_prefix_search = os.path.splitext(path)[0] + f"_debug_search_{i+1}"

                if hasattr(self, 'cosmetic_images') and path in self.cosmetic_images:
                    img = self.cosmetic_images[path]
                else:
                    img, header, bit_depth, is_mono = load_image(path)

                # Pass debug_prefix_search to preprocessImage
                processed = self.preprocessImage(img, debug_prefix=debug_prefix_search)
                self.preprocessed_search.append({"path": path, "image": processed})

                self.preprocess_progress_label.setText(f"Preprocessing image {i+1} of {len(search_paths)}... Done.")
                QApplication.processEvents()

            except Exception as e:
                print(f"Failed to preprocess {path}: {e}")

        self.status_label.setText("All search images preprocessed.")
        QApplication.processEvents()



    def preprocessImage(self, img, debug_prefix=None):
        """
        Runs the full preprocessing chain on a single image:
        1. Background Neutralization
        2. Automatic Background Extraction (ABE)
        3. Pixel-math stretching

        Optionally saves debug images if debug_prefix is provided.
        """


        # --- Step 1: Background Neutralization ---
        if img.ndim == 3 and img.shape[2] == 3:
            h, w, _ = img.shape
            sample_x = int(w * 0.45)
            sample_y = int(h * 0.45)
            sample_w = max(1, int(w * 0.1))
            sample_h = max(1, int(h * 0.1))
            sample_region = img[sample_y:sample_y+sample_h, sample_x:sample_x+sample_w, :]
            medians = np.median(sample_region, axis=(0, 1))
            average_median = np.mean(medians)
            neutralized = img.copy()
            for c in range(3):
                diff = medians[c] - average_median
                numerator = neutralized[:, :, c] - diff
                denominator = 1.0 - diff
                if abs(denominator) < 1e-8:
                    denominator = 1e-8
                neutralized[:, :, c] = np.clip(numerator / denominator, 0, 1)
        else:
            neutralized = img


        # --- Step 2: Automatic Background Extraction (ABE) ---
        pgr = PolyGradientRemoval(
            neutralized,
            poly_degree=2,          # or pass in a user choice
            downsample_scale=4,
            num_sample_points=100
        )
        abe = pgr.process()  # returns final polynomial-corrected image in original domain


        # --- Step 3: Pixel Math Stretch ---
        stretched = self.pixel_math_stretch(abe)

        return stretched



    def pixel_math_stretch(self, image):
        """
        Replaces the old pixel math stretch logic by using the existing
        stretch_mono_image or stretch_color_image methods. 
        """
        # Choose a target median (the default you’ve used elsewhere is often 0.25)
        target_median = 0.25

        # Check if the image is mono or color
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Treat it as mono
            stretched = stretch_mono_image(
                image.squeeze(),  # squeeze in case it's (H,W,1)
                target_median=target_median,
                normalize=False,  # Adjust if you want normalization
                apply_curves=False,
                curves_boost=0.0
            )
            # If it was (H,W,1), replicate to 3 channels (optional)
            # or just keep it mono if you prefer
            # For now, replicate to 3 channels:
            stretched = np.stack([stretched]*3, axis=-1)
        else:
            # Full-color image
            stretched = stretch_color_image(
                image,
                target_median=target_median,
                linked=False,      # or False if you want per-channel stretches
                normalize=False,  
                apply_curves=False,
                curves_boost=0.0
            )

        return np.clip(stretched, 0, 1)

    def runSearch(self):
        if self.preprocessed_reference is None:
            QMessageBox.warning(self, "Error", "Reference image not preprocessed.")
            return
        if not self.preprocessed_search:
            QMessageBox.warning(self, "Error", "No search images preprocessed.")
            return

        ref_gray = self.to_grayscale(self.preprocessed_reference)

        self.anomalyData = []
        total = len(self.preprocessed_search)
        for i, search_dict in enumerate(self.preprocessed_search):
            search_img = search_dict["image"]
            search_gray = self.to_grayscale(search_img)

            diff_img = self.subtractImagesOnce(search_gray, ref_gray)
            anomalies = self.detectAnomaliesConnected(diff_img, threshold=self.parameters["threshold"])

            # Just store the anomalies
            self.anomalyData.append({
                "imageName": os.path.basename(search_dict["path"]),
                "anomalyCount": len(anomalies),
                "anomalies": anomalies
            })

            self.search_progress_label.setText(f"Processing image {i+1} of {total}...")
            QApplication.processEvents()

        self.search_progress_label.setText("Search for anomalies complete.")

        # Optionally still show the text-based summary:
        self.showDetailedResultsDialog(self.anomalyData)

        # Now build & show the anomaly tree for user double-click
        self.showAnomalyListDialog()

    def showAnomalyListDialog(self):
        """
        Build a QDialog with a QTreeWidget listing each image and its anomaly count.
        Double-clicking an item will open a non-modal preview.
        """
        if not self.anomalyData:
            QMessageBox.information(self, "Info", "No anomalies or no images processed.")
            return

        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Results")

        layout = QVBoxLayout(dialog)

        self.anomaly_tree = QTreeWidget(dialog)
        self.anomaly_tree.setColumnCount(2)
        self.anomaly_tree.setHeaderLabels(["Image", "Anomaly Count"])
        layout.addWidget(self.anomaly_tree)

        # Populate the tree
        for i, data in enumerate(self.anomalyData):
            item = QTreeWidgetItem([
                data["imageName"],
                str(data["anomalyCount"])
            ])
            # Store an index or reference so we know which image to open
            item.setData(0, Qt.ItemDataRole.UserRole, i)
            self.anomaly_tree.addTopLevelItem(item)

        # Connect double-click
        self.anomaly_tree.itemDoubleClicked.connect(self.onAnomalyItemDoubleClicked)

        dialog.setLayout(layout)
        dialog.resize(300, 200)
        dialog.show()  # non-modal, so the user can keep using the main window

    def onAnomalyItemDoubleClicked(self, item, column):
        """
        Called when the user double-clicks a row in the anomaly tree.
        We'll open a MosaicPreviewWindow showing bounding boxes for that image.
        """
        # Retrieve the index we stored
        idx = item.data(0, Qt.ItemDataRole.UserRole)
        if idx is None:
            return

        # anomalies from anomalyData
        anomalies = self.anomalyData[idx]["anomalies"]
        image_name = self.anomalyData[idx]["imageName"]

        # The preprocessed image from self.preprocessed_search
        # We assume the i-th preprocessed image matches the i-th anomalyData.
        # Make sure your code lines up these two lists the same order.
        # e.g., i=0 => self.preprocessed_search[0], self.anomalyData[0]
        search_img = self.preprocessed_search[idx]["image"]  # already in [0..1], shape (H,W,3)

        if anomalies:
            # Create an annotated image
            annotated_8bit = self.draw_bounding_boxes_on_stretched(search_img, anomalies)

            # Pass to MosaicPreviewWindow
            preview = MosaicPreviewWindow(
                annotated_8bit, 
                title=f"Anomalies in {image_name}", 
                parent=self
            )
            # Optionally disable auto-stretch so the boxes remain bright
            preview.stretch_toggle.setChecked(False)
            preview.resize(800, 600)
            preview.show()  # non-modal
        else:
            QMessageBox.information(self, "No Anomalies", f"No anomalies found for {image_name}.")


    def draw_bounding_boxes_on_stretched(self,
        stretched_image: np.ndarray, 
        anomalies: list
    ) -> np.ndarray:
        """
        1) Convert 'stretched_image' [0..1] -> [0..255] 8-bit color
        2) Draw red rectangles for each anomaly in 'anomalies'.
        Each anomaly is assumed to have keys: minX, minY, maxX, maxY
        3) Return the 8-bit color image (H,W,3).
        """
        # Ensure 3 channels
        if stretched_image.ndim == 2:
            stretched_3ch = np.stack([stretched_image]*3, axis=-1)
        elif stretched_image.ndim == 3 and stretched_image.shape[2] == 1:
            stretched_3ch = np.concatenate([stretched_image]*3, axis=2)
        else:
            stretched_3ch = stretched_image

        # Convert float [0..1] => uint8 [0..255]
        img_bgr = (stretched_3ch * 255).clip(0,255).astype(np.uint8)

        # Define the margin
        margin = 15

        # Draw red boxes in BGR color = (0, 0, 255)
        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Expand the bounding box by a 10-pixel margin
            x1_exp = x1 - margin
            y1_exp = y1 - margin
            x2_exp = x2 + margin
            y2_exp = y2 + margin
            cv2.rectangle(
                img_bgr, (x1_exp, y1_exp), (x2_exp, y2_exp),
                color=(255, 0, 0),
                thickness=5
            )

        return img_bgr


    def subtractImagesOnce(self, search_img, ref_img, debug_prefix=None):
        """
        Compute the absolute difference of two images (both already grayscale).
        Both images must have the same dimensions.

        Optionally, if 'debug_prefix' is provided, save the difference
        as a debug image. For example: "mydebugprefix_diff.tif".
        """
        if search_img.shape != ref_img.shape:
            raise ValueError("Image dimensions do not match for difference.")

        # Both search_img and ref_img are assumed in [0..1]
        # so the absolute difference will also be in [0..1].
        result = search_img - ref_img
        print("Computed difference between search and reference images.")

        # If debug_prefix is specified, save the difference image
        # For example:
        #self.debug_save_image(
        #    result,
        #    prefix=debug_prefix,
        #    step_name="diff",
        #    ext=".tif"
        #)
        np.clip(result, 0, 1)  # Ensure result is in [0..1]
        return result

    def debug_save_image(self, image, prefix="debug", step_name="step", ext=".tif"):
        """
        Saves 'image' to disk for debugging. 
        - 'prefix' can be a directory path or prefix for your debug images.
        - 'step_name' is appended to the filename to indicate which step.
        - 'ext' could be '.tif', '.png', or another format you support.

        This example uses your 'save_image' function from earlier or can
        directly use tiff.imwrite or similar.
        """

        # Ensure the image is float32 in [0..1] before saving
        image = image.astype(np.float32, copy=False)

        # Build debug filename
        filename = f"{prefix}_{step_name}{ext}"

        # E.g., if you have a global 'save_image' function:
        save_image(
            image, 
            filename,
            original_format="tif",  # or "png", "fits", etc.
            bit_depth="16-bit"
        )
        print(f"[DEBUG] Saved {step_name} => {filename}")

    def to_grayscale(self, image):
        """
        Converts an image to grayscale by averaging channels if needed.
        If the image is already 2D, return it as is.
        """
        if image.ndim == 2:
            # Already grayscale
            return image
        elif image.ndim == 3 and image.shape[2] == 3:
            # Average the three channels
            return np.mean(image, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:
            # Squeeze out that single channel
            return image[:, :, 0]
        else:
            raise ValueError(f"Unsupported image shape for grayscale: {image.shape}")

    def detectAnomaliesConnected(self, diff_img: np.ndarray, threshold: float = 0.1):
        """
        1) Build mask = diff_img > threshold.
        2) Optionally skip 5% border by zeroing out that region in the mask.
        3) connectedComponentsWithStats => bounding boxes.
        4) Filter by min_area, etc.
        5) Return a list of anomalies, each with minX, minY, maxX, maxY, area.
        """
        h, w = diff_img.shape

        # 1) Create the mask
        mask = (diff_img > threshold).astype(np.uint8)

        # 2) Skip 5% border (optional)
        border_x = int(0.05 * w)
        border_y = int(0.05 * h)
        mask[:border_y, :] = 0
        mask[h - border_y:, :] = 0
        mask[:, :border_x] = 0
        mask[:, w - border_x:] = 0

        # 3) connectedComponentsWithStats => label each region
        # connectivity=8 => 8-way adjacency
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)

        # stats[i] = [x, y, width, height, area], for i in [1..num_labels-1]
        # label_id=0 => background

        anomalies = []
        for label_id in range(1, num_labels):
            x, y, width_, height_, area_ = stats[label_id]

            # bounding box corners
            minX = x
            minY = y
            maxX = x + width_ - 1
            maxY = y + height_ - 1

            # 4) Filter out tiny or huge areas if you want:
            # e.g., skip anything <4x4 => area<16
            if area_ < 25:
                continue
            # e.g., skip bounding boxes bigger than 40 in either dimension if you want
            if width_ > 200 or height_ > 200:
                continue

            anomalies.append({
                "minX": minX,
                "minY": minY,
                "maxX": maxX,
                "maxY": maxY,
                "area": area_
            })

        return anomalies


    def showDetailedResultsDialog(self, anomalyData):
        dialog = QDialog(self)
        dialog.setWindowTitle("Anomaly Detection Results")
        layout = QVBoxLayout(dialog)
        text_edit = QTextEdit(dialog)
        text_edit.setReadOnly(True)
        result_text = "Detailed Anomaly Results:\n\n"

        for data in anomalyData:
            result_text += f"Image: {data['imageName']}\nAnomalies: {data['anomalyCount']}\n"
            for group in data["anomalies"]:
                # Now refer to 'minX', 'minY', 'maxX', 'maxY'
                result_text += (
                    f"  Group Bounding Box: "
                    f"Top-Left ({group['minX']}, {group['minY']}), "
                    f"Bottom-Right ({group['maxX']}, {group['maxY']})\n"
                )
            result_text += "\n"

        text_edit.setText(result_text)
        layout.addWidget(text_edit)
        dialog.setLayout(layout)
        dialog.show()

    def showAnomaliesOnImage(self, image: np.ndarray, anomalies: list, window_title="Anomalies"):
        """
        Displays 'image' in a QDialog with red bounding boxes for each anomaly.
        'image' is assumed to be float32 in [0..1], shape (H,W) or (H,W,3).
        'anomalies' is a list of dicts, each with keys: minX, minY, maxX, maxY, etc.
        """
        # 1) Convert to 3-channel if needed
        if image.ndim == 2:
            # grayscale => replicate to 3-ch so we can draw colored rectangles
            image_3ch = np.stack([image, image, image], axis=-1)
        elif image.ndim == 3 and image.shape[2] == 1:
            # single-channel in last dimension
            image_3ch = np.concatenate([image, image, image], axis=2)
        else:
            image_3ch = image

        # 2) Convert float [0..1] => uint8 [0..255], and reorder to BGR if needed
        # OpenCV expects BGR order for color. If your array is already RGB, we can just treat it as BGR if color correctness isn't critical. 
        # For a quick approach, let's do it directly:
        image_bgr = (image_3ch * 255).astype(np.uint8)

        # 3) Draw bounding boxes with a margin
        margin = 10  # You can adjust this as desired
        height, width = image_bgr.shape[:2]

        for anomaly in anomalies:
            x1, y1 = anomaly["minX"], anomaly["minY"]
            x2, y2 = anomaly["maxX"], anomaly["maxY"]

            # Inflate the bounding box
            x1 = max(0, x1 - margin)
            y1 = max(0, y1 - margin)
            x2 = min(width - 1,  x2 + margin)
            y2 = min(height - 1, y2 + margin)

            # Draw the rectangle (BGR color=(255,0,0) => Blue if you want red use (0,0,255))
            cv2.rectangle(
                image_bgr, 
                (x1, y1), (x2, y2), 
                color=(255, 0, 0),  # Blue in BGR
                thickness=5
            )


        # 4) Convert the annotated BGR image back to QImage => QPixmap => show in QDialog
        # We can do something like:
        height, width = image_bgr.shape[:2]

        # For color images, QImage.Format_RGB888 expects an RGB order
        # We can convert BGR->RGB by:
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        qimg = QImage(
            image_rgb.data, 
            width, 
            height, 
            3 * width, 
            QImage.Format.Format_RGB888
        )
        pixmap = QPixmap.fromImage(qimg)

        # 5) Show in a simple QDialog with a QLabel or QGraphicsView
        dialog = QDialog(self)
        dialog.setWindowTitle(window_title)
        layout = QVBoxLayout(dialog)

        label = QLabel(dialog)
        label.setPixmap(pixmap)
        layout.addWidget(label)

        dialog.setLayout(layout)
        dialog.resize(width, height)
        dialog.show()


    def newInstance(self):
        # Reset parameters and UI elements for a new run
        self.parameters = {"referenceImagePath": "", "searchImagePaths": [], "threshold": 0.10}
        self.ref_line_edit.clear()
        self.search_list.clear()
        self.cosmetic_checkbox.setChecked(False)
        self.thresh_slider.setValue(10)
        self.preprocess_progress_label.setText("Preprocessing progress: 0 / 0")
        self.search_progress_label.setText("Processing progress: 0 / 0")
        self.preprocessed_reference = None
        self.preprocessed_search = []
        self.anomalyData = []
        QMessageBox.information(self, "New Instance", "Reset for a new instance.")

class HDRWorker(QObject):
    """
    Worker class to perform WaveScale HDRation in a separate thread.
    Emits signals to update progress.
    """
    progress_update = pyqtSignal(str, int)  # Signal: (current_step, percent_complete)
    finished = pyqtSignal(np.ndarray, np.ndarray)  # Signal: (transformed_rgb, mask)

    def __init__(self, rgb_image, n_scales, compression_factor, mask_gamma, b3_spline_kernel):
        super().__init__()
        self.rgb_image = rgb_image
        self.n_scales = n_scales
        self.compression_factor = compression_factor
        self.mask_gamma = mask_gamma
        self.b3_spline_kernel = b3_spline_kernel

    def run(self):
        try:
            # Step 1: Convert to Lab
            self.progress_update.emit("Converting to Lab color space...", 10)
            lab = self.rgb_to_lab(self.rgb_image)
            L_original = lab[..., 0].copy()  # Store original L for median calculation
            L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

            # Step 2: Decompose using à trous wavelet
            self.progress_update.emit("Performing wavelet decomposition...", 20)
            scales = self.atrous_wavelet_decompose(L, self.n_scales)

            # Step 3: Create Luminance Mask
            self.progress_update.emit("Creating luminance mask...", 30)
            mask = self.create_luminance_mask(L, gamma=self.mask_gamma)

            # Step 4: Apply mask to wavelet planes
            self.progress_update.emit("Applying mask to wavelet planes...", 40)
            wavelet_planes = scales[:-1]
            residual = scales[-1]

            # Step 5: Enhance wavelet planes based on mask and compression factor with decaying influence
            self.progress_update.emit("Enhancing wavelet planes...", 50)
            decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
            for i in range(len(wavelet_planes)):
                # Calculate decay factor for the current scale
                decay_factor = decay_rate ** i  # Higher scales have smaller decay_factor
                # Compute scaling factor with decay
                scaling_factor = (1.0 + (self.compression_factor - 1.0) * mask * decay_factor) * 2
                # Apply scaling to the wavelet plane
                wavelet_planes[i] *= scaling_factor
                # Emit intermediate progress
                percent = 50 + int(((i + 1) / len(wavelet_planes)) * 10)  # Distribute 10% across scales
                self.progress_update.emit(f"Enhancing wavelet scale {i+1}...", percent)

            # Step 6: Reconstruct L channel
            self.progress_update.emit("Reconstructing L channel...", 60)
            L_reconstructed = self.atrous_wavelet_reconstruct(wavelet_planes + [residual])

            # Step 7: Apply midtones transfer to align median luminance
            self.progress_update.emit("Applying midtones transfer...", 70)
            median_original = np.median(L_original)
            median_reconstructed = np.median(L_reconstructed)

            if median_reconstructed == 0:
                scaling_midtones = 1.0
            else:
                scaling_midtones = median_original / median_reconstructed

            L_reconstructed *= scaling_midtones
            L_reconstructed = np.clip(L_reconstructed, 0, 100)

            # Update the Lab image with the reconstructed L channel
            lab[..., 0] = L_reconstructed

            # Step 8: Convert back to RGB
            self.progress_update.emit("Converting back to RGB color space...", 80)
            transformed_rgb = self.lab_to_rgb(lab)

            # Step 9: Apply a non-linear curve to the HDR-enhanced image to dim bright areas
            self.progress_update.emit("Applying dimming curve...", 90)
            transformed_rgb = self.apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0 + self.n_scales * 0.2)

            # Step 10: Finish
            self.progress_update.emit("Finalizing...", 100)
            self.finished.emit(transformed_rgb, mask)

        except Exception as e:
            print(f"Error during HDR transformation: {e}")
            self.finished.emit(None, None)

    # Define necessary methods copied from the main dialog
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

    def apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    def create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100)^gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)


class WaveScaleHDRDialog(QDialog):
    """
    A self-contained WaveScale HDR dialog that:
      - Displays a preview of the image in a QGraphicsView.
      - Uses à trous (starlet) wavelet decomposition on the L channel in Lab space.
      - Lets you adjust # of scales, coarse compression, and mask gamma, then preview or apply.
      - Applies a simple L-based mask (absolute luminance scaled to [0..1]^gamma) so bright areas get full HDR,
        and dark areas get minimal changes.
      - Displays the luminance mask in a separate window for debugging purposes.
    """

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("WaveScale HDR")
        self.setMinimumSize(800, 600)  # Increased width to better accommodate preview and mask display

        self.image_manager = image_manager

        self.showing_original = False

        # Detect if the image is grayscale or RGB
        if self.image_manager.image.ndim == 2:
            self.is_grayscale = True
            # Convert to 3-channel by stacking
            self.original_image_rgb = np.stack([self.image_manager.image] * 3, axis=-1)
        elif self.image_manager.image.ndim == 3 and self.image_manager.image.shape[2] == 3:
            self.is_grayscale = False
            self.original_image_rgb = self.image_manager.image.copy()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format.")
            self.reject()
            return  # Exit initialization if image format is unsupported

        # Make local copies for preview and original
        self.original_image = np.clip(self.original_image_rgb.astype(np.float32), 0, 1)
        self.preview_image = self.original_image.copy()

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the preview area (QGraphicsView in a scrollable region)
        self._create_preview_area()
        self._create_zoom_area()

        # 2) Create the HDR controls
        self._create_controls()

        # 3) Lay out preview & controls with progress display
        content_layout = QVBoxLayout()
        content_layout.addWidget(self.scroll_area)
        content_layout.addWidget(self.zoom_group_box)

        # Create the Progress Display Area
        self._create_progress_display()

        # Create a Horizontal Layout to hold controls and progress side by side
        hbox_layout = QHBoxLayout()
        hbox_layout.addWidget(self.controls_group, stretch=3)        # Allocate more space to controls
        hbox_layout.addWidget(self.progress_group_box, stretch=1)   # Allocate less space to progress

        content_layout.addLayout(hbox_layout)  # Add the HBoxLayout to the content_layout

        self.main_layout.addLayout(content_layout)

        # 4) Bottom buttons (Apply / Cancel)
        self._create_bottom_buttons()

        # 5) Initialize and show the mask display window
        self._create_mask_window()

        # B3-spline kernel for à trous wavelet
        self.b3_spline_kernel = np.array([1, 4, 6, 4, 1], dtype=np.float32) / 16.0

        # Initialize zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Convert original image to Lab and compute initial mask
        self.lab_original = self.rgb_to_lab(self.original_image)
        self.L_original = self.lab_original[..., 0].copy()  # Store original L for mask computation
        self.mask = self._create_luminance_mask(self.L_original, gamma=self.mask_gamma_slider.value() / 100.0)



        # Show the initial preview
        self._update_preview_pixmap(self.preview_image)

        # Show the initial mask in MaskDisplayWindow
        self.mask_window.update_mask(self.mask)        

        self.apply_button.setEnabled(False)
        self.preview_button.clicked.connect(self._enable_apply_button)   
        self.mask_gamma_slider.valueChanged.connect(self._on_mask_gamma_changed)        

    def _on_mask_gamma_changed(self, value):
        """
        Recompute the luminance mask based on the new gamma value and update the mask display.
        
        Args:
            value (int): The new value from the mask_gamma_slider.
        """
        try:
            gamma = value / 100.0  # Convert slider value to gamma
            self.mask = self._create_luminance_mask(self.L_original, gamma=gamma)
            self.mask_window.update_mask(self.mask)
            print(f"Mask gamma changed to {gamma}, mask updated.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update mask: {e}")

    # -------------------------------------------------------------------------
    # 1) Zoom AREA
    # -------------------------------------------------------------------------
    def _create_zoom_area(self):
        """Create a QGroupBox containing Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_group_box = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Fit to Preview Button
        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_group_box.setLayout(zoom_layout)

    def _fit_to_preview(self):
        """Fit the entire image within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No image to fit

        # Fit the pixmap within the view, maintaining aspect ratio
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

        # Reset zoom factor
        self.zoom_factor = 1.0

    # -------------------------------------------------------------------------
    # 1) PREVIEW AREA
    # -------------------------------------------------------------------------
    def _create_preview_area(self):
        """Create a QGraphicsView & QGraphicsScene for the preview, inside a scroll area."""
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)

        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Optionally, enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        self.scroll_area.setWidget(self.graphics_view)

    # -------------------------------------------------------------------------
    # 2) CONTROLS
    # -------------------------------------------------------------------------
    def _create_controls(self):
        """Create the HDR sliders (# scales, compression, mask gamma) and zoom buttons."""
        self.controls_group = QGroupBox("HDR Controls")
        controls_layout = QFormLayout()

        # Number of scales
        self.scales_slider = QSlider(Qt.Orientation.Horizontal)
        self.scales_slider.setRange(2, 10)
        self.scales_slider.setValue(5)
        self.scales_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.scales_slider.setTickInterval(1)
        controls_layout.addRow("Number of Scales:", self.scales_slider)

        # Coarse compression
        self.compression_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => factor = 0.1..3.0
        self.compression_slider.setRange(10, 500)
        self.compression_slider.setValue(150)
        self.compression_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.compression_slider.setTickInterval(10)
        controls_layout.addRow("Coarse Compression:", self.compression_slider)

        # Mask gamma
        self.mask_gamma_slider = QSlider(Qt.Orientation.Horizontal)
        # 10..300 => gamma = 0.1..3.0
        self.mask_gamma_slider.setRange(10, 1000)
        self.mask_gamma_slider.setValue(500)
        self.mask_gamma_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.mask_gamma_slider.setTickInterval(10)
        controls_layout.addRow("Mask Gamma:", self.mask_gamma_slider)

        buttons_layout = QHBoxLayout()

        # Preview Button
        self.preview_button = QPushButton("Preview")
        self.preview_button.clicked.connect(self._on_preview_clicked)
        buttons_layout.addWidget(self.preview_button)

        self.toggle_button = QPushButton("Show Original")
        self.toggle_button.setCheckable(True)
        self.toggle_button.clicked.connect(self._toggle_image)
        buttons_layout.addWidget(self.toggle_button)

        controls_layout.addRow(buttons_layout)

        self.controls_group.setLayout(controls_layout)

    # -------------------------------------------------------------------------
    # 3) BOTTOM BUTTONS
    # -------------------------------------------------------------------------
    def _create_bottom_buttons(self):
        bottom_layout = QHBoxLayout()

        self.apply_button = QPushButton("Apply")
        self.apply_button.clicked.connect(self._on_apply_clicked)
        bottom_layout.addWidget(self.apply_button)

        self.reset_button = QPushButton("Reset")
        self.reset_button.clicked.connect(self._on_reset_clicked)
        bottom_layout.addWidget(self.reset_button)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        bottom_layout.addWidget(self.cancel_button)

        self.main_layout.addLayout(bottom_layout)

    # -------------------------------------------------------------------------
    # 4) MASK DISPLAY WINDOW
    # -------------------------------------------------------------------------
    def _create_mask_window(self):
        """Initialize and show the separate mask display window."""
        self.mask_window = MaskDisplayWindow(self)
        self.mask_window.show()

    # -------------------------------------------------------------------------
    # 5) Progress Display Area
    # -------------------------------------------------------------------------
    def _create_progress_display(self):
        """Create a progress display area on the right side of the content_layout."""
        self.progress_group_box = QGroupBox("Processing Progress")
        progress_layout = QVBoxLayout()

        # Current Step Label
        self.current_step_label = QLabel("Idle")
        self.current_step_label.setAlignment(Qt.AlignmentFlag.AlignTop)
        progress_layout.addWidget(self.current_step_label)

        # Progress Bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        progress_layout.addWidget(self.progress_bar)

        self.progress_group_box.setLayout(progress_layout)

    def _toggle_image(self):
        if self.toggle_button.isChecked():
            # user wants to see the *un*-processed original
            self.toggle_button.setText("Show Preview")
            self._update_preview_pixmap(self.original_image)
            self.showing_original = True
        else:
            # back to the HDR preview
            self.toggle_button.setText("Show Original")
            self._update_preview_pixmap(self.preview_image)
            self.showing_original = False

    def _on_reset_clicked(self):
        """Reset the image and sliders to their default states."""
        try:
            # Reset sliders to default values
            self.scales_slider.setValue(5)
            self.compression_slider.setValue(150)
            self.mask_gamma_slider.setValue(500)

            # Reset the preview image to the original image
            self.preview_image = self.original_image.copy()
            self._update_preview_pixmap(self.preview_image)

            # Reset progress display
            self.current_step_label.setText("Idle")
            self.progress_bar.setValue(0)

            # Disable the Apply button since no changes are pending
            self.apply_button.setEnabled(False)

            # Optionally, reset the zoom to default
            self.zoom_factor = 1.0
            self.graphics_view.resetTransform()

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to reset: {e}")

    # -------------------------------------------------------------------------
    # PREVIEW / APPLY
    # -------------------------------------------------------------------------
    def _on_preview_clicked(self):
        """Generate a preview image with current settings and display it."""
        try:
            # Disable buttons to prevent multiple clicks
            self.preview_button.setEnabled(False)
            self.apply_button.setEnabled(False)

            # Reset progress display
            self.current_step_label.setText("Starting HDR Transformation...")
            self.progress_bar.setValue(0)

            # Gather current settings
            n_scales = self.scales_slider.value()
            compression_factor = self.compression_slider.value() / 100.0
            mask_gamma = self.mask_gamma_slider.value() / 100.0

            # Initialize worker and thread
            self.worker = HDRWorker(
                rgb_image=self.original_image,
                n_scales=n_scales,
                compression_factor=compression_factor,
                mask_gamma=mask_gamma,
                b3_spline_kernel=self.b3_spline_kernel
            )
            self.thread = QThread()
            self.worker.moveToThread(self.thread)

            # Connect signals
            self.thread.started.connect(self.worker.run)
            self.worker.progress_update.connect(self._update_progress)
            self.worker.finished.connect(self._on_worker_finished)
            self.worker.finished.connect(self.thread.quit)
            self.worker.finished.connect(self.worker.deleteLater)
            self.thread.finished.connect(self.thread.deleteLater)

            # Start the thread
            self.thread.start()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))
            self.preview_button.setEnabled(True)
            self.apply_button.setEnabled(False)

    def _update_progress(self, step, percent):
        """Update the progress display based on signals from the worker."""
        self.current_step_label.setText(step)
        self.progress_bar.setValue(percent)

    def _on_worker_finished(self, transformed_rgb, mask):
        """Handle the completion of the worker thread."""
        if transformed_rgb is not None:
            if self.is_grayscale:
                # For grayscale, take one channel and keep it single-channel
                mask_expanded = mask[:, :, np.newaxis]  # Shape: (h, w, 1)
                blended_preview = self.original_image[:, :, 0:1] * (1 - mask_expanded) + transformed_rgb[:, :, 0:1] * mask_expanded
                # Stack back to 3 channels for consistent display
                blended_preview = np.repeat(blended_preview, 3, axis=2)
            else:
                # For RGB
                mask_expanded = np.repeat(mask[:, :, np.newaxis], 3, axis=2)  # Shape: (h, w, 3)
                blended_preview = self.original_image * (1 - mask_expanded) + transformed_rgb * mask_expanded

            # Update preview image
            self.preview_image = blended_preview
            self._update_preview_pixmap(blended_preview)

            self.toggle_button.setChecked(False)
            self.toggle_button.setText("Show Original")
            self.showing_original = False

            # Enable Apply button
            self.apply_button.setEnabled(True)

        else:
            QMessageBox.critical(self, "Error", "WaveScale HDR failed.")

        # Re-enable preview button
        self.preview_button.setEnabled(True)

    def _enable_apply_button(self):
        """Enable the Apply button after a preview is generated."""
        self.apply_button.setEnabled(True)

    def _on_apply_clicked(self):
        """Apply the HDR transform to the main image manager and close the dialog."""
        try:
            # Check if a preview has been generated
            if not hasattr(self, 'preview_image'):
                QMessageBox.warning(self, "Warning", "Please generate a preview before applying the transformation.")
                return

            # Use the existing preview_image as the output image
            output_image = self.preview_image.copy()

            # Update the main ImageManager
            self.image_manager.set_image(output_image, {"description": "WaveScale HDR"}, step_name="WaveScale HDR")
            QMessageBox.information(self, "Success", "WaveScale HDR applied.")
            self.accept()

        except Exception as e:
            QMessageBox.critical(self, "Error", str(e))

    # -------------------------------------------------------------------------
    # UTILITY: UPDATE PREVIEW PIXMAP
    # -------------------------------------------------------------------------
    def _update_preview_pixmap(self, image):
        """Convert `image` (float32 [0..1]) to QPixmap and display."""
        pixmap = self._convert_image_to_pixmap(image)
        self.pixmap_item.setPixmap(pixmap)
        self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

    def _convert_image_to_pixmap(self, image):
        """Convert float32 [0..1] image to QPixmap (RGB888)."""
        image_uint8 = (np.clip(image, 0, 1) * 255).astype(np.uint8)
        h, w = image_uint8.shape[:2]

        if image_uint8.ndim == 2:
            # Grayscale => expand to 3 channels
            image_uint8 = np.repeat(image_uint8[..., None], 3, axis=2)

        bytes_per_line = 3 * w
        qimage = QImage(
            image_uint8.data, w, h, bytes_per_line, QImage.Format.Format_RGB888
        )
        return QPixmap.fromImage(qimage)

    # -------------------------------------------------------------------------
    # ZOOM METHODS
    # -------------------------------------------------------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self._zoom_in()
        else:
            self._zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def _apply_zoom(self):
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    # -------------------------------------------------------------------------
    # HDR ALGORITHM
    # -------------------------------------------------------------------------
    def _perform_hdr_transform(self, rgb_image, n_scales, compression_factor, mask_gamma):
        """
        1) Convert to Lab
        2) à trous wavelet decompose L
        3) Create L-based mask: M = (L / 100)^gamma
           - bright => near 1
           - dark => near 0
        4) Apply mask to wavelet planes
        5) Compress (enhance) wavelet planes based on mask and compression factor
        6) Reconstruct L
        7) Apply midtones transfer to align median luminance
        8) Convert back to RGB
        9) Return transformed RGB and mask for blending
        """
        # 1) Convert to Lab using custom rgb_to_lab
        lab = self.rgb_to_lab(rgb_image)
        L_original = lab[..., 0].copy()  # Store original L for median calculation

        L = lab[..., 0]  # L in [0..100] as per custom rgb_to_lab

        # 2) Decompose
        scales = self._atrous_wavelet_decompose(L, n_scales)

        # 3) L-based mask
        mask = self._create_luminance_mask(L, gamma=mask_gamma)
        # => bright areas ~1.0, dark areas ~0.0

        # Update the mask display window
        #self.mask_window.update_mask(mask)

        # 4) Apply mask to wavelet planes
        wavelet_planes = scales[:-1]
        residual = scales[-1]

        # 5) Enhance wavelet planes based on mask and compression factor
        decay_rate = 0.5  # Adjust decay rate as needed (0 < decay_rate < 1)
        for i in range(len(wavelet_planes)):
            # Compute scaling factor: 1 + (compression_factor -1) * mask
            decay_factor = decay_rate ** i
            scaling_factor = (1.0 + (compression_factor - 1.0) * mask* decay_factor)*2
            wavelet_planes[i] *= scaling_factor
            print(f"Scale {i} - Scaling Factor Stats: min={scaling_factor.min()}, max={scaling_factor.max()}, mean={scaling_factor.mean()}")
            print(f"Scale {i} - Wavelet Plane Modified Stats: min={wavelet_planes[i].min()}, max={wavelet_planes[i].max()}, mean={wavelet_planes[i].mean()}")

        # Reconstruct L
        L_reconstructed = self._atrous_wavelet_reconstruct(wavelet_planes + [residual])

        # 7) Apply midtones transfer to align median luminance
        median_original = np.median(L_original)
        median_reconstructed = np.median(L_reconstructed)

        if median_reconstructed == 0:
            scaling_midtones = 1.0
        else:
            scaling_midtones = median_original / median_reconstructed

        L_reconstructed *= scaling_midtones
        L_reconstructed = np.clip(L_reconstructed, 0, 100)

        # Update the Lab image with the reconstructed L channel
        lab[..., 0] = L_reconstructed

        # 8) Convert back to RGB using custom lab_to_rgb
        transformed_rgb = self.lab_to_rgb(lab)

        # 9) Return both transformed RGB and mask for blending
        transformed_rgb = self._apply_curve_to_hdr_image(transformed_rgb, curve_type='gamma', strength=1.0+n_scales*0.2)
        return transformed_rgb, mask

    def _apply_curve_to_hdr_image(self, hdr_image, curve_type='gamma', strength=2.0):
        """
        Apply a non-linear curve to the HDR-enhanced image to dim bright areas.

        Args:
            hdr_image (np.ndarray): HDR-enhanced RGB image with values in [0, 1].
            curve_type (str): Type of curve to apply ('gamma').
            strength (float): Strength of the curve effect. For 'gamma', gamma value.

        Returns:
            np.ndarray: Adjusted HDR image.
        """
        if curve_type == 'gamma':
            # Gamma correction to dim the image
            return np.power(hdr_image, strength)
        else:
            raise ValueError("Unsupported curve type. Currently only 'gamma' is supported.")

    def _create_luminance_mask(self, L_channel, gamma=1.0):
        """
        Use absolute luminance scaled to [0..1], then apply gamma:
           M = (L / 100) ^ gamma
        Bright => 1, dark => 0
        """
        # Assuming L_channel is in [0..100]
        mask = L_channel / 100.0
        mask = np.clip(mask, 0.0, 1.0)  # Ensure mask is within [0,1]
        if gamma != 1.0:
            mask = mask ** gamma
        return mask.astype(np.float32)

    def _atrous_wavelet_decompose(self, image_2d, n_scales):
        """
        à trous wavelet decomposition on a 2D (L channel) image.
        Returns [wavelet_plane1, wavelet_plane2, ..., wavelet_planeN, residual].
        """
        current_image = image_2d.copy()
        scales = []

        for scale_idx in range(n_scales):
            # Insert zeros between kernel taps
            spaced_kernel = self._build_spaced_kernel(self.b3_spline_kernel, scale_idx)
            # Separable convolution
            tmp = convolve(current_image, spaced_kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, spaced_kernel.reshape(-1, 1), mode='reflect')

            wavelet_plane = current_image - smooth
            scales.append(wavelet_plane)
            current_image = smooth

        # Final residual
        scales.append(current_image)
        return scales

    def _build_spaced_kernel(self, kernel, scale_idx):
        """
        Insert zeros between kernel taps for the à trous transform.
        scale_idx=0 => use kernel as is.
        scale_idx=1 => place 1 zero between taps (step=2).
        scale_idx=2 => place 3 zeros (step=4), etc.
        """
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced_len = len(kernel) + (len(kernel) - 1) * (step - 1)
        spaced = np.zeros(spaced_len, dtype=kernel.dtype)
        spaced[0::step] = kernel
        return spaced

    def _atrous_wavelet_reconstruct(self, scales):
        """Sum all wavelet planes + final residual to get the reconstructed image."""
        reconstructed = scales[-1].copy()
        for wplane in scales[:-1]:
            reconstructed += wplane
        return reconstructed

    # -------------------------------------------------------------------------
    # COLOR SPACE: CUSTOM LAB CONVERSIONS
    # -------------------------------------------------------------------------
    def rgb_to_lab(self, rgb_image):
        """Convert a 32-bit floating-point RGB image to Lab color space."""
        # Transformation matrix for RGB to XYZ (D65 reference white)
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        # Convert RGB to linear RGB (no gamma correction needed for 32-bit normalized data)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        # Convert RGB to XYZ
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047  # Normalize by D65 reference white
        xyz_image[..., 2] /= 1.08883

        # Convert XYZ to Lab
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        """Convert a 32-bit floating-point Lab image to RGB color space."""
        # Transformation matrix for XYZ to RGB (D65 reference white)
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)

        # Convert Lab to XYZ
        fy = (lab_image[..., 0] + 16.0) / 116.0
        fx = fy + lab_image[..., 1] / 500.0
        fz = fy - lab_image[..., 2] / 200.0

        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4 / 29))

        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)

        xyz_image = np.stack([X, Y, Z], axis=-1)

        # Convert XYZ to RGB
        rgb_image = np.dot(xyz_image.reshape(-1, 3), M_inv.T).reshape(xyz_image.shape)

        # Clip RGB to [0, 1] to maintain valid color ranges
        rgb_image = np.clip(rgb_image, 0.0, 1.0)

        return rgb_image

class DSEWorker(QObject):
    progress_update = pyqtSignal(str, int)
    finished = pyqtSignal(np.ndarray, np.ndarray)

    def __init__(self, rgb_image, n_scales, boost_factor, gamma, b3_spline_kernel, iterations=1, is_mono=False):
        super().__init__()
        self.rgb_image = rgb_image
        self.n_scales = n_scales
        self.boost_factor = boost_factor
        self.gamma = gamma
        self.b3_spline_kernel = b3_spline_kernel
        self.iterations = iterations
        self.is_mono = is_mono

    def run(self):
        try:
            if self.is_mono:
                self.progress_update.emit("Enhancing mono image...", 10)
                L = self.rgb_image.squeeze()  # shape HxW

                for iter_idx in range(self.iterations):
                    if self.iterations > 1:
                        self.progress_update.emit(f"Iteration {iter_idx+1} of {self.iterations}", 10 + iter_idx * int(70 / self.iterations))

                    self.progress_update.emit("Building darkness mask...", 20)
                    mask = self.create_darkness_mask(L, self.gamma)

                    self.progress_update.emit("Decomposing via à trous...", 30)
                    wavelet_planes, residual = self.atrous_wavelet_decompose(L)

                    self.progress_update.emit("Enhancing dark structures...", 50)
                    decay_rate = 0.5
                    for i in range(len(wavelet_planes)):
                        if i == 0:
                            continue
                        decay_factor = decay_rate ** i
                        neg = np.clip(-wavelet_planes[i], 0, None)
                        enhancement = neg * mask * (self.boost_factor - 1.0) * decay_factor
                        wavelet_planes[i] -= enhancement
                        self.progress_update.emit(f"Enhancing scale {i+1}", 50 + int(i / len(wavelet_planes) * 20))

                    self.progress_update.emit("Reconstructing L...", 80)
                    L = np.clip(self.atrous_wavelet_reconstruct(wavelet_planes + [residual]), 0, 1)

                self.progress_update.emit("Done", 100)
                output = L[..., np.newaxis] if self.rgb_image.ndim == 3 else L
                self.finished.emit(output.astype(np.float32), mask)

            else:
                self.progress_update.emit("Converting to Lab...", 10)
                lab = self.rgb_to_lab(self.rgb_image)
                L = lab[..., 0]

                for iter_idx in range(self.iterations):
                    if self.iterations > 1:
                        self.progress_update.emit(f"Iteration {iter_idx+1} of {self.iterations}", 10 + iter_idx * int(70 / self.iterations))

                    self.progress_update.emit("Building darkness mask...", 20)
                    mask = self.create_darkness_mask(L, self.gamma)

                    self.progress_update.emit("Decomposing via à trous...", 30)
                    wavelet_planes, residual = self.atrous_wavelet_decompose(L)

                    self.progress_update.emit("Enhancing dark structures...", 50)
                    decay_rate = 0.5
                    for i in range(len(wavelet_planes)):
                        if i == 0:
                            continue
                        decay_factor = decay_rate ** i
                        neg = np.clip(-wavelet_planes[i], 0, None)
                        enhancement = neg * mask * (self.boost_factor - 1.0) * decay_factor
                        wavelet_planes[i] -= enhancement
                        self.progress_update.emit(f"Enhancing scale {i+1}", 50 + int(i / len(wavelet_planes) * 20))

                    self.progress_update.emit("Reconstructing L...", 80)
                    L = np.clip(self.atrous_wavelet_reconstruct(wavelet_planes + [residual]), 0, 100)

                lab[..., 0] = L
                self.progress_update.emit("Converting back to RGB...", 90)
                rgb_out = self.lab_to_rgb(lab)
                self.progress_update.emit("Done", 100)
                self.finished.emit(rgb_out.astype(np.float32), mask)

        except Exception as e:
            print(f"Error in DSEWorker: {e}")
            self.finished.emit(None, None)

    def rgb_to_lab(self, rgb_image):
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)
        rgb = np.clip(rgb_image, 0, 1)
        xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)
        xyz[..., 0] /= 0.95047
        xyz[..., 2] /= 1.08883
        def f(t):
            delta = 6 / 29
            return np.where(t > delta**3, np.cbrt(t), t / (3 * delta**2) + 4 / 29)
        fx = f(xyz[..., 0])
        fy = f(xyz[..., 1])
        fz = f(xyz[..., 2])
        L = 116 * fy - 16
        a = 500 * (fx - fy)
        b = 200 * (fy - fz)
        return np.stack([L, a, b], axis=-1)

    def lab_to_rgb(self, lab_image):
        M_inv = np.array([
            [3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)
        fy = (lab_image[..., 0] + 16) / 116
        fx = fy + lab_image[..., 1] / 500
        fz = fy - lab_image[..., 2] / 200
        def f_inv(t):
            delta = 6 / 29
            return np.where(t > delta, t**3, 3 * delta**2 * (t - 4/29))
        X = 0.95047 * f_inv(fx)
        Y = f_inv(fy)
        Z = 1.08883 * f_inv(fz)
        xyz = np.stack([X, Y, Z], axis=-1)
        rgb = np.dot(xyz.reshape(-1, 3), M_inv.T).reshape(xyz.shape)
        return np.clip(rgb, 0, 1)


    def create_darkness_mask(self, L_channel, gamma):
        """
        Builds a dark structure mask by:
        - Running à trous decomposition
        - Extracting only the negative parts (dark structures)
        - Combining key wavelet scales (e.g., 2–4)
        - Applying a non-linear stretch with gamma
        - Smoothing to suppress speckle and noise
        """
        # Step 1: à trous decomposition
        wavelet_planes, _ = self.atrous_wavelet_decompose(L_channel)

        # Step 2: Select mid-scales — scales 2, 3, 4 (1:4)
        selected_scales = wavelet_planes[1:4]

        # Step 3: Extract only dark structures (negative components)
        dark_masks = [np.clip(-w, 0, None) for w in selected_scales]

        # Step 4: Combine with mean instead of max for smoother map
        combined = np.mean(dark_masks, axis=0)

        # Step 5: Normalize
        norm = combined / np.max(combined + 1e-8)

        # Step 6: Apply gamma for user control
        stretched = np.power(norm, gamma).astype(np.float32)

        # Step 7: Apply Gaussian smoothing to suppress speckle
        mask = gaussian_filter(stretched, sigma=3)  # sigma=3–5 works well
        # Step 8: Apply brightening curve to emphasize midrange
        def curves_brighten(x):
            # Boosts midtones with a soft S-curve, adjustable
            return np.clip(1.5 * x - 0.5 * x**2, 0, 1)

        enhanced_mask = curves_brighten(mask)

        return enhanced_mask


    def atrous_wavelet_decompose(self, image):
        current = image.copy()
        scales = []
        for scale_idx in range(self.n_scales):
            kernel = self._spaced_kernel(self.b3_spline_kernel, scale_idx)
            tmp = convolve(current, kernel.reshape(1, -1), mode='reflect')
            smooth = convolve(tmp, kernel.reshape(-1, 1), mode='reflect')
            wavelet = current - smooth
            scales.append(wavelet)
            current = smooth
        return scales, current

    def atrous_wavelet_reconstruct(self, planes):
        result = planes[-1].copy()
        for p in planes[:-1]:
            result += p
        return result

    def _spaced_kernel(self, kernel, scale_idx):
        if scale_idx == 0:
            return kernel
        step = 2 ** scale_idx
        spaced = np.zeros((len(kernel) - 1) * step + 1, dtype=kernel.dtype)
        spaced[::step] = kernel
        return spaced


class WaveScaleDarkEnhanceDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("WaveScale Dark Enhancer")
        self.setMinimumSize(800, 600)
        self.image_manager = image_manager
        self.showing_original = False

        if self.image_manager.image is None:
            QMessageBox.critical(self, "Error", "No image loaded.")
            self.reject()
            return

        img = self.image_manager.image
        img = img.astype(np.float32)
        img = np.clip(img, 0, 1)

        self.original_image = img.copy()
        self.preview_image  = img.copy()

        # Determine mono vs RGB
        if img.ndim == 2 or (img.ndim == 3 and img.shape[2] == 1):
            self.is_mono = True
            self.L_original = img.squeeze()
        else:
            self.is_mono = False
            self.lab_original = self.rgb_to_lab(img)
            self.L_original  = self.lab_original[..., 0].copy()

        self.b3_spline_kernel = np.array([1, 4, 6, 4, 1], dtype=np.float32) / 16.0

        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0



        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        self._create_preview_area()
        self._create_zoom_area()
        self._create_controls()
        self._create_progress_display()

        layout = QVBoxLayout()
        layout.addWidget(self.scroll_area)
        layout.addWidget(self.zoom_group_box)

        hbox_layout = QHBoxLayout()
        hbox_layout.addWidget(self.controls_group, stretch=3)
        hbox_layout.addWidget(self.progress_group_box, stretch=1)

        layout.addLayout(hbox_layout)
        self.main_layout.addLayout(layout)

        self._create_bottom_buttons()

        self.gamma_update_timer = QTimer()
        self.gamma_update_timer.setSingleShot(True)
        self.gamma_update_timer.timeout.connect(self._update_mask_preview)

        self._create_mask_window()
        self._update_mask_preview()  # initial mask
        self.gamma_slider.valueChanged.connect(self._delayed_gamma_update)
        self._update_preview_pixmap(self.original_image)

        self.accepted.connect(self.mask_window.close)
        self.rejected.connect(self.mask_window.close)

    def _delayed_gamma_update(self):
        self.gamma_update_timer.start(500)  # waits 500 ms after last change

    def _on_gamma_changed(self, value):
        """Updates the mask when gamma slider is moved."""
        self._update_mask_preview()

    def _create_mask_window(self):
        class ResizableMaskWindow(QMainWindow):
            def __init__(self, outer):
                super().__init__(outer)
                self.outer = outer
                self._aspect_ratio = None  # Will be set once we get a mask

            def resizeEvent(self, event):
                super().resizeEvent(event)
                if self._aspect_ratio:
                    new_width = self.width()
                    new_height = int(new_width / self._aspect_ratio)
                    self.resize(new_width, new_height)
                self.outer._rescale_mask_pixmap()

            def set_aspect_ratio(self, aspect_ratio):
                self._aspect_ratio = aspect_ratio

        self.mask_window = ResizableMaskWindow(self)
        self.mask_window.setWindowTitle("Dark Mask Preview")

        central_widget = QWidget()
        layout = QVBoxLayout()
        central_widget.setLayout(layout)

        self.mask_label = QLabel()
        self.mask_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.mask_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.mask_label.setScaledContents(True)

        layout.addWidget(self.mask_label)
        self.mask_window.setCentralWidget(central_widget)

        self.mask_window.resize(300, 300)
        self.mask_window.show()

    def _update_mask_preview(self):
        gamma = self.gamma_slider.value() / 100.0
        temp_worker = DSEWorker(
            self.original_image,
            self.scales_slider.value(),
            self.boost_slider.value() / 100.0,
            gamma,
            self.b3_spline_kernel
        )
        mask = temp_worker.create_darkness_mask(self.L_original, gamma)
        self.current_mask = mask

        mask_img = (np.clip(mask, 0, 1) * 255).astype(np.uint8)
        qimage = QImage(mask_img.data, mask.shape[1], mask.shape[0], mask.shape[1], QImage.Format.Format_Grayscale8)
        self.mask_pixmap = QPixmap.fromImage(qimage)  # save original pixmap
        self.mask_window.set_aspect_ratio(mask.shape[1] / mask.shape[0])  # width / height
        self._rescale_mask_pixmap()

    def _rescale_mask_pixmap(self):
        if hasattr(self, "mask_pixmap") and self.mask_pixmap:
            resized = self.mask_pixmap.scaled(
                self.mask_window.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.mask_label.setPixmap(resized)

    def _create_preview_area(self):
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)

        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        self.scroll_area.setWidget(self.graphics_view)

    def _create_zoom_area(self):
        self.zoom_group_box = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_group_box.setLayout(zoom_layout)

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()

    def _fit_to_preview(self):
        if self.pixmap_item.pixmap().isNull():
            return
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        self.zoom_factor = 1.0

    def _apply_zoom(self):
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def _create_controls(self):
        self.controls_group = QGroupBox("DSE Controls")
        controls_layout = QFormLayout()

        # Number of Scales
        self.scales_slider = QSlider(Qt.Orientation.Horizontal)
        self.scales_slider.setRange(2, 10)
        self.scales_slider.setValue(6)
        self.scales_value = QLabel(str(self.scales_slider.value()))
        self.scales_slider.valueChanged.connect(lambda v: self.scales_value.setText(str(v)))
        scale_layout = QHBoxLayout()
        scale_layout.addWidget(self.scales_slider)
        scale_layout.addWidget(self.scales_value)
        controls_layout.addRow("Number of Scales:", scale_layout)

        # Boost Factor
        self.boost_slider = QSlider(Qt.Orientation.Horizontal)
        self.boost_slider.setRange(10, 1000)
        self.boost_slider.setValue(500)
        self.boost_value = QLabel(str(self.boost_slider.value() / 100.0))
        self.boost_slider.valueChanged.connect(lambda v: self.boost_value.setText(f"{v / 100.0:.2f}"))
        boost_layout = QHBoxLayout()
        boost_layout.addWidget(self.boost_slider)
        boost_layout.addWidget(self.boost_value)
        controls_layout.addRow("Boost Factor:", boost_layout)

        # Iterations
        self.iter_slider = QSlider(Qt.Orientation.Horizontal)
        self.iter_slider.setRange(1, 10)
        self.iter_slider.setValue(2)
        self.iter_value = QLabel(str(self.iter_slider.value()))
        self.iter_slider.valueChanged.connect(lambda v: self.iter_value.setText(str(v)))
        iter_layout = QHBoxLayout()
        iter_layout.addWidget(self.iter_slider)
        iter_layout.addWidget(self.iter_value)
        controls_layout.addRow("Iterations:", iter_layout)

        # Mask Gamma
        self.gamma_slider = QSlider(Qt.Orientation.Horizontal)
        self.gamma_slider.setRange(10, 1000)
        self.gamma_slider.setValue(100)
        self.gamma_value = QLabel(f"{self.gamma_slider.value() / 100.0:.2f}")
        self.gamma_slider.valueChanged.connect(lambda v: self.gamma_value.setText(f"{v / 100.0:.2f}"))
        gamma_layout = QHBoxLayout()
        gamma_layout.addWidget(self.gamma_slider)
        gamma_layout.addWidget(self.gamma_value)
        controls_layout.addRow("Mask Gamma:", gamma_layout)

        # Preview and toggle buttons
        togglebuttonlayout = QHBoxLayout()
        self.preview_button = QPushButton("Preview")
        self.preview_button.clicked.connect(self._on_preview_clicked)
        togglebuttonlayout.addWidget(self.preview_button)

        self.toggle_button = QPushButton("Show Original")
        self.toggle_button.setCheckable(True)
        self.toggle_button.clicked.connect(self._toggle_image)
        togglebuttonlayout.addWidget(self.toggle_button)

        controls_layout.addRow(togglebuttonlayout)
        self.controls_group.setLayout(controls_layout)

    def _toggle_image(self):
        if self.toggle_button.isChecked():
            self.toggle_button.setText("Show Preview")
            self._update_preview_pixmap(self.original_image)
            self.showing_original = True
        else:
            self.toggle_button.setText("Show Original")
            self._update_preview_pixmap(self.preview_image)
            self.showing_original = False

    def _create_progress_display(self):
        self.progress_group_box = QGroupBox("Progress")
        layout = QVBoxLayout()

        self.current_step_label = QLabel("Idle")
        layout.addWidget(self.current_step_label)

        self.progress_bar = QProgressBar()
        layout.addWidget(self.progress_bar)

        self.progress_group_box.setLayout(layout)

    def _create_bottom_buttons(self):
        bottom_layout = QHBoxLayout()

        self.apply_button = QPushButton("Apply")
        self.apply_button.clicked.connect(self._on_apply_clicked)
        bottom_layout.addWidget(self.apply_button)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        bottom_layout.addWidget(self.cancel_button)

        self.main_layout.addLayout(bottom_layout)

    def _on_preview_clicked(self):
        self.preview_button.setEnabled(False)
        self.apply_button.setEnabled(False)
        self.progress_bar.setValue(0)

        n_scales = self.scales_slider.value()
        boost_factor = self.boost_slider.value() / 100.0
        gamma = self.gamma_slider.value() / 100.0
        iterations = self.iter_slider.value()

        self.worker = DSEWorker(
            self.original_image, n_scales, boost_factor, gamma,
            self.b3_spline_kernel, iterations=iterations, is_mono=self.is_mono
        )
        self.thread = QThread()
        self.worker.moveToThread(self.thread)

        self.thread.started.connect(self.worker.run)
        self.worker.progress_update.connect(self._update_progress)
        self.worker.finished.connect(self._on_worker_finished)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)

        self.thread.start()

    def _update_progress(self, message, percent):
        self.current_step_label.setText(message)
        self.progress_bar.setValue(percent)

    def _on_worker_finished(self, output_image, mask):
        if output_image is not None:
            self.preview_image = output_image
            self._update_preview_pixmap(output_image)
            self.apply_button.setEnabled(True)
        else:
            QMessageBox.critical(self, "Error", "DSE process failed.")

        self.preview_button.setEnabled(True)

    def _on_apply_clicked(self):
        self.image_manager.set_image(self.preview_image, {"description": "WaveScale Dark Enhance"}, step_name="WaveScale Dark Enhance")
        self.accept()

    def _update_preview_pixmap(self, image):
        image_uint8 = (np.clip(image, 0, 1) * 255).astype(np.uint8)
        if image_uint8.ndim == 2:
            image_uint8 = np.repeat(image_uint8[..., None], 3, axis=2)
        h, w = image_uint8.shape[:2]
        qimage = QImage(image_uint8.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(qimage)
        self.pixmap_item.setPixmap(pixmap)
        self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())

    def rgb_to_lab(self, rgb_image):
        M = np.array([[0.4124564, 0.3575761, 0.1804375],
                      [0.2126729, 0.7151522, 0.0721750],
                      [0.0193339, 0.1191920, 0.9503041]], dtype=np.float32)
        rgb_image = np.clip(rgb_image, 0.0, 1.0)
        xyz_image = np.dot(rgb_image.reshape(-1, 3), M.T).reshape(rgb_image.shape)
        xyz_image[..., 0] /= 0.95047
        xyz_image[..., 2] /= 1.08883

        def f(t):
            delta = 6 / 29
            return np.where(t > delta ** 3, np.cbrt(t), (t / (3 * delta ** 2)) + (4 / 29))

        fx = f(xyz_image[..., 0])
        fy = f(xyz_image[..., 1])
        fz = f(xyz_image[..., 2])

        L = (116.0 * fy) - 16.0
        a = 500.0 * (fx - fy)
        b = 200.0 * (fy - fz)

        return np.stack([L, a, b], axis=-1)

    def closeEvent(self, event):
        if hasattr(self, "mask_window") and self.mask_window is not None:
            self.mask_window.close()
        super().closeEvent(event)

class BlemishBlasterWorkerSignals(QObject):
    finished = pyqtSignal(np.ndarray)  # Emitted when processing is done

class BlemishBlasterWorker(QRunnable):
    def __init__(self, image, x, y, radius, feather, opacity, channels_to_process=[0,1,2]):
        super().__init__()
        self.image = image.copy()
        self.x = x
        self.y = y
        self.radius = radius
        self.feather = feather
        self.opacity = opacity
        self.channels_to_process = channels_to_process
        self.signals = BlemishBlasterWorkerSignals()

    @pyqtSlot()
    def run(self):
        # Perform blemish removal
        corrected_image = self.remove_blemish(
            self.image, self.x, self.y, self.radius, self.feather, self.opacity, self.channels_to_process
        )
        # Emit the corrected image
        self.signals.finished.emit(corrected_image)

    def remove_blemish(self, image, x, y, radius, feather, opacity, channels_to_process):
        """
        Perform per-pixel blemish removal by sampling from surrounding circles.
        Handles edge cases where correction circles may extend beyond image boundaries.
        """
        corrected_image = image.copy()
        h, w = image.shape[:2]

        # Define angles for surrounding circles
        angles = [0, 60, 120, 180, 240, 300]
        surrounding_centers = []
        for angle in angles:
            rad = math.radians(angle)
            dx = int(math.cos(rad) * (radius * 1.5))  # 1.5 times the radius away
            dy = int(math.sin(rad) * (radius * 1.5))
            surrounding_centers.append((x + dx, y + dy))

        # Calculate medians for each surrounding circle and the target circle
        target_median = self.calculate_median_circle(image, x, y, radius, channels_to_process)
        surrounding_medians = [
            self.calculate_median_circle(image, cx, cy, radius, channels_to_process)
            for cx, cy in surrounding_centers
        ]

        # Determine the three correction circles closest to the target median
        median_diffs = [abs(median - target_median) for median in surrounding_medians]
        closest_indices = np.argsort(median_diffs)[:3]  # Indices of the three closest circles
        selected_circles = [surrounding_centers[i] for i in closest_indices]

        # Iterate through each channel
        for c in channels_to_process:
            # Iterate through each pixel in the target blemish circle
            for i in range(max(y - radius, 0), min(y + radius + 1, h)):
                for j in range(max(x - radius, 0), min(x + radius + 1, w)):
                    dist = math.sqrt((j - x) ** 2 + (i - y) ** 2)
                    if dist <= radius:
                        # Apply feathering based on distance
                        if feather > 0:
                            weight = max(0, min(1, (radius - dist) / (radius * feather)))
                        else:
                            weight = 1

                        # Collect corresponding pixel values from the selected correction circles
                        sampled_values = []
                        for (cx, cy) in selected_circles:
                            # Find the corresponding pixel position
                            corresponding_j = j + (cx - x)
                            corresponding_i = i + (cy - y)

                            # Ensure the corresponding pixel is within image bounds
                            if 0 <= corresponding_i < h and 0 <= corresponding_j < w:
                                if image.ndim == 2:
                                    sampled_values.append(image[corresponding_i, corresponding_j])
                                elif image.ndim == 3:
                                    if image.shape[2] == 1:
                                        sampled_values.append(image[corresponding_i, corresponding_j, 0])
                                    elif image.shape[2] > c:
                                        sampled_values.append(image[corresponding_i, corresponding_j, c])
                                    else:
                                        continue  # Skip if channel is out of bounds

                        if sampled_values:
                            # Calculate the median of the sampled values
                            median_val = np.median(sampled_values)
                        else:
                            # If no valid sampled pixels, retain the original pixel value
                            if image.ndim == 2:
                                median_val = image[i, j]
                            elif image.ndim == 3 and image.shape[2] ==1:
                                median_val = image[i, j,0]
                            else:
                                median_val = image[i,j,c]

                        # Blend the median value into the target pixel using opacity and feathering
                        if image.ndim ==2:
                            original_val = image[i, j]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j] = blended_val
                        elif image.ndim ==3 and image.shape[2] ==1:
                            original_val = image[i, j,0]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j,0] = blended_val
                        elif image.ndim ==3 and image.shape[2] >c:
                            original_val = image[i, j, c]
                            blended_val = (1 - opacity * weight) * original_val + (opacity * weight) * median_val
                            corrected_image[i, j, c] = blended_val

        return corrected_image

    def calculate_median_circle(self, image, cx, cy, radius, channels):
        """
        Calculate the median value of a circle for the specified channels.

        Args:
            image (np.ndarray): The image array.
            cx (int): X-coordinate of the circle center.
            cy (int): Y-coordinate of the circle center.
            radius (int): Radius of the circle.
            channels (list): List of channel indices to process.

        Returns:
            float: The overall median value across specified channels.
        """
        values = []
        for c in channels:
            y_min = max(cy - radius, 0)
            y_max = min(cy + radius + 1, image.shape[0])
            x_min = max(cx - radius, 0)
            x_max = min(cx + radius + 1, image.shape[1])

            if image.ndim == 2:
                # Grayscale image (2D)
                roi = image[y_min:y_max, x_min:x_max]
            elif image.ndim == 3:
                if image.shape[2] ==1:
                    # Grayscale image with single channel
                    roi = image[y_min:y_max, x_min:x_max, 0]
                elif image.shape[2] >= c+1:
                    # RGB image
                    roi = image[y_min:y_max, x_min:x_max, c]
                else:
                    continue  # Skip if channel is out of bounds
            else:
                continue  # Unsupported image dimensions

            yy, xx = np.ogrid[:roi.shape[0], :roi.shape[1]]
            dist_from_center = np.sqrt((xx - (cx - x_min))**2 + (yy - (cy - y_min))**2)
            mask = dist_from_center <= radius
            values.extend(roi[mask].flatten())

        return np.median(values) if values else 0.0   
         
class GraphicsView(QGraphicsView):
    """
    Custom QGraphicsView to handle mouse events for blemish removal.
    Emits signals for mouse movements and clicks.
    """
    mouse_moved = pyqtSignal(QPointF)
    mouse_clicked = pyqtSignal(QPointF)

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)  # Enable mouse tracking without button presses

    def mouseMoveEvent(self, event):
        pos = self.mapToScene(event.position().toPoint())
        self.mouse_moved.emit(pos)
        super().mouseMoveEvent(event)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            pos = self.mapToScene(event.position().toPoint())
            self.mouse_clicked.emit(pos)
        super().mousePressEvent(event)


class BlemishBlasterDialog(QDialog):
    blemish_removed = pyqtSignal(np.ndarray)  # Signal emitted when a blemish is removed

    def __init__(self, image_manager, parent=None):
        """
        Initializes the BlemishBlaster dialog.

        Args:
            image_manager (ImageManager): The ImageManager instance from the main application.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Blemish Blaster")
        self.setMinimumSize(800, 600)  # Set initial size to 800x600

        self.image_manager = image_manager  # Reference to ImageManager
        self.image = self.image_manager.image.copy()  # Work on a copy for display

        # Triplicate single-channel images to ensure 3 channels
        if self.image.ndim == 2:
            self.image = np.repeat(self.image[:, :, np.newaxis], 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 1:
            self.image = np.repeat(self.image, 3, axis=2)
        elif self.image.ndim == 3 and self.image.shape[2] == 3:
            pass  # RGB image, no action needed
        else:
            raise ValueError(f"Unsupported image shape: {self.image.shape}")

        self.display_image = self.image.copy()

        # Initialize QScrollArea for image display with scroll bars
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)  # Allow the scroll area to resize its widget

        # Initialize QGraphicsScene and QGraphicsView
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable panning via mouse drag
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)  # Center the image if smaller than viewport

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))

        # Initialize QGraphicsEllipseItem for the correction circle
        self.circle_item = QGraphicsEllipseItem()
        self.circle_item.setPen(QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine))
        self.circle_item.setBrush(QBrush(Qt.BrushStyle.NoBrush))  # Corrected Line
        self.circle_item.setVisible(False)  # Initially hidden
        self.scene.addItem(self.circle_item)

        # Set the graphics_view as the widget inside the scroll area
        self.scroll_area.setWidget(self.graphics_view)

        # Main layout
        self.layout = QVBoxLayout()
        self.setLayout(self.layout)
        self.layout.addWidget(self.scroll_area)

        # Create a horizontal layout to hold controls and visualization side by side
        controls_visualization_layout = QHBoxLayout()

        # Sliders and Controls
        controls_group = self.setup_controls()

        # Visualization
        visualization_group = self.setup_visualization()

        # Add controls and visualization to the horizontal layout
        controls_visualization_layout.addWidget(controls_group)
        controls_visualization_layout.addWidget(visualization_group)

        # Add the horizontal layout to the main vertical layout
        self.layout.addLayout(controls_visualization_layout)

        # Undo, Redo, and Apply Changes Buttons
        self.setup_undo_redo_apply()

        # Thread Pool for handling image processing
        self.threadpool = QThreadPool()

        # Current cursor position
        self.current_x = None
        self.current_y = None

        # Install event filter to capture mouse events
        self.graphics_view.installEventFilter(self)

        self.graphics_view.setMouseTracking(True)
        self.graphics_view.mousePressEvent = self.view_mouse_press_event
        self.graphics_view.mouseMoveEvent = self.view_mouse_move_event

        # Shortcut actions for Undo and Redo
        self.setup_shortcuts()
        self.cursor_over_scrollbar = False     

        self.undo_stack = []
        self.redo_stack = []       
        self.is_stretched = False    

        # Initialize Zoom parameters
        self.zoom_factor = 1.0  # Current zoom level
        self.zoom_step = 1.25   # Zoom increment factor
        self.zoom_min = 0.02     # Minimum zoom (10%)
        self.zoom_max = 2     # Maximum zoom (500%)

    def setup_controls(self):
        """Set up sliders for Correction Radius, Feathering, and Opacity."""
        controls_group = QGroupBox("Controls")
        form_layout = QFormLayout()        

        # Zoom Buttons Layout
        zoom_layout = QHBoxLayout()

        # Zoom In Button
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        # Zoom Out Button
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        # Optionally, add a label to display current zoom level
        self.zoom_label = QLabel("100%")
        zoom_layout.addWidget(self.zoom_label)

        form_layout.addRow("Zoom:", zoom_layout)

 

        # Correction Radius Slider
        self.radius_slider = QSlider(Qt.Orientation.Horizontal)
        self.radius_slider.setMinimum(1)
        self.radius_slider.setMaximum(300)
        self.radius_slider.setValue(10)
        self.radius_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.radius_slider.setTickInterval(10)
        self.radius_slider.valueChanged.connect(self.update_visualization)

        form_layout.addRow("Correction Radius:", self.radius_slider)

        # Feathering Slider
        self.feather_slider = QSlider(Qt.Orientation.Horizontal)
        self.feather_slider.setMinimum(0)
        self.feather_slider.setMaximum(100)
        self.feather_slider.setValue(50)
        self.feather_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.feather_slider.setTickInterval(10)
        self.feather_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Feathering:", self.feather_slider)

        # Opacity Slider
        self.opacity_slider = QSlider(Qt.Orientation.Horizontal)
        self.opacity_slider.setMinimum(0)
        self.opacity_slider.setMaximum(100)
        self.opacity_slider.setValue(100)
        self.opacity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.opacity_slider.setTickInterval(10)
        self.opacity_slider.valueChanged.connect(self.update_visualization)
        form_layout.addRow("Opacity:", self.opacity_slider)

        # Autostretch Button
        self.autostretch_button = QPushButton("Autostretch")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow("Autostretch:", self.autostretch_button)

        controls_group.setLayout(form_layout)
        return controls_group

    def setup_visualization(self):
        """Set up the feathering and opacity visualization."""
        visualization_group = QGroupBox("Feathering & Opacity Visualization")
        visualization_layout = QHBoxLayout()

        self.visualization_label = QLabel()
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)
        visualization_layout.addWidget(self.visualization_label)

        visualization_group.setLayout(visualization_layout)
        return visualization_group

    def setup_undo_redo_apply(self):
        """Set up Undo, Redo, and Apply Changes buttons."""
        history_group = QGroupBox("History")
        history_layout = QHBoxLayout()

        # Apply Changes Button
        self.apply_button = QPushButton("Apply Changes")
        self.apply_button.clicked.connect(self.apply_changes)
        history_layout.addWidget(self.apply_button)

        # Undo Button
        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.perform_undo)
        history_layout.addWidget(self.undo_button)

        # Redo Button
        self.redo_button = QPushButton("Redo")
        self.redo_button.clicked.connect(self.perform_redo)
        history_layout.addWidget(self.redo_button)

        history_group.setLayout(history_layout)
        self.layout.addWidget(history_group)

    def setup_shortcuts(self):
        """Set up keyboard shortcuts for Undo (Ctrl+Z) and Redo (Ctrl+Y)."""
        undo_shortcut = QAction(self)
        undo_shortcut.setShortcut(QKeySequence.StandardKey.Undo)
        undo_shortcut.triggered.connect(self.perform_undo)
        self.addAction(undo_shortcut)

        redo_shortcut = QAction(self)
        redo_shortcut.setShortcut(QKeySequence.StandardKey.Redo)
        redo_shortcut.triggered.connect(self.perform_redo)
        self.addAction(redo_shortcut)

    def perform_undo(self):
        """Perform undo action by interacting with the local undo stack."""
        if self.undo_stack:
            # Push current image to redo stack
            self.redo_stack.append(self.image.copy())
            # Pop the last image from undo stack
            self.image = self.undo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def perform_redo(self):
        """Perform redo action by interacting with the local redo stack."""
        if self.redo_stack:
            # Push current image to undo stack
            self.undo_stack.append(self.image.copy())
            # Pop the last image from redo stack
            self.image = self.redo_stack.pop()
            self.display_image = self.image.copy()
            self.update_display_image()
            print("Redo performed.")
        else:
            QMessageBox.information(self, "Redo", "No actions to redo.")   

    def create_visualization_pixmap(self):
        """
        Create a visualization of feathering and opacity on a white disc.
        """
        size = 100  # Size of the visualization image
        image = np.ones((size, size, 3), dtype=np.float32)  # White background

        center = (size // 2, size // 2)
        radius = self.radius_slider.value()
        feather = self.feather_slider.value() / 100.0
        opacity = self.opacity_slider.value() / 100.0

        yy, xx = np.ogrid[:size, :size]
        dist_from_center = np.sqrt((xx - center[0])**2 + (yy - center[1])**2)
        mask = dist_from_center <= radius

        # Feathering mask
        if feather > 0:
            feather_mask = np.clip((radius - dist_from_center) / (radius * feather), 0, 1)
        else:
            feather_mask = np.ones_like(mask, dtype=np.float32)

        feather_mask = feather_mask * mask

        # Apply opacity
        # Red color for the correction area
        image[mask] = (1 - opacity * feather_mask)[mask, np.newaxis] * image[mask] + \
                      (opacity * feather_mask)[mask, np.newaxis] * np.array([1, 0, 0])

        # Convert to QImage
        image_uint8 = (image * 255).astype(np.uint8)
        q_image = QImage(image_uint8.data, size, size, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        return pixmap

    def update_visualization(self):
        """Update the visualization pixmap based on current feathering and opacity."""
        self.visualization_pixmap = self.create_visualization_pixmap()
        self.visualization_label.setPixmap(self.visualization_pixmap)

    def view_mouse_press_event(self, event):
        """Handle mouse press events in the graphics view"""
        if event.button() == Qt.MouseButton.LeftButton:
            # Convert mouse position to scene coordinates
            scene_pos = self.graphics_view.mapToScene(event.pos())
            self.on_mouse_click(scene_pos)
        event.accept()

    def view_mouse_move_event(self, event):
        """Handle mouse move events in the graphics view"""
        # Convert mouse position to scene coordinates
        scene_pos = self.graphics_view.mapToScene(event.pos())
        self.on_mouse_move(scene_pos)
        event.accept()

    def convert_image_to_pixmap(self, image):
        """
        Convert a numpy image array to QPixmap for display.

        Args:
            image (np.ndarray): Image array normalized to [0,1].

        Returns:
            QPixmap: The converted pixmap.
        """
        # Convert from [0,1] to [0,255]
        image_uint8 = np.clip(image * 255, 0, 255).astype(np.uint8)

        if image_uint8.ndim == 2:
            # Grayscale image (2D) - Triplicate to make 3 channels
            height, width = image_uint8.shape
            image_triplicated = np.repeat(image_uint8[:, :, np.newaxis], 3, axis=2)
            bytes_per_line = 3 * width
            q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif image_uint8.ndim == 3:
            if image_uint8.shape[2] == 3:
                # RGB image (3 channels)
                height, width, channels = image_uint8.shape
                bytes_per_line = channels * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif image_uint8.shape[2] == 1:
                # Grayscale image represented as (height, width, 1) - Triplicate to make 3 channels
                height, width, channels = image_uint8.shape
                image_triplicated = np.repeat(image_uint8, 3, axis=2)
                bytes_per_line = 3 * width
                q_image = QImage(image_triplicated.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
            else:
                raise ValueError(f"Unsupported number of channels: {image_uint8.shape[2]}")
        else:
            raise ValueError(f"Unsupported image shape: {image_uint8.shape}")

        return QPixmap.fromImage(q_image)


    def eventFilter(self, source, event):
        """Event filter to capture mouse move and click events."""
        if source == self.graphics_view:
            if event.type() == QEvent.Type.MouseMove:
                pos = self.graphics_view.mapToScene(event.position().toPoint())
                self.on_mouse_move(pos)
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    pos = self.graphics_view.mapToScene(event.position().toPoint())
                    self.on_mouse_click(pos)
            elif event.type() == QEvent.Type.Enter:
                # Optionally, set the cursor to ArrowCursor when entering
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
            elif event.type() == QEvent.Type.Leave:
                self.graphics_view.unsetCursor()
        return super().eventFilter(source, event)

    def on_mouse_move(self, pos):
        """
        Handle mouse move events to display a dynamic circle indicating the blemish removal radius.

        Args:
            pos (QPointF): The position of the mouse in scene coordinates.
        """
        x, y = pos.x(), pos.y()
        self.current_x, self.current_y = x, y

        radius = self.radius_slider.value()

        # Update the circle's position and size
        self.circle_item.setRect(x - radius, y - radius, 2 * radius, 2 * radius)
        self.circle_item.setVisible(True)

        # Detect if cursor is over scroll bars
        viewport_pos = self.graphics_view.mapFromScene(pos)
        scrollbar_over = False

        # Check horizontal scroll bar
        h_scrollbar = self.graphics_view.horizontalScrollBar()
        if h_scrollbar.isVisible():
            h_scrollbar_rect = h_scrollbar.geometry()
            if h_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Check vertical scroll bar
        v_scrollbar = self.graphics_view.verticalScrollBar()
        if v_scrollbar.isVisible():
            v_scrollbar_rect = v_scrollbar.geometry()
            if v_scrollbar_rect.contains(viewport_pos):
                scrollbar_over = True

        # Update cursor based on position
        if scrollbar_over:
            if self.cursor_over_scrollbar:
                # Already over scrollbar, no action needed
                pass
            else:
                # Now over scrollbar
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = True
        else:
            if self.cursor_over_scrollbar:
                # Moved away from scrollbar, set default cursor
                self.graphics_view.setCursor(Qt.CursorShape.ArrowCursor)
                self.cursor_over_scrollbar = False
            else:
                # Already using default cursor, no action needed
                pass
            
    def on_mouse_click(self, pos):
        """
        Handle mouse press events to remove blemishes on click.

        Args:
            pos (QPointF): The position of the mouse click in scene coordinates.
        """
        x, y = int(pos.x()), int(pos.y())

        # Validate coordinates
        if 0 <= x < self.image.shape[1] and 0 <= y < self.image.shape[0]:
            radius = self.radius_slider.value()
            feather = self.feather_slider.value() / 100.0
            opacity = self.opacity_slider.value() / 100.0

            # Determine channels to process based on image dimensionality
            if self.image.ndim == 2:
                channels_to_process = [0]  # Single channel
            elif self.image.ndim == 3:
                channels_to_process = [0, 1, 2]  # RGB channels
            else:
                QMessageBox.warning(self, "Unsupported Image", "Image format not supported for blemish removal.")
                return

            # Start the blemish removal in a separate thread
            worker = BlemishBlasterWorker(
                image=self.image.copy(),  # Pass the current image from ImageManager
                x=x,
                y=y,
                radius=radius,
                feather=feather,
                opacity=opacity,
                channels_to_process=[0, 1, 2]  # RGB channels
            )
            worker.signals.finished.connect(self.on_processing_finished)
            self.threadpool.start(worker)

            self.setEnabled(False)  # Disable the dialog to prevent multiple clicks
            print(f"Started blemish removal at ({x}, {y}) with radius {radius}, feathering {feather}, opacity {opacity}.")

    def on_processing_finished(self, corrected_image):
        """
        Slot to handle the completion of blemish removal.

        Args:
            corrected_image (np.ndarray): The image after blemish removal.
        """
        # Push the current image to the undo stack before updating
        self.undo_stack.append(self.image.copy())
        # Clear the redo stack as new action invalidates future redos
        self.redo_stack.clear()

        # Update the local image with the corrected image
        self.image = corrected_image.copy()
        self.display_image = self.image.copy()
        self.update_display_image()

        self.setEnabled(True)  # Re-enable the dialog
        print("Blemish removal completed.")

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image

    def autostretch_image(self):
        """Handle the Autostretch button click to stretch or unstretch the image."""
        if not self.is_stretched:
            # Perform stretching
            stretched_image = self.stretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = stretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = True
            self.autostretch_button.setText("Remove Stretch")
            print("Image stretched.")
        else:
            # Optionally, allow removing stretch before applying changes
            # Uncomment the following lines if you want to allow removing stretch manually
            unstretched_image = self.unstretch_image(self.image)
            self.undo_stack.append(self.image.copy())  # Push current state to undo stack
            self.image = unstretched_image.copy()
            self.display_image = self.image.copy()
            self.update_display_image()
            self.is_stretched = False
            self.autostretch_button.setText("Autostretch")
            print("Stretch removed.")


    def apply_changes(self):
        """Apply all changes by pushing the final image to the ImageManager."""
        try:
            # If the image is stretched, unstretch it before applying
            if self.is_stretched:
                self.image = self.unstretch_image(self.image)
                self.display_image = self.image.copy()
                self.update_display_image()
                self.is_stretched = False
                self.autostretch_button.setText("Autostretch")
                print("Image unstretched before applying changes.")

            current_slot = self.image_manager.current_slot
            existing_metadata = self.image_manager._metadata.get(current_slot, {}).copy()

            # Ensure 'notes' exists and is a list
            if 'notes' in existing_metadata and isinstance(existing_metadata['notes'], list):
                existing_metadata['notes'].append("Blemish removed using Blemish Blaster.")
                print("Appended blemish removal note to existing metadata.")
            else:
                existing_metadata['notes'] = ["Blemish removed using Blemish Blaster."]
                print("Initialized blemish removal note in metadata.")

            # Push the updated image and metadata to the ImageManager
            self.image_manager.set_image(self.image.copy(), metadata=existing_metadata, step_name="blemish_blaster")
            self.blemish_removed.emit(self.image_manager.image)

            # Clear the undo and redo stacks as changes are now applied
            self.undo_stack.clear()
            self.redo_stack.clear()


            self.accept()
            print("Applied changes to ImageManager.")

        except Exception as e:
            QMessageBox.critical(
                self,
                "Apply Changes Error",
                f"An error occurred while applying changes:\n{str(e)}"
            )
            print(f"ERROR in apply_changes: {e}")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """Zoom in the image by a predefined step."""
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed in to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        """Zoom out the image by a predefined step."""
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self.apply_zoom()
            self.zoom_label.setText(f"{int(self.zoom_factor * 100)}%")
            print(f"Zoomed out to {int(self.zoom_factor * 100)}%")
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def apply_zoom(self):
        """Apply the current zoom factor to the QGraphicsView."""
        self.graphics_view.resetTransform()  # Reset any existing transformations
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def reset_zoom(self):
        """Reset zoom to the default factor (100%)."""
        self.zoom_factor = 1.0
        self.apply_zoom()
        self.zoom_label.setText("100%")
        print("Zoom reset to 100%.")

    def update_display_image(self):
        """Update the display image from the local image and refresh the pixmap."""
        self.pixmap_item.setPixmap(self.convert_image_to_pixmap(self.display_image))
        # Optionally, clear the correction circle
        self.circle_item.setVisible(False)

    def closeEvent(self, event):

        super().closeEvent(event)

class PolyGradientRemoval:
    """
    A headless class that replicates the polynomial background removal
    logic from GradientRemovalDialog, minus the RBF step and UI code.

    Flow:
      1) Stretch the image (unlinked linear stretch).
      2) Downsample.
      3) Build an exclusion mask that:
         - Skips zero-valued pixels in any channel.
         - Optionally skip user-specified mask areas if desired (can pass mask to process()).
      4) Generate sample points from corners, borders, quartiles, do gradient_descent_to_dim_spot, skip bright areas.
      5) Fit a polynomial background and subtract it.
      6) Re-normalize median, clip to [0..1].
      7) Unstretch the final image back to the original domain.
    """

    def __init__(
        self,
        image: np.ndarray,
        poly_degree: int = 2,
        downsample_scale: int = 5,
        num_sample_points: int = 100
    ):
        """
        Args:
            image (np.ndarray): Input image in [0..1], shape (H,W) or (H,W,3), float32 recommended.
            poly_degree (int): Polynomial degree (1=linear,2=quadratic).
            downsample_scale (int): Factor for area downsampling.
            num_sample_points (int): Number of sample points to generate.
        """
        self.image = image.copy()
        self.poly_degree = poly_degree
        self.downsample_scale = downsample_scale
        self.num_sample_points = num_sample_points

        # For the stretch/unstretch logic
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        self.was_single_channel = False

    def process(self, user_exclusion_mask: np.ndarray = None) -> np.ndarray:
        """
        Main pipeline to remove polynomial gradient. 
        user_exclusion_mask: optional (H,W) boolean array, False => skip those pixels.
        
        Returns the final corrected image in the original brightness domain.
        """
        # 1) Stretch
        stretched = self.pixel_math_stretch(self.image)
        print("stretching")

        # 2) Downsample
        small_stretched = self.downsample_image(stretched, self.downsample_scale)
        h_s, w_s = small_stretched.shape[:2]
        print("downsampling")

        # 3) Build an exclusion mask in the small domain that:

        # 4) Generate sample points from corners/borders/quartiles
        sample_points = generate_sample_points(
            small_stretched,
            num_points=self.num_sample_points
        )
        print("sample points generated")

        # 5) Fit polynomial on the downsampled image
        poly_background_small = self.fit_polynomial_gradient(
            small_stretched, sample_points, degree=self.poly_degree
        )
        print("fit poly")

        # Upscale background to full size
        poly_background = self.upscale_background(
            poly_background_small, stretched.shape[:2]
        )
        print("upscale")

        # Subtract
        after_poly = stretched - poly_background
        print("subtracted")

        # Re-normalize median to original
        original_median = np.median(stretched)
        after_poly = self.normalize_image(after_poly, original_median)
        print("normalized")

        # Clip
        after_poly = np.clip(after_poly, 0, 1)

        # 6) Unstretch
        corrected = self.unstretch_image(after_poly)

        return corrected

    # ---------------------------------------------------------------
    # Helper: Stretch / Unstretch
    # ---------------------------------------------------------------
    def pixel_math_stretch(self, image: np.ndarray) -> np.ndarray:
        """
        Unlinked linear stretch using your existing Numba functions.

        Steps:
        1) If single-channel, replicate to 3-ch so we can store stats & do consistent logic.
        2) For each channel c: subtract the channel's min => data is >= 0.
        3) Compute the median after min subtraction for that channel.
        4) Call the appropriate Numba function:
            - If single-channel (was originally 1-ch), call numba_mono_final_formula
            on the 1-ch array.
            - If 3-ch color, call numba_color_final_formula_unlinked.
        5) Clip to [0,1].
        6) Store self.stretch_original_mins / medians so we can unstretch later.
        """
        target_median = 0.25

        # 1) Handle single-channel => replicate to 3 channels
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            self.was_single_channel = True
            image_3ch = np.stack([image.squeeze()] * 3, axis=-1)
        else:
            self.was_single_channel = False
            image_3ch = image

        image_3ch = image_3ch.astype(np.float32, copy=True)

        H, W, C = image_3ch.shape
        # We assume C=3 now.

        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # 2) Subtract min per channel
        for c in range(C):
            cmin = image_3ch[..., c].min()
            image_3ch[..., c] -= cmin
            self.stretch_original_mins.append(float(cmin))

        # 3) Compute median after min subtraction
        medians_after_sub = []
        for c in range(C):
            cmed = float(np.median(image_3ch[..., c]))
            medians_after_sub.append(cmed)
        self.stretch_original_medians = medians_after_sub

        # 4) Apply the final formula with your Numba functions
        if self.was_single_channel:
            # If originally single-channel, let's do a single pass with numba_mono_final_formula
            # on the single channel. We can do that by extracting one channel from image_3ch.
            # Then replicate the result to 3 channels, or keep it as 1-ch?
            # Typically we keep it as 1-ch in the end, so let's do that.

            # We'll just pick channel 0, run the mono formula, store it back in a 2D array.
            mono_array = image_3ch[..., 0]  # shape (H,W)
            cmed = medians_after_sub[0]     # The median for that channel
            # We call the numba function
            stretched_mono = numba_mono_final_formula(mono_array, cmed, target_median)

            # Now place it back into image_3ch for consistency
            for c in range(3):
                image_3ch[..., c] = stretched_mono
        else:
            # 3-channel unlinked
            medians_rescaled = np.array(medians_after_sub, dtype=np.float32)
            # 'image_3ch' is our 'rescaled'
            stretched_3ch = numba_color_final_formula_unlinked(
                image_3ch, medians_rescaled, target_median
            )
            image_3ch = stretched_3ch

        # 5) Clip to [0..1]
        np.clip(image_3ch, 0.0, 1.0, out=image_3ch)
        image = image_3ch
        return image


    def unstretch_image(self, image: np.ndarray) -> np.ndarray:
        """
        Calls the Numba-optimized unstretch function.
        """
        image = image.astype(np.float32, copy=True)

        # Convert lists to NumPy arrays for efficient Numba processing
        stretch_original_medians = np.array(self.stretch_original_medians, dtype=np.float32)
        stretch_original_mins = np.array(self.stretch_original_mins, dtype=np.float32)

        # Call the Numba function
        unstretched = numba_unstretch(image, stretch_original_medians, stretch_original_mins)

        if self.was_single_channel:
            # Convert back to grayscale
            unstretched = np.mean(unstretched, axis=2, keepdims=True)

        return unstretched


    # ---------------------------------------------------------------
    # Helper: Downsample
    # ---------------------------------------------------------------
    def downsample_image(self, image: np.ndarray, scale: int=6) -> np.ndarray:
        """
        Downsamples with area interpolation.
        """
        h, w = image.shape[:2]
        new_w = max(1, w//scale)
        new_h = max(1, h//scale)
        return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)



    # ---------------------------------------------------------------
    # 5) Fit Polynomial
    # ---------------------------------------------------------------
    def fit_polynomial_gradient(self, image: np.ndarray, sample_points: np.ndarray, degree: int = 2, patch_size: int = 15) -> np.ndarray:
        """
        Optimized polynomial background fitting.
        - Extracts sample points using vectorized NumPy median calculations.
        - Solves for polynomial coefficients in parallel.
        - Precomputes polynomial basis terms for efficiency.
        """

        H, W = image.shape[:2]
        half_patch = patch_size // 2
        num_samples = len(sample_points)

        # Convert sample points to NumPy arrays
        sample_points = np.array(sample_points, dtype=np.int32)
        x_coords, y_coords = sample_points[:, 0], sample_points[:, 1]

        # Precompute polynomial design matrix
        A = build_poly_terms(x_coords, y_coords, degree)

        # Extract sample values efficiently
        if image.ndim == 3 and image.shape[2] == 3:
            # Color image
            background = np.zeros_like(image, dtype=np.float32)
            for c in range(3):
                # Extract patches and compute medians using vectorized NumPy operations
                z_vals = np.array([
                    np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                    max(0, x-half_patch):min(W, x+half_patch+1), c])
                    for x, y in zip(x_coords, y_coords)
                ], dtype=np.float32)

                # Solve for polynomial coefficients
                coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

                # Generate full polynomial background
                background[..., c] = evaluate_polynomial(H, W, coeffs, degree)

        else:
            # Grayscale image
            background = np.zeros((H, W), dtype=np.float32)

            z_vals = np.array([
                np.median(image[max(0, y-half_patch):min(H, y+half_patch+1),
                                max(0, x-half_patch):min(W, x+half_patch+1)])
                for x, y in zip(x_coords, y_coords)
            ], dtype=np.float32)

            # Solve for polynomial coefficients
            coeffs = np.linalg.lstsq(A, z_vals, rcond=None)[0]

            # Generate full polynomial background
            background = evaluate_polynomial(H, W, coeffs, degree)

        return background
    # ---------------------------------------------------------------
    # 6) Upscale
    # ---------------------------------------------------------------
    def upscale_background(self, background: np.ndarray, out_shape: tuple) -> np.ndarray:
        """
        Resizes 'background' to out_shape=(H,W) using OpenCV interpolation.
        """
        oh, ow = out_shape

        if background.ndim == 3 and background.shape[2] == 3:
            # Resizing each channel efficiently without looping in Python
            return np.stack([cv2.resize(background[..., c], (ow, oh), interpolation=cv2.INTER_LANCZOS4)
                            for c in range(3)], axis=-1)
        else:
            return cv2.resize(background, (ow, oh), interpolation=cv2.INTER_LANCZOS4).astype(np.float32)
    # ---------------------------------------------------------------
    # 7) Normalize
    # ---------------------------------------------------------------
    def normalize_image(self, image: np.ndarray, target_median: float) -> np.ndarray:
        """
        Shift image so its median matches target_median.
        """
        cmed = np.median(image)
        diff = target_median - cmed
        return image + diff

class CustomDoubleSpinBox(QWidget):
    valueChanged = pyqtSignal(float)

    def __init__(self, minimum=0.0, maximum=10.0, initial=0.0, step=0.1,
                 suffix: str = "", parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial
        self.suffix = suffix

        # Line edit
        self.lineEdit = QLineEdit(f"{initial:.3f}")
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)
        validator = QDoubleValidator(self.minimum, self.maximum, 3, self)
        validator.setNotation(QDoubleValidator.Notation.StandardNotation)
        self.lineEdit.setValidator(validator)
        self.lineEdit.editingFinished.connect(self.onEditingFinished)

        # Up/down buttons
        self.upButton = QToolButton(); self.upButton.setText("▲")
        self.downButton = QToolButton(); self.downButton.setText("▼")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton.clicked.connect(self.decreaseValue)

        # Buttons layout
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Optional suffix label
        self.suffixLabel = QLabel(self.suffix) if self.suffix else None
        if self.suffixLabel:
            self.suffixLabel.setAlignment(Qt.AlignmentFlag.AlignLeft | Qt.AlignmentFlag.AlignVCenter)

        # Main layout
        mainLayout = QHBoxLayout()
        mainLayout.setSpacing(2)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        if self.suffixLabel:
            mainLayout.addWidget(self.suffixLabel)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def onEditingFinished(self):
        try:
            new_val = float(self.lineEdit.text())
        except ValueError:
            new_val = self._value
        self.setValue(new_val)

    def setValue(self, val: float):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if abs(val - self._value) > 1e-9:
            self._value = val
            self.lineEdit.setText(f"{val:.3f}")
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def value(self) -> float:
        return self._value

class CustomSpinBox(QWidget):
    """
    A simple custom spin box that mimics QSpinBox functionality.
    Emits valueChanged(int) when the value changes.
    """
    valueChanged = pyqtSignal(int)

    def __init__(self, minimum=0, maximum=100, initial=0, step=1, parent=None):
        super().__init__(parent)
        self.minimum = minimum
        self.maximum = maximum
        self.step = step
        self._value = initial

        # Create a line edit to show the value.
        self.lineEdit = QLineEdit(str(initial))
        self.lineEdit.setAlignment(Qt.AlignmentFlag.AlignRight)
        # Optionally, restrict input to integers using a validator.
        
        self.lineEdit.setValidator(QIntValidator(self.minimum, self.maximum, self))
        self.lineEdit.editingFinished.connect(self.editingFinished)

        # Create up and down buttons with arrow text or icons.
        self.upButton = QToolButton()
        self.upButton.setText("▲")
        self.downButton = QToolButton()
        self.downButton.setText("▼")
        self.upButton.clicked.connect(self.increaseValue)
        self.downButton.clicked.connect(self.decreaseValue)

        # Arrange the buttons vertically.
        buttonLayout = QVBoxLayout()
        buttonLayout.addWidget(self.upButton)
        buttonLayout.addWidget(self.downButton)
        buttonLayout.setSpacing(0)
        buttonLayout.setContentsMargins(0, 0, 0, 0)

        # Arrange the line edit and buttons horizontally.
        mainLayout = QHBoxLayout()
        mainLayout.addWidget(self.lineEdit)
        mainLayout.addLayout(buttonLayout)
        mainLayout.setSpacing(0)
        mainLayout.setContentsMargins(0, 0, 0, 0)
        self.setLayout(mainLayout)

        self.updateButtonStates()

    @property
    def value(self):
        return self._value

    def setValue(self, val):
        if val < self.minimum:
            val = self.minimum
        elif val > self.maximum:
            val = self.maximum
        if val != self._value:
            self._value = val
            self.lineEdit.setText(str(val))
            self.valueChanged.emit(val)
            self.updateButtonStates()

    def updateButtonStates(self):
        self.upButton.setEnabled(self._value < self.maximum)
        self.downButton.setEnabled(self._value > self.minimum)

    def increaseValue(self):
        self.setValue(self._value + self.step)

    def decreaseValue(self):
        self.setValue(self._value - self.step)

    def editingFinished(self):
        try:
            newVal = int(self.lineEdit.text())
        except ValueError:
            newVal = self._value
        self.setValue(newVal)

class GradientRemovalDialog(QDialog):
    # Define signals to communicate with AstroEditingSuite
    processing_completed = pyqtSignal(np.ndarray, np.ndarray, bool, str)  # Corrected Image, Gradient Background

    def __init__(self, image, parent=None):
        """
        Initializes the GradientRemoval dialog.

        Args:
            image: Original image as a NumPy array (float32, normalized 0-1).
            parent: Parent widget.
        """
        super().__init__(parent)
        self.setWindowTitle("Gradient Removal")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowMaximizeButtonHint)
        self.image = image.copy()  # Original image (float32, 0-1)
        self.exclusion_polygons = []  # List of polygons (each polygon is a list of QPoint)
        self.drawing = False
        self.current_polygon = []

        # Initialize parameters with default values
        self.num_sample_points = 100
        self.poly_degree = 2
        self.rbf_smooth = 0.1
        self.show_gradient = False

        # Downsample scale factor (can be made user-definable if needed)
        self.downsample_scale = 4
        self.save_to_slot_1 = False

        # Calculate scale factor to fit image within max_display_size
        original_height, original_width = self.image.shape[:2]
        max_display_size = (800, 600)
        max_width, max_height = max_display_size

        scale_w = max_width / original_width
        scale_h = max_height / original_height
        scale = min(scale_w, scale_h, 1.0)  # Prevent upscaling if image is smaller
        self.scale_factor = scale

        scaled_width = int(original_width * scale)
        scaled_height = int(original_height * scale)

        # Prepare display image (same for grayscale or color)
        display_image = (self.image * 255).astype(np.uint8)
        display_image = cv2.resize(display_image, (scaled_width, scaled_height), interpolation=cv2.INTER_AREA)

        # Convert to QImage
        if display_image.ndim == 2:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_Grayscale8)
        else:
            q_img = QImage(display_image.data, scaled_width, scaled_height,
                           display_image.strides[0], QImage.Format.Format_RGB888)

        # Set up QGraphicsScene and QGraphicsView for consistent coordinate mapping
        self.scene = QGraphicsScene(self)
        self.pixmap_item = QGraphicsPixmapItem(QPixmap.fromImage(q_img))
        self.scene.addItem(self.pixmap_item)

        self.view = QGraphicsView(self.scene, self)
        self.view.setRenderHints(QPainter.RenderHint.Antialiasing | QPainter.RenderHint.SmoothPixmapTransform)
        self.view.setAlignment(Qt.AlignmentFlag.AlignTop | Qt.AlignmentFlag.AlignLeft)
        self.view.setDragMode(QGraphicsView.DragMode.NoDrag)
        self.view.viewport().installEventFilter(self)  # Install event filter on the viewport

        # Set up controls (you can leave your setup_controls() largely unchanged)
        self.setup_controls()

        # Layout
        main_layout = QHBoxLayout()
        main_layout.addWidget(self.view, 1)
        controls_widget = QWidget()
        controls_layout = QVBoxLayout()
        controls_layout.addWidget(self.controls_groupbox)
        controls_layout.addStretch(1)
        self.status_label = QLabel("Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        controls_layout.addWidget(self.status_label)
        controls_widget.setLayout(controls_layout)
        controls_widget.setFixedWidth(300)
        main_layout.addWidget(controls_widget, 0)
        self.setLayout(main_layout)
        self.setMinimumSize(1000, 700)

        # For later use, we keep the original (full-resolution) image and store a scaling factor.
        # Here, self.display_scale is used to display the image. When processing, you work with self.image.
        self.thread = None
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        QTimer.singleShot(0, lambda: self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio))


    def setup_controls(self):
        """
        Sets up the user controls for parameters.
        """
        self.controls_groupbox = QGroupBox("Parameters")
        form_layout = QFormLayout()

        # Number of sample points
        self.sample_points_spinbox = CustomSpinBox(minimum=10, maximum=1000, initial=self.num_sample_points, step=10)
        self.sample_points_spinbox.valueChanged.connect(self.update_num_sample_points)
        form_layout.addRow("Number of Sample Points:", self.sample_points_spinbox)

        # Polynomial degree
        self.poly_degree_spinbox = CustomSpinBox(minimum=1, maximum=10, initial=self.poly_degree, step=1)
        self.poly_degree_spinbox.valueChanged.connect(self.update_poly_degree)
        form_layout.addRow("Polynomial Degree:", self.poly_degree_spinbox)

        # RBF smoothing using CustomDoubleSpinBox
        self.rbf_smooth_spinbox = CustomDoubleSpinBox(minimum=0.0, maximum=10.0, initial=self.rbf_smooth, step=0.1)
        self.rbf_smooth_spinbox.valueChanged.connect(self.update_rbf_smooth)
        form_layout.addRow("RBF Smoothness:", self.rbf_smooth_spinbox)

        # Show gradient removal
        self.show_gradient_checkbox = QCheckBox("Show Gradient Removed")
        self.show_gradient_checkbox.stateChanged.connect(self.update_show_gradient)
        form_layout.addRow(self.show_gradient_checkbox)

        # **New: Slot Selection Dropdown**
        self.save_slot_dropdown = QComboBox()
        self.save_slot_dropdown.addItems(["Slot 1", "Slot 2", "Slot 3", "Slot 4", "Slot 5", "Slot 6", "Slot 7", "Slot 8", "Slot 9"])  # Example slot choices
        form_layout.addRow("Save Gradient To:", self.save_slot_dropdown)

        # Add AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.setStatusTip("Apply auto-stretch to the displayed image")
        self.autostretch_button.clicked.connect(self.autostretch_image)
        form_layout.addRow(self.autostretch_button)

        # Clear Drawn Exclusion Areas button
        self.clear_exclusion_button = QPushButton("Clear Exclusion Areas")
        self.clear_exclusion_button.setStatusTip("Clear all drawn exclusion areas")
        self.clear_exclusion_button.clicked.connect(self.clear_exclusion_areas)
        form_layout.addRow(self.clear_exclusion_button)

        # Process button
        self.process_button = QPushButton("Process")
        self.process_button.clicked.connect(self.process_image)
        form_layout.addRow(self.process_button)

        # Instruction for Exclusion Zones
        instructions = QLabel("Draw exclusion zones by clicking and dragging on the image.\n"
                            "Press 'Enter' to finalize each polygon.")
        form_layout.addRow(instructions)

        self.controls_groupbox.setLayout(form_layout)

    def autostretch_image(self):
        """
        Applies auto-stretch to the displayed image without affecting the original image.
        """
        # Stretch the original image for display
        stretched_image = siril_style_autostretch(self.image)

        # Get the current pixmap size from the pixmap_item.
        current_pixmap = self.pixmap_item.pixmap()
        scaled_width = current_pixmap.width()
        scaled_height = current_pixmap.height()

        # Prepare display image (convert from float32 [0,1] to uint8)
        display_image = (stretched_image * 255).astype(np.uint8)

        # Resize for display
        display_image = cv2.resize(
            display_image,
            (scaled_width, scaled_height),
            interpolation=cv2.INTER_AREA,
        )

        # Convert to QImage based on whether image is grayscale or color
        if display_image.ndim == 2:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_Grayscale8,
            )
        else:
            q_img = QImage(
                display_image.data,
                scaled_width,
                scaled_height,
                display_image.strides[0],
                QImage.Format.Format_RGB888,
            )

        # Update the pixmap with the stretched image
        stretched_pixmap = QPixmap.fromImage(q_img)
        self.pixmap_item.setPixmap(stretched_pixmap)
        # Optionally, re-fit the view:
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)


    def eventFilter(self, source, event):
        if source is self.view.viewport():
            if event.type() == QEvent.Type.KeyPress:
                # Finalize current polygon on Enter key
                if event.key() == Qt.Key.Key_Return or event.key() == Qt.Key.Key_Enter:
                    if self.current_polygon:
                        self.exclusion_polygons.append(self.current_polygon.copy())
                        self.current_polygon = []
                        self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    # Map the mouse position directly to scene coordinates
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon = [scene_point]
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    self.update_selection()
                    return True
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    scene_point = self.view.mapToScene(event.pos())
                    self.current_polygon.append(scene_point)
                    # Finalize polygon automatically (or wait for Enter if you prefer)
                    self.exclusion_polygons.append(self.current_polygon.copy())
                    self.current_polygon = []
                    self.update_selection()
                    return True
        return super().eventFilter(source, event)

    def update_selection(self):
        """
        Redraws the pixmap with the exclusion polygons overlaid.
        The polygons are stored in scene coordinates.
        """
        # Start by resetting the pixmap item to the original display image.
        # (Since we're working in scene coordinates, we don't need to re-scale manually.)
        self.pixmap_item.setPixmap(self.pixmap_item.pixmap())

        # Create an overlay pixmap
        overlay = QPixmap(self.pixmap_item.pixmap().size())
        overlay.fill(Qt.GlobalColor.transparent)
        painter = QPainter(overlay)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        # Draw finalized polygons in green (semi-transparent)
        QPen_pen = QPen(QColor(0, 255, 0), 2)
        QPen_brush = QColor(0, 255, 0, 50)
        painter.setPen(QPen_pen)
        painter.setBrush(QPen_brush)
        for polygon in self.exclusion_polygons:
            # Convert list of QPointF to QPolygonF and draw it
            poly = QPolygonF(polygon)
            painter.drawPolygon(poly)

        # Draw current (in-progress) polygon in red dashed outline
        if self.drawing and len(self.current_polygon) > 1:
            pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.DashLine)
            painter.setPen(pen)
            painter.setBrush(Qt.BrushStyle.NoBrush)
            poly = QPolygonF(self.current_polygon)
            painter.drawPolyline(poly)

        painter.end()

        # Create a new QGraphicsPixmapItem for the overlay and add it on top of the image.
        # Remove any existing overlay items.
        for item in self.scene.items():
            if isinstance(item, QGraphicsPixmapItem) and item != self.pixmap_item:
                self.scene.removeItem(item)
        overlay_item = QGraphicsPixmapItem(overlay)
        overlay_item.setZValue(1)  # Ensure it is on top
        self.scene.addItem(overlay_item)


    def clear_exclusion_areas(self):
        """Clears all drawn exclusion polygons."""
        self.exclusion_polygons = []
        self.current_polygon = []
        self.update_selection()


    def update_num_sample_points(self, value):
        self.num_sample_points = value

    def update_poly_degree(self, value):
        self.poly_degree = value

    def update_rbf_smooth(self, value):
        self.rbf_smooth = value

    def update_show_gradient(self, state):
        self.show_gradient = state == Qt.CheckState.Checked

    def mouse_press_event(self, event):
        """
        Handles the mouse press event to initiate drawing.
        Converts the event's position (in label coordinates) to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            # The label's current pixmap is the scaled (displayed) image.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            # Map the mouse position to base coordinates.
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.drawing = True
            self.current_polygon = [base_point]
            self.update_selection()

    def mouse_move_event(self, event):
        """
        Handles the mouse move event to update the current polygon being drawn.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if self.drawing:
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.update_selection()

    def mouse_release_event(self, event):
        """
        Handles the mouse release event to finalize the polygon.
        Converts the event's position from label coordinates to base image coordinates.
        """
        if event.button() == Qt.MouseButton.LeftButton and self.drawing:
            # Optionally, update with the final point.
            displayed = self.label.pixmap()
            if displayed is not None:
                ratio_x = self.base_pixmap.width() / displayed.width()
                ratio_y = self.base_pixmap.height() / displayed.height()
            else:
                ratio_x = ratio_y = 1.0
            base_point = QPoint(int(event.pos().x() * ratio_x),
                                int(event.pos().y() * ratio_y))
            self.current_polygon.append(base_point)
            self.drawing = False
            # Store the polygon (which is in base coordinates)
            self.exclusion_polygons.append(QPolygon(self.current_polygon))
            self.current_polygon = []
            self.update_selection()



    def process_image(self):
        """
        Processes the image to subtract the background in two stages:
        1. Polynomial gradient removal.
        2. RBF gradient removal.
        """
        # Disable the process button to prevent multiple clicks
        self.save_to_slot_1 = self.show_gradient_checkbox.isChecked()
        self.process_button.setEnabled(False)

        # Stretch the image before processing
        self.status_label.setText("Normalizing image for processing...")
        QApplication.processEvents()
        stretched_image = self.stretch_image(self.image)

        # Check if the image is color
        is_color = len(stretched_image.shape) == 3

        # Store original median
        original_median = np.median(stretched_image)

        # Create exclusion mask
        exclusion_mask = self.create_exclusion_mask(stretched_image.shape, self.exclusion_polygons) if self.exclusion_polygons else None

        # ------------------ First Stage: Polynomial Gradient Removal ------------------
        self.status_label.setText("Step 1: Polynomial Gradient Removal")
        QApplication.processEvents()
        # Downsample for polynomial background fitting
        small_image_poly = self.downsample_image(stretched_image, self.downsample_scale)

        # Create a downsampled exclusion mask for polynomial fitting
        if exclusion_mask is not None:
            small_exclusion_mask_poly = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_poly = None

        # Generate sample points for polynomial fitting with exclusions
        poly_sample_points = self.generate_sample_points(
            small_image_poly, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_poly
        )

        # Fit the polynomial gradient
        if is_color:
            poly_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                poly_bg_channel = self.fit_polynomial_gradient(
                    small_image_poly[:, :, channel], poly_sample_points, degree=self.poly_degree
                )
                poly_background[:, :, channel] = self.upscale_background(poly_bg_channel, stretched_image.shape[:2])
        else:
            poly_background_small = self.fit_polynomial_gradient(small_image_poly, poly_sample_points, degree=self.poly_degree)
            poly_background = self.upscale_background(poly_background_small, stretched_image.shape[:2])

        # Subtract the polynomial background
        image_after_poly = stretched_image - poly_background

        # Normalize to restore original median
        image_after_poly = self.normalize_image(image_after_poly, original_median)

        # Clip the values to valid range
        image_after_poly = np.clip(image_after_poly, 0, 1)

        # ------------------ Second Stage: RBF Gradient Removal ------------------
        self.status_label.setText("Step 2: RBF Gradient Removal")
        QApplication.processEvents()
        # Downsample the image after polynomial removal for RBF fitting
        small_image_rbf = self.downsample_image(image_after_poly, self.downsample_scale)

        # Create a downsampled exclusion mask for RBF fitting
        if exclusion_mask is not None:
            small_exclusion_mask_rbf = self.downsample_image(exclusion_mask.astype(np.float32), self.downsample_scale) >= 0.5
        else:
            small_exclusion_mask_rbf = None

        # Generate sample points for RBF fitting with exclusions
        rbf_sample_points = self.generate_sample_points(
            small_image_rbf, num_points=self.num_sample_points, exclusion_mask=small_exclusion_mask_rbf
        )

        # Fit the RBF gradient
        if is_color:
            rbf_background = np.zeros_like(stretched_image)
            for channel in range(3):  # Process each channel separately
                rbf_bg_channel = self.fit_background(
                    small_image_rbf[:, :, channel], rbf_sample_points, smooth=self.rbf_smooth, patch_size=15
                )
                rbf_background[:, :, channel] = self.upscale_background(rbf_bg_channel, stretched_image.shape[:2])
        else:
            rbf_background_small = self.fit_background(small_image_rbf, rbf_sample_points, smooth=self.rbf_smooth, patch_size=15)
            rbf_background = self.upscale_background(rbf_background_small, stretched_image.shape[:2])

        # Subtract the RBF background
        corrected_image = image_after_poly - rbf_background

        # Normalize to restore original median
        corrected_image = self.normalize_image(corrected_image, original_median)

        # Clip the values to valid range
        corrected_image = np.clip(corrected_image, 0, 1)

        # Unstretch both the corrected image and the gradient background
        self.status_label.setText("De-Normalizing the processed images...")
        QApplication.processEvents()
        corrected_image = self.unstretch_image(corrected_image)
        total_background = poly_background + rbf_background
        gradient_background = self.unstretch_image(total_background)

                # Ensure both images are 3-channel RGB
        # Ensure both images are 3-channel RGB
        corrected_image = self.ensure_rgb(corrected_image)
        gradient_background = self.ensure_rgb(gradient_background)


        print("[DEBUG] Step 2 Completed.")

        # ------------------ Emit Results ------------------
        print("[DEBUG] Emitting results...")
        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()

        # Check if the user wants to save the gradient
        save_gradient = self.show_gradient_checkbox.isChecked()

        # Get the selected slot from the dropdown
        selected_slot = self.save_slot_dropdown.currentText()  # Example: "Slot 1"

        if save_gradient:
            print(f"[INFO] Saving extracted gradient to {selected_slot}")
        else:
            print("[INFO] User chose not to save the extracted gradient.")

        # Emit the processed images back to `AstroEditingSuite`
        self.processing_completed.emit(corrected_image, gradient_background, save_gradient, selected_slot)

        self.status_label.setText("Processing Complete")
        self.process_button.setEnabled(True)
        QApplication.processEvents()
        self.accept()

    # ------------------ Helper Functions ------------------
    # Ensure corrected_image and gradient_background are strictly 3-channel RGB
    def ensure_rgb(self,image):
        """
        Ensures the given image is 3-channel RGB.
        Args:
            image: The input NumPy array (can be 2D or 3D with a single channel).
        Returns:
            A 3D NumPy array with shape (height, width, 3).
        """
        if image.ndim == 2:  # Grayscale image
            return np.repeat(image[:, :, np.newaxis], 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 1:  # Single-channel image with an extra dimension
            return np.repeat(image, 3, axis=2)
        elif image.ndim == 3 and image.shape[2] == 3:  # Already RGB
            return image
        else:
            raise ValueError(f"Unexpected image shape: {image.shape}")




    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image.
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # Check if the image is single-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)  # Convert to 3-channel by duplicating

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Initialize lists to store per-channel minima and medians
        self.stretch_original_mins = []
        self.stretch_original_medians = []

        # Initialize stretched_image as a copy of the input image
        stretched_image = image.copy()

        # Define the target median for stretching
        target_median = 0.25

        # Apply the stretch for each channel independently
        for c in range(3):
            # Record the minimum of the current channel
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)

            # Subtract the channel's minimum to shift the image
            stretched_image[..., c] -= channel_min

            # Record the median of the shifted channel
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)

            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        # Clip stretched image to [0, 1] range
        stretched_image = np.clip(stretched_image, 0.0, 1.0)

        # Store stretch parameters
        self.was_single_channel = was_single_channel

        return stretched_image


    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch to return the image to its original state.
        Each channel is unstretched independently by reverting the stretch formula
        using the stored medians and adding back the individual channel minima.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        # Ensure the image is a float32 array for precise calculations and writable
        image = image.astype(np.float32).copy()

        # Apply the unstretch for each channel independently
        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]

            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                # To avoid division by zero
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")

            # Add back the channel's original minimum
            image[..., c] += original_min

        # Clip to [0, 1] range
        image = np.clip(image, 0, 1)

        # If the image was originally single-channel, convert back to single-channel
        if was_single_channel:
            image = np.mean(image, axis=2, keepdims=True)  # Convert back to single-channel

        return image



    def downsample_image(self, image, scale=4):
        """
        Downsamples the image by the specified scale factor using area interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            scale: Downsampling scale factor.

        Returns:
            downsampled_image: Downsampled image.
        """
        new_size = (max(1, image.shape[1] // scale), max(1, image.shape[0] // scale))
        return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)

    def upscale_background(self, background, original_shape):
        """
        Upscales the background model to the original image size.

        Args:
            background: 2D NumPy array (single-channel background model).
            original_shape: Tuple of (height, width) for the target size.

        Returns:
            upscaled_background: Upscaled 2D background model.
        """
        if background.ndim == 2:
            # Single-channel (grayscale) input
            return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LANCZOS4)
        elif background.ndim == 3 and background.shape[2] == 1:
            # Ensure input shape is reduced to 2D for single-channel data
            background = background.squeeze()  # Remove singleton dimension

        return cv2.resize(background, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LANCZOS4)



    def divide_into_quartiles(self, image):
        """
        Divides the image into four quartiles.

        Args:
            image: 2D/3D NumPy array of the image.

        Returns:
            quartiles: Dictionary containing quartile images.
        """
        h, w = image.shape[:2]
        half_h, half_w = h // 2, w // 2
        return {
            'top_left': image[:half_h, :half_w],
            'top_right': image[:half_h, half_w:],
            'bottom_left': image[half_h:, :half_w],
            'bottom_right': image[half_h:, half_w:],
        }

    def exclude_bright_regions(self, quartile, exclusion_fraction=0.5):
        """
        Excludes the brightest regions in a quartile based on the exclusion fraction.

        Args:
            quartile: 2D/3D NumPy array of the quartile image.
            exclusion_fraction: Fraction of the brightest pixels to exclude.

        Returns:
            mask: Boolean mask where True indicates eligible pixels.
        """
        flattened = quartile.flatten()
        threshold = np.percentile(flattened, 100 * (1 - exclusion_fraction))
        mask = quartile < threshold
        return mask

    def gradient_descent_to_dim_spot(self, image, x, y, max_iterations=100, patch_size=15):
        """
        Moves a point to a dimmer spot using gradient descent, considering the median of a patch.

        Args:
            image: 2D/3D NumPy array of the image.
            x, y: Initial coordinates of the point.
            max_iterations: Maximum number of descent steps.
            patch_size: Size of the square patch (e.g., 15 for a 15x15 patch).

        Returns:
            (x, y): Coordinates of the dimmest local spot found.
        """
        half_patch = patch_size // 2

        # Get image dimensions and convert to luminance if color
        if len(image.shape) == 3:
            h, w, _ = image.shape
            luminance = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            h, w = image.shape
            luminance = image

        for _ in range(max_iterations):
            # Define patch around the current point
            xmin, xmax = max(0, x - half_patch), min(w, x + half_patch + 1)
            ymin, ymax = max(0, y - half_patch), min(h, y + half_patch + 1)
            patch = luminance[ymin:ymax, xmin:xmax]
            current_value = np.median(patch)

            # Define a 3x3 window around the point
            neighbors = [
                (nx, ny) for nx in range(max(0, x - 1), min(w, x + 2))
                          for ny in range(max(0, y - 1), min(h, y + 2))
                          if (nx, ny) != (x, y)
            ]

            # Find the dimmest neighbor using patch medians
            def patch_median(coord):
                nx, ny = coord
                xmin_n, xmax_n = max(0, nx - half_patch), min(w, nx + half_patch + 1)
                ymin_n, ymax_n = max(0, ny - half_patch), min(h, ny + half_patch + 1)
                neighbor_patch = luminance[ymin_n:ymax_n, xmin_n:xmax_n]
                return np.median(neighbor_patch)

            dimmest_neighbor = min(neighbors, key=patch_median)
            dimmest_value = patch_median(dimmest_neighbor)

            # If the current point is already the dimmest, stop
            if dimmest_value >= current_value:
                break

            # Move to the dimmest neighbor
            x, y = dimmest_neighbor

        return x, y

    def fit_polynomial_gradient(self, image, sample_points, degree=2, patch_size=15):
        """
        Fits a polynomial gradient (up to the specified degree) to the image using sample points.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            degree: Degree of the polynomial (e.g., 1 for linear, 2 for quadratic).
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The polynomial gradient model across the image.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit polynomial model for this channel
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((x**i) * (y**j))
                A = np.column_stack(terms)
                coeffs, _, _, _ = np.linalg.lstsq(A, z, rcond=None)

                # Generate polynomial model
                xx, yy = np.meshgrid(np.arange(w), np.arange(h))
                terms = []
                for i in range(degree + 1):
                    for j in range(degree + 1 - i):
                        terms.append((xx**i) * (yy**j))
                terms = np.array(terms)
                background[:, :, channel] = np.sum(coeffs[:, None, None] * terms, axis=0)
            return background
        else:  # Grayscale image
            return self.fit_polynomial_gradient(image[:, :, np.newaxis], sample_points, degree, patch_size)

    def generate_sample_points(self, image, num_points=100, exclusion_mask=None):
        """
        Generates sample points for gradient fitting, avoiding exclusion zones.

        Args:
            image: 2D/3D NumPy array of the image.
            num_points: Total number of sample points to generate.
            exclusion_mask: 2D boolean NumPy array where False indicates exclusion.

        Returns:
            points: NumPy array of shape (N, 2) with (x, y) coordinates.
        """
        h, w = image.shape[:2]
        points = []

        # Add border points: 1 in each corner and 5 along each border
        border_margin = 10

        # Corner points
        corners = [
            (border_margin, border_margin),                # Top-left
            (w - border_margin - 1, border_margin),        # Top-right
            (border_margin, h - border_margin - 1),        # Bottom-left
            (w - border_margin - 1, h - border_margin - 1) # Bottom-right
        ]
        for x, y in corners:
            if exclusion_mask is not None and not exclusion_mask[y, x]:
                continue
            x_new, y_new = self.gradient_descent_to_dim_spot(image, x, y)
            if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                continue
            points.append((x_new, y_new))

        # Top and bottom borders
        for x in np.linspace(border_margin, w - border_margin, 5, dtype=int):
            # Top border
            if exclusion_mask is not None and not exclusion_mask[border_margin, x]:
                continue
            x_top, y_top = self.gradient_descent_to_dim_spot(image, x, border_margin)
            if exclusion_mask is not None and not exclusion_mask[y_top, x_top]:
                continue
            points.append((x_top, y_top))
            # Bottom border
            if exclusion_mask is not None and not exclusion_mask[h - border_margin - 1, x]:
                continue
            x_bottom, y_bottom = self.gradient_descent_to_dim_spot(image, x, h - border_margin - 1)
            if exclusion_mask is not None and not exclusion_mask[y_bottom, x_bottom]:
                continue
            points.append((x_bottom, y_bottom))

        # Left and right borders
        for y in np.linspace(border_margin, h - border_margin, 5, dtype=int):
            # Left border
            if exclusion_mask is not None and not exclusion_mask[y, border_margin]:
                continue
            x_left, y_left = self.gradient_descent_to_dim_spot(image, border_margin, y)
            if exclusion_mask is not None and not exclusion_mask[y_left, x_left]:
                continue
            points.append((x_left, y_left))
            # Right border
            if exclusion_mask is not None and not exclusion_mask[y, w - border_margin - 1]:
                continue
            x_right, y_right = self.gradient_descent_to_dim_spot(image, w - border_margin - 1, y)
            if exclusion_mask is not None and not exclusion_mask[y_right, x_right]:
                continue
            points.append((x_right, y_right))

        # Add random points in eligible areas (using quartiles)
        quartiles = self.divide_into_quartiles(image)
        for key, quartile in quartiles.items():
            # Determine the coordinates of the quartile in the full image
            h_quart, w_quart = quartile.shape[:2]
            if "top" in key:
                y_start = 0
            else:
                y_start = h // 2
            if "left" in key:
                x_start = 0
            else:
                x_start = w // 2

            # Create local exclusion mask for the quartile
            if exclusion_mask is not None:
                quart_exclusion_mask = exclusion_mask[y_start:y_start + h_quart, x_start:x_start + w_quart]
            else:
                quart_exclusion_mask = None

            # Convert quartile to grayscale if it has multiple channels
            if quartile.ndim == 3:
                # Assuming the color channels are last, convert to luminance
                quartile_gray = np.dot(quartile[..., :3], [0.2989, 0.5870, 0.1140])
            else:
                quartile_gray = quartile

            # Exclude bright regions
            mask = self.exclude_bright_regions(quartile_gray, exclusion_fraction=0.5)
            if quart_exclusion_mask is not None:
                mask &= quart_exclusion_mask

            eligible_indices = np.argwhere(mask)

            if len(eligible_indices) == 0:
                continue  # Skip if no eligible points in this quartile

            # Ensure we don't request more points than available
            num_points_in_quartile = min(len(eligible_indices), self.num_sample_points // 4)
            selected_indices = eligible_indices[np.random.choice(len(eligible_indices), num_points_in_quartile, replace=False)]

            for idx in selected_indices:
                y_idx, x_idx = idx  # Unpack row to y, x
                y_coord = y_start + y_idx
                x_coord = x_start + x_idx

                # Apply gradient descent to move to a dimmer spot
                x_new, y_new = self.gradient_descent_to_dim_spot(image, x_coord, y_coord)

                # Check if the new point is in exclusion
                if exclusion_mask is not None and not exclusion_mask[y_new, x_new]:
                    continue  # Skip points in exclusion areas

                points.append((x_new, y_new))

        return np.array(points)

    def fit_background(self, image, sample_points, smooth=0.1, patch_size=15):
        """
        Fits a background model using RBF interpolation.

        Args:
            image: 2D/3D NumPy array of the image.
            sample_points: Array of (x, y) sample point coordinates.
            smooth: Smoothness parameter for the RBF fitting.
            patch_size: Size of the square patch for median calculation.

        Returns:
            background: The RBF-based background model.
        """
        h, w = image.shape[:2]
        half_patch = patch_size // 2

        x, y = sample_points[:, 0].astype(np.int32), sample_points[:, 1].astype(np.int32)
        valid_indices = (x >= 0) & (x < w) & (y >= 0) & (y < h)
        x, y = x[valid_indices], y[valid_indices]

        if len(image.shape) == 3:  # Color image
            background = np.zeros_like(image)
            for channel in range(image.shape[2]):  # Process each channel separately
                z = []
                for xi, yi in zip(x, y):
                    xmin, xmax = max(0, xi - half_patch), min(w, xi + half_patch + 1)
                    ymin, ymax = max(0, yi - half_patch), min(h, yi + half_patch + 1)
                    patch = image[ymin:ymax, xmin:xmax, channel]
                    z.append(np.median(patch))
                z = np.array(z, dtype=np.float64)

                # Fit RBF for this channel
                rbf = Rbf(x, y, z, function='multiquadric', smooth=smooth, epsilon=1.0)
                grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))
                background[:, :, channel] = rbf(grid_x, grid_y)
            return background
        else:  # Grayscale image
            return self.fit_background(image[:, :, np.newaxis], sample_points, smooth, patch_size)

    def calculate_median(self, values):
        """
        Calculates the median of the given values.

        Args:
            values: NumPy array of values.

        Returns:
            median: Median value.
        """
        return np.median(values)

    def calculate_mad(self, values, median):
        """
        Calculates the Median Absolute Deviation (MAD).

        Args:
            values: NumPy array of values.
            median: Median of the values.

        Returns:
            mad: Median Absolute Deviation.
        """
        deviations = np.abs(values - median)
        return np.median(deviations)

    def calculate_noise_weight(self, median, mad):
        """
        Calculates the noise weight based on median and MAD.

        Args:
            median: Median value.
            mad: Median Absolute Deviation.

        Returns:
            noise_weight: Noise weight (0.0 to 1.0).
        """
        if median == 0:
            median = 1e-6  # Avoid division by zero
        noise_factor = 1.0 - (mad / median)
        return max(0.0, min(1.0, noise_factor))

    def calculate_brightness_weight(self, avg_brightness, median_brightness):
        """
        Calculates the brightness weight based on average and median brightness.

        Args:
            avg_brightness: Average brightness of the patch.
            median_brightness: Median brightness of the patch.

        Returns:
            brightness_weight: Brightness weight (0.8 to 1.0).
        """
        if median_brightness == 0:
            median_brightness = 1e-6  # Avoid division by zero
        weight = 1.0 - abs(avg_brightness - median_brightness) / median_brightness
        return max(0.8, min(1.0, weight))  # Limit range for stability

    def calculate_spatial_weight(self, x, y, width, height):
        """
        Calculates the spatial weight based on the position of the point.

        Args:
            x: X-coordinate.
            y: Y-coordinate.
            width: Image width.
            height: Image height.

        Returns:
            spatial_weight: Spatial weight (0.95 to 1.0).
        """
        center_x = width / 2
        center_y = height / 2
        distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
        max_distance = np.sqrt(center_x ** 2 + center_y ** 2)
        normalized_distance = distance / max_distance
        return 0.95 + 0.05 * normalized_distance

    def create_exclusion_mask(self, image_shape, exclusion_polygons):
        """
        Creates a boolean mask with False in exclusion areas and True elsewhere.

        Args:
            image_shape: Shape of the image (height, width, channels).
            exclusion_polygons: List of QPolygon objects.

        Returns:
            mask: 2D boolean NumPy array.
        """
        mask = np.ones(image_shape[:2], dtype=bool)  # Initialize all True

        if not exclusion_polygons:
            return mask  # No exclusions

        # Prepare polygons for OpenCV
        polygons = []
        for polygon in exclusion_polygons:
            points = []
            for point in polygon:
                # Scale back to original image coordinates
                x_original = point.x() / self.scale_factor
                y_original = point.y() / self.scale_factor
                points.append([int(x_original), int(y_original)])
            polygons.append(np.array(points, dtype=np.int32))

        # Create a single-channel mask
        exclusion_mask = np.zeros(image_shape[:2], dtype=np.uint8)

        # Fill the polygons on the exclusion mask
        cv2.fillPoly(exclusion_mask, polygons, 1)  # 1 inside polygons

        # Update the main mask: False inside exclusion polygons
        mask[exclusion_mask == 1] = False

        return mask

    def normalize_image(self, image, target_median):
        """
        Normalizes the image so that its median matches the target median.

        Args:
            image: 2D/3D NumPy array of the image.
            target_median: The desired median value.

        Returns:
            normalized_image: The median-normalized image.
        """
        current_median = np.median(image)
        median_diff = target_median - current_median
        normalized_image = image + median_diff
        return normalized_image


class ImagePreview(QWidget):
    # Define a custom signal that emits the slot number
    closed = pyqtSignal(int)
    
    def __init__(self, image_data, slot, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        # Use the parent's custom slot name if available; otherwise default to "Slot {slot}"
        if parent is not None and hasattr(parent, 'slot_names'):
            custom_name = parent.slot_names.get(slot, f"Slot {slot}")
        else:
            custom_name = f"Slot {slot}"
        self.setWindowTitle(f"Preview - {custom_name}")
        self.image_data = image_data  # Numpy array containing the image
        self.zoom_factor = 1.0
        self.slot = slot
        self.is_autostretched = False  # Track if AutoStretch is applied
        self.stretched_image_data = None  # Store stretched image data for visual purposes

        # Create UI components
        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidgetResizable(True)
        
        # Install event filter on the scroll area’s viewport
        self.scroll_area.viewport().installEventFilter(self)

        # Convert numpy image data to QImage and display it
        self.update_image_display()

        # Create Zoom controls
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(1, 400)  # Zoom range from 1% to 400%
        self.zoom_slider.setValue(100)  # Default zoom (100%)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(lambda: self.adjust_zoom(10))

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(lambda: self.adjust_zoom(-10))

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)

        # AutoStretch button
        self.autostretch_button = QPushButton("AutoStretch")
        self.autostretch_button.clicked.connect(self.apply_autostretch)

        # Create the "Make Active" Button.
        # (We disable it if this slot is already active.)
        self.make_active_button = QPushButton("Make Active")
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            current_active_slot = self.parent().image_manager.current_slot
            if current_active_slot == self.slot:
                self.make_active_button.setEnabled(False)
        self.make_active_button.clicked.connect(self.make_slot_active)
        
        swap_layout = QHBoxLayout()
        swap_layout.addStretch()
        swap_layout.addWidget(self.make_active_button)

        # Layout for zoom controls
        zoom_layout = QHBoxLayout()
        zoom_layout.addWidget(self.zoom_out_button)
        zoom_layout.addWidget(self.zoom_slider)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.fit_to_preview_button)
        zoom_layout.addWidget(self.autostretch_button)

        # Main layout
        layout = QVBoxLayout(self)
        layout.addWidget(self.scroll_area)
        layout.addLayout(zoom_layout)
        layout.addLayout(swap_layout)  # Add swap button layout
        self.setLayout(layout)

        # Variables to handle panning
        self._panning = False
        self._pan_start_x = 0
        self._pan_start_y = 0

    def make_slot_active(self):
        """Sets this preview's slot as the active slot in the image manager."""
        if self.parent() is not None and hasattr(self.parent(), 'image_manager'):
            self.parent().image_manager.set_current_slot(self.slot)
            self.close()  # Optionally close the preview window after setting the active slot
        else:
            QMessageBox.critical(self, "Error", "Parent does not have an image manager.")

    def eventFilter(self, source, event):
        """
        Intercept events on the scroll area's viewport to implement panning and zooming.
        """
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.Wheel:
                # When the wheel is scrolled, adjust zoom.
                if event.angleDelta().y() > 0:
                    self.adjust_zoom(10)  # Zoom in (increase slider value by 10)
                else:
                    self.adjust_zoom(-10)  # Zoom out (decrease slider value by 10)
                event.accept()
                return True  # Indicate the event has been handled.

            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = True
                    self._pan_start_x = event.position().x()
                    self._pan_start_y = event.position().y()
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ClosedHandCursor)
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseMove:
                if self._panning and (event.buttons() & Qt.MouseButton.LeftButton):
                    delta_x = event.position().x() - self._pan_start_x
                    delta_y = event.position().y() - self._pan_start_y
                    # Adjust scroll bars for panning.
                    new_h = self.scroll_area.horizontalScrollBar().value() - int(delta_x)
                    new_v = self.scroll_area.verticalScrollBar().value() - int(delta_y)
                    self.scroll_area.horizontalScrollBar().setValue(new_h)
                    self.scroll_area.verticalScrollBar().setValue(new_v)
                    # Update the start position.
                    self._pan_start_x = event.position().x()
                    self._pan_start_y = event.position().y()
                    return True  # Event handled.
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton:
                    self._panning = False
                    self.scroll_area.viewport().setCursor(Qt.CursorShape.ArrowCursor)
                    return True  # Event handled.
        return super().eventFilter(source, event)


    def apply_autostretch(self):
        """Applies AutoStretch to the displayed image for visualization."""
        if self.is_autostretched:
            # If already stretched, reset to the original image
            self.is_autostretched = False
            self.update_image_display()
        else:
            # Perform AutoStretch using the global stretch functions (target median = 0.25) and display it
            self.is_autostretched = True
            self.stretched_image_data = self.stretch_image(self.image_data)
            self.update_image_display()

    def stretch_image(self, image):
        """
        Apply the global stretch functions to the image with a target median of 0.25.
        For grayscale images, use stretch_mono_image.
        For color images, use stretch_color_image.
        """
        target_median = 0.25
        if image.ndim == 2:
            # Grayscale image
            return stretch_mono_image(image, target_median)
        elif image.ndim == 3:
            # Color image (assumes channels are in the last dimension)
            return stretch_color_image(image, target_median, linked=False)
        else:
            raise ValueError("Unsupported image dimensions: must be 2D or 3D")

    def update_image_display(self):
        """Update the QLabel with the current image."""
        # Choose the display image: either autostretched or the original.
        display_image = self.stretched_image_data if self.is_autostretched else self.image_data

        # Normalize image data if necessary
        if display_image.dtype != np.uint8:
            image_data_normalized = np.clip(display_image * 255, 0, 255).astype('uint8')
        else:
            image_data_normalized = display_image

        # Create QImage from the numpy array
        if len(image_data_normalized.shape) == 2:  # Grayscale image
            height, width = image_data_normalized.shape
            bytes_per_line = width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        elif len(image_data_normalized.shape) == 3 and image_data_normalized.shape[2] == 3:  # RGB image
            height, width, channels = image_data_normalized.shape
            bytes_per_line = 3 * width
            qimage = QImage(image_data_normalized.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            QMessageBox.warning(self, "Invalid Image", "Unsupported image format for display.")
            return

        # Convert to pixmap and store the original if not already stored
        pixmap = QPixmap.fromImage(qimage)
        self.original_pixmap = pixmap  # Always update to the current image


        # Scale from the original pixmap size using the current zoom factor
        scaled_pixmap = self.original_pixmap.scaled(
            self.original_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)


    def resizeEvent(self, event):
        """Ensure the image scales appropriately when the window is resized."""
        self.update_image_display()
        super().resizeEvent(event)

    def on_zoom_changed(self, value):
        """Handle changes in zoom slider."""
        self.zoom_factor = value / 100.0  # Convert slider value to zoom factor
        self.update_image_display()

    def adjust_zoom(self, delta):
        """Adjust zoom by a specified delta."""
        new_value = self.zoom_slider.value() + delta
        self.zoom_slider.setValue(max(1, min(400, new_value)))

    def fit_to_preview(self):
        """Fit the image to the preview window."""
        # Ensure we have the original pixmap
        if not hasattr(self, 'original_pixmap') or self.original_pixmap.isNull():
            return

        # Get available size from the scroll area's viewport
        available_size = self.scroll_area.viewport().size()
        pixmap_size = self.original_pixmap.size()

        # Calculate the zoom factor to fit the image
        zoom_factor_w = available_size.width() / pixmap_size.width()
        zoom_factor_h = available_size.height() / pixmap_size.height()
        self.zoom_factor = min(zoom_factor_w, zoom_factor_h)

        # Update the slider value accordingly (convert to percentage)
        self.zoom_slider.setValue(int(self.zoom_factor * 100))
        self.update_image_display()

    def swap_with_slot_zero(self):
        """Swap images between the current slot and Slot 0."""
        confirmation = QMessageBox.question(
            self,
            "Confirm Swap",
            f"Are you sure you want to swap Slot {self.slot} with Slot 0?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            # Debug: Print parent details
            print(f"Attempting to swap Slot {self.slot} with Slot 0.")
            print(f"Parent: {self.parent()}, Type: {type(self.parent())}")
            print(f"Does parent have 'swap_slots'? {'Yes' if hasattr(self.parent(), 'swap_slots') else 'No'}")
            
            # Call the swap_slots method in the parent (AstroEditingSuite)
            if self.parent() and hasattr(self.parent(), 'swap_slots'):
                self.parent().swap_slots(self.slot, 0)

                # Optionally, close the preview window after swapping
                self.close()
            else:
                QMessageBox.critical(self, "Error", "Parent does not have a swap_slots method.")
                print("Error: Parent does not have a swap_slots method.")

    def closeEvent(self, event):
        """Override the close event to emit the custom closed signal."""
        self.closed.emit(self.slot)  # Emit the slot number
        event.accept()  # Proceed with the standard close event

class GraXpertThread(QThread):
    """Thread to execute GraXpert commands."""
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        """Run the GraXpert command and capture output."""
        print(f"[DEBUG] Running command: {self.command}")
        if isinstance(self.command, list):
            print(f"[DEBUG] First item (executable): {self.command[0]}")

        # Copy the current environment and remove variables that might interfere.
        env = os.environ.copy()
        env.pop("PYTHONHOME", None)
        env.pop("PYTHONPATH", None)
        env.pop("DYLD_LIBRARY_PATH", None)
        env.pop("DYLD_FALLBACK_LIBRARY_PATH", None)
        env.pop("PYTHONEXECUTABLE", None)

        process = subprocess.Popen(
            self.command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            env=env,
            start_new_session=True
        )
        for line in process.stdout:
            self.stdout_signal.emit(line.strip())
        for line in process.stderr:
            self.stderr_signal.emit(line.strip())
        self.finished_signal.emit(process.wait())


class RGBCombinationDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.setWindowTitle("RGB Combination")
        self.setModal(True)
        self.image_manager = image_manager  # Reference to ImageManager
        
        self.r_image_path = None
        self.g_image_path = None
        self.b_image_path = None
        self.use_existing_slots = False

        # Retrieve slot_names from parent if available; otherwise use empty dict.
        if parent is not None and hasattr(parent, "slot_names"):
            self.slot_names = parent.slot_names
        else:
            self.slot_names = {}

        # Create UI components
        self.mode_label = QLabel("Select RGB Combination Mode:")
        
        # Radio buttons for mode selection
        self.load_files_radio = QRadioButton("Load Individual Files")
        self.use_slots_radio = QRadioButton("Use Existing Slots")
        self.load_files_radio.setChecked(True)  # Default mode
        
        # Button group to ensure only one radio button is selected
        self.mode_group = QButtonGroup()
        self.mode_group.addButton(self.load_files_radio)
        self.mode_group.addButton(self.use_slots_radio)
        self.mode_group.buttonClicked.connect(self.update_mode)
        
        # GroupBox for mode selection
        self.mode_groupbox = QGroupBox()
        mode_layout = QVBoxLayout()
        mode_layout.addWidget(self.load_files_radio)
        mode_layout.addWidget(self.use_slots_radio)
        self.mode_groupbox.setLayout(mode_layout)
        
        # Load File Mode Widgets
        self.load_r_button = QPushButton("Load Red Image")
        self.load_r_button.clicked.connect(self.load_r_image)
        
        self.load_g_button = QPushButton("Load Green Image")
        self.load_g_button.clicked.connect(self.load_g_image)
        
        self.load_b_button = QPushButton("Load Blue Image")
        self.load_b_button.clicked.connect(self.load_b_image)
        
        self.r_label = QLabel("Red Image: Not Selected")
        self.g_label = QLabel("Green Image: Not Selected")
        self.b_label = QLabel("Blue Image: Not Selected")
        
        # Layout for Load Files Mode
        self.load_files_layout = QVBoxLayout()
        self.load_files_layout.addWidget(self.r_label)
        self.load_files_layout.addWidget(self.load_r_button)
        self.load_files_layout.addWidget(self.g_label)
        self.load_files_layout.addWidget(self.load_g_button)
        self.load_files_layout.addWidget(self.b_label)
        self.load_files_layout.addWidget(self.load_b_button)
        
        # Use Existing Slots Mode Widgets: Three dropdowns for selecting slots for R, G, and B
        self.slots_selection_widget = QGroupBox("Select Slots for R, G, B")
        slots_layout = QHBoxLayout()
        # Red Slot ComboBox
        red_layout = QVBoxLayout()
        red_layout.addWidget(QLabel("Red Slot:"))
        self.red_slot_combo = QComboBox()
        red_layout.addWidget(self.red_slot_combo)
        slots_layout.addLayout(red_layout)
        # Green Slot ComboBox
        green_layout = QVBoxLayout()
        green_layout.addWidget(QLabel("Green Slot:"))
        self.green_slot_combo = QComboBox()
        green_layout.addWidget(self.green_slot_combo)
        slots_layout.addLayout(green_layout)
        # Blue Slot ComboBox
        blue_layout = QVBoxLayout()
        blue_layout.addWidget(QLabel("Blue Slot:"))
        self.blue_slot_combo = QComboBox()
        blue_layout.addWidget(self.blue_slot_combo)
        slots_layout.addLayout(blue_layout)
        self.slots_selection_widget.setLayout(slots_layout)
        
        # Populate the slot dropdowns.
        # Use the image_manager.max_slots if available; for each slot, try to get the name from self.slot_names.
        if self.image_manager is not None and hasattr(self.image_manager, "max_slots"):
            for i in range(self.image_manager.max_slots):
                # Use the stored name if available; note that your rgb_extract stores names keyed by slot number.
                display_text = self.slot_names.get(i, f"Slot {i + 1}")
                self.red_slot_combo.addItem(display_text, i)
                self.green_slot_combo.addItem(display_text, i)
                self.blue_slot_combo.addItem(display_text, i)
        else:
            # Fallback: assume 10 slots.
            for i in range(10):
                display_text = self.slot_names.get(i, f"Slot {i + 1}")
                self.red_slot_combo.addItem(display_text, i)
                self.green_slot_combo.addItem(display_text, i)
                self.blue_slot_combo.addItem(display_text, i)
        
        # Combine and Cancel buttons
        self.combine_button = QPushButton("Combine")
        self.combine_button.clicked.connect(self.combine_images)
        self.combine_button.setEnabled(False)  # Disabled until required inputs are available
        
        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.reject)
        
        # Layout for buttons
        buttons_layout = QHBoxLayout()
        buttons_layout.addStretch()
        buttons_layout.addWidget(self.combine_button)
        buttons_layout.addWidget(self.cancel_button)
        
        # Main Layout
        self.main_layout = QVBoxLayout()
        self.main_layout.addWidget(self.mode_label)
        self.main_layout.addWidget(self.mode_groupbox)
        self.main_layout.addLayout(self.load_files_layout)
        self.main_layout.addWidget(self.slots_selection_widget)
        self.main_layout.addLayout(buttons_layout)
        
        self.setLayout(self.main_layout)
        
        # Set initial state: show file mode, hide slot selection
        self.set_mode_visibility()
    
    def set_mode_visibility(self):
        if self.load_files_radio.isChecked():
            self.use_existing_slots = False
            for widget in [self.r_label, self.load_r_button,
                           self.g_label, self.load_g_button,
                           self.b_label, self.load_b_button]:
                widget.setEnabled(True)
            self.slots_selection_widget.hide()
        else:
            self.use_existing_slots = True
            for widget in [self.r_label, self.load_r_button,
                           self.g_label, self.load_g_button,
                           self.b_label, self.load_b_button]:
                widget.setEnabled(False)
            self.slots_selection_widget.show()
        self.check_inputs()
    
    def update_mode(self):
        self.set_mode_visibility()
    
    def load_r_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Red Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.r_image_path = file_path
            self.r_label.setText(f"Red Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_g_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Green Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.g_image_path = file_path
            self.g_label.setText(f"Green Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def load_b_image(self):
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Blue Image", "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.xisf *.jpg *.jpeg);;All Files (*)"
        )
        if file_path:
            self.b_image_path = file_path
            self.b_label.setText(f"Blue Image: {os.path.basename(file_path)}")
            self.check_inputs()
    
    def check_inputs(self):
        if self.use_existing_slots:
            red_slot = self.red_slot_combo.currentData()
            green_slot = self.green_slot_combo.currentData()
            blue_slot = self.blue_slot_combo.currentData()
            if (self.image_manager._images.get(red_slot) is not None and
                self.image_manager._images.get(green_slot) is not None and
                self.image_manager._images.get(blue_slot) is not None):
                self.combine_button.setEnabled(True)
            else:
                self.combine_button.setEnabled(False)
        else:
            if self.r_image_path and self.g_image_path and self.b_image_path:
                self.combine_button.setEnabled(True)
            else:
                self.combine_button.setEnabled(False)
    
    def combine_images(self):
        try:
            if self.use_existing_slots:
                red_slot = self.red_slot_combo.currentData()
                green_slot = self.green_slot_combo.currentData()
                blue_slot = self.blue_slot_combo.currentData()
                r = self.image_manager._images.get(red_slot).copy()
                g = self.image_manager._images.get(green_slot).copy()
                b = self.image_manager._images.get(blue_slot).copy()
            else:
                r, _, _, _ = load_image(self.r_image_path)
                g, _, _, _ = load_image(self.g_image_path)
                b, _, _, _ = load_image(self.b_image_path)
                if r is None or g is None or b is None:
                    raise ValueError("One or more images failed to load.")
    
            if r.ndim == 3 and r.shape[2] > 1:
                print("Red channel image has multiple channels, extracting first channel.")
                r = r[:, :, 0]
            if g.ndim == 3 and g.shape[2] > 1:
                print("Green channel image has multiple channels, extracting first channel.")
                g = g[:, :, 0]
            if b.ndim == 3 and b.shape[2] > 1:
                print("Blue channel image has multiple channels, extracting first channel.")
                b = b[:, :, 0]
    
            if not (r.shape == g.shape == b.shape):
                raise ValueError("All images must have the same dimensions.")
    
            rgb_image = np.stack([r, g, b], axis=2)
            self.rgb_image = rgb_image  # Store the combined image.
    
            # Use ImageManager.set_image to set the image in the active slot.
            self.image_manager.set_image(new_image=self.rgb_image, metadata={"description": "RGB Combined Image"}, step_name="RGB Combination")
    
            self.accept()  # Close the dialog with success.
            print("RGB Combination successful.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to combine images: {e}")
            print(f"Error in RGB Combination: {e}")

class StarNetThread(QThread):
    # Define signals to communicate with the main thread
    stdout_signal = pyqtSignal(str)
    stderr_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(int)  # Emit return code

    def __init__(self, command, cwd):
        super().__init__()
        self.command = command
        self.cwd = cwd
        self._process = None  # To handle process termination

    def run(self):
        try:
            # Start the StarNet process
            self._process = subprocess.Popen(
                self.command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=self.cwd,
                bufsize=1,
                universal_newlines=True
            )

            # Read stdout and stderr in real-time
            while True:
                output = self._process.stdout.readline()
                if output:
                    self.stdout_signal.emit(output.strip())
                elif self._process.poll() is not None:
                    break

            # Capture remaining stdout
            remaining_stdout, remaining_stderr = self._process.communicate()
            if remaining_stdout:
                self.stdout_signal.emit(remaining_stdout.strip())
            if remaining_stderr:
                self.stderr_signal.emit(remaining_stderr.strip())

            # Emit the return code
            self.finished_signal.emit(self._process.returncode)

        except Exception as e:
            self.stderr_signal.emit(str(e))
            self.finished_signal.emit(-1)

    def stop(self):
        if self._process and self._process.poll() is None:
            self._process.terminate()
            self.wait()

class StarNetDialog(QDialog):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Star Removal Progress")
        self.setMinimumSize(600, 400)
        self.initUI()

    def initUI(self):
        layout = QVBoxLayout()
        self.text_edit = QTextEdit()
        self.text_edit.setReadOnly(True)
        layout.addWidget(self.text_edit)

        self.cancel_button = QPushButton("Cancel")
        self.cancel_button.clicked.connect(self.cancel_process)
        layout.addWidget(self.cancel_button)

        self.setLayout(layout)

    def append_text(self, text):
        self.text_edit.append(text)
        # Auto-scroll to the bottom
        self.text_edit.verticalScrollBar().setValue(self.text_edit.verticalScrollBar().maximum())

    def cancel_process(self):
        self.reject()  # Close the dialog

class DarkStarConfigDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Dark Star Parameters")
        layout = QVBoxLayout(self)

        # Disable GPU
        self.gpu_combo = QComboBox()
        self.gpu_combo.addItems(["No", "Yes"])
        layout.addWidget(QLabel("Disable GPU Acceleration?"))
        layout.addWidget(self.gpu_combo)

        # Mode
        self.mode_combo = QComboBox()
        self.mode_combo.addItems(["unscreen", "additive"])
        layout.addWidget(QLabel("Star Removal Mode"))
        layout.addWidget(self.mode_combo)

        # Show extracted stars
        self.show_stars_combo = QComboBox()
        self.show_stars_combo.addItems(["Yes", "No"])
        layout.addWidget(QLabel("Show Extracted Stars?"))
        layout.addWidget(self.show_stars_combo)

        # Stride
        self.chunk_size_combo = QComboBox()
        self.chunk_size_combo.addItems(["32", "64", "128", "256", "512", "1024", "2048"])
        self.chunk_size_combo.setCurrentText("512")
        layout.addWidget(QLabel("Stride (power of 2):"))
        layout.addWidget(self.chunk_size_combo)

        # Buttons
        buttons = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel
        )
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addWidget(buttons)

    def get_values(self):
        return {
            "disable_gpu": self.gpu_combo.currentText() == "Yes",
            "mode": self.mode_combo.currentText(),
            "show_extracted_stars": self.show_stars_combo.currentText() == "Yes",
            "chunk_size": int(self.chunk_size_combo.currentText())
        }


class AddStarsDialog(QDialog):
    """
    Dialog for configuring and previewing star additions to an image.
    """
    # Define a custom signal to emit the blended image back to the main application
    stars_added = pyqtSignal(np.ndarray)  # Emitting the blended image

    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Add Stars to Image")
        self.image_manager = image_manager  # Reference to ImageManager
        self.current_slot = self.image_manager.current_slot
        self.starless_image = None
        self.stars_only_image = None
        self.blended_image = None
        self.scale_factor = 1.0
        self.fitted = False  # To ensure fit_to_preview is called only once

        # Initialize UI
        self.init_ui()

    def init_ui(self):
        """
        Sets up the UI components.
        """
        # Main layout
        main_layout = QVBoxLayout()

        # Preview Area
        self.preview_label = QLabel()
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.preview_label.setBackgroundRole(self.palette().ColorRole.Base)
        self.preview_label.setSizePolicy(QSizePolicy.Policy.Ignored, QSizePolicy.Policy.Ignored)
        self.preview_label.setScaledContents(False)

        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(False)
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        main_layout.addWidget(self.scroll_area)

        # Zoom Controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        fit_button = QPushButton("Fit to Preview")
        fit_button.clicked.connect(self.fit_to_preview)

        # Add tooltips for better user guidance
        zoom_in_button.setToolTip("Increase the zoom level of the preview image.")
        zoom_out_button.setToolTip("Decrease the zoom level of the preview image.")
        fit_button.setToolTip("Automatically fit the image to the preview area.")

        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Selection Controls
        selection_layout = QGridLayout()

        # Blend Type Dropdown
        blend_type_label = QLabel("Blend Type:")
        self.blend_type_combo = QComboBox()
        self.blend_type_combo.addItems(["Screen", "Add"])
        self.blend_type_combo.currentIndexChanged.connect(self.update_preview)
        self.blend_type_combo.setToolTip("Select the blend type to apply.")

        selection_layout.addWidget(blend_type_label, 0, 0)
        selection_layout.addWidget(self.blend_type_combo, 0, 1)

        # Starless Image Selection
        starless_label = QLabel("Starless Image:")
        self.starless_combo = QComboBox()
        self.populate_slot_combo(self.starless_combo)
        self.starless_combo.currentIndexChanged.connect(self.load_starless_image)
        starless_file_button = QPushButton("Load from File")
        starless_file_button.clicked.connect(lambda: self.load_image_from_file(source='starless'))
        starless_file_button.setToolTip("Load a starless image from your filesystem.")

        selection_layout.addWidget(starless_label, 1, 0)
        selection_layout.addWidget(self.starless_combo, 1, 1)
        selection_layout.addWidget(starless_file_button, 1, 2)

        # Stars-Only Image Selection
        stars_only_label = QLabel("Stars-Only Image:")
        self.stars_only_combo = QComboBox()
        self.populate_slot_combo(self.stars_only_combo)
        self.stars_only_combo.currentIndexChanged.connect(self.load_stars_only_image)
        stars_only_file_button = QPushButton("Load from File")
        stars_only_file_button.clicked.connect(lambda: self.load_image_from_file(source='stars_only'))
        stars_only_file_button.setToolTip("Load a stars-only image from your filesystem.")

        selection_layout.addWidget(stars_only_label, 2, 0)
        selection_layout.addWidget(self.stars_only_combo, 2, 1)
        selection_layout.addWidget(stars_only_file_button, 2, 2)

        main_layout.addLayout(selection_layout)

        # Blend Ratio Slider
        blend_ratio_layout = QHBoxLayout()
        blend_ratio_label = QLabel("Blend Ratio (Screen/Add Intensity):")
        self.blend_ratio_slider = QSlider(Qt.Orientation.Horizontal)
        self.blend_ratio_slider.setMinimum(0)
        self.blend_ratio_slider.setMaximum(100)
        self.blend_ratio_slider.setValue(100)  # Default to full blend type effect
        self.blend_ratio_slider.setTickInterval(10)
        self.blend_ratio_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.blend_ratio_slider.valueChanged.connect(self.update_preview)
        self.blend_ratio_slider.setToolTip("Adjust the intensity of the selected blend type.")

        blend_ratio_layout.addWidget(blend_ratio_label)
        blend_ratio_layout.addWidget(self.blend_ratio_slider)

        main_layout.addLayout(blend_ratio_layout)

        # Action Buttons
        action_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_blend)
        apply_button.setToolTip("Apply the blended image to the current slot.")
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        cancel_button.setToolTip("Cancel and close the dialog without applying changes.")

        action_layout.addStretch()
        action_layout.addWidget(apply_button)
        action_layout.addWidget(cancel_button)

        main_layout.addLayout(action_layout)

        self.setLayout(main_layout)
        self.setMinimumSize(800, 600)

    def populate_slot_combo(self, combo_box):
        """
        Populates a QComboBox with available image slots from the ImageManager.
        Uses the custom slot names if they have been renamed.
        """
        combo_box.clear()
        # "Select Slot" item, with no slot data
        combo_box.addItem("Select Slot", None)

        parent = self.parent()  # The parent might have slot_names
        for slot in range(self.image_manager.max_slots):
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                if parent is not None and hasattr(parent, "slot_names"):
                    # Use the renamed slot if it exists; otherwise default to "Slot {slot}"
                    name = parent.slot_names.get(slot, f"Slot {slot}")
                else:
                    name = f"Slot {slot}"

                # --> Add the item with the *display text* = name and *data* = slot index
                combo_box.addItem(name, slot)

        # Option to load from file, store a sentinel like "file" or -1
        combo_box.addItem("Load from File", "file")


    def load_image_from_file(self, source):
        """
        Loads an image from a file for either starless or stars-only.
        Utilizes the global load_image method.
        """
        filename, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {'Starless' if source == 'starless' else 'Stars-Only'} Image",
            "",
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.jpg *.jpeg *.raw *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if filename:
            # Utilize the global load_image function
            image, original_header, bit_depth, is_mono = load_image(filename)
            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the selected image.")
                return

            # Assign to the appropriate variable
            if source == 'starless':
                self.starless_image = image
                self.starless_combo.setCurrentIndex(self.starless_combo.count() - 1)  # Select "Load from File"
                print(f"Starless image loaded from file: {filename}")
            elif source == 'stars_only':
                self.stars_only_image = image
                self.stars_only_combo.setCurrentIndex(self.stars_only_combo.count() - 1)  # Select "Load from File"
                print(f"Stars-only image loaded from file: {filename}")

            self.update_preview()

    def load_starless_image(self):
        """Loads the starless image based on the selection in the combo box."""
        selected_data = self.starless_combo.currentData()

        if selected_data is None:
            # This is the "Select Slot" item
            self.starless_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button, so do nothing here
            pass

        else:
            # Here, selected_data should be the integer slot index
            slot = selected_data  
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.starless_image = image.copy()
                print(f"Starless image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.starless_image = None

        self.update_preview()


    def load_stars_only_image(self):
        """Loads the stars-only image based on the selection in the combo box."""
        selected_data = self.stars_only_combo.currentData()

        if selected_data is None:
            # "Select Slot"
            self.stars_only_image = None

        elif selected_data == "file":
            # "Load from File" is handled by the button
            pass

        else:
            slot = selected_data
            image = self.image_manager._images.get(slot, None)
            if image is not None:
                self.stars_only_image = image.copy()
                print(f"Stars-only image loaded from slot {slot}.")
            else:
                QMessageBox.warning(self, "Empty Slot", f"Slot {slot} does not contain an image.")
                self.stars_only_image = None

        self.update_preview()
        
    def blend_images(self):
        """
        Blends the starless and stars-only images based on the selected method and blend ratio.
        Applies the mask to the blended image.
        Returns the final blended image.
        """
        if self.starless_image is None or self.stars_only_image is None:
            return None

        # Ensure both images have the same dimensions
        if self.starless_image.shape != self.stars_only_image.shape:
            QMessageBox.critical(self, "Error", "Images have different dimensions. Please select matching images.")
            return None

        blend_type = self.blend_type_combo.currentText()
        blend_ratio = self.blend_ratio_slider.value() / 100.0  # Convert to [0,1]

        # Compute blended image based on blend type
        if blend_type == "Screen":
            blended_type = self.starless_image + self.stars_only_image - (self.starless_image * self.stars_only_image)
        elif blend_type == "Add":
            blended_type = self.starless_image + self.stars_only_image
        else:
            blended_type = self.starless_image.copy()

        # Apply blend ratio to control the intensity of the blend type
        # blended = (1 - blend_ratio) * starless + blend_ratio * blended_type
        blended = (1 - blend_ratio) * self.starless_image + blend_ratio * blended_type

        # Clip the result to [0,1]
        blended = np.clip(blended, 0.0, 1.0)

        # ✅ Only apply mask if it is actively applied
        mask_slot = self.image_manager.mask_manager.get_applied_mask_slot()
        if mask_slot == self.current_slot:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                # Ensure mask has correct dimensions
                if mask.shape != self.starless_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match image dimensions.")
                    return None

                # Normalize mask to [0,1]
                if mask.dtype != np.float32:
                    mask = mask.astype('float32') / 255.0

                if mask.ndim == 3:
                    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)

                if self.starless_image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=2)
                    mask = np.repeat(mask, self.starless_image.shape[2], axis=2)

                mask = np.clip(mask, 0.0, 1.0)

                final_image = self.starless_image * (1 - mask) + mask * blended
                final_image = np.clip(final_image, 0.0, 1.0)
                print("✅ Applied active mask to the blended image.")
            else:
                final_image = blended
                print("⚠️ No active mask found. Using blended image directly.")
        else:
            final_image = blended
            print("ℹ️ Mask slot is not active. Skipping mask application.")

        return final_image
    def update_preview(self):
        """
        Updates the preview area with the current blended image while maintaining zoom and scroll position.
        """
        final_image = self.blend_images()
        if final_image is not None:
            self.blended_image = final_image.copy()

            # Convert final image to QPixmap
            pixmap = self.convert_to_pixmap(final_image)

            # Store current scroll positions
            h_scroll = self.scroll_area.horizontalScrollBar().value()
            v_scroll = self.scroll_area.verticalScrollBar().value()

            # Scale the pixmap based on scale_factor
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.scale_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )

            # Update the preview label with the scaled pixmap
            self.preview_label.setPixmap(scaled_pixmap)
            self.preview_label.adjustSize()

            # Restore scroll positions
            self.scroll_area.horizontalScrollBar().setValue(h_scroll)
            self.scroll_area.verticalScrollBar().setValue(v_scroll)
            print("Updated preview with the final blended image.")
        else:
            self.preview_label.clear()
            print("Cleared preview due to missing images or errors.")

    def convert_to_pixmap(self, image):
        """
        Converts a numpy image array to QPixmap for display.
        """
        # Ensure image is in [0,1] range
        image = np.clip(image, 0, 1)

        # Convert to 8-bit
        image_8bit = (image * 255).astype(np.uint8)

        # Handle grayscale and RGB images
        if image_8bit.ndim == 2:
            # Grayscale
            q_image = QImage(
                image_8bit.data,
                image_8bit.shape[1],
                image_8bit.shape[0],
                image_8bit.strides[0],
                QImage.Format.Format_Grayscale8
            )
        elif image_8bit.ndim == 3:
            if image_8bit.shape[2] == 3:
                # RGB
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGB888
                )
            elif image_8bit.shape[2] == 4:
                # RGBA
                q_image = QImage(
                    image_8bit.data,
                    image_8bit.shape[1],
                    image_8bit.shape[0],
                    image_8bit.strides[0],
                    QImage.Format.Format_RGBA8888
                )
            else:
                # Unsupported format
                QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
                return QPixmap()
        else:
            QMessageBox.critical(self, "Error", "Unsupported image format for preview.")
            return QPixmap()

        return QPixmap.fromImage(q_image)

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    @announce_zoom
    def zoom_in(self):
        """Zoom in on the preview image."""
        self.scale_factor *= 1.25
        self.update_image()
        print(f"Zoomed in. Current scale factor: {self.scale_factor}")

    @announce_zoom
    def zoom_out(self):
        """Zoom out of the preview image."""
        self.scale_factor /= 1.25
        self.update_image()
        print(f"Zoomed out. Current scale factor: {self.scale_factor}")

    def fit_to_preview(self):
        """Fit the blended image to the preview area."""
        if self.blended_image is None:
            return
        QTimer.singleShot(0, self.perform_fit_to_preview)

    def perform_fit_to_preview(self):
        """
        Performs the fit to preview action after the event loop has processed show events.
        """
        if self.blended_image is None:
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        pixmap = self.convert_to_pixmap(self.blended_image)
        pixmap_size = pixmap.size()

        # Calculate scale factor to fit the image within the viewport while maintaining aspect ratio
        scale_w = viewport_size.width() / pixmap_size.width()
        scale_h = viewport_size.height() / pixmap_size.height()
        scale_factor = min(scale_w, scale_h)

        # Apply the scale factor
        self.scale_factor = scale_factor
        self.update_preview()
        print(f"Fitted image to preview. New scale factor: {self.scale_factor}")

    def scale_image(self, factor):
        """Scales the image by the given factor."""
        if self.blended_image is None:
            return
        self.scale_factor *= factor
        self.update_preview()
        print(f"Scaled image by a factor of {factor}. New scale factor: {self.scale_factor}")

    def update_image(self):
        """
        Updates the displayed image based on the current scale factor.
        """
        if self.blended_image is None:
            return

        pixmap = self.convert_to_pixmap(self.blended_image)
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.scale_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.preview_label.setPixmap(scaled_pixmap)
        self.preview_label.adjustSize()
        print("Updated image display based on new scale factor.")

    def apply_blend(self):
        """
        Applies the blended image to the main application and closes the dialog.
        """
        if self.blended_image is None:
            QMessageBox.warning(self, "No Blend", "No blended image to apply.")
            print("Apply blend failed: No blended image available.")
            return

        # Emit the blended image
        self.stars_added.emit(self.blended_image)
        self.accept()
        print("Applied blended image and closed dialog.")

    def showEvent(self, event):
        """
        Overrides the showEvent to fit the image to the window when the dialog is shown.
        """
        super().showEvent(event)
        if not self.fitted:
            QTimer.singleShot(0, self.fit_to_preview)  # Schedule fit_to_preview after the event loop
            self.fitted = True
            print("Dialog shown and image fitted to preview.")

class ApertureHelpWindow(QDialog):
    """
    A simple dialog that displays an image to help the user understand
    the aperture parameters (number of vanes, pupil radius, obstruction, vane width, etc.)
    """
    def __init__(self, image_path, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Aperture Help")
        self.setMinimumSize(400, 400)
        layout = QVBoxLayout(self)

        try:
            pixmap = QPixmap(image_path)
            if pixmap.isNull():
                raise ValueError("Could not load image.")
            label = QLabel()
            label.setPixmap(pixmap)
            label.setAlignment(Qt.AlignmentFlag.AlignCenter)
            layout.addWidget(label)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load aperture help image: {e}")
        self.setLayout(layout)

class StarSpikePreviewWindow(QDialog):
    """
    A separate window to display the final star-spiked image for preview.
    Includes:
      - Zoom In, Zoom Out, Fit to Preview controls
      - An optional "Save to Slot" button if an ImageManager is provided
    """
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.setWindowTitle("Star Spike Preview")
        self.setMinimumSize(400, 400)

        # (Optional) If we want to allow saving to slots
        self.image_manager = image_manager
        self.preview_image = None  # We'll store the display image here

        # Zoom parameters
        self.zoom_factor = 1.0
        self.zoom_step = 1.25
        self.zoom_min = 0.1
        self.zoom_max = 5.0

        # Main layout
        self.main_layout = QVBoxLayout(self)
        self.setLayout(self.main_layout)

        # 1) Create the image display area (QGraphicsView)
        self._create_image_display_area()

        # 2) Create the zoom controls
        self._create_zoom_controls()

        # 3) Optionally create a "Save to Slot" button if image_manager is present
        if self.image_manager is not None:
            self._create_save_button()

    def _create_image_display_area(self):
        """Create a QGraphicsView & QGraphicsScene for the preview image."""
        self.scene = QGraphicsScene()
        self.graphics_view = QGraphicsView()
        self.graphics_view.setScene(self.scene)
        self.graphics_view.setAlignment(Qt.AlignmentFlag.AlignCenter)

        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)

        # Enable panning with mouse drag
        self.graphics_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)

        # Enable scroll bars
        self.graphics_view.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)
        self.graphics_view.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)

        # Add the graphics view to the main layout
        self.main_layout.addWidget(self.graphics_view)

    def _create_zoom_controls(self):
        """Create a group with Zoom In, Zoom Out, and Fit to Preview buttons."""
        self.zoom_controls_group = QGroupBox("Zoom Controls")
        zoom_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self._zoom_in)
        zoom_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self._zoom_out)
        zoom_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(self.fit_to_preview_button)

        self.zoom_controls_group.setLayout(zoom_layout)
        self.main_layout.addWidget(self.zoom_controls_group)

    def _create_save_button(self):
        """Create a 'Save to Slot' button if we have an image_manager."""
        self.save_button = QPushButton("Save to Slot")
        self.save_button.clicked.connect(self._save_to_slot)
        self.main_layout.addWidget(self.save_button)

    def _zoom_in(self):
        new_zoom = self.zoom_factor * self.zoom_step
        if new_zoom <= self.zoom_max:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom In", "Maximum zoom level reached.")

    def _zoom_out(self):
        new_zoom = self.zoom_factor / self.zoom_step
        if new_zoom >= self.zoom_min:
            self.zoom_factor = new_zoom
            self._apply_zoom()
        else:
            QMessageBox.information(self, "Zoom Out", "Minimum zoom level reached.")

    def _fit_to_preview(self):
        """Fit the entire image within the QGraphicsView."""
        if self.pixmap_item.pixmap().isNull():
            return  # No image
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)
        self.zoom_factor = 1.0

    def _apply_zoom(self):
        """Apply the current zoom factor to the graphics view."""
        self.graphics_view.resetTransform()
        self.graphics_view.scale(self.zoom_factor, self.zoom_factor)

    def update_image(self, image_array):
        """
        Update the preview with the given image array (color or mono).
        image_array: np.ndarray (H,W) or (H,W,3) in [0..1] or up to e.g. 65535.
        """
        try:
            # Convert to 8-bit for display
            # If float [0..1], scale to 0..255. 
            arr = np.clip(image_array, 0, 1) * 255.0
            arr = arr.astype(np.uint8)

            # Determine shape
            if arr.ndim == 2:
                # Mono => QImage.Format_Grayscale8
                h, w = arr.shape
                qimage = QImage(arr.data, w, h, w, QImage.Format.Format_Grayscale8)
            elif arr.ndim == 3 and arr.shape[2] == 3:
                # Color => QImage.Format_RGB888
                h, w, _ = arr.shape
                qimage = QImage(arr.data, w, h, 3*w, QImage.Format.Format_RGB888)
            else:
                raise ValueError("Unsupported image shape for preview.")

            pixmap = QPixmap.fromImage(qimage)
            self.pixmap_item.setPixmap(pixmap)
            self.graphics_view.setSceneRect(self.pixmap_item.boundingRect())
            self._fit_to_preview()

            # Store the final array if we want to save it
            self.preview_image = image_array

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to update preview: {e}")

    def _save_to_slot(self):
        """
        If we have an image_manager, let user pick a slot and store self.preview_image.
        We'll push old image to that slot's undo stack if you have a method like set_image_for_slot(...).
        """
        if self.preview_image is None:
            QMessageBox.warning(self, "No Image", "No preview image to save.")
            return

        if self.image_manager is None:
            QMessageBox.warning(self, "No Manager", "No ImageManager passed to preview window.")
            return

        # Prompt user for a slot index
        slot_idx, ok = QInputDialog.getInt(
            self,
            "Save to Slot",
            f"Enter slot number (0..{self.image_manager.max_slots - 1}):",
            self.image_manager.current_slot,  # default
            0,
            self.image_manager.max_slots - 1,
            1
        )
        if not ok:
            return

        # Build metadata
        new_metadata = {
            "description": "Star-Spiked from Preview",
            "is_float": True
        }

        # If you have set_image_for_slot(...):
        if hasattr(self.image_manager, "set_image_for_slot"):
            self.image_manager.set_image_for_slot(slot_idx, self.preview_image, new_metadata, step_name="Star Spike Tool")
        else:
            # fallback to add_image(...) if you want
            self.image_manager.add_image(slot_idx, self.preview_image, new_metadata)

        print(f"Preview image saved to slot {slot_idx}.")

class AdvancedOptionsDialog(QDialog):
    """
    A popup dialog for advanced parameters.
    Contains advanced parameters such as Flux Max Range, BrightScale Min/Max,
    Shrink Min/Max, and now Detect Threshold.
    When accepted, the values can be retrieved by the calling code.
    """
    def __init__(self, parent=None, initial_values=None):
        super().__init__(parent)
        self.setWindowTitle("Advanced Options")
        self.setModal(True)
        layout = QVBoxLayout(self)

        form = QFormLayout()
        self.flux_max_spin = CustomDoubleSpinBox(minimum=1.0, maximum=999999.0,
                                                   initial=initial_values.get('flux_max', 300.0),
                                                   step=50.0)
        form.addRow("Flux Max Range:", self.flux_max_spin)

        self.bscale_min_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                    initial=initial_values.get('bscale_min', 10.0),
                                                    step=1.0)
        form.addRow("BrightScale Min:", self.bscale_min_spin)

        self.bscale_max_spin = CustomDoubleSpinBox(minimum=1.0, maximum=999.0,
                                                    initial=initial_values.get('bscale_max', 30.0),
                                                    step=1.0)
        form.addRow("BrightScale Max:", self.bscale_max_spin)

        self.shrink_min_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                    initial=initial_values.get('shrink_min', 1.0),
                                                    step=0.2)
        form.addRow("Shrink Min:", self.shrink_min_spin)

        self.shrink_max_spin = CustomDoubleSpinBox(minimum=0.1, maximum=999.0,
                                                   initial=initial_values.get('shrink_max', 5.0),
                                                   step=0.2)
        form.addRow("Shrink Max:", self.shrink_max_spin)

        # Move Detect Threshold into the advanced options.
        self.detect_thresh_spin = CustomDoubleSpinBox(minimum=0.0, maximum=100.0,
                                                      initial=initial_values.get('detect_thresh', 5.0),
                                                      step=0.1)
        form.addRow("Detect Threshold:", self.detect_thresh_spin)

        layout.addLayout(form)

        # OK and Cancel buttons
        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("OK")
        ok_btn.clicked.connect(self.accept)
        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)
        layout.addLayout(btn_layout)

        self.setLayout(layout)

    def get_values(self):
        return {
            'flux_max': self.flux_max_spin.value(),
            'bscale_min': self.bscale_min_spin.value(),
            'bscale_max': self.bscale_max_spin.value(),
            'shrink_min': self.shrink_min_spin.value(),
            'shrink_max': self.shrink_max_spin.value(),
            'detect_thresh': self.detect_thresh_spin.value(),
            # Note: color boost is now in the basic UI.
        }
       

class StarSpikeTool(QDialog):
    """
    A stand-alone dialog that integrates with AstroEditingSuite.
    - Reads the active image from image_manager.
    - Lets the user define star detection & diffraction parameters.
    - Generates star spikes with multi-threading.
    - Optionally overwrites the same slot in image_manager.
    """
    def __init__(self, image_manager, mask_manager, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Star Spike Tool")
        self.image_manager = image_manager
        self.mask_manager  = mask_manager
        self.final_image = None

        # Set default advanced parameters.
        self.advanced_params = {
            'flux_max': 300.0,
            'bscale_min': 10.0,
            'bscale_max': 30.0,
            'shrink_min': 1.0,
            'shrink_max': 5.0,
            'detect_thresh': 5.0  # default advanced detect threshold.
        }
        # UI Setup
        self._init_ui()
        self._image_data = None

    def _init_ui(self):
        """Builds the layout with basic form parameters, an advanced options popup, and other controls."""
        main_layout = QVBoxLayout(self)

        # Basic parameters form.
        basic_form = QFormLayout()

        # New: Toggle switch for pupil type.
        # Using a QCheckBox as a toggle. When checked, we simulate a JWST pupil.
        # -- Toggle Switch Button for Aperture Type --
        self.pupil_toggle_button = QPushButton("Circular")
        self.pupil_toggle_button.setCheckable(True)
        self.pupil_toggle_button.setChecked(False)  # Start off in 'Circular' mode
        self.pupil_toggle_button.toggled.connect(self._on_pupil_toggle)
        # Optionally style it to look like a sliding switch:
        self.pupil_toggle_button.setStyleSheet("""
            QPushButton {
                min-width: 60px;   max-width: 60px;
                min-height: 28px;  max-height: 28px;
                border-radius: 14px;
                background-color: #ccc;
                border: 1px solid #999;
            }
            QPushButton:checked {
                background-color: #66bb6a; /* A greenish color */
            }
        """)
        basic_form.addRow("Aperture Type:", self.pupil_toggle_button)

        # Store labels for vanes, vane width, and obstruction.
        self.radius_label = QLabel("Pupil Radius:")
        self.radius_spin = CustomDoubleSpinBox(minimum=1.0, maximum=512.0, initial=128.0, step=1.0)
        basic_form.addRow(self.radius_label, self.radius_spin)

        self.obstruction_label = QLabel("Obstruction:")
        self.obstruction_spin = CustomDoubleSpinBox(minimum=0.0, maximum=0.99, initial=0.2, step=0.05)
        basic_form.addRow(self.obstruction_label, self.obstruction_spin)

        self.num_vanes_label = QLabel("Number of Vanes:")
        self.num_vanes_spin = CustomSpinBox(minimum=2, maximum=8, initial=2, step=1)
        basic_form.addRow(self.num_vanes_label, self.num_vanes_spin)

        self.vane_width_label = QLabel("Vane Width:")
        self.vane_width_spin = CustomDoubleSpinBox(minimum=0.0, maximum=50.0, initial=4.0, step=0.5)
        basic_form.addRow(self.vane_width_label, self.vane_width_spin)

        # New: Rotation angle.
        self.rotation_spin = CustomDoubleSpinBox(minimum=0.0, maximum=360.0, initial=0.0, step=1.0)
        basic_form.addRow("Rotation Angle (deg):", self.rotation_spin)

        # The Color Boost control is now in basic UI.
        self.color_boost_spin = CustomDoubleSpinBox(minimum=0.1, maximum=10.0, initial=1.5, step=0.1)
        basic_form.addRow("Spike Boost:", self.color_boost_spin)

        self.blur_sigma_spin = CustomDoubleSpinBox(minimum=0.1, maximum=10.0, initial=2.0, step=0.1)
        basic_form.addRow("PSF Blur Sigma:", self.blur_sigma_spin)

        # Remove Detect Threshold from basic form (will be in advanced)
        # And we already have Flux Min here.
        self.flux_min_spin = CustomDoubleSpinBox(minimum=0.0, maximum=999999.0, initial=30.0, step=10.0)
        basic_form.addRow("Flux Min:", self.flux_min_spin)

        main_layout.addLayout(basic_form)

        # Advanced Options button.
        self.adv_options_btn = QPushButton("Advanced Options...")
        self.adv_options_btn.setToolTip("Configure advanced parameters")
        self.adv_options_btn.clicked.connect(self._show_advanced_options)
        main_layout.addWidget(self.adv_options_btn)

        # Buttons: Generate Spikes and Save to Slot.
        btn_layout = QHBoxLayout()
        self.run_button = QPushButton("Generate Spikes")
        self.run_button.clicked.connect(self._run_spikes)
        btn_layout.addWidget(self.run_button)

        self.save_button = QPushButton("Save to Slot")
        self.save_button.clicked.connect(self._save_to_slot)
        self.save_button.setEnabled(False)
        btn_layout.addWidget(self.save_button)
        main_layout.addLayout(btn_layout)

        # Progress Bar.
        self.progress_bar = QProgressBar()
        self.progress_bar.setValue(0)
        main_layout.addWidget(self.progress_bar)
        # Status label at the bottom.
        self.status_label = QLabel("Ready")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout.addWidget(self.status_label)
        # Help Button.
        self.help_button = QPushButton("Help")
        self.help_button.setToolTip("Click to view an example diagram of the telescope aperture and PSF parameters.")
        self.help_button.clicked.connect(self._show_aperture_help)
        main_layout.addWidget(self.help_button)

        self.setLayout(main_layout)

        # Initialize state of advanced controls based on pupil type.
        self._on_pupil_toggle(self.pupil_toggle_button.isChecked())


    def _on_pupil_toggle(self, checked: bool):
        """
        When toggled, if checked (JWST mode) hide the controls that are not applicable.
        Otherwise, show them.
        """
        if checked:
            self.pupil_toggle_button.setText("JWST")
            self.num_vanes_label.hide()
            self.num_vanes_spin.hide()
            self.vane_width_label.hide()
            self.vane_width_spin.hide()
            self.obstruction_label.hide()
            self.obstruction_spin.hide()
            # Optionally, you might hide the pupil radius control as well if fixed.
            self.radius_spin.hide()
        else:
            self.pupil_toggle_button.setText("Circular")
            self.num_vanes_label.show()
            self.num_vanes_spin.show()
            self.vane_width_label.show()
            self.vane_width_spin.show()
            self.obstruction_label.show()
            self.obstruction_spin.show()
            self.radius_spin.show()

    def _show_advanced_options(self):
        """Opens a popup dialog for advanced options."""
        dialog = AdvancedOptionsDialog(parent=self, initial_values=self.advanced_params)
        if dialog.exec() == QDialog.DialogCode.Accepted:
            self.advanced_params = dialog.get_values()
            print("Advanced parameters updated:")
            print(self.advanced_params)


    def _show_aperture_help(self):
        """Opens a help window to display the aperture/PSF example image."""
        try:
            # Replace 'aperture_path' with your actual file path for the help image.
            help_dialog = ApertureHelpWindow(aperture_path, parent=self)
            help_dialog.show()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to open help image: {e}")


    # --------------------------- Primary logic ---------------------------
    def _run_spikes(self):
        """
        Main entry point to run star detection & add spikes.
        """
        self.status_label.setText("Loading active image...")
        QApplication.processEvents()
        blur_sigma = self.blur_sigma_spin.value()
        # 1) Get the active image array + metadata from image_manager
        image_data, metadata = self.image_manager.get_current_image_and_metadata()
        if image_data is None or image_data.size == 0:
            QMessageBox.warning(self, "No Image", "No image found in the active slot!")
            return

        # Convert to float32 if needed
        self._image_data = image_data.astype(np.float32)
        # If RGBA, strip alpha
        if self._image_data.ndim == 3 and self._image_data.shape[2] == 4:
            self._image_data = self._image_data[..., :3]

        # 2) Gather user params from spinboxes
        num_vanes   = self.num_vanes_spin.value
        obstruction = self.obstruction_spin.value()
        radius      = self.radius_spin.value()
        vane_width  = self.vane_width_spin.value()
        rotation     = self.rotation_spin.value()  # New: rotation angle in degrees
        detect_thresh= self.advanced_params.get('detect_thresh', 5.0)
        flux_min     = self.flux_min_spin.value()
        flux_max   = self.advanced_params.get('flux_max', 300.0)
        bscale_min = self.advanced_params.get('bscale_min', 10.0)
        bscale_max = self.advanced_params.get('bscale_max', 30.0)
        shrink_min = self.advanced_params.get('shrink_min', 1.0)
        shrink_max = self.advanced_params.get('shrink_max', 5.0)
        color_boost = self.color_boost_spin.value()

        # 3) "un-stretch" with midtones(0.95)
        if self._image_data.ndim == 3:
            # apply midtones to each channel
            lin_img = self._image_data.copy()
            for c in range(3):
                lin_img[..., c] = self._midtones_m(lin_img[..., c], 0.95)
            base_for_detect = 0.2126*lin_img[...,0] + 0.7152*lin_img[...,1] + 0.0722*lin_img[...,2]
        else:
            lin_img = self._midtones_m(self._image_data, 0.95)
            base_for_detect = lin_img

        # 4) detect stars
        self.status_label.setText("Detecting stars...")
        QApplication.processEvents()
        stars = self._detect_stars(base_for_detect, detect_thresh, flux_min, 1.0)
        self.status_label.setText(f"Detected {len(stars)} stars.")
        QApplication.processEvents()
        if len(stars) == 0:
            QMessageBox.information(self, "No Stars", "No stars found above flux_min.")
            return

        # 5) build a single pupil for all
        self.status_label.setText("Building pupil and PSFs...")
        QApplication.processEvents()
        big_pupil = self._make_pupil(size=1024, radius=radius,
                                      obstruction=obstruction,
                                      vane_width=vane_width,
                                      num_vanes=num_vanes,
                                      rotation=rotation) 
        psf_r = self._simulate_psf(big_pupil, wavelength_scale=1.15, blur_sigma=blur_sigma)
        psf_g = self._simulate_psf(big_pupil, wavelength_scale=1.0, blur_sigma=blur_sigma)
        psf_b = self._simulate_psf(big_pupil, wavelength_scale=0.85, blur_sigma=blur_sigma)


        # 6) Multi-thread star overlay
        self.status_label.setText("Generating star overlay...")
        if lin_img.ndim == 3:
            H, W, _ = lin_img.shape
        else:
            H, W = lin_img.shape
        canvas = np.zeros((H, W, 3), dtype=np.float32)

        from concurrent.futures import ThreadPoolExecutor, as_completed
        total = len(stars)
        self.progress_bar.setValue(0)
        next_update = 0.05

        def star_runner(i):
            x, y, flux, a, b = stars[i]
            brightness = np.clip(np.log1p(flux)/8.0, 0.1, 3.0)
            tile_size  = int(256 + brightness*20)
            tile_size  = min(tile_size, 768)
            tile_size += tile_size % 2
            pad = tile_size // 2
            if not (pad <= x < W - pad and pad <= y < H - pad):
                return None

            # Extract & scale
            # measure star color from original image (the "lin_img" or maybe the raw image_data)
            r_ratio, g_ratio, b_ratio = self.measure_star_color(self._image_data, x, y, sampling_radius=3)

            # Then incorporate that ratio
            tile_r = self._extract_center_tile(psf_r, tile_size) * brightness * r_ratio
            tile_g = self._extract_center_tile(psf_g, tile_size) * brightness * g_ratio
            tile_b = self._extract_center_tile(psf_b, tile_size) * brightness * b_ratio

            # Then your existing color_boost if you want a global multiplier
            tile_r *= color_boost
            tile_g *= color_boost
            tile_b *= color_boost


            # flux-based final scale
            b_scale, s_factor = self._compute_boost_and_shrink_from_flux(
                flux, 1.0, flux_max, bscale_min, bscale_max, shrink_min, shrink_max
            )
            final_r = self._shrink_and_boost(tile_r, brightness_scale=b_scale, shrink_factor=s_factor)
            final_g = self._shrink_and_boost(tile_g, brightness_scale=b_scale, shrink_factor=s_factor)
            final_b = self._shrink_and_boost(tile_b, brightness_scale=b_scale, shrink_factor=s_factor)

            new_size = final_r.shape[0]
            pad_new  = new_size // 2
            y0, y1   = y - pad_new, y - pad_new + new_size
            x0, x1   = x - pad_new, x - pad_new + new_size
            if (y0 < 0 or y1 > H or x0 < 0 or x1 > W):
                return None

            part = np.zeros((H, W, 3), dtype=np.float32)
            part[y0:y1, x0:x1, 0] = final_r
            part[y0:y1, x0:x1, 1] = final_g
            part[y0:y1, x0:x1, 2] = final_b
            return part

        with ThreadPoolExecutor() as exec_:
            futures = {exec_.submit(star_runner, i): i for i in range(total)}
            for idx, fut in enumerate(as_completed(futures)):
                partial = fut.result()
                if partial is not None:
                    canvas += partial
                pct = (idx + 1) / total
                if pct >= next_update:
                    self.progress_bar.setValue(int(pct * 100))
                    next_update += 0.05

        # 7) combine with lin_img
        self.status_label.setText("Combining star overlay with original image...")
        if lin_img.ndim == 3:
            spiked_lin = np.clip(lin_img + canvas, 0, 1)
        else:
            # If the input is mono but the spikes are RGB, convert spikes to mono before adding
            spikes_mono = 0.2126 * canvas[..., 0] + 0.7152 * canvas[..., 1] + 0.0722 * canvas[..., 2]
            spiked_lin = np.clip(lin_img + spikes_mono, 0, 1)

        # 8) re-stretch with midtones(0.05)
        final = np.zeros_like(spiked_lin)
        if spiked_lin.ndim == 3:
            for c in range(3):
                final[..., c] = self._midtones_m(spiked_lin[..., c], 0.05)
        else:
            final = self._midtones_m(spiked_lin, 0.05)

        # ─── 9) If there’s an active mask, blend final with original ───────────
        applied_mask = self.mask_manager.get_applied_mask()
        if applied_mask is not None:
            # 1) Check dimensions
            h, w = self._image_data.shape[:2]
            if applied_mask.shape[:2] != (h, w):
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the image.")
                return

            # 2) Normalize mask to float [0,1]
            if applied_mask.dtype not in (np.float32, np.float64):
                applied_mask = applied_mask.astype(np.float32) / 255.0
            applied_mask = np.clip(applied_mask, 0.0, 1.0)

            # 3) Expand 2D mask to 3 channels if needed
            if final.ndim == 3 and applied_mask.ndim == 2:
                mask_3c = applied_mask[..., None]
            else:
                mask_3c = applied_mask

            # 4) Blend: keep original where mask==1, use spiked final where mask==0
            blended = final * (mask_3c) + self._image_data * (1.0 - mask_3c)
            final = np.clip(blended, 0.0, 1.0)

        self.final_image = final   
        self.save_button.setEnabled(True)
        self.progress_bar.setValue(100)
        self.status_label.setText("Star spike generation completed.")
        self._preview_spiked_image()

    def _preview_spiked_image(self):
        if self.final_image is None:
            return

        # create and display the preview
        preview = StarSpikePreviewWindow(parent=self, image_manager=self.image_manager)
        preview.update_image(self.final_image)
        preview.show()

    def _save_to_slot(self):
        if self.final_image is None:
            QMessageBox.warning(self, "No Output", "Please run spikes first.")
            return

        # 1) Let the user pick which slot to save into
        slot_idx, ok = QInputDialog.getInt(
            self,
            "Save to Slot",
            f"Enter slot number (0..{self.image_manager.max_slots-1}):",
            self.image_manager.current_slot,  # default
            0,                                # min
            self.image_manager.max_slots-1,   # max
            1                                 # step
        )
        if not ok:
            return  # user canceled

        # 2) Build metadata
        new_metadata = {
            "description": "Star-Spiked",
            "is_float": True  # or any other flags you want
        }

        # 3) Save the final image to the chosen slot
        self.image_manager.set_image_for_slot(slot_idx, self.final_image, new_metadata, step_name="Star Spike Tool")

        print(f"Spiked image saved to slot {slot_idx}.")
        self.close()



    # ---------------------- Helper Methods as Private ----------------------

    def _midtones_m(self, x, m):
        """Encapsulated midtones code inside the class."""
        x = np.clip(x, 0.0, 1.0).astype(np.float32)
        out = np.zeros_like(x, dtype=np.float32)
        mask0 = (x == 0)
        out[mask0] = 0.0
        mask1 = (x == 1)
        out[mask1] = 1.0
        eps = 1e-7
        maskm = (np.abs(x - m) < eps)
        out[maskm] = 0.5
        mask_oth = ~(mask0 | mask1 | maskm)
        xm = x[mask_oth]
        num = (m - 1.0)*xm
        den = (2.0*m - 1.0)*xm - m
        out[mask_oth] = np.clip(num/(den+1e-12),0,1)
        return out

    def _make_pupil(self, size=512, radius=100, obstruction=0.3, vane_width=2, num_vanes=4, rotation=0):
        """
        Creates a pupil (aperture mask) based on the selected pupil type.
        If the pupil_type_slider value is >= 50, uses the JWST pupil.
        Otherwise, generates a standard circular pupil with diffraction vanes.
        The 'rotation' argument rotates the vane pattern.
        """
        # Use the slider value instead of a checkbox.
        if self.pupil_toggle_button.isChecked():
            # JWST pupil from a PNG
            return self._load_pupil_from_png(jwstpupil_path, size=size, rotation=rotation)
        else:
            # Build a standard circular pupil.
            y, x = np.indices((size, size)) - size // 2
            r = np.sqrt(x**2 + y**2)
            pupil = (r <= radius).astype(np.float32)
            pupil[r < radius * obstruction] = 0.0
            if num_vanes >= 2:
                rotation_radians = np.deg2rad(rotation)
                for angle in np.linspace(0, np.pi, num_vanes, endpoint=False) + rotation_radians:
                    xp = x * np.cos(angle) + y * np.sin(angle)
                    vane = np.abs(xp) < vane_width
                    pupil[vane] = 0.0
            return pupil

    def _load_pupil_from_png(self, filepath, size=1024, rotation=0.0):
        """
        Loads a JWST pupil mask from a PNG file using OpenCV.

        Args:
            filepath (str): The path to the JWST pupil PNG file.
            size (int): The desired output size (size x size).
            rotation (float): Rotation angle in degrees. Positive values rotate counterclockwise.

        Returns:
            np.ndarray: A (size x size) float32 array with values normalized to [0, 1].
        """
        # Load the image in grayscale
        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError(f"Failed to load image from {filepath}")
        
        # Normalize to [0, 1] (assuming white = open, black = blocked)
        img = img.astype(np.float32) / 255.0

        # Resize if necessary
        if img.shape != (size, size):
            img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)
        
        # Apply rotation if needed
        if abs(rotation) > 1e-3:
            center = (size // 2, size // 2)
            # Get the rotation matrix. Note that cv2.getRotationMatrix2D expects rotation in degrees.
            M = cv2.getRotationMatrix2D(center, rotation, 1.0)
            img = cv2.warpAffine(img, M, (size, size), flags=cv2.INTER_LINEAR,
                                borderMode=cv2.BORDER_CONSTANT, borderValue=0)
        
        return img


    def _simulate_psf(self, pupil, wavelength_scale=1.0, blur_sigma=1.0):
        # Apply a Gaussian blur to the pupil to simulate wavelength-dependent phase variations.
        scaled_pupil = gaussian_filter(pupil, sigma=0.1 * wavelength_scale)
        # Compute Fourier transform to get the raw diffraction pattern.
        fft = np.fft.fftshift(np.fft.fft2(np.fft.ifftshift(scaled_pupil)))
        intensity = np.abs(fft)**2
        intensity /= (intensity.max() + 1e-8)
        # Apply a second Gaussian filter (blur_sigma) to simulate additional spreading.
        blurred = gaussian_filter(intensity, sigma=blur_sigma)
        psf = blurred / max(blurred.max(), 1e-8)
        
        # **New step:** Scale the spatial dimensions of the PSF.
        # Here, a lower wavelength_scale (e.g. for blue) produces a smaller PSF.
        # If wavelength_scale=1.0 is our nominal size, then for a channel with
        # wavelength_scale < 1.0 the PSF should be smaller, and vice versa.
        zoom_factor = wavelength_scale   # Adjust this mapping as needed.
        if zoom_factor != 1.0:
            psf = ndi.zoom(psf, zoom=zoom_factor, order=1)
            psf /= psf.max()  # Re-normalize after zooming.
        return psf

    def _extract_center_tile(self, psf, tile_size):
        center = psf.shape[0]//2
        half   = tile_size//2
        y0, x0 = max(0, center-half), max(0, center-half)
        y1, x1 = y0+tile_size, x0+tile_size
        cropped= psf[y0:y1, x0:x1]
        if cropped.shape != (tile_size, tile_size):
            padded = np.zeros((tile_size,tile_size), dtype=np.float32)
            ph, pw = cropped.shape
            padded[:ph, :pw]= cropped
            return padded
        return cropped

    def _detect_stars(self, image, threshold=5.0, flux_min=30.0, size_min=1.0):
        data = image.astype(np.float32)
        bkg = sep.Background(data)
        data_sub = data - bkg.back()
        err_val = bkg.globalrms

        try:
            objects = sep.extract(data_sub, threshold, err=err_val)
        except Exception as e:
            if "internal pixel buffer full" in str(e):
                print("[ERROR] Star detection failed: internal pixel buffer full.")
                QMessageBox.warning(
                    self,
                    "Star Detection Failed",
                    "Star detection failed because the internal pixel buffer was exceeded.\n\n"
                    "Try increasing the detection threshold (sigma) or the minimum flux."
                )
            else:
                print(f"[ERROR] Star detection failed: {e}")
                QMessageBox.critical(
                    self,
                    "Unexpected Error",
                    f"An unexpected error occurred during star detection:\n\n{e}"
                )
            return []

        star_list = []
        for obj in objects:
            flux = obj['flux']
            a = obj['a']
            b = obj['b']
            star_size = max(a, b)
            if flux >= flux_min and star_size >= size_min:
                star_list.append((int(obj['x']), int(obj['y']), flux, a, b))
        return star_list

    def _shrink_and_boost(self, tile, brightness_scale=2.0, shrink_factor=1.5):
        tile = tile*brightness_scale
        tile = np.clip(tile, 0.0, 1.0)
        in_size = tile.shape[0]
        out_size= int(in_size//shrink_factor)
        out_size+= out_size%2
        zoom_factor= out_size/float(in_size)
        smaller= ndi.zoom(tile, zoom_factor, order=1)
        return np.clip(smaller, 0.0,1.0)

    def _compute_boost_and_shrink_from_flux(self,
                                            flux, flux_min, flux_max,
                                            bscale_min, bscale_max,
                                            shrink_min,shrink_max):
        flux_c= np.clip(flux, flux_min, flux_max)
        alpha = 0.0
        if flux_max>flux_min:
            alpha= (flux_c - flux_min)/(flux_max - flux_min)
        brightness_scale= bscale_min + alpha*(bscale_max - bscale_min)
        # invert for shrink => bigger flux => smaller factor
        factor= shrink_max - alpha*(shrink_max - shrink_min)
        return brightness_scale, factor

    def measure_star_color(self, img_color, x, y, sampling_radius=20):
        """
        Measures star color at (x, y) and returns ratios where the brightest channel is 1.0.
        """
        if img_color.ndim == 2:
            print(f"[DEBUG] Mono image at ({x:.1f}, {y:.1f}) – returning white")
            return (1.0, 1.0, 1.0)

        H, W, C = img_color.shape
        if C != 3:
            return (1.0, 1.0, 1.0)

        x0 = max(0, int(x - sampling_radius))
        x1 = min(W, int(x + sampling_radius + 1))
        y0 = max(0, int(y - sampling_radius))
        y1 = min(H, int(y + sampling_radius + 1))

        if x1 <= x0 or y1 <= y0:
            return (1.0, 1.0, 1.0)

        patch = img_color[y0:y1, x0:x1, :]
        mean_col = np.mean(patch, axis=(0, 1))  # shape (3,)
        max_col = np.max(mean_col)

        if max_col < 1e-9:
            return (1.0, 1.0, 1.0)

        r_ratio = mean_col[0] / max_col
        g_ratio = mean_col[1] / max_col
        b_ratio = mean_col[2] / max_col

        return (r_ratio, g_ratio, b_ratio)

def aperture_sum(image: np.ndarray, x: float, y: float, radius: float) -> float:
    """
    Sum pixel values within a circular aperture.

    Parameters
    ----------
    image : 2D numpy array
        Grayscale image (H×W).
    x, y : float
        Subpixel center of aperture (in image coordinates).
    radius : float
        Radius of aperture in pixels.

    Returns
    -------
    float
        Sum of image pixels whose centers are within radius of (x,y).
    """
    H, W = image.shape[:2]
    # Define integer bounds for the square containing the circle
    x0 = max(int(np.floor(x - radius)), 0)
    x1 = min(int(np.ceil (x + radius)), W - 1)
    y0 = max(int(np.floor(y - radius)), 0)
    y1 = min(int(np.ceil (y + radius)), H - 1)

    # Create a grid of coordinates within that box
    yy, xx = np.ogrid[y0:y1+1, x0:x1+1]
    dist2 = (yy - y)**2 + (xx - x)**2

    # Mask of points inside the circle
    mask = dist2 <= (radius**2)

    # Extract the sub-image and sum only the masked points
    sub = image[y0:y1+1, x0:x1+1]
    return float(np.sum(sub[mask]))

class OverlayView(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        # disable built-in hand drag
        self.setDragMode(QGraphicsView.DragMode.NoDrag)
        # always arrow cursor
        self.viewport().setCursor(Qt.CursorShape.ArrowCursor)
        self._panning = False
        self._last_pos = QPoint()

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            scene_pt = self.mapToScene(event.pos())
            # if we clicked an ellipse, let it handle the event
            for it in self.scene().items(scene_pt):
                if isinstance(it, ClickableEllipseItem):
                    super().mousePressEvent(event)
                    return
            # else: start panning
            self._panning = True
            self._last_pos = event.pos()
            event.accept()
            return
        super().mousePressEvent(event)

    def mouseMoveEvent(self, event):
        if self._panning:
            delta = event.pos() - self._last_pos
            self._last_pos = event.pos()
            self.horizontalScrollBar().setValue(self.horizontalScrollBar().value() - delta.x())
            self.verticalScrollBar().setValue(self.verticalScrollBar().value() - delta.y())
            event.accept()
            return
        super().mouseMoveEvent(event)

    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton and self._panning:
            self._panning = False
            event.accept()
            return
        super().mouseReleaseEvent(event)

class ClickableEllipseItem(QGraphicsEllipseItem):
    def __init__(self, rect: QRectF, index: int, callback):
        super().__init__(rect)
        self.index = index
        self.callback = callback
        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton)
        self.setAcceptHoverEvents(True)

    def mousePressEvent(self, ev):
        if ev.button() == Qt.MouseButton.LeftButton:
            shift = bool(ev.modifiers() & Qt.KeyboardModifier.ShiftModifier)
            self.callback(self.index, shift)
        super().mousePressEvent(ev)


class ReferenceOverlayDialog(QDialog):
    def __init__(self, plane: np.ndarray, positions: List[Tuple], target_median: float, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Reference Frame: Stars Overlay")
        self.plane = plane.astype(np.float32)
        self.positions = positions
        self.target_median = target_median
        self.autostretch = True

        # pens for normal vs selected
        self._normal_pen   = QPen(QColor('lightblue'), 3)  # for normal state
        self._dip_pen      = QPen(QColor('yellow'),    3)  # flagged by threshold
        self._selected_pen = QPen(QColor('red'),       4)  # when selected

        # store ellipses here
        self.ellipse_items: dict[int, ClickableEllipseItem] = {}
        self.flagged_stars: Set[int] = set()  # updated by apply_threshold

        self._build_ui()
        self._init_graphics()

        # wire up list‐clicks in the parent to recolor
        if parent and hasattr(parent, 'star_list'):
            parent.star_list.itemSelectionChanged.connect(self._update_highlights)

        # after show, reset zoom so 1px == 1screen-px
        QTimer.singleShot(0, self._fit_to_100pct)

    def _build_ui(self):
        self.view = OverlayView(self)
        self.view.setRenderHints(
            QPainter.RenderHint.Antialiasing |
            QPainter.RenderHint.SmoothPixmapTransform
        )
        self.scene = QGraphicsScene(self)
        self.view.setScene(self.scene)

        btns = QHBoxLayout()
        for txt, slot in [
            ("Zoom In",        lambda: self.view.scale(1.2, 1.2)),
            ("Zoom Out",       lambda: self.view.scale(1/1.2, 1/1.2)),
            ("Reset Zoom",     self._fit_to_100pct),
            ("Fit to Window",  self._fit_to_window),
            ("Toggle Stretch", self._toggle_autostretch),
        ]:
            b = QPushButton(txt)
            b.clicked.connect(slot)
            btns.addWidget(b)
        btns.addStretch()

        lay = QVBoxLayout(self)
        lay.addWidget(self.view)
        lay.addLayout(btns)
        self.resize(800, 600)

    def _init_graphics(self):
        # draw the image...
        img = self.plane if not self.autostretch else stretch_mono_image(self.plane, target_median=0.3)
        arr8 = (np.clip(img,0,1) * 255).astype(np.uint8)
        h, w = img.shape
        qimg = QImage(arr8.data, w, h, w, QImage.Format.Format_Grayscale8)
        pix  = QPixmap.fromImage(qimg)

        self.scene.clear()
        self.ellipse_items.clear()
        self.scene.addItem(QGraphicsPixmapItem(pix))

        # add one ellipse per star
        radius = max(2, int(math.ceil(1.2*self.target_median)))
        for idx, (x, y) in enumerate(self.positions):
            r = QRectF(x-radius, y-radius, 2*radius, 2*radius)
            ell = ClickableEllipseItem(r, idx, self._on_star_clicked)
            ell.setPen(self._normal_pen)
            ell.setBrush(QBrush(Qt.BrushStyle.NoBrush))
            self.scene.addItem(ell)
            self.ellipse_items[idx] = ell

    def _fit_to_100pct(self):
        self.view.resetTransform()
        rect = self.scene.itemsBoundingRect()
        self.view.setSceneRect(rect)
        # scroll so that scene center ends up in the view’s center
        self.view.centerOn(rect.center())

    def _fit_to_window(self):
        rect = self.scene.itemsBoundingRect()
        self.view.fitInView(rect, Qt.AspectRatioMode.KeepAspectRatio)

    def _toggle_autostretch(self):
        self.autostretch = not self.autostretch
        self._init_graphics()

    def _on_star_clicked(self, index: int, shift: bool):
        """Star‐circle was clicked; update list selection then recolor."""
        parent = self.parent()
        if not parent or not hasattr(parent, 'star_list'):
            return

        lst = parent.star_list
        item = lst.item(index)
        if not item:
            return

        if shift:
            item.setSelected(not item.isSelected())
        else:
            lst.clearSelection()
            item.setSelected(True)

        lst.scrollToItem(item)
        self._update_highlights()

    def _update_highlights(self):
        """Recolor all ellipses according to star_list selection and dip flags."""
        parent = self.parent()
        if not parent or not hasattr(parent, 'star_list'):
            return

        sel = {item.data(Qt.ItemDataRole.UserRole)
            for item in parent.star_list.selectedItems()}
        
        for idx, ell in self.ellipse_items.items():
            if idx in sel:
                ell.setPen(self._selected_pen)
            elif idx in self.flagged_stars:
                ell.setPen(self._dip_pen)
            else:
                ell.setPen(self._normal_pen)

    def update_dip_flags(self, flagged_indices: Set[int]):
        """Update the visual color of stars flagged by threshold dips."""
        self.flagged_stars = flagged_indices
        self._update_highlights()


class ExoPlanetWindow(QDialog):
    referenceSelected = pyqtSignal(str)
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Exoplanet Transit Detector")
        self.resize(900, 600)

        # State
        self.image_paths    = []
        self._cached_images = []
        self._cached_headers = []   # parallel to _cached_images
        self.times = None           # will become a 1D array of astropy Time        
        self.star_positions = []
        self.fluxes         = None   # stars × frames
        self.flags          = None
        self.median_fwhm    = None
        self.master_dark    = None
        self.master_flat    = None
        self.exposure_time = None
        self._last_ensemble = []
        # ------------ new settings ------------
        # SEP detection threshold in σ
        self.sep_threshold  = 5.0
        # fraction of image border to ignore [0–0.5]
        self.border_fraction = 0.10
        # number of companion stars in ensemble model
        self.ensemble_k          = 10

        # ——— Analysis settings ——————————————————
        self.ls_min_frequency     = 0.01
        self.ls_max_frequency     = 10.0
        self.ls_samples_per_peak  = 10

        self.bls_min_period       = 0.05
        self.bls_max_period       = 2.0
        self.bls_n_periods        = 1000
        self.bls_duration_min_frac= 0.01
        self.bls_duration_max_frac= 0.5
        self.bls_n_durations      = 20
        # ------------------------------------------   

        # — WCS coordinates —
        self.wcs_ra = None
        self.wcs_dec = None

        # — Mode selector —
        mode_layout = QHBoxLayout()
        mode_layout.addWidget(QLabel("Mode:"))
        self.aligned_mode_rb = QRadioButton("Aligned Subs")
        self.raw_mode_rb     = QRadioButton("Raw Subs")
        self.aligned_mode_rb.setChecked(True)
        mg = QButtonGroup(self)
        mg.addButton(self.aligned_mode_rb); mg.addButton(self.raw_mode_rb)
        mg.buttonToggled.connect(self.on_mode_changed)
        mode_layout.addWidget(self.aligned_mode_rb)
        mode_layout.addWidget(self.raw_mode_rb)
        mode_layout.addStretch()
        self.wrench_button = QToolButton()
        self.wrench_button.setIcon(QIcon(wrench_path))
        self.wrench_button.setToolTip("Settings…")
        self.wrench_button.setStyleSheet("""
            QToolButton {
                background-color: #FF4500;
                color: white;
                padding: 4px;
                border-radius: 4px;
            }
            QToolButton:hover {
                background-color: #FF6347;
            }
        """)
        self.wrench_button.clicked.connect(self.open_settings)    
        mode_layout.addWidget(self.wrench_button)    

        # — Calibration controls (hidden in Aligned) —
        cal_layout = QHBoxLayout()
        self.load_darks_btn = QPushButton("Load Master Dark…")
        self.load_flats_btn = QPushButton("Load Master Flat…")
        for w in (self.load_darks_btn, self.load_flats_btn):
            w.clicked.connect(self.load_masters)
            w.hide()
            cal_layout.addWidget(w)
        self.dark_status_label = QLabel("Dark: ❌");  self.dark_status_label.hide()
        self.flat_status_label = QLabel("Flat: ❌");  self.flat_status_label.hide()
        cal_layout.addWidget(self.dark_status_label)
        cal_layout.addWidget(self.flat_status_label)
        cal_layout.addStretch()

        # — Status & Progress —
        self.status_label = QLabel("Ready")
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)

        # — Top controls: load vs measure —
        top_layout = QHBoxLayout()
        self.load_raw_btn     = QPushButton("1: Load Raw Subs…")
        self.load_aligned_btn = QPushButton("Load, Measure && Photometry…")
        self.calibrate_btn       = QPushButton("1a: Calibrate && Align Subs")
        self.measure_btn      = QPushButton("2: Measure && Photometry")
        self.load_raw_btn.    clicked.connect(self.load_raw_subs)
        self.load_aligned_btn.clicked.connect(self.load_and_measure_subs)
        self.calibrate_btn.clicked.connect(self.calibrate_and_align)
        self.measure_btn.     clicked.connect(self.detect_stars)
        self.detrend_combo = QComboBox()
        self.detrend_combo.addItems(["No Detrend", "Linear", "Quadratic"])
        self.save_aligned_btn = QPushButton("Save Aligned Frames…")
        self.save_aligned_btn.clicked.connect(self.save_aligned_frames)
       
        
        top_layout.addWidget(self.load_raw_btn)
        top_layout.addWidget(self.load_aligned_btn)
        top_layout.addWidget(self.calibrate_btn)
        top_layout.addWidget(self.measure_btn)
        top_layout.addStretch()
        top_layout.addWidget(QLabel("Detrend:"))
        top_layout.addWidget(self.detrend_combo)
        top_layout.addWidget(self.save_aligned_btn)        

        # — Star list & Plot —
        middle = QHBoxLayout()
        self.star_list  = QListWidget()
        self.star_list.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)
        self.star_list.itemSelectionChanged.connect(self.update_plot_for_selection)
        self.star_list.setStyleSheet("""
            QListWidget::item:selected {
                background: #3399ff; 
                color: white;
            }
        """)
        middle.addWidget(self.star_list, 2)
        self.plot_widget = pg.PlotWidget(title="Light Curves")
        self.plot_widget.addLegend()
        middle.addWidget(self.plot_widget, 5)

        # — Bottom: export & threshold —
        row1 = QHBoxLayout()
        row1.addWidget(QLabel("Dip threshold (ppt):"))

        # slider
        self.threshold_slider = QSlider(Qt.Orientation.Horizontal)
        self.threshold_slider.setRange(0, 100)
        self.threshold_slider.setValue(20)
        row1.addWidget(self.threshold_slider)

        # dynamically-updated label
        self.threshold_value_label = QLabel(f"{self.threshold_slider.value()} ppt")
        row1.addWidget(self.threshold_value_label)

        row1.addStretch()

        # detrend combo, export button, etc.
        self.identify_btn = QPushButton("Identify Star…")
        self.identify_btn.clicked.connect(self.on_identify_star)
        row1.addWidget(self.identify_btn)
    
        self.show_ensemble_btn = QPushButton("Show Ensemble Members")
        self.show_ensemble_btn.clicked.connect(self.show_ensemble_members)
        row1.addWidget(self.show_ensemble_btn)

        self.analyze_btn = QPushButton("Analyze Star…")
        self.analyze_btn.clicked.connect(self.on_analyze)
        row1.addWidget(self.analyze_btn)

        row2 = QHBoxLayout()
        self.fetch_tesscut_btn = QPushButton("Query TESScut Light Curve")
        self.fetch_tesscut_btn.setEnabled(False)
        self.fetch_tesscut_btn.clicked.connect(self.query_tesscut)
        row2.addWidget(self.fetch_tesscut_btn)
        self.export_btn = QPushButton("Export CSV/FITS")
        self.export_btn.clicked.connect(self.export_data)
        row2.addWidget(self.export_btn)
        self.export_aavso_btn = QPushButton("Export → AAVSO")
        self.export_aavso_btn.clicked.connect(self.export_to_aavso)
        row2.addWidget(self.export_aavso_btn)

        # — Assemble —
        main = QVBoxLayout(self)
        main.addLayout(mode_layout)
        main.addLayout(cal_layout)
        main.addLayout(top_layout)
        main.addLayout(middle)
        main.addLayout(row1)
        main.addLayout(row2)
        # status at very bottom
        statlay = QHBoxLayout()
        statlay.addWidget(self.status_label)
        statlay.addWidget(self.progress_bar)
        main.addLayout(statlay)

        # initialize
        self.on_mode_changed(self.aligned_mode_rb, True)
        self.detrend_combo.setCurrentIndex(2)
        # And in case setCurrentIndex doesn’t auto‐fire, call it manually:
        self.on_detrend_changed(2)
        self.threshold_slider.valueChanged.connect(self._on_threshold_changed)
        self.analyze_btn.setEnabled(False)
        self.calibrate_btn.hide()

    def _on_threshold_changed(self, v: int):
        # update the little “20 ppt” label
        self.threshold_value_label.setText(f"{v} ppt")
        # now re-apply your dip-detection
        self.apply_threshold(v)
        if hasattr(self, '_ref_overlay'):
            self._ref_overlay._update_highlights()      

    def open_settings(self):
        dlg = QDialog(self)
        dlg.setWindowTitle("Photometry & Analysis Settings")
        layout = QVBoxLayout(dlg)

        # — Photometry settings —
        photo_box = QGroupBox("Photometry")
        fb = QFormLayout(photo_box)
        self.sep_spin = QDoubleSpinBox()
        self.sep_spin.setRange(1.0, 20.0)
        self.sep_spin.setSingleStep(0.5)
        self.sep_spin.setValue(self.sep_threshold)
        fb.addRow("SEP detection σ:", self.sep_spin)

        self.border_spin = QDoubleSpinBox()
        self.border_spin.setRange(0.0, 0.5)
        self.border_spin.setSingleStep(0.01)
        self.border_spin.setValue(self.border_fraction)
        fb.addRow("Border fraction:", self.border_spin)
        layout.addWidget(photo_box)

        ens_box = QGroupBox("Ensemble Normalization")
        ef = QFormLayout(ens_box)
        self.ensemble_spin = QSpinBox()
        self.ensemble_spin.setRange(1, 50)
        self.ensemble_spin.setValue(self.ensemble_k)
        ef.addRow("Comparison stars (k):", self.ensemble_spin)
        layout.addWidget(ens_box)

        # — Analysis settings —  
        ana_box = QGroupBox("Analysis (period search)")
        form = QFormLayout(ana_box)

        # LS samples-per-peak only
        self.ls_samp_spin = QSpinBox()
        self.ls_samp_spin.setRange(1, 100)
        self.ls_samp_spin.setValue(self.ls_samples_per_peak)
        form.addRow("LS samples / peak:", self.ls_samp_spin)

        # BLS min/max period
        self.bls_min_spin = QDoubleSpinBox(); self.bls_min_spin.setRange(0.01, 10.0)
        self.bls_min_spin.setValue(self.bls_min_period)
        form.addRow("BLS min period [d]:", self.bls_min_spin)

        self.bls_max_spin = QDoubleSpinBox(); self.bls_max_spin.setRange(0.01, 10.0)
        self.bls_max_spin.setValue(self.bls_max_period)
        form.addRow("BLS max period [d]:", self.bls_max_spin)

        # BLS # periods
        self.bls_nper_spin = QSpinBox()
        self.bls_nper_spin.setRange(10, 20000)
        self.bls_nper_spin.setValue(self.bls_n_periods)
        form.addRow("BLS # periods:", self.bls_nper_spin)

        # BLS min/max duration fraction
        self.bls_min_frac_spin = QDoubleSpinBox()
        self.bls_min_frac_spin.setRange(0.0001, 1.0)
        self.bls_min_frac_spin.setSingleStep(0.001)
        self.bls_min_frac_spin.setValue(self.bls_duration_min_frac)
        form.addRow("BLS min dur frac:", self.bls_min_frac_spin)

        self.bls_max_frac_spin = QDoubleSpinBox()
        self.bls_max_frac_spin.setRange(0.01, 1.0)
        self.bls_max_frac_spin.setSingleStep(0.01)
        self.bls_max_frac_spin.setValue(self.bls_duration_max_frac)
        form.addRow("BLS max dur frac:", self.bls_max_frac_spin)

        # BLS # durations
        self.bls_ndur_spin = QSpinBox()
        self.bls_ndur_spin.setRange(1, 200)
        self.bls_ndur_spin.setValue(self.bls_n_durations)
        form.addRow("BLS # durations:", self.bls_ndur_spin)


        layout.addWidget(ana_box)

        # OK/Cancel
        btns = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok |
            QDialogButtonBox.StandardButton.Cancel
        )
        btns.accepted.connect(dlg.accept)
        btns.rejected.connect(dlg.reject)
        layout.addWidget(btns)

        if dlg.exec() == QDialog.DialogCode.Accepted:
            # Photometry
            self.sep_threshold   = self.sep_spin.value()
            self.border_fraction = self.border_spin.value()
            self.ensemble_k          = self.ensemble_spin.value()

            # Lomb–Scargle
            self.ls_samples_per_peak = self.ls_samp_spin.value()

            # Box–Least–Squares
            self.bls_min_period        = self.bls_min_spin.value()
            self.bls_max_period        = self.bls_max_spin.value()
            self.bls_n_periods         = self.bls_nper_spin.value()
            self.bls_duration_min_frac = self.bls_min_frac_spin.value()
            self.bls_duration_max_frac = self.bls_max_frac_spin.value()
            self.bls_n_durations       = self.bls_ndur_spin.value()


    def on_mode_changed(self, button, checked):
        is_raw = checked and (button is self.raw_mode_rb)

        # show/hide the Raw‐mode loaders + calibrate button
        for w in (
            self.load_raw_btn,
            self.load_darks_btn,
            self.load_flats_btn,
            self.dark_status_label,
            self.flat_status_label,
            self.calibrate_btn,
        ):
            w.setVisible(is_raw)

        # in Aligned mode only allow the aligned loader
        self.load_aligned_btn.setVisible(not is_raw)
        self.measure_btn.setVisible(is_raw)


    def load_and_measure_subs(self):
        # 1) load & sort
        self.load_aligned_subs()
        # 2) once loaded, immediately run photometry
        self.detect_stars()

    def load_raw_subs(self):
        settings = QSettings()
        start_dir = settings.value(
            "ExoPlanet/lastRawFolder",
            os.path.expanduser("~"),
            type=str
        )

        paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Select Raw Frames",
            start_dir,
            "FITS, TIFF or XISF (*.fit *.fits *.tif *.tiff *.xisf)"
        )
        if not paths:
            return

        # remember for next time
        settings.setValue("ExoPlanet/lastRawFolder", os.path.dirname(paths[0]))

        # ——— PASS 1: extract DATE-OBS & sort ———
        self.status_label.setText("Reading headers…")
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(len(paths))
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        datelist = []
        for i, p in enumerate(paths, start=1):
            ext = os.path.splitext(p)[1].lower()
            ds = None

            if ext == '.xisf':
                try:
                    xisf     = XISF(p)
                    img_meta = xisf.get_images_metadata()[0].get('FITSKeywords', {})
                    if 'DATE-OBS' in img_meta:
                        ds = img_meta['DATE-OBS'][0]['value']
                except:
                    ds = None

            elif ext in ('.fit', '.fits', '.fz'):
                try:
                    hdr0, _ = get_valid_header(p)
                    ds      = hdr0.get('DATE-OBS')
                except:
                    ds = None

            # parse into astropy Time or None
            t = None
            if isinstance(ds, str):
                try:
                    t = Time(ds, format='isot', scale='utc')
                except Exception as e:
                    print(f"[DEBUG] Failed to parse DATE-OBS for {p}: {e}")

            datelist.append((p, t))
            self.progress_bar.setValue(i)
            QApplication.processEvents()

        # sort by (has_time, time or filename)
        datelist.sort(key=lambda x: (x[1] is None, x[1] or x[0]))
        sorted_paths = [p for p, _ in datelist]

        # ——— PASS 2: load, bin, stash headers, exposure_time & airmass ———
        self.image_paths     = sorted_paths
        self._cached_images  = []
        self._cached_headers = []
        self.airmasses       = []

        # clear any old UI elements
        self.star_list.clear()
        self.plot_widget.clear()

        self.status_label.setText("Loading raw frames…")
        self.progress_bar.setMaximum(len(sorted_paths))
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        for i, p in enumerate(sorted_paths, start=1):
            self.status_label.setText(f"Loading raw frame {i}/{len(sorted_paths)}…")
            QApplication.processEvents()

            img, hdr, bit_depth, is_mono = load_image(p)
            if img is None:
                QMessageBox.warning(
                    self, "Load Error",
                    f"Failed to load raw frame:\n{os.path.basename(p)}"
                )
                self._cached_images.append(None)
                self._cached_headers.append(None)
                am = 1.0
            else:
                # bin & cache
                img_binned = bin2x2_numba(img)
                self._cached_images.append(img_binned)
                self._cached_headers.append(hdr)

                # — grab exposure_time once —
                if self.exposure_time is None:
                    if isinstance(hdr, fits.Header):
                        self.exposure_time = hdr.get('EXPOSURE',
                                                    hdr.get('EXPTIME', None))
                    elif isinstance(hdr, dict):
                        img_meta = hdr.get('image_meta', {}) or {}
                        fits_kw  = img_meta.get('FITSKeywords', {})
                        val = None
                        if 'EXPOSURE' in fits_kw:
                            val = fits_kw['EXPOSURE'][0].get('value')
                        elif 'EXPTIME' in fits_kw:
                            val = fits_kw['EXPTIME'][0].get('value')
                        try:
                            self.exposure_time = float(val)
                        except:
                            print(f"[DEBUG] Could not parse exposure_time={val!r}")
                    print(f"[DEBUG] Loaded exposure_time = {self.exposure_time}")

                # — extract airmass —
                am = None
                # 1) FITS header
                if isinstance(hdr, fits.Header):
                    if 'AIRMASS' in hdr:
                        try:
                            am = float(hdr['AIRMASS'])
                        except:
                            am = None
                    if am is None:
                        alt = (hdr.get('OBJCTALT')
                            or hdr.get('ALT')
                            or hdr.get('ALTITUDE')
                            or hdr.get('EL'))
                        try:
                            am = self.estimate_airmass_from_altitude(float(alt))
                        except:
                            am = 1.0

                # 2) XISF keywords dict
                elif isinstance(hdr, dict):
                    img_meta = hdr.get('image_meta', {}) or {}
                    fits_kw  = img_meta.get('FITSKeywords', {})
                    if 'AIRMASS' in fits_kw:
                        try:
                            am = float(fits_kw['AIRMASS'][0]['value'])
                        except:
                            am = None
                    if am is None:
                        for key in ('OBJCTALT','ALT','ALTITUDE','EL'):
                            ent = fits_kw.get(key)
                            if ent:
                                try:
                                    am = self.estimate_airmass_from_altitude(
                                        float(ent[0]['value'])
                                    )
                                    break
                                except:
                                    pass
                        else:
                            am = 1.0

                # 3) fallback
                if am is None:
                    am = 1.0

            self.airmasses.append(am)
            self.progress_bar.setValue(i)
            QApplication.processEvents()

        # ——— build time array from PASS 1 ———
        iso_strs = []
        mask_arr = []
        for _, t in datelist:
            if t is not None:
                iso_strs.append(t.isot)
                mask_arr.append(False)
            else:
                iso_strs.append('')
                mask_arr.append(True)

        ma_strs = np.ma.MaskedArray(iso_strs, mask=mask_arr)
        self.times = Time(
            ma_strs,
            format='isot',
            scale='utc',
            out_subfmt='date'
        )

        # done
        self.progress_bar.setVisible(False)
        loaded = sum(1 for im in self._cached_images if im is not None)
        self.status_label.setText(
            f"Loaded {loaded}/{len(sorted_paths)} raw frames"
        )

    def load_aligned_subs(self):
        settings = QSettings()
        start_dir = settings.value(
            "ExoPlanet/lastAlignedFolder",
            os.path.expanduser("~"),
            type=str
        )

        paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Select Aligned Frames",
            start_dir,
            "FITS or TIFF (*.fit *.fits *.tif *.tiff *.xisf)"
        )
        if not paths:
            return

        # remember for next time
        settings.setValue("ExoPlanet/lastAlignedFolder", os.path.dirname(paths[0]))

        # ——— PASS 1: read DATE-OBS & sort ———
        self.status_label.setText("Reading metadata from aligned frames…")
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(len(paths))
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        datelist = []
        for i, p in enumerate(paths, start=1):
            ext = os.path.splitext(p)[1].lower()
            ds = None

            if ext == '.xisf':
                try:
                    xisf     = XISF(p)
                    img_meta = xisf.get_images_metadata()[0]
                    kw       = img_meta.get('FITSKeywords', {})
                    if 'DATE-OBS' in kw:
                        ds = kw['DATE-OBS'][0]['value']
                except:
                    ds = None

            elif ext in ('.fit', '.fits', '.fz'):
                try:
                    hdr0, _ = get_valid_header(p)
                    ds      = hdr0.get('DATE-OBS')
                except:
                    ds = None

            # parse into astropy Time or None
            t = None
            if isinstance(ds, str):
                try:
                    t = Time(ds, format='isot', scale='utc')
                except Exception as e:
                    print(f"[DEBUG] Failed to parse DATE-OBS for {p}: {e}")

            datelist.append((p, t))
            self.progress_bar.setValue(i)
            QApplication.processEvents()

        # sort by (has_time, then time or filename)
        datelist.sort(key=lambda x: (x[1] is None, x[1] or x[0]))
        sorted_paths = [p for p, _ in datelist]

        # ——— PASS 2: load & bin & extract headers, exposure_time, airmass ———
        self.image_paths     = sorted_paths
        self._cached_images  = []
        self._cached_headers = []
        self.airmasses       = []

        self.status_label.setText("Loading aligned frames…")
        self.progress_bar.setMaximum(len(sorted_paths))
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        for i, p in enumerate(sorted_paths, start=1):
            self.status_label.setText(f"Loading frame {i}/{len(sorted_paths)}…")
            QApplication.processEvents()

            img, hdr, bit_depth, is_mono = load_image(p)
            if img is None:
                QMessageBox.warning(
                    self, "Load Error",
                    f"Failed to load aligned frame:\n{os.path.basename(p)}"
                )
                self._cached_images.append(None)
                self._cached_headers.append(None)
                am = 1.0
            else:
                # bin & cache
                img_binned = bin2x2_numba(img)
                self._cached_images.append(img_binned)
                self._cached_headers.append(hdr)

                # — extract exposure_time once —
                if self.exposure_time is None:
                    if isinstance(hdr, fits.Header):
                        self.exposure_time = hdr.get('EXPOSURE',
                                                    hdr.get('EXPTIME', None))
                    elif isinstance(hdr, dict):
                        img_meta = hdr.get('image_meta', {}) or {}
                        fits_kw  = img_meta.get('FITSKeywords', {})
                        val = None
                        if 'EXPOSURE' in fits_kw:
                            val = fits_kw['EXPOSURE'][0].get('value')
                        elif 'EXPTIME' in fits_kw:
                            val = fits_kw['EXPTIME'][0].get('value')
                        try:
                            self.exposure_time = float(val)
                        except:
                            print(f"[DEBUG] Could not parse exposure_time={val!r}")
                    print(f"[DEBUG] Loaded exposure_time = {self.exposure_time}")

                # — extract airmass —
                am = None
                if isinstance(hdr, fits.Header):
                    # 1) explicit AIRMASS
                    if 'AIRMASS' in hdr:
                        try:
                            am = float(hdr['AIRMASS'])
                        except:
                            am = None
                    # 2) fallback: altitude → airmass
                    if am is None:
                        alt = (hdr.get('OBJCTALT')
                            or hdr.get('ALT')
                            or hdr.get('ALTITUDE')
                            or hdr.get('EL'))
                        try:
                            am = self.estimate_airmass_from_altitude(float(alt))
                        except:
                            am = 1.0

                elif isinstance(hdr, dict):
                    img_meta = hdr.get('image_meta', {}) or {}
                    fits_kw  = img_meta.get('FITSKeywords', {})
                    # 1) explicit
                    if 'AIRMASS' in fits_kw:
                        try:
                            am = float(fits_kw['AIRMASS'][0]['value'])
                        except:
                            am = None
                    # 2) altitude fallback
                    if am is None:
                        for key in ('OBJCTALT','ALT','ALTITUDE','EL'):
                            ent = fits_kw.get(key)
                            if ent:
                                try:
                                    am = self.estimate_airmass_from_altitude(
                                        float(ent[0]['value'])
                                    )
                                    break
                                except:
                                    pass
                        else:
                            am = 1.0
                else:
                    am = 1.0

            # store it (even if load failed)
            self.airmasses.append(am)

            self.progress_bar.setValue(i)
            QApplication.processEvents()

        # ——— now build your Time array from PASS 1 ———
        iso_strs = []
        mask_arr = []
        for _, t in datelist:
            if t is not None:
                iso_strs.append(t.isot)
                mask_arr.append(False)
            else:
                iso_strs.append('')
                mask_arr.append(True)

        ma_strs = np.ma.MaskedArray(iso_strs, mask=mask_arr)
        self.times = Time(
            ma_strs,
            format='isot',
            scale='utc',
            out_subfmt='date'
        )

        # done
        self.progress_bar.setVisible(False)
        loaded = sum(1 for im in self._cached_images if im is not None)
        self.status_label.setText(
            f"Loaded {loaded}/{len(sorted_paths)} aligned frames"
        )

    def load_masters(self):
        """
        Load a single master dark or flat, 2×2 bin it immediately,
        then check compatibility against any already‐loaded master.
        Remembers the last‐used folder in QSettings.
        """
        # — pull last folder from QSettings —
        settings = QSettings()
        last_master_dir = settings.value(
            "ExoPlanet/lastMasterFolder",
            os.path.expanduser("~"),
            type=str
        )

        # — configure file dialog —
        sender = self.sender()
        dlg = QFileDialog(self, "Select Master File",
                        last_master_dir,
                        "FITS, TIFF or XISF (*.fit *.fits *.tif *.tiff *.xisf)")
        dlg.setFileMode(QFileDialog.FileMode.ExistingFile)
        if not dlg.exec():
            return

        path = dlg.selectedFiles()[0]

        settings.setValue("ExoPlanet/lastMasterFolder", os.path.dirname(path))

        img, hdr, bit_depth, is_mono = load_image(path)
        if img is None:
            QMessageBox.warning(self, "Load Error", f"Failed to load master file:\n{path}")
            return

        # normalize dtype and bin
        img = img.astype(np.float32)
        binned = bin2x2_numba(img)

        # decide dark vs flat
        if "Dark" in sender.text():
            # if there's already a flat, ensure shapes match
            if self.master_flat is not None:
                if not self._shapes_compatible(binned, self.master_flat):
                    QMessageBox.warning(
                        self, "Shape Mismatch",
                        "This master dark (binned) doesn’t match your existing flat."
                    )
                    return

            self.master_dark = binned
            self.dark_status_label.setText("Dark: ✅")
            self.dark_status_label.setStyleSheet("color: #00cc66; font-weight: bold;")


        else:
            # flat
            if self.master_dark is not None:
                if not self._shapes_compatible(self.master_dark, binned):
                    QMessageBox.warning(
                        self, "Shape Mismatch",
                        "This master flat (binned) doesn’t match your existing dark."
                    )
                    return

            self.master_flat = binned
            self.flat_status_label.setText("Flat: ✅")
            self.flat_status_label.setStyleSheet("color: #00cc66; font-weight: bold;")


    def _shapes_compatible(self, master: np.ndarray, other: np.ndarray) -> bool:
        """
        Return True if `master` and `other` can be used together in calibration:
          - Exactly the same shape, OR
          - master is 2D (H×W) and other is 3D (H×W×3), OR
          - vice versa.
        """
        if master.shape == other.shape:
            return True

        # If one is 2D and the other is H×W×3, check the first two dims
        if master.ndim == 2 and other.ndim == 3 and other.shape[:2] == master.shape:
            return True
        if other.ndim == 2 and master.ndim == 3 and master.shape[:2] == other.shape:
            return True

        return False

    def calibrate_and_align(self):
        """
        Apply master dark/flat to each raw frame, then align them to the first frame.
        """
        if not self._cached_images:
            QMessageBox.warning(self, "Calibrate", "Load raw subs first.")
            return

        self.status_label.setText("Calibrating & aligning frames…")
        self.progress_bar.setVisible(True)
        n = len(self._cached_images)
        self.progress_bar.setMaximum(n)

        reference_image_2d = None

        for i, (img, hdr) in enumerate(zip(self._cached_images, self._cached_headers), start=1):
            # 1) subtract master dark
            if self.master_dark is not None:
                img = img.astype(np.float32) - self.master_dark

            # 2) divide by master flat
            if self.master_flat is not None:
                img = apply_flat_division_numba(img, self.master_flat)
           
            # 4) promote to 3-channel if still mono
            if img.ndim == 2:
                img = np.stack([img, img, img], axis=2)

            # 5) build mono “plane” for star registration
            plane = img if img.ndim == 2 else img.mean(axis=2)

            # 6) on first frame, set reference
            if reference_image_2d is None:
                reference_image_2d = plane.copy()

            # 7) compute transform & apply
            delta = StarRegistrationWorker.compute_affine_transform_astroalign(
                plane, reference_image_2d
            )
            if delta is None:
                delta = IDENTITY_2x3

            # apply to full image
            img_aligned = StarRegistrationThread.apply_affine_transform_static(img, delta)
            # update our cache
            self._cached_images[i-1] = img_aligned

            # update progress
            self.progress_bar.setValue(i)
            QApplication.processEvents()

        self.progress_bar.setVisible(False)
        self.status_label.setText("Calibration & alignment complete")

    def save_aligned_frames(self):
        """Save out each image in self._cached_images using our global save_image()."""
        if not self._cached_images:
            QMessageBox.warning(self, "Save Aligned Frames", "No images to save. Run Calibrate & Align first.")
            return

        # pick a folder
        out_dir = QFileDialog.getExistingDirectory(self, "Choose Output Folder")
        if not out_dir:
            return

        for i, orig_path in enumerate(self.image_paths):
            img = self._cached_images[i]
            # derive extension & format
            ext = os.path.splitext(orig_path)[1].lstrip(".").lower()
            fmt = ext if ext in ("fits","fit","tiff","tif","xisf","png","jpg","jpeg") else "fits"

            # pull back the original header block if we saved it
            hdr = None
            if hasattr(self, "_cached_headers") and i < len(self._cached_headers):
                hdr = self._cached_headers[i]

            # choose an output name
            base = os.path.splitext(os.path.basename(orig_path))[0]
            out_name = f"{base}_aligned.{fmt}"
            out_path = os.path.join(out_dir, out_name)

            # call your global helper
            # note: bit_depth, is_mono, image_meta, file_meta can all be None or defaulted
            save_image(
                img_array=img,
                filename=out_path,
                original_format=fmt,
                bit_depth=None,
                original_header=hdr,
                is_mono=(img.ndim==2),
                image_meta=None,
                file_meta=None
            )

        QMessageBox.information(
            self, "Save Complete",
            f"Saved {len(self._cached_images)} aligned frames to:\n{out_dir}"
        )

    def detect_stars(self):
        #print("=== detect_stars file order ===")
        #for i, path in enumerate(self.image_paths, start=1):
        #    print(f"{i:3d}: {path}")
        #print("===============================")        
        # — build & reset UI —
        self.status_label.setText("Measuring frames…")
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(len(self.image_paths))
        self.progress_bar.setValue(0)
        #QApplication.processEvents()

        # 0) make sure all the images are in memory
        if not hasattr(self, "_cached_images") or len(self._cached_images) != len(self.image_paths):
            self._cached_images = [load_image(p)[0] for p in self.image_paths]

        n_frames = len(self._cached_images)
        self.status_label.setText("Measuring frames…")
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(n_frames)
        self.progress_bar.setValue(0)
        #QApplication.processEvents()

        # 1) prepare a frame‐processing helper
        def _process_frame(idx, img):
            # mono-plane
            plane = img.mean(axis=2) if img.ndim == 3 else img
            mean, med, std = sigma_clipped_stats(plane)
            zeroed = plane - med

            # background
            bkg    = sep.Background(zeroed)
            bkgmap = bkg.back()
            rmsmap = bkg.rms()
            data_sub = zeroed - bkgmap

            # SEP extract
            try:
                objs = sep.extract(
                    data_sub,
                    thresh=self.sep_threshold, err=rmsmap,
                    minarea=16, deblend_nthresh=32, clean=True
                )
            except Exception:
                objs = None

            # compute FWHM/ecc if we got stars
            if objs is None or len(objs)==0:
                sc = 0; avg_fwhm = 0.0; avg_ecc = 0.0
            else:
                sc = len(objs)
                a = np.clip(objs['a'],1e-3,None)
                b = np.clip(objs['b'],1e-3,None)
                fwhm_vals = 2.3548 * np.sqrt(a*b)
                ecc_vals  = np.sqrt(1.0 - np.clip(b/a,0,1)**2)
                avg_fwhm = float(np.nanmean(fwhm_vals))
                avg_ecc   = float(np.nanmean(ecc_vals))

            stats = {
                "star_count":   sc,
                "eccentricity": avg_ecc,
                "mean":         float(np.mean(plane)),
                "fwhm":         avg_fwhm
            }
            return idx, data_sub, objs, rmsmap, stats

        # decide how many threads to spin up
        cpu_cnt = multiprocessing.cpu_count()
        n_workers = max(1, int(cpu_cnt * 0.8))

        frame_data = {}
        stats_map  = {}
        # 2) fire off the jobs
        with ThreadPoolExecutor(max_workers=n_workers) as exe:
            futures = [
                exe.submit(_process_frame, idx, img)
                for idx, img in enumerate(self._cached_images)
            ]
            done = 0
            for fut in as_completed(futures):
                idx, data_sub, objs, rmsmap, stats = fut.result()
                frame_data[idx] = (data_sub, objs, rmsmap)
                stats_map[idx]  = stats

                # update progress
                done += 1
                self.progress_bar.setValue(done)
                self.status_label.setText(f"Measured frame {done}/{n_frames}")
                #QApplication.processEvents()

        # 2) pick best reference by star_count/(FWHM * mean)
        def quality(i):
            s = stats_map[i]
            return s["star_count"] / (s["fwhm"] * s["mean"] + 1e-8)

        ref_idx   = max(stats_map.keys(), key=quality)
        ref_stats = stats_map[ref_idx]

        # 3) fire off Whats In My Image and plate solving
        self.ref_idx = ref_idx

        # grab the binned image & its header
        plane = self._cached_images[ref_idx]
        hdr   = self._cached_headers[ref_idx]

        tmp = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp.name
        # write the binned plane with its header
        fits.PrimaryHDU(data=plane).writeto(tmp_path, overwrite=True)
        tmp.close()

        # now plate‐solve that binned FITS
        self._emit_reference_later(tmp_path)

        # 4) pull the SEP catalog for reference
        data_ref, objs_ref, rms_ref = frame_data[ref_idx]
        if objs_ref is None or len(objs_ref) == 0:
            QMessageBox.warning(self, "No Stars", "No stars found in reference frame.")
            self.progress_bar.setVisible(False)
            return

        xs = objs_ref['x']
        ys = objs_ref['y']

        # --- drop detections too close to the edge ---
        h, w = data_ref.shape
        bf = self.border_fraction
        keep_border = (
            (xs > w*bf) & (xs < w*(1-bf)) &
            (ys > h*bf) & (ys < h*(1-bf))
        )
        xs = xs[keep_border]
        ys = ys[keep_border]

        self.median_fwhm = ref_stats["fwhm"]
        aper_r = max(2, 1.2 * self.median_fwhm)

        # 5) vectorized aperture sums on *all* frames
        # — 5) vectorized aperture sums on *all* frames ——
        n_stars  = len(xs)
        n_frames = len(self._cached_images)
        raw_flux = np.zeros((n_stars, n_frames), float)
        flags    = np.zeros((n_stars, n_frames), int)

        # NEW: array to hold the SEP‐reported errors
        raw_flux_err = np.zeros((n_stars, n_frames), float)

        self.status_label.setText("Computing aperture sums…")
        self.progress_bar.setMaximum(n_frames)
        self.progress_bar.setValue(0)
        #QApplication.processEvents()

        for t, img in enumerate(self._cached_images):
            self.status_label.setText(f"Running Photometry frame {t+1}/{n_frames}…")
            QApplication.processEvents()

            plane = img.mean(axis=2) if img.ndim == 3 else img
            if self.raw_mode_rb.isChecked():
                if self.master_dark is not None:
                    plane = plane.astype(np.float32) - self.master_dark
                if self.master_flat is not None:
                    plane = apply_flat_division_numba(plane, self.master_flat)

            bkg    = sep.Background(plane - np.median(plane))
            rmsmap = bkg.rms()
            data_sub = plane - bkg.back()

            # SEP sum circle returns flux, flux_error, flags
            fl, ferr, flg = sep.sum_circle(
                data_sub, xs, ys, aper_r, err=rmsmap
            )
            raw_flux[:, t]     = fl
            raw_flux_err[:, t] = ferr     # <— capture the per‐star error
            flags[:, t]        = flg

            self.progress_bar.setValue(t+1)
            #QApplication.processEvents()


        # ——— 6) ENSEMBLE NORMALIZATION ———
        # first compute each star’s “reference brightness” (e.g. median over all frames)
        n_stars, n_frames = raw_flux.shape

        # compute each star’s “reference brightness” (for neighbor search)
        star_refs = np.nanmedian(raw_flux, axis=1)

        # allocate outputs
        rel_flux = np.zeros_like(raw_flux)
        rel_err  = np.zeros_like(raw_flux_err)

        k = self.ensemble_k  # e.g. 10 by default
        self.ensemble_map = {} 

        for i in range(n_stars):
            # 1) find the k neighbors closest in ref‐brightness
            diffs = np.abs(star_refs - star_refs[i])
            diffs[i] = np.inf
            neigh = np.argpartition(diffs, k)[:k]
            self.ensemble_map[i] = list(neigh)

            # 2) build the ensemble curve + estimate its error
            ens_flux = np.nanmedian(raw_flux[neigh, :], axis=0)  # length n_frames
            # propagate errors in quadrature, then /sqrt(N)
            ens_err = np.sqrt(np.nansum(raw_flux_err[neigh, :]**2, axis=0)) / np.sqrt(len(neigh))

            # 3) normalize star i by that ensemble (guard against zeros)
            mask = ens_flux != 0
            rel_flux[i, mask] = raw_flux[i, mask] / ens_flux[mask]

            # 4) propagate the two error terms:
            #    σ_rel = rel_flux * sqrt[ (σ_raw / raw_flux)**2 + (σ_ens / ens_flux)**2 ]
            with np.errstate(divide='ignore', invalid='ignore'):
                term1 = np.where(raw_flux[i]  != 0, raw_flux_err[i]  / raw_flux[i], 0)
                term2 = np.where(ens_flux      != 0, ens_err           / ens_flux,      0)
                rel_err[i, mask] = rel_flux[i, mask] * np.sqrt(term1[mask]**2 + term2[mask]**2)

        # store for downstream steps & export
        self.fluxes      = rel_flux
        self.flux_errors = rel_err
        self.flags       = flags

        # — 6.5) detrend each star if requested —
        if self.detrend_degree is not None:
            n_stars = rel_flux.shape[0]

            self.status_label.setText("Detrending curves…")
            self.progress_bar.setVisible(True)
            self.progress_bar.setMaximum(n_stars)
            self.progress_bar.setValue(0)
            #QApplication.processEvents()

            for i in range(n_stars):
                curve = rel_flux[i].copy()
                # mask = only those frames where we actually _have_ a measurement
                good = np.isfinite(curve) & (curve > 0)


                # do the fit _without_ excluding flagged points
                detrended = self._detrend_curve(curve, self.detrend_degree, mask=good)
                rel_flux[i] = detrended

                self.progress_bar.setValue(i+1)
                #QApplication.processEvents()

            self.progress_bar.setVisible(False)
            self.status_label.setText("Detrending complete")  

        # ——— 7) flag per‐star 3σ outliers, but don’t drop the star entirely ———
        for i in range(n_stars):
            curve = rel_flux[i, :]
            med_i = np.nanmedian(curve)
            mad_i = np.nanmedian(np.abs(curve - med_i))
            # robust σ estimate
            sigma_i = 1.4826 * mad_i if mad_i > 0 else np.nanstd(curve)
            if sigma_i > 0:
                outlier_mask = np.abs(curve - med_i) > 2 * sigma_i
                flags[i, outlier_mask] = 1

        # ——— 8) now drop only stars that are flagged in ≥ 75% of frames ———
        good_counts = np.sum(flags == 0, axis=1)
        keep       = good_counts >= (0.75 * n_frames)

        xs       = xs[keep]
        ys       = ys[keep]
        rel_flux = rel_flux[keep, :]
        flags    = flags[keep, :]

        self.star_positions = list(zip(xs, ys))
        self.fluxes         = rel_flux.copy()
        self.flags          = flags

        # ——— 9) populate list with survivors ———
        self.star_list.clear()
        for i, (x, y) in enumerate(self.star_positions):
            item = QListWidgetItem(
                f"#{i}: x={x:.1f}, y={y:.1f}   RelFlux={rel_flux[i,0]:.3f}   FWHM={self.median_fwhm:.2f}"
            )
            item.setData(Qt.ItemDataRole.UserRole, i)
            self.star_list.addItem(item)

        # ——— 10) overlay & finish ———
        self._show_reference_with_circles(data_ref, self.star_positions)

        self.status_label.setText("Ready")
        self.progress_bar.setVisible(False)
        self.analyze_btn.setEnabled(True)
        self._on_threshold_changed(self.threshold_slider.value())

    def show_ensemble_members(self):
        sels = self.star_list.selectedItems()
        if len(sels) != 1:
            return
        target = sels[0].data(Qt.ItemDataRole.UserRole)
        members = self.ensemble_map.get(target, [])

        # 1) clear *only* the old ensemble highlights (light‑blue),
        #    leave any yellow flagged items in place
        for idx in self._last_ensemble:
            item = self.star_list.item(idx)
            if item:
                color = item.background().color()
                if color == QColor('lightblue'):
                    item.setBackground(QBrush())

        # 2) highlight the new ensemble members, but don't override yellow
        for idx in members:
            item = self.star_list.item(idx)
            if item:
                if item.background().color() != QColor('yellow'):
                    item.setBackground(QBrush(QColor('lightblue')))

        # 3) remember for next time
        self._last_ensemble = members
    def on_detrend_changed(self, idx: int):
        # idx==0 → quadratic, 1 → linear, 2 → none
        mapping = {0:None, 1:1, 2:2}
        self.detrend_degree = mapping[idx]
        # if we already have fluxes, replot immediately
        if getattr(self, 'fluxes', None) is not None:
            self.update_plot_for_selection()

    def _emit_reference_later(self, path: str):
        # wrap the actual emit in a singleShot so it always posts back to the event loop
        QTimer.singleShot(0, lambda: self.referenceSelected.emit(path))

    @staticmethod
    def _detrend_curve(curve: np.ndarray, deg: int, mask: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Fit up to a degree‐`deg` polynomial to the curve vs frame index and divide it out,
        using only the points where mask==True.  If you don't have enough points for `deg`,
        it will automatically degrade to a lower degree (down to linear).
        """
        x = np.arange(curve.size)

        # default mask = “finite, positive, unflagged”
        if mask is None:
            mask = np.isfinite(curve) & (curve > 0)

        n_good = int(mask.sum())
        # need at least 2 points to fit *anything*
        if n_good < 2:
            return curve

        # pick the highest degree we can actually fit
        fit_deg = min(deg, n_good - 1)
        if fit_deg < 1:
            return curve

        # perform the fit *only* on the good points
        try:
            coeffs = np.polyfit(x[mask], curve[mask], fit_deg)

        except Exception:
            # e.g. singular matrix

            return curve

        trend = np.polyval(coeffs, x)
        # avoid divide-by-zero
        trend[trend == 0] = 1.0
        return curve / trend

    def _show_reference_with_circles(self, plane, positions):
        dlg = ReferenceOverlayDialog(
            plane=plane,
            positions=positions,
            target_median=self.median_fwhm,
            parent=self
        )
        # keep a reference so it doesn’t get garbage‐collected
        self._ref_overlay = dlg
        dlg.show()


    def update_plot_for_selection(self):
        # 1) Sanity check
        if not hasattr(self, 'fluxes') or self.fluxes is None:
            QMessageBox.warning(
                self, "No Photometry",
                "Please run photometry before selecting a star."
            )
            return

        # 2) Build the X axis: hours since first exposure, or frame index fallback
        try:
            import astropy.units as u
            delta = (self.times - self.times[0]).to(u.hour).value  # array of hours
            x_all = delta
            bottom_label = "Hours since start"
        except Exception:
            # If self.times isn't set or parsing fails
            x_all = np.arange(self.fluxes.shape[1])
            bottom_label = "Frame"

        # 3) Clear plot and relabel axes
        self.plot_widget.clear()
        self.plot_widget.addLegend()
        self.plot_widget.setLabel('bottom', bottom_label)
        self.plot_widget.setLabel('left',   'Relative Flux')

        n_stars = self.fluxes.shape[0]

        # 4) Compute each star’s median flux once (for normalization)
        medians = np.nanmedian(self.fluxes, axis=1)

        # 5) Which stars to draw?
        inds = [item.data(Qt.ItemDataRole.UserRole)
                for item in self.star_list.selectedItems()]

        # 6) Plot each star’s relative flux curve
        max_gap = 1.0
        for idx in inds:
                # build rel flux & time
                f = self.fluxes[idx]
                flags_star = (self.flags[idx] if hasattr(self, 'flags') 
                            else np.zeros_like(f, int))
                mask = (np.isfinite(f) & (f > 0) & (flags_star == 0))
                if mask.sum() < 2:
                    continue

                rel = f[mask] / medians[idx]
                x   = x_all[mask]
                ma  = self.moving_average(rel, window=5)

                # find where gaps exceed max_gap
                dt = np.diff(x)
                breaks = np.where(dt > max_gap)[0]
                segments = np.split(np.arange(len(x)), breaks+1)

                color = pg.intColor(idx, hues=n_stars)
                pen   = pg.mkPen(color=color, width=2)
                dash  = pg.mkPen(color=color, width=2, style=Qt.PenStyle.DashLine)
                brush = pg.mkBrush(color=color)

                dull_color = QColor(color)
                dull_color.setAlpha(60)            # out of 255, lower → more transparent
                dull_pen   = pg.mkPen(color=dull_color, width=1)
                dull_brush = pg.mkBrush(color=dull_color)

                for seg in segments:
                    xs, ys, mas = x[seg], rel[seg], ma[seg]
                    # raw points (dimmer!)
                    self.plot_widget.plot(
                        xs, ys,
                        pen=dull_pen,
                        symbol='o',
                        symbolBrush=dull_brush,
                        name=f"Star #{idx}"
                    )
                    # moving average (full strength)
                    self.plot_widget.plot(
                        xs, mas,
                        pen=dash,
                        name=f"MA (w=5)"
                    )

    def apply_threshold(self, ppt_threshold: int, sigma_upper: float=3.0):
        """
        Flag dips below `ppt_threshold` ppt *and* clip any spikes > `sigma_upper` above the moving average.
        """
        if not hasattr(self, 'fluxes') or self.fluxes is None:
            return

        # relative flux and compute MA & sigma per star
        rel = self.fluxes  # stars × frames
        n_stars, n_frames = rel.shape

        # build moving averages star-by-star
        ma = np.array([self.moving_average(rel[i], window=5) for i in range(n_stars)])
        # robust σ estimate of the *upper* side
        diffs = rel - ma
        # only consider diffs > 0 for σ
        pos = diffs.copy()
        pos[pos < 0] = np.nan
        sigma_up = 1.4826 * np.nanmedian(np.abs(pos - np.nanmedian(pos, axis=1)[:,None]), axis=1)

        # compute dips (ppt) relative to MA
        dips = np.maximum((ma - rel)*1000, 0)  # bigger if rel << ma

        # per-star flags:  
        #  (a) dips ≥ ppt_threshold  
        #  (b) remove any timepoints where rel > ma + sigma_upper*sigma_up 
        flagged = set()
        for i in range(n_stars):
            dip_mask = dips[i] >= ppt_threshold
            spike_mask = rel[i] > (ma[i] + sigma_upper*sigma_up[i])
            # apply hysteresis: require at least 2 consecutive dip points to count
            consec = np.convolve(dip_mask.astype(int), [1,1], mode='valid') == 2
            dip_hyst = np.concatenate([[False], consec, [False]])
            if np.any(dip_hyst):
                flagged.add(i)
            # zero out the spiky points so they don’t get highlighted
            if np.any(spike_mask):
                self.flags[i, spike_mask] = 1
        for dlg in self.findChildren(ReferenceOverlayDialog):
            dlg.update_dip_flags(flagged)                

        # highlight in the star list
        for row in range(self.star_list.count()):
            item = self.star_list.item(row)
            item.setBackground(QBrush())
        for idx in flagged:
            item = self.star_list.item(idx)
            if item: item.setBackground(QBrush(QColor('yellow')))
        self.status_label.setText(f"{len(flagged)} star(s) dip ≥ {ppt_threshold} ppt")   

    def moving_average(self, curve, window=5):
        """
        Return a centered moving average of `curve` with length `window`.
        5→ average of points [i-2..i+2], etc.
        """

        pad = window//2
        ext = np.pad(curve, pad, mode="edge")
        kernel = np.ones(window)/window
        ma = np.convolve(ext, kernel, mode="valid")
        return ma


    def on_analyze(self):
        sel = self.star_list.selectedItems()
        if len(sel) != 1:
            QMessageBox.information(self, "Analyze", "Please select exactly one star.")
            return
        idx = sel[0].data(Qt.ItemDataRole.UserRole)

        # 1) Time + flux + mask
        t_all = self.times.mjd
        t_rel = t_all - t_all[0]
        f_all = self.fluxes[idx]
        good  = np.isfinite(f_all) & (self.flags[idx]==0)
        t0, f0 = t_rel[good], f_all[good]
        if len(t0) < 10:
            QMessageBox.warning(self, "Analyze", "Not enough good points to analyze.")
            return

        # 2) Lomb–Scargle (data-driven bounds)
        ls = LombScargle(t0, f0)
        Tspan = np.ptp(t0)
        dt    = np.median(np.diff(np.sort(t0)))
        min_f = 1.0 / Tspan
        max_f = 0.5  / dt
        freq, power_ls = ls.autopower(
            minimum_frequency    = min_f,
            maximum_frequency    = max_f,
            samples_per_peak     = self.ls_samples_per_peak
        )
        mask = (freq>0) & np.isfinite(power_ls)
        freq, power_ls = freq[mask], power_ls[mask]
        periods = 1.0/freq
        order   = np.argsort(periods)
        periods, power_ls = periods[order], power_ls[order]
        best_period = periods[np.argmax(power_ls)]

        # 3) Box–Least–Squares (absolute min duration)
        bls = BoxLeastSquares(t0 * u.day, f0)
        per_grid = np.linspace(
            self.bls_min_period,
            self.bls_max_period,
            self.bls_n_periods
        ) * u.day
        min_p = per_grid.min().value
        durations = np.linspace(
            self.bls_duration_min_frac * min_p,
            self.bls_duration_max_frac * min_p,
            self.bls_n_durations
        ) * u.day

        res      = bls.power(per_grid, durations)
        power    = res.power
        flat_idx = np.nanargmax(power)
        if power.ndim == 2:
            pi, di = np.unravel_index(flat_idx, power.shape)
            P_bls  = res.period[pi]
            D_bls  = durations[di]
            T0_bls = res.transit_time[pi, di]
        else:
            pi, di = flat_idx, 0
            P_bls  = res.period[pi]
            D_bls  = durations[0]
            T0_bls = res.transit_time[pi]

        dur_idx = di

        # 4) Phase‐fold & model
        phase = (((t0*u.day) - T0_bls)/P_bls) % 1
        phase = phase.value
        model = bls.model(t0*u.day, P_bls, D_bls, T0_bls)

        # 5) show in a dialog
        dlg = QDialog(self)
        dlg.setWindowTitle(f"Analysis: Star #{idx}")
        layout = QVBoxLayout(dlg)

        # LS plot
        pg_ls = pg.PlotWidget(title="Lomb–Scargle")
        pg_ls.plot(1/freq, power_ls, pen='w')
        pg_ls.addLine(x=best_period, pen=pg.mkPen('y', style=Qt.PenStyle.DashLine))
        pg_ls.setLabel('bottom','Period [d]')
        pg_ls.showGrid(True,True)
        layout.addWidget(pg_ls)

        # BLS plot (pick the slice at dur_idx)
        pg_bls = pg.PlotWidget(title="BLS Periodogram")
        # if power is 2D, pick out the fixed-duration slice, otherwise plot the whole 1D
        bls_power = res.power
        if bls_power.ndim == 2:
            y = bls_power[:, dur_idx]
        else:
            y = bls_power
        pg_bls.plot(res.period.value, y, pen='w')
        pg_bls.addLine(x=P_bls.value, pen=pg.mkPen('r', style=Qt.PenStyle.DashLine))
        pg_bls.setLabel('bottom','Period [d]')
        pg_bls.showGrid(True,True)
        layout.addWidget(pg_bls)

        # Phase‐fold + box model
        pg_fold = pg.PlotWidget(title=f"Phase‐Folded (P={P_bls.value:.4f} d)")
        pg_fold.plot(phase, f0, pen=None, symbol='o', symbolBrush='c')
        ord = np.argsort(phase)
        pg_fold.plot(phase[ord], model[ord], pen=pg.mkPen('y',width=2))
        pg_fold.setLabel('bottom','Phase')
        pg_fold.showGrid(True,True)
        layout.addWidget(pg_fold)

        dlg.resize(900,600)
        dlg.exec()

    def on_identify_star(self):
        # 1) Get the RA/Dec
        radec = self.get_selected_star_radec()
        if radec is None:
            QMessageBox.warning(self, "Identify Star", "Please select exactly one star first.")
            return
        ra, dec = radec
        coord = SkyCoord(ra=ra*u.deg, dec=dec*u.deg, frame='icrs')

        # 2) Configure SIMBAD: clear everything, then ask for otype + V-flux
        custom_simbad = Simbad()
        custom_simbad.reset_votable_fields()          # clear defaults
        custom_simbad.add_votable_fields("otype")     # object type
        custom_simbad.add_votable_fields("flux(V)")   # V-band magnitude

        # 3) Retry up to 5×
        result = None
        for attempt in range(1, 6):
            try:
                result = custom_simbad.query_region(coord, radius=5*u.arcsec)
                break
            except Exception as e:
                print(f"[DEBUG] SIMBAD attempt {attempt} failed: {e}")
                if attempt == 5:
                    QMessageBox.critical(
                        self, "SIMBAD Error",
                        f"Could not reach SIMBAD after 5 tries:\n{e}"
                    )
                    return
                time.sleep(1)

        # 4) Debug: show which columns we got
        if result is not None:
            print("SIMBAD column names:", result.colnames)
            print("=== SIMBAD raw result ===")
            result.pprint()
            print("=========================")

        # 5) No hits?
        if result is None or len(result) == 0:
            QMessageBox.information(
                self, "No SIMBAD Matches",
                f"No objects found within 5″ of {ra:.6f}, {dec:.6f}."
            )
            return

        # 6) Pick out the first row & dynamically find the right keys
        row = result[0]
        cols = [c.lower() for c in result.colnames]

        # find the columns
        id_col    = next(c for c in result.colnames if c.lower()=="main_id")
        ra_col    = next(c for c in result.colnames if c.lower()=="ra")
        dec_col   = next(c for c in result.colnames if c.lower()=="dec")
        otype_col = next((c for c in result.colnames if c.lower()=="otype"), None)
        flux_col  = next((c for c in result.colnames if c.upper()=="V" or c.upper()=="FLUX_V"), None)

        # extract & decode
        main_id = row[id_col]
        if isinstance(main_id, bytes):
            main_id = main_id.decode("utf-8")

        ra_val  = float(row[ra_col])
        dec_val = float(row[dec_col])
        match_coord = SkyCoord(ra=ra_val*u.deg, dec=dec_val*u.deg, frame='icrs')
        offset = coord.separation(match_coord).arcsec

        obj_type = None
        if otype_col:
            obj_type = row[otype_col]
            if isinstance(obj_type, bytes):
                obj_type = obj_type.decode("utf-8")
        obj_type = obj_type or "n/a"

        vmag = None
        if flux_col:
            raw = row[flux_col]
            try:
                vmag = float(raw)
            except Exception:
                vmag = None
        vmag_str = f"{vmag:.3f}" if vmag is not None else "n/a"

        # 7) Show results
        simbad_url = (
            "https://simbad.cds.unistra.fr/simbad/sim-id"
            f"?Ident={quote(main_id)}"
        )

        # Create a QMessageBox with two buttons: “OK” and “Open in SIMBAD”
        msg = QMessageBox(self)
        msg.setWindowTitle("SIMBAD Lookup")
        msg.setText(
            f"Nearest object:\n"
            f"  ID:     {main_id}\n"
            f"  Type:   {obj_type}\n"
            f"  V mag:  {vmag_str}\n"
            f"  Offset: {offset:.2f}″"
        )
        # add Open‐in‐Simbad as an ActionRole so it shows up beside the standard buttons
        open_btn = msg.addButton("Open in SIMBAD", QMessageBox.ButtonRole.ActionRole)
        ok_btn   = msg.addButton(QMessageBox.StandardButton.Ok)
        # run the dialog
        msg.exec()

        # if they clicked our button, open the URL in the default browser
        if msg.clickedButton() == open_btn:
            webbrowser.open(simbad_url)


    def _query_simbad_main_id(self):
        """
        Try up to 5× to look up the MAIN_ID from SIMBAD for the currently selected star.
        Returns the name (string) on success, or None on failure/no match.
        """

        # 1) get the star's sky coord
        radec = self.get_selected_star_radec()
        if radec is None:
            return None
        coord = SkyCoord(ra=radec[0]*u.deg, dec=radec[1]*u.deg, frame="icrs")

        # 2) retry up to 5×, just like on_identify_star()
        table = None
        for attempt in range(1, 6):
            try:
                custom = Simbad()
                custom.reset_votable_fields()
                custom.add_votable_fields("otype")
                custom.add_votable_fields("flux(V)")
                table = custom.query_region(coord, radius=5*u.arcsec)
                break
            except Exception as e:
                print(f"[DEBUG] SIMBAD lookup attempt {attempt} failed: {e}")
                if attempt == 5:
                    QMessageBox.critical(
                        self, "SIMBAD Error",
                        f"Could not reach SIMBAD after 5 tries:\n{e}"
                    )
                    return None
                time.sleep(1)

        # 3) no results?
        if table is None or len(table) == 0:
            return None

        # 4) dynamically find the MAIN_ID column (case‐insensitive)
        try:
            id_col = next(c for c in table.colnames if c.lower() == "main_id")
        except StopIteration:
            return None

        # 5) extract and decode
        val = table[0][id_col]
        if isinstance(val, bytes):
            val = val.decode("utf-8")
        return val

    def _query_simbad_name_and_vmag(self, ra_deg, dec_deg, radius=5*u.arcsec):
        """
        Return (main_id, vmag) from SIMBAD within `radius` of (ra_deg,dec_deg),
        retrying up to 5×.  If no valid match, return (None,None).
        """
        coord = SkyCoord(ra=ra_deg*u.deg, dec=dec_deg*u.deg, frame="icrs")
        table = None

        for attempt in range(1,6):
            try:
                custom = Simbad()
                custom.reset_votable_fields()
                custom.add_votable_fields("otype","flux(V)")
                table = custom.query_region(coord, radius=radius)
                break
            except Exception as e:
                if attempt==5:
                    QMessageBox.critical(
                        self, "SIMBAD Error",
                        f"Could not reach SIMBAD after 5 tries:\n{e}"
                    )
                    return None, None
                time.sleep(1)

        if table is None or len(table)==0:
            return None, None

        # find MAIN_ID column name dynamically
        try:
            id_col = next(c for c in table.colnames if c.lower()=="main_id")
        except StopIteration:
            return None, None

        raw_id = table[0][id_col]
        if isinstance(raw_id, bytes):
            raw_id = raw_id.decode()
        # find V‑mag column dynamically
        v_col = next((c for c in table.colnames if c.upper() in ("FLUX_V","V")), None)
        vmag = None
        if v_col:
            try:
                v = float(table[0][v_col])
                # drop nans as “no valid magnitude”
                if np.isfinite(v):
                    vmag = v
            except Exception:
                vmag = None

        return raw_id, vmag

    def export_data(self):
        if self.fluxes is None or self.times is None:
            QMessageBox.warning(self, "Export", "No photometry to export. Run Measure & Photometry first.")
            return

        # ask CSV vs FITS
        dlg = QFileDialog(self, "Export Light Curves")
        dlg.setAcceptMode(QFileDialog.AcceptMode.AcceptSave)
        dlg.setNameFilters(["CSV files (*.csv)", "FITS files (*.fits)"])
        if not dlg.exec():
            return
        path = dlg.selectedFiles()[0]
        fmt  = dlg.selectedNameFilter()

        # assemble time & flux arrays
        times_mjd = self.times.mjd              # float days
        n_stars   = self.fluxes.shape[0]

        # --- compute per-star RA/Dec from WCS + pixel positions ---
        # self.star_positions is list of (x,y) in pixels
        # pull the solved WCS from the WIMI tab in the main window
        wimi_tab = self.parent().wimi_tab
        wcs      = wimi_tab.wcs
        xs = np.array([xy[0] for xy in self.star_positions])
        ys = np.array([xy[1] for xy in self.star_positions])
        sky = wcs.pixel_to_world(xs, ys)
        ras = sky.ra.deg
        decs = sky.dec.deg

        # CSV export: add STAR_i_RA and STAR_i_DEC columns
        if fmt.startswith("CSV") or path.lower().endswith(".csv"):
            df = pd.DataFrame({"MJD": times_mjd})
            for i in range(n_stars):
                df[f"STAR_{i}"]     = self.fluxes[i]
                df[f"FLAG_{i}"]     = self.flags[i]
                df[f"STAR_{i}_RA"]  = ras[i]
                df[f"STAR_{i}_DEC"] = decs[i]
            df.to_csv(path, index=False)
            QMessageBox.information(self, "Export CSV", f"Wrote CSV →\n{path}")
            return

        # — otherwise FITS export —

        # 1) build a header from reference‐frame metadata
        hdr_out = fits.Header()
        orig_hdr = None
        if hasattr(self, "_cached_headers") and 0 <= self.ref_idx < len(self._cached_headers):
            orig_hdr = self._cached_headers[self.ref_idx]

        # copy whitelist from orig_hdr if available
        if isinstance(orig_hdr, fits.Header):
            for key in ("OBJECT","TELESCOP","INSTRUME","OBSERVER",
                        "DATE-OBS","EXPTIME","FILTER",
                        "CRVAL1","CRVAL2","CRPIX1","CRPIX2",
                        "CDELT1","CDELT2","CTYPE1","CTYPE2"):
                if key in orig_hdr:
                    hdr_out[key] = orig_hdr[key]
        elif isinstance(orig_hdr, dict):
            for key in ("OBJECT","TELESCOP","INSTRUME","DATE-OBS","EXPTIME","FILTER"):
                val = orig_hdr.get(key, [{}])[0].get("value")
                if val is not None:
                    hdr_out[key] = val

        # 2) reduction metadata
        hdr_out["SEPTHR"]  = (self.sep_threshold,  "SEP detection threshold (sigma)")
        hdr_out["BFRAC"]   = (self.border_fraction, "Border ignore fraction")
        hdr_out["REFIDX"]  = (self.ref_idx,         "Reference frame index")
        hdr_out["MEDFWHM"] = (self.median_fwhm,     "Median FWHM of reference")
        hdr_out.add_history("Exported by Seti Astro Suite")

        # 3) light curve table
        cols = [fits.Column(name="MJD",  format="D", array=times_mjd)]
        for i in range(n_stars):
            cols.append(fits.Column(name=f"STAR_{i}",      format="E", array=self.fluxes[i]))
            cols.append(fits.Column(name=f"FLAG_{i}",      format="I", array=self.flags[i]))
        lc_hdu = fits.BinTableHDU.from_columns(cols, header=hdr_out, name="LIGHTCURVE")

        # 4) star‐metadata table (per‐star x,y,RA,Dec)
        star_idx = np.arange(n_stars, dtype=int)
        cols2 = [
            fits.Column(name="INDEX", format="I", array=star_idx),
            fits.Column(name="X",     format="E", array=xs),
            fits.Column(name="Y",     format="E", array=ys),
            fits.Column(name="RA",    format="D", array=ras),
            fits.Column(name="DEC",   format="D", array=decs),
        ]
        stars_hdu = fits.BinTableHDU.from_columns(cols2, name="STARS")

        # 5) write out
        primary = fits.PrimaryHDU(header=hdr_out)
        hdul    = fits.HDUList([primary, lc_hdu, stars_hdu])
        hdul.writeto(path, overwrite=True)
        QMessageBox.information(self, "Export FITS", f"Wrote FITS →\n{path}")


    def estimate_airmass_from_altitude(self, alt_deg):
        # avoid division by zero at the horizon
        alt_rad = np.deg2rad(np.clip(alt_deg, 0.1, 90.0))
        print(f"Estimating airmass for altitude {alt_deg}° → {alt_rad} rad")
        return 1.0 / np.sin(alt_rad)

    def export_to_aavso(self):
        """Export in AAVSO EXTENDED format, converting to apparent magnitudes."""
        # 0) make sure we have photometry
        if getattr(self, "fluxes", None) is None or getattr(self, "times", None) is None:
            QMessageBox.warning(self, "Export AAVSO",
                                "No photometry available. Run Measure & Photometry first.")
            return

        # 1) exactly one star selected
        sels = self.star_list.selectedItems()
        if len(sels) != 1:
            QMessageBox.warning(self, "Export AAVSO",
                                "Please select exactly one star before exporting.")
            return
        idx = sels[0].data(Qt.ItemDataRole.UserRole)

        star_id = self._query_simbad_main_id()

        if star_id:
            try:
                # 1) show what we’re about to do
                print(f"AAVSO export → VSX lookup for SIMBAD ID: {star_id!r}")

                Vizier.ROW_LIMIT = 1
                v = Vizier(columns=["Name"], catalog="B/vsx")
                print(f"  Vizier.query_object parameters: columns={v.columns}, catalog={v.catalog}")

                # 2) do the query
                tbls = v.query_object(star_id)

                # 3) dump the raw response
                if tbls is None:
                    print("  Vizier returned None")
                else:
                    for i, tbl in enumerate(tbls):
                        print(f"  Vizier returned table #{i} with {len(tbl)} row(s):\n{tbl}")

                # 4) extract the VSX “Name” if present
                if tbls and len(tbls) > 0 and len(tbls[0]) > 0:
                    new_id = tbls[0]["Name"][0]
                    print(f"  VSX Name found: {new_id!r} (will use this as STARID)")
                    star_id = new_id
                else:
                    print("  No VSX entry found, keeping SIMBAD ID")

            except Exception as e:
                print(f"  VSX lookup failed with exception: {e}")

        if not star_id:
            # manual fallback
            star_id, ok = QInputDialog.getText(
                self, "Target Star Name",
                "Could not auto‑identify.  Enter target star name for STARID:",
                QLineEdit.EchoMode.Normal, ""
            )
            if not ok or not star_id.strip():
                return
            star_id = star_id.strip()

        # 2) exposure time
        if not hasattr(self, "exposure_time") or self.exposure_time is None:
            exp, ok = QInputDialog.getDouble(
                self, "Exposure Time",
                "No EXPOSURE found in headers. Please enter exposure time (s):",
                decimals=1
            )
            if not ok:
                return
            self.exposure_time = exp

        # 3) observer code
        settings = QSettings()
        prev_code = settings.value("AAVSO/observer_code", "", type=str)
        code, ok = QInputDialog.getText(
            self, "Observer Code",
            "Enter your AAVSO observer code:",
            QLineEdit.EchoMode.Normal,
            prev_code
        )
        if not ok:
            return
        code = code.strip().upper()
        settings.setValue("AAVSO/observer_code", code)

        # 4) submission type
        fmt, ok = QInputDialog.getItem(
            self, "AAVSO Format",
            "Choose submission format:",
            ["Variable-Star Photometry", "Exoplanet Report"],
            0, False
        )
        if not ok:
            return

        # 5) automatically pick a check star from your ensemble_map
        #    use the same k you used in detect_stars()
        from astropy.wcs import WCS
        wcs = self.parent().wimi_tab.wcs

        raw_members = self.ensemble_map.get(idx, [])
        members     = [m for m in raw_members if 0 <= m < len(self.star_positions)]

        kname = None
        kmag  = None

        for m in members:
            x, y = self.star_positions[m]
            sky = wcs.pixel_to_world(x, y)
            name, v = self._query_simbad_name_and_vmag(sky.ra.deg, sky.dec.deg)
            if name and (v is not None) and np.isfinite(v):
                kname, kmag = name, v
                break

        # if none of the ensemble members resolved, fall back to manual entry
        if kname is None:
            kname, ok = QInputDialog.getText(
                self, "Check Star Name",
                "Could not auto‑identify a check star. Enter check‑star ID:"
            )
            if not ok or not kname.strip():
                return
            kname = kname.strip()
            kmag, ok = QInputDialog.getDouble(
                self, "Check Star Magnitude",
                f"Enter catalog magnitude for {kname}:",
                decimals=3
            )
            if not ok:
                return

        # 6) choose filter code
        filt_choices = ["V","TG","TB","TR"]
        filt, ok = QInputDialog.getItem(
            self, "Filter",
            "Select filter code for this dataset:",
            filt_choices, 0, False
        )
        if not ok:
            return

        # 7) output filename
        path, _ = QFileDialog.getSaveFileName(
            self, "Save AAVSO File", "", "Text files (*.txt *.dat *.csv)"
        )
        if not path:
            return

        # 8) build header lines
        header_lines = [
            "#TYPE=EXTENDED",
            f"#OBSCODE={code}",
            f"#SOFTWARE=Seti Astro Suite v{VERSION}",
            "#DELIM=,",
            "#DATE=JD",
            "#OBSTYPE=CCD",
        ]
        # RA/Dec of the selected star
        radec = self.get_selected_star_radec()
        if radec is None:
            QMessageBox.warning(self, "Export AAVSO",
                                "Could not determine RA/Dec of selected star.")
            return
        from astropy.coordinates import SkyCoord
        import astropy.units as u
        c = SkyCoord(ra=radec[0]*u.deg, dec=radec[1]*u.deg, frame="icrs")
        header_lines += [
            "#RA="  + c.ra.to_string(unit=u.hour, sep=":", pad=True, precision=2),
            "#DEC=" + c.dec.to_string(unit=u.degree, sep=":", pad=True,
                                    alwayssign=True, precision=1),
        ]
        header_lines.append("#NAME,DATE,MAG,MERR,FILT,TRANS,MTYPE,CNAME,CMAG,KNAME,KMAG,AMASS,GROUP,CHART,NOTES")

        # 9) prepare your time & magnitudes
        jd = self.times.utc.jd
        rel_flux = self.fluxes[idx, :]           # relative flux per frame
        # convert to mag:  m = kmag − 2.5 log10(rel_flux)
        with np.errstate(divide="ignore"):
            mags = kmag - 2.5 * np.log10(rel_flux)
        # magnitude errors from flux_errors if you stored them
        if hasattr(self, "flux_errors"):
            rel_err = self.flux_errors[idx, :]
            merr = (2.5/np.log(10)) * (rel_err / rel_flux)
        else:
            merr = np.full_like(mags, np.nan)

        # 10) write out
        try:
            with open(path, "w") as f:
                for L in header_lines:
                    f.write(L + "\n")
                f.write("\n")
                for j, t in enumerate(jd):
                    m   = mags[j]
                    me  = merr[j]
                    me_str = f"{me:.3f}" if np.isfinite(me) else "na"
                    note = "MAG calc via ensemble: m=-2.5 log10(F/Fe)+K"

                    # clamp airmass to [1, 40]
                    if j < len(self.airmasses):
                        am = self.airmasses[j]
                    else:
                        am = 1.0
                    am = float(np.clip(am, 1.0, 40.0))


                    fields = [
                        star_id,
                        f"{t:.5f}",
                        f"{m:.3f}",
                        me_str,
                        filt,
                        "NO",
                        "STD",
                        "ENSEMBLE",
                        "na",
                        kname,
                        f"{kmag:.3f}",
                        f"{am:.1f}",       # now a valid AIRMASS
                        "na",
                        "na",
                        note
                    ]
                    f.write(",".join(fields) + "\n")
        except Exception as e:
            QMessageBox.critical(self, "Export AAVSO",
                                f"Failed to write file:\n{e}")
            return

        # 11) offer to open the AAVSO upload page
        msg = QMessageBox(self)
        msg.setWindowTitle("Export AAVSO")
        msg.setText(f"Wrote {fmt} →\n{path}\n\nOpen AAVSO WebObs upload page now?")
        yes = msg.addButton("Yes", QMessageBox.ButtonRole.AcceptRole)
        msg.addButton("No", QMessageBox.ButtonRole.RejectRole)
        msg.exec()
        if msg.clickedButton() == yes:
            import webbrowser
            webbrowser.open("https://www.aavso.org/webobs/file")





    @pyqtSlot(float, float)
    def receive_wcs_coordinates(self, ra, dec):
        """
        Accepts RA/Dec from WIMI after plate solve.
        Stores coordinates and enables TESScut button.
        """
        self.wcs_ra = ra
        self.wcs_dec = dec
        self.status_label.setText(f"WCS received: RA={ra:.5f}, Dec={dec:.5f}")
        self.fetch_tesscut_btn.setEnabled(True)  

    def query_tesscut(self):
        # 1) Get the RA/Dec of the selected star
        radec = self.get_selected_star_radec()
        if radec is None:
            QMessageBox.warning(
                self, "No Star Selected",
                "Please select a star from the list to fetch TESScut data."
            )
            return
        ra, dec = radec
        print(f"[DEBUG] TESScut Query Requested for RA={ra:.6f}, Dec={dec:.6f}")
        coord = SkyCoord(ra=ra, dec=dec, unit="deg")

        size = 10         # cutout size in pixels
        MAX_RETRIES = 5

        # ─── Manifest retry loop ───
        manifest = None
        for mtry in range(1, MAX_RETRIES+1):
            try:
                print(f"[DEBUG] Manifest attempt {mtry}/{MAX_RETRIES}…")
                manifest = Tesscut.get_cutouts(coordinates=coord, size=size)
                if manifest:
                    print(f"[DEBUG] Manifest OK: {len(manifest)} sector(s).")
                    break
                else:
                    raise RuntimeError("Empty manifest")
            except Exception as me:
                print(f"[DEBUG] Manifest attempt {mtry} failed: {me}")
                if mtry == MAX_RETRIES:
                    QMessageBox.information(
                        self, "No TESS Data",
                        "There are no TESS cutouts available at that position."
                    )
                    self.status_label.setText("No TESScut data found.")
                    return
                time.sleep(2)

        # ─── Download retry loop ───
        self.status_label.setText("Querying TESScut…")
        QApplication.processEvents()
        cache_dir = os.path.join(os.path.expanduser("~"), ".setiastro", "tesscut_cache")
        os.makedirs(cache_dir, exist_ok=True)

        for dtry in range(1, MAX_RETRIES+1):
            try:
                print(f"[DEBUG] Download attempt {dtry}/{MAX_RETRIES}…")
                cutouts = Tesscut.download_cutouts(
                    coordinates=coord, size=size, path=cache_dir
                )
                if not cutouts:
                    raise RuntimeError("No cutouts downloaded")
                print(f"[DEBUG] Downloaded {len(cutouts)} cutout(s).")

                for cutout in cutouts:
                    original_path = cutout['Local Path']
                    print(f"[DEBUG] Processing: {original_path}")

                    # Read sector from header
                    with fits.open(original_path, mode='readonly') as hdul:
                        sector = hdul[1].header.get('SECTOR', 'unknown')

                    # Cache filename
                    ext = os.path.splitext(original_path)[1]
                    cache_key = (
                        f"tess_sector{sector}_"
                        f"ra{int(round(ra*10000))}_"
                        f"dec{int(round(dec*10000))}{ext}"
                    )
                    cached_path = os.path.join(cache_dir, cache_key)

                    if not os.path.exists(cached_path):
                        print(f"[DEBUG] Caching as: {cached_path}")
                        shutil.move(original_path, cached_path)
                    else:
                        print(f"[DEBUG] Already cached: {cached_path}")
                        os.remove(original_path)

                    # Open with Lightkurve
                    tpf = TessTargetPixelFile(cached_path)

                    # Custom circular aperture on selected star
                    xpix, ypix = tpf.wcs.world_to_pixel(coord)
                    ny, nx = tpf.flux.shape[1], tpf.flux.shape[2]
                    Y, X = np.mgrid[:ny, :nx]
                    r_pix = 2.5
                    aper_mask = ((X - xpix)**2 + (Y - ypix)**2) <= r_pix**2

                    lc = (
                        tpf.to_lightcurve(aperture_mask=aper_mask)
                        .remove_nans()
                        .normalize()
                    )
                    # Clip both ends: no points > 5× or < –1×
                    upper, lower = 5.0, -1.0
                    mask = (lc.flux < upper) & (lc.flux > lower)
                    n_clipped = np.sum(~mask)
                    print(f"[DEBUG] Clipping {n_clipped} points outside [{lower}, {upper}]×")
                    lc = lc[mask]

                    # then plot the cleaned curve
                    lc.plot(label=f"Sector {tpf.sector} (clipped)")
                    plt.title(f"TESS Light Curve - Sector {tpf.sector}")
                    plt.tight_layout()
                    plt.show()

                self.status_label.setText("TESScut fetch complete.")
                return

            except Exception as de:
                print(f"[ERROR] Download attempt {dtry} failed: {de}")
                self.status_label.setText(
                    f"TESScut attempt {dtry}/{MAX_RETRIES} failed."
                )
                QApplication.processEvents()
                if dtry == MAX_RETRIES:
                    QMessageBox.critical(
                        self, "TESScut Error",
                        f"TESScut failed after {MAX_RETRIES} attempts.\n\n{de}"
                    )
                    self.status_label.setText("TESScut fetch failed.")
                else:
                    time.sleep(2)

    def get_selected_star_radec(self):
        selected_items = self.star_list.selectedItems()
        if not selected_items:
            return None

        selected_index = selected_items[0].data(Qt.ItemDataRole.UserRole)
        x, y = self.star_positions[selected_index]

        # Need WCS to convert
        if hasattr(self.parent().wimi_tab, 'wcs'):
            wcs = self.parent().wimi_tab.wcs
            sky = wcs.pixel_to_world(x, y)
            return sky.ra.degree, sky.dec.degree
        return None                         

class BackgroundNeutralizationDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Background Neutralization")
        self.setGeometry(100, 100, 800, 600)
        
        # new flag for auto-stretch
        self.auto_stretch = False
        self.zoom_factor = 1.0        
        self.initUI()
        self.selection_rect_item = None

    def initUI(self):
        layout = QVBoxLayout(self)

        # Instruction Label
        instruction_label = QLabel("Draw a sample box or use Find Background to auto-select.")
        layout.addWidget(instruction_label)

        # Graphics View for Image Display
        self.graphics_view = QGraphicsView()
        self.scene = QGraphicsScene()
        self.graphics_view.setScene(self.scene)
        layout.addWidget(self.graphics_view)

        # Buttons: Apply, Cancel, Auto-Stretch, Find Background
        btn_row = QHBoxLayout()
        apply_btn = QPushButton("Apply Neutralization")
        apply_btn.clicked.connect(self.apply_neutralization)
        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        self.toggle_stretch_btn = QPushButton("Enable Auto-Stretch")
        self.toggle_stretch_btn.clicked.connect(self.toggle_auto_stretch)
        find_bg_btn = QPushButton("Find Background")
        find_bg_btn.clicked.connect(self.find_background)

        btn_row.addWidget(apply_btn)
        btn_row.addWidget(cancel_btn)
        btn_row.addWidget(self.toggle_stretch_btn)
        btn_row.addWidget(find_bg_btn)
        layout.addLayout(btn_row)

        # Zoom controls
        zoom_row = QHBoxLayout()
        zoom_in_btn  = QPushButton("Zoom In ＋")
        zoom_out_btn = QPushButton("Zoom Out －")
        fit_btn      = QPushButton("Fit to View")
        zoom_in_btn.clicked.connect(self.zoom_in)
        zoom_out_btn.clicked.connect(self.zoom_out)
        fit_btn.clicked.connect(self.fit_to_view)
        zoom_row.addWidget(zoom_out_btn)
        zoom_row.addWidget(fit_btn)
        zoom_row.addWidget(zoom_in_btn)
        layout.addLayout(zoom_row)

        # Prepare for drawing rectangle
        self.origin = QPointF()
        self.current_rect = QRectF()
        self.drawing = False
        self.graphics_view.viewport().installEventFilter(self)

        # finally load
        self.load_image()


    def load_image(self):
        """Loads the current image, applies auto-stretch, resets zoom & displays it."""
        self.scene.clear()
        self.selection_rect_item = None
        img = self.image_manager.image
        if img is None:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            self.reject()
            return

        display = img.copy()
        if self.auto_stretch:
            display = stretch_color_image(display, 0.25, linked=False, normalize=False)

        h, w, ch = display.shape
        data = (display * 255).astype(np.uint8).tobytes()
        if ch == 3:
            qimg = QImage(data, w, h, 3*w, QImage.Format.Format_RGB888)
        else:
            qimg = QImage(data, w, h, w,   QImage.Format.Format_Grayscale8)
        pix = QPixmap.fromImage(qimg)

        # reset zoom & show
        self.zoom_factor = 1.0
        self.graphics_view.resetTransform()
        self.pixmap_item = QGraphicsPixmapItem(pix)
        self.scene.addItem(self.pixmap_item)
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def zoom_in(self):
        """Zoom in by 25%."""
        if self.zoom_factor < 5.0:
            self.zoom_factor *= 1.25
            self.graphics_view.scale(1.25, 1.25)

    def zoom_out(self):
        """Zoom out by 20%."""
        if self.zoom_factor > 0.2:
            self.zoom_factor /= 1.25
            self.graphics_view.scale(0.8, 0.8)

    def fit_to_view(self):
        """Reset zoom so the image fits in the view."""
        self.zoom_factor = 1.0
        self.graphics_view.resetTransform()
        self.graphics_view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    def toggle_auto_stretch(self):
        """Toggle between normal and auto-stretched display."""
        self.auto_stretch = not self.auto_stretch
        self.toggle_stretch_btn.setText(
            "Disable Auto-Stretch" if self.auto_stretch else "Enable Auto-Stretch"
        )
        self.load_image()

    def toggle_auto_stretch(self):
        """Toggle between normal and auto-stretched display."""
        self.auto_stretch = not self.auto_stretch
        self.toggle_stretch_btn.setText(
            "Disable Auto-Stretch" if self.auto_stretch else "Enable Auto-Stretch"
        )
        # re-load the image so we immediately see the effect
        self.load_image()

    def find_background(self):
        """Locate the best 50×50 background patch (≥100px from edges), allow small shifts to avoid stars, and draw it."""
        img = self.image_manager.image
        if img is None:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            return

        h, w, ch = img.shape
        if ch != 3:
            QMessageBox.warning(self, "Not RGB", "Only 3-channel RGB supported.")
            return

        # work on luminance
        lum = img.mean(axis=2)

        # 1) find the raw best center by downhill‐walk search
        best_y, best_x = self._find_best_patch_center(lum)

        # 2) enforce a 100px border so a 50×50 never touches edges
        margin = 100
        half   = 25
        min_cx = margin + half
        max_cx = w - (margin + half)
        min_cy = margin + half
        max_cy = h - (margin + half)
        best_x = int(np.clip(best_x, min_cx, max_cx))
        best_y = int(np.clip(best_y, min_cy, max_cy))

        # 3) refine by testing shifts of ±half pix in both directions
        best_val = np.inf
        cx, cy   = best_x, best_y
        for dy in (-half, 0, +half):
            for dx in (-half, 0, +half):
                ty = int(np.clip(best_y + dy, min_cy, max_cy))
                tx = int(np.clip(best_x + dx, min_cx, max_cx))
                y0, y1 = ty - half, ty + half
                x0, x1 = tx - half, tx + half
                m = np.median(lum[y0:y1, x0:x1])
                if m < best_val:
                    best_val = m
                    cy, cx   = ty, tx

        # 4) build the final 50×50 in image coords
        ix0, ix1 = cx - half, cx + half
        iy0, iy1 = cy - half, cy + half

        # 5) map to scene coords and draw
        scene_rect = self.scene.sceneRect()
        sx = scene_rect.width()  / w
        sy = scene_rect.height() / h
        x0, y0 = ix0 * sx, iy0 * sy
        x1, y1 = ix1 * sx, iy1 * sy

        if self.selection_rect_item:
            self.scene.removeItem(self.selection_rect_item)

        pen = QPen(QColor(255, 215, 0), 2)  # gold
        rect = QRectF(QPointF(x0, y0), QPointF(x1, y1))
        self.selection_rect_item = QGraphicsRectItem(rect)
        self.selection_rect_item.setPen(pen)
        self.scene.addItem(self.selection_rect_item)

        # store so Apply uses same region (in image coords!)
        self.current_rect = QRectF(ix0, iy0, ix1 - ix0, iy1 - iy0)




    def _find_best_patch_center(self, plane: np.ndarray):
        """
        1) tile medians 10×10
        2) pick two darkest tiles
        3) 100 downhill walks per tile → finals
        4) for each final point compute median in a 50×50 square
        5) pick the point with the smallest such median
        """
        h, w = plane.shape
        th, tw = h//10, w//10

        # 1) tile medians
        meds = np.zeros((10,10), float)
        for i in range(10):
            for j in range(10):
                y0, x0 = i*th, j*tw
                y1 = (i+1)*th if i<9 else h
                x1 = (j+1)*tw if j<9 else w
                meds[i,j] = np.median(plane[y0:y1, x0:x1])

        # 2) two darkest
        flat = meds.flatten()
        idxs = np.argsort(flat)[:2]

        # 3) downhill from random in each tile
        finals = []
        for idx in idxs:
            ti, tj = divmod(idx, 10)
            y0, x0 = ti*th, tj*tw
            y1 = (ti+1)*th if ti<9 else h
            x1 = (tj+1)*tw if tj<9 else w
            for _ in range(200):
                y = np.random.randint(y0, y1)
                x = np.random.randint(x0, x1)
                while True:
                    mv, mpos = plane[y,x], (y,x)
                    for dy in (-1,0,1):
                        for dx in (-1,0,1):
                            if dy==0 and dx==0: continue
                            ny, nx = y+dy, x+dx
                            if 0<=ny<h and 0<=nx<w and plane[ny,nx] < mv:
                                mv, mpos = plane[ny,nx], (ny,nx)
                    if mpos == (y,x):
                        break
                    y, x = mpos
                finals.append(mpos)

        # 4) compute each 50×50 median
        best_val = np.inf
        best_pt = (h//2, w//2)
        for (y,x) in finals:
            y0 = max(0, y-25); y1 = min(h, y+25)
            x0 = max(0, x-25); x1 = min(w, x+25)
            m = np.median(plane[y0:y1, x0:x1])
            if m < best_val:
                best_val, best_pt = m, (y,x)

        return best_pt

    def _compute_bg_median(self, plane: np.ndarray) -> float:
        """Implements your PI‐style finder on a single channel."""
        h, w = plane.shape
        th, tw = h//10, w//10
        # 1) tile medians
        tile_meds = np.zeros((10,10), float)
        for i in range(10):
            for j in range(10):
                y0, x0 = i*th, j*tw
                y1 = (i+1)*th if i<9 else h
                x1 = (j+1)*tw if j<9 else w
                tile_meds[i,j] = np.median(plane[y0:y1, x0:x1])
        # 2) pick two darkest tiles
        idxs = np.argsort(tile_meds.flatten())[:2]
        # 3) random walks
        finals = []
        for idx in idxs:
            ti, tj = divmod(idx, 10)
            y0, x0 = ti*th, tj*tw
            y1 = (ti+1)*th if ti<9 else h
            x1 = (tj+1)*tw if tj<9 else w
            for _ in range(100):
                y = np.random.randint(y0, y1)
                x = np.random.randint(x0, x1)
                # downhill walk
                while True:
                    mv, mpos = plane[y,x], (y,x)
                    for dy in (-1,0,1):
                        for dx in (-1,0,1):
                            if dy==0 and dx==0: continue
                            ny, nx = y+dy, x+dx
                            if 0<=ny<h and 0<=nx<w and plane[ny,nx] < mv:
                                mv, mpos = plane[ny,nx], (ny,nx)
                    if mpos == (y,x):
                        break
                    y, x = mpos
                finals.append((y,x))
        # 4) medians of 50×50 around each final point
        square_meds = []
        for (y,x) in finals:
            y0, y1 = max(0,y-25), min(h,y+25)
            x0, x1 = max(0,x-25), min(w,x+25)
            square_meds.append(np.median(plane[y0:y1, x0:x1]))
        return float(min(square_meds))

    def eventFilter(self, source, event):
        """Handles mouse events for drawing the sample box."""
        if source is self.graphics_view.viewport():
            if event.type() == QEvent.Type.MouseButtonPress:
                if event.button() == Qt.MouseButton.LeftButton:
                    self.drawing = True
                    self.origin = self.graphics_view.mapToScene(event.pos())
                    # Remove existing selection rectangle if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
            elif event.type() == QEvent.Type.MouseMove:
                if self.drawing:
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Remove existing rectangle item if any
                    if self.selection_rect_item:
                        self.scene.removeItem(self.selection_rect_item)
                        self.selection_rect_item = None
                    # Draw the new rectangle
                    pen = QPen(QColor(0, 255, 0), 2, Qt.PenStyle.DashLine)
                    self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                    self.selection_rect_item.setPen(pen)
                    self.scene.addItem(self.selection_rect_item)
            elif event.type() == QEvent.Type.MouseButtonRelease:
                if event.button() == Qt.MouseButton.LeftButton and self.drawing:
                    self.drawing = False
                    # Finalize the rectangle
                    current_pos = self.graphics_view.mapToScene(event.pos())
                    self.current_rect = QRectF(self.origin, current_pos).normalized()
                    # Ensure minimum size to avoid accidental small selections
                    min_size = 10  # pixels
                    if self.current_rect.width() < min_size or self.current_rect.height() < min_size:
                        QMessageBox.warning(self, "Selection Too Small", "Please draw a larger selection box.")
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                            self.selection_rect_item = None
                        self.current_rect = QRectF()
                    else:
                        # Redraw the rectangle to ensure it's persistent
                        if self.selection_rect_item:
                            self.scene.removeItem(self.selection_rect_item)
                        pen = QPen(QColor(255, 0, 0), 2, Qt.PenStyle.SolidLine)
                        self.selection_rect_item = QGraphicsRectItem(self.current_rect)
                        self.selection_rect_item.setPen(pen)
                        self.scene.addItem(self.selection_rect_item)
        return super().eventFilter(source, event)

    def apply_neutralization(self):
        """Applies background neutralization based on the selected sample region."""
        if self.current_rect.isNull():
            QMessageBox.warning(self, "No Selection", "Please draw a sample box on the image.")
            return

        # Map the selection rectangle to image coordinates
        image = self.image_manager.image
        if image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to neutralize.")
            return

        # Get the image dimensions
        height, width, channels = image.shape
        if channels != 3:
            QMessageBox.warning(self, "Not RGB", "Background Neutralization currently supports only 3-channel RGB images.")
            return

        # Calculate scaling factors to map from scene coords to image coords
        scene_rect = self.scene.sceneRect()
        scale_x = width / scene_rect.width()
        scale_y = height / scene_rect.height()

        # Convert scene coordinates to image coordinates
        x = int(self.current_rect.left() * scale_x)
        y = int(self.current_rect.top() * scale_y)
        w = int(self.current_rect.width() * scale_x)
        h = int(self.current_rect.height() * scale_y)

        # Ensure the rectangle is within image bounds
        x = max(0, min(x, width - 1))
        y = max(0, min(y, height - 1))
        w = max(1, min(w, width - x))
        h = max(1, min(h, height - y))

        # Extract the sample region
        sample_region = image[y:y + h, x:x + w, :]  # Shape: (h, w, 3)

        # Calculate medians for each channel
        medians = np.median(sample_region, axis=(0, 1))  # Shape: (3,)
        # Compute the average of these three medians
        average_median = np.mean(medians)

        # Create a copy of the image for adjustments
        adjusted_image = image.copy()

        # For each RGB channel, compute the difference and apply the formula
        # newChannel = (oldChannel - diff) / (1 - diff),
        # where diff = median(channel) - average_median
        for c in range(3):
            diff = medians[c] - average_median

            # Numerator = old - diff
            # Denominator = 1 - diff
            # Make sure we handle any extreme edge cases where (1 - diff) could be 0 or negative
            numerator = adjusted_image[:, :, c] - diff
            denominator = 1.0 - diff

            # Avoid division by zero or extremely small denominators
            # (in normal circumstances, diff should be well within -1..1 for images in [0,1])
            if abs(denominator) < 1e-8:
                # If this occurs, you could skip or handle differently.
                # For safety, just skip or clamp in real code:
                denominator = 1e-8 if denominator >= 0 else -1e-8

            new_values = numerator / denominator

            # Clip the results to [0, 1] to remain in valid image range
            new_values = np.clip(new_values, 0.0, 1.0)

            adjusted_image[:, :, c] = new_values

        # Update the image in the ImageManager
        self.image_manager.set_image(
            adjusted_image,
            metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Background Neutralization"
        )

        # Inform the user
        print("Background neutralization applied successfully.")

        # Close the dialog
        self.accept()

class RemoveGreenDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the RemoveGreenDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Remove Green")
        self.initUI()

    def initUI(self):
        """
        Sets up the UI components.
        """
        layout = QVBoxLayout()

        # Instruction Label
        instruction_label = QLabel("Select the amount to remove green noise:")
        layout.addWidget(instruction_label)

        # Slider Configuration
        self.slider = QSlider(Qt.Orientation.Horizontal)
        self.slider.setMinimum(0)
        self.slider.setMaximum(100)  # Represents 0.0 to 1.0
        self.slider.setValue(100)     # Default to 1.0
        self.slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.slider.setTickInterval(10)
        self.slider.valueChanged.connect(self.update_label)
        layout.addWidget(self.slider)

        # Current Value Display
        self.value_label = QLabel("Amount: 1.00")
        layout.addWidget(self.value_label)

        # Buttons Layout
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        cancel_button = QPushButton("Cancel")
        apply_button.clicked.connect(self.apply)
        cancel_button.clicked.connect(self.reject)
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)
        layout.addLayout(button_layout)

        self.setLayout(layout)

    def update_label(self, value):
        """
        Updates the value label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        amount = value / 100.0
        self.value_label.setText(f"Amount: {amount:.2f}")

    def apply(self):
        """
        Applies the Remove Green operation to the image, considering the applied mask.
        """
        amount = self.slider.value() / 100.0

        if self.image_manager.image is not None:
            try:
                # Apply the global SCNR function to reduce green noise
                new_image = apply_average_neutral_scnr(self.image_manager.image, amount=amount)

                # Retrieve the currently applied mask from MaskManager
                applied_mask = self.mask_manager.get_applied_mask()

                if applied_mask is not None:
                    # Ensure mask dimensions match the image dimensions
                    if applied_mask.shape[:2] != self.image_manager.image.shape[:2]:
                        QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                        return

                    # Ensure mask is a float array with values between 0 and 1
                    if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                        applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                    # Clip mask values to [0,1] to avoid unexpected results
                    applied_mask = np.clip(applied_mask, 0.0, 1.0)

                    # If image has multiple channels, ensure mask has the same number of channels
                    if self.image_manager.image.ndim == 3 and applied_mask.ndim == 2:
                        applied_mask = np.expand_dims(applied_mask, axis=-1)

                    # Perform the blending: combined_image = image * (1 - mask) + new_image * mask
                    combined_image = self.image_manager.image * (1 - applied_mask) + new_image * applied_mask

                    # Ensure the combined image's pixel values are within [0,1]
                    combined_image = np.clip(combined_image, 0.0, 1.0)

                    # Update the ImageManager's current image with the combined image
                    self.image_manager.set_image(
                        combined_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Remove Green"
                    )
                else:
                    # No mask applied; update with the processed image directly
                    self.image_manager.set_image(
                        new_image,
                        metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="Remove Green"
                    )

                # Inform the user of the successful operation
                print(f"Remove Green applied with amount {amount:.2f}")

                # Close the dialog
                self.accept()
            except Exception as e:
                # Handle any errors during processing
                QMessageBox.critical(self, "Error", f"Failed to apply Remove Green:\n{e}")
        else:
            # Inform the user if no image is loaded
            QMessageBox.warning(self, "No Image", "No image loaded to apply Remove Green.")
            self.reject()

class CLAHEDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the CLAHEDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("CLAHE")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # CLAHE Parameters Group
        parameters_group = QGroupBox("CLAHE Parameters")
        parameters_layout = QGridLayout()

        # Clip Limit Slider and Label
        clip_label = QLabel("Clip Limit:")
        self.clip_slider = QSlider(Qt.Orientation.Horizontal)
        self.clip_slider.setMinimum(1)
        self.clip_slider.setMaximum(40)  # Represents 0.1 to 4.0
        self.clip_slider.setValue(20)     # Default 2.0
        self.clip_slider.setTickInterval(1)
        self.clip_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.clip_value_label = QLabel("2.0")  # Initial value
        self.clip_slider.setToolTip("Adjust the clip limit for contrast enhancement. Higher values increase contrast.")

        self.clip_slider.valueChanged.connect(self.update_clip_value)
        self.clip_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(clip_label, 0, 0)
        parameters_layout.addWidget(self.clip_slider, 0, 1)
        parameters_layout.addWidget(self.clip_value_label, 0, 2)

        # Tile Grid Size Slider and Label
        tile_label = QLabel("Tile Grid Size:")
        self.tile_slider = QSlider(Qt.Orientation.Horizontal)
        self.tile_slider.setMinimum(1)
        self.tile_slider.setMaximum(32)
        self.tile_slider.setValue(8)        # Default (8,8)
        self.tile_slider.setTickInterval(1)
        self.tile_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.tile_value_label = QLabel("8")  # Initial value
        self.tile_slider.setToolTip("Adjust the size of grid for histogram equalization. Larger values affect broader areas.")

        self.tile_slider.valueChanged.connect(self.update_tile_value)
        self.tile_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(tile_label, 1, 0)
        parameters_layout.addWidget(self.tile_slider, 1, 1)
        parameters_layout.addWidget(self.tile_value_label, 1, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_clahe)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_clip_value(self, value):
        """
        Updates the clip limit label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        clip_limit = value / 10.0  # 0.1 to 4.0
        self.clip_value_label.setText(f"{clip_limit:.1f}")

    def update_tile_value(self, value):
        """
        Updates the tile grid size label based on slider position.

        Args:
            value (int): Current value of the slider.
        """
        self.tile_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current slider values and applied mask.
        """
        if self.original_image is None:
            # Clear the scene and then re-add the pixmap item.
            self.preview_scene.clear()
            self.pixmap_item = QGraphicsPixmapItem()  # Reinitialize pixmap item.
            self.preview_scene.addItem(self.pixmap_item)
            self.preview_scene.addText("No image loaded.")
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                preview_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use CLAHE image directly
                preview_image = clahe_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate CLAHE preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)

        # Convert QRect to QRectF before setting
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_clahe(self):
        """
        Applies CLAHE with current parameters to the main image, considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply CLAHE.")
            self.reject()
            return

        clip_limit = self.clip_slider.value() / 10.0  # 0.1 to 4.0
        tile_grid_size = self.tile_slider.value()

        try:
            # Apply CLAHE to the original image
            clahe_image = apply_clahe(
                self.original_image,
                clip_limit=clip_limit,
                tile_grid_size=(tile_grid_size, tile_grid_size)
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + clahe_image * mask
                combined_image = self.original_image * (1 - applied_mask) + clahe_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="CLAHE"
                )
            else:
                # No mask applied; update with the CLAHE-processed image directly
                self.image_manager.set_image(
                    clahe_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="CLAHE"
                )

            # Inform the user of the successful operation
            print("CLAHE applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply CLAHE:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders to their default values and updates the preview.
        """
        self.clip_slider.setValue(20)  # Default 2.0
        self.tile_slider.setValue(8)   # Default (8,8)

class MorphologyDialog(QDialog):
    def __init__(self, image_manager, mask_manager, parent=None):
        """
        Initializes the MorphologyDialog.

        Args:
            image_manager (ImageManager): Instance of ImageManager to handle image operations.
            mask_manager (MaskManager): Instance of MaskManager to handle mask operations.
            parent (QWidget, optional): Parent widget.
        """
        super().__init__(parent)
        self.image_manager = image_manager
        self.mask_manager = mask_manager
        self.setWindowTitle("Morphological Operations")
        self.setGeometry(100, 100, 800, 600)  # Increased size for better layout
        self.initUI()
        self.current_zoom = 1.0  # Initial zoom level

    def initUI(self):
        """
        Sets up the UI components.
        """
        main_layout = QVBoxLayout()

        # Morphological Parameters Group
        parameters_group = QGroupBox("Morphological Parameters")
        parameters_layout = QGridLayout()

        # Operation Type Selection
        operation_label = QLabel("Operation Type:")
        self.operation_combo = QComboBox()
        self.operation_combo.addItems(["Erosion", "Dilation", "Opening", "Closing"])
        self.operation_combo.setToolTip("Select the type of morphological operation to apply.")
        self.operation_combo.currentTextChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(operation_label, 0, 0)
        parameters_layout.addWidget(self.operation_combo, 0, 1, 1, 2)

        # Kernel Size Slider and Label
        kernel_label = QLabel("Kernel Size:")
        self.kernel_slider = QSlider(Qt.Orientation.Horizontal)
        self.kernel_slider.setMinimum(1)
        self.kernel_slider.setMaximum(31)
        self.kernel_slider.setValue(3)        # Default kernel size
        self.kernel_slider.setTickInterval(2)
        self.kernel_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.kernel_value_label = QLabel("3")  # Initial value
        self.kernel_slider.setToolTip("Adjust the size of the structuring element. Must be an odd number.")

        self.kernel_slider.valueChanged.connect(self.update_kernel_value)
        self.kernel_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(kernel_label, 1, 0)
        parameters_layout.addWidget(self.kernel_slider, 1, 1)
        parameters_layout.addWidget(self.kernel_value_label, 1, 2)

        # Iterations Slider and Label
        iterations_label = QLabel("Iterations:")
        self.iterations_slider = QSlider(Qt.Orientation.Horizontal)
        self.iterations_slider.setMinimum(1)
        self.iterations_slider.setMaximum(10)
        self.iterations_slider.setValue(1)        # Default iterations
        self.iterations_slider.setTickInterval(1)
        self.iterations_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.iterations_value_label = QLabel("1")  # Initial value
        self.iterations_slider.setToolTip("Adjust the number of times the operation is applied.")

        self.iterations_slider.valueChanged.connect(self.update_iterations_value)
        self.iterations_slider.valueChanged.connect(self.debounce_preview)

        parameters_layout.addWidget(iterations_label, 2, 0)
        parameters_layout.addWidget(self.iterations_slider, 2, 1)
        parameters_layout.addWidget(self.iterations_value_label, 2, 2)

        parameters_group.setLayout(parameters_layout)
        main_layout.addWidget(parameters_group)

        # Preview Area
        preview_group = QGroupBox("Preview")
        preview_layout = QVBoxLayout()

        # QGraphicsView and QGraphicsScene
        self.preview_view = QGraphicsView()
        self.preview_scene = QGraphicsScene()
        self.preview_view.setScene(self.preview_scene)

        self.preview_view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)  # Enable panning
        #self.preview_view.setFixedSize(780, 400)  # Adjusted size to fit layout

        # Initialize QGraphicsPixmapItem
        self.pixmap_item = QGraphicsPixmapItem()
        self.preview_scene.addItem(self.pixmap_item)

        preview_layout.addWidget(self.preview_view)
        preview_group.setLayout(preview_layout)
        main_layout.addWidget(preview_group)

        # Zoom and Fit Buttons
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In (+)")
        zoom_in_button.setToolTip("Zoom in the preview image.")
        zoom_in_button.clicked.connect(self.zoom_in)

        zoom_out_button = QPushButton("Zoom Out (-)")
        zoom_out_button.setToolTip("Zoom out the preview image.")
        zoom_out_button.clicked.connect(self.zoom_out)

        fit_button = QPushButton("Fit to Preview")
        fit_button.setToolTip("Fit the image to the preview area.")
        fit_button.clicked.connect(self.fit_to_preview)

        zoom_layout.addStretch()
        zoom_layout.addWidget(zoom_in_button)
        zoom_layout.addWidget(zoom_out_button)
        zoom_layout.addWidget(fit_button)

        main_layout.addLayout(zoom_layout)

        # Apply, Reset, and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_morphology)
        reset_button = QPushButton("Reset")
        reset_button.clicked.connect(self.reset_parameters)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(reset_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # Initialize Debounce Timer
        self.debounce_timer = QTimer()
        self.debounce_timer.setSingleShot(True)
        self.debounce_timer.timeout.connect(self.update_preview)

        # Store Original Image
        if self.image_manager.image.copy() is not None:
            self.original_image = self.image_manager.image.copy()
        else:
            self.original_image = None

        # Initialize Preview
        self.update_preview()

    def update_kernel_value(self, value):
        """
        Updates the kernel size label based on slider position.
        Ensures that the kernel size is always an odd number.
        
        Args:
            value (int): Current value of the slider.
        """
        if value % 2 == 0:
            value += 1  # Ensure kernel size is odd
            if value > self.kernel_slider.maximum():
                value = self.kernel_slider.maximum() - 1 if self.kernel_slider.maximum() % 2 == 0 else self.kernel_slider.maximum()
            self.kernel_slider.setValue(value)
        self.kernel_value_label.setText(str(value))

    def update_iterations_value(self, value):
        """
        Updates the iterations label based on slider position.
        
        Args:
            value (int): Current value of the slider.
        """
        self.iterations_value_label.setText(str(value))

    def debounce_preview(self):
        """
        Starts or restarts the debounce timer to limit the frequency of preview updates.
        """
        self.debounce_timer.start(300)  # 300 milliseconds delay

    def update_preview(self):
        """
        Updates the preview image based on current parameters and applied mask.
        """
        if self.original_image is None:
            self.pixmap_item.setPixmap(QPixmap())
            self.preview_scene.clear()
            self.preview_scene.addText("No image loaded.")
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1
            self.kernel_slider.setValue(kernel_size)

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                preview_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the preview image's pixel values are within [0,1]
                preview_image = np.clip(preview_image, 0.0, 1.0)
            else:
                # No mask applied; use morphed image directly
                preview_image = morphed_image

            # Display the preview image
            self.display_image(preview_image)
        except Exception as e:
            self.preview_scene.clear()
            self.preview_scene.addText("Failed to generate preview.")
            QMessageBox.critical(self, "Error", f"Failed to generate Morphological preview:\n{e}")

    def display_image(self, image):
        """
        Converts a NumPy image array to QPixmap and displays it in the QGraphicsView.
        Maintains the current zoom and pan settings.

        Args:
            image (np.ndarray): Image to display.
        """
        # Convert image from [0,1] to [0,255] and to uint8
        image_uint8 = (image * 255).astype('uint8')

        # Create QImage from the NumPy array
        height, width, channel = image_uint8.shape
        bytes_per_line = 3 * width
        q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        # Update the existing pixmap item
        self.pixmap_item.setPixmap(pixmap)
        self.preview_scene.setSceneRect(QRectF(pixmap.rect()))  # Convert QRect to QRectF

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms in the preview image by 25%.
        """
        self.current_zoom *= 1.25
        self.preview_view.scale(1.25, 1.25)

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out the preview image by 20%.
        """
        self.current_zoom *= 0.8
        self.preview_view.scale(0.8, 0.8)

    def fit_to_preview(self):
        """
        Fits the image to the preview area.
        """
        self.preview_view.fitInView(self.preview_scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
        self.current_zoom = 1.0  # Reset zoom level

    def apply_morphology(self):
        """
        Applies the selected morphological operation with current parameters to the main image,
        considering the applied mask.
        """
        if self.original_image is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply morphological operations.")
            self.reject()
            return

        operation = self.operation_combo.currentText().lower()  # e.g., 'erosion'
        kernel_size = self.kernel_slider.value()
        iterations = self.iterations_slider.value()

        # Ensure kernel size is odd
        if kernel_size % 2 == 0:
            kernel_size += 1

        try:
            # Apply the selected morphological operation to the original image
            morphed_image = apply_morphology(
                self.original_image,
                operation=operation,
                kernel_size=kernel_size,
                iterations=iterations
            )

            # Retrieve the currently applied mask from MaskManager
            applied_mask = self.mask_manager.get_applied_mask()

            if applied_mask is not None:
                # Ensure mask dimensions match the image dimensions
                if applied_mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return

                # Ensure mask is a float array with values between 0 and 1
                if applied_mask.dtype != np.float32 and applied_mask.dtype != np.float64:
                    applied_mask = applied_mask.astype(np.float32) / 255.0  # Normalize if needed

                # Clip mask values to [0,1] to avoid unexpected results
                applied_mask = np.clip(applied_mask, 0.0, 1.0)

                # If image has multiple channels, ensure mask has the same number of channels
                if self.original_image.ndim == 3 and applied_mask.ndim == 2:
                    applied_mask = np.expand_dims(applied_mask, axis=-1)

                # Perform the blending: combined_image = image * (1 - mask) + morphed_image * mask
                combined_image = self.original_image * (1 - applied_mask) + morphed_image * applied_mask

                # Ensure the combined image's pixel values are within [0,1]
                combined_image = np.clip(combined_image, 0.0, 1.0)

                # Update the ImageManager's current image with the combined image
                self.image_manager.set_image(
                    combined_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="morphology"
                )
            else:
                # No mask applied; update with the morphed image directly
                self.image_manager.set_image(
                    morphed_image,
                    metadata=self.image_manager._metadata[self.image_manager.current_slot], step_name="morphology"
                )

            # Inform the user of the successful operation
            QMessageBox.information(self, "Success", f"{self.operation_combo.currentText()} applied successfully.")

            # Close the dialog
            self.accept()
        except Exception as e:
            # Handle any errors during processing
            QMessageBox.critical(self, "Error", f"Failed to apply morphological operations:\n{e}")
            self.reject()

    def reset_parameters(self):
        """
        Resets sliders and operation type to default values and updates the preview.
        """
        self.operation_combo.setCurrentIndex(0)  # 'Erosion'
        self.kernel_slider.setValue(3)           # Default kernel size
        self.iterations_slider.setValue(1)       # Default iterations

class WhiteBalanceDialog(QDialog):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("White Balance")
        self.setGeometry(100, 100, 800, 500)  # Adjusted size to remove preview area
        self.initUI()

    def initUI(self):
        main_layout = QVBoxLayout()

        # White Balance Type Selection
        type_label = QLabel("White Balance Type:")
        self.type_combo = QComboBox()
        self.type_combo.addItems(["Star-Based", "Manual", "Auto"])
        self.type_combo.currentTextChanged.connect(self.update_options)

        type_layout = QHBoxLayout()
        type_layout.addWidget(type_label)
        type_layout.addWidget(self.type_combo)
        type_layout.addStretch()

        main_layout.addLayout(type_layout)

        # Standard White Balance Options
        self.standard_widget = QWidget()
        self.standard_layout = QVBoxLayout()

        # Gain Sliders for R, G, B
        gain_group = QGroupBox("Adjust Gain for Each Channel")
        gain_layout = QGridLayout()

        self.r_slider = QSlider(Qt.Orientation.Horizontal)
        self.r_slider.setMinimum(50)
        self.r_slider.setMaximum(150)
        self.r_slider.setValue(100)  # Represents 0.5 to 1.5
        self.r_slider.setTickInterval(10)
        self.r_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.r_label = QLabel("100")

        self.g_slider = QSlider(Qt.Orientation.Horizontal)
        self.g_slider.setMinimum(50)
        self.g_slider.setMaximum(150)
        self.g_slider.setValue(100)
        self.g_slider.setTickInterval(10)
        self.g_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.g_label = QLabel("100")

        self.b_slider = QSlider(Qt.Orientation.Horizontal)
        self.b_slider.setMinimum(50)
        self.b_slider.setMaximum(150)
        self.b_slider.setValue(100)
        self.b_slider.setTickInterval(10)
        self.b_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.b_label = QLabel("100")

        # Connect sliders to update labels
        self.r_slider.valueChanged.connect(lambda val: self.r_label.setText(str(val)))
        self.g_slider.valueChanged.connect(lambda val: self.g_label.setText(str(val)))
        self.b_slider.valueChanged.connect(lambda val: self.b_label.setText(str(val)))

        # Arrange sliders and labels in grid
        gain_layout.addWidget(QLabel("Red Gain:"), 0, 0)
        gain_layout.addWidget(self.r_slider, 0, 1)
        gain_layout.addWidget(self.r_label, 0, 2)

        gain_layout.addWidget(QLabel("Green Gain:"), 1, 0)
        gain_layout.addWidget(self.g_slider, 1, 1)
        gain_layout.addWidget(self.g_label, 1, 2)

        gain_layout.addWidget(QLabel("Blue Gain:"), 2, 0)
        gain_layout.addWidget(self.b_slider, 2, 1)
        gain_layout.addWidget(self.b_label, 2, 2)

        gain_group.setLayout(gain_layout)
        self.standard_layout.addWidget(gain_group)
        self.standard_widget.setLayout(self.standard_layout)
        main_layout.addWidget(self.standard_widget)

        # Star-Based White Balance Options
        self.star_widget = QWidget()
        self.star_layout = QVBoxLayout()
        self.star_widget.setLayout(self.star_layout)
        self.star_widget.hide()  # Hidden initially

        star_info = QLabel("Star-Based White Balance automatically detects stars to adjust colors.")
        self.star_layout.addWidget(star_info)

        # Sensitivity Slider for Star Detection Threshold (scaled from 1 to 100 sigma)
        sensitivity_group = QGroupBox("Detection Sensitivity")
        sensitivity_layout = QHBoxLayout()

        # Add sensitivity direction labels
        more_sensitive_label = QLabel("More Sensitive")
        less_sensitive_label = QLabel("Less Sensitive")

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(1)
        self.sensitivity_slider.setMaximum(100)
        self.sensitivity_slider.setValue(50)  # Default: 50 sigma
        self.sensitivity_slider.setTickInterval(10)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_label = QLabel("Threshold: 50")  # Initial value

        # Create a timer to delay star detection until the user stops adjusting the slider
        self.sensitivity_timer = QTimer()
        self.sensitivity_timer.setSingleShot(True)
        self.sensitivity_timer.setInterval(1000)  # 1 second delay
        self.sensitivity_timer.timeout.connect(self.detect_and_display_stars)

        def update_sensitivity_label(value):
            self.sensitivity_label.setText(f"Threshold: {value:.2f}")
            self.sensitivity_timer.start()  # Restart debounce timer

        self.sensitivity_slider.valueChanged.connect(update_sensitivity_label)

        # Add components to layout
        sensitivity_layout.addWidget(more_sensitive_label)
        sensitivity_layout.addWidget(self.sensitivity_slider)
        sensitivity_layout.addWidget(less_sensitive_label)
        sensitivity_layout.addWidget(self.sensitivity_label)

        sensitivity_group.setLayout(sensitivity_layout)
        self.star_layout.addWidget(sensitivity_group)


        # Autostretch Checkbox
        self.autostretch_checkbox = QCheckBox("Autostretch Display")
        self.autostretch_checkbox.setChecked(True)  # Enable by default
        self.autostretch_checkbox.stateChanged.connect(self.detect_and_display_stars)
        self.star_layout.addWidget(self.autostretch_checkbox)


        # Label to show number of detected stars
        self.star_count_label = QLabel("Detecting stars...")
        self.star_layout.addWidget(self.star_count_label)

        # Image display for detected stars
        self.star_image_label = QLabel()
        self.star_image_label.setFixedSize(800, 500)  # Reduced size as no preview is needed
        self.star_image_label.setStyleSheet("border: 1px solid black;")
        self.star_layout.addWidget(self.star_image_label)

        main_layout.addWidget(self.star_widget)

        # Apply and Cancel Buttons
        button_layout = QHBoxLayout()
        apply_button = QPushButton("Apply")
        apply_button.clicked.connect(self.apply_white_balance)
        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.reject)
        button_layout.addStretch()
        button_layout.addWidget(apply_button)
        button_layout.addWidget(cancel_button)

        main_layout.addLayout(button_layout)

        self.setLayout(main_layout)

        # **Set initial selection to "Star-Based" and display relevant widgets**
        self.type_combo.setCurrentText("Star-Based")
        self.update_options("Star-Based")

    def update_sensitivity_label(self, value):
        self.sensitivity_label.setText(f"Threshold: {value}")

    def update_options(self, text):
        if text == "Manual":
            self.star_widget.hide()
            self.standard_widget.show()
        elif text == "Auto":
            self.standard_widget.hide()
            self.star_widget.hide()
        elif text == "Star-Based":
            self.standard_widget.hide()
            self.star_widget.show()
            self.star_count_label.setText("Detecting stars...")
            # Trigger star detection and display
            QTimer.singleShot(1000, self.detect_and_display_stars)

    def detect_and_display_stars(self):
        try:
            image = self.image_manager.image
            if image is not None:
                threshold = self.sensitivity_slider.value()  # Convert to float
                autostretch_enabled = self.autostretch_checkbox.isChecked()

                # Apply star-based WB with optional stretch for display
                balanced_image, star_count, image_with_stars = apply_star_based_white_balance(
                    image, threshold, autostretch=autostretch_enabled
                )

                # Convert image_with_stars to QPixmap for display
                height, width, channel = image_with_stars.shape
                bytes_per_line = 3 * width
                q_image = QImage(image_with_stars.data, width, height, bytes_per_line, QImage.Format.Format_BGR888)
                pixmap = QPixmap.fromImage(q_image).scaled(
                    self.star_image_label.width(),
                    self.star_image_label.height(),
                    Qt.AspectRatioMode.KeepAspectRatio
                )
                self.star_image_label.setPixmap(pixmap)
                self.star_count_label.setText(f"Detected {star_count} stars.")
            else:
                self.star_count_label.setText("No image loaded.")
        except Exception as e:
            self.star_count_label.setText("Detection failed.")
            self.star_image_label.clear()
            QMessageBox.critical(self, "Error", f"Failed to detect stars:\n{e}")


    def apply_white_balance(self):
        wb_type = self.type_combo.currentText()

        try:
            image = self.image_manager.image
            if image is not None:
                if wb_type == "Manual":
                    r_gain = self.r_slider.value() / 100.0  # 0.5 to 1.5
                    g_gain = self.g_slider.value() / 100.0
                    b_gain = self.b_slider.value() / 100.0
                    balanced_image = apply_standard_white_balance(image, r_gain, g_gain, b_gain)
                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )
                    QMessageBox.information(self, "Success", "Manual White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Auto":
                    balanced_image = apply_auto_white_balance(image)
                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )
                    QMessageBox.information(self, "Success", "Auto White Balance applied successfully.")
                    self.accept()
                elif wb_type == "Star-Based":
                    threshold = self.sensitivity_slider.value()
                    balanced_image, star_count, _, raw_star_colors, after_star_colors = apply_star_based_white_balance(
                        image,
                        threshold,
                        autostretch=False,
                        reuse_cached_sources=True,
                        return_star_colors=True  # ✅ enable star color scatter plot
                    )

                    # Show the technical scatter plot after applying WB
                    plot_star_color_ratios_comparison(raw_star_colors, after_star_colors)

                    self.image_manager.set_image(
                        balanced_image,
                        metadata=self.image_manager._metadata.get(self.image_manager.current_slot, {}), step_name="white_balance"
                    )

                    QMessageBox.information(self, "Success", f"Star-Based White Balance applied successfully.\nDetected {star_count} stars.")
                    self.accept()
                else:
                    raise ValueError("Invalid White Balance Type.")
            else:
                QMessageBox.warning(self, "No Image", "No image loaded to apply White Balance.")
                self.reject()
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to apply White Balance:\n{e}")
            self.reject()

class SaspViewer(QMainWindow):
    def __init__(self, sasp_data_path, user_custom_path):
        super().__init__()
        self.setWindowTitle("SASP Viewer (Pickles + RGB Responses)")

        # 1) Open both FITS:
        self.base_hdul   = fits.open(sasp_data_path,   mode="readonly", memmap=False)
        self.custom_hdul = fits.open(user_custom_path, mode="readonly", memmap=False)

        # 2) Build master lists from both
        self.pickles_templates = []
        self.filter_list       = []
        self.sensor_list       = []
        for hdul in (self.custom_hdul, self.base_hdul):
            for hdu in hdul:
                if not isinstance(hdu, fits.BinTableHDU):
                    continue
                c = hdu.header.get("CTYPE","").upper()
                e = hdu.header.get("EXTNAME","")
                if c == "SED":
                    self.pickles_templates.append(e)
                elif c == "FILTER":
                    self.filter_list.append(e)
                elif c == "SENSOR":
                    self.sensor_list.append(e)

        for lst in (self.pickles_templates, self.filter_list, self.sensor_list):
            lst.sort()

        self.rgb_filter_choices = ["(None)"] + self.filter_list

        # 4) Build the UI
        central = QWidget()
        self.setCentralWidget(central)
        vbox = QVBoxLayout()
        central.setLayout(vbox)

        row = QHBoxLayout()
        vbox.addLayout(row)

        # Star Template dropdown
        row.addWidget(QLabel("Star Template:"))
        self.star_combo = QComboBox()
        self.star_combo.addItems(self.pickles_templates)
        row.addWidget(self.star_combo)

        # R‐Filter dropdown
        row.addWidget(QLabel("R‐Filter:"))
        self.r_filter_combo = QComboBox()
        self.r_filter_combo.addItems(self.rgb_filter_choices)
        row.addWidget(self.r_filter_combo)

        # G‐Filter dropdown
        row.addWidget(QLabel("G‐Filter:"))
        self.g_filter_combo = QComboBox()
        self.g_filter_combo.addItems(self.rgb_filter_choices)
        row.addWidget(self.g_filter_combo)

        # B‐Filter dropdown
        row.addWidget(QLabel("B‐Filter:"))
        self.b_filter_combo = QComboBox()
        self.b_filter_combo.addItems(self.rgb_filter_choices)
        row.addWidget(self.b_filter_combo)

        # ——— LP/Cut filter & Sensor go on their own second row ———
        row2 = QHBoxLayout()
        vbox.addLayout(row2)

        row2.addWidget(QLabel("LP/Cut Filter1:"))
        self.lp_filter_combo = QComboBox()
        self.lp_filter_combo.addItems(self.rgb_filter_choices)
        row2.addWidget(self.lp_filter_combo)

        row2.addWidget(QLabel("LP/Cut Filter2:"))
        self.lp_filter_combo2 = QComboBox()
        self.lp_filter_combo2.addItems(self.rgb_filter_choices)
        row2.addWidget(self.lp_filter_combo2)

        row2.addSpacing(20)
        row2.addWidget(QLabel("Sensor (QE):"))
        self.sens_combo = QComboBox()
        self.sens_combo.addItems(self.sensor_list)
        row2.addWidget(self.sens_combo)

        # Plot button
        self.plot_btn = QPushButton("Plot")
        self.plot_btn.clicked.connect(self.update_plot)
        row.addWidget(self.plot_btn)

        # Matplotlib FigureCanvas
        self.figure = Figure(figsize=(9, 6))
        self.canvas = FigureCanvas(self.figure)
        vbox.addWidget(self.canvas)

        # 5) Initial plot
        self.update_plot()

    def load_any(self, extname, field):
        """
        Look for `extname` in custom_hdul first, then base_hdul.
        Returns the data[field] array as float.
        """
        for hdul in (self.custom_hdul, self.base_hdul):
            if extname in hdul:
                return hdul[extname].data[field].astype(float)
        raise KeyError(f"Extension '{extname}' not found")

    def update_plot(self):
        star_ext = self.star_combo.currentText()
        r_filt   = self.r_filter_combo.currentText()
        g_filt   = self.g_filter_combo.currentText()
        b_filt   = self.b_filter_combo.currentText()
        sens_ext = self.sens_combo.currentText()
        lp_ext1  = self.lp_filter_combo.currentText()      # ① first LP
        lp_ext2  = self.lp_filter_combo2.currentText()     # ② second LP  (NEW)

        # -- Load star SED --

        wl_star = self.load_any(star_ext, "WAVELENGTH")
        fl_star = self.load_any(star_ext, "FLUX")

        # -- Load sensor QE --
        wl_sens = self.load_any(sens_ext, "WAVELENGTH")
        qe_sens = self.load_any(sens_ext, "THROUGHPUT")

        # -- Build common 1 Å grid from 1150 to 10620 Å --
        wl_min, wl_max = 1150.0, 10620.0
        common_wl = np.arange(wl_min, wl_max + 1.0, 1.0)

        # -- Interpolate SED and QE onto common grid --
        sed_interp  = interp1d(wl_star, fl_star, kind="linear",
                               bounds_error=False, fill_value=0.0)
        sens_interp = interp1d(wl_sens, qe_sens, kind="linear",
                               bounds_error=False, fill_value=0.0)

        fl_common   = sed_interp(common_wl)    # star flux on common grid
        sens_common = sens_interp(common_wl)   # QE on common grid

        # -- For each of R, G, B, load filter if selected and build filter×QE×LP & response --
        rgb_data = {}
        for color, filt_name in (("red",   r_filt),
                                ("green", g_filt),
                                ("blue",  b_filt)):

            if filt_name == "(None)":
                rgb_data[color] = None
                continue

            # ---- channel filter -------------------------------------------------
            wl_filt = self.load_any(filt_name, "WAVELENGTH")
            tr_filt = self.load_any(filt_name, "THROUGHPUT")
            filt_interp = interp1d(wl_filt, tr_filt, bounds_error=False,
                                fill_value=0.0)
            filt_common = filt_interp(common_wl)

            # ---- LP / Cut filters (may be zero, one or two) ---------------------
            def lp_curve(ext):
                if ext == "(None)":
                    return np.ones_like(common_wl)
                wl_lp  = self.load_any(ext, "WAVELENGTH")
                tr_lp  = self.load_any(ext, "THROUGHPUT")
                return interp1d(wl_lp, tr_lp, bounds_error=False,
                                fill_value=0.0)(common_wl)

            T_LP = lp_curve(lp_ext1) * lp_curve(lp_ext2)    # ③ cascade the two curves

            # ---- system throughput & response -----------------------------------
            T_sys = filt_common * sens_common * T_LP
            resp  = fl_common * T_sys

            rgb_data[color] = {
                "filter_name": filt_name,
                "wl_filter":   wl_filt,
                "tr_filter":   tr_filt,
                "T_sys":       T_sys,
                "response":    resp
            }

        # -- Compute synthetic magnitudes for each channel relative to A0V --
        mag_texts = []
        if "A0V" in self.pickles_templates:
            # load_any will look in custom_hdul first, then base_hdul
            wl_veg = self.load_any("A0V", "WAVELENGTH")
            fl_veg = self.load_any("A0V", "FLUX")
            veg_interp = interp1d(wl_veg, fl_veg, kind="linear",
                                bounds_error=False, fill_value=0.0)
            fl_veg_c = veg_interp(common_wl)

            # Loop over color AND now correctly retrieve "filter_name" from rgb_data
            for color in ("red", "green", "blue"):
                data = rgb_data[color]
                if data is not None:
                    chan_filter = data["filter_name"]
                    resp_star = data["response"]
                    resp_veg  = fl_veg_c * data["T_sys"]
                    S_star = np.trapz(resp_star, x=common_wl)
                    S_veg  = np.trapz(resp_veg, x=common_wl)
                    if (S_veg > 0) and (S_star > 0):
                        mag = -2.5 * np.log10(S_star / S_veg)
                        mag_texts.append(f"{color[0].upper()}→{chan_filter}: {mag:.2f}")
                    else:
                        mag_texts.append(f"{color[0].upper()}→{chan_filter}: N/A")

        title_text = " | ".join(mag_texts) if mag_texts else "No channels selected"

        # -- Plotting --
        self.figure.clf()
        ax1 = self.figure.add_subplot(111)

        # (a) Plot star SED on left axis (in black)
        ax1.plot(common_wl, fl_common,
                 color="black", linewidth=1, label=f"{star_ext} SED")
        ax1.set_xlabel("Wavelength (Å)")
        ax1.set_ylabel("Flux (erg s⁻¹ cm⁻² Å⁻¹)", color="black")
        ax1.tick_params(axis="y", labelcolor="black")

        # (b) Plot each selected channel’s response (SED×Filter×QE) in yellow
        for color, data in rgb_data.items():
            if data is not None:
                ax1.plot(common_wl, data["response"],
                         color="gold", linewidth=1.5,
                         label=f"{color.upper()} Response")

        # Right‐hand axis for throughput curves
        ax2 = ax1.twinx()
        ax2.set_ylabel("Relative Throughput", color="red")
        ax2.tick_params(axis="y", labelcolor="red")
        ax2.set_ylim(0.0, 1.0)

        # (c) Plot each channel’s throughput (filter×QE) in matching dashed color
        if rgb_data["red"] is not None:
            ax2.plot(common_wl, rgb_data["red"]["T_sys"],
                     color="red", linestyle="--", linewidth=1,
                     label="R filter×QE")
        if rgb_data["green"] is not None:
            ax2.plot(common_wl, rgb_data["green"]["T_sys"],
                     color="green", linestyle="--", linewidth=1,
                     label="G filter×QE")
        if rgb_data["blue"] is not None:
            ax2.plot(common_wl, rgb_data["blue"]["T_sys"],
                     color="blue", linestyle="--", linewidth=1,
                     label="B filter×QE")

        ax1.set_xlim(wl_min, wl_max)
        ax1.grid(True, which="both", linestyle="--", alpha=0.3)
        self.figure.suptitle(title_text, fontsize=10)

        # Combine legends from both axes
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc="upper right")

        self.canvas.draw()


    def closeEvent(self, event):
        self.base_hdul.close()
        self.custom_hdul.close()
        super().closeEvent(event)

def pickles_match_for_simbad(simbad_sp: str, available_extnames: List[str]) -> List[str]:
    """
    Given a SIMBAD‐style spectral type (e.g. "A", "A3", "A3V", "M0V", "kA3hF0mF3", etc.)
    and a list of available Pickles EXTNAMEs (like ["A5III","A5V","A7III","B0V","G5V","M0V",...]),
    return a **list** of one or more EXTNAMEs that best match.

    Strategy:

      1) Normalize SIMBAD string to uppercase, strip whitespace.
      2) Use regex to extract:
         - letter_class:  O, B, A, F, G, K, M, …  (first letter),
         - numeric_subtype: integer 0–9 (if present),
         - lum_class: one of I, II, III, IV, V, etc. (if present—commonly 'V' or 'III').
      3) Search in available_extnames for:
         a)  Exact match: e.g.  SIMBAD="A3V"  →  look for `"A3V"` in available_extnames.
         b)  If no exact lif it, try “same letter+luminosity, nearest numeric.” E.g. SIMBAD="A3V"
             → collect all `ext for ext in available_extnames if ext.startswith("A") and ext.endswith("V")`,
             parse their numeric part, pick whichever numeric is closest to 3.
         c)  If still nothing (maybe no “A?V” templates exist), try “same letter, any luminosity”—
             pick nearest numeric. E.g. SIMBAD="A3V" but you only have “A3III” or “A0III” or “A7III” or “A0V”:
             compare absolute difference |3 – subtype|.
         d)  If SIMBAD gave you only a single letter (e.g. “A”), gather all extnames that begin with “A” (e.g. “A0V”, “A3V”, “A5III”…). 
             You could return them all (and average their SEDs), or choose a canonical one (e.g. “A0V”). Here we return _all_ of them so the caller can decide to average. 
      4) Return a list of 0, 1, or multiple EXTNAME strings. (0 only if literally no “A…” templates exist.)
    """

    sp = simbad_sp.strip().upper()

    # Step 1: Early bail if not a “classic” stellar type
    # For example, “SN” or “WD” or “C?” might not match Pickles. You can decide to skip them.
    # Here we just try to parse anything that starts with [OBAFGKMLT]…
    if not sp:
        return []

    # Regular expression to capture: letter (A–Z), optional digit (0–9), optional luminosity (I, II, III, IV, V)
    # e.g. "A3V", "K0III", "M1V", "F", "B9", "G5III", etc.
    m = re.match(r"^([OBAFGKMLT])(\d?)(I{1,3}|IV|V)?", sp)
    if not m:
        # Could not parse into letter+digit+lum, so return empty
        return []

    letter_class = m.group(1)    # e.g. "A"
    digit_part   = m.group(2)    # e.g. "3" or "" if none
    lum_part     = m.group(3)    # e.g. "V", "III", or None

    # Convert digit to integer or None
    if digit_part != "":
        subclass = int(digit_part)
    else:
        subclass = None

    # Make a helper to parse an EXTNAME like “A5V” → (letter="A", subtype=5, lum="V")
    def parse_pickles_extname(ext: str):
        ext = ext.strip().upper()
        # Pickles EXTNAMEs in your SASP_data should be like: "A5III", "A5V", "B0I", "B0V", "F5V", "G5V", “M0V”, etc.
        m2 = re.match(r"^([OBAFGKMLT])(\d+)(I{1,3}|IV|V)$", ext)
        if not m2:
            return None, None, None
        letter2  = m2.group(1)            # e.g. "A"
        digit2   = int(m2.group(2))       # e.g. 5
        lum2     = m2.group(3)            # e.g. "V", "III", ...
        return letter2, digit2, lum2

    # Build a list of all (extname, (letter2, digit2, lum2)) for quick lookup
    parsed_templates = []
    for ext in available_extnames:
        letter2, digit2, lum2 = parse_pickles_extname(ext)
        if letter2 is None:
            continue
        parsed_templates.append((ext, letter2, digit2, lum2))

    # STEP 2: look for an **exact** extname match if SIMBAD gave one
    if subclass is not None and lum_part is not None:
        attempt_exact = f"{letter_class}{subclass}{lum_part}"
        if attempt_exact in available_extnames:
            return [attempt_exact]

    # STEP 3: collect all candidates that have the same “letter_class.” We will score by numeric closeness.
    #    If SIMBAD gave a lum_part (e.g. "V"), first try to match that subset.
    same_letter_and_lum = []
    same_letter_any_lum   = []
    for (ext, letter2, digit2, lum2) in parsed_templates:
        if letter2 != letter_class:
            continue
        if lum_part is not None and lum2 == lum_part:
            same_letter_and_lum.append((ext, digit2))
        else:
            same_letter_any_lum.append((ext, digit2))

    def pick_nearest(candidates: List[tuple[str,int]], target_sub: int) -> List[str]:
        """
        Given a list of (extname, subtype_int) and an integer target_sub,
        return the extname(s) whose subtype_int is closest to target_sub.
        If multiple templates tie at equal distance, return all of them.
        """
        if not candidates or target_sub is None:
            return []

        # Compute absolute distance for each
        arr = np.array([abs(digit2 - target_sub) for (_, digit2) in candidates])
        min_dist = np.min(arr)
        # Return all extnames whose distance == min_dist
        return [candidates[i][0] for i in np.where(arr == min_dist)[0]]

    # A) If we have letter + digit + lum, try step‐3a:
    if subclass is not None and lum_part is not None:
        if same_letter_and_lum:
            # pick the one(s) with nearest numeric subclass
            best = pick_nearest(same_letter_and_lum, subclass)
            return best
        # else: no same‐letter same‐lum candidates exist → fall back to same letter any lum
        if same_letter_any_lum:
            return pick_nearest(same_letter_any_lum, subclass)

    # B) If we have letter + digit but NO lum (e.g. SIMBAD="A3"):
    if subclass is not None and lum_part is None:
        # first try to find all templates of that letter that have a numeric digit (any lum)
        if same_letter_any_lum:
            return pick_nearest(same_letter_any_lum, subclass)

    # C) If SIMBAD gave only a letter (e.g. "A"):
    #    Return all “letter_class” templates for caller to average or pick one arbitrarily.
    #    (If you want a canonical single pick, you could choose to return only the one with digit closest to 0 or 5.)
    if subclass is None and lum_part is None:
        # all extnames whose letter2 == letter_class
        all_same_letter = [ext for (ext, letter2, _, _) in parsed_templates if letter2 == letter_class]
        return sorted(all_same_letter)

    # D) If SIMBAD gave letter+lum but no digit (e.g. "M V")—very rare—treat same as case C except filter by lum:
    if subclass is None and lum_part is not None:
        candidates = [ (ext, digit2) for (ext, letter2, digit2, lum2) in parsed_templates
                       if letter2 == letter_class and lum2 == lum_part ]
        if candidates:
            # If there are multiple subtypes, return them all (caller may average or pick median)
            return sorted([ext for (ext, _) in candidates])
        # otherwise fall back to “letter only” case:
        return sorted([ext for (ext, letter2, _, _) in parsed_templates if letter2 == letter_class])

    # Fallback: no match at all
    return []

def compute_gradient_map(sources, delta_flux, shape, method="poly2"):
    """
    sources:    Nx2 array of (x_i, y_i)
    delta_flux: length-N array of measured/expected ratio or Δ values
    shape:      (H, W) of the image
    method:     "poly2", "poly3", or "rbf"
    returns:    background_map of shape (H, W)
    """
    H, W = shape
    xs, ys = sources[:, 0], sources[:, 1]

    # 2nd-order polynomial
    if method == "poly2":
        A = np.vstack([
            np.ones_like(xs), xs, ys,
            xs**2, xs*ys, ys**2
        ]).T
        coeffs, *_ = np.linalg.lstsq(A, delta_flux, rcond=None)
        YY, XX = np.mgrid[0:H, 0:W]
        B = (
            coeffs[0]
          + coeffs[1] * XX + coeffs[2] * YY
          + coeffs[3] * XX**2 + coeffs[4] * XX * YY + coeffs[5] * YY**2
        )
        return B

    # 3rd-order polynomial
    elif method == "poly3":
        A = np.vstack([
            np.ones_like(xs), xs, ys,
            xs**2, xs*ys, ys**2,
            xs**3, xs**2 * ys, xs * ys**2, ys**3
        ]).T
        coeffs, *_ = np.linalg.lstsq(A, delta_flux, rcond=None)
        YY, XX = np.mgrid[0:H, 0:W]
        B = (
            coeffs[0]
          + coeffs[1] * XX + coeffs[2] * YY
          + coeffs[3] * XX**2 + coeffs[4] * XX * YY + coeffs[5] * YY**2
          + coeffs[6] * XX**3 + coeffs[7] * XX**2 * YY
          + coeffs[8] * XX * YY**2 + coeffs[9] * YY**3
        )
        return B

    # radial basis function interpolation (fast, smooth)
    elif method == "rbf":
        # use the newer RBFInterpolator for speed and smoothing
        pts = np.vstack([xs, ys]).T  # shape (N,2)
        # smoothing >0 yields faster, smoother fits; tweak as needed
        rbfi = RBFInterpolator(pts, delta_flux,
                               kernel="thin_plate_spline",
                               smoothing=1.0)
        YY, XX = np.mgrid[0:H, 0:W]
        grid_pts = np.vstack([XX.ravel(), YY.ravel()]).T
        B = rbfi(grid_pts).reshape(H, W)
        return B

    else:
        raise ValueError(f"Unknown method '{method}', must be 'poly2','poly3', or 'rbf'")

class SFCCDialog(QDialog):
    """
    A dialog for Spectral Flux Color Calibration (SFCC).
    Allows:
      1. Fetching stars via Simbad (populate star dropdown),
      2. Selecting R, G, B filters and a sensor QE curve,
      3. Running the SFCC algorithm and plotting results.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Spectral Flux Color Calibration")
        self.setMinimumSize(800, 600)

        # ——— Fetch “active slot” image & header from the parent’s ImageManager ———
        self.current_image = None
        self.current_header = None

        # Orientation label (just for debugging)
        self.orientation_label = QLabel("Orientation: N/A")
        self.sasp_viewer_window = None

        self.main_win = parent

        # Keep a handle back to the main SASP_data HDUList
        # (we assume the parent has already opened SASP_data.fits in self.hdul)
        # Make sure `sasp_data_path` is defined somewhere earlier
        self.sasp_data_path = sasp_data_path


        # open (or create) a user‐writable FITS in ~/.local/share/…

        app_data = QStandardPaths.writableLocation(
            QStandardPaths.StandardLocation.AppDataLocation
        )
        os.makedirs(app_data, exist_ok=True)
        self.user_custom_path = os.path.join(app_data, "usercustomcurves.fits")
        if not os.path.exists(self.user_custom_path):
            # create an empty FITS if it doesn't exist yet
            fits.HDUList([fits.PrimaryHDU()]).writeto(self.user_custom_path)
        # open for update


        # now build your lists off both:
        self._reload_hdu_lists()

        # Placeholder: will be populated by fetch_stars()
        self.star_list = []

        # Build the UI (all combo-boxes get created inside _build_ui())
        self._build_ui()

        # ——— After UI is built, load any saved QSettings for these dropdowns ———
        self.load_settings()

        # ——— Connect signals so that changing any combo immediately writes to QSettings ———
        self.r_filter_combo.currentIndexChanged.connect(self.save_r_filter_setting)
        self.g_filter_combo.currentIndexChanged.connect(self.save_g_filter_setting)
        self.b_filter_combo.currentIndexChanged.connect(self.save_b_filter_setting)
        self.lp_filter_combo.currentIndexChanged.connect(self.save_lp_setting)
        self.lp_filter_combo2.currentIndexChanged.connect(self.save_lp2_setting)
        self.sens_combo.currentIndexChanged.connect(self.save_sensor_setting)
        # (If you also want to remember which “White Reference” star was chosen, connect star_combo as well)
        self.star_combo.currentIndexChanged.connect(self.save_star_setting)


    def _build_ui(self):
        layout = QVBoxLayout(self)

        # ——— Row 1: “Fetch Stars” button + “Select White Reference” dropdown ———
        row1 = QHBoxLayout()
        layout.addLayout(row1)

        # “Fetch Stars” button
        self.fetch_stars_btn = QPushButton("Step1: Fetch Stars from Image")
        self.fetch_stars_btn.clicked.connect(self.fetch_stars)
        # make the text bold:
        font = self.fetch_stars_btn.font()
        font.setBold(True)
        self.fetch_stars_btn.setFont(font)
        row1.addWidget(self.fetch_stars_btn)

        row1.addSpacing(20)

        # “Open SASP Viewer” button
        self.open_sasp_btn = QPushButton("Open SASP Viewer")
        self.open_sasp_btn.clicked.connect(self.open_sasp_viewer)
        row1.addWidget(self.open_sasp_btn)

        # Spacing
        row1.addSpacing(40)

        row1.addWidget(QLabel("Select White Reference:"))
        self.star_combo = QComboBox()
        # 1) First item is always Vega (A0V)
        self.star_combo.addItem("Vega (A0V)", userData="A0V")
        # 2) Then add all other Pickles‐SED templates, skipping “A0V” itself
        for sed in self.sed_list:
            if sed.upper() == "A0V":
                continue
            self.star_combo.addItem(sed, userData=sed)
        row1.addWidget(self.star_combo)
        idx_g2v = self.star_combo.findData("G2V")
        if idx_g2v >= 0:
            self.star_combo.setCurrentIndex(idx_g2v)
        # ——— Row 2: Filter dropdowns for R, G, B ———
        row2 = QHBoxLayout()
        layout.addLayout(row2)

        row2.addWidget(QLabel("R Filter:"))
        self.r_filter_combo = QComboBox()
        self.r_filter_combo.addItem("(None)")
        self.r_filter_combo.addItems(self.filter_list)
        row2.addWidget(self.r_filter_combo)

        row2.addSpacing(20)
        row2.addWidget(QLabel("G Filter:"))
        self.g_filter_combo = QComboBox()
        self.g_filter_combo.addItem("(None)")
        self.g_filter_combo.addItems(self.filter_list)
        row2.addWidget(self.g_filter_combo)

        row2.addSpacing(20)
        row2.addWidget(QLabel("B Filter:"))
        self.b_filter_combo = QComboBox()
        self.b_filter_combo.addItem("(None)")
        self.b_filter_combo.addItems(self.filter_list)
        row2.addWidget(self.b_filter_combo)

        # ——— Row 3: Sensor/QE dropdown ———
        row3 = QHBoxLayout()
        layout.addLayout(row3)
        row3.addStretch()
        row3.addWidget(QLabel("Sensor (QE):"))
        self.sens_combo = QComboBox()
        self.sens_combo.addItem("(None)")
        self.sens_combo.addItems(self.sensor_list)
        row3.addWidget(self.sens_combo)

        # ——— Stacked LP/Cut filter dropdown ———
        row3.addSpacing(20)
        row3.addWidget(QLabel("LP/Cut Filter1:"))
        self.lp_filter_combo = QComboBox()
        self.lp_filter_combo.addItem("(None)")
        self.lp_filter_combo.addItems(self.filter_list)
        row3.addWidget(self.lp_filter_combo)
        row3.addSpacing(20)
        row3.addWidget(QLabel("LP/Cut Filter2:"))
        self.lp_filter_combo2 = QComboBox()
        self.lp_filter_combo2.addItem("(None)")
        self.lp_filter_combo2.addItems(self.filter_list)
        row3.addWidget(self.lp_filter_combo2)        
        row3.addStretch()


        # ——— Row 4: “Run Calibration” + “Close” ———
        row4 = QHBoxLayout()
        layout.addLayout(row4)

        self.run_spcc_btn = QPushButton("Step2: Run Color Calibration")
        self.run_spcc_btn.clicked.connect(self.run_spcc)
        # make the text bold:
        font2 = self.run_spcc_btn.font()
        font2.setBold(True)
        self.run_spcc_btn.setFont(font2)
        row4.addWidget(self.run_spcc_btn)

        self.neutralize_chk = QCheckBox("Background Neutralization")
        self.neutralize_chk.setChecked(True)          # default = ON  (pick what you like)
        row4.addWidget(self.neutralize_chk)

        # NEW: Run Gradient Extraction
        self.run_grad_btn = QPushButton("Run Gradient Extraction (Beta)")
        font3 = self.run_grad_btn.font()
        font3.setBold(True)
        self.run_grad_btn.setFont(font3)
        self.run_grad_btn.clicked.connect(self.run_gradient_extraction)
        row4.addWidget(self.run_grad_btn)

        #row4.addWidget(QLabel("Gradient Model:"))
        self.grad_method_combo = QComboBox()
        self.grad_method_combo.addItems(["poly2", "poly3", "rbf"])
        self.grad_method_combo.setCurrentText("poly3")          # default
        row4.addWidget(self.grad_method_combo)

        row4.addStretch()
        self.add_curve_btn = QPushButton("Add Custom Filter/Sensor Curve…")
        self.add_curve_btn.clicked.connect(self.add_custom_curve)
        row4.addWidget(self.add_curve_btn)

        self.remove_curve_btn = QPushButton("Remove Filter/Sensor Curve…")
        self.remove_curve_btn.clicked.connect(self.remove_custom_curve)
        row4.addWidget(self.remove_curve_btn)        

        row4.addStretch()
        self.close_btn = QPushButton("Close")
        self.close_btn.clicked.connect(self.close)
        row4.addWidget(self.close_btn)

        # ——— Count label (number of stars fetched) ———
        self.count_label = QLabel("")  # Will be updated after fetch_stars()
        layout.addWidget(self.count_label)

        # ——— Bottom: Matplotlib canvas for showing result curves / histogram ———
        self.figure = Figure(figsize=(5, 4))
        self.canvas = FigureCanvas(self.figure)
        self.canvas.setVisible(False)      # hide it initially
        layout.addWidget(self.canvas, stretch=1)

        self.reset_btn = QPushButton("Reset SFCC")
        self.reset_btn.clicked.connect(self.reset_sfcc)
        layout.addWidget(self.reset_btn)        

        # 1)  Simply hide or show on demand
        self.run_grad_btn.hide()          # not drawn, doesn’t take layout space
        self.grad_method_combo.hide()
        self.grad_method = "poly3"
        self.grad_method_combo.currentTextChanged.connect(
            lambda m: setattr(self, "grad_method", m))

    # ——— QSettings helpers ———

    def _reload_hdu_lists(self):
        # 1) pickles SEDs come only from the main SASP_data.fits
        self.sed_list = []
        with fits.open(self.sasp_data_path, mode="readonly", memmap=False) as base:
            for hdu in base:
                if isinstance(hdu, fits.BinTableHDU) and hdu.header.get("CTYPE","").upper()=="SED":
                    self.sed_list.append(hdu.header["EXTNAME"])
        # 2) filters/sensors come from BOTH files
        self.filter_list = []
        self.sensor_list = []
        for path in (self.sasp_data_path, self.user_custom_path):
            with fits.open(path, mode="readonly", memmap=False) as hdul:
                for hdu in hdul:
                    if not isinstance(hdu, fits.BinTableHDU):
                        continue
                    c = hdu.header.get("CTYPE","").upper()
                    e = hdu.header.get("EXTNAME","")
                    if c=="FILTER":
                        self.filter_list.append(e)
                    elif c=="SENSOR":
                        self.sensor_list.append(e)
        # sort them
        self.sed_list.sort()
        self.filter_list.sort()
        self.sensor_list.sort()

    def load_settings(self):
        """
        Read previously saved comboBox selections from QSettings
        and apply them (if they still exist in the list).
        """
        settings = QSettings()

        # 1) Star selection (white reference)
        saved_star = settings.value("SFCC/WhiteReference", "")
        if saved_star:
            idx = self.star_combo.findText(saved_star)
            if idx != -1:
                self.star_combo.setCurrentIndex(idx)

        # 2) R filter
        saved_r = settings.value("SFCC/RFilter", "")
        if saved_r:
            idx = self.r_filter_combo.findText(saved_r)
            if idx != -1:
                self.r_filter_combo.setCurrentIndex(idx)

        # 3) G filter
        saved_g = settings.value("SFCC/GFilter", "")
        if saved_g:
            idx = self.g_filter_combo.findText(saved_g)
            if idx != -1:
                self.g_filter_combo.setCurrentIndex(idx)

        # 4) B filter
        saved_b = settings.value("SFCC/BFilter", "")
        if saved_b:
            idx = self.b_filter_combo.findText(saved_b)
            if idx != -1:
                self.b_filter_combo.setCurrentIndex(idx)

        # 5) Sensor/QE
        saved_sensor = settings.value("SFCC/Sensor", "")
        if saved_sensor:
            idx = self.sens_combo.findText(saved_sensor)
            if idx != -1:
                self.sens_combo.setCurrentIndex(idx)

        # 6) LP/Cut filter
        saved_lp = settings.value("SFCC/LPFilter", "")
        if saved_lp:
            idx = self.lp_filter_combo.findText(saved_lp)
            if idx != -1:
                self.lp_filter_combo.setCurrentIndex(idx)

        saved_lp2 = settings.value("SFCC/LPFilter2", "")
        if saved_lp2:
            idx = self.lp_filter_combo2.findText(saved_lp2)
            if idx != -1:
                self.lp_filter_combo2.setCurrentIndex(idx)

    def save_lp_setting(self, index):
        """Write the currently selected LP/Cut filter into QSettings."""
        current = self.lp_filter_combo.currentText()
        QSettings().setValue("SFCC/LPFilter", current)

    def save_lp2_setting(self, index):
        """Write the currently selected LP/Cut filter into QSettings."""
        current = self.lp_filter_combo2.currentText()
        QSettings().setValue("SFCC/LPFilter2", current)

    def save_star_setting(self, index):
        """
        Write the currently selected “White Reference” star into QSettings.
        """
        current = self.star_combo.currentText()
        QSettings().setValue("SFCC/WhiteReference", current)


    def save_r_filter_setting(self, index):
        """
        Write the currently selected R‐filter into QSettings.
        """
        current = self.r_filter_combo.currentText()
        QSettings().setValue("SFCC/RFilter", current)


    def save_g_filter_setting(self, index):
        """
        Write the currently selected G‐filter into QSettings.
        """
        current = self.g_filter_combo.currentText()
        QSettings().setValue("SFCC/GFilter", current)


    def save_b_filter_setting(self, index):
        """
        Write the currently selected B‐filter into QSettings.
        """
        current = self.b_filter_combo.currentText()
        QSettings().setValue("SFCC/BFilter", current)


    def save_sensor_setting(self, index):
        """
        Write the currently selected sensor/QE curve into QSettings.
        """
        current = self.sens_combo.currentText()
        QSettings().setValue("SFCC/Sensor", current)

    def interpolate_bad_points(self, wl, tr):
        """
        Finds indices where tr < 0 or tr > 1.
        Interpolates only those indices (bad points) based on their two nearest good neighbors.
        Returns a corrected transmission array.
        """
        tr = tr.copy()
        bad = (tr < 0.0) | (tr > 1.0)
        good = ~bad

        if not np.any(bad):
            # No anomalies to fix
            return tr, np.array([], dtype=int)

        # If there are fewer than 2 good points, we can't interpolate
        if np.sum(good) < 2:
            raise RuntimeError("Not enough valid data to interpolate anomalies. Need at least 2 good points.")

        # Perform 1-D linear interpolation at the bad wavelengths only:
        #   - np.interp(wl[bad], wl[good], tr[good]) will give corrected values for the bad indices.
        tr_corr = tr.copy()
        tr_corr[bad] = np.interp(wl[bad], wl[good], tr[good])

        return tr_corr, np.where(bad)[0]


    def smooth_curve(self, tr, window_size=5):
        """
        Applies a median filter of specified window_size (must be odd).
        Only to remove isolated single‐pixel spikes, not to overly blur the entire curve.
        Returns the smoothed array.
        """
        # medfilt pads edges automatically in SciPy ≥1.6; 
        # if you get a warning, ensure window_size is odd.
        return medfilt(tr, kernel_size=window_size)

    def get_calibration_points(self, rgb_img: np.ndarray):
        """
        Show the RGB image and let the user click exactly three points:
        1) (λ_min, resp_min)  [bottom‐left]
        2) (λ_max, resp_min)  [bottom‐right]
        3) (λ_min, resp_max)  [top‐left]

        Returns:
            (px_bl, py_bl), (px_br, py_br), (px_tl, py_tl)
        """
        print("\nClick three calibration points in this order:")
        print("  1) λ_min / resp_min  [bottom‐left]")
        print("  2) λ_max / resp_min  [bottom‐right]")
        print("  3) λ_min / resp_max  [top‐left]\n")

        fig, ax = plt.subplots(figsize=(8, 5))
        ax.imshow(rgb_img)
        ax.set_title("Click 3 calibration points, then close this window")

        pts = plt.ginput(3, timeout=-1)
        plt.close(fig)

        if len(pts) != 3:
            raise RuntimeError("Error: Need exactly three clicks for calibration.")
        return pts[0], pts[1], pts[2]


    def build_transforms(self, px_bl, py_bl, px_br, py_br, px_tl, py_tl,
                        λ_min, λ_max, resp_min, resp_max):
        """
        Build two linear mapping functions:
        px_to_λ(px)    → wavelength (nm)
        py_to_resp(py) → response (0..1)

        Calibration points:
        (px_bl, py_bl) → (λ_min, resp_min)
        (px_br, py_br) → (λ_max, resp_min)
        (px_tl, py_tl) → (λ_min, resp_max)
        """
        nm_per_px = (λ_max - λ_min) / (px_br - px_bl)
        resp_per_px = (resp_max - resp_min) / (py_bl - py_tl)

        def px_to_λ(px):
            return λ_min + (px - px_bl) * nm_per_px

        def py_to_resp(py):
            return resp_max - (py - py_tl) * resp_per_px

        return px_to_λ, py_to_resp


    def extract_curve(self, gray_img: np.ndarray,
                    λ_mapper: callable,
                    resp_mapper: callable,
                    λ_min: float,
                    λ_max: float,
                    threshold: int = 50):
        """
        For each column x = 0..(W-1):
        1) Find py_min = argmin(gray_img[:, x])  → the darkest pixel in that column.
        2) If gray_img[py_min, x] < threshold and λ = λ_mapper(x) is in [λ_min, λ_max]:
            keep (λ, response = resp_mapper(py_min))
        3) Otherwise, skip that column.

        Returns a DataFrame with columns:
        'wavelength_nm' (float), 'response' (float 0..1),
        clipped to [λ_min, λ_max] and containing endpoints exactly at (λ_min, 0) and (λ_max, 0).
        """
        H, W = gray_img.shape
        data = []

        for px in range(W):
            column = gray_img[:, px]
            py_min = int(np.argmin(column))
            val_min = int(column[py_min])

            if val_min < threshold:
                λ = λ_mapper(px)
                if λ_min <= λ <= λ_max:
                    resp = resp_mapper(py_min)
                    data.append((λ, resp))

        if not data:
            raise RuntimeError(
                "No dark pixels found within threshold. "
                "Try raising `threshold` or adjusting your clicks."
            )

        df = pd.DataFrame(data, columns=["wavelength_nm", "response"])
        df = df.sort_values("wavelength_nm").reset_index(drop=True)

        # Clip strictly to [λ_min, λ_max]
        df = df[(df["wavelength_nm"] >= λ_min) & (df["wavelength_nm"] <= λ_max)].copy()

        # Ensure endpoints (λ_min, 0.0) and (λ_max, 0.0) exist
        if df["wavelength_nm"].iloc[0] > λ_min:
            df = pd.concat(
                [pd.DataFrame([[λ_min, 0.0]], columns=["wavelength_nm", "response"]), df],
                ignore_index=True
            )

        if df["wavelength_nm"].iloc[-1] < λ_max:
            df = pd.concat(
                [df,
                pd.DataFrame([[λ_max, 0.0]], columns=["wavelength_nm", "response"])],
                ignore_index=True
            )

        df = df.sort_values("wavelength_nm").reset_index(drop=True)
        return df

    def add_custom_curve(self):
        """
        Add a custom filter / sensor curve via one of two methods:

        • Import from a 2-column CSV   (λ_nm , response 0-1)
        • Digitize an image (existing 3-click workflow)

        The user first chooses the method; the rest proceeds accordingly.
        """

        # ──────────────────────────────────────────────────────────────────
        # 0)  Ask user which method
        # -----------------------------------------------------------------
        msg = QMessageBox(self)
        msg.setWindowTitle("Add Custom Curve")
        msg.setText("Choose how you want to add the curve:")

        csv_btn = msg.addButton("Import CSV",
                                QMessageBox.ButtonRole.AcceptRole)
        img_btn = msg.addButton("Digitize Image",
                                QMessageBox.ButtonRole.AcceptRole)
        cancel_btn = msg.addButton(QMessageBox.StandardButton.Cancel)

        msg.exec()

        if msg.clickedButton() == csv_btn:
            self._import_curve_from_csv()
        elif msg.clickedButton() == img_btn:
            self._digitize_curve_from_image()
        else:
            return  # user cancelled



    # ────────────────────────────────────────────────────────────────────
    # 1)  CSV ROUTE  (complete)
    # --------------------------------------------------------------------
    def _import_curve_from_csv(self):
        csv_path, _ = QFileDialog.getOpenFileName(
            self, "Select 2-column CSV (λ_nm, response)", "",
            "CSV Files (*.csv);;All Files (*)")
        if not csv_path:
            return                                     # user cancelled

        # --- read CSV (no header, ignore comments) ----------------------
        try:
            # 1st attempt: assume NO header
            df = (pd.read_csv(csv_path, comment="#", header=None)
                    .iloc[:, :2]                   # keep first two cols
                    .dropna())
            df.columns = ["wavelength_nm", "response"]
            # make sure cast to float succeeds; will raise if header words present
            wl_nm = df["wavelength_nm"].astype(float).to_numpy()
            tp    = df["response"].astype(float).to_numpy()

        except ValueError:
            # retry assuming the FIRST row *is* a header
            try:
                df = (pd.read_csv(csv_path, comment="#", header=0)
                        .iloc[:, :2]
                        .dropna())
                df.columns = ["wavelength_nm", "response"]
                wl_nm = df["wavelength_nm"].astype(float).to_numpy()
                tp    = df["response"].astype(float).to_numpy()
            except Exception as e2:
                QMessageBox.critical(self, "CSV Error",
                    f"Could not read CSV (even with header row):\n{e2}")
                return
        except Exception as e:
            QMessageBox.critical(self, "CSV Error",
                f"Could not read CSV:\n{e}")
            return

        # --- ask name / channel ----------------------------------------
        ok, extname_base, channel_val = self._query_name_channel()
        if not ok:
            return

        # --- nm → Å arrays ---------------------------------------------
        wl_ang   = (wl_nm * 10.0).astype(np.float32)
        tr_final = tp.astype(np.float32)

        # --- build HDU & append ----------------------------------------
        self._append_curve_hdu(
            wl_ang   = wl_ang,
            tr_final = tr_final,
            extname  = extname_base,
            ctype    = "SENSOR" if channel_val == "Q" else "FILTER",
            origin   = f"CSV:{os.path.basename(csv_path)}"
        )

        # refresh UI
        self._reload_hdu_lists()
        self.refresh_filter_sensor_lists()
        QMessageBox.information(
            self, "Done",
            f"CSV curve '{extname_base}' added."
        )



    # ────────────────────────────────────────────────────────────────────
    # 2)  IMAGE-DIGITIZE ROUTE  (original workflow, intact)
    # --------------------------------------------------------------------
    def _digitize_curve_from_image(self):
        # Step 1: pick image
        img_path_str, _ = QFileDialog.getOpenFileName(
            self, "Select Curve Image to Digitize", "",
            "Images (*.png *.jpg *.jpeg *.bmp);;All Files (*)")
        if not img_path_str:
            return
        img_filename = os.path.basename(img_path_str)

        # Step 2: load image
        try:
            bgr = cv2.imread(img_path_str)
            if bgr is None:
                raise RuntimeError(f"cv2.imread returned None for '{img_path_str}'")
            rgb_img  = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
            gray_img = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Could not load image:\n{e}")
            return

        # Step 3: Digitize 3 calibration points
        try:
            (px_bl, py_bl), (px_br, py_br), (px_tl, py_tl) = self.get_calibration_points(rgb_img)
        except Exception as e:
            QMessageBox.critical(self, "Digitization Error", str(e))
            return

        # Step 4: λ_min / λ_max
        λ_min_str, ok1 = QInputDialog.getText(self, "λ_min", "Enter λ_min (in nm):")
        λ_max_str, ok2 = QInputDialog.getText(self, "λ_max", "Enter λ_max (in nm):")
        if not (ok1 and ok2 and λ_min_str.strip() and λ_max_str.strip()):
            return
        try:
            λ_min = float(λ_min_str);  λ_max = float(λ_max_str)
        except ValueError:
            QMessageBox.critical(self, "Input Error", "λ_min and λ_max must be numbers.")
            return

        # Step 5: name / channel
        ok, extname_base, channel_val = self._query_name_channel()
        if not ok:
            return

        # Step 6: Build transforms
        px_to_λ, py_to_resp = self.build_transforms(
            px_bl, py_bl, px_br, py_br, px_tl, py_tl,
            λ_min, λ_max, 0.0, 1.0)

        # Step 7: extract curve points
        try:
            df_curve = self.extract_curve(gray_img, px_to_λ, py_to_resp,
                                        λ_min, λ_max, threshold=50)
        except Exception as e:
            QMessageBox.critical(self, "Extraction Error", str(e))
            return

        # Step 8: aggregate, interpolate, smooth
        df_curve["wl_int"] = df_curve["wavelength_nm"].round().astype(int)
        grp = (df_curve.groupby("wl_int")["response"]
                    .median()
                    .reset_index()
                    .sort_values("wl_int"))
        wl = grp["wl_int"].to_numpy(dtype=int)
        tr = grp["response"].to_numpy(dtype=float)

        try:
            tr_corr, _ = self.interpolate_bad_points(wl, tr)
        except Exception as e:
            QMessageBox.critical(self, "Interpolation Error", str(e))
            return

        tr_smoothed = self.smooth_curve(tr_corr, window_size=5)

        # Step 9: nm → Å  arrays
        wl_ang   = (wl.astype(float) * 10.0).astype(np.float32)
        tr_final = tr_smoothed.astype(np.float32)

        # Step 10: append HDU
        self._append_curve_hdu(
            wl_ang   = wl_ang,
            tr_final = tr_final,
            extname  = extname_base,
            ctype    = "SENSOR" if channel_val == "Q" else "FILTER",
            origin   = f"UserDefined:{img_filename}"
        )

        self._reload_hdu_lists()
        self.refresh_filter_sensor_lists()
        QMessageBox.information(
            self, "Done",
            f"Added curve '{extname_base}'."
        )



    # ────────────────────────────────────────────────────────────────────
    # Helper: ask for name / channel
    # --------------------------------------------------------------------
    def _query_name_channel(self):
        name_str, ok1 = QInputDialog.getText(
            self, "Curve Name", "Enter curve name (EXTNAME):")
        if not (ok1 and name_str.strip()):
            return False, None, None
        extname = name_str.strip().upper().replace(" ", "_")

        ch_str, ok2 = QInputDialog.getText(
            self, "Channel", "Enter channel (R,G,B or Q for sensor):")
        if not (ok2 and ch_str.strip()):
            return False, None, None
        return True, extname, ch_str.strip().upper()



    # ────────────────────────────────────────────────────────────────────
    # Helper: append HDU to user_custom_path
    # --------------------------------------------------------------------
    def _append_curve_hdu(self, wl_ang, tr_final, extname, ctype, origin):
        col_wl = fits.Column(name="WAVELENGTH", format="E", unit="Angstrom", array=wl_ang)
        col_tr = fits.Column(name="THROUGHPUT", format="E", unit="REL",      array=tr_final)
        new_hdu = fits.BinTableHDU.from_columns([col_wl, col_tr])
        new_hdu.header["EXTNAME"] = extname
        new_hdu.header["CTYPE"]   = ctype
        new_hdu.header["ORIGIN"]  = origin
        with fits.open(self.user_custom_path, mode="update", memmap=False) as hdul:
            hdul.append(new_hdu)
            hdul.flush()

    def remove_custom_curve(self):
        """
        1) Offer the user a list of all current FILTER+SENSOR names.
        2) If they pick one, rebuild the FITS without that EXTNAME.
        3) Atomically replace the old file, then reload.
        """
        all_curves = self.filter_list + self.sensor_list
        if not all_curves:
            QMessageBox.information(self, "Remove Curve", "No custom curves to remove.")
            return

        curve, ok = QInputDialog.getItem(
            self,
            "Remove Curve",
            "Select a FILTER or SENSOR curve to delete:",
            all_curves, 0, False
        )
        if not ok or not curve:
            return

        reply = QMessageBox.question(
            self,
            "Confirm Deletion",
            f"Delete '{curve}'?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply != QMessageBox.StandardButton.Yes:
            return

        temp_path = self.user_custom_path + ".tmp"
        try:
            # 1) Read entire file into memory
            with fits.open(self.user_custom_path, memmap=False) as old_hdul:
                # 2) Build a fresh list of HDUs we want to keep
                new_hdus = []
                for hdu in old_hdul:
                    # always keep primary HDU
                    if hdu is old_hdul[0]:
                        new_hdus.append(hdu.copy())
                    else:
                        # drop only the one whose EXTNAME matches `curve`
                        if hdu.header.get("EXTNAME") != curve:
                            new_hdus.append(hdu.copy())

            # 3) Write to a temp file
            fits.HDUList(new_hdus).writeto(temp_path, overwrite=True)
            # 4) Atomically replace the original
            os.replace(temp_path, self.user_custom_path)

        except Exception as e:
            # cleanup temp file if something went wrong
            if os.path.exists(temp_path):
                os.remove(temp_path)
            QMessageBox.critical(self, "Write Error", f"Could not remove curve:\n{e}")
            return

        # 5) Reload and refresh
        self._reload_hdu_lists()
        self.refresh_filter_sensor_lists()
        QMessageBox.information(self, "Removed", f"Deleted curve '{curve}'.")




    def refresh_filter_sensor_lists(self):
        """
        Re-scan both SASP_data.fits and the user-custom FITS for
        CTYPE=FILTER/SENSOR and repopulate self.filter_list, self.sensor_list,
        and all the R/G/B + sensor combo-boxes.
        """
        # 1) Rebuild the lists from disk
        self._reload_hdu_lists()

        # 2) Now self.filter_list & self.sensor_list are up to date—
        #    do exactly the same combo-box clearing/filling you already have:
        current_r = self.r_filter_combo.currentText()
        current_g = self.g_filter_combo.currentText()
        current_b = self.b_filter_combo.currentText()
        current_s = self.sens_combo.currentText()
        current_lp  = self.lp_filter_combo.currentText()
        current_lp2 = self.lp_filter_combo2.currentText()

        for cb, lst, prev in [
            (self.r_filter_combo, self.filter_list, current_r),
            (self.g_filter_combo, self.filter_list, current_g),
            (self.b_filter_combo, self.filter_list, current_b),
        ]:
            cb.clear()
            cb.addItem("(None)")
            cb.addItems(lst)
            idx = cb.findText(prev)
            if idx != -1:
                cb.setCurrentIndex(idx)

        for cb, prev in [(self.lp_filter_combo,  current_lp),
                            (self.lp_filter_combo2, current_lp2)]:
            cb.clear()
            cb.addItem("(None)")
            cb.addItems(self.filter_list)
            idx = cb.findText(prev)
            if idx != -1:
                cb.setCurrentIndex(idx)

        self.sens_combo.clear()
        self.sens_combo.addItem("(None)")
        self.sens_combo.addItems(self.sensor_list)
        idx = self.sens_combo.findText(current_s)
        if idx != -1:
            self.sens_combo.setCurrentIndex(idx)


    def initialize_wcs_from_header(self, header):
        """Initialize a 2D WCS from a genuine fits.Header."""
        if header is None:
            print("No FITS header available; cannot build WCS.")
            return

        try:
            # Force n‐dimensional → 2D by telling Astropy “naxis=2, relax=True”
            self.wcs = WCS(header, naxis=2, relax=True)

            # pixel_scale_matrix → arcsec/pixel
            psm = self.wcs.pixel_scale_matrix
            self.pixscale = (np.hypot(psm[0, 0], psm[1, 0]) * 3600.0)

            self.center_ra, self.center_dec = self.wcs.wcs.crval
            self.wcs_header = self.wcs.to_header(relax=True)

            self.print_corner_coordinates()

            # Orientation: prefer CROTA2 if present; else fallback to CD→angle
            if 'CROTA2' in header:
                try:
                    self.orientation = float(header['CROTA2'])
                except Exception:
                    self.orientation = None
            else:
                self.orientation = self.calculate_orientation(header)

            if self.orientation is not None:
                print(f"Orientation = {self.orientation:.2f}°")
                self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
            else:
                self.orientation_label.setText("Orientation: N/A")

            print(f"WCS OK: RA={self.center_ra:.6f}, Dec={self.center_dec:.6f}, Pixscale={self.pixscale:.3f}\"/px")
        except Exception as e:
            print("WCS initialization error (no pop‐up):\n", e)
            import traceback; traceback.print_exc()
            return

    def calculate_orientation(self, header):
        """
        Fallback calculation of rotation angle (°) from the CD‐matrix if CROTA2 is missing.
        We'll use CD1_1 and CD1_2 to compute arctan2(CD1_2, CD1_1) in degrees.
        """
        try:
            cd1_1 = float(header.get("CD1_1", 0.0))
            cd1_2 = float(header.get("CD1_2", 0.0))
            angle = math.degrees(math.atan2(cd1_2, cd1_1))
            return angle
        except Exception:
            return None

    def print_corner_coordinates(self):
        """Print the RA/Dec of each of the four corners, for debugging."""
        if not hasattr(self, "wcs") or self.current_image is None:
            print("Cannot print corners: WCS or image is missing.")
            return

        h, w = self.current_image.shape[:2]
        corners = {
            "Top-Left":    (0, 0),
            "Top-Right":   (w, 0),
            "Bottom-Left": (0, h),
            "Bottom-Right":(w, h),
        }
        print("Corner RA/Dec coordinates:")
        for name, (x, y) in corners.items():
            ra, dec = self.calculate_ra_dec_from_pixel(x, y)
            if ra is None:
                continue
            ra_hms = self.convert_ra_to_hms(ra)
            dec_dms = self.convert_dec_to_dms(dec)
            print(f"  {name}: RA={ra_hms}, Dec={dec_dms}")

    def calculate_ra_dec_from_pixel(self, x, y):
        """Convert pixel coordinates (x, y) to RA/Dec via the 2D WCS."""
        if not hasattr(self, "wcs"):
            return None, None
        ra, dec = self.wcs.all_pix2world(x, y, 0)
        return ra, dec

    def convert_ra_to_hms(self, ra_deg):
        """Convert Right Ascension in degrees to Hours:Minutes:Seconds format."""
        ra_hours = ra_deg / 15.0  # Convert degrees to hours
        hours = int(ra_hours)
        minutes = int((ra_hours - hours) * 60)
        seconds = (ra_hours - hours - minutes / 60.0) * 3600
        return f"{hours:02d}h{minutes:02d}m{seconds:05.2f}s"

    def convert_dec_to_dms(self, dec_deg):
        """Convert Declination in degrees to Degrees:Minutes:Seconds format."""
        sign = "-" if dec_deg < 0 else "+"
        dec_deg = abs(dec_deg)
        degrees = int(dec_deg)
        minutes = int((dec_deg - degrees) * 60)
        seconds = (dec_deg - degrees - minutes / 60.0) * 3600
        degree_symbol = "\u00B0"
        return f"{sign}{degrees:02d}{degree_symbol}{minutes:02d}m{seconds:05.2f}s"

    def _neutralize_background(self,
                            rgb_img: np.ndarray,
                            patch_size: int = 50) -> np.ndarray:
        """
        Linear background-neutralisation:
        1. Split the image into a patch_size×patch_size grid.
        2. Pick the patch with the *lowest* sum of RGB medians
            (≈ darkest, least signal).
        3. Let  best_med = [mR, mG, mB]  for that patch and
            target      = mean(best_med).
        4. For every channel           new = (old – diff) / (1 – diff)
            with diff = mC – target.
        5. Clip to [0,1] and return.

        The transform is linear, therefore
        old = 0   ⇒   new = 0
        old = 1   ⇒   new = 1
        so neither the black- nor white-point is touched; only the
        *colour* of the background drifts toward neutral gray.
        """
        img = rgb_img.copy()
        h, w = img.shape[:2]
        ph, pw = h // patch_size, w // patch_size

        # ── 1 · locate darkest patch ─────────────────────────────────────────
        min_sum, best_med = np.inf, None
        for i in range(patch_size):
            for j in range(patch_size):
                y0, x0 = i * ph, j * pw
                patch = img[y0:min(y0+ph, h), x0:min(x0+pw, w), :]
                med   = np.median(patch, axis=(0, 1))        # [R,G,B]
                s     = med.sum()
                if s < min_sum:
                    min_sum, best_med = s, med

        if best_med is None:          # shouldn’t happen, but be safe
            return img

        # ── 2 · linear shift/scale per channel ──────────────────────────────
        target = float(best_med.mean())
        eps    = 1e-8
        for c in range(3):
            diff = float(best_med[c] - target)
            if abs(diff) < eps:
                continue                           # already on target
            img[..., c] = np.clip((img[..., c] - diff) / (1.0 - diff),
                                0.0, 1.0)

        return img

    def fetch_stars(self):
        """
        1) Ensure plate-solved header & image exist.
        2) Build 2-D WCS and compute on-sky radius (deg).
        3) Query SIMBAD for SP_TYPE + B / V / R.
        4) Infer spectral class from B–V if SP_TYPE missing.
        5) Populate self.star_list and draw a histogram of Pickles matches.
        """

        # ─── 0) Grab current image + header ────────────────────────────
        if self.main_win is not None and hasattr(self.main_win, "image_manager"):
            img, meta = self.main_win.image_manager.get_current_image_and_metadata()
            self.current_image  = img
            self.current_header = meta.get("original_header", None)
        else:
            self.current_image  = None
            self.current_header = None

        if self.current_header is None or self.current_image is None:
            QMessageBox.warning(self, "No Plate Solution",
                                "Please plate-solve the image first.")
            return

        # ─── 1) Ensure we have Pickles templates loaded only once ──────
        if not hasattr(self, "pickles_templates"):
            self.pickles_templates = []
            for p in (self.user_custom_path, self.sasp_data_path):
                try:
                    with fits.open(p) as hd:
                        for hdu in hd:
                            if (isinstance(hdu, fits.BinTableHDU)
                                    and hdu.header.get("CTYPE", "").upper() == "SED"):
                                extname = hdu.header.get("EXTNAME", None)
                                if extname and extname not in self.pickles_templates:
                                    self.pickles_templates.append(extname)
                except Exception as e:
                    print(f"[fetch_stars] Could not load Pickles templates from {p}: {e}")

        # ─── 2) Build 2-D WCS and search radius ───────────────────────
        try:
            self.initialize_wcs_from_header(self.current_header)
        except Exception:
            QMessageBox.critical(self, "WCS Error",
                                "Could not build a 2-D WCS from header.")
            return

        H, W = self.current_image.shape[:2]
        pix = np.array([[W/2, H/2], [0,0], [W,0], [0,H], [W,H]])
        try:
            sky = self.wcs.all_pix2world(pix, 0)
        except Exception as e:
            QMessageBox.critical(self, "WCS Conversion Error", str(e))
            return

        center_sky  = SkyCoord(ra=sky[0,0]*u.deg, dec=sky[0,1]*u.deg, frame="icrs")
        corners_sky = SkyCoord(ra=sky[1:,0]*u.deg, dec=sky[1:,1]*u.deg, frame="icrs")
        radius_deg  = center_sky.separation(corners_sky).max().deg
        print(f"[fetch_stars] Center = {center_sky.to_string('hmsdms')}, "
            f"Radius = {radius_deg:.4f}°")

        # ─── 3) Configure SIMBAD TAP ───────────────────────────────────
        Simbad.reset_votable_fields()
        for attempt in range(1, 11):
            try:
                Simbad.add_votable_fields('sp', 'flux(B)', 'flux(V)', 'flux(R)')
                break
            except DALServiceError as e:
                self.count_label.setText(f"Attempt {attempt}/10 to fetch stars…")
                QApplication.processEvents()
                if attempt < 10:
                    time.sleep(3)
                else:
                    QMessageBox.critical(self, "SIMBAD TAP Error",
                                        "Could not retrieve SIMBAD fields.")
                    return

        Simbad.ROW_LIMIT = 10000

        # ─── 4) Query SIMBAD ───────────────────────────────────────────
        for attempt in range(1, 11):
            try:
                result = Simbad.query_region(center_sky, radius=radius_deg * u.deg)
                break
            except Exception as e:
                self.count_label.setText(f"Attempt {attempt}/10 to query SIMBAD…")
                QApplication.processEvents()
                if attempt < 10:
                    time.sleep(3)
                else:
                    QMessageBox.critical(self, "SIMBAD Error",
                                        f"Query failed:\n{e}")
                    return

        if result is None or len(result) == 0:
            QMessageBox.information(self, "No Stars Found",
                                    "SIMBAD returned zero objects in that region.")
            self.star_list = []
            self.star_combo.clear()
            self.star_combo.addItem("Vega (A0V)", userData="A0V")
            return
        # helper: infer spectral letter from B–V
        def infer_letter(bv):
            if bv is None or (isinstance(bv, float) and np.isnan(bv)):
                return None
            if   bv < 0.00: return "B"
            elif bv < 0.30: return "A"
            elif bv < 0.58: return "F"
            elif bv < 0.81: return "G"
            elif bv < 1.40: return "K"
            elif bv > 1.40: return "M"
            else:           return "U"

        # ─── 5) Build star list + histogram items ──────────────────────
        self.star_list = []
        templates_for_hist = []       # only Pickles names (no None)

        for row in result:
            raw_sp = row['sp_type']
            bmag, vmag, rmag = row['B'], row['V'], row['R']
            ra_deg, dec_deg  = float(row['ra']), float(row['dec'])

            try:
                sc = SkyCoord(ra=ra_deg*u.deg, dec=dec_deg*u.deg, frame="icrs")
            except Exception:
                continue

            # ── Determine spectral string (sp_clean) ──────────────────
            sp_clean = None
            if raw_sp and str(raw_sp).strip():
                sp = str(raw_sp).strip().upper()
                if not (sp.startswith("SN") or sp.startswith("KA")):
                    sp_clean = sp
            elif bmag is not None and vmag is not None:
                try:
                    sp_clean = infer_letter(float(bmag) - float(vmag))
                except Exception:
                    pass

            if not sp_clean:
                continue

            # ── Match to Pickles template ─────────────────────────────
            match_list   = pickles_match_for_simbad(sp_clean, self.pickles_templates)
            best_template = match_list[0] if match_list else None

            # Project to pixel coords and store star
            xpix, ypix = self.wcs.all_world2pix(sc.ra.deg, sc.dec.deg, 0)
            if 0 <= xpix < W and 0 <= ypix < H:
                self.star_list.append({
                    "ra": sc.ra.deg,
                    "dec": sc.dec.deg,
                    "sp_clean": sp_clean,
                    "pickles_match": best_template,
                    "x": xpix,
                    "y": ypix,
                    "Bmag": float(bmag) if bmag else None,
                    "Vmag": float(vmag) if vmag else None,
                    "Rmag": float(rmag) if rmag else None,
                })
                if best_template is not None:
                    templates_for_hist.append(best_template)

        # ─── 6) Histogram / UI update ─────────────────────────────────
        self.figure.clf()
        if templates_for_hist:
            uniq, cnt = np.unique(templates_for_hist, return_counts=True)
            types_str = ", ".join(uniq)
            self.count_label.setText(
                f"Found {len(templates_for_hist)} stars; templates: {types_str}"
            )

            ax = self.figure.add_subplot(111)
            ax.bar(uniq, cnt, edgecolor="black")
            ax.set_xlabel("Spectral Type")
            ax.set_ylabel("Count")
            ax.set_title("Spectral Distribution")
            ax.tick_params(axis='x', rotation=90)
            ax.grid(axis="y", linestyle="--", alpha=0.3)
            self.canvas.setVisible(True)
            self.canvas.draw()
        else:
            self.count_label.setText("Found 0 stars with Pickles matches.")
            self.canvas.setVisible(False)
            self.canvas.draw()

    def run_spcc(self):
        """
        Run a *color‐ratio* SFCC (Spectral Photometric Color Calibration):
        1) Use SEP to detect star centroids (x,y).
        2) Match each Simbad star to the nearest SEP centroid.
        3) At that pixel, read (R_meas, G_meas, B_meas).
        4) Integrate each star’s Pickles SED → (S_star_R, S_star_G, S_star_B).
        5) Compute exp_RG = S_star_R/S_star_G, exp_BG = S_star_B/S_star_G.
        6) Fit meas_RG = R_meas/G_meas → exp_RG and meas_BG = B_meas/G_meas → exp_BG.
        7) Apply R_corrected = m_R·R + b_R·G, B_corrected = m_B·B + b_B·G.
        8) Store per-star Δ-flux for gradient extraction.
        9) Replace image with calibrated RGB.
        """

        # — Step 0: Validate user choices —
        ref_sed_name = self.star_combo.currentData()
        r_filt = self.r_filter_combo.currentText()
        g_filt = self.g_filter_combo.currentText()
        b_filt = self.b_filter_combo.currentText()
        sens_name = self.sens_combo.currentText()
        lp_filt = self.lp_filter_combo.currentText()
        lp_filt2 = self.lp_filter_combo2.currentText()

        if not ref_sed_name:
            QMessageBox.warning(self, "Error", "Please select a reference spectral type (e.g. “A0V”).")
            return
        if r_filt == "(None)" and g_filt == "(None)" and b_filt == "(None)":
            QMessageBox.warning(self, "Error", "Please pick at least one of R, G or B filters.")
            return
        if sens_name == "(None)":
            QMessageBox.warning(self, "Error", "Please select a sensor QE curve.")
            return

        # — Step 1A: Convert to float [0..1] & neutralize large pedestals —
        img, _ = self.main_win.image_manager.get_current_image_and_metadata()
        if img is None:
            QMessageBox.critical(self, "Error", "No active image in the current slot.")
            return
        H, W, C = img.shape
        if C != 3:
            QMessageBox.critical(self, "Error", "Current image is not RGB (3 channels).")
            return
        if img.dtype == np.uint8:
            base = img.astype(np.float32) / 255.0
        else:
            base = img.astype(np.float32)

        ch_min = np.min(base, axis=(0, 1))       # shape = (3,)
        base   = np.clip(base - ch_min, 0.0, None)

        # — record per-channel minima & medians before neutralization —
        orig_min    = np.min(base, axis=(0,1))    # shape (3,)
        orig_median = np.median(base, axis=(0,1)) # shape (3,)
        orig_median_scalar = float(np.median(orig_median)) # single float

        # initial patch‐based neutralization
        patch_size = 10
        h, w = base.shape[:2]
        ph, pw = h//patch_size, w//patch_size

        min_sum = np.inf
        best_med = None
        for i in range(patch_size):
            for j in range(patch_size):
                y0, x0 = i*ph, j*pw
                y1, x1 = min(y0+ph, h), min(x0+pw, w)
                patch = base[y0:y1, x0:x1, :]
                meds  = np.median(patch, axis=(0,1))   # [R_med, G_med, B_med]
                s     = meds.sum()
                if s < min_sum:
                    min_sum, best_med = s, meds

        if best_med is not None:
            avg = best_med.mean()
            for c in range(3):
                diff  = best_med[c] - avg
                denom = 1.0 - diff if abs(1.0-diff)>1e-8 else 1e-8
                base[:,:,c] = np.clip((base[:,:,c] - diff)/denom, 0.0, 1.0)


        # — restore the original median via your stretch helper —
        # assumes you have a method stretch_color_image(img, target_median, linked=True)
        #base = stretch_color_image(base, orig_median_scalar, linked=False)


        # — Step 1B: SEP extraction on grayscale image —
        gray = np.mean(base, axis=2)
        self.count_label.setText("Detecting stars (SEP)…")
        QApplication.processEvents()
        bkg = sep.Background(gray)
        data_sub = gray - bkg.back()
        err = bkg.globalrms
        sources = sep.extract(data_sub, 5.0, err=err)
        if sources.size == 0:
            QMessageBox.critical(self, "SEP Error", "SEP found no sources in the image.")
            return

        r_fluxrad, _ = sep.flux_radius(
            gray,
            sources["x"], sources["y"],
            2.0 * sources["a"], 0.5,
            normflux=sources["flux"],
            subpix=5
        )
        mask = (r_fluxrad > .2) & (r_fluxrad <= 10)
        sources = sources[mask]
        if sources.size == 0:
            QMessageBox.critical(self, "SEP Error",
                                 "All SEP‐detected sources were rejected by radius filter.")
            return

        # — Step 2: Match Simbad stars to SEP centroids —
        if not getattr(self, "star_list", None):
            QMessageBox.warning(self, "Error",
                                "You must Fetch Stars (and plate‐solve) before running SFCC.")
            return
        raw_matches = []
        for i, star in enumerate(self.star_list):
            dx = sources["x"] - star["x"]
            dy = sources["y"] - star["y"]
            j = np.argmin(dx*dx + dy*dy)
            if (dx[j]**2 + dy[j]**2) < 3.0**2:
                xi, yi = int(round(sources["x"][j])), int(round(sources["y"][j]))
                if 0 <= xi < W and 0 <= yi < H:
                    raw_matches.append({
                        "sim_index": i,
                        # Use the exact Pickles template if we have one,
                        # else fall back to the full SIMBAD string.
                        "template":  star.get("pickles_match") or star["sp_clean"],
                        "ra":        star["ra"],
                        "dec":       star["dec"],
                        "x_pix":     xi,
                        "y_pix":     yi
                    })
        if not raw_matches:
            QMessageBox.warning(self, "No Matches",
                                "Could not match any Simbad star to SEP detections.")
            return

        # — Step 3: Build throughput curves & reference SED —
        wl_min, wl_max = 3000, 11000
        wl_grid = np.arange(wl_min, wl_max+1)

        def load_curve(ext):
            for p in (self.user_custom_path, self.sasp_data_path):
                with fits.open(p) as hd:
                    if ext in hd:
                        d = hd[ext].data
                        return d["WAVELENGTH"], d["THROUGHPUT"]
            raise KeyError(f"Curve '{ext}' not found")

        def load_sed(ext):
            for p in (self.user_custom_path, self.sasp_data_path):
                with fits.open(p) as hd:
                    if ext in hd:
                        d = hd[ext].data
                        return d["WAVELENGTH"], d["FLUX"]
            raise KeyError(f"SED '{ext}' not found")

        def interp(wl_o, tp_o):
            return np.interp(wl_grid, wl_o, tp_o, left=0., right=0.)

        # system throughput
        T_R = interp(*load_curve(r_filt)) if r_filt!="(None)" else np.ones_like(wl_grid)
        T_G = interp(*load_curve(g_filt)) if g_filt!="(None)" else np.ones_like(wl_grid)
        T_B = interp(*load_curve(b_filt)) if b_filt!="(None)" else np.ones_like(wl_grid)
        QE  = interp(*load_curve(sens_name)) if sens_name!="(None)" else np.ones_like(wl_grid)
        LP1 = interp(*load_curve(lp_filt))   if lp_filt != "(None)"  else np.ones_like(wl_grid)
        LP2 = interp(*load_curve(lp_filt2))  if lp_filt2!= "(None)"  else np.ones_like(wl_grid)
        LP  = LP1 * LP2

        T_sys_R = T_R * QE * LP
        T_sys_G = T_G * QE * LP
        T_sys_B = T_B * QE * LP

        # reference SED integrals
        wl_ref, fl_ref = load_sed(ref_sed_name)
        fr_i = np.interp(wl_grid, wl_ref, fl_ref, left=0., right=0.)
        S_ref_R = np.trapz(fr_i * T_sys_R, x=wl_grid)
        S_ref_G = np.trapz(fr_i * T_sys_G, x=wl_grid)
        S_ref_B = np.trapz(fr_i * T_sys_B, x=wl_grid)

        # ——— Step 4: Measure each star, compute expected ratios & collect diagnostics ———
        diag_meas_RG = []; diag_exp_RG = []
        diag_meas_BG = []; diag_exp_BG = []
        enriched     = []


        # (you should already have S_ref_G from your reference‐SED integration)
        # …
        for m in raw_matches:
            xi, yi, sp = m["x_pix"], m["y_pix"], m["template"]
            star_src = self.star_list[m["sim_index"]]
            if img.dtype == np.uint8:
                Rm = img[yi, xi, 0] / 255.0
                Gm = img[yi, xi, 1] / 255.0
                Bm = img[yi, xi, 2] / 255.0
            else:
                Rm = float(base[yi, xi, 0])
                Gm = float(base[yi, xi, 1])
                Bm = float(base[yi, xi, 2])
            if Gm <= 0:
                continue

            cands = pickles_match_for_simbad(sp, self.pickles_templates)
            if not cands:
                continue
            wl_s, fl_s = load_sed(cands[0])
            fs_i = np.interp(wl_grid, wl_s, fl_s, left=0., right=0.)
            S_sr = np.trapz(fs_i * T_sys_R, x=wl_grid)
            S_sg = np.trapz(fs_i * T_sys_G, x=wl_grid)
            S_sb = np.trapz(fs_i * T_sys_B, x=wl_grid)
            if S_sg <= 0:
                continue

            exp_RG = S_sr / S_sg
            exp_BG = S_sb / S_sg

            meas_RG = Rm / Gm
            meas_BG = Bm / Gm

            diag_meas_RG.append(meas_RG)
            diag_exp_RG .append(exp_RG)
            diag_meas_BG.append(meas_BG)
            diag_exp_BG .append(exp_BG)

            enriched.append({
                **m,
                "R_meas":   Rm,
                "G_meas":   Gm,
                "B_meas":   Bm,
                "S_star_R": S_sr,
                "S_star_G": S_sg,
                "S_star_B": S_sb,
                "exp_RG":   exp_RG,
                "exp_BG":   exp_BG,
                "R_mag":    star_src.get("Rmag"),
                "V_mag":    star_src.get("Vmag"),
                "B_mag":    star_src.get("Bmag"),                
            })

        # convert diagnostics to arrays and bail if none
        diag_meas_RG = np.array(diag_meas_RG)
        diag_exp_RG  = np.array(diag_exp_RG)
        diag_meas_BG = np.array(diag_meas_BG)
        diag_exp_BG  = np.array(diag_exp_BG)
        if diag_meas_RG.size == 0 or diag_meas_BG.size == 0:
            QMessageBox.information(self, "No Valid Stars",
                                    "Could not find any stars with valid measured vs expected.")
            return

        # how many stars?
        n_stars = diag_meas_RG.size

        # compute median of all G_meas
        all_G = np.array([e["G_meas"] for e in enriched])
        medG  = np.median(all_G)

        # now compute per‐channel delta‐flux
        for e in enriched:
            # expected G ratio relative to reference SED
            exp_GG = e["S_star_G"] / S_ref_G

            e["delta_R"] = e["R_meas"] - (e["exp_RG"] * e["G_meas"])
            e["delta_G"] = (e["G_meas"] - (exp_GG * e["G_meas"])) * exp_GG
            e["delta_B"] = e["B_meas"] - (e["exp_BG"] * e["G_meas"])

        self._last_matched = enriched

        # ---------- Step-5 : choose best colour-ratio model --------------------
        def rms_frac(pred, exp):
            """Fractional RMS of (pred/exp – 1)."""
            return np.sqrt(np.mean(((pred/exp) - 1.0) ** 2))

        # helpers ---------------------------------------------------------------
        slope_only = lambda x, m:            m*x
        affine     = lambda x, m, b:         m*x + b
        quad       = lambda x, a, b, c:      a*x**2 + b*x + c

        # --- candidate-1 : slope-only  (b = 0)
        mR_s = np.sum(diag_meas_RG * diag_exp_RG) / np.sum(diag_meas_RG**2)
        mB_s = np.sum(diag_meas_BG * diag_exp_BG) / np.sum(diag_meas_BG**2)

        rms_s = rms_frac(slope_only(diag_meas_RG, mR_s), diag_exp_RG) + \
                rms_frac(slope_only(diag_meas_BG, mB_s), diag_exp_BG)

        # --- candidate-2 : affine  y = m·x + b
        mR_a, bR_a = np.linalg.lstsq(
                        np.vstack([diag_meas_RG, np.ones_like(diag_meas_RG)]).T,
                        diag_exp_RG, rcond=None)[0]
        mB_a, bB_a = np.linalg.lstsq(
                        np.vstack([diag_meas_BG, np.ones_like(diag_meas_BG)]).T,
                        diag_exp_BG, rcond=None)[0]

        rms_a = rms_frac(affine(diag_meas_RG, mR_a, bR_a), diag_exp_RG) + \
                rms_frac(affine(diag_meas_BG, mB_a, bB_a), diag_exp_BG)

        # --- candidate-3 : quadratic  y = a·x² + b·x + c
        aR_q, bR_q, cR_q = np.polyfit(diag_meas_RG, diag_exp_RG, 2)
        aB_q, bB_q, cB_q = np.polyfit(diag_meas_BG, diag_exp_BG, 2)

        rms_q = rms_frac(quad(diag_meas_RG, aR_q, bR_q, cR_q), diag_exp_RG) + \
                rms_frac(quad(diag_meas_BG, aB_q, bB_q, cB_q), diag_exp_BG)

        # --- pick the winner ---------------------------------------------------
        idx = np.argmin([rms_s, rms_a, rms_q])
        if idx == 0:              # slope-only
            coeff_R, coeff_B = (0, mR_s, 0), (0, mB_s, 0)   # (a,b,c)
            model_choice = "slope-only"
        elif idx == 1:            # affine
            coeff_R, coeff_B = (0, mR_a, bR_a), (0, mB_a, bB_a)
            model_choice = "affine"
        else:                     # quadratic
            coeff_R, coeff_B = (aR_q, bR_q, cR_q), (aB_q, bB_q, cB_q)
            model_choice = "quadratic"

        print(f"SFCC picked {model_choice}   →  RMS = {min(rms_s, rms_a, rms_q):.3f}")

        poly = lambda c, x: c[0]*x**2 + c[1]*x + c[2]        # universal evaluator

        # ─── 6 · Diagnostics ────────────────────────────────────────────────
        self.figure.clf()

        # ---------------- panel 1 : histograms -----------------------------
        ax1 = self.figure.add_subplot(1, 3, 1)
        bins = 20
        ax1.hist(diag_meas_RG, bins=bins, alpha=.65,
                 label="meas R/G", color="firebrick", edgecolor="black")
        ax1.hist(diag_exp_RG,  bins=bins, alpha=.55,
                 label="exp R/G", color="salmon", edgecolor="black")
        ax1.hist(diag_meas_BG, bins=bins, alpha=.65,
                 label="meas B/G", color="royalblue", edgecolor="black")
        ax1.hist(diag_exp_BG,  bins=bins, alpha=.55,
                 label="exp B/G", color="lightskyblue", edgecolor="black")
        ax1.set_xlabel("Ratio  (band / G)")
        ax1.set_ylabel("Number of stars")
        ax1.set_title("Measured vs expected")
        ax1.legend(fontsize=7, frameon=False)

        # ---------------- convenience -------------------------------------
        res0_RG = (diag_meas_RG / diag_exp_RG) - 1.0
        res0_BG = (diag_meas_BG / diag_exp_BG) - 1.0
        res1_RG = (poly(coeff_R, diag_meas_RG) / diag_exp_RG) - 1.0
        res1_BG = (poly(coeff_B, diag_meas_BG) / diag_exp_BG) - 1.0

        def rms(a): return np.sqrt(np.mean(a**2))

        #  full vertical span from *un-corrected* residuals -----------------
        ymin = np.min(np.concatenate([res0_RG, res0_BG]))
        ymax = np.max(np.concatenate([res0_RG, res0_BG]))
        pad  = 0.05 * (ymax - ymin) if ymax > ymin else 0.02
        y_lim = (ymin - pad, ymax + pad)

        # helper: horizontal IQR shading -----------------------------------
        def shade_iqr_y(ax, y_vals, color):
            q1, q3 = np.percentile(y_vals, [25, 75])
            ax.axhspan(q1, q3, color=color, alpha=.10, zorder=0)

        # --------------- panel 2 : BEFORE fit ------------------------------
        ax2 = self.figure.add_subplot(1, 3, 2)
        ax2.axhline(0, color="0.65", ls="--", lw=1)
        shade_iqr_y(ax2, res0_RG, "firebrick")
        shade_iqr_y(ax2, res0_BG, "royalblue")
        ax2.scatter(diag_exp_RG, res0_RG,
                    c="firebrick",  marker="o", alpha=.7, label="R/G residual")
        ax2.scatter(diag_exp_BG, res0_BG,
                    c="royalblue", marker="s", alpha=.7, label="B/G residual")
        ax2.set_ylim(*y_lim)                      # auto-range from residuals
        ax2.set_xlabel("Expected ratio  (band / G)")
        ax2.set_ylabel("Fractional residual  (meas/exp − 1)")
        ax2.set_title("Residuals  •  BEFORE fit", pad=10)
        ax2.legend(frameon=False, fontsize=7, loc="lower right")
        ax2.text(.04, .95, f"σ(R/G) = {rms(res0_RG)*100:.1f} %",
                 transform=ax2.transAxes, va="top", color="firebrick")
        ax2.text(.04, .88, f"σ(B/G) = {rms(res0_BG)*100:.1f} %",
                 transform=ax2.transAxes, va="top", color="royalblue")

        # --------------- panel 3 : AFTER fit -------------------------------
        ax3 = self.figure.add_subplot(1, 3, 3)
        ax3.axhline(0, color="0.65", ls="--", lw=1)
        shade_iqr_y(ax3, res1_RG, "firebrick")
        shade_iqr_y(ax3, res1_BG, "royalblue")
        ax3.scatter(diag_exp_RG, res1_RG,
                    c="firebrick",  marker="o", alpha=.7, label="R/G residual")
        ax3.scatter(diag_exp_BG, res1_BG,
                    c="royalblue", marker="s", alpha=.7, label="B/G residual")
        ax3.set_ylim(*y_lim)                      # same scale as BEFORE panel
        ax3.set_xlabel("Expected ratio  (band / G)")
        ax3.set_ylabel("Fractional residual  (corrected/exp − 1)")
        ax3.set_title("Residuals  •  AFTER fit", pad=10)
        ax3.legend(frameon=False, fontsize=7, loc="lower right")
        ax3.text(.04, .95, f"σ(R/G) = {rms(res1_RG)*100:.1f} %",
                 transform=ax3.transAxes, va="top", color="firebrick")
        ax3.text(.04, .88, f"σ(B/G) = {rms(res1_BG)*100:.1f} %",
                 transform=ax3.transAxes, va="top", color="royalblue")

        # -------------------------------------------------------------------
        self.canvas.setVisible(True)
        self.figure.tight_layout(w_pad=2.)
        self.canvas.draw()


        # ——— Step 7: Apply the color‐ratio fit to the entire image ———
        self.count_label.setText("Applying SFCC color scales to image…")
        QApplication.processEvents()

        if img.dtype == np.uint8:
            img_float = (img.astype(np.float32) / 255.0).copy()
        else:
            img_float = img.astype(np.float32).copy()

        # ratios in the raw image
        RG = img_float[..., 0] / np.maximum(img_float[..., 1], 1e-8)
        BG = img_float[..., 2] / np.maximum(img_float[..., 1], 1e-8)

        # predicted correct ratios from the chosen model
        aR, bR, cR = coeff_R
        aB, bB, cB = coeff_B
        RG_corr = aR*RG**2 + bR*RG + cR
        BG_corr = aB*BG**2 + bB*BG + cB

        calibrated = img_float.copy()
        calibrated[..., 0] = RG_corr * img_float[..., 1]   # R = (R/G)_corr × G
        calibrated[..., 2] = BG_corr * img_float[..., 1]   # B = (B/G)_corr × G
        calibrated = np.clip(calibrated, 0, 1)

        # ─── Step 8: optional background neutralization ───────────────
        if self.neutralize_chk.isChecked():
            calibrated = self._neutralize_background(calibrated, patch_size=10)

        # ——— Convert back to uint8 if needed and push calibrated image onward ———
        if img.dtype == np.uint8:
            calibrated = (calibrated * 255.0).astype(np.uint8)
        print(img.dtype)    

        # ——— Step 9: Push the calibrated (and neutralized) image back into the current slot ———
        if not hasattr(self, "main_win") or self.main_win is None:
            QMessageBox.critical(self, "Internal Error", "Cannot find parent to store calibrated image.")
            return

        _, old_meta = self.main_win.image_manager.get_current_image_and_metadata()
        new_meta = (old_meta or {}).copy()
        new_meta["SFCC_applied"]   = True
        new_meta["SFCC_timestamp"] = datetime.now().isoformat()
        new_meta["SFCC_model"]     = model_choice
        new_meta["SFCC_coeff_R"]   = [float(v) for v in coeff_R]   # (a,b,c)
        new_meta["SFCC_coeff_B"]   = [float(v) for v in coeff_B]

        self.main_win.image_manager.set_image(
            calibrated,
            new_meta,
            step_name="SFCC Calibrated"
        )

        self.count_label.setText(f"Applied SFCC color calibration using {n_stars} stars")
        QApplication.processEvents()

        # ——— Step 10: Final summary dialog ———
        # ---------- final summary dialog ---------------------------------------
        def pretty(coeff):
            """return y at x=1  (easy-to-interpret overall scale)"""
            return coeff[0] + coeff[1] + coeff[2]          # a*1² + b*1 + c

        ratio_R = pretty(coeff_R)
        ratio_B = pretty(coeff_B)

        QMessageBox.information(
            self, "SFCC Complete",
            f"Applied SFCC colour calibration using {n_stars} stars\n"
            f"  Model chosen : {model_choice}\n"
            f"  R ratio (at x=1) = {ratio_R:.4f}\n"
            f"  B ratio (at x=1) = {ratio_B:.4f}\n"
            "\n"
            "Background neutralisation " +
            ("ENABLED" if self.neutralize_chk.isChecked() else "skipped") + "."
        )
        self.current_image = calibrated

    def run_gradient_extraction(self):
        """
        Chromatic-gradient removal using only Pickles-based colour ratios.
        * No catalog magnitudes
        * No sky probes
        * Work on ¼-res copy for speed, upscale the result.
        """
        # ─── 0. prerequisites ───────────────────────────────────────────────
        if not getattr(self, "_last_matched", None):
            QMessageBox.warning(self, "No Star Matches",
                                "Run colour calibration first.")
            return

        img, meta = self.main_win.image_manager.get_current_image_and_metadata()
        if img is None or img.ndim != 3 or img.shape[2] != 3:
            QMessageBox.critical(self, "Error", "Current image must be RGB.")
            return

        is_u8  = img.dtype == np.uint8
        img_f  = img.astype(np.float32) / (255. if is_u8 else 1.)
        H, W   = img_f.shape[:2]

        # ─── 1. down-sample working copy ────────────────────────────────────
        down_fact = 4                                     # <— tweak if needed
        Hs, Ws    = H // down_fact, W // down_fact
        small     = cv2.resize(img_f, (Ws, Hs), interpolation=cv2.INTER_AREA)

        # helper → convert star’s full-res coords to small
        def to_small(x, y): return x / down_fact, y / down_fact

        # quick luminance for σ-clipping later
        gray_s = np.mean(small, axis=2)

        # ─── 2. re-measure every star’s colour ratios ───────────────────────
        pts, dRG, dBG = [], [], []
        eps, box = 1e-8, 3                       # box → 7×7 median @ ¼-res

        for st in self._last_matched:
            xs_full, ys_full = st["x_pix"], st["y_pix"]
            xs, ys           = to_small(xs_full, ys_full)
            xs_c, ys_c       = int(round(xs)), int(round(ys))
            if not (0 <= xs_c < Ws and 0 <= ys_c < Hs):   # off-frame?
                continue

            # median in 7×7 patch (clamped to edges)
            xsl = slice(max(0, xs_c-box), min(Ws, xs_c+box+1))
            ysl = slice(max(0, ys_c-box), min(Hs, ys_c+box+1))
            Rm  = np.median(small[ysl, xsl, 0])
            Gm  = np.median(small[ysl, xsl, 1])
            Bm  = np.median(small[ysl, xsl, 2])
            if Gm <= 0: continue

            exp_RG = st["exp_RG"];   exp_BG = st["exp_BG"]
            if exp_RG is None or exp_BG is None:   # shouldn’t happen
                continue

            meas_RG = Rm / Gm
            meas_BG = Bm / Gm

            dm_RG = -2.5 * np.log10((meas_RG+eps)/(exp_RG+eps))
            dm_BG = -2.5 * np.log10((meas_BG+eps)/(exp_BG+eps))

            pts.append([xs, ys])
            dRG.append(dm_RG)
            dBG.append(dm_BG)

        pts  = np.asarray(pts);   dRG = np.asarray(dRG);   dBG = np.asarray(dBG)
        if pts.shape[0] < 5:
            QMessageBox.warning(self, "Too Few Stars",
                                "Need ≥5 stars after clipping.")
            return

        # σ-clip
        def sclip(arr, p, s=2.5):
            m, sd = np.median(arr), np.std(arr)
            keep  = np.abs(arr-m) < s*sd
            return p[keep], arr[keep]

        ptsRG, dRG = sclip(dRG, pts)
        ptsBG, dBG = sclip(dBG, pts)

        # ─── 3. fit 2-D surfaces (¼-res) ────────────────────────────────────
        mode = getattr(self, "grad_method", "poly2")      # poly2/poly3/rbf
        bgRG_s = compute_gradient_map(ptsRG, dRG, (Hs, Ws), method=mode)
        bgBG_s = compute_gradient_map(ptsBG, dBG, (Hs, Ws), method=mode)

        # centre & clamp to ±0.2 mag
        for bg in (bgRG_s, bgBG_s):
            bg -= np.median(bg)
            peak = np.max(np.abs(bg))
            if peak > 0.2: bg *= 0.2/peak

        # ─── 4. upscale to full res ─────────────────────────────────────────
        bgRG = cv2.resize(bgRG_s, (W, H), interpolation=cv2.INTER_CUBIC)
        bgBG = cv2.resize(bgBG_s, (W, H), interpolation=cv2.INTER_CUBIC)

        scale_R = 10**(-0.4*bgRG)
        scale_B = 10**(-0.4*bgBG)

        # ─── 5. visualisation ───────────────────────────────────────────────
        self.figure.clf()
        for i,(surf,lbl) in enumerate(((bgRG,"Δm R/G"),(bgBG,"Δm B/G"))):
            ax  = self.figure.add_subplot(1,2,i+1)
            im  = ax.imshow(surf, origin="lower", cmap="RdBu")
            ax.scatter(pts[:,0]*down_fact, pts[:,1]*down_fact,
                    s=25, facecolors='none', edgecolors='k', lw=.6)
            ax.set_title(lbl); ax.set_ylim(H,0)
            self.figure.colorbar(im, ax=ax)
        self.canvas.setVisible(True)
        self.figure.tight_layout(); self.canvas.draw()

        # ─── 6. apply correction (only R & B) ───────────────────────────────
        corrected        = img_f.copy()
        corrected[...,0] = np.clip(corrected[...,0] / scale_R, 0, 1.0)
        corrected[...,2] = np.clip(corrected[...,2] / scale_B, 0, 1.0)
        if is_u8: corrected = (corrected*255.).astype(np.uint8)

        meta = meta.copy() if meta else {}
        meta["ColourGradRemoved"] = True
        self.main_win.image_manager.set_image(
            corrected, meta,
            step_name="Colour-Gradient (star spectra, ¼-res fit)"
        )
        self.count_label.setText("Chromatic gradient removed ✓")
        QApplication.processEvents()

    def open_sasp_viewer(self):
        """
        Called when the “Open SASP Viewer” button is clicked.
        Instantiates SaspViewer and shows it as a separate window.
        """
        # If it’s already open, just bring it to the front
        if self.sasp_viewer_window is not None:
            if self.sasp_viewer_window.isVisible():
                # It’s already open and visible → just bring to front
                self.sasp_viewer_window.raise_()
            else:
                # It exists but was closed (hidden) → show it again
                self.sasp_viewer_window.show()
            return

        # Create and show a new SaspViewer using the same SASP_data path
        self.sasp_viewer_window = SaspViewer(sasp_data_path=sasp_data_path, user_custom_path=self.user_custom_path)
        self.sasp_viewer_window.show()

        # When the SaspViewer is closed, clear the reference so we can reopen later
        self.sasp_viewer_window.destroyed.connect(self._on_sasp_closed)

    def reset_sfcc(self):
        """
        Close & delete this dialog, clear the parent’s pointer, 
        then call SFCC_show() to build an entirely new one.
        """
        parent = self.main_win
        # 1) Close and schedule this dialog for deletion
        self.close()
        self.deleteLater()

        # 2) Clear the parent’s reference so SFCC_show will make a fresh one
        parent.SFCC_window = None

        # 3) Call the same show method you use to open it initially
        parent.SFCC_show()


    def _on_sasp_closed(self, obj):
        # Called when the SaspViewer window is closed
        self.sasp_viewer_window = None

    def closeEvent(self, event):
        # Make sure to close the FITS file on exit

        super().closeEvent(event)


class PixelImage:
    def __init__(self, array):
        self.array = array

    def __getitem__(self, channel_index):
        """
        Return a new PixelImage containing only the requested channel (2D array).
        For example, slot0[0] -> red channel, slot0[1] -> green, slot0[2] -> blue.
        """
        # Make sure the requested channel is valid for this image's shape.
        if self.array.ndim < 3:
            raise ValueError("This image has no channel dimension to index.")
        if not (0 <= channel_index < self.array.shape[2]):
            raise IndexError(f"Channel index {channel_index} is out of range for shape {self.array.shape}")
        
        single_channel = self.array[..., channel_index]  # shape (height, width)
        return PixelImage(single_channel)

    def __add__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array + other.array)
        else:
            return PixelImage(self.array + other)
    __radd__ = __add__

    def __sub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array - other.array)
        else:
            return PixelImage(self.array - other)

    def __rsub__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array - self.array)
        else:
            return PixelImage(other - self.array)

    def __mul__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array * other.array)
        else:
            return PixelImage(self.array * other)
    __rmul__ = __mul__

    def __truediv__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(self.array / other.array)
        else:
            return PixelImage(self.array / other)

    def __invert__(self):
        # Overload the ~ operator to mean image inversion: 1 - array.
        return PixelImage(1 - self.array)

    def __xor__(self, other):
        # Overload the ^ operator for exponentiation.
        if isinstance(other, PixelImage):
            return PixelImage(self.array ** other.array)
        else:
            return PixelImage(self.array ** other)

    def __rxor__(self, other):
        if isinstance(other, PixelImage):
            return PixelImage(other.array ** self.array)
        else:
            return PixelImage(other ** self.array)

    def __repr__(self):
        return f"PixelImage({self.array})"
    
    def __lt__(self, other):
        if isinstance(other, PixelImage):
            return self.array < other.array
        else:
            return self.array < other   

    def __eq__(self, other):
        if isinstance(other, PixelImage):
            return self.array == other.array
        else:
            return self.array == other

class PixelMathDialog(QDialog):
    def __init__(self, parent=None, image_manager=None):
        super().__init__(parent)
        self.image_manager = image_manager
        self.setWindowTitle("Pixel Math")
        
        # Attempt to retrieve QSettings from the parent
        if parent is not None and hasattr(parent, "settings"):
            self.settings = parent.settings
        else:
            self.settings = None

        self.favorites = []
        self.initUI()
        self.load_favorites()

    def initUI(self):
        main_layout = QVBoxLayout(self)

        instruction = QLabel(
            "Enter a pixel math expression using image slot variables.\n"
            "Examples:\n"
            "  (slot0 + slot1) / 2\n"
            "  slot0 - med(slot0)\n"
            "  ~(~slot0 * ~slot1)\n"
            "  slot0 - mean(slot0)\n"
            "  min(slot0) + max(slot0)\n"
            "  log(slot0)\n"
            "  iff(slot0 < med(slot0), 0, 1)\n"
            "  mtf(slot0, 0.25)   <-- midtones transform\n\n"
            "You may also use your renamed slot names (e.g., stars_image, starless_image).\n"
            "Note: The '~' operator means image inversion (i.e., 1 - image),\n"
            "      '^' is overloaded for exponentiation, and 'iff' is a conditional function.\n"
            "      For Separate Expressions use channel indexes ie slot0[0] + slot0[1] etc.\n"
        )
        main_layout.addWidget(instruction)

        # --- Radio Buttons for Single vs. Separate ---
        mode_layout = QHBoxLayout()
        self.single_expr_radio = QRadioButton("Single Expression")
        self.separate_expr_radio = QRadioButton("Separate Expressions (R, G, B)")
        self.single_expr_radio.setChecked(True)
        
        self.mode_button_group = QButtonGroup()
        self.mode_button_group.addButton(self.single_expr_radio)
        self.mode_button_group.addButton(self.separate_expr_radio)
        self.mode_button_group.buttonClicked.connect(self.on_mode_changed)
        
        mode_layout.addWidget(self.single_expr_radio)
        mode_layout.addWidget(self.separate_expr_radio)
        main_layout.addLayout(mode_layout)

        # --- Single Expression Field ---
        self.single_expression_edit = QPlainTextEdit()
        self.single_expression_edit.setPlaceholderText("Enter single pixel math expression")
        self.single_expression_edit.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        main_layout.addWidget(self.single_expression_edit)

        # --- Separate (Per-Channel) Expressions (Tab Widget) ---
        self.tab_widget = QTabWidget()
        self.tab_widget.setVisible(False)  # hidden by default
        # Create a tab for R, G, B
        self.red_edit = QPlainTextEdit()
        self.red_edit.setPlaceholderText("Expression for Red channel")
        self.green_edit = QPlainTextEdit()
        self.green_edit.setPlaceholderText("Expression for Green channel")
        self.blue_edit = QPlainTextEdit()
        self.blue_edit.setPlaceholderText("Expression for Blue channel")

        # Optionally set the same stylesheet on these fields:
        for editor in (self.red_edit, self.green_edit, self.blue_edit):
            editor.setStyleSheet("""
                QPlainTextEdit {
                    background-color: white;
                    color: black;
                    font-size: 12px;
                    font-family: 'Courier New', Courier, monospace;
                    padding: 5px;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                }
                QPlainTextEdit::line {
                    background-color: #f0faff;
                }
                QPlainTextEdit::line:nth-child(odd) {
                    background-color: #e6f7ff;
                }
                QPlainTextEdit::line:nth-child(even) {
                    background-color: #f0faff;
                }
            """)

        # Add them as tabs
        tab_r = QWidget()
        tab_r_layout = QVBoxLayout(tab_r)
        tab_r_layout.addWidget(self.red_edit)
        self.tab_widget.addTab(tab_r, "Red")

        tab_g = QWidget()
        tab_g_layout = QVBoxLayout(tab_g)
        tab_g_layout.addWidget(self.green_edit)
        self.tab_widget.addTab(tab_g, "Green")

        tab_b = QWidget()
        tab_b_layout = QVBoxLayout(tab_b)
        tab_b_layout.addWidget(self.blue_edit)
        self.tab_widget.addTab(tab_b, "Blue")

        main_layout.addWidget(self.tab_widget)

        # --- Favorites area ---
        favorites_layout = QHBoxLayout()
        self.favorites_dropdown = QComboBox()
        self.favorites_dropdown.addItem("Select a favorite expression")
        self.favorites_dropdown.currentTextChanged.connect(self.load_favorite)
        favorites_layout.addWidget(self.favorites_dropdown)

        self.save_favorite_button = QPushButton("Save as Favorite")
        self.save_favorite_button.clicked.connect(self.save_favorite)
        favorites_layout.addWidget(self.save_favorite_button)

        # Remove Favorite Button
        self.remove_favorite_button = QPushButton("Remove Favorite")
        self.remove_favorite_button.clicked.connect(self.remove_selected_favorite)
        favorites_layout.addWidget(self.remove_favorite_button)

        # Clear All Favorites Button
        self.clear_all_favorites_button = QPushButton("Clear All Favorites")
        self.clear_all_favorites_button.clicked.connect(self.clear_all_favorites)
        favorites_layout.addWidget(self.clear_all_favorites_button)

        main_layout.addLayout(favorites_layout)

        # --- Buttons (OK, Cancel, Help) ---
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(self.apply_pixel_math)
        buttons.rejected.connect(self.reject)
        help_button = buttons.addButton("Help", QDialogButtonBox.ButtonRole.HelpRole)
        help_button.clicked.connect(self.show_help)
        main_layout.addWidget(buttons)

        self.setLayout(main_layout)

    def on_mode_changed(self, button):
        """
        Switch UI between single expression mode and separate (R,G,B) mode.
        """
        if button == self.single_expr_radio:
            # Single expression
            self.single_expression_edit.setVisible(True)
            self.tab_widget.setVisible(False)
        else:
            # Separate (R,G,B)
            self.single_expression_edit.setVisible(False)
            self.tab_widget.setVisible(True)

    # --- Favorite Expressions Persistence ---
    def load_favorites(self):
        if self.settings:
            favorites_list = self.settings.value("pixelmath_favorites", [])
            if isinstance(favorites_list, str):
                try:
                    favorites_list = json.loads(favorites_list)
                except Exception:
                    favorites_list = []
            elif not isinstance(favorites_list, list):
                favorites_list = list(favorites_list)
            self.favorites = favorites_list
        else:
            self.favorites = []
        
        self.favorites_dropdown.clear()
        self.favorites_dropdown.addItem("Select a favorite expression")
        for fav in self.favorites:
            self.favorites_dropdown.addItem(fav)

    def save_favorite(self):
        """
        Save the currently visible expression(s) as a favorite.
        For simplicity, we’ll just store the single or the RGB triple.
        """
        if self.single_expr_radio.isChecked():
            expr = self.single_expression_edit.toPlainText().strip()
        else:
            # For separate mode, maybe store the R/G/B together in some notation:
            r_expr = self.red_edit.toPlainText().strip()
            g_expr = self.green_edit.toPlainText().strip()
            b_expr = self.blue_edit.toPlainText().strip()
            expr = f"[R]{r_expr} | [G]{g_expr} | [B]{b_expr}"

        if expr and expr not in self.favorites:
            self.favorites.append(expr)
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.favorites_dropdown.addItem(expr)
            QMessageBox.information(self, "Saved as Favorite", "Expression saved to favorites.")
        else:
            QMessageBox.warning(self, "Invalid Expression", "Expression is empty or already in favorites.")

    def remove_selected_favorite(self):
        """
        Remove the currently selected favorite from the dropdown and from self.favorites.
        """
        current_text = self.favorites_dropdown.currentText()
        if current_text == "Select a favorite expression":
            QMessageBox.information(self, "Remove Favorite", "No valid favorite is selected.")
            return

        # Confirm removal
        reply = QMessageBox.question(
            self, 
            "Remove Favorite", 
            f"Are you sure you want to remove '{current_text}' from favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, 
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            if current_text in self.favorites:
                self.favorites.remove(current_text)
                if self.settings:
                    self.settings.setValue("pixelmath_favorites", self.favorites)
                self.load_favorites()  # reload the dropdown
                QMessageBox.information(self, "Remove Favorite", "Favorite removed successfully.")
            else:
                QMessageBox.warning(self, "Remove Favorite", "Favorite not found in list.")

    def clear_all_favorites(self):
        """
        Clear all favorites after a confirmation.
        """
        reply = QMessageBox.question(
            self,
            "Clear All Favorites",
            "Are you sure you want to remove ALL favorites?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.favorites.clear()
            if self.settings:
                self.settings.setValue("pixelmath_favorites", self.favorites)
            self.load_favorites()
            QMessageBox.information(self, "Clear All Favorites", "All favorites have been removed.")

    def load_favorite(self, favorite_expr):
        """
        If the user picks a favorite that has the [R] [G] [B] format,
        parse it into the separate text fields. Otherwise, treat it as a single expression.
        """
        if favorite_expr == "Select a favorite expression":
            return

        # Quick detection to see if it has the [R] or [G] or [B] tokens
        if "[R]" in favorite_expr or "[G]" in favorite_expr or "[B]" in favorite_expr:
            # Switch to separate mode
            self.separate_expr_radio.setChecked(True)
            self.on_mode_changed(self.separate_expr_radio)

            # Attempt to split them out
            # Simple approach: [R] ... | [G] ... | [B] ...
            parts = favorite_expr.split("|")
            r_expr = ""
            g_expr = ""
            b_expr = ""
            for p in parts:
                p = p.strip()
                if p.startswith("[R]"):
                    r_expr = p[3:].strip()
                elif p.startswith("[G]"):
                    g_expr = p[3:].strip()
                elif p.startswith("[B]"):
                    b_expr = p[3:].strip()

            self.red_edit.setPlainText(r_expr)
            self.green_edit.setPlainText(g_expr)
            self.blue_edit.setPlainText(b_expr)
        else:
            # Single expression
            self.single_expr_radio.setChecked(True)
            self.on_mode_changed(self.single_expr_radio)
            self.single_expression_edit.setPlainText(favorite_expr)
    # --- Pixel Math Evaluation ---
    def show_help(self):
        help_text = (
            "Allowed Operators:\n"
            "  +, -, *, /: Standard arithmetic operations\n"
            "  ^: Exponentiation (overloaded; e.g., slot0 ^ 2 means slot0**2)\n"
            "  ~: Image inversion (i.e., 1 - image)\n"
            "  <, ==: Elementwise comparisons (slot0 < med(slot0))\n\n"
            "Allowed Functions:\n"
            "  med(x), mean(x), min(x), max(x), std(x), mad(x), log(x)\n"
            "  iff(condition, a, b): elementwise conditional\n"
            "  mtf(x, m): Midtones transform\n\n"
            "Variables:\n"
            "  img: The current image (replicated to RGB if needed)\n"
            "  slot0, slot1, ...: image slots\n"
            "  Channels can be accessed via [0],[1],[2]. e.g. slot0[0]\n\n"
            "Notes:\n"
            "  - Grayscale images automatically get 3 channels.\n"
            "  - For separate expressions mode, each expression is evaluated for its channel.\n"
        )
        QMessageBox.information(self, "Pixel Math Help", help_text)

    # Updated helper functions (med, mean, min, max, std, mad, log, iff, mtf) remain unchanged...
    def med(self, x):
        """
        Return a PixelImage where each channel (if present) is replaced by its median value.
        If x is 2D, we replace that entire 2D array with its median.
        """
        if isinstance(x, PixelImage):
            arr = x.array
            if arr.ndim == 2:
                # Single-channel (2D)
                median_val = np.median(arr)
                # Make a new 2D array with every pixel = median_val
                new_arr = np.full_like(arr, median_val)
                return PixelImage(new_arr)
            elif arr.ndim == 3:
                # 3D: compute per-channel medians
                med_vals = np.median(arr, axis=(0, 1))  # shape (3,)
                new_arr = np.empty_like(arr)
                for ch in range(arr.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return PixelImage(new_arr)
            else:
                # Some unexpected dimensionality
                raise ValueError(f"med() got array with unsupported ndim={arr.ndim}")
        else:
            # If x is not a PixelImage but a raw np.ndarray, handle that scenario similarly:
            if x.ndim == 2:
                median_val = np.median(x)
                new_arr = np.full_like(x, median_val)
                return new_arr
            elif x.ndim == 3:
                med_vals = np.median(x, axis=(0,1))
                new_arr = np.empty_like(x)
                for ch in range(x.shape[2]):
                    new_arr[..., ch] = med_vals[ch]
                return new_arr
            else:
                # 1D or something else
                return np.median(x)
            
    def mean(self, x):
        """Replace each channel (or the single channel) by its mean value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            # Single channel (2D)
            val = np.mean(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            # 3-channel
            means = np.mean(arr, axis=(0, 1))  # shape=(3,)
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = means[ch]
        else:
            # 1D or something else—decide how you want to handle it or just return arr
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def min(self, x):
        """Replace each channel (or the single channel) by its min value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.min(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            mins = np.min(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = mins[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def max(self, x):
        """Replace each channel (or the single channel) by its max value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.max(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            maxs = np.max(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = maxs[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def std(self, x):
        """Replace each channel (or the single channel) by its std value."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            val = np.std(arr)
            new_arr = np.full(arr.shape, val, dtype=arr.dtype)
        elif arr.ndim == 3:
            stds = np.std(arr, axis=(0, 1))
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                new_arr[..., ch] = stds[ch]
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def mad(self, x):
        """Replace each channel (or the single channel) by its median absolute deviation."""
        if isinstance(x, PixelImage):
            arr = x.array
            was_pixelimage = True
        else:
            arr = x
            was_pixelimage = False

        if arr.ndim == 2:
            m = np.median(arr)
            mad_val = np.median(np.abs(arr - m))
            new_arr = np.full(arr.shape, mad_val, dtype=arr.dtype)
        elif arr.ndim == 3:
            new_arr = np.empty_like(arr)
            for ch in range(arr.shape[2]):
                channel = arr[..., ch]
                m = np.median(channel)
                mad_val = np.median(np.abs(channel - m))
                new_arr[..., ch] = mad_val
        else:
            new_arr = arr

        return PixelImage(new_arr) if was_pixelimage else new_arr

    def log(self, x):
        if isinstance(x, PixelImage):
            return PixelImage(np.log(x.array))
        else:
            return np.log(x)

    def iff(self, condition, a, b):
        if isinstance(condition, PixelImage):
            cond_val = condition.array
        else:
            cond_val = condition

        if isinstance(a, PixelImage):
            a_val = a.array
        else:
            a_val = a

        if isinstance(b, PixelImage):
            b_val = b.array
        else:
            b_val = b

        result = np.where(cond_val, a_val, b_val)
        if isinstance(condition, PixelImage) or isinstance(a, PixelImage) or isinstance(b, PixelImage):
            return PixelImage(result)
        else:
            return result

    def mtf(self, x, m):
        if isinstance(x, PixelImage):
            arr = x.array
        else:
            arr = x
        with np.errstate(divide='ignore', invalid='ignore'):
            new_arr = ((m - 1) * arr) / (((2 * m - 1) * arr) - m)
            new_arr = np.nan_to_num(new_arr, nan=0.0, posinf=1.0, neginf=0.0)
        if isinstance(x, PixelImage):
            return PixelImage(new_arr)
        else:
            return new_arr

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                if self.image_manager.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                if mask.shape[:2] != self.image_manager.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None


    def evaluate_multiline_expression(self, expr, safe_namespace):
        """
        Allows multiple lines in the user expression.
        - All but the last line are executed with `exec`, so they can contain assignments.
        - The last line is evaluated with `eval` to produce the final result.
        """

        # Split into lines and strip out empty ones
        lines = [line.strip() for line in expr.split('\n') if line.strip()]
        if not lines:
            raise ValueError("No expression provided.")

        # Exec each line except the last
        for line in lines[:-1]:
            exec(line, {"__builtins__": None}, safe_namespace)

        # Evaluate the last line, which must be an expression returning a result
        final_line = lines[-1]
        result = eval(final_line, {"__builtins__": None}, safe_namespace)
        return result

    def apply_pixel_math(self):
        """
        Evaluates the user-entered expression(s) and updates the current image slot.
        If single_expr_radio is checked, we do the usual single-expression approach.
        If separate_expr_radio is checked, we evaluate three expressions (R, G, B).
        """
        if self.single_expr_radio.isChecked():
            # Single expression mode
            expr = self.single_expression_edit.toPlainText().strip()
            if not expr:
                QMessageBox.warning(self, "No Expression", "Please enter a valid pixel math expression.")
                return
            
            try:
                # Evaluate single expression
                result = self.evaluate_expression(expr)

                # Convert PixelImage -> array if needed
                if isinstance(result, PixelImage):
                    new_img = result.array
                else:
                    new_img = result

                # If it's a scalar, fill the current image shape
                ref = self.image_manager.image
                if ref is None:
                    # fall back to the first non-empty slot variable
                    for i in range(self.image_manager.max_slots):
                        slot_img = self.image_manager._images.get(i)
                        if slot_img is not None:
                            ref = slot_img
                            break
                if ref is None:
                    raise ValueError("No image or slot referenced; cannot infer output size.")

                # normalize ref to 3-channel if needed
                if ref.ndim == 2:
                    ref_arr = np.stack([ref]*3, axis=-1)
                else:
                    ref_arr = ref

                # if scalar, broadcast
                if np.isscalar(new_img):
                    new_img = np.full(ref_arr.shape, new_img, dtype=ref_arr.dtype)

                # Update the image
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = expr
                mask = self.get_active_mask()
                if mask is not None:
                    original = self.image_manager.image
                    if original.ndim == 2:
                        original = np.stack([original]*3, axis=-1)
                    if mask.ndim == 2:
                        mask = np.expand_dims(mask, axis=-1)
                    if mask.shape[2] == 1 and original.ndim == 3:
                        mask = np.repeat(mask, original.shape[2], axis=2)

                    new_img = new_img * mask + original * (1 - mask)
                    new_img = np.clip(new_img, 0.0, 1.0)

                self.image_manager.set_image(new_img, metadata, step_name="Pixel Math")

                QMessageBox.information(self, "Pixel Math", "Pixel math operation applied successfully.")
                self.accept()
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

        else:
            # Separate expressions mode
            expr_r = self.red_edit.toPlainText().strip()
            expr_g = self.green_edit.toPlainText().strip()
            expr_b = self.blue_edit.toPlainText().strip()

            if not expr_r and not expr_g and not expr_b:
                QMessageBox.warning(self, "No Expression", 
                                    "Please enter a valid expression for at least one channel.")
                return

            try:
                # Evaluate each channel expression or treat as 0 if blank
                r_result = self.evaluate_expression(expr_r) if expr_r else 0
                g_result = self.evaluate_expression(expr_g) if expr_g else 0
                b_result = self.evaluate_expression(expr_b) if expr_b else 0

                # Convert PixelImages to arrays
                if isinstance(r_result, PixelImage):
                    r_result = r_result.array
                if isinstance(g_result, PixelImage):
                    g_result = g_result.array
                if isinstance(b_result, PixelImage):
                    b_result = b_result.array

                # Validate shapes: must be scalar or 2D
                def ensure_2d_or_scalar(arr, channel_name):
                    if np.isscalar(arr):
                        return
                    if arr.ndim == 3:
                        raise ValueError(
                            f"Expression for {channel_name} returned a 3D array. "
                            "In separate expressions mode, please specify a single channel, e.g. slot0[0]."
                        )

                ensure_2d_or_scalar(r_result, "Red")
                ensure_2d_or_scalar(g_result, "Green")
                ensure_2d_or_scalar(b_result, "Blue")

                # Now get shape of current image for stacking
                current_img = self.image_manager.image
                if current_img is None:
                    QMessageBox.warning(self, "No Image", "There is no image loaded to operate on.")
                    return
                if current_img.ndim == 2:
                    current_img = np.stack([current_img]*3, axis=-1)
                
                h, w, _ = current_img.shape

                # If scalar, fill to (H,W)
                if np.isscalar(r_result):
                    r_result = np.full((h, w), r_result, dtype=current_img.dtype)
                if np.isscalar(g_result):
                    g_result = np.full((h, w), g_result, dtype=current_img.dtype)
                if np.isscalar(b_result):
                    b_result = np.full((h, w), b_result, dtype=current_img.dtype)

                # Stack
                combined = np.stack([r_result, g_result, b_result], axis=-1)

                # Update the slot
                current_slot = self.image_manager.current_slot
                metadata = self.image_manager._metadata.get(current_slot, {}).copy()
                metadata['pixel_math'] = f"R:{expr_r}, G:{expr_g}, B:{expr_b}"
                mask = self.get_active_mask()
                if mask is not None:
                    original = self.image_manager.image
                    if original.ndim == 2:
                        original = np.stack([original]*3, axis=-1)
                    if mask.ndim == 2:
                        mask = np.expand_dims(mask, axis=-1)
                    if mask.shape[2] == 1 and original.ndim == 3:
                        mask = np.repeat(mask, original.shape[2], axis=2)

                    combined = combined * mask + original * (1 - mask)
                    combined = np.clip(combined, 0.0, 1.0)

                self.image_manager.set_image(combined, metadata, step_name="Pixel Math")


                QMessageBox.information(self, "Pixel Math", 
                                        "Pixel math operation (per-channel) applied successfully.")
                self.accept()

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to apply pixel math expression:\n{e}")

    def evaluate_expression(self, expr):
        """
        Evaluates a single expression in the restricted environment (safe_namespace).
        Returns a PixelImage or numpy array. 
        """
        if not expr:
            return 0  # If no expression, treat as 0

        # Create a safe namespace
        safe_namespace = {
            "np": np,
            "med": self.med,
            "mean": self.mean,
            "min": self.min,
            "max": self.max,
            "std": self.std,
            "mad": self.mad,
            "log": self.log,
            "iff": self.iff,
            "mtf": self.mtf,
        }

        # Insert current image as 'img'
        current_img = self.image_manager.image
        if current_img is not None:
            if current_img.ndim == 2:
                current_img = np.stack([current_img]*3, axis=-1)
            safe_namespace["img"] = PixelImage(current_img)

        # Insert image slots as slot0, slot1, ...
        max_slots = self.image_manager.max_slots
        parent = self.parent()
        for i in range(max_slots):
            img = self.image_manager._images.get(i, None)
            if img is not None:
                if img.ndim == 2:
                    img = np.stack([img]*3, axis=-1)
                pix_img = PixelImage(img)
                safe_namespace[f"slot{i}"] = pix_img
                if parent is not None and hasattr(parent, "slot_names"):
                    custom_name = parent.slot_names.get(i, None)
                    if custom_name:
                        safe_namespace[custom_name] = pix_img

        # Evaluate
            # Instead of a direct `eval`, we now do:
        return self.evaluate_multiline_expression(expr, safe_namespace)


class TransformHandle(QGraphicsEllipseItem):
    def __init__(self, parent_item, scene):
        super().__init__(-5, -5, 10, 10)
        self.parent_item = parent_item
        self.scene = scene

        self.setBrush(QColor("blue"))
        self.setPen(QPen(Qt.PenStyle.SolidLine))
        self.setCursor(Qt.CursorShape.SizeAllCursor)
        self.setZValue(2)

        self.setFlags(
            QGraphicsItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsItem.GraphicsItemFlag.ItemIsFocusable |
            QGraphicsItem.GraphicsItemFlag.ItemIgnoresParentOpacity |
            QGraphicsItem.GraphicsItemFlag.ItemIsSelectable
        )

        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton)
        self.setAcceptHoverEvents(True)

        self.initial_distance = None
        self.initial_angle = None
        self.initial_scale = parent_item.scale()

        self.scene.addItem(self)
        self.update_position()

    def update_position(self):
        corner = self.parent_item.boundingRect().topRight()
        scene_corner = self.parent_item.mapToScene(corner)
        self.setPos(scene_corner)

    def mousePressEvent(self, event):
        center = self.parent_item.mapToScene(self.parent_item.boundingRect().center())
        handle_scene_pos = self.scenePos()
        delta = handle_scene_pos - center
        self.initial_distance = math.hypot(delta.x(), delta.y())
        self.initial_angle = math.degrees(math.atan2(delta.y(), delta.x()))
        self.initial_scale = self.parent_item.scale()
        event.accept()

    def mouseMoveEvent(self, event):
        center = self.parent_item.mapToScene(self.parent_item.boundingRect().center())
        new_pos = self.mapToScene(event.pos())
        delta = new_pos - center
        distance = math.hypot(delta.x(), delta.y())
        angle = math.degrees(math.atan2(delta.y(), delta.x()))

        # Apply scale
        scale_factor = distance / self.initial_distance if self.initial_distance != 0 else 1.0
        scale = max(0.05, self.initial_scale * scale_factor)
        self.parent_item.setScale(scale)

        # Apply rotation
        rotation = angle - self.initial_angle
        self.parent_item.setRotation(rotation)

        self.update_position()
        event.accept()

    def mouseReleaseEvent(self, event):
        self.initial_distance = None
        self.initial_angle = None
        self.initial_scale = self.parent_item.scale()
        event.accept()


class InsertView(QGraphicsView):
    def __init__(self, scene, parent_window):
        super().__init__(scene)
        self.parent_window = parent_window
        self.setRenderHints(QPainter.RenderHint.Antialiasing | QPainter.RenderHint.SmoothPixmapTransform)
        self.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)
        self.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        self.zoom_factor = 1.0
        self.min_zoom = 0.1
        self.max_zoom = 10.0

    def contextMenuEvent(self, event):
        scene_pos = self.mapToScene(event.pos())
        item = self.scene().itemAt(scene_pos, self.transform())

        # If it's a bounding box, get its parent item
        if isinstance(item, QGraphicsRectItem) and item.parentItem() in self.parent_window.inserts:
            item = item.parentItem()

        if isinstance(item, QGraphicsPixmapItem) and item in self.parent_window.inserts:
            menu = QMenu(self)
            positions = {
                "Top-Left": "top_left",
                "Top-Center": "top_center",
                "Top-Right": "top_right",
                "Middle-Left": "middle_left",
                "Center": "center",
                "Middle-Right": "middle_right",
                "Bottom-Left": "bottom_left",
                "Bottom-Center": "bottom_center",
                "Bottom-Right": "bottom_right"
            }
            for label, key in positions.items():
                menu.addAction(label, lambda k=key, i=item: self.parent_window.send_insert_to_position(i, k))
            menu.exec(event.globalPos())
        else:
            super().contextMenuEvent(event)

    def wheelEvent(self, event):
        # Support Ctrl+Wheel only
        if event.modifiers() & Qt.KeyboardModifier.ControlModifier:
            zoom_in = event.angleDelta().y() > 0
            zoom_step = 1.15
            factor = zoom_step if zoom_in else 1 / zoom_step
            self.set_zoom(self.zoom_factor * factor)
        else:
            super().wheelEvent(event)

    def set_zoom(self, new_zoom):
        new_zoom = max(self.min_zoom, min(self.max_zoom, new_zoom))
        self.zoom_factor = new_zoom
        self.setTransform(QTransform().scale(new_zoom, new_zoom))

    def zoom_in(self):
        self.set_zoom(self.zoom_factor * 1.15)

    @announce_zoom
    def zoom_out(self):
        self.set_zoom(self.zoom_factor / 1.15)

    def reset_zoom(self):
        self.set_zoom(1.0)

class SignatureInsertWindow(QMainWindow):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)  # Pass parent to super
        self.image_manager = image_manager
        self.setWindowTitle("Signature / Insert")
        self.setWindowIcon(QIcon(signature_icon_path))
        self.scene = QGraphicsScene(self)
        self.view = InsertView(self.scene, self)
        self.inserts = []
        self.bounding_boxes_enabled = True
        self.bounding_boxes = []
        self.bounding_box_pen = QPen(QColor("red"), 2, Qt.PenStyle.DashLine)


        # Sync timer for handle positioning
        self.sync_timer = QTimer()
        self.sync_timer.timeout.connect(self.sync_handles)
        self.sync_timer.start(16)

        # Set up UI
        central = QWidget(self)
        self.setCentralWidget(central)
        self.initUI(central)
        self.resize(800, 600)

    def initUI(self, parent):
        layout = QHBoxLayout(parent)
        controls = QVBoxLayout()

        load_slot_btn = QPushButton("Load Insert from Slot")
        load_slot_btn.clicked.connect(lambda: self.load_insert_source("slot"))
        load_file_btn = QPushButton("Load Insert from File")
        load_file_btn.clicked.connect(lambda: self.load_insert_source("file"))

        rotate_btn = QPushButton("Rotate Selected 90°")
        rotate_btn.clicked.connect(self.rotate_selected)

        self.scale_slider = QSlider(Qt.Orientation.Horizontal)
        self.scale_slider.setRange(10, 400)
        self.scale_slider.setValue(100)
        self.scale_slider.valueChanged.connect(self.scale_selected)

        self.opacity_slider = QSlider(Qt.Orientation.Horizontal)
        self.opacity_slider.setRange(0, 100)
        self.opacity_slider.setValue(100)
        self.opacity_slider.valueChanged.connect(self.opacity_changed)

        self.draw_box_checkbox = QCheckBox("Draw Bounding Box")
        self.draw_box_checkbox.setChecked(True)
        self.draw_box_checkbox.stateChanged.connect(self.toggle_bounding_boxes)

        # Color selector
        self.box_color_btn = QPushButton("Box Color")
        self.box_color_btn.clicked.connect(self.pick_box_color)

        # Thickness
        self.box_thickness_slider = QSlider(Qt.Orientation.Horizontal)
        self.box_thickness_slider.setRange(1, 10)
        self.box_thickness_slider.setValue(2)
        self.box_thickness_slider.valueChanged.connect(self.update_box_pen)

        # Style selector
        self.box_style_combo = QComboBox()
        self.box_style_combo.addItems(["Solid", "Dash", "Dot", "DashDot", "DashDotDot"])
        self.box_style_combo.currentIndexChanged.connect(self.update_box_pen)

        affix_btn = QPushButton("Affix Inserts")
        affix_btn.clicked.connect(self.affix_inserts)
        clear_btn = QPushButton("Clear All Inserts")
        clear_btn.clicked.connect(self.clear_inserts)

        zoom_controls = QHBoxLayout()
        zoom_in_btn = QPushButton("Zoom In")
        zoom_out_btn = QPushButton("Zoom Out")
        zoom_reset_btn = QPushButton("Reset Zoom")

        zoom_in_btn.clicked.connect(self.view.zoom_in)
        zoom_out_btn.clicked.connect(self.view.zoom_out)
        zoom_reset_btn.clicked.connect(self.view.reset_zoom)

        zoom_controls.addWidget(zoom_out_btn)
        zoom_controls.addWidget(zoom_in_btn)
        zoom_controls.addWidget(zoom_reset_btn)

        controls.addWidget(load_slot_btn)
        controls.addWidget(load_file_btn)
        controls.addSpacing(10)
        controls.addWidget(rotate_btn)
        controls.addWidget(QLabel("Scale Selected (%)"))
        controls.addWidget(self.scale_slider)
        controls.addWidget(QLabel("Transparency (%)"))
        controls.addWidget(self.opacity_slider)        
        controls.addSpacing(10)
        controls.addWidget(self.draw_box_checkbox)
        controls.addWidget(QLabel("Bounding Box Settings"))
        controls.addWidget(self.box_color_btn)
        controls.addWidget(QLabel("Box Thickness"))
        controls.addWidget(self.box_thickness_slider)
        controls.addWidget(QLabel("Box Style"))
        controls.addWidget(self.box_style_combo)        
        controls.addSpacing(10)
        controls.addStretch(1)
        controls.addWidget(QLabel("Right-click on an insert to send it a location."))
        controls.addWidget(affix_btn)
        controls.addWidget(clear_btn)
        controls.addStretch(1)
        controls.addSpacing(10)
        controls.addLayout(zoom_controls)

        container = QWidget()
        container.setLayout(controls)
        layout.addWidget(container)
        layout.addWidget(self.view, stretch=1)
        parent.setLayout(layout)

        self.update_main_image()

    def contextMenuEvent(self, event):
        """Show right-click menu on an insert."""
        item = self.scene.itemAt(self.view.mapToScene(event.pos()), self.view.transform())
        if isinstance(item, QGraphicsPixmapItem) and item in self.inserts:
            menu = QMenu(self)
            positions = {
                "Top-Left": "top_left",
                "Top-Center": "top_center",
                "Top-Right": "top_right",
                "Middle-Left": "middle_left",
                "Center": "center",
                "Middle-Right": "middle_right",
                "Bottom-Left": "bottom_left",
                "Bottom-Center": "bottom_center",
                "Bottom-Right": "bottom_right"
            }
            for label, pos_key in positions.items():
                menu.addAction(label, lambda pk=pos_key, i=item: self.send_insert_to_position(i, pk))
            menu.exec(event.globalPos())

    def send_insert_to_position(self, item, position_key):
        """Move insert to a specific location on the base image, respecting signature size."""
        base_item = next((obj for obj in self.scene.items()
                        if isinstance(obj, QGraphicsPixmapItem) and obj.zValue() == 0), None)
        if not base_item:
            return

        base_rect = base_item.boundingRect()
        item_rect = item.boundingRect()
        item_size = item_rect.size()

        # Compute target top-left point inside the base image
        if position_key == "top_left":
            target = base_rect.topLeft()
        elif position_key == "top_center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2, base_rect.top())
        elif position_key == "top_right":
            target = QPointF(base_rect.right() - item_size.width(), base_rect.top())
        elif position_key == "middle_left":
            target = QPointF(base_rect.left(), base_rect.center().y() - item_size.height() / 2)
        elif position_key == "center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2,
                            base_rect.center().y() - item_size.height() / 2)
        elif position_key == "middle_right":
            target = QPointF(base_rect.right() - item_size.width(),
                            base_rect.center().y() - item_size.height() / 2)
        elif position_key == "bottom_left":
            target = QPointF(base_rect.left(), base_rect.bottom() - item_size.height())
        elif position_key == "bottom_center":
            target = QPointF(base_rect.center().x() - item_size.width() / 2,
                            base_rect.bottom() - item_size.height())
        elif position_key == "bottom_right":
            target = QPointF(base_rect.right() - item_size.width(),
                            base_rect.bottom() - item_size.height())
        else:
            return  # Unknown key

        # Convert target to scene coordinates
        new_scene_pos = base_item.mapToScene(target)
        item.setPos(new_scene_pos)


    def sync_handles(self):
        for item in self.scene.items():
            if isinstance(item, TransformHandle):
                item.update_position()

    def update_main_image(self):
        self.scene.clear()
        arr = self.image_manager.image
        if arr is None:
            return
        qimg = self.numpy_to_qimage(arr)
        pix = QPixmap.fromImage(qimg)
        item = QGraphicsPixmapItem(pix)
        item.setZValue(0)
        self.scene.addItem(item)

    def load_insert_source(self, source):
        pixmap = None

        if source == "file":
            file_path, _ = QFileDialog.getOpenFileName(
                self, "Select Insert Image", "", "Images (*.png *.tif *.tiff)"
            )
            if not file_path:
                return
            pixmap = QPixmap(file_path)

        elif source == "slot":
            # Ask which slot...
            if self.parent() and hasattr(self.parent(), "slot_names"):
                slot_names = self.parent().slot_names
            else:
                slot_names = {i: f"Slot {i}" for i in range(self.image_manager.max_slots)}
            display = [slot_names[i] for i in range(self.image_manager.max_slots)]
            choice, ok = QInputDialog.getItem(self, "Select Slot", "Choose slot:", display, False)
            if not ok:
                return
            idx = display.index(choice)

            # --- ALWAYS use the in-memory image array for slots ---
            img_data = self.image_manager._images.get(idx)
            if img_data is None:
                QMessageBox.warning(self, "Missing Image", f"No image data in slot {idx}.")
                return
            qimg = self.numpy_to_qimage(img_data)
            pixmap = QPixmap.fromImage(qimg)

        # If we still don't have a valid pixmap, warn and bail
        if pixmap is None or pixmap.isNull():
            QMessageBox.warning(self, "Load Failed", "Could not load insert image.")
            return

        # Otherwise add it exactly as before...
        item = QGraphicsPixmapItem(pixmap)
        item.setFlags(
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsMovable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsSelectable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemIsFocusable |
            QGraphicsPixmapItem.GraphicsItemFlag.ItemSendsGeometryChanges
        )
        item.setTransformationMode(Qt.TransformationMode.SmoothTransformation)
        item.setTransformOriginPoint(item.boundingRect().center())
        item.setZValue(1)
        item.setOpacity(1.0)

        self.scene.addItem(item)
        self.inserts.append(item)
        TransformHandle(item, self.scene)

        if self.bounding_boxes_enabled:
            rect = QGraphicsRectItem(item.boundingRect())
            rect.setParentItem(item)
            rect.setPen(self.bounding_box_pen)
            rect.setAcceptedMouseButtons(Qt.MouseButton.NoButton)
            rect.setAcceptDrops(False)
            rect.setFlag(QGraphicsItem.GraphicsItemFlag.ItemIgnoresParentOpacity, True)
            rect.setFlag(QGraphicsItem.GraphicsItemFlag.ItemDoesntPropagateOpacityToChildren, True)
            rect.setZValue(item.zValue() + 0.1)
            self.scene.addItem(rect)
            self.bounding_boxes.append(rect)


    def rotate_selected(self):
        for it in self.inserts:
            if it.isSelected():
                it.setRotation(it.rotation() + 90)

    def scale_selected(self, value):
        factor = value / 100.0
        for it in self.inserts:
            if it.isSelected():
                it.setScale(factor)
                for box in self.bounding_boxes:
                    if box.parentItem() == it:
                        box.setRect(it.boundingRect())



    def opacity_changed(self, value):
        """Set opacity of selected inserts from 0% (transparent) to 100% (opaque)."""
        opacity = value / 100.0
        for it in self.inserts:
            if it.isSelected():
                it.setOpacity(opacity)

    def toggle_bounding_boxes(self, state):
        self.bounding_boxes_enabled = bool(state)
        for box in self.bounding_boxes:
            box.setVisible(self.bounding_boxes_enabled)

    def pick_box_color(self):
        color = QColorDialog.getColor()
        if color.isValid():
            self.bounding_box_pen.setColor(color)
            self.update_all_bounding_boxes()

    def update_box_pen(self):
        style_map = {
            "Solid": Qt.PenStyle.SolidLine,
            "Dash": Qt.PenStyle.DashLine,
            "Dot": Qt.PenStyle.DotLine,
            "DashDot": Qt.PenStyle.DashDotLine,
            "DashDotDot": Qt.PenStyle.DashDotDotLine
        }
        self.bounding_box_pen.setWidth(self.box_thickness_slider.value())
        self.bounding_box_pen.setStyle(style_map[self.box_style_combo.currentText()])
        self.update_all_bounding_boxes()

    def update_all_bounding_boxes(self):
        for box in self.bounding_boxes:
            box.setPen(self.bounding_box_pen)


    def affix_inserts(self):
        """Bake inserts into the main image and clear overlays."""
        if not self.inserts:
            QMessageBox.information(self, "No Inserts", "There are no inserts to affix.")
            return

        # ✅ Deselect all inserts to avoid selection outlines (but DO NOT hide bounding boxes unless user wants them hidden)
        for it in self.inserts:
            it.setSelected(False)

        # Only hide bounding boxes if checkbox is off
        boxes_to_hide = []
        if not self.bounding_boxes_enabled:
            for box in self.bounding_boxes:
                box.setVisible(False)
                boxes_to_hide.append(box)  # Remember which were hidden

        # 1. Filter items: background + inserts and bounding boxes
        relevant_items = []
        for item in self.scene.items():
            if isinstance(item, QGraphicsPixmapItem) and (item in self.inserts or item.zValue() == 0):
                relevant_items.append(item)
            elif self.bounding_boxes_enabled and isinstance(item, QGraphicsRectItem):
                relevant_items.append(item)


        # 2. Compute bounding rect of relevant items
        bounding_rect = QRectF()
        for item in relevant_items:
            bounding_rect = bounding_rect.united(item.sceneBoundingRect())

        bounding_rect = bounding_rect.normalized()
        x = int(bounding_rect.left())
        y = int(bounding_rect.top())
        width = int(bounding_rect.right()) - x
        height = int(bounding_rect.bottom()) - y

        # 3. Temporarily hide non-relevant items
        hidden_items = []
        for item in self.scene.items():
            if item not in relevant_items:
                item.setVisible(False)
                hidden_items.append(item)

        # 4. Create target QImage and QPainter
        img = QImage(width, height, QImage.Format.Format_ARGB32)
        img.fill(Qt.GlobalColor.transparent)
        painter = QPainter(img)

        # 5. Render scene contents to QImage
        self.scene.render(painter,
                        target=QRectF(0, 0, width, height),
                        source=QRectF(x, y, width, height))
        painter.end()

        # 6. Restore hidden items
        for item in hidden_items:
            item.setVisible(True)

        # Restore any bounding boxes that were temporarily hidden
        for box in boxes_to_hide:
            box.setVisible(True)

        # 7. Convert to NumPy and push to ImageManager (trim alpha)
        arr = self.qimage_to_numpy(img)
        if arr.shape[2] == 4:
            arr = arr[:, :, :3]

        slot = self.image_manager.current_slot
        metadata = self.image_manager._metadata.get(slot, {})
        self.image_manager.set_image(arr, metadata, step_name="Signature Adder")

        # 8. Cleanup overlays
        self.clear_inserts()
        self.update_main_image()


    def clear_inserts(self):
        for it in self.inserts:
            self.scene.removeItem(it)
        self.inserts.clear()
        for box in self.bounding_boxes:
            self.scene.removeItem(box)
        self.bounding_boxes.clear()

    def numpy_to_qimage(self, arr):
        # 1) Normalize & convert to uint8 0–255
        arr = np.clip(arr, 0.0, 1.0)
        arr_uint8 = (arr * 255).astype(np.uint8)

        # 2) Force a contiguous buffer
        arr_c = np.ascontiguousarray(arr_uint8)
        h, w = arr_c.shape[:2]

        # 3) Pick the right QImage format & compute bytesPerLine
        if arr_c.ndim == 2:
            fmt = QImage.Format.Format_Grayscale8
            channels = 1
        elif arr_c.shape[2] == 3:
            fmt = QImage.Format.Format_RGB888
            channels = 3
        elif arr_c.shape[2] == 4:
            fmt = QImage.Format.Format_RGBA8888
            channels = 4
        else:
            raise ValueError(f"Unsupported array shape: {arr_c.shape}")

        bytes_per_line = w * channels

        # 4) Grab a real bytes buffer
        buf = arr_c.tobytes()

        # 5) Build and return the QImage
        return QImage(buf, w, h, bytes_per_line, fmt).copy()

    def qimage_to_numpy(self, img):
        img = img.convertToFormat(QImage.Format.Format_RGBA8888)
        w, h = img.width(), img.height()
        ptr = img.bits()
        ptr.setsize(h * img.bytesPerLine())
        arr = np.frombuffer(ptr, np.uint8).reshape((h, img.bytesPerLine()))
        arr = arr[:, :w * 4].reshape((h, w, 4))
        return arr.astype(np.float32) / 255.0

class InteractiveGraphicsView(QGraphicsView):
    """
    A QGraphicsView that captures Shift+Click to define a Larson–Sekanina center.
    Draws a small crosshair at the chosen point.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.ls_center = None    # (x, y) in scene coordinates
        self.cross_items = []    # To hold the QGraphicsLineItem(s) for the marker

    def mousePressEvent(self, event):
        # If Shift is held during a left‐click, record the LS center:
        if (event.modifiers() & Qt.KeyboardModifier.ShiftModifier) and event.button() == Qt.MouseButton.LeftButton:
            scene_pt = self.mapToScene(event.position().toPoint())
            x, y = scene_pt.x(), scene_pt.y()
            self.ls_center = (x, y)
            self._draw_crosshair_at(x, y)
            # Don’t propagate further, so we don’t start panning:
            return

        # Otherwise, fallback to normal panning behavior:
        super().mousePressEvent(event)

    def _draw_crosshair_at(self, x: float, y: float):
        # Remove any existing crosshair
        for item in self.cross_items:
            self.scene().removeItem(item)
        self.cross_items.clear()

        size = 10  # crosshair half‐length in pixels
        pen = QPen(QColor(255, 0, 0), 2)
        # Horizontal line
        hline = self.scene().addLine(x - size, y, x + size, y, pen)
        # Vertical line
        vline = self.scene().addLine(x, y - size, x, y + size, pen)
        self.cross_items.extend([hline, vline])

class FloatSliderWithEdit(QWidget):
    """
    A composite widget combining a QSlider (integer) and a QLineEdit (float).
    Internally maps the slider’s integer range [min_int … max_int] → float range
    [min_float … max_float] in fixed steps.  Emits valueChanged(float).
    """

    # Signal with the new float value whenever it changes.
    valueChanged = pyqtSignal(float)

    def __init__(
        self,
        *,
        minimum: float,
        maximum: float,
        step: float,
        initial: float,
        suffix: str = "",
        parent = None
    ):
        """
        - minimum, maximum: the float range.
        - step: the smallest increment (e.g. 0.1).
        - initial: starting float value (must lie between [minimum..maximum]).
        - suffix: e.g. " px" or "°", appended in the QLineEdit.
        """
        super().__init__(parent)

        self._min = minimum
        self._max = maximum
        self._step = step
        self._suffix = suffix

        # Compute integer mapping factor = 1/step
        self._factor = 1.0 / step
        # So slider integer range:
        self._int_min = int(round(minimum * self._factor))
        self._int_max = int(round(maximum * self._factor))

        # Layout: QSlider on the left, QLineEdit on the right
        layout = QHBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 0)

        # 1) Build QSlider
        self.slider = QSlider(Qt.Orientation.Horizontal, self)
        self.slider.setRange(self._int_min, self._int_max)
        layout.addWidget(self.slider, stretch=1)

        # 2) Build QLineEdit with validator for float
        self.edit = QLineEdit(self)
        self.edit.setFixedWidth(60)
        validator = QDoubleValidator(minimum, maximum, int(abs(np.log10(step))), self)
        validator.setNotation(QDoubleValidator.Notation.StandardNotation)
        self.edit.setValidator(validator)
        layout.addWidget(self.edit)

        # 3) Initialize both to the given initial value
        self.setValue(initial)

        # 4) Connect slider→edit
        self.slider.valueChanged.connect(self._on_slider_changed)
        # 5) Connect edit→slider (when editing is finished)
        self.edit.editingFinished.connect(self._on_edit_finished)

    def _on_slider_changed(self, int_val: int):
        """
        Called whenever the slider moves.  Convert int_val → float,
        update the text field, and emit valueChanged(float).
        """
        f = int_val / self._factor
        # Clamp to [min..max] in case of rounding
        if f < self._min: f = self._min
        if f > self._max: f = self._max
        text = f"{f:.{max(0, int(-np.log10(self._step)))}f}{self._suffix}"
        # Block signals on edit so we don’t re-enter _on_edit_finished
        self.edit.blockSignals(True)
        self.edit.setText(text)
        self.edit.blockSignals(False)
        self.valueChanged.emit(f)

    def _on_edit_finished(self):
        """
        Called when the user types a number and presses Enter (or leaves the field).
        Parse the float (ignoring suffix), clamp it, update the slider.
        """
        txt = self.edit.text().rstrip(self._suffix)
        try:
            f = float(txt)
        except ValueError:
            # If parsing fails, reset to slider’s current float
            current_int = self.slider.value()
            f = current_int / self._factor

        if f < self._min:
            f = self._min
        elif f > self._max:
            f = self._max

        int_val = int(round(f * self._factor))
        self.slider.blockSignals(True)
        self.slider.setValue(int_val)
        self.slider.blockSignals(False)
        # Setting the slider will trigger _on_slider_changed, which updates the text & emits.

    def value(self) -> float:
        """Return the current float value."""
        return self.slider.value() / self._factor

    def setValue(self, f: float):
        """Programmatically set to a given float f (clamped & rounded)."""
        if f < self._min:
            f = self._min
        elif f > self._max:
            f = self._max
        int_val = int(round(f * self._factor))
        self.slider.blockSignals(True)
        self.slider.setValue(int_val)
        self.slider.blockSignals(False)
        # Also update the text explicitly:
        s = f"{(int_val / self._factor):.{max(0, int(-np.log10(self._step)))}f}{self._suffix}"
        self.edit.setText(s)
        # Finally, emit that value
        self.valueChanged.emit(int_val / self._factor)

class ConvoDeconvoDialog(QDialog):
    """
    Convolution / Deconvolution dialog with a two‐column layout:
     - Left column: parameter tabs + action buttons (Preview, Undo, Push, Close)
     - Right column: a QGraphicsView showing the preview, with Zoom In/Out/Fit controls
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Convolution / Deconvolution")
        self.resize(1000, 650)
        self._use_custom_psf = False
        self._custom_psf = None
        # Make it a top‐level window (won't minimize with parent)
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.Window)

        # Keep track of original & preview images for Undo/Push
        self._original_image = None
        self._preview_result = None

        # ─── Build the two‐column layout ───────────────────────────────────
        main_layout = QHBoxLayout(self)
        # Left panel (controls) will be fixed‐width
        left_panel = QFrame()
        left_panel.setFrameShape(QFrame.Shape.StyledPanel)
        left_panel.setFixedWidth(350)
        left_layout = QVBoxLayout(left_panel)
        main_layout.addWidget(left_panel)

        # Right panel (preview) will expand
        preview_panel = QFrame()
        preview_layout = QVBoxLayout(preview_panel)
        main_layout.addWidget(preview_panel, stretch=1)

        # ─── LEFT PANEL: TABS + Action Buttons ────────────────────────────
        # 1) Tab widget
        self.tabs = QTabWidget()
        left_layout.addWidget(self.tabs)

        self.deconv_param_stack = {}
        self.deconv_stack_container = QWidget()
        self.deconv_stack_layout = QVBoxLayout(self.deconv_stack_container)

        # Build both tabs (as before)
        self._build_convolution_tab()
        self._build_deconvolution_tab()
        self._build_psf_estimator_tab()
        self._build_tv_denoise_tab()
        self.sep_use_button.clicked.connect(self._on_use_stellar_psf)

        # 2) PSF preview label (64×64)
        self.conv_psf_label = QLabel()
        self.conv_psf_label.setFixedSize(64, 64)
        self.conv_psf_label.setStyleSheet("border: 1px solid #888;")
        left_layout.addWidget(self.conv_psf_label, alignment=Qt.AlignmentFlag.AlignHCenter)

        # (strength)
        self.strength_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=1.0, step=0.01, initial=1.0, suffix=""
        )
        strength_layout = QHBoxLayout()
        strength_layout.addWidget(QLabel("Strength:"))
        strength_layout.addWidget(self.strength_slider)
        left_layout.addLayout(strength_layout)

        # 2) Action buttons
        btn_layout = QHBoxLayout()
        self.preview_btn = QPushButton("Preview")
        self.undo_btn    = QPushButton("Undo")
        self.push_btn    = QPushButton("Push to Slot")
        self.close_btn   = QPushButton("Close")
        btn_layout.addWidget(self.preview_btn)
        btn_layout.addWidget(self.undo_btn)
        left_layout.addLayout(btn_layout)

        btn_layout2 = QHBoxLayout()
        btn_layout2.addWidget(self.push_btn)
        btn_layout2.addWidget(self.close_btn)
        left_layout.addLayout(btn_layout2)

        # Add stretch so these stay at the bottom of left panel
        left_layout.addStretch()

        self.rl_status_label = QLabel("")
        self.rl_status_label.setStyleSheet("color: #ffffff; background-color: #333333; padding: 4px;")
        self.rl_status_label.setFixedHeight(24)
        left_layout.addWidget(self.rl_status_label)

        # ─── RIGHT PANEL: Zoom Controls + QGraphicsView ───────────────────
        # 1) Zoom toolbar (in a horizontal layout)
        zoom_layout = QHBoxLayout()
        zoom_layout.addStretch()
        self.zoom_in_btn  = QToolButton()
        self.zoom_in_btn.setIcon(QIcon.fromTheme("zoom-in"))
        self.zoom_in_btn.setToolTip("Zoom In")
        self.zoom_out_btn = QToolButton()
        self.zoom_out_btn.setIcon(QIcon.fromTheme("zoom-out"))
        self.zoom_out_btn.setToolTip("Zoom Out")
        self.fit_btn      = QToolButton()
        self.fit_btn.setIcon(QIcon.fromTheme("zoom-fit-best"))
        self.fit_btn.setToolTip("Fit to Preview")
        zoom_layout.addWidget(self.zoom_in_btn)
        zoom_layout.addWidget(self.zoom_out_btn)
        zoom_layout.addWidget(self.fit_btn)
        preview_layout.addLayout(zoom_layout)

        # 2) QGraphicsView + QGraphicsScene for the preview
        self.scene = QGraphicsScene()
        self.view = InteractiveGraphicsView(self.scene)
        self.view.setDragMode(QGraphicsView.DragMode.ScrollHandDrag)
        self.view.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        self.pixmap_item = QGraphicsPixmapItem()
        self.scene.addItem(self.pixmap_item)
        preview_layout.addWidget(self.view)

        self._load_original_on_startup()

        # ─── Connect signals for buttons ───────────────────────────────────
        self.preview_btn.clicked.connect(self._on_preview)
        self.undo_btn.clicked.connect(self._on_undo)
        self.push_btn.clicked.connect(self._on_push_to_slot)
        self.close_btn.clicked.connect(self.close)

        self.zoom_in_btn.clicked.connect(self.zoom_in)
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        self.fit_btn.clicked.connect(self._on_fit_clicked)

        # 4) Whenever the user switches tabs, or changes Algorithm, or any PSF slider:
        self.tabs.currentChanged.connect(self._update_psf_preview)
        self.deconv_algo_combo.currentTextChanged.connect(self._update_psf_preview)

        self.sep_run_button.clicked.connect(self._on_run_sep)
        #self.sep_use_button.clicked.connect(self._on_use_stellar_psf)
        self.sep_save_button.clicked.connect(self._on_save_stellar_psf)

        # 5) Connect all convolution sliders to the same updater:
        for s in (
            self.conv_radius_slider,
            self.conv_shape_slider,
            self.conv_aspect_slider,
            self.conv_rotation_slider
        ):
            s.valueChanged.connect(self._update_psf_preview)

        # 6) Connect all RL‐decon sliders to the same updater:
        for s in (
            self.rl_psf_radius_slider,
            self.rl_psf_shape_slider,
            self.rl_psf_aspect_slider,
            self.rl_psf_rotation_slider
        ):
            s.valueChanged.connect(self._update_psf_preview)

        # 7) Finally, initialize the preview once
        self._update_psf_preview()

    def showEvent(self, event):
        """
        Whenever this dialog is shown (or re‐shown), pull in the current active
        slot’s image and reset preview. This way it won’t “remember” the old one.
        """
        super().showEvent(event)
        # Clear any previous preview so we start fresh:
        self._preview_result = None

        # Reload the “original” from the active slot:
        self._load_original_on_startup()

        # Also clear PSF‐preview label (if you want it blank on open):
        self.conv_psf_label.clear()
        self.sep_psf_preview.clear()

    def closeEvent(self, event):
        """
        When the user closes this dialog, clear out all large arrays,
        custom-PSF flags, and any QLabel pixmaps so nothing “sticks”
        for the next time you open it.
        """
        # 1) Clear Larson–Sekanina center (if set)
        if hasattr(self.view, "ls_center"):
            self.view.ls_center = None

        # 2) Drop references to NumPy arrays
        self._original_image   = None
        self._preview_result   = None

        # 3) Clear any SEP-derived PSF
        self._last_stellar_psf = None
        self._custom_psf       = None
        self._use_custom_psf   = False

        # 4) Clear all QLabel pixmaps so they don’t linger
        self.conv_psf_label.clear()
        self.sep_psf_preview.clear()

        # 5) Clear the RL status bar text
        self.rl_status_label.setText("")

        # 6) Un‐check any “Using Stellar PSF” UI elements
        self.rl_custom_label.setVisible(False)
        self.rl_disable_custom_btn.setVisible(False)
        self.custom_psf_bar.setVisible(False)

        # 7) (Optional) Reset any TV-Denoise sliders to their defaults if you want
        self.tv_weight_slider.setValue(0.1)
        self.tv_iter_slider.setValue(10)
        self.tv_multichannel_checkbox.setChecked(True)

        # 8) Finally call the base implementation so it actually closes
        super().closeEvent(event)

    # ─────────────────────────────────────────────────────────────────────
    def _load_original_on_startup(self):
        """
        Called once during __init__ to fetch the current active slot’s image
        and display it. Also stores it as self._original_image for Undo.
        """
        if not hasattr(self.parent(), "image_manager"):
            return
        img, _ = self.parent().image_manager.get_current_image_and_metadata()
        if img is None:
            return

        # Store as “original” so Undo can revert to this
        self._original_image = img.copy()
        # We want to fit on first display, so set flag:
        self._auto_fit = True
        self._display_in_view(img)

    def _build_convolution_tab(self):
        conv_tab = QWidget()
        layout = QVBoxLayout(conv_tab)
        form = QFormLayout()
        form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        # ── Radius (0.1 … 500.0, step=0.1) ─────────────────────────
        self.conv_radius_slider = FloatSliderWithEdit(
            minimum=0.1,
            maximum=200.0,
            step=0.1,
            initial=5.0,
            suffix=" px"
        )
        form.addRow("Radius:", self.conv_radius_slider)

        # ── Kurtosis (σ) (0.1 … 10.0, step=0.1) ─────────────────────
        self.conv_shape_slider = FloatSliderWithEdit(
            minimum=0.1,
            maximum=10.0,
            step=0.1,
            initial=2.0,
            suffix="σ"
        )
        form.addRow("Kurtosis (σ):", self.conv_shape_slider)

        # ── Aspect Ratio (0.1 … 10.0, step=0.1) ────────────────────
        self.conv_aspect_slider = FloatSliderWithEdit(
            minimum=0.1,
            maximum=10.0,
            step=0.1,
            initial=1.0,
            suffix=""
        )
        form.addRow("Aspect Ratio:", self.conv_aspect_slider)

        # ── Rotation (0.0 … 360.0, step=1.0) ───────────────────────
        self.conv_rotation_slider = FloatSliderWithEdit(
            minimum=0.0,
            maximum=360.0,
            step=1.0,
            initial=0.0,
            suffix="°"
        )
        form.addRow("Rotation:", self.conv_rotation_slider)

        layout.addLayout(form)
        layout.addStretch()
        self.tabs.addTab(conv_tab, "Convolution")

    # ─────────────────────────────────────────────────────────────────────
    def _build_deconvolution_tab(self):
        deconv_tab = QWidget()
        outer_layout = QVBoxLayout(deconv_tab)

        # ── (1) Algorithm selector ─────────────────────────────────────────
        algo_layout = QHBoxLayout()
        algo_label = QLabel("Algorithm:")
        self.deconv_algo_combo = QComboBox()
        self.deconv_algo_combo.addItems([
            "Richardson-Lucy",
            "Wiener",
            "Larson-Sekanina",
            "Van Cittert",
        ])
        self.deconv_algo_combo.currentTextChanged.connect(self._on_deconv_algo_changed)
        algo_layout.addWidget(algo_label)
        algo_layout.addWidget(self.deconv_algo_combo)
        algo_layout.addStretch()
        outer_layout.addLayout(algo_layout)

        # ── (2) Shared PSF slider group (radius/kurtosis/aspect/rotation) ──
        self.psf_param_group = QWidget()
        psf_group_layout = QFormLayout(self.psf_param_group)
        psf_group_layout.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        self.rl_psf_radius_slider = FloatSliderWithEdit(
            minimum=0.1, maximum=100.0, step=0.1, initial=3.0, suffix=" px"
        )
        psf_group_layout.addRow("PSF Radius:", self.rl_psf_radius_slider)

        self.rl_psf_shape_slider = FloatSliderWithEdit(
            minimum=0.1, maximum=10.0, step=0.1, initial=2.0, suffix="σ"
        )
        psf_group_layout.addRow("PSF Kurtosis (σ):", self.rl_psf_shape_slider)

        self.rl_psf_aspect_slider = FloatSliderWithEdit(
            minimum=0.1, maximum=10.0, step=0.1, initial=1.0, suffix=""
        )
        psf_group_layout.addRow("PSF Aspect Ratio:", self.rl_psf_aspect_slider)

        self.rl_psf_rotation_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=360.0, step=1.0, initial=0.0, suffix="°"
        )
        psf_group_layout.addRow("PSF Rotation:", self.rl_psf_rotation_slider)

        outer_layout.addWidget(self.psf_param_group)
        # Hide PSF sliders if not in RL or Wiener initially
        if self.deconv_algo_combo.currentText() not in ("Richardson-Lucy", "Wiener"):
            self.psf_param_group.setVisible(False)

        # ── (2b) Shared “Using Stellar PSF” bar ────────────────────────────
        self.custom_psf_bar = QWidget()
        bar_layout = QHBoxLayout(self.custom_psf_bar)
        bar_layout.setContentsMargins(0, 0, 0, 0)
        bar_layout.setSpacing(4)

        self.rl_custom_label = QLabel("Using Stellar PSF")
        self.rl_custom_label.setStyleSheet(
            "color: #ffffff; background-color: #007acc; padding: 2px;"
        )
        self.rl_custom_label.setVisible(False)

        self.rl_disable_custom_btn = QPushButton("Disable Stellar PSF")
        self.rl_disable_custom_btn.setToolTip(
            "Revert to using the Gaussian defined by the PSF sliders"
        )
        self.rl_disable_custom_btn.setVisible(False)

        bar_layout.addWidget(self.rl_custom_label)
        bar_layout.addWidget(self.rl_disable_custom_btn)
        bar_layout.addStretch()

        outer_layout.addWidget(self.custom_psf_bar)
        # Hide that bar completely unless stellar PSF is active AND algo is RL or Wiener
        self.custom_psf_bar.setVisible(False)

        # ── (3) Stacked parameter panels ───────────────────────────────────
        self.deconv_param_stack.clear()
        self.deconv_stack_container = QWidget()
        self.deconv_stack_layout = QVBoxLayout(self.deconv_stack_container)

        # ---- (3a) RL panel (iterations, clip, L* only) ----
        rl_widget = QWidget()
        rl_form = QFormLayout(rl_widget)
        rl_form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        self.rl_iterations_slider = FloatSliderWithEdit(
            minimum=1.0, maximum=100.0, step=1.0, initial=30.0, suffix=""
        )
        rl_form.addRow("Iterations:", self.rl_iterations_slider)

        # ── Regularization Type (None vs. Tikhonov vs. TV) ───────────
        self.rl_reg_combo = QComboBox()
        self.rl_reg_combo.addItems([
            "None (Plain R–L)",
            "Tikhonov (L2)",
            "Total Variation (TV)"
        ])
        rl_form.addRow("Regularization:", self.rl_reg_combo)

        self.rl_clip_checkbox = QCheckBox("Enable de‐ring")
        self.rl_clip_checkbox.setChecked(True)
        rl_form.addRow("", self.rl_clip_checkbox)

        self.rl_luminance_only_checkbox = QCheckBox("Deconvolve L* Only")
        self.rl_luminance_only_checkbox.setChecked(True)
        self.rl_luminance_only_checkbox.setToolTip(
            "If checked and the image is color, RL runs only on the L* channel."
        )
        rl_form.addRow("", self.rl_luminance_only_checkbox)

        rl_widget.setLayout(rl_form)
        self.deconv_param_stack["Richardson-Lucy"] = rl_widget

        # ---- (3b) Wiener panel (λ slider, regularization, L* only) ----
        wiener_widget = QWidget()
        wiener_layout = QVBoxLayout(wiener_widget)

        wiener_form = QFormLayout()
        wiener_form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        self.wiener_nsr_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=1.0, step=0.001, initial=0.01, suffix=""
        )
        wiener_form.addRow("Noise/Signal (λ):", self.wiener_nsr_slider)

        self.wiener_reg_combo = QComboBox()
        self.wiener_reg_combo.addItems([
            "None (Classical Wiener)",
            "Tikhonov (L2)"
        ])
        wiener_form.addRow("Regularization:", self.wiener_reg_combo)

        self.wiener_luminance_only_checkbox = QCheckBox("Deconvolve L* Only")
        self.wiener_luminance_only_checkbox.setChecked(True)
        self.wiener_luminance_only_checkbox.setToolTip(
            "If checked and the image is color, Wiener runs only on the L* channel."
        )
        wiener_form.addRow("", self.wiener_luminance_only_checkbox)


        # Add “Enable de-ring” checkbox here
        self.wiener_dering_checkbox = QCheckBox("Enable de-ring")
        self.wiener_dering_checkbox.setChecked(True)
        self.wiener_dering_checkbox.setToolTip(
            "If checked, apply a single bilateral denoise pass after Wiener deconvolution"
        )
        wiener_form.addRow("", self.wiener_dering_checkbox)

        wiener_layout.addLayout(wiener_form)
        wiener_widget.setLayout(wiener_layout)
        self.deconv_param_stack["Wiener"] = wiener_widget

        # ---- (3c) Larson–Sekanina panel (no PSF or stellar bar) ----
        ls_widget = QWidget()
        ls_form = QFormLayout(ls_widget)
        ls_form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        self.ls_radial_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=50.0, step=0.1, initial=0.0, suffix=" px"
        )
        ls_form.addRow("Radial Step (px):", self.ls_radial_slider)

        self.ls_angular_slider = FloatSliderWithEdit(
            minimum=0.1, maximum=360.0, step=0.1, initial=1.0, suffix="°"
        )
        ls_form.addRow("Angular Step (°):", self.ls_angular_slider)

        self.ls_operator_combo = QComboBox()
        self.ls_operator_combo.addItems(["Divide", "Subtract"])
        ls_form.addRow("LS Operator:", self.ls_operator_combo)

        self.ls_blend_combo = QComboBox()
        self.ls_blend_combo.addItems(["SoftLight", "Screen"])
        ls_form.addRow("Blend Mode:", self.ls_blend_combo)

        ls_widget.setLayout(ls_form)
        self.deconv_param_stack["Larson-Sekanina"] = ls_widget

        # ---- (3d) Van Cittert panel (no PSF or stellar bar) ----
        vc_widget = QWidget()
        vc_form = QFormLayout(vc_widget)
        vc_form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        self.vc_iterations_slider = FloatSliderWithEdit(
            minimum=1, maximum=1000, step=1, initial=10, suffix=""
        )
        vc_form.addRow("Iterations:", self.vc_iterations_slider)

        self.vc_relax_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=1.0, step=0.01, initial=0.0, suffix=""
        )
        vc_form.addRow("Relaxation (0–1):", self.vc_relax_slider)

        vc_widget.setLayout(vc_form)
        self.deconv_param_stack["Van Cittert"] = vc_widget

        # ── Add all panels (hidden initially) ─────────────────────────────────
        for name, widget in self.deconv_param_stack.items():
            widget.setVisible(False)
            self.deconv_stack_layout.addWidget(widget)

        # Show only the starting algorithm’s panel
        first_algo = self.deconv_algo_combo.currentText()
        if first_algo in self.deconv_param_stack:
            self.deconv_param_stack[first_algo].setVisible(True)

        outer_layout.addWidget(self.deconv_stack_container)
        outer_layout.addStretch()
        self.tabs.addTab(deconv_tab, "Deconvolution")

        # ── Connect “Disable Stellar PSF” and PSF‐slider changes to clear custom flag ──
        self.rl_disable_custom_btn.clicked.connect(self._clear_custom_psf_flag)
        for s in (
            self.rl_psf_radius_slider,
            self.rl_psf_shape_slider,
            self.rl_psf_aspect_slider,
            self.rl_psf_rotation_slider
        ):
            s.valueChanged.connect(self._clear_custom_psf_flag)

    def _build_psf_estimator_tab(self):
        """
        Build the UI for the “PSF Estimator” tab (SEP‐based), using only
        CustomSpinBox (no QSpinBox).
        """
        psf_tab = QWidget()
        layout = QVBoxLayout(psf_tab)

        # — Image picker / label showing current image —
        h_image = QHBoxLayout()
        h_image.addWidget(QLabel("Image for PSF Estimate:"))
        self.sep_image_label = QLabel("(Current Active Image)")
        h_image.addWidget(self.sep_image_label)
        layout.addLayout(h_image)

        # — SEP Detection Parameters —
        form = QFormLayout()
        form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        # Detection σ (float)
        self.sep_threshold_slider = FloatSliderWithEdit(
            minimum=1.0, maximum=5.0, step=0.1, initial=2.5, suffix=" σ"
        )
        form.addRow("Detection σ:", self.sep_threshold_slider)

        # Min Area (px²) → use CustomSpinBox
        self.sep_minarea_spin = CustomSpinBox(
            minimum=1, maximum=100, initial=5, step=1
        )
        form.addRow("Min Area (px²):", self.sep_minarea_spin)

        # Saturation Cutoff (float)
        self.sep_sat_slider = FloatSliderWithEdit(
            minimum=1000, maximum=100000, step=500, initial=50000, suffix=" ADU"
        )
        form.addRow("Saturation Cutoff:", self.sep_sat_slider)

        # Max Stars → use CustomSpinBox
        self.sep_maxstars_spin = CustomSpinBox(
            minimum=1, maximum=500, initial=50, step=1
        )
        form.addRow("Max Stars:", self.sep_maxstars_spin)

        # Half‐Width (px) → use CustomSpinBox
        self.sep_stamp_spin = CustomSpinBox(
            minimum=5, maximum=50, initial=15, step=1
        )
        form.addRow("Half‐Width (px):", self.sep_stamp_spin)

        layout.addLayout(form)

        # — Buttons: Run SEP & Use / Save PSF —
        h_buttons = QHBoxLayout()
        self.sep_run_button = QPushButton("Run SEP Extraction")
        self.sep_save_button = QPushButton("Save PSF…")
        self.sep_use_button  = QPushButton("Use as Current PSF")
        h_buttons.addWidget(self.sep_run_button)
        h_buttons.addWidget(self.sep_save_button)
        h_buttons.addWidget(self.sep_use_button)
        layout.addLayout(h_buttons)

        # — PSF Preview (64×64 QLabel) —
        self.psf_estimate_title = QLabel("Estimated PSF (64×64):")
        layout.addWidget(self.psf_estimate_title, alignment=Qt.AlignmentFlag.AlignLeft)

        self.sep_psf_preview = QLabel()
        self.sep_psf_preview.setFixedSize(64, 64)
        self.sep_psf_preview.setStyleSheet("border: 1px solid #888;")
        layout.addWidget(self.sep_psf_preview, alignment=Qt.AlignmentFlag.AlignHCenter)

        layout.addStretch()
        self.tabs.addTab(psf_tab, "PSF Estimator")

        # Placeholder for the last computed PSF
        self._last_stellar_psf = None

    def _build_tv_denoise_tab(self):
        """
        Build the UI for a “TV Denoise” tab, allowing the user to choose
        total‐variation denoising parameters and apply them.
        """
        tvd_tab = QWidget()
        layout = QVBoxLayout(tvd_tab)

        form = QFormLayout()
        form.setLabelAlignment(Qt.AlignmentFlag.AlignRight)

        # TV weight (0.0 … 1.0)
        self.tv_weight_slider = FloatSliderWithEdit(
            minimum=0.0, maximum=1.0, step=0.01, initial=0.1, suffix=""
        )
        form.addRow("TV Weight:", self.tv_weight_slider)

        # Max iterations for TV algorithm (1 … 100, step=1)
        self.tv_iter_slider = FloatSliderWithEdit(
            minimum=1, maximum=100, step=1, initial=10, suffix=""
        )
        form.addRow("Max Iterations:", self.tv_iter_slider)

        # Multichannel checkbox
        self.tv_multichannel_checkbox = QCheckBox("Multi‐channel")
        self.tv_multichannel_checkbox.setChecked(True)
        self.tv_multichannel_checkbox.setToolTip(
            "If checked and the image is color, run TV on all channels jointly"
        )
        form.addRow("", self.tv_multichannel_checkbox)

        layout.addLayout(form)
        layout.addStretch()
        self.tabs.addTab(tvd_tab, "TV Denoise")

    # ─────────────────────────────────────────────────────────────────────
    def _on_deconv_algo_changed(self, selected: str):
        # Hide all panels, then show the one for `selected`
        for name, widget in self.deconv_param_stack.items():
            widget.setVisible(False)
        if selected in self.deconv_param_stack:
            self.deconv_param_stack[selected].setVisible(True)

        # 1) Always clear stellar‐PSF bar if we’re not in RL or Wiener
        if selected not in ("Richardson-Lucy", "Wiener"):
            self._use_custom_psf = False
            self.custom_psf_bar.setVisible(False)
        else:
            # If user had already clicked “Use Stellar PSF,” show it
            if self._use_custom_psf and (self._custom_psf is not None):
                self.custom_psf_bar.setVisible(True)
            else:
                self.custom_psf_bar.setVisible(False)

        # 2) Show PSF sliders group only for RL or Wiener
        self.psf_param_group.setVisible(selected in ("Richardson-Lucy", "Wiener"))

    def _on_ls_operator_changed(self, op_text: str):
        """
        Whenever the user picks “Subtract” or “Divide” in the LS Operator dropdown,
        this forces the Blend‐Mode dropdown to the matching mode:
          Subtract → Screen
          Divide   → SoftLight
        """
        if op_text == "Divide":
            # If the user explicitly chose Divide, auto‐select SoftLight
            self.ls_blend_combo.setCurrentText("SoftLight")
        else:
            # Otherwise (Subtract), force Screen
            self.ls_blend_combo.setCurrentText("Screen")

    def _make_psf_pixmap(self, radius, kurtosis, aspect, rotation_deg) -> QPixmap:
        """
        Build a float32 PSF via make_elliptical_gaussian_psf(...),
        convert to 0–255 grayscale, wrap in QImage, scale to 64×64,
        center it in a 64×64 QPixmap, and return that QPixmap.
        """
        psf = make_elliptical_gaussian_psf(radius, kurtosis, aspect, rotation_deg)
        h, w = psf.shape

        if psf.max() > 0:
            norm = (psf / psf.max()) * 255.0
        else:
            norm = psf
        img8 = norm.astype(np.uint8)

        qimg = QImage(img8.data, w, h, w, QImage.Format.Format_Grayscale8)

        scaled = QPixmap.fromImage(qimg).scaled(
            64, 64,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        final = QPixmap(64, 64)
        final.fill(Qt.GlobalColor.transparent)
        painter = QPainter(final)
        x_off = (64 - scaled.width()) // 2
        y_off = (64 - scaled.height()) // 2
        painter.drawPixmap(x_off, y_off, scaled)
        painter.end()

        return final

    def _make_stellar_psf_pixmap(self, psf_kernel: np.ndarray) -> QPixmap:
        """
        Given a 2D float32 PSF (sum=1), produce a 64×64 QPixmap centered in a transparent background.
        """
        h, w = psf_kernel.shape
        maxval = psf_kernel.max()
        if maxval > 0:
            img8 = (psf_kernel / maxval * 255.0).astype(np.uint8)
        else:
            img8 = np.zeros_like(psf_kernel, dtype=np.uint8)

        qimg = QImage(img8.data, w, h, w, QImage.Format.Format_Grayscale8)
        scaled = QPixmap.fromImage(qimg).scaled(
            64, 64,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        final = QPixmap(64, 64)
        final.fill(Qt.GlobalColor.transparent)
        painter = QPainter(final)
        x_off = (64 - scaled.width()) // 2
        y_off = (64 - scaled.height()) // 2
        painter.drawPixmap(x_off, y_off, scaled)
        painter.end()

        return final


    def _update_psf_preview(self):
        current_tab = self.tabs.tabText(self.tabs.currentIndex())
        algo = self.deconv_algo_combo.currentText()

        if current_tab == "Convolution":
            r, k, a, rot = (
                self.conv_radius_slider.value(),
                self.conv_shape_slider.value(),
                self.conv_aspect_slider.value(),
                self.conv_rotation_slider.value(),
            )
            pix = self._make_psf_pixmap(r, k, a, rot)
            self.conv_psf_label.setPixmap(pix)

        elif current_tab == "Deconvolution" and algo in ("Richardson-Lucy", "Wiener"):
            if self._use_custom_psf and (self._custom_psf is not None):
                stellar_pix = self._make_stellar_psf_pixmap(self._custom_psf)
                self.conv_psf_label.setPixmap(stellar_pix)
            else:
                r, k, a, rot = (
                    self.rl_psf_radius_slider.value(),
                    self.rl_psf_shape_slider.value(),
                    self.rl_psf_aspect_slider.value(),
                    self.rl_psf_rotation_slider.value(),
                )
                pix = self._make_psf_pixmap(r, k, a, rot)
                self.conv_psf_label.setPixmap(pix)
        else:
            self.conv_psf_label.clear()

    def get_active_mask(self) -> Optional[np.ndarray]:
        """
        Retrieves the currently applied mask from MaskManager (if any),
        normalizes it to [0..1], and makes sure the shape matches
        the active image’s dimensions.  Returns None if no mask is
        applied or if shapes mismatch.
        """
        if not hasattr(self.parent(), "image_manager"):
            return None

        mask_manager = self.parent().image_manager.mask_manager
        if mask_manager is None:
            return None

        mask = mask_manager.get_applied_mask()
        if mask is None:
            return None

        # Convert to float32 [0..1]
        if mask.dtype not in (np.float32, np.float64):
            mask = mask.astype(np.float32) / 255.0

        # If active image is color (H×W×3) but mask is 2D (H×W), broadcast to 3 channels
        img, _ = self.parent().image_manager.get_current_image_and_metadata()
        if img is None:
            return None

        H_img, W_img = img.shape[:2]
        if mask.shape[:2] != (H_img, W_img):
            QMessageBox.critical(
                self,
                "Error",
                "Mask dimensions do not match the image dimensions."
            )
            return None

        if img.ndim == 3 and img.shape[2] == 3 and mask.ndim == 2:
            mask = np.expand_dims(mask, axis=-1)  # now (H×W×1)
            mask = np.repeat(mask, 3, axis=2)      # (H×W×3)

        return mask

    # ─────────────────────────────────────────────────────────────────────
    def _on_preview(self):
        """
        1) Get active image from ImageManager
        2) Perform convolution or deconvolution (with optional L* only)
        3) If a mask is applied, blend processed & original via mask
        4) Display the final blended result in QGraphicsView
        """
        if not hasattr(self.parent(), "image_manager"):
            self._show_message("Error: No ImageManager found")
            return

        img, metadata = self.parent().image_manager.get_current_image_and_metadata()
        if img is None:
            self._show_message("No active image to process.")
            return

        # Save original for Undo (only the very first time)
        if self._original_image is None:
            self._original_image = img.copy()

        tab = self.tabs.currentIndex()
        current_tab_name = self.tabs.tabText(self.tabs.currentIndex())

        if current_tab_name == "Convolution":
            # ─── CONVOLUTION ───────────────────────────────────────────
            radius  = self.conv_radius_slider.value()
            kurtosis = self.conv_shape_slider.value()
            aspect  = self.conv_aspect_slider.value()
            rotation = self.conv_rotation_slider.value()

            psf_kernel = make_elliptical_gaussian_psf(
                radius, kurtosis, aspect, rotation
            ).astype(np.float32)

            processed = self._convolve_color(img, psf_kernel)
            processed = processed*self.strength_slider.value()+(1-self.strength_slider.value())*img
        elif current_tab_name == "Deconvolution":
            # ─── DECONVOLUTION ─────────────────────────────────────────
            algo = self.deconv_algo_combo.currentText()

            if algo == "Richardson-Lucy":
                iters = self.rl_iterations_slider.value()
                reg_type = self.rl_reg_combo.currentText()
                pr    = self.rl_psf_radius_slider.value()
                ps    = self.rl_psf_shape_slider.value()
                pa    = self.rl_psf_aspect_slider.value()
                pt    = self.rl_psf_rotation_slider.value()

                psf_kernel = make_elliptical_gaussian_psf(
                    pr, ps, pa, pt
                ).astype(np.float32)

                clip_flag = self.rl_clip_checkbox.isChecked()

                # If “L* only” & image is color, extract L*, run RL on L*, then recombine
                if getattr(self, "rl_luminance_only_checkbox", None) is not None \
                   and self.rl_luminance_only_checkbox.isChecked() \
                   and img.ndim == 3 and img.shape[2] == 3:
                    # Convert RGB→Lab, scale L* to [0..1]
                    lab = rgb2lab(img.astype(np.float32))
                    L  = (lab[:, :, 0] / 100.0).astype(np.float32)

                    # Run R–L on the L* channel only
                    deconv_L = self._richardson_lucy_color(L, psf_kernel, iterations=iters, reg_type=reg_type, clip_flag=clip_flag)

                    # Put deconv_L back into L* (scale up to [0..100])
                    lab[:, :, 0] = deconv_L * 100.0

                    # Convert Lab→RGB
                    rgb_deconv = lab2rgb(lab.astype(np.float32))
                    processed = np.clip(rgb_deconv.astype(np.float32), 0.0, 1.0)
                    processed = processed*self.strength_slider.value()+(1-self.strength_slider.value())*img
                else:
                    # Just run R–L on full (grayscale or 3-channel)
                    processed = self._richardson_lucy_color(
                        img.astype(np.float32),
                        psf_kernel,
                        iterations=iters,
                        reg_type=reg_type,
                        clip_flag=clip_flag
                    )
                    processed = processed*self.strength_slider.value()+(1-self.strength_slider.value())*img
            # ── 2) WIENER (CLASSICAL) ────────────────────────────────────
            elif algo == "Wiener":
                # 1) Decide which PSF to use: stellar (if flagged) or Gaussian from sliders
                if self._use_custom_psf and (self._custom_psf is not None):
                    small_psf = self._custom_psf.astype(np.float32)
                else:
                    pr = self.rl_psf_radius_slider.value()
                    ps = self.rl_psf_shape_slider.value()
                    pa = self.rl_psf_aspect_slider.value()
                    pt = self.rl_psf_rotation_slider.value()
                    small_psf = make_elliptical_gaussian_psf(pr, ps, pa, pt).astype(np.float32)

                # 2) Read lambda and regularization choice
                nsr = self.wiener_nsr_slider.value()
                reg_choice = self.wiener_reg_combo.currentText()
                if reg_choice == "None (Classical Wiener)":
                    reg_type = "Wiener"
                else:
                    reg_type = "Tikhonov"

                do_dering = self.wiener_dering_checkbox.isChecked()

                # 3) Apply Wiener on L* only or all channels
                if getattr(self, "wiener_luminance_only_checkbox", None) is not None \
                and self.wiener_luminance_only_checkbox.isChecked() \
                and img.ndim == 3 and img.shape[2] == 3:

                    lab = rgb2lab(img.astype(np.float32))
                    L = (lab[:, :, 0] / 100.0).astype(np.float32)

                    deconv_L = self._wiener_deconv_with_kernel(L, small_psf, nsr, reg_type, do_dering)
                    lab[:, :, 0] = np.clip(deconv_L * 100.0, 0.0, 100.0)
                    rgb_deconv = lab2rgb(lab.astype(np.float32))
                    processed = np.clip(rgb_deconv.astype(np.float32), 0.0, 1.0)
                    processed = processed * self.strength_slider.value() \
                                + (1 - self.strength_slider.value()) * img
                else:
                    processed = self._wiener_deconv_with_kernel(img, small_psf, nsr, reg_type, do_dering)
                    processed = np.clip(processed, 0.0, 1.0)
                    processed = processed * self.strength_slider.value() \
                                + (1 - self.strength_slider.value()) * img
            elif algo == "Larson-Sekanina":
                if not hasattr(self.view, "ls_center") or self.view.ls_center is None:
                    QMessageBox.information(
                        self,
                        "Hold Shift + Click",
                        "To choose a Larson–Sekanina center, "
                        "please hold Shift and click on the preview."
                    )
                    return

                center = self.view.ls_center
                rstep  = self.ls_radial_slider.value()
                astep  = self.ls_angular_slider.value()
                operator = self.ls_operator_combo.currentText()
                blend_mode = self.ls_blend_combo.currentText()

                B = larson_sekanina(
                    image=img,
                    center=center,
                    radial_step=rstep,
                    angular_step_deg=astep,
                    operator=operator
                )
                A = img
                if A.ndim == 3 and A.shape[2] == 3:
                    # Color‐input path: B is 2D → replicate into 3 channels
                    B_rgb = np.repeat(B[:, :, np.newaxis], 3, axis=2)
                    A_rgb = A
                else:
                    # Grayscale‐input path: keep A and B as 2D, but we'll work in a dummy 3rd axis
                    A_rgb = A[..., np.newaxis]   # shape = (H, W, 1)
                    B_rgb = B[..., np.newaxis]   # shape = (H, W, 1)

                if blend_mode == "Screen":
                    C = A_rgb + B_rgb - (A_rgb * B_rgb)
                else:  # SoftLight
                    C = (1 - 2 * B_rgb) * (A_rgb**2) + 2 * B_rgb * A_rgb

                clipped = np.clip(C, 0.0, 1.0)

                # If the original was grayscale (2D), squeeze back to 2D
                if img.ndim == 2:
                    processed = clipped[..., 0]   # shape = (H, W)
                else:
                    processed = clipped           # shape = (H, W, 3)

                # Now blend with the original img (they match shapes)
                strength = self.strength_slider.value()
                processed = processed * strength + (1 - strength) * img
            elif algo == "Van Cittert":
                iters2 = self.vc_iterations_slider.value()
                relax  = self.vc_relax_slider.value()
                if img.ndim == 3 and img.shape[2] == 3:
                    chans = []
                    for c in range(3):
                        ch = img[:, :, c]
                        deconv_ch = van_cittert_deconv(ch, iters2, relax)
                        chans.append(deconv_ch)
                    processed = np.stack(chans, axis=2)
                else:
                    processed = van_cittert_deconv(img, iters2, relax)
                processed = np.clip(processed, 0.0, 1.0)
                processed = processed*self.strength_slider.value()+(1-self.strength_slider.value())*img
            else:
                self._show_message("Unknown deconvolution algorithm")
                return

        elif current_tab_name == "TV Denoise":
            weight = self.tv_weight_slider.value()
            max_iter = int(self.tv_iter_slider.value())
            multichannel = self.tv_multichannel_checkbox.isChecked()

            if img.ndim == 3 and multichannel:
                # TV on all channels jointly
                processed = denoise_tv_chambolle(
                    img.astype(np.float32),
                    weight=weight,
                    max_num_iter=max_iter,
                    channel_axis=-1
                ).astype(np.float32)
            else:
                # Grayscale or per‐channel
                if img.ndim == 3 and img.shape[2] == 3:
                    # Apply TV to each channel separately
                    channels_out = []
                    for c in range(3):
                        ch = img[:, :, c].astype(np.float32)
                        denoised_ch = denoise_tv_chambolle(
                            ch,
                            weight=weight,
                            max_num_iter=max_iter,
                            channel_axis=None
                        ).astype(np.float32)
                        channels_out.append(denoised_ch)
                    processed = np.stack(channels_out, axis=2)
                else:
                    gray = img.astype(np.float32) if img.ndim == 2 else img
                    processed = denoise_tv_chambolle(
                        gray,
                        weight=weight,
                        max_num_iter=max_iter,
                        channel_axis=None
                    ).astype(np.float32)

            processed = np.clip(processed, 0.0, 1.0)
            processed = (
                processed * self.strength_slider.value()
                + (1 - self.strength_slider.value()) * img
            )


        # ─── If there is an active mask, blend “processed” & “original” via the mask ─────
        mask = self.get_active_mask()
        if mask is not None:
            # Ensure the mask is broadcast to same channels as `processed`
            if processed.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)
            # Blend: processed * mask + original * (1 - mask)
            blended = processed * mask + self._original_image * (1.0 - mask)
            blended = np.clip(blended, 0.0, 1.0)
            final_result = blended
        else:
            final_result = processed

        # 3) Store & show the final_result
        self._preview_result = final_result
        self._display_in_view(final_result)


    # ─────────────────────────────────────────────────────────────────────
    def _on_undo(self):
        """Revert to the original image (clears preview)."""
        if self._original_image is not None:
            self._preview_result = None
            self._display_in_view(self._original_image)
        else:
            self._show_message("Nothing to undo.")

    # ─────────────────────────────────────────────────────────────────────
    def _on_push_to_slot(self):
        """
        Push the last preview into the current slot via ImageManager.set_image(),
        which automatically handles undo history. Then pop up a small dialog
        and reload the new slot image into the preview area so the user can
        continue iterating.
        """
        if self._preview_result is None:
            QMessageBox.warning(self, "No Preview", "No preview to push. Click Preview first.")
            return

        # 1) Grab current image and metadata (prior to overwrite)
        _, metadata = self.parent().image_manager.get_current_image_and_metadata()
        new_meta = metadata.copy()
        new_meta["source"] = "ConvoDeconvo"

        # 2) Commit the preview into the same slot (ImageManager will push the old image
        #    onto its undo stack automatically)
        self.parent().image_manager.set_image(self._preview_result.copy(), new_meta, step_name="ConvoDeconvo")

        # 3) Inform the user with a quick message box
        QMessageBox.information(self, "Pushed to Slot", "Result has been pushed into the current slot.")

        # 4) Reload from the slot (in case the user wants to iterate further).
        #    Now “original” becomes the freshly‐pushed image.
        img_after, _ = self.parent().image_manager.get_current_image_and_metadata()
        self._original_image = img_after.copy()
        self._preview_result = None

        # 5) Display it in the QGraphicsView (preserving current zoom/pan if desired).
        #    Usually you want to keep whatever zoom/pan the user had, so do NOT force a fit.
        self._display_in_view(self._original_image)

    # ─────────────────────────────────────────────────────────────────────
    def _show_message(self, text: str):
        """Temporarily show a text placeholder in the preview area."""
        self.scene.clear()
        self.pixmap_item = QGraphicsPixmapItem()  # blank
        self.scene.addItem(self.pixmap_item)
        self.view.resetTransform()
        self.preview_label = QLabel(text)
        # Instead of reusing preview_label, we push a temporary text into the scene:
        temp_label = QLabel(text)
        temp_label.setStyleSheet("color: white; background-color: #222;")
        temp_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Convert QLabel to QPixmap:
        pixmap = temp_label.grab()
        self.pixmap_item.setPixmap(pixmap)
        self.view.fitInView(self.pixmap_item, Qt.AspectRatioMode.KeepAspectRatio)

    # ─────────────────────────────────────────────────────────────────────
    def _convolve_color(self, image: np.ndarray, psf_kernel: np.ndarray) -> np.ndarray:
        """
        If 2D: convolve directly. If 3D (H,W,3): convolve each channel.
        """
        if image.ndim == 2:
            return fftconvolve(image, psf_kernel, mode="same")
        elif image.ndim == 3 and image.shape[2] == 3:
            chans = []
            for c in range(3):
                ch = image[:, :, c]
                conv_ch = fftconvolve(ch, psf_kernel, mode="same")
                chans.append(conv_ch)
            return np.stack(chans, axis=2)
        else:
            return image.copy()

    # ─────────────────────────────────────────────────────────────────────
    def _richardson_lucy_color(self,
                            image: np.ndarray,
                            psf_kernel: np.ndarray,
                            iterations: int,
                            reg_type: str = "None (Plain R–L)",
                            clip_flag: bool = True
                            ) -> np.ndarray:
        """
        Run Richardson–Lucy with optional Tikhonov or TV regularization, in parallel
        over horizontal strips (with overlap), followed by an optional bilateral‐denoise
        if clip_flag=True.

        Parameters
        ----------
        image : np.ndarray
            float32 in [0..1], either 2D (H×W) or 3D (H×W×3).
        psf_kernel : np.ndarray
            2D float32 PSF (sum=1).
        iterations : int
        reg_type : str
            "None (Plain R–L)", "Tikhonov (L2)", or "Total Variation (TV)".
        clip_flag : bool
            If True, apply one bilateral denoise pass on each tile’s output.

        Returns
        -------
        deconv : np.ndarray
            float32 in [0..1], same shape as `image`.
        """
        iters = int(round(iterations))
        psf = psf_kernel.astype(np.float32)

        def _deconv_2d_parallel(gray: np.ndarray) -> np.ndarray:
            H, W = gray.shape
            psf_h, psf_w = psf.shape
            half_psf = max(psf_h, psf_w) // 2
            extra = 15
            pad = half_psf + extra
            overlap = pad

            n_cores = os.cpu_count() or 1
            n_cores = min(n_cores, H)
            tile_h = math.ceil(H / n_cores)

            tile_ranges = []
            for i in range(n_cores):
                y0 = i * tile_h
                y1 = min((i + 1) * tile_h, H)
                if y0 >= H:
                    break
                tile_ranges.append((y0, y1))

            accum_image = np.zeros((H, W), dtype=np.float32)
            accum_weight = np.zeros((H, W), dtype=np.float32)

            def _build_vertical_ramp(L: int, ov: int) -> np.ndarray:
                w = np.ones(L, dtype=np.float32)
                if ov <= 0:
                    return w
                if 2 * ov >= L:
                    for i in range(L):
                        w[i] = 1.0 - abs((i - (L - 1) / 2) / ((L - 1) / 2))
                    return w
                for i in range(ov):
                    w[i] = (i + 1) / float(ov)
                for i in range(ov):
                    idx = L - 1 - i
                    w[idx] = (i + 1) / float(ov)
                return w

            tile_inputs = []
            for idx, (y0, y1) in enumerate(tile_ranges):
                y0_ext = max(0, y0 - overlap)
                y1_ext = min(H, y1 + overlap)
                core_tile = gray[y0_ext:y1_ext, :]

                padded = np.pad(
                    core_tile,
                    ((pad, pad), (pad, pad)),
                    mode="reflect"
                )

                L_ext = y1_ext - y0_ext
                tile_inputs.append((
                    idx, padded, psf, iters, clip_flag, pad, reg_type,
                    y0_ext, y1_ext, L_ext
                ))

            results = [None] * len(tile_inputs)
            with ProcessPoolExecutor() as executor:
                for tile_index, deconv_ext in executor.map(_rl_tile_process_reg, tile_inputs):
                    results[tile_index] = deconv_ext

            for idx, (y0, y1) in enumerate(tile_ranges):
                (_, _, _, _, _, _, _, y0_ext, y1_ext, L_ext) = tile_inputs[idx]
                deconv_ext = results[idx]

                w = _build_vertical_ramp(L_ext, overlap)
                w2d = np.broadcast_to(w[:, None], (L_ext, W)).astype(np.float32)

                accum_image[y0_ext:y1_ext, :] += deconv_ext * w2d
                accum_weight[y0_ext:y1_ext, :] += w2d

            final_deconv = np.zeros_like(accum_image, dtype=np.float32)
            mask_nonzero = accum_weight > 0
            final_deconv[mask_nonzero] = accum_image[mask_nonzero] / accum_weight[mask_nonzero]

            return final_deconv

        if image.ndim == 2:
            if hasattr(self, "rl_status_label"):
                self.rl_status_label.setText(f"Running RL for {iters} iterations")
                QApplication.processEvents()
            deconv = _deconv_2d_parallel(image.astype(np.float32))
            if hasattr(self, "rl_status_label"):
                self.rl_status_label.setText("")
                QApplication.processEvents()
            return np.clip(deconv, 0.0, 1.0)

        elif image.ndim == 3 and image.shape[2] == 3:
            channels_out = []
            for c in range(3):
                if hasattr(self, "rl_status_label"):
                    self.rl_status_label.setText(f"Running RL on ch {c+1} for {iters} iterations")
                    QApplication.processEvents()
                ch = image[:, :, c].astype(np.float32)
                deconv_ch = _deconv_2d_parallel(ch)
                channels_out.append(np.clip(deconv_ch, 0.0, 1.0))
            if hasattr(self, "rl_status_label"):
                self.rl_status_label.setText("")
                QApplication.processEvents()
            return np.stack(channels_out, axis=2)

        else:
            return image.copy()

    def _wiener_deconv_with_kernel(self,
                                image: np.ndarray,
                                small_psf: np.ndarray,
                                nsr: float,
                                reg_type: str,
                                do_dering: bool
                                ) -> np.ndarray:
        """
        2D Wiener or Tikhonov deconvolution using an explicit small_psf array.
        - image: 2D float32 or 3D (H×W×3) float32 in [0..1].
        - small_psf: 2D float32 PSF (normalized so sum=1).
        - nsr: noise‐to‐signal parameter [0..1].
        - reg_type: "Wiener" or "Tikhonov".
        Returns: deconvolved image (same shape as input) clipped to [0..1].
        """
        def _deconv_gray(im2d: np.ndarray, do_dering_flag: bool) -> np.ndarray:
            H, W = im2d.shape
            psf_h, psf_w = small_psf.shape

            # Zero-pad PSF to image size, centered
            Hpsf = np.zeros((H, W), dtype=np.float32)
            cy, cx = H // 2, W // 2
            y0 = cy - psf_h // 2
            x0 = cx - psf_w // 2
            Hpsf[y0:y0+psf_h, x0:x0+psf_w] = small_psf

            # Convert to frequency domain
            H_f = fft2(ifftshift(Hpsf))
            H_f_conj = np.conj(H_f)
            mag2 = np.abs(H_f) ** 2

            # Choose K = nsr (Wiener) or nsr^2 (Tikhonov)
            if reg_type == "Tikhonov":
                K = nsr * nsr
            else:
                K = nsr

            denom = mag2 + K
            W_filter = H_f_conj / denom

            I_f = fft2(im2d)
            deconv_f = W_filter * I_f
            deconv = np.real(ifft2(deconv_f)).astype(np.float32)

            if do_dering_flag:
                # One bilateral‐denoise pass on the full deconv image
                deconv = denoise_bilateral(
                    deconv,
                    sigma_color=0.08,
                    sigma_spatial=1
                )

            return deconv.clip(0.0, 1.0)

        # If color, run per-channel; else grayscale
        if image.ndim == 2:
            return _deconv_gray(image.astype(np.float32), do_dering)
        elif image.ndim == 3 and image.shape[2] == 3:
            chans = []
            for c in range(3):
                ch = image[:, :, c].astype(np.float32)
                chans.append(_deconv_gray(ch, do_dering))
            return np.stack(chans, axis=2)
        else:
            # Fallback: return copy
            return image.copy()

    # ─────────────────────────────────────────────────────────────────────
    def _display_in_view(self, array: np.ndarray):
        """
        Convert `array` → QPixmap and show in the existing QGraphicsView.
        Does NOT reset the zoom/pan unless self._auto_fit is True.
        After doing an auto‐fit, sets self._auto_fit = False.
        """
        arr = array.copy()
        # Convert to 8‐bit for display:
        if arr.dtype in (np.float32, np.float64):
            arr = np.clip(arr, 0.0, 1.0)
            arr8 = (arr * 255).astype(np.uint8)
        elif arr.dtype == np.uint16:
            arr8 = (np.clip(arr, 0, 65535) // 257).astype(np.uint8)
        elif arr.dtype == np.uint8:
            arr8 = arr
        else:
            mn, mx = arr.min(), arr.max()
            if mx > mn:
                arr8 = ((arr - mn) / (mx - mn) * 255).astype(np.uint8)
            else:
                arr8 = np.zeros_like(arr, dtype=np.uint8)

        h, w = arr8.shape[:2]
        if arr8.ndim == 2:
            fmt = QImage.Format.Format_Grayscale8
            bytespp = w
        else:
            fmt = QImage.Format.Format_RGB888
            bytespp = 3 * w

        qimg = QImage(arr8.data, w, h, bytespp, fmt)
        pix = QPixmap.fromImage(qimg)

        # Update the pixmap item
        self.pixmap_item.setPixmap(pix)
        # Resize the scene to match the new image dimensions
        self.scene.setSceneRect(0, 0, w, h)

        # If self._auto_fit is True, reset any previous zoom, then fit to view.
        # Otherwise, leave the user’s current zoom/pan alone.
        if getattr(self, "_auto_fit", False):
            self.view.resetTransform()
            self.view.fitInView(self.scene.sceneRect(), Qt.AspectRatioMode.KeepAspectRatio)
            self._auto_fit = False

    # ─────────────────────────────────────────────────────────────────────
    def zoom_in(self):
        """Zoom in by 20%."""
        self.view.scale(1.2, 1.2)

    def zoom_out(self):
        """Zoom out by 20%."""
        self.view.scale(1/1.2, 1/1.2)

    def _on_fit_clicked(self):
        """
        Called when the user clicks “Fit to Preview.” We set self._auto_fit = True
        and then re‐invoke _display_in_view on whichever image is currently shown.
        """
        self._auto_fit = True
        if self._preview_result is not None:
            # Fit the preview image
            self._display_in_view(self._preview_result)
        elif self._original_image is not None:
            # No preview yet, so fit the original image
            self._display_in_view(self._original_image)
        else:
            # Nothing to fit; clear or do nothing
            pass



    def _on_run_sep(self):
        """
        Called when “Run SEP Extraction” is clicked.
        Grabs the active image from `self.parent().image_manager`, runs SEP,
        shows the preview, and stores the kernel internally.
        """
        # 1) Grab the current image array (assume parent has image_manager.get_current_image())
        img, _ = self.parent().image_manager.get_current_image_and_metadata()
        if img is None:
            QMessageBox.warning(self, "No Image", "Please load or select an image before estimating PSF.")
            return

        if img.ndim == 3:
            # Convert to grayscale by averaging the three channels (or pick one channel)
            img_gray = img.mean(axis=2).astype(np.float32)
        else:
            img_gray = img.astype(np.float32)

        # 2) Read SEP parameters from the UI
        sigma   = self.sep_threshold_slider.value()
        minarea = self.sep_minarea_spin.value
        sat     = self.sep_sat_slider.value()
        maxstars= self.sep_maxstars_spin.value
        half_w  = self.sep_stamp_spin.value

        try:
            # 3) Call the helper
            psf_kernel = estimate_psf_from_image(
                image_array       = img_gray,
                threshold_sigma   = sigma,
                min_area          = minarea,
                saturation_limit  = sat,
                max_stars         = maxstars,
                stamp_half_width  = half_w
            )
        except RuntimeError as e:
            QMessageBox.critical(self, "PSF Error", str(e))
            return

        # 4) Store it
        self._last_stellar_psf = psf_kernel

        # 5) Show preview in 64×64 QLabel
        self._show_stellar_psf_preview(psf_kernel)

    def _show_stellar_psf_preview(self, psf_kernel: np.ndarray):
        """
        Convert `psf_kernel` → 64×64 QPixmap and show in self.sep_psf_preview.
        """
        h, w = psf_kernel.shape

        # Normalize to 0..255
        maxval = psf_kernel.max()
        if maxval > 0:
            img8 = (psf_kernel / maxval * 255.0).astype(np.uint8)
        else:
            img8 = np.zeros_like(psf_kernel, dtype=np.uint8)

        # Wrap in QImage
        qimg = QImage(img8.data, w, h, w, QImage.Format.Format_Grayscale8)

        # Scale to 64×64, keep aspect
        scaled = QPixmap.fromImage(qimg).scaled(
            64, 64,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # Center in 64×64 transparent pixmap
        final = QPixmap(64, 64)
        final.fill(Qt.GlobalColor.transparent)
        painter = QPainter(final)
        x_off = (64 - scaled.width()) // 2
        y_off = (64 - scaled.height()) // 2
        painter.drawPixmap(x_off, y_off, scaled)
        painter.end()

        self.sep_psf_preview.setPixmap(final)

    def _on_use_stellar_psf(self):
        """
        Called when “Use as Current PSF” is clicked.
        Store the SEP‐derived kernel and enable the “custom” flag.
        """
        if self._last_stellar_psf is None:
            QMessageBox.warning(self, "No PSF", "Please run SEP extraction first.")
            return

        # 1) Save the custom PSF array and set the flag
        self._custom_psf = self._last_stellar_psf.copy()
        self._use_custom_psf = True

        # 1a) Immediately update the 64×64 preview label with the stellar PSF
        stellar_pix = self._make_stellar_psf_pixmap(self._custom_psf)
        self.conv_psf_label.setPixmap(stellar_pix)

        # 2) Switch the Deconvolution algorithm to Richardson–Lucy
        self.deconv_algo_combo.setCurrentText("Richardson-Lucy")

        # 3) Show the “Using Stellar PSF” label
        self.rl_custom_label.setVisible(True)
        self.rl_disable_custom_btn.setVisible(True)

        # 4) Inform the user
        QMessageBox.information(
            self,
            "PSF Selected",
            "Stellar PSF is now active for Richardson–Lucy."
        )

    def _clear_custom_psf_flag(self, _=None):
        """
        Turn off “Use Stellar PSF” mode.
        """
        if self._use_custom_psf:
            self._use_custom_psf = False
            self._custom_psf = None
            self.rl_custom_label.setVisible(False)
            self.rl_disable_custom_btn.setVisible(False)

    def _on_save_stellar_psf(self):
        """
        Let the user save the last computed PSF to disk as a FITS or TIFF.
        """
        if self._last_stellar_psf is None:
            QMessageBox.warning(self, "No PSF", "Run SEP extraction before saving.")
            return

        path, _ = QFileDialog.getSaveFileName(self, "Save PSF as...", "", "TIFF (*.tif);;FITS (*.fits)")
        if not path:
            return

        # If the user chose .fits or .tif, write appropriately
        ext = path.lower().split('.')[-1]
        if ext == 'fits':
            hdu = fits.PrimaryHDU(self._last_stellar_psf.astype(np.float32))
            hdu.writeto(path, overwrite=True)
        elif ext in ('tif', 'tiff'):
            # If you have tifffile installed:
            import tifffile
            tifffile.imwrite(path, self._last_stellar_psf.astype(np.float32))
        else:
            QMessageBox.warning(self, "Invalid Extension", "Please choose .fits or .tif.")
            return
        QMessageBox.information(self, "Saved", f"PSF saved to:\n{path}")

def estimate_psf_from_image(image_array: np.ndarray,
                            threshold_sigma: float,
                            min_area: int,
                            saturation_limit: float,
                            max_stars: int,
                            stamp_half_width: int) -> np.ndarray:
    """
    Given a 2D NumPy image (float or uint16/uint32), run SEP‐based star detection,
    discard anything brighter than saturation_limit, extract postage stamps of size
    (2*stamp_half_width+1)² around the star centroids, recast to float32, 
    align & normalize each stamp, and return their average as a normalized PSF.
    
    Returns:
        psf_kernel: 2D float32 array (sum=1), size = (2*stamp_half_width+1).
    """
    # 1) Convert to the SEP‐friendly dtype (float32) if needed
    data = image_array.astype(np.float32)

    # 2) Estimate background & RMS
    bkg = sep.Background(data)
    bkg_sub = data - bkg.back()  # subtract background

    # 3) Run SEP extraction with given σ threshold and min_area
    #    `err` can be None for now; SEP will estimate it from data.
    sources = sep.extract(bkg_sub, thresh=threshold_sigma, 
                          err=bkg.globalrms, minarea=min_area)
    if len(sources) == 0:
        raise RuntimeError("No sources found with SEP threshold = %.1f σ." % threshold_sigma)

    # 4) Filter out saturated detections
    #    SEP’s “peak” column is the maximum pixel value of the detection.
    valid_sources = []
    for src in sources:
        if src['peak'] < saturation_limit:
            valid_sources.append(src)

    if len(valid_sources) == 0:
        raise RuntimeError("All detected sources exceed saturation limit %.0f." % saturation_limit)

    # 5) Sort by brightness (peak) descending, take brightest `max_stars`
    valid_sources.sort(key=lambda s: s['peak'], reverse=True)
    selected = valid_sources[: max_stars]

    # 6) For each selected source, extract a postage stamp of size (2*w + 1)
    w = stamp_half_width
    kernel_size = 2*w + 1
    psf_sum = np.zeros((kernel_size, kernel_size), dtype=np.float32)
    count = 0

    for src in selected:
        x_centroid = src['x']  # float pixel coordinate
        y_centroid = src['y']

        # Convert to nearest integer for raw indexing
        xi = int(round(x_centroid))
        yi = int(round(y_centroid))

        # Define stamp boundaries in image coordinates
        y0 = yi - w
        y1 = yi + w + 1   # +1 because Python slices exclude the upper bound
        x0 = xi - w
        x1 = xi + w + 1

        # Skip if the stamp would go partially outside the image
        if y0 < 0 or x0 < 0 or y1 > data.shape[0] or x1 > data.shape[1]:
            continue

        stamp = bkg_sub[y0:y1, x0:x1].astype(np.float32)

        # 7) Recentroid to subpixel (optional enhancement):
        #    If you want subpixel alignment, re‐compute the centroid
        #    of the stamp via a 2D weighted average, then shift the stamp by that offset.
        #    For simplicity, you can skip subpixel alignment for now.

        # 8) Normalize this stamp so its sum = 1 (or sum of positive values)
        total_flux = np.sum(stamp)
        if total_flux <= 0:
            # Something went wrong; skip it
            continue

        stamp_normalized = stamp / total_flux

        psf_sum += stamp_normalized
        count += 1

    if count == 0:
        raise RuntimeError("No valid postage stamps extracted (all were off‐edge or zero).")

    # 9) Final averaged PSF
    psf_kernel = (psf_sum / count).astype(np.float32)

    # 10) Normalize one more time to ensure sum(psf)=1 (safety)
    psf_total = psf_kernel.sum()
    if psf_total > 0:
        psf_kernel /= psf_total
    else:
        # As a last resort, return a delta‐PSF
        psf_kernel = np.zeros_like(psf_kernel, dtype=np.float32)
        center = w
        psf_kernel[center, center] = 1.0

    return psf_kernel

# ─────────────────────────────────────────────────────────────────────────────
def make_elliptical_gaussian_psf(radius: float,
                                 kurtosis: float,
                                 aspect: float,
                                 rotation_deg: float) -> np.ndarray:
    """
    Build a 2D elliptical generalized‐Gaussian PSF kernel (sum=1):
    
      PSF(x,y) = A ⋅ exp( − [ (x'/σ_x)^2 + (y'/σ_y)^2 ]^β )
    
    where:
      σ_x = radius,
      σ_y = radius / aspect,
      β   = kurtosis,
      and (x',y') is the coordinate rotated by rotation_deg (in degrees).
    
    Returns a normalized (sum=1) float32 array.
    """
    # 1) Compute σ_x and σ_y
    sigma_x = radius
    sigma_y = radius / aspect

    # 2) Build a bounding box so we capture essentially all of the PSF
    #    ~6×sigma_x on each side (force odd so there’s a center pixel).
    size = int(np.ceil(6 * sigma_x))
    if size % 2 == 0:
        size += 1
    half = size // 2

    # 3) Create (x, y) grid centered at 0
    xs = np.linspace(-half, half, size)
    ys = np.linspace(-half, half, size)
    xv, yv = np.meshgrid(xs, ys)  # shape = (size, size)

    # 4) Rotate coordinates by −rotation_deg to align major axis with x'
    θ = np.deg2rad(rotation_deg)
    cos_t, sin_t = np.cos(θ), np.sin(θ)
    x_rot =  cos_t * xv + sin_t * yv
    y_rot = -sin_t * xv + cos_t * yv

    # 5) Compute “generalized exponent” = [ (x'/σ_x)^2 + (y'/σ_y)^2 ]^β
    β = kurtosis
    squared_sum = (x_rot / sigma_x)**2 + (y_rot / sigma_y)**2
    exponent = squared_sum ** β

    # 6) Build PSF
    psf = np.exp(-exponent)

    # 7) Normalize to sum = 1
    total = psf.sum()
    if total != 0:
        psf = (psf / total).astype(np.float32)
    else:
        psf = np.zeros_like(psf, dtype=np.float32)

    return psf


def _rl_tile_process_reg(tile_and_meta: Tuple[int, np.ndarray]) -> Tuple[int, np.ndarray]:
    """
    Worker for a padded tile that implements:
      - Plain Richardson–Lucy (RL)
      - RL + Tikhonov (L2) penalty at each iteration
      - RL + Total Variation (TV) penalty at each iteration
      followed by an optional single bilateral‐denoise (“dering”).

    Arguments in tile_and_meta:
      0) tile_index   : int  (to re‐assemble in order)
      1) padded_tile  : np.ndarray of shape ((L_ext + 2*pad) × (W + 2*pad))
      2) psf          : np.ndarray (2D, normalized kernel)
      3) num_iter     : int  (number of RL iterations)
      4) clip_flag    : bool (if True, apply one bilateral pass at end)
      5) pad          : int  (how many pixels were padded on each side)
      6) reg_type     : str  ("None (Plain R–L)", "Tikhonov (L2)", or "Total Variation (TV)")
      7) y0_ext       : int  (row‐index of top of extended region, in the full image)
      8) y1_ext       : int  (row‐index of bottom of extended region, in the full image)
      9) L_ext        : int  (number of rows in the extended region, before padding)

    Returns:
      (tile_index, deconv_core) where deconv_core.shape = (L_ext, W).
    """
    (tile_index,
     padded_tile,
     psf,
     num_iter,
     clip_flag,
     pad,
     reg_type,
     y0_ext,
     y1_ext,
     L_ext) = tile_and_meta

    # === Choose small constants for L2 and TV penalties ===
    alpha_L2 = 0.01     # Tikhonov weight
    alpha_tv = 0.01     # TV weight

    # === Initialize f ===
    # For RL we typically start with sharp initial guess = padded tile itself (clipped to [eps..1])
    f = np.clip(padded_tile.astype(np.float32), 1e-8, None)

    # Pre‐flip PSF for the “backward” convolution step
    psf_flipped = psf[::-1, ::-1]

    # === Full RL loop with optional regularization ===
    for _ in range(num_iter):
        # 1) Convolve current estimate with PSF
        estimate_blurred = fftconvolve(f, psf, mode="same")

        # 2) Compute ratio = observed / estimate_blurred
        ratio = padded_tile / (estimate_blurred + 1e-8)

        # 3) Backproject ratio through PSF^T
        correction = fftconvolve(ratio, psf_flipped, mode="same")

        # 4) Update f
        f = f * correction

        # 5) Apply Tikhonov (L2) penalty if requested:
        if reg_type == "Tikhonov (L2)":
            # A simple L2 step: subtract a small Laplacian
            # Note: `laplace(f)` returns the discrete Laplacian of f
            f = f - alpha_L2 * laplace(f)

        # 6) Apply TV penalty if requested:
        elif reg_type == "Total Variation (TV)":
            # Running a single‐iteration TV denoise at each step
            f = denoise_tv_chambolle(f, weight=alpha_tv, channel_axis=None).astype(np.float32)

        # 7) Ensure non‐negativity and clip to [0..1]
        f = np.clip(f, 0.0, 1.0)

    # === Optional “deringing” (one bilateral‐denoise) ===
    if clip_flag:
        f = denoise_bilateral(
            f,
            sigma_color=0.08,
            sigma_spatial=1
        ).astype(np.float32)

    # === Crop away padding: return only the core region of size L_ext × W ===
    full_h, full_w = f.shape
    Wcore = full_w - 2 * pad
    deconv_core = f[pad : pad + L_ext, pad : pad + Wcore].astype(np.float32)

    return (tile_index, deconv_core)

# ─────────────────────────────────────────────────────────────────────────────
def van_cittert_deconv(image: np.ndarray, iterations: int, relaxation: float) -> np.ndarray:
    """
    Simple Van Cittert deconvolution:
      f_0 = image
      For n in [0..iterations-1]:
        f_{n+1} = f_n + relaxation * (image - f_n * psf)
      (Here we assume 'psf' is the same elliptical Gaussian PSF used in RL
       with default parameters. You may want to pass a PSF separately.)

    For demonstration, we’ll build a small Gaussian PSF with fixed parameters.
    In practice, you should pass the appropriate PSF (matching how you convolved).
    """
    # Example: use a small 1D Gaussian PSF for van Cittert. In practice, match your convolution PSF.
    sigma = 3.0
    size = int(np.ceil(6 * sigma))
    if size % 2 == 0:
        size += 1
    xs = np.linspace(-size//2, size//2, size)
    kernel_1d = np.exp(-(xs**2) / (2*sigma**2))
    kernel_1d = kernel_1d / kernel_1d.sum()

    # Create a separable 2D PSF
    psf = np.outer(kernel_1d, kernel_1d).astype(np.float32)

    # Initialize f_n
    f = image.copy().astype(np.float32)

    for _ in range(iterations):
        conv = fftconvolve(f, psf, mode="same")
        f = f + relaxation * (image.astype(np.float32) - conv)

    return np.clip(f, 0.0, 1.0)

def rotate_about_center(
    image: np.ndarray,
    angle_deg: float,
    center: Tuple[float, float]
) -> np.ndarray:
    """
    Rotate an image (H×W or H×W×3) by `angle_deg` degrees around a given center (y0, x0).
    - image: np.ndarray, float32 in [0..1] or uint8/uint16.
    - angle_deg: positive = CCW rotation (in degrees).
    - center: (row=y0, col=x0), pivot point in pixel coords.
    Returns a float32 array in [0..1] of the same shape as input.
    """
    # 1) Convert input to float32 [0..1]
    img_f = img_as_float32(image)

    H, W = img_f.shape[:2]
    y0, x0 = center

    # 2) Build a 2×3 affine transform that:
    #    - shifts center to origin
    #    - rotates by angle
    #    - shifts back to (x0, y0)
    theta = np.deg2rad(angle_deg)
    cos_t = np.cos(theta)
    sin_t = np.sin(theta)

    # For a point (x, y), the rotation matrix about the origin is:
    #   [ cos  -sin ]
    #   [ sin   cos ]
    # To pivot about (x0, y0), we do:  Shift(-x0, -y0) → Rotate → Shift(+x0, +y0)
    # The combined 2×3 matrix M = [ [cos, -sin, tx], [sin, cos, ty] ] where:
    tx = x0 - ( x0 * cos_t - y0 * sin_t )
    ty = y0 - ( x0 * sin_t + y0 * cos_t )

    M = np.array([[ cos_t, -sin_t, tx ],
                  [ sin_t,  cos_t, ty ]], dtype=np.float32)

    # 3) Use skimage.warp with this affine matrix (inverse mapping).
    #    `warp` expects the inverse transformation, so we feed `np.linalg.inv(A)` or
    #    simply use `affine_transform=...` via the `inverse_map` argument. However,
    #    scikit‐image lets us pass a 3×3 homogeneous matrix to `warp` directly:
    #
    #    We can embed M into a 3×3 as:
    #       [ cos  -sin  tx ]
    #       [ sin   cos  ty ]
    #       [  0     0    1 ]
    #
    #    Then `warp(image, AffineTransform(matrix=inv(M3x3)).inverse)` or simpler: use
    #    `warp(..., transform=AffineTransform(...))`.
    #
    #    But since `warp` also accepts a 2×3 “inverse map” if you pass `inverse_map=M_inv`
    #    directly, we can do that. In practice, the easiest is to create a 3×3 and invert:
    from skimage.transform import AffineTransform

    # Build a 3×3 homogeneous transform from M:
    M3 = np.eye(3, dtype=np.float32)
    M3[:2, :] = M

    # We want to tell `warp` to use the inverse of M3, so that output(x_out) = input(M3^{-1} * [x_out y_out 1]^T).
    tform = AffineTransform(matrix=np.linalg.inv(M3))

    # 4) Call warp.  For color images, `warp` applies the same transform to each channel.
    rotated = warp(
        img_f,
        inverse_map=tform,      # warp will apply tform to each output pixel to sample from img_f
        order=1,                # bilinear interpolation
        mode='constant',        # pixels outside get filled with cval
        cval=0.0,
        preserve_range=True     # keep value range in [0..1]
    )

    return rotated.astype(np.float32)

def _bilinear_interpolate_gray(
    gray: np.ndarray,
    y_coords: np.ndarray,
    x_coords: np.ndarray,
    cval: float = 0.0
) -> np.ndarray:
    """
    Perform bilinear interpolation on a single‐channel 2D array `gray` at
    the (possibly non‐integer) coordinates given by y_coords, x_coords.

    Parameters
    ----------
    gray : np.ndarray
        2D float32 array of shape (H, W), values in [0..1].
    y_coords, x_coords : np.ndarray
        1D arrays of the same length N, giving the fractional sample positions.
    cval : float
        Value to use for any sample falling outside [0..H-1]×[0..W-1].

    Returns
    -------
    samples : np.ndarray
        1D float32 array of length N, containing the bilinearly‐interpolated
        values (or cval for out‐of‐bounds).
    """
    H, W = gray.shape
    N = y_coords.size

    # Floor and ceil indices for each coordinate
    x0 = np.floor(x_coords).astype(int)
    x1 = x0 + 1
    y0 = np.floor(y_coords).astype(int)
    y1 = y0 + 1

    # Compute interpolation weights
    dx = x_coords - x0
    dy = y_coords - y0

    # Clip indices to be within [0..W-1] or [0..H-1]
    x0c = np.clip(x0, 0, W - 1)
    x1c = np.clip(x1, 0, W - 1)
    y0c = np.clip(y0, 0, H - 1)
    y1c = np.clip(y1, 0, H - 1)

    # Gather the four neighbor pixels, but we'll mask out OOB afterward
    Ia = gray[y0c, x0c]  # top-left
    Ib = gray[y0c, x1c]  # top-right
    Ic = gray[y1c, x0c]  # bottom-left
    Id = gray[y1c, x1c]  # bottom-right

    # Compute the weighted sum
    wa = (1 - dx) * (1 - dy)
    wb = dx * (1 - dy)
    wc = (1 - dx) * dy
    wd = dx * dy
    interp = (Ia * wa) + (Ib * wb) + (Ic * wc) + (Id * wd)

    # Now mask out-of-bounds positions:
    # A point is OOB if x_coords<0 or x_coords>W-1 or y_coords<0 or y_coords>H-1.
    oob_mask = (
        (x_coords < 0) | (x_coords >= W) |
        (y_coords < 0) | (y_coords >= H)
    )
    interp[oob_mask] = cval

    return interp.astype(np.float32)
# ─────────────────────────────────────────────────────────────────────────────
def larson_sekanina(
    image: np.ndarray,
    center: Tuple[float, float],
    radial_step: Optional[float],
    angular_step_deg: float,
    operator: str = "Divide"
) -> np.ndarray:
    """
    Larson–Sekanina implemented entirely via direct Cartesian sampling, WITHOUT warp_polar.

    If radial_step is None or <= 0, falls back to a single global rotation (Δr = 0).
    Otherwise, for each pixel at (y,x), compute its
      r = sqrt((x-x0)^2 + (y-y0)^2),  θ = atan2(y-y0, x-x0)
      →  r' = r + radial_step,   θ' = θ + angular_step_deg*(π/180)
      →  x' = x0 + r' * cos(θ'),  y' = y0 + r' * sin(θ')
      Sample J = gray(y', x') by bilinear interpolation.
      Then either Subtract or Divide (flat‐style) to get B(y,x).

    Parameters
    ----------
    image : np.ndarray
        A float32 array in [0..1], shape (H,W) or (H,W,3).  If color, first converts to grayscale.
    center : (float, float)
        (row=y0, col=x0) pivot for polar coordinates (float).
    radial_step : float or None
        If <=0 or None, do Δr=0 (pure rotation). Otherwise, Δr = radial_step.
    angular_step_deg : float
        How many degrees to rotate CCW for every sample: Δθ in degrees.
    operator : str, default "Divide"
        - "Subtract": B = max(gray – J, 0), then normalize so that max(B)=1.
        - "Divide":   B = gray * (median(J) / (J + ε)), then clip to [0..1].

    Returns
    -------
    B : np.ndarray
        2D float32 array of shape (H, W), values in [0..1], representing
        the LS result ready to be blended (Screen/SoftLight) or added.
    """

    # 1) Ensure image is float32 in [0..1], reduce to grayscale if needed
    if image.dtype != np.float32:
        raise ValueError("larson_sekanina: input must be float32 in [0..1]")
    if image.ndim == 3 and image.shape[2] == 3:
        # Convert RGB → grayscale in [0..1]
        from skimage.color import rgb2gray
        gray = rgb2gray(image)
    else:
        gray = image  # already float32 [0..1]

    H, W = gray.shape
    y0, x0 = center

    # Convert Δθ to radians
    dtheta = (angular_step_deg / 180.0) * np.pi

    # 2) Precompute (r, θ) for each pixel (vectorized)
    ys = np.arange(H, dtype=np.float32)[:, None]  # shape (H,1)
    xs = np.arange(W, dtype=np.float32)[None, :]  # shape (1,W)
    dy = ys - y0         # shape (H,1)
    dx = xs - x0         # shape (1,W)
    # Broadcast to (H,W):
    dy = np.broadcast_to(dy, (H, W))
    dx = np.broadcast_to(dx, (H, W))
    r  = np.sqrt(dx*dx + dy*dy)             # radius for each pixel
    θ  = np.arctan2(dy, dx)                 # angle in [-π..π]
    θ[θ < 0] += 2*np.pi                     # now θ in [0..2π)

    # 3) Build the target (r', θ') arrays
    if radial_step is None or radial_step <= 0:
        # Pure rotation: Δr = 0
        r2 = r
    else:
        r2 = r + radial_step

    θ2 = θ + dtheta
    θ2 %= (2*np.pi)  # wrap back into [0..2π)

    # 4) Convert (r2, θ2) back to Cartesian sample positions (x2, y2)
    x2 = x0 + r2 * np.cos(θ2)
    y2 = y0 + r2 * np.sin(θ2)

    # 5) Flatten to 1D arrays for interpolation
    x2_flat = x2.ravel()
    y2_flat = y2.ravel()

    # 6) Bilinear‐interpolate gray at (y2_flat, x2_flat)
    J_flat = _bilinear_interpolate_gray(gray, y2_flat, x2_flat, cval=0.0)  # shape (H*W,)
    J = J_flat.reshape(H, W)  # shape (H, W)

    # 7) Form B according to operator
    if operator == "Divide":
        eps = 1e-6
        med = np.median(J)
        if med <= 0:
            med = 1e-6
        B_unclipped = gray * (med / (J + eps))
        B = np.clip(B_unclipped, 0.0, 1.0)
    else:  # "Subtract"
        diff = gray - J
        B = np.clip(diff, 0.0, None)
        maxv = B.max()
        if maxv > 0:
            B = B / maxv
        else:
            B = np.zeros_like(B)

    return B.astype(np.float32)

class XISFViewer(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.image_data = None
        self.file_meta = None
        self.image_meta = None
        self.is_mono = False
        self.bit_depth = None
        self.scale_factor = 1.0
        self.dragging = False
        self.drag_start_pos = QPoint()
        self.autostretch_enabled = False
        self.current_pixmap = None
        self.filename = ""              # ← initialize to empty string
        self.original_header = None     # ← likewise     
        self.image = None
        self.preview_image = None          
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
    
    def initUI(self):
        main_layout = QHBoxLayout()
        splitter = QSplitter(Qt.Orientation.Horizontal)
        splitter.setHandleWidth(5)



        # Set the window icon
        self.setWindowIcon(QIcon(icon_path))

        # Left side layout for image display and save button
        left_widget = QWidget()        
        left_layout = QVBoxLayout(left_widget)
        left_widget.setMinimumSize(400, 400)
        
        self.load_button = QPushButton("Load Image File")
        self.load_button.clicked.connect(self.load_xisf)
        #left_layout.addWidget(self.load_button)

        self.image_label = QLabel()
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        
        # Add a scroll area to allow panning
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setWidgetResizable(False)  # Keep it resizable
        self.scroll_area.setAlignment(Qt.AlignmentFlag.AlignCenter)
        left_layout.addWidget(self.scroll_area)

        self.toggle_button = QPushButton("Toggle Autostretch", self)
        self.toggle_button.setCheckable(True)
        self.toggle_button.clicked.connect(self.toggle_autostretch)
        left_layout.addWidget(self.toggle_button)        

        # Zoom buttons
        zoom_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(self.zoom_in_button)
        zoom_layout.addWidget(self.zoom_out_button)
        # Add the "Fit to Window" button
        self.fit_to_window_button = QPushButton("Fit to Window")
        self.fit_to_window_button.clicked.connect(self.fit_to_window)
        zoom_layout.addWidget(self.fit_to_window_button)       
        left_layout.addLayout(zoom_layout)

        # Inside the initUI method, where the Save button is added
        self.save_button = QPushButton("Save As")
        self.save_button.clicked.connect(self.save_as)
        #self.save_button.setEnabled(False)



        # Add the Save button and checkbox to a horizontal layout
        #save_layout = QHBoxLayout()
        #save_layout.addWidget(self.save_button)

        #left_layout.addLayout(save_layout)

        # Add a Batch Process button
        self.batch_process_button = QPushButton("XISF Converter Batch Process")
        self.batch_process_button.clicked.connect(self.open_batch_process_window)
        left_layout.addWidget(self.batch_process_button)

        self.load_logo()

        # Right side layout for metadata display
        right_widget = QWidget()
        right_widget.setMinimumWidth(300)
        right_layout = QVBoxLayout()
        self.metadata_tree = QTreeWidget()
        self.metadata_tree.setHeaderLabels(["Property", "Value"])
        self.metadata_tree.setColumnWidth(0, 150)
        right_layout.addWidget(self.metadata_tree)
        
        # Save Metadata button below metadata tree
        self.save_metadata_button = QPushButton("Save Metadata")
        self.save_metadata_button.clicked.connect(self.save_metadata)
        right_layout.addWidget(self.save_metadata_button)
        
        right_widget.setLayout(right_layout)

        # Add left widget and metadata tree to the splitter
        splitter.addWidget(left_widget)
        splitter.addWidget(right_widget)
        #splitter.setSizes([800, 200])  # Initial sizes for the left (preview) and right (metadata) sections
        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 0)

        main_layout.addWidget(splitter)
        self.setLayout(main_layout)
        self.setWindowTitle("XISF Liberator V1.2")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        if not self.isVisible():
            return

        # Clear previous content
        self.image_label.clear()
        self.metadata_tree.clear()

        # Pull the filename from metadata (or empty string)
        self.filename = metadata.get('file_path', '') or ''
        self.original_header = metadata.get('original_header', None)

        if image is None:
            print(f"XISFViewer: Cleared image display for slot {slot}.")
            return

        # Get image and metadata from the current slot
        if slot == self.image_manager.current_slot:
            if not isinstance(image, np.ndarray):
                image = np.array(image)
            self.image = image
            self.preview_image = None
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', "Unknown File")

        # --- If the file is a FITS file with a Bayer pattern, debayer before converting to 3-channel ---
        if self.filename.lower().endswith(('.fits', '.fit', '.fits.fz', '.fit.fz')):
            if self.original_header and self.original_header.get('BAYERPAT'):
                print(f"Running debayer_image on {self.filename}")
                # Expecting the raw image to be 2D (mono)
                if self.image.ndim == 2:
                    debayered_image, debayered_mono = self.debayer_image(self.image, self.filename, self.original_header, True)
                    self.image_data = debayered_image
                    self.is_mono = debayered_mono
                else:
                    # If it's already 3D, skip debayering.
                    print("Image already has multiple channels; skipping debayering.")
                    self.image_data = self.image
            else:
                self.image_data = self.image
        else:
            self.image_data = self.image

        # --- If the image is still mono (and not debayered), convert 2D to 3-channel RGB for display ---
        if self.is_mono and self.image_data.ndim == 2:
            self.image_data = np.stack([self.image_data] * 3, axis=-1)

        # --- Autostretch if enabled ---
        if self.autostretch_enabled:
            self.apply_autostretch()

        # Display the image
        self.display_image()

        # Update metadata display (if applicable)
        if self.filename.lower().endswith(('.fits', '.fit', '.fits.fz', '.fit.fz', '.xisf',
                                            '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            self.display_metadata(self.filename)

        print(f"XISFViewer: Image updated from ImageManager slot {slot}.")







    def load_logo(self):
        """
        Load and display the XISF Liberator logo before any image is loaded.
        """
        logo_path = resource_path("astrosuite.png")
        if not os.path.exists(logo_path):
            print(f"Logo image not found at path: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        # Load the logo image
        logo_pixmap = QPixmap(logo_path)
        if logo_pixmap.isNull():
            print(f"Failed to load logo image from: {logo_path}")
            self.image_label.setText("XISF Liberator")
            return

        self.current_pixmap = logo_pixmap  # Store the logo pixmap
        scaled_pixmap = logo_pixmap.scaled(
            logo_pixmap.size() * self.scale_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.resize(scaled_pixmap.size())

    def toggle_autostretch(self):
        if self.image_data is None:
            QMessageBox.warning(self, "No Image", "No image loaded to apply autostretch.")
            return        
        self.autostretch_enabled = not self.autostretch_enabled
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.stretched_image = self.image_data  # Reset to original image if stretch is disabled

        self.display_image()

    def apply_autostretch(self):
        # Determine if the image is mono or color
        if len(self.image_data.shape) == 2:  # Mono image
            self.stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:  # Color image
            self.stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=False, normalize=False)

    def open_batch_process_window(self):
        self.batch_dialog = BatchProcessDialog(self)
        self.batch_dialog.show()


    def load_xisf(self):
        file_name, _ = QFileDialog.getOpenFileName(
            self, 
            "Open Image File", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fits *.fit *.fz *.fz *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )

        if file_name:
            try:
                # Use the global load_image function to load the image and its metadata
                image, header, bit_depth, is_mono = load_image(file_name)
                
                # Apply debayering if needed (for non-mono images)
                if is_mono:  # Only debayer if the image is not mono
                    image, is_mono = self.debayer_image(image, file_name, header, is_mono)

                # Check if the image is mono or RGB
                self.is_mono = is_mono
                self.bit_depth = bit_depth
                self.image_data = image

                # Reset scale factor when a new image is loaded
                self.scale_factor = 0.25

                # If autostretch is enabled, apply stretch immediately after loading
                if self.autostretch_enabled:
                    self.apply_autostretch()

                # Display the image with scaling and normalization
                
                self.display_image()

                # Set image metadata (using header from load_image)
                self.file_meta = header  # Use the loaded header for metadata
                self.image_meta = None  # No separate image metadata for XISF in this example
                
                # Display metadata (using the global display_metadata method for appropriate file types)
                self.display_metadata(file_name)

                # Push the loaded image to ImageManager (only if image_manager exists)
                if hasattr(self, 'image_manager'):
                    metadata = {
                        'file_path': file_name,
                        'is_mono': self.is_mono,
                        'bit_depth': self.bit_depth,
                        'source': 'XISF'  # Or specify 'FITS' if applicable
                    }
                    # Push the numpy array to ImageManager (not memoryview)
                    self.image_manager.update_image(np.array(self.image_data), metadata, slot=0)  # Add image to slot 0 in ImageManager

                # Enable save button if the image is loaded successfully
                self.save_button.setEnabled(True)

            except Exception as e:
                self.image_label.setText(f"Failed to load XISF file: {e}")


    def debayer_image(self, image, file_path, header, is_mono):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        # For FITS files, check for BAYERPAT in the header.
        if file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
            print(f"running debayer_image on {file_path}")
            bayer_pattern = header.get('BAYERPAT', None)
            if bayer_pattern is None:
                bayer_header = get_bayer_header(file_path)
                bayer_pattern = bayer_header.get('BAYERPAT', None) if bayer_header else None

            if bayer_pattern:
                print(f"Debayering FITS image: {file_path} with Bayer pattern {bayer_pattern}")
                is_mono = False
                # use numba-accelerated fast version
                image = debayer_fits_fast(image, bayer_pattern)
            else:
                print(f"No Bayer pattern found in FITS header: {file_path}")

        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            # For RAW files, apply fast debayer_raw_fast
            print(f"Debayering RAW image: {file_path}")
            is_mono = False
            image = debayer_raw_fast(image)

        return image, is_mono


    def debayer_fits(self, image_data, bayer_pattern):
        """Legacy alias to the fast numba-accelerated debayer."""
        return debayer_fits_fast(image_data, bayer_pattern)


    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Legacy alias to the fast numba-accelerated debayer."""
        return debayer_raw_fast(raw_image_data, bayer_pattern)


    def display_image(self):
        if self.image_data is None:
            return

        # pick the right source
        im_data = self.stretched_image if self.autostretch_enabled else self.image_data

        # mono → RGB
        if im_data.ndim == 2:
            im_data = np.stack([im_data] * 3, axis=-1)
        elif im_data.ndim == 3 and im_data.shape[2] == 1:
            im_data = np.repeat(im_data, 3, axis=-1)

        # now we expect a H×W×3 array
        if im_data.ndim != 3 or im_data.shape[2] != 3:
            print(f"Unexpected image shape: {im_data.shape}")
            return

        h, w, c = im_data.shape
        bytes_per_line = c * w

        # prepare an 8-bit buffer
        if im_data.dtype == np.uint8:
            buf8 = im_data

        elif im_data.dtype == np.uint16:
            # linear map 0…65535 → 0…255
            buf8 = (im_data.astype(np.float32) / 65535.0 * 255.0) \
                    .clip(0, 255).astype(np.uint8)

        elif im_data.dtype in (np.float32, np.float64):
            # assume values already in [0…1]
            buf8 = (im_data * 255.0).clip(0, 255).astype(np.uint8)

        else:
            print(f"Unsupported dtype for display: {im_data.dtype}")
            return

        # build a QImage from the 8-bit data
        qimg = QImage(buf8.tobytes(), w, h, bytes_per_line,
                      QImage.Format.Format_RGB888)

        # apply current zoom/scale
        sw = int(qimg.width() * self.scale_factor)
        sh = int(qimg.height() * self.scale_factor)
        scaled = qimg.scaled(sw, sh,
                             Qt.AspectRatioMode.KeepAspectRatio,
                             Qt.TransformationMode.SmoothTransformation)

        pix = QPixmap.fromImage(scaled)
        self.current_pixmap = pix
        self.image_label.setPixmap(pix)
        self.image_label.resize(scaled.size())


    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        self.center_image_on_zoom(1.25)


    def zoom_out(self):
        self.center_image_on_zoom(1 / 1.25)

    def fit_to_window(self):
        if self.image_data is None:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")
            return

        # Get the size of the scroll area viewport
        viewport_size = self.scroll_area.viewport().size()
        viewport_width = viewport_size.width()
        viewport_height = viewport_size.height()

        # Get the image dimensions
        if self.autostretch_enabled and hasattr(self, 'stretched_image') and self.stretched_image is not None:
            img_height, img_width = self.stretched_image.shape[:2]
        else:
            img_height, img_width = self.image_data.shape[:2]

        # Calculate scale factors for width and height
        scale_factor_width = viewport_width / img_width
        scale_factor_height = viewport_height / img_height

        # Choose the smaller scale factor to ensure the image fits within the viewport
        self.scale_factor = min(scale_factor_width, scale_factor_height)

        # Update the display
        self.display_image()

    def center_image_on_zoom(self, zoom_factor):
        # Get the current center point of the visible area
        current_center_x = self.scroll_area.horizontalScrollBar().value() + (self.scroll_area.viewport().width() / 2)
        current_center_y = self.scroll_area.verticalScrollBar().value() + (self.scroll_area.viewport().height() / 2)
        
        # Adjust the scale factor
        self.scale_factor *= zoom_factor
        
        # Display the image with the new scale factor
        self.display_image()
        
        # Calculate the new center point after zooming
        new_center_x = current_center_x * zoom_factor
        new_center_y = current_center_y * zoom_factor
        
        # Adjust scrollbars to keep the image centered
        self.scroll_area.horizontalScrollBar().setValue(int(new_center_x - self.scroll_area.viewport().width() / 2))
        self.scroll_area.verticalScrollBar().setValue(int(new_center_y - self.scroll_area.viewport().height() / 2))

        # 4) announce
        pct = int(self.scale_factor * 100)

        vp = self.scroll_area.viewport()
        center_local = vp.rect().center()                    # QPoint in viewport coords
        center_global = vp.mapToGlobal(center_local)         # map to screen coords

        QToolTip.showText(center_global, f"{pct}%")

    def wheelEvent(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def display_metadata(self, file_path):
        print("starting display_metadata")
        """
        Load and display metadata from the given file if the file is an XISF or FITS file.
        For other file types, simply skip without failing.
        """
        if not file_path:
            print("No file path provided. Skipping metadata display.")
            return

        if not isinstance(file_path, str):
            print(f"Invalid file path type: {type(file_path)}. Expected a string.")
            return

        try:
            if file_path.lower().endswith('.xisf'):
                print("Loading metadata from XISF file.")
                # XISF handling
                try:
                    # Load XISF file for metadata
                    xisf = XISF(file_path)
                    file_meta = xisf.get_file_metadata()
                    image_meta = xisf.get_images_metadata()[0]

                    # Assign metadata to instance variables
                    self.file_meta = file_meta
                    self.image_meta = image_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add File Metadata
                    file_meta_item = QTreeWidgetItem(["File Metadata"])
                    self.metadata_tree.addTopLevelItem(file_meta_item)
                    for key, value in file_meta.items():
                        item = QTreeWidgetItem([key, str(value.get('value', ''))])  # Ensure 'value' exists
                        file_meta_item.addChild(item)

                    # Add Image Metadata
                    image_meta_item = QTreeWidgetItem(["Image Metadata"])
                    self.metadata_tree.addTopLevelItem(image_meta_item)
                    for key, value in image_meta.items():
                        if key == 'FITSKeywords':
                            fits_item = QTreeWidgetItem(["FITS Keywords"])
                            image_meta_item.addChild(fits_item)
                            for kw, kw_values in value.items():
                                for kw_value in kw_values:
                                    item = QTreeWidgetItem([kw, str(kw_value.get("value", ''))])
                                    fits_item.addChild(item)
                        elif key == 'XISFProperties':
                            props_item = QTreeWidgetItem(["XISF Properties"])
                            image_meta_item.addChild(props_item)
                            for prop_name, prop in value.items():
                                item = QTreeWidgetItem([prop_name, str(prop.get("value", ''))])
                                props_item.addChild(item)
                        else:
                            item = QTreeWidgetItem([key, str(value)])
                            image_meta_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load XISF metadata: {e}")

            elif file_path.lower().endswith(('.fits', '.fit', '.fz', '.fz')):
                print("Loading metadata from FITS file.")
                # FITS handling using get_valid_header
                try:
                    # Unpack the header and ignore the extension index for metadata display.
                    header, _ = get_valid_header(file_path)

                    # Assign metadata to instance variables
                    self.file_meta = header
                    self.image_meta = {}  # FITS files typically don't have separate image-level metadata

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add FITS Header Metadata
                    fits_header_item = QTreeWidgetItem(["FITS Header"])
                    self.metadata_tree.addTopLevelItem(fits_header_item)

                    # Loop through the header and add each keyword
                    for keyword, value in header.items():
                        item = QTreeWidgetItem([keyword, str(value)])
                        fits_header_item.addChild(item)

                    self.metadata_tree.expandAll()  # Expand all metadata items
                except Exception as e:
                    print(f"Failed to load FITS metadata: {e}")

            # Handle Camera Raw files (e.g., .cr2, .nef, .arw, .dng)
            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print("Loading metadata from Camera RAW file.")
                try:
                    # Use rawpy to read RAW file metadata
                    raw_meta = {}
                    with rawpy.imread(file_path) as raw:
                        # Example: Extract some basic metadata
                        raw_meta['camera_whitebalance'] = raw.camera_whitebalance
                        raw_meta['camera_white_level_per_channel'] = raw.camera_white_level_per_channel
                        raw_meta['tone_curve_length'] = len(raw.tone_curve) if raw.tone_curve is not None else 0

                    # Assign metadata to instance variables
                    self.file_meta = {}  # RAW files typically don't have file-level metadata in this context
                    self.image_meta = raw_meta

                    self.metadata_tree.clear()  # Clear previous metadata

                    # Add Camera RAW Metadata
                    raw_meta_item = QTreeWidgetItem(["Camera RAW Metadata"])
                    self.metadata_tree.addTopLevelItem(raw_meta_item)

                    for key, value in raw_meta.items():
                        if isinstance(value, (list, tuple, np.ndarray)):
                            for i, item in enumerate(value):
                                raw_meta_item.addChild(QTreeWidgetItem([f"{key}_{i+1}", str(item)]))
                        else:
                            raw_meta_item.addChild(QTreeWidgetItem([key, str(value)]))

                    self.metadata_tree.expandAll()
                except Exception as e:
                    print(f"Failed to load Camera RAW metadata: {e}")

            else:
                # If the file is not a FITS or XISF file, simply return without displaying metadata
                print(f"Skipping metadata for unsupported file type: {file_path}")

        except AttributeError as ae:
            print(f"AttributeError in display_metadata: {ae}")
        except Exception as e:
            print(f"Unexpected error in display_metadata: {e}")


    def save_as(self):
        output_path, _ = QFileDialog.getSaveFileName(self, "Save Image As", "", "XISF (*.xisf);;FITS (*.fits);;TIFF (*.tif);;PNG (*.png)")
        
        if output_path:
            # Determine if we should save the stretched image or the original
            image_to_save = self.stretched_image if self.save_stretched_checkbox.isChecked() and self.stretched_image is not None else self.image_data
            _, ext = os.path.splitext(output_path)
            
            # Determine bit depth and color mode
            is_32bit_float = image_to_save.dtype == np.float32
            is_16bit = image_to_save.dtype == np.uint16
            is_8bit = image_to_save.dtype == np.uint8

            try:
                # Save as FITS file with FITS header only (no XISF properties)
                if ext.lower() in ['.fits', '.fit']:
                    header = fits.Header()
                    crval1, crval2 = None, None
                    
                    # Populate FITS header with FITS keywords and essential WCS keywords only
                    wcs_keywords = ["CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
                    
                    if 'FITSKeywords' in self.image_meta:
                        for keyword, values in self.image_meta['FITSKeywords'].items():
                            for entry in values:
                                if 'value' in entry:
                                    value = entry['value']
                                    if keyword in wcs_keywords:
                                        try:
                                            value = int(value)
                                        except ValueError:
                                            value = float(value)
                                    header[keyword] = value

                    # Manually add WCS information if missing
                    if 'CTYPE1' not in header:
                        header['CTYPE1'] = 'RA---TAN'
                    if 'CTYPE2' not in header:
                        header['CTYPE2'] = 'DEC--TAN'
                    
                    # Add the -SIP suffix if SIP coefficients are present
                    if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                        header['CTYPE1'] = 'RA---TAN-SIP'
                        header['CTYPE2'] = 'DEC--TAN-SIP'

                    # Set default reference pixel (center of the image)
                    if 'CRPIX1' not in header:
                        header['CRPIX1'] = image_to_save.shape[1] / 2  # X center
                    if 'CRPIX2' not in header:
                        header['CRPIX2'] = image_to_save.shape[0] / 2  # Y center

                    # Retrieve RA and DEC values if available
                    if 'FITSKeywords' in self.image_meta:
                        if 'RA' in self.image_meta['FITSKeywords']:
                            crval1 = float(self.image_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
                        if 'DEC' in self.image_meta['FITSKeywords']:
                            crval2 = float(self.image_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

                    # Add CRVAL1 and CRVAL2 to the header if found
                    if crval1 is not None and crval2 is not None:
                        header['CRVAL1'] = crval1
                        header['CRVAL2'] = crval2
                    else:
                        print("RA and DEC values not found in FITS Keywords")

                    # Calculate pixel scale if focal length and pixel size are available
                    if 'FOCALLEN' in self.image_meta['FITSKeywords'] and 'XPIXSZ' in self.image_meta['FITSKeywords']:
                        focal_length = float(self.image_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
                        pixel_size = float(self.image_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
                        pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
                        header['CDELT1'] = -pixel_scale / 3600.0
                        header['CDELT2'] = pixel_scale / 3600.0
                    else:
                        header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
                        header['CDELT2'] = 2.77778e-4

                    # Populate CD matrix using the XISF LinearTransformationMatrix if available
                    if 'XISFProperties' in self.image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in self.image_meta['XISFProperties']:
                        linear_transform = self.image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        header['CD1_1'] = linear_transform[0][0]
                        header['CD1_2'] = linear_transform[0][1]
                        header['CD2_1'] = linear_transform[1][0]
                        header['CD2_2'] = linear_transform[1][1]
                    else:
                        header['CD1_1'] = header['CDELT1']
                        header['CD1_2'] = 0.0
                        header['CD2_1'] = 0.0
                        header['CD2_2'] = header['CDELT2']

                    # Duplicate the mono image to create a 3-channel image if it’s mono
                    if self.is_mono:
                        image_data_fits = np.stack([image_to_save[:, :, 0]] * 3, axis=-1)  # Create 3-channel from mono
                        image_data_fits = np.transpose(image_data_fits, (2, 0, 1))  # Reorder to (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)
                    else:
                        image_data_fits = np.transpose(image_to_save, (2, 0, 1))  # RGB images in (channels, height, width)
                        header['NAXIS'] = 3
                        header['NAXIS3'] = 3  # Channels (RGB)

                    hdu = fits.PrimaryHDU(image_data_fits, header=header)
                    hdu.writeto(output_path, overwrite=True)
                    print(f"Saved FITS image with metadata to: {output_path}")

                # Save as TIFF based on bit depth
                elif ext.lower() in ['.tif', '.tiff']:
                    if is_16bit:
                        self.save_tiff(output_path, bit_depth=16)
                    elif is_32bit_float:
                        self.save_tiff(output_path, bit_depth=32)
                    else:
                        self.save_tiff(output_path, bit_depth=8)
                    print(f"Saved TIFF image with {self.bit_depth} bit depth to: {output_path}")

                # Save as PNG
                elif ext.lower() == '.png':
                    # Convert mono images to RGB for PNG format
                    if self.is_mono:
                        image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                        image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)  # Duplicate channel to create RGB
                    else:
                        image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                    Image.fromarray(image_8bit_rgb).save(output_path)
                    print(f"Saved 8-bit PNG image to: {output_path}")

                # Save as XISF with metadata
                elif ext.lower() == '.xisf':
                    XISF.write(output_path, image_to_save, xisf_metadata=self.file_meta)
                    print(f"Saved XISF image with metadata to: {output_path}")

            except Exception as e:
                print(f"Error saving file: {e}")


    def process_batch(self, input_dir, output_dir, file_format, update_status_callback):
        

        xisf_files = glob.glob(f"{input_dir}/*.xisf")
        if not xisf_files:
            QMessageBox.warning(self, "Error", "No XISF files found in the input directory.")
            update_status_callback("")
            return

        for i, xisf_file in enumerate(xisf_files, start=1):
            try:
                # Update progress
                update_status_callback(f"Processing file {i}/{len(xisf_files)}: {Path(xisf_file).name}")

                # Load the XISF file
                xisf = XISF(xisf_file)
                im_data = xisf.read_image(0)

                # Set metadata
                file_meta = xisf.get_file_metadata()
                image_meta = xisf.get_images_metadata()[0]
                is_mono = im_data.shape[2] == 1 if len(im_data.shape) == 3 else True

                # Determine output file path
                base_name = Path(xisf_file).stem
                output_file = Path(output_dir) / f"{base_name}{file_format}"

                # Save the file using save_direct
                self.save_direct(output_file, im_data, file_meta, image_meta, is_mono)

            except Exception as e:
                update_status_callback(f"Error processing file {Path(xisf_file).name}: {e}")
                continue  # Skip to the next file

        update_status_callback("Batch Processing Complete!")

    def save_direct(self, output_path, image_to_save, file_meta, image_meta, is_mono):
        """
        Save an image directly to the specified path with the given metadata.
        This function does not prompt the user and is suitable for batch processing.
        """
        _, ext = os.path.splitext(output_path)

        # Determine bit depth and color mode
        is_32bit_float = image_to_save.dtype == np.float32
        is_16bit = image_to_save.dtype == np.uint16
        is_8bit = image_to_save.dtype == np.uint8

        try:
            # Save as FITS file with metadata
            if ext.lower() in ['.fits', '.fit']:
                header = fits.Header()
                crval1, crval2 = None, None

                # Populate FITS header with FITS keywords and WCS keywords
                wcs_keywords = [
                    "CTYPE1", "CTYPE2", "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", 
                    "CDELT1", "CDELT2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"
                ]

                if 'FITSKeywords' in image_meta:
                    for keyword, values in image_meta['FITSKeywords'].items():
                        for entry in values:
                            if 'value' in entry:
                                value = entry['value']
                                # Convert only numerical values to float
                                if keyword in wcs_keywords and isinstance(value, (int, float)):
                                    value = float(value)
                                header[keyword] = value

                # Add default WCS information if missing
                if 'CTYPE1' not in header:
                    header['CTYPE1'] = 'RA---TAN'
                if 'CTYPE2' not in header:
                    header['CTYPE2'] = 'DEC--TAN'

                # Add the -SIP suffix for SIP coefficients
                if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
                    header['CTYPE1'] = 'RA---TAN-SIP'
                    header['CTYPE2'] = 'DEC--TAN-SIP'

                # Set default reference pixel if missing
                if 'CRPIX1' not in header:
                    header['CRPIX1'] = image_to_save.shape[1] / 2
                if 'CRPIX2' not in header:
                    header['CRPIX2'] = image_to_save.shape[0] / 2

                # Add CRVAL1 and CRVAL2 if available
                if 'RA' in image_meta.get('FITSKeywords', {}):
                    crval1 = float(image_meta['FITSKeywords']['RA'][0]['value'])
                if 'DEC' in image_meta.get('FITSKeywords', {}):
                    crval2 = float(image_meta['FITSKeywords']['DEC'][0]['value'])

                if crval1 is not None and crval2 is not None:
                    header['CRVAL1'] = crval1
                    header['CRVAL2'] = crval2

                # Add CD matrix if available
                if 'XISFProperties' in image_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in image_meta['XISFProperties']:
                    linear_transform = image_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                    header['CD1_1'] = linear_transform[0][0]
                    header['CD1_2'] = linear_transform[0][1]
                    header['CD2_1'] = linear_transform[1][0]
                    header['CD2_2'] = linear_transform[1][1]
                else:
                    header['CD1_1'] = header['CDELT1'] if 'CDELT1' in header else 0.0
                    header['CD1_2'] = 0.0
                    header['CD2_1'] = 0.0
                    header['CD2_2'] = header['CDELT2'] if 'CDELT2' in header else 0.0

                # Duplicate mono image to create 3-channel if necessary
                if is_mono:
                    image_data_fits = image_to_save[:, :, 0] if len(image_to_save.shape) == 3 else image_to_save
                    header['NAXIS'] = 2  # Mono images are 2-dimensional
                else:
                    image_data_fits = np.transpose(image_to_save, (2, 0, 1))
                    header['NAXIS'] = 3
                    header['NAXIS3'] = 3

                hdu = fits.PrimaryHDU(image_data_fits, header=header)
                hdu.writeto(output_path, overwrite=True)
                print(f"Saved FITS image to: {output_path}")


            # Save as TIFF
            elif ext.lower() in ['.tif', '.tiff']:
                if is_16bit:
                    tiff.imwrite(output_path, (image_to_save * 65535).astype(np.uint16))
                elif is_32bit_float:
                    tiff.imwrite(output_path, image_to_save.astype(np.float32))
                else:
                    tiff.imwrite(output_path, (image_to_save * 255).astype(np.uint8))
                print(f"Saved TIFF image to: {output_path}")

            # Save as PNG
            elif ext.lower() == '.png':
                if is_mono:
                    image_8bit = (image_to_save[:, :, 0] * 255).astype(np.uint8) if not is_8bit else image_to_save[:, :, 0]
                    image_8bit_rgb = np.stack([image_8bit] * 3, axis=-1)
                else:
                    image_8bit_rgb = (image_to_save * 255).astype(np.uint8) if not is_8bit else image_to_save
                Image.fromarray(image_8bit_rgb).save(output_path)
                print(f"Saved PNG image to: {output_path}")

            # Save as XISF
            elif ext.lower() == '.xisf':
                XISF.write(output_path, image_to_save, xisf_metadata=file_meta)
                print(f"Saved XISF image to: {output_path}")

            else:
                print(f"Unsupported file format: {ext}")

        except Exception as e:
            print(f"Error saving file {output_path}: {e}")


    def save_tiff(self, output_path, bit_depth):
        if bit_depth == 16:
            if self.is_mono:
                tiff.imwrite(output_path, (self.image_data[:, :, 0] * 65535).astype(np.uint16))
            else:
                tiff.imwrite(output_path, (self.image_data * 65535).astype(np.uint16))
        elif bit_depth == 32:
            if self.is_mono:
                tiff.imwrite(output_path, self.image_data[:, :, 0].astype(np.float32))
            else:
                tiff.imwrite(output_path, self.image_data.astype(np.float32))
        else:  # 8-bit
            image_8bit = (self.image_data * 255).astype(np.uint8)
            if self.is_mono:
                tiff.imwrite(output_path, image_8bit[:, :, 0])
            else:
                tiff.imwrite(output_path, image_8bit)

    def save_metadata(self):
        if not self.file_meta and not self.image_meta:
            QMessageBox.warning(self, "Warning", "No metadata to save.")
            return
        file_path, _ = QFileDialog.getSaveFileName(self, "Save Metadata", "", "CSV Files (*.csv);;All Files (*)")
        if file_path:
            try:
                # Flatten metadata function
                def flatten_metadata(data, parent_key=''):
                    items = []
                    for key, value in data.items():
                        new_key = f"{parent_key}.{key}" if parent_key else key
                        if isinstance(value, dict):
                            items.extend(flatten_metadata(value, new_key).items())
                        elif isinstance(value, list):
                            for i, list_item in enumerate(value):
                                list_key = f"{new_key}_{i}"
                                items.extend(flatten_metadata({list_key: list_item}).items())
                        else:
                            items.append((new_key, value if value is not None else ''))  # Replace None with an empty string
                    return dict(items)

                # Flatten both file_meta and image_meta
                flattened_file_meta = flatten_metadata(self.file_meta) if self.file_meta else {}
                flattened_image_meta = flatten_metadata(self.image_meta) if self.image_meta else {}

                # Combine both metadata into one dictionary for CSV
                combined_meta = {**flattened_file_meta, **flattened_image_meta}

                # Write to CSV
                with open(file_path, mode='w', newline='', encoding='utf-8') as file:
                    writer = csv.writer(file)
                    writer.writerow(["Key", "Value"])  # Header row
                    for key, value in combined_meta.items():
                        writer.writerow([key, value])

                QMessageBox.information(self, "Success", f"Metadata saved to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to save metadata: {e}")       

class BatchProcessDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Batch Process")
        self.setMinimumWidth(400)

        layout = QVBoxLayout()

        # Input directory
        self.input_dir_label = QLabel("Input Directory:")
        self.input_dir_button = QPushButton("Select Input Directory")
        self.input_dir_button.clicked.connect(self.select_input_directory)
        self.input_dir = QLineEdit()
        self.input_dir.setReadOnly(True)

        layout.addWidget(self.input_dir_label)
        layout.addWidget(self.input_dir)
        layout.addWidget(self.input_dir_button)

        # Output directory
        self.output_dir_label = QLabel("Output Directory:")
        self.output_dir_button = QPushButton("Select Output Directory")
        self.output_dir_button.clicked.connect(self.select_output_directory)
        self.output_dir = QLineEdit()
        self.output_dir.setReadOnly(True)

        layout.addWidget(self.output_dir_label)
        layout.addWidget(self.output_dir)
        layout.addWidget(self.output_dir_button)

        # File format
        self.format_label = QLabel("Select Output Format:")
        self.format_combo = QComboBox()
        self.format_combo.addItems([".png", ".fit", ".fits", ".tif", ".tiff"])

        layout.addWidget(self.format_label)
        layout.addWidget(self.format_combo)

        # Start Batch Processing button
        self.start_button = QPushButton("Start Batch Processing")
        self.start_button.clicked.connect(self.start_batch_processing)
        layout.addWidget(self.start_button)

        # Status label
        self.status_label = QLabel("")
        layout.addWidget(self.status_label)

        self.setLayout(layout)

    def select_input_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Input Directory")
        if directory:
            self.input_dir.setText(directory)

    def select_output_directory(self):
        directory = QFileDialog.getExistingDirectory(self, "Select Output Directory")
        if directory:
            self.output_dir.setText(directory)

    def start_batch_processing(self):
        input_dir = self.input_dir.text()
        output_dir = self.output_dir.text()
        file_format = self.format_combo.currentText()

        if not input_dir or not output_dir:
            QMessageBox.warning(self, "Error", "Please select both input and output directories.")
            return

        self.status_label.setText("Initializing batch processing...")
        QApplication.processEvents()  # Ensures UI updates immediately

        # Call the parent function to process files with progress updates
        self.parent().process_batch(input_dir, output_dir, file_format, self.update_status)

        self.status_label.setText("Batch Processing Complete!")

    def update_status(self, message):
        self.status_label.setText(message)
        QApplication.processEvents()  # Ensures UI updates immediately

class MetricsPanel(QWidget):
    """2×2 grid with clickable dots and draggable thresholds."""
    pointClicked = pyqtSignal(int, int)
    thresholdChanged = pyqtSignal(int, float)

    def __init__(self, parent=None):
        super().__init__(parent)
        layout = QVBoxLayout(self)
        grid = QGridLayout()
        layout.addLayout(grid)

        # caching slots
        self._orig_images = None       # last list passed
        self.metrics_data = None       # list of 4 numpy arrays
        self.flags = None              # list of bools
        self._threshold_initialized = [False]*4
        self._open_previews = []

        self.plots, self.scats, self.lines = [], [], []
        titles = ["FWHM (px)", "Eccentricity", "Background", "Star Count"]
        for idx, title in enumerate(titles):
            pw = pg.PlotWidget()
            pw.setTitle(title)
            pw.showGrid(x=True, y=True, alpha=0.3)
            pw.getPlotItem().getViewBox().setBackgroundColor(
                self.palette().color(self.backgroundRole())
            )

            scat = pg.ScatterPlotItem(pen=pg.mkPen(None),
                                      brush=pg.mkBrush(100,100,255,200),
                                      size=8)
            scat.sigClicked.connect(lambda plot, pts, m=idx: self._on_point_click(m, pts))
            pw.addItem(scat)

            line = pg.InfiniteLine(pos=0, angle=0, movable=True,
                                   pen=pg.mkPen('r', width=2))
            line.sigPositionChangeFinished.connect(
                lambda ln, m=idx: self._on_line_move(m, ln))
            pw.addItem(line)

            grid.addWidget(pw, idx//2, idx%2)
            self.plots.append(pw)
            self.scats.append(scat)
            self.lines.append(line)

    @staticmethod
    def _compute_one(i_entry):
        """
        Worker: run SEP on one image entry.
        Returns (idx, fwhm, ecc, orig_back, star_count).
        If SEP overflows its internal pixel buffer, we catch it and
        return sentinel “bad” values so the frame will be flagged.
        """
        idx, entry = i_entry

        # rebuild normalized mono data
        img = entry['image_data']
        if img.dtype == np.uint8:
            data = img.astype(np.float32) / 255.0
        elif img.dtype == np.uint16:
            data = img.astype(np.float32) / 65535.0
        else:
            data = np.asarray(img, dtype=np.float32)
        if data.ndim == 3:
            data = data.mean(axis=2)

        # detection parameters
        thresh   = 7.0    # σ threshold
        min_area = 16     # at least a 4×4 blob

        try:
            bkg = sep.Background(data)
            back, gb, gr = bkg.back(), bkg.globalback, bkg.globalrms

            cat = sep.extract(
                data - back,
                thresh,
                err=gr,
                minarea=min_area,
                clean=True,
                deblend_nthresh=32
            )

            if len(cat) > 0:
                # σ = geometric mean of the two RMS axes
                sig      = np.sqrt(cat['a'] * cat['b'])
                fwhm     = np.nanmedian(2.3548 * sig)

                # true eccentricity e = sqrt(1 - (b/a)^2)
                ratios   = np.clip(cat['b'] / cat['a'], 0, 1)
                ecc_vals = np.sqrt(1.0 - ratios**2)
                ecc      = np.nanmedian(ecc_vals)

                star_cnt = len(cat)
            else:
                fwhm, ecc, star_cnt = np.nan, np.nan, 0

        except Exception as e:
            # catch SEP overflow (or any other) and mark as “bad” frame
            # you can even check `if "internal pixel buffer full" in str(e):`
            fwhm, ecc, star_cnt = 10.0, 1.0, 0

        orig_back = entry.get('orig_background', np.nan)
        return idx, fwhm, ecc, orig_back, star_cnt


    def compute_all_metrics(self, loaded_images):
        # ─── HEADS-UP DIALOG ───────────────────────────────────────────
        settings = QSettings()
        # default to True (i.e. show warning) if the key isn't there yet
        show = settings.value("metrics/showWarning", True, type=bool)
        if show:
            msg = QMessageBox(self)
            msg.setWindowTitle("Heads-up")
            msg.setText(
                "This is going to use ALL your CPU cores and the UI may lock up until it finishes.\n\n"
                "Continue?"
            )
            msg.setStandardButtons(QMessageBox.StandardButton.Yes |
                                QMessageBox.StandardButton.No)
            cb = QCheckBox("Don't show again", msg)
            msg.setCheckBox(cb)
            answer = msg.exec()
            if answer != QMessageBox.StandardButton.Yes:
                return
            if cb.isChecked():
                settings.setValue("metrics/showWarning", False)  
        """Run SEP over the full list in parallel using threads and cache results."""
        n = len(loaded_images)
        # pre-allocate result arrays
        m0 = np.full(n, np.nan)
        m1 = np.full(n, np.nan)
        m2 = np.full(n, np.nan)
        m3 = np.full(n, np.nan)
        flags = [e.get('flagged', False) for e in loaded_images]

        # set up a cancelable progress dialog
        prog = QProgressDialog("Computing frame metrics…", "Cancel", 0, n, self)
        prog.setWindowModality(Qt.WindowModality.WindowModal)
        prog.setMinimumDuration(0)
        prog.show()
        QApplication.processEvents()

        workers = min((os.cpu_count() or 1), 60)
        tasks   = [(i, loaded_images[i]) for i in range(n)]
        with ProcessPoolExecutor(max_workers=workers) as exe:
            futures = {exe.submit(self._compute_one, t): t[0] for t in tasks}
            done = 0
            for fut in as_completed(futures):
                if prog.wasCanceled():
                    break
                idx, fwhm, ecc, orig_back, star_cnt = fut.result()
                m0[idx], m1[idx], m2[idx], m3[idx] = fwhm, ecc, orig_back, star_cnt
                done += 1
                prog.setValue(done)
                QApplication.processEvents()

        prog.close()

        # stash results
        self._orig_images = loaded_images
        self.metrics_data  = [m0, m1, m2, m3]
        self.flags         = flags
        self._threshold_initialized = [False]*4

    def plot(self, loaded_images, indices=None):
        """
        Plot metrics for loaded_images.
        If indices is given (list/array of ints), only those frames are shown.
        """
        # empty clear
        if not loaded_images:
            self.metrics_data = None
            for pw, scat, line in zip(self.plots, self.scats, self.lines):
                scat.setData(x=[], y=[])
                line.setPos(0)
                pw.getPlotItem().getViewBox().update()
                pw.repaint()
            return

        # compute & cache on first call or new image list
        if self._orig_images is not loaded_images or self.metrics_data is None:
            self.compute_all_metrics(loaded_images)

        # default to all indices
        if indices is None:
            indices = np.arange(len(loaded_images), dtype=int)

        # store for later recoloring
        self._cur_indices = np.array(indices, dtype=int)

        x = np.arange(len(indices))

        for m, (pw, scat, line) in enumerate(zip(self.plots, self.scats, self.lines)):
            arr = self.metrics_data[m]
            y   = arr[indices]

            brushes = [
                pg.mkBrush(255,0,0,200) if self.flags[idx] else pg.mkBrush(100,100,255,200)
                for idx in indices
            ]
            scat.setData(x=x, y=y, brush=brushes, pen=pg.mkPen(None), size=8)

            # initialize threshold line once
            if not self._threshold_initialized[m]:
                mx, mn = np.nanmax(y), np.nanmin(y)
                span   = mx-mn if mx!=mn else 1.0
                line.setPos((mx+0.05*span) if m<3 else 0)
                self._threshold_initialized[m] = True

    def _refresh_scatter_colors(self):
        """Re-color your dots without re-computing SEP, even in subset mode."""
        # For each scatter, its x‐values are local positions into self._cur_indices,
        # so we must map them back to the original-frame index before pulling flags.
        for scat in self.scats:
            x, y = scat.getData()[:2]
            brushes = []
            for xi in x:
                li = int(xi)                    # local index in this subset
                gi = self._cur_indices[li]     # global frame index
                if self.flags[gi]:
                    brushes.append(pg.mkBrush(255,0,0,200))
                else:
                    brushes.append(pg.mkBrush(100,100,255,200))
            scat.setData(x=x, y=y, brush=brushes)

    def _on_point_click(self, metric_idx, points):
        for pt in points:
            frame_idx = int(round(pt.pos().x()))
            mods = QApplication.keyboardModifiers()
            if mods & Qt.KeyboardModifier.ShiftModifier:
                entry  = self._orig_images[frame_idx]
                img    = entry['image_data']
                is_mono= entry.get('is_mono', False)
                dlg = ImagePreviewDialog(img, is_mono)
                dlg.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  
                dlg.show()
                self._open_previews.append(dlg)  # <-- hold a reference

                # optionally prune closed ones:
                dlg.destroyed.connect(lambda _=None, d=dlg: 
                      self._open_previews.remove(d)
                      if d in self._open_previews else None)
            else:
                self.pointClicked.emit(metric_idx, frame_idx)

    def _on_line_move(self, metric_idx, line):
        self.thresholdChanged.emit(metric_idx, line.value())

class MetricsWindow(QWidget):
    def __init__(self, parent=None):
        super().__init__(parent, Qt.WindowType.Window)
        self._thresholds_per_group: dict[str, List[float|None]] = {}
        self.setWindowTitle("Frame Metrics")
        self.resize(800, 600)

        vbox = QVBoxLayout(self)

        # ← **new** instructions label
        instr = QLabel(
            "Instructions:\n"
            " • Use the filter dropdown to restrict by FILTER.\n"
            " • Click a dot to flag/unflag a frame.\n"
            " • Shift-click a dot to preview the image.\n"
            " • Drag the red lines to set thresholds.",
            self
        )
        instr.setWordWrap(True)
        instr.setStyleSheet("color: #ccc; font-size: 12px;")
        vbox.addWidget(instr)

        # → filter selector
        self.group_combo = QComboBox(self)
        self.group_combo.addItem("All")
        self.group_combo.currentTextChanged.connect(self._on_group_change)
        vbox.addWidget(self.group_combo)

        # → the 2×2 metrics panel
        self.metrics_panel = MetricsPanel(self)
        vbox.addWidget(self.metrics_panel)

        # keep status up‐to‐date when things happen
        self.metrics_panel.thresholdChanged.connect(self._update_status)
        self.metrics_panel.pointClicked   .connect(self._update_status)

        # ← status label
        self.status_label = QLabel("", self)
        vbox.addWidget(self.status_label)

        # internal storage
        self._all_images = []
        self._current_indices: Optional[List[int]] = None


    def _update_status(self, *args):
        """Recompute and show: Flagged Items X / Y (Z%)."""
        flags = getattr(self.metrics_panel, 'flags', []) or []
        # which subset are we in?
        idxs = self._current_indices if self._current_indices is not None else range(len(flags))
        total = len(idxs)
        flagged = sum(flags[i] for i in idxs)
        pct = (flagged/total*100) if total else 0.0
        self.status_label.setText(f"Flagged Items {flagged}/{total}  ({pct:.1f}%)")

    def set_images(self, loaded_images):
        """Initialize with a brand-new set of images."""
        self._all_images = loaded_images

        # ─── rebuild the combo-list of FILTER groups ─────────────
        self.group_combo.blockSignals(True)
        self.group_combo.clear()
        self.group_combo.addItem("All")
        seen = set()
        for entry in loaded_images:
            filt = entry.get('header', {}).get('FILTER', 'Unknown')
            if filt not in seen:
                seen.add(filt)
                self.group_combo.addItem(filt)
        self.group_combo.blockSignals(False)

        # ─── reset & seed per-group thresholds ────────────────────
        self._thresholds_per_group.clear()
        self._thresholds_per_group["All"] = [None]*4
        for entry in loaded_images:
            filt = entry.get('header', {}).get('FILTER', 'Unknown')
            if filt not in self._thresholds_per_group:
                self._thresholds_per_group[filt] = [None]*4

        # ─── compute & cache all metrics once ────────────────────
        self.metrics_panel.compute_all_metrics(self._all_images)

        # ─── show “All” by default and plot ───────────────────────
        self._current_indices = None
        self._apply_thresholds("All")
        self.metrics_panel.plot(self._all_images, indices=None)

        # ─── update the flagged-items status label ───────────────
        self._update_status()


    def _on_group_change(self, name: str):
        """Re-plot for the selected FILTER group."""
        if name == "All":
            self._current_indices = None
        else:
            # collect indices matching this filter
            self._current_indices = [
                i for i, e in enumerate(self._all_images)
                if e.get('header', {}).get('FILTER', 'Unknown') == name
            ]

        # apply saved thresholds for this group
        self._apply_thresholds(name)
        # re-draw
        self.metrics_panel.plot(self._all_images, indices=self._current_indices)

    def _on_panel_threshold_change(self, metric_idx: int, new_val: float):
        """User just dragged a threshold line."""
        grp = self.group_combo.currentText()
        # save it for this group
        self._thresholds_per_group[grp][metric_idx] = new_val

        # (if you also want immediate re-flagging in the tree, keep your BlinkTab logic hooked here)

    def _apply_thresholds(self, group_name: str):
        """Restore the four InfiniteLine positions for a given group."""
        saved = self._thresholds_per_group.get(group_name, [None]*4)
        for idx, line in enumerate(self.metrics_panel.lines):
            if saved[idx] is not None:
                line.setPos(saved[idx])
            # if saved[idx] is None, we leave it so that
            # the panel’s own auto-init can run on next plot()

    def update_metrics(self, loaded_images):
        """
        Called whenever BlinkTab.loadImages or clearImages fires.
        If it's a new list, re-init; otherwise just re-plot current group.
        """
        if loaded_images is not self._all_images:
            self.set_images(loaded_images)
        else:
            # same list, just redraw current selection
            self._on_group_change(self.group_combo.currentText())

class BlinkTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()

        self.image_paths = []  # Store the file paths of loaded images
        self.loaded_images = []  # Store the image objects (as numpy arrays)
        self.image_labels = []  # Store corresponding file names for the TreeWidget
        self.image_manager = image_manager  # Reference to ImageManager
        self.metrics_window: Optional[MetricsWindow] = None
        self.zoom_level = 0.5  # Default zoom level
        self.dragging = False  # Track whether the mouse is dragging
        self.last_mouse_pos = None  # Store the last mouse position
        self.thresholds_by_group: dict[str, List[float|None]] = {}
        self.aggressive_stretch_enabled = False
        self.current_sigma = 3.7
        self.current_pixmap = None
        self._last_preview_name = None
        self._pending_preview_timer = QTimer(self)
        self._pending_preview_timer.setSingleShot(True)
        self._pending_preview_timer.setInterval(40)  # 40–80ms is plenty
        self._pending_preview_item = None
        self._pending_preview_timer.timeout.connect(self._do_preview_update)
        self.initUI()
        self.init_shortcuts()

    def initUI(self):
        main_layout = QHBoxLayout(self)


        # Create a QSplitter to allow resizing between left and right panels
        splitter = QSplitter(Qt.Orientation.Horizontal, self)

        # Left Column for the file loading and TreeView
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)

        # --------------------
        # Instruction Label
        # --------------------
        instruction_text = "Press 'F' to flag/unflag an image.\nRight-click on an image for more options."
        self.instruction_label = QLabel(instruction_text, self)
        self.instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.instruction_label.setWordWrap(True)
        self.instruction_label.setStyleSheet("font-weight: bold;")  # Optional: Make the text bold for emphasis

        self.instruction_label.setStyleSheet(f"""
            QLabel {{
                font-weight: bold;
            }}
        """)

        # Add the instruction label to the left layout at the top
        left_layout.addWidget(self.instruction_label)

        # Horizontal layout for "Select Images" and "Select Directory" buttons
        button_layout = QHBoxLayout()

        # "Select Images" Button
        self.fileButton = QPushButton('Select Images', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        button_layout.addWidget(self.fileButton)

        # "Select Directory" Button
        self.dirButton = QPushButton('Select Directory', self)
        self.dirButton.clicked.connect(self.openDirectoryDialog)
        button_layout.addWidget(self.dirButton)

        self.addButton = QPushButton("Add Additional", self)
        self.addButton.clicked.connect(self.addAdditionalImages)
        button_layout.addWidget(self.addButton)

        left_layout.addLayout(button_layout)

        self.metrics_button = QPushButton("Show Metrics", self)
        self.metrics_button.clicked.connect(self.show_metrics)
        left_layout.addWidget(self.metrics_button)



        # Playback controls (left arrow, play, pause, right arrow)
        playback_controls_layout = QHBoxLayout()

        # Left Arrow Button
        self.left_arrow_button = QPushButton(self)
        self.left_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        self.left_arrow_button.clicked.connect(self.previous_item)
        playback_controls_layout.addWidget(self.left_arrow_button)

        # Play Button
        self.play_button = QPushButton(self)
        self.play_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPlay))
        self.play_button.clicked.connect(self.start_playback)
        playback_controls_layout.addWidget(self.play_button)

        # Pause Button
        self.pause_button = QPushButton(self)
        self.pause_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_MediaPause))
        self.pause_button.clicked.connect(self.stop_playback)
        playback_controls_layout.addWidget(self.pause_button)

        # Right Arrow Button
        self.right_arrow_button = QPushButton(self)
        self.right_arrow_button.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowRight))
        self.right_arrow_button.clicked.connect(self.next_item)
        playback_controls_layout.addWidget(self.right_arrow_button)

        left_layout.addLayout(playback_controls_layout)

        # Tree view for file names
        self.fileTree = QTreeWidget(self)
        self.fileTree.setColumnCount(1)
        self.fileTree.setHeaderLabels(["Image Files"])
        self.fileTree.setSelectionMode(QAbstractItemView.SelectionMode.ExtendedSelection)  # Allow multiple selections
        #self.fileTree.itemClicked.connect(self.on_item_clicked)
        self.fileTree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.fileTree.customContextMenuRequested.connect(self.on_right_click)
        self.fileTree.currentItemChanged.connect(self._on_current_item_changed_safe)
        self.fileTree.setStyleSheet("""
                QTreeWidget::item:selected {
                    background-color: #3a75c4;  /* Blue background for selected items */
                    color: #ffffff;  /* White text color */
                }
            """)
        left_layout.addWidget(self.fileTree)

        # "Clear Flags" Button
        self.clearFlagsButton = QPushButton('Clear Flags', self)
        self.clearFlagsButton.clicked.connect(self.clearFlags)
        left_layout.addWidget(self.clearFlagsButton)

        # "Clear Images" Button
        self.clearButton = QPushButton('Clear Images', self)
        self.clearButton.clicked.connect(self.clearImages)
        left_layout.addWidget(self.clearButton)

        # Add progress bar
        self.progress_bar = QProgressBar(self)
        self.progress_bar.setRange(0, 100)
        left_layout.addWidget(self.progress_bar)

        # Add loading message label
        self.loading_label = QLabel("Loading images...", self)
        left_layout.addWidget(self.loading_label)

        # Set the layout for the left widget
        left_widget.setLayout(left_layout)

        # Add the left widget to the splitter
        splitter.addWidget(left_widget)

        # Right Column for Image Preview
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls: Add Zoom In and Zoom Out buttons
        zoom_controls_layout = QHBoxLayout()

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        zoom_controls_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_out_button)

        self.fit_to_preview_button = QPushButton("Fit to Preview")
        self.fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_controls_layout.addWidget(self.fit_to_preview_button)

        self.aggressive_button = QPushButton("Aggressive Stretch", self)
        self.aggressive_button.setCheckable(True)
        self.aggressive_button.clicked.connect(self.toggle_aggressive)
        zoom_controls_layout.addWidget(self.aggressive_button)

        right_layout.addLayout(zoom_controls_layout)

        # Scroll area for the preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scroll_area.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.preview_label = QLabel(self)
        self.preview_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.preview_label)

        right_layout.addWidget(self.scroll_area)

        # Set the layout for the right widget
        right_widget.setLayout(right_layout)

        # Add the right widget to the splitter
        splitter.addWidget(right_widget)

        # Set initial splitter sizes
        splitter.setSizes([300, 700])  # Adjust proportions as needed

        # Add the splitter to the main layout
        main_layout.addWidget(splitter)

        # Set the main layout for the widget
        self.setLayout(main_layout)

        # Initialize playback timer
        self.playback_timer = QTimer(self)
        self.playback_timer.setInterval(200)  # Set the playback interval to 500ms
        self.playback_timer.timeout.connect(self.next_item)

        # Connect the selection change signal to update the preview when arrow keys are used
        self.fileTree.selectionModel().selectionChanged.connect(self.on_selection_changed)
        self.setFocusPolicy(Qt.FocusPolicy.StrongFocus)



    def _on_current_item_changed_safe(self, current, previous):
        if not current:
            return

        # If a mouse button is currently pressed, don't scroll now—defer a bit
        if QApplication.mouseButtons() != Qt.MouseButton.NoButton:
            QTimer.singleShot(120, lambda: self._center_if_no_mouse(current))
            return

        # Let selection settle, then gently ensure it's visible (no jump)
        QTimer.singleShot(0, lambda: self.fileTree.scrollToItem(
            current, QAbstractItemView.ScrollHint.EnsureVisible
        ))

    def _center_if_no_mouse(self, item):
        # Only center if the mouse is up AND the item is still current
        if QApplication.mouseButtons() == Qt.MouseButton.NoButton and item is self.fileTree.currentItem():
            self.fileTree.scrollToItem(item, QAbstractItemView.ScrollHint.EnsureVisible)

    def toggle_aggressive(self):
        self.aggressive_stretch_enabled = self.aggressive_button.isChecked()
        # force a redisplay of the current image
        cur = self.fileTree.currentItem()
        if cur:
            self.on_item_clicked(cur, 0)

    def clearFlags(self):
        """Clear all flagged states, update tree icons & metrics."""
        # 1) Reset internal flag state
        for entry in self.loaded_images:
            entry['flagged'] = False

        # 2) Update tree widget: strip any "⚠️ " prefix and reset color
        normal = self.fileTree.palette().color(QPalette.ColorRole.WindowText)
        for item in self.get_all_leaf_items():
            name = item.text(0).lstrip("⚠️ ")
            item.setText(0, name)
            item.setForeground(0, QBrush(normal))

        # 3) If metrics window is open, refresh its dots & status
        if self.metrics_window:
            panel = self.metrics_window.metrics_panel
            panel.flags = [False] * len(self.loaded_images)
            panel._refresh_scatter_colors()
            # update the "Flagged Items X/Y" label
            self.metrics_window._update_status()

    def addAdditionalImages(self):
        """Let the user pick more images to append to the blink list."""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Add Additional Images",
            "",
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )
        # filter out duplicates
        new_paths = [p for p in file_paths if p not in self.image_paths]
        if not new_paths:
            QMessageBox.information(self, "No New Images", "No new images selected or already loaded.")
            return
        self._appendImages(new_paths)

    def _appendImages(self, file_paths):
        # decide dtype exactly as in loadImages
        mem = psutil.virtual_memory()
        avail = mem.available / (1024**3)
        if avail <= 16:
            target_dtype = np.uint8
        elif avail <= 32:
            target_dtype = np.uint16
        else:
            target_dtype = np.float32

        total_new = len(file_paths)
        self.progress_bar.setRange(0, total_new)
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        # load one-by-one (or you could parallelize as you like)
        for i, path in enumerate(sorted(file_paths, key=lambda p: self._natural_key(os.path.basename(p)))):
            try:
                _, hdr, bit_depth, is_mono, stored, back = self._load_one_image(path, target_dtype)
            except Exception as e:
                print(f"Failed to load {path}: {e}")
                continue

            # append to our master lists
            self.image_paths.append(path)
            self.loaded_images.append({
                'file_path':      path,
                'image_data':     stored,
                'header':         hdr or {},
                'bit_depth':      bit_depth,
                'is_mono':        is_mono,
                'flagged':        False,
                'orig_background': back
            })

            # update progress bar
            self.progress_bar.setValue(i+1)
            QApplication.processEvents()

            # and add it into the tree under the correct object/filter/exp
            self.add_item_to_tree(path)

        # update status
        self.loading_label.setText(f"Loaded {len(self.loaded_images)} images.")
        if self.metrics_window and self.metrics_window.isVisible():
            self.metrics_window.update_metrics(self.loaded_images)

    def show_metrics(self):
        if self.metrics_window is None:
            self.metrics_window = MetricsWindow()
            mp = self.metrics_window.metrics_panel
            mp.pointClicked.connect(self.on_metrics_point)
            mp.thresholdChanged.connect(self.on_threshold_change)

        # ← here ←
        self.metrics_window.set_images(self.loaded_images)
        panel = self.metrics_window.metrics_panel
        self.thresholds_by_group["All"] = [ line.value() for line in panel.lines ]
        self.metrics_window.show()
        self.metrics_window.raise_()

    def on_metrics_point(self, metric_idx, frame_idx):
        # Toggle the flagged state on the image…
        item = self.get_tree_item_for_index(frame_idx)
        if not item:
            return
        self._toggle_flag_on_item(item)

        # Now update the panel’s flags and refresh
        panel = self.metrics_window.metrics_panel
        panel.flags = [entry['flagged'] for entry in self.loaded_images]
        panel._refresh_scatter_colors()
        self.metrics_window._update_status()


    def on_threshold_change(self, metric_idx, threshold):
        panel = self.metrics_window.metrics_panel
        if panel.metrics_data is None:
            return

        # figure out which FILTER group we're in
        group = self.metrics_window.group_combo.currentText()
        # ensure we have a 4-slot list for this group
        thr_list = self.thresholds_by_group.setdefault(group, [None]*4)
        # store the new threshold for this metric
        thr_list[metric_idx] = threshold

        # build the list of indices to re-evaluate
        if group == "All":
            indices = range(len(self.loaded_images))
        else:
            indices = [
                i for i, e in enumerate(self.loaded_images)
                if e.get('header', {}).get('FILTER','Unknown') == group
            ]

        # re‐flag only those frames in this group, OR across all 4 metrics
        for i in indices:
            entry = self.loaded_images[i]
            flagged = False
            for m, thr in enumerate(thr_list):
                if thr is None:
                    continue
                val = panel.metrics_data[m][i]
                if np.isnan(val):
                    continue
                if (m < 3 and val > thr) or (m == 3 and val < thr):
                    flagged = True
                    break
            entry['flagged'] = flagged

            # update the tree icon
            item = self.get_tree_item_for_index(i)
            if item:
                RED = Qt.GlobalColor.red
                normal = self.fileTree.palette().color(QPalette.ColorRole.WindowText)
                name = item.text(0).lstrip("⚠️ ")
                if flagged:
                    item.setText(0, f"⚠️ {name}")
                    item.setForeground(0, QBrush(RED))
                else:
                    item.setText(0, name)
                    item.setForeground(0, QBrush(normal))

        # now push the *entire* up-to-date flagged list into the panel
        panel.flags = [e['flagged'] for e in self.loaded_images]
        panel._refresh_scatter_colors()
        self.metrics_window._update_status()



    def get_tree_item_for_index(self, idx):
        target = os.path.basename(self.image_paths[idx])
        for item in self.get_all_leaf_items():
            if item.text(0).lstrip("⚠️ ") == target:
                return item
        return None

    def compute_metric(self, metric_idx, entry):
        """Recompute a single metric for one image.  Use cached orig_background for metric 2."""
        # metric 2 is the pre-stretch background we already computed
        if metric_idx == 2:
            return entry.get('orig_background', np.nan)

        # otherwise rebuild a float32 [0..1] array from whatever dtype we stored
        img = entry['image_data']
        if img.dtype == np.uint8:
            data = img.astype(np.float32)/255.0
        elif img.dtype == np.uint16:
            data = img.astype(np.float32)/65535.0
        else:
            data = np.asarray(img, dtype=np.float32)
        if data.ndim == 3:
            data = data.mean(axis=2)

        # run SEP for the other metrics
        bkg = sep.Background(data)
        back, gr, rr = bkg.back(), bkg.globalback, bkg.globalrms
        cat = sep.extract(data - back, 5.0, err=gr, minarea=9)
        if len(cat)==0:
            return np.nan

        sig = np.sqrt(cat['a']*cat['b'])
        if metric_idx == 0:
            return np.nanmedian(2.3548*sig)
        elif metric_idx == 1:
            return np.nanmedian(1 - (cat['b']/cat['a']))
        else:  # metric_idx == 3 (star count)
            return len(cat)


    def init_shortcuts(self):
        """Initialize keyboard shortcuts."""
        # Create a shortcut for the "F" key to flag images
        flag_shortcut = QShortcut(QKeySequence("F"), self.fileTree)
        flag_shortcut.activated.connect(self.flag_current_image)

    def openDirectoryDialog(self):
        """Allow users to select a directory and load all images within it recursively."""
        directory = QFileDialog.getExistingDirectory(self, "Select Directory", "")
        if directory:
            # Supported image extensions
            supported_extensions = (
                '.png', '.tif', '.tiff', '.fits', '.fit',
                '.xisf', '.cr2', '.nef', '.arw', '.dng',
                '.orf', '.rw2', '.pef'
            )

            # Collect all image file paths recursively
            new_file_paths = []
            for root, _, files in os.walk(directory):
                for file in sorted(files, key=str.lower):  # 🔹 Sort alphabetically (case-insensitive)
                    if file.lower().endswith(supported_extensions):
                        full_path = os.path.join(root, file)
                        if full_path not in self.image_paths:  # Avoid duplicates
                            new_file_paths.append(full_path)

            if new_file_paths:
                self.loadImages(new_file_paths)
            else:
                QMessageBox.information(self, "No Images Found", "No supported image files were found in the selected directory.")


    def clearImages(self):
        """Clear all loaded images and reset the tree view."""
        confirmation = QMessageBox.question(
            self,
            "Clear All Images",
            "Are you sure you want to clear all loaded images?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )
        if confirmation == QMessageBox.StandardButton.Yes:
            self.stop_playback()
            self.image_paths.clear()
            self.loaded_images.clear()
            self.image_labels.clear()
            self.fileTree.clear()
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')
            self.current_pixmap = None
            self.progress_bar.setValue(0)
            self.loading_label.setText("Loading images...")

            # (legacy) if you still have this, you can delete it:
            # self.thresholds = [None, None, None, None]

            # also reset the metrics panel (if it’s open)
            if self.metrics_window is not None:
                mp = self.metrics_window.metrics_panel
                # clear out old data & reset flags / thresholds
                mp.metrics_data = None
                mp._threshold_initialized = [False]*4
                for scat in mp.scats:
                    scat.clear()
                for line in mp.lines:
                    line.setPos(0)

                # clear per‐group threshold storage
                self.metrics_window._thresholds_per_group.clear()

        # finally, tell the MetricsWindow to fully re‐init with no images
        if self.metrics_window is not None:
            self.metrics_window.update_metrics([])


    @staticmethod
    def _load_one_image(file_path: str, target_dtype):
        """Load + pre-process one image & return all metadata."""

        # 1) load
        image, header, bit_depth, is_mono = load_image(file_path)
        if image is None or image.size == 0:
            raise ValueError("Empty image")

        # 2) optional debayer
        if is_mono:
            # adjust this call to match your debayer signature
            image = BlinkTab.debayer_image(image, file_path, header)

        # 3) SEP background on mono float32
        data = np.asarray(image, dtype=np.float32, order='C')
        if data.ndim == 3:
            data = data.mean(axis=2)
        bkg = sep.Background(data)
        global_back = bkg.globalback

        # 4) stretch
        target_med = 0.25
        if image.ndim == 2:
            stretched = stretch_mono_image(image, target_med)
        else:
            stretched = stretch_color_image(image, target_med, linked=False)

        # 5) cast to target_dtype
        clipped = np.clip(stretched, 0.0, 1.0)
        if target_dtype is np.uint8:
            stored = (clipped * 255).astype(np.uint8)
        elif target_dtype is np.uint16:
            stored = (clipped * 65535).astype(np.uint16)
        else:
            stored = clipped.astype(np.float32)

        return file_path, header, bit_depth, is_mono, stored, global_back

    @staticmethod
    def debayer_image(image, file_path, header):
        """Check if image is OSC (One-Shot Color) and debayer if required."""
        if file_path.lower().endswith(('.fits', '.fit')):
            bayer_pattern = header.get('BAYERPAT', None)
            if bayer_pattern:
                image = debayer_fits_fast(image, bayer_pattern)
        elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
            image = debayer_raw_fast(image, bayer_pattern="RGGB")
        return image

    @staticmethod
    def _natural_key(path: str):
        """
        Split a filename into text and integer chunks so that 
        “…_2.fit” sorts before “…_10.fit”.
        """
        name = os.path.basename(path)
        return [int(tok) if tok.isdigit() else tok.lower()
                for tok in re.split(r'(\d+)', name)]

    def loadImages(self, file_paths):
        # 0) early out
        if not file_paths:
            return

        # ---------- NEW: natural sort the list of filenames ----------
        file_paths = sorted(file_paths, key=lambda p: self._natural_key(os.path.basename(p)))

        # 1) pick dtype based on RAM
        mem = psutil.virtual_memory()
        avail = mem.available / (1024**3)
        if avail <= 16:
            target_dtype = np.uint8
        elif avail <= 32:
            target_dtype = np.uint16
        else:
            target_dtype = np.float32

        total = len(file_paths)
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        QApplication.processEvents()

        self.image_paths.clear()
        self.loaded_images.clear()
        self.fileTree.clear()

        # ---------- NEW: Retry-aware parallel load ----------
        MAX_RETRIES = 2
        RETRY_DELAY = 2
        remaining = list(file_paths)
        completed = []
        attempt = 0

        while remaining and attempt <= MAX_RETRIES:
            
            total_cpus = os.cpu_count() or 1
            reserved_cpus = min(4, max(1, int(total_cpus * 0.25)))
            max_workers = max(1, min(total_cpus - reserved_cpus, 60))

            futures = {}
            failed = []

            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                for path in remaining:
                    futures[executor.submit(self._load_one_image, path, target_dtype)] = path

                for fut in as_completed(futures):
                    path = futures[fut]
                    try:
                        result = fut.result()
                        completed.append(result)
                        done = len(completed)
                        self.progress_bar.setValue(int(100 * done / total))
                        QApplication.processEvents()
                    except Exception as e:
                        print(f"[WARN][Attempt {attempt}] Failed to load {path}: {e}")
                        failed.append(path)

            remaining = failed
            attempt += 1
            if remaining:
                print(f"[Retry] {len(remaining)} images will be retried after {RETRY_DELAY}s...")
                time.sleep(RETRY_DELAY)

        if remaining:
            print(f"[FAILURE] These files failed to load after {MAX_RETRIES} retries:")
            for path in remaining:
                print(f"  - {path}")

        # ---------- Unpack completed results ----------
        for path, header, bit_depth, is_mono, stored, back in completed:
            header = header or {}
            self.image_paths.append(path)
            self.loaded_images.append({
                'file_path':      path,
                'image_data':     stored,
                'header':         header,
                'bit_depth':      bit_depth,
                'is_mono':        is_mono,
                'flagged':        False,
                'orig_background': back
            })

        # 3) rebuild object/filter/exposure tree
        grouped = defaultdict(list)
        for entry in self.loaded_images:
            hdr = entry['header']
            obj = hdr.get('OBJECT', 'Unknown')
            filt = hdr.get('FILTER', 'Unknown')
            exp = hdr.get('EXPOSURE', 'Unknown')
            grouped[(obj, filt, exp)].append(entry['file_path'])

        for key, paths in grouped.items():
            paths.sort(key=lambda p: self._natural_key(os.path.basename(p)))
        by_object = defaultdict(lambda: defaultdict(dict))
        for (obj, filt, exp), paths in grouped.items():
            by_object[obj][filt][exp] = paths

        for obj in sorted(by_object, key=lambda o: o.lower()):
            obj_item = QTreeWidgetItem([f"Object: {obj}"])
            self.fileTree.addTopLevelItem(obj_item)
            obj_item.setExpanded(True)

            for filt in sorted(by_object[obj], key=lambda f: f.lower()):
                filt_item = QTreeWidgetItem([f"Filter: {filt}"])
                obj_item.addChild(filt_item)
                filt_item.setExpanded(True)

                for exp in sorted(by_object[obj][filt], key=lambda e: str(e).lower()):
                    exp_item = QTreeWidgetItem([f"Exposure: {exp}"])
                    filt_item.addChild(exp_item)
                    exp_item.setExpanded(True)

                    for p in by_object[obj][filt][exp]:
                        leaf = QTreeWidgetItem([os.path.basename(p)])
                        exp_item.addChild(leaf)

        self.loading_label.setText(f"Loaded {len(self.loaded_images)} images.")
        self.progress_bar.setValue(100)
        if self.metrics_window and self.metrics_window.isVisible():
            self.metrics_window.update_metrics(self.loaded_images)

    def findTopLevelItemByName(self, name):
        """Find a top-level item in the tree by its name."""
        for index in range(self.fileTree.topLevelItemCount()):
            item = self.fileTree.topLevelItem(index)
            if item.text(0) == name:
                return item
        return None

    def findChildItemByName(self, parent, name):
        """Find a child item under a given parent by its name."""
        for index in range(parent.childCount()):
            child = parent.child(index)
            if child.text(0) == name:
                return child
        return None


    def _toggle_flag_on_item(self, item: QTreeWidgetItem):
        """Toggle the flagged state on this tree item and its loaded_images entry."""
        file_name = item.text(0).lstrip("⚠️ ")
        # find the matching image entry
        file_path = next((p for p in self.image_paths if os.path.basename(p) == file_name), None)
        if file_path is None:
            return

        idx = self.image_paths.index(file_path)
        entry = self.loaded_images[idx]
        entry['flagged'] = not entry['flagged']

        # update the tree view
        RED = Qt.GlobalColor.red
        palette = self.fileTree.palette()
        normal_color = palette.color(QPalette.ColorRole.WindowText)

        if entry['flagged']:
            item.setText(0, f"⚠️ {file_name}")
            item.setForeground(0, QBrush(RED))
        else:
            item.setText(0, file_name)
            item.setForeground(0, QBrush(normal_color))

    def flag_current_image(self):
        """Called by the F-key: toggle flag on the currently selected item."""
        item = self.fileTree.currentItem()
        if not item:
            QMessageBox.warning(self, "No Selection", "No image is currently selected to flag.")
            return
        self._toggle_flag_on_item(item)
        self.next_item()  # Move to the next item after flagging


    def on_current_item_changed(self, current, previous):
        """Ensure the selected item is visible by scrolling to it."""
        if current:
            self.fileTree.scrollToItem(current, QAbstractItemView.ScrollHint.PositionAtCenter)

    def previous_item(self):
        """Select the previous item in the TreeWidget."""
        current_item = self.fileTree.currentItem()
        if current_item:
            all_items = self.get_all_leaf_items()
            current_index = all_items.index(current_item)
            if current_index > 0:
                previous_item = all_items[current_index - 1]
            else:
                previous_item = all_items[-1]  # Loop back to the last item
            self.fileTree.setCurrentItem(previous_item)
            #self.on_item_clicked(previous_item, 0)  # Update the preview

    def next_item(self):
        """Select the next item in the TreeWidget, looping back to the first item if at the end."""
        current_item = self.fileTree.currentItem()
        if current_item:
            # Get all leaf items
            all_items = self.get_all_leaf_items()

            # Check if the current item is in the leaf items
            try:
                current_index = all_items.index(current_item)
            except ValueError:
                # If the current item is not a leaf, move to the first leaf item
                print("Current item is not a leaf. Selecting the first leaf item.")
                if all_items:
                    next_item = all_items[0]
                    self.fileTree.setCurrentItem(next_item)
                    self.on_item_clicked(next_item, 0)
                return

            # Select the next leaf item or loop back to the first
            if current_index < len(all_items) - 1:
                next_item = all_items[current_index + 1]
            else:
                next_item = all_items[0]  # Loop back to the first item

            self.fileTree.setCurrentItem(next_item)
            #self.on_item_clicked(next_item, 0)  # Update the preview
        else:
            print("No current item selected.")

    def get_all_leaf_items(self):
        """Get a flat list of all leaf items (actual files) in the TreeWidget."""
        def recurse(parent):
            items = []
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.childCount() == 0:  # It's a leaf item
                    items.append(child)
                else:
                    items.extend(recurse(child))
            return items

        root = self.fileTree.invisibleRootItem()
        return recurse(root)

    def start_playback(self):
        """Start playing through the items in the TreeWidget."""
        if not self.playback_timer.isActive():
            self.playback_timer.start()

    def stop_playback(self):
        """Stop playing through the items."""
        if self.playback_timer.isActive():
            self.playback_timer.stop()


    def openFileDialog(self):
        """Allow users to select multiple images and add them to the existing list."""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Open Images",
            "",
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf *.cr2 *.cr3 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)"
        )
        
        # Filter out already loaded images to prevent duplicates
        new_file_paths = [path for path in file_paths if path not in self.image_paths]

        if new_file_paths:
            self.loadImages(new_file_paths)
        else:
            QMessageBox.information(self, "No New Images", "No new images were selected or all selected images are already loaded.")


    def debayer_fits(self, image_data, bayer_pattern):
        """Debayer a FITS image using a basic Bayer pattern (2x2)."""
        if bayer_pattern == 'RGGB':
            # RGGB Bayer pattern
            r = image_data[::2, ::2]  # Red
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            b = image_data[1::2, 1::2]  # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'BGGR':
            # BGGR Bayer pattern
            b = image_data[::2, ::2]  # Blue
            g1 = image_data[::2, 1::2]  # Green 1
            g2 = image_data[1::2, ::2]  # Green 2
            r = image_data[1::2, 1::2]  # Red

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GRBG':
            # GRBG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            r = image_data[::2, 1::2]  # Red
            b = image_data[1::2, ::2]  # Blue
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        elif bayer_pattern == 'GBRG':
            # GBRG Bayer pattern
            g1 = image_data[::2, ::2]  # Green 1
            b = image_data[::2, 1::2]  # Blue
            r = image_data[1::2, ::2]  # Red
            g2 = image_data[1::2, 1::2]  # Green 2

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)

        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")

    def remove_item_from_tree(self, file_path):
        """Remove a specific item from the tree view based on file path."""
        file_name = os.path.basename(file_path)
        root = self.fileTree.invisibleRootItem()

        def recurse(parent):
            for index in range(parent.childCount()):
                child = parent.child(index)
                if child.text(0).endswith(file_name):
                    parent.removeChild(child)
                    return True
                if recurse(child):
                    return True
            return False

        recurse(root)

    def add_item_to_tree(self, file_path):
        """Add a specific item to the tree view based on file path."""
        # Extract metadata for grouping
        image_entry = next((img for img in self.loaded_images if img['file_path'] == file_path), None)
        if not image_entry:
            return

        header = image_entry['header']
        object_name = header.get('OBJECT', 'Unknown') if header else 'Unknown'
        filter_name = header.get('FILTER', 'Unknown') if header else 'Unknown'
        exposure_time = header.get('EXPOSURE', 'Unknown') if header else 'Unknown'

        # Group images by filter and exposure time
        group_key = (object_name, filter_name, exposure_time)

        # Find or create the object item
        object_item = self.findTopLevelItemByName(f"Object: {object_name}")
        if not object_item:
            object_item = QTreeWidgetItem([f"Object: {object_name}"])
            self.fileTree.addTopLevelItem(object_item)
            object_item.setExpanded(True)

        # Find or create the filter item
        filter_item = self.findChildItemByName(object_item, f"Filter: {filter_name}")
        if not filter_item:
            filter_item = QTreeWidgetItem([f"Filter: {filter_name}"])
            object_item.addChild(filter_item)
            filter_item.setExpanded(True)

        # Find or create the exposure item
        exposure_item = self.findChildItemByName(filter_item, f"Exposure: {exposure_time}")
        if not exposure_item:
            exposure_item = QTreeWidgetItem([f"Exposure: {exposure_time}"])
            filter_item.addChild(exposure_item)
            exposure_item.setExpanded(True)

        # Add the file item
        file_name = os.path.basename(file_path)
        item = QTreeWidgetItem([file_name])
        exposure_item.addChild(item)



    def debayer_raw(self, raw_image_data, bayer_pattern="RGGB"):
        """Debayer a RAW image based on the Bayer pattern, ensuring even dimensions."""
        H, W = raw_image_data.shape
        # Crop to even dimensions if necessary
        if H % 2 != 0:
            raw_image_data = raw_image_data[:H-1, :]
        if W % 2 != 0:
            raw_image_data = raw_image_data[:, :W-1]
        
        if bayer_pattern == 'RGGB':
            r = raw_image_data[::2, ::2]      # Red
            g1 = raw_image_data[::2, 1::2]     # Green 1
            g2 = raw_image_data[1::2, ::2]     # Green 2
            b = raw_image_data[1::2, 1::2]     # Blue

            # Average green channels
            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'BGGR':
            b = raw_image_data[::2, ::2]      # Blue
            g1 = raw_image_data[::2, 1::2]     # Green 1
            g2 = raw_image_data[1::2, ::2]     # Green 2
            r = raw_image_data[1::2, 1::2]     # Red

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'GRBG':
            g1 = raw_image_data[::2, ::2]     # Green 1
            r = raw_image_data[::2, 1::2]      # Red
            b = raw_image_data[1::2, ::2]      # Blue
            g2 = raw_image_data[1::2, 1::2]     # Green 2

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        elif bayer_pattern == 'GBRG':
            g1 = raw_image_data[::2, ::2]     # Green 1
            b = raw_image_data[::2, 1::2]      # Blue
            r = raw_image_data[1::2, ::2]      # Red
            g2 = raw_image_data[1::2, 1::2]     # Green 2

            g = (g1 + g2) / 2
            return np.stack([r, g, b], axis=-1)
        else:
            raise ValueError(f"Unsupported Bayer pattern: {bayer_pattern}")

    

    def on_item_clicked(self, item, column):
        """Handle click on a file name in the tree to preview the image."""
        self.fileTree.setFocus()

        name = item.text(0).lstrip("⚠️ ").strip()
        file_path = next((p for p in self.image_paths if os.path.basename(p) == name), None)
        if not file_path:
            return

        idx = self.image_paths.index(file_path)
        raw = self.loaded_images[idx]['image_data']

        # bring raw into float [0..1]
        if raw.dtype == np.uint16:
            imgf = raw.astype(np.float32) / 65535.0
        elif raw.dtype == np.uint8:
            imgf = raw.astype(np.float32) / 255.0
        else:
            imgf = raw.astype(np.float32).clip(0,1)

        # choose stretch
        if self.aggressive_stretch_enabled:
            disp = siril_style_autostretch(imgf, sigma=self.current_sigma)
        else:
            # your existing SEP‐based or linked stretch; e.g.:
            if imgf.ndim == 2:
                disp = stretch_mono_image(imgf, target_median=0.25, normalize=True)
            else:
                disp = stretch_color_image(imgf, target_median=0.25, linked=False)

        # convert back to uint8 for display
        disp8 = (disp * 255.0).clip(0,255).astype(np.uint8)
        qimage = self.convert_to_qimage(disp8)
        pixmap = QPixmap.fromImage(qimage)
        self.current_pixmap = pixmap
        self.apply_zoom()

    def apply_zoom(self):
        """Apply the current zoom level to the pixmap and update the display."""
        if not self.current_pixmap:
            return

        # 1) scale & show it
        scaled = self.current_pixmap.scaled(
            self.current_pixmap.size() * self.zoom_level,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation,
        )
        self.preview_label.setPixmap(scaled)
        self.preview_label.resize(scaled.size())

        # 2) center scrollbars
        self.scroll_area.horizontalScrollBar().setValue(
            (scaled.width() - self.scroll_area.viewport().width()) // 2
        )
        self.scroll_area.verticalScrollBar().setValue(
            (scaled.height() - self.scroll_area.viewport().height()) // 2
        )

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def zoom_in(self):
        """Increase the zoom level and refresh the image."""
        self.zoom_level = min(self.zoom_level * 1.2, 3.0)  # Cap at 3x
        self.apply_zoom()


    def zoom_out(self):
        """Decrease the zoom level and refresh the image."""
        self.zoom_level = max(self.zoom_level / 1.2, 0.05)  # Cap at 0.2x
        self.apply_zoom()


    def fit_to_preview(self):
        """Adjust the zoom level so the image fits within the QScrollArea viewport."""
        if self.current_pixmap:
            # Get the size of the QScrollArea's viewport
            viewport_size = self.scroll_area.viewport().size()
            pixmap_size = self.current_pixmap.size()

            # Calculate the zoom level required to fit the pixmap in the QScrollArea viewport
            width_ratio = viewport_size.width() / pixmap_size.width()
            height_ratio = viewport_size.height() / pixmap_size.height()
            self.zoom_level = min(width_ratio, height_ratio)

            # Apply the zoom level
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def _is_leaf(self, item: Optional[QTreeWidgetItem]) -> bool:
        return bool(item and item.childCount() == 0)

    def on_right_click(self, pos):
        item = self.fileTree.itemAt(pos)
        if not self._is_leaf(item):
            # Optional: expand/collapse-only menu, or just ignore
            return

        menu = QMenu(self)

        push_action = QAction("Push Image for Processing", self)
        push_action.triggered.connect(lambda: self.push_image_to_manager(item))
        menu.addAction(push_action)

        rename_action = QAction("Rename", self)
        rename_action.triggered.connect(lambda: self.rename_item(item))
        menu.addAction(rename_action)

        move_action = QAction("Move Selected Items", self)
        move_action.triggered.connect(self.move_items)
        menu.addAction(move_action)

        delete_action = QAction("Delete Selected Items", self)
        delete_action.triggered.connect(self.delete_items)
        menu.addAction(delete_action)

        menu.addSeparator()
        batch_delete_action = QAction("Delete All Flagged Images", self)
        batch_delete_action.triggered.connect(self.batch_delete_flagged_images)
        menu.addAction(batch_delete_action)

        batch_move_action = QAction("Move All Flagged Images", self)
        batch_move_action.triggered.connect(self.batch_move_flagged_images)
        menu.addAction(batch_move_action)

        menu.exec(self.fileTree.mapToGlobal(pos))

    def rename_item(self, item):
        """Allow the user to rename the selected image."""
        current_name = item.text(0).lstrip("⚠️ ")
        new_name, ok = QInputDialog.getText(self, "Rename Image", "Enter new name:", text=current_name)

        if ok and new_name:
            file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)
            if file_path:
                # Get the new file path with the new name
                new_file_path = os.path.join(os.path.dirname(file_path), new_name)

                try:
                    # Rename the file
                    os.rename(file_path, new_file_path)
                    print(f"File renamed from {current_name} to {new_name}")
                    
                    # Update the image paths and tree view
                    self.image_paths[self.image_paths.index(file_path)] = new_file_path
                    item.setText(0, new_name)
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

    def batch_rename_items(self):
        """Batch rename selected items by adding a prefix or suffix."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for renaming.")
            return

        # Create a custom dialog for entering the prefix and suffix
        dialog = QDialog(self)
        dialog.setWindowTitle("Batch Rename")
        dialog_layout = QVBoxLayout(dialog)

        instruction_label = QLabel("Enter a prefix or suffix to rename selected files:")
        dialog_layout.addWidget(instruction_label)

        # Create fields for prefix and suffix
        form_layout = QHBoxLayout()

        prefix_field = QLineEdit(dialog)
        prefix_field.setPlaceholderText("Prefix")
        form_layout.addWidget(prefix_field)

        current_filename_label = QLabel("currentfilename", dialog)
        form_layout.addWidget(current_filename_label)

        suffix_field = QLineEdit(dialog)
        suffix_field.setPlaceholderText("Suffix")
        form_layout.addWidget(suffix_field)

        dialog_layout.addLayout(form_layout)

        # Add OK and Cancel buttons
        button_layout = QHBoxLayout()
        ok_button = QPushButton("OK", dialog)
        ok_button.clicked.connect(dialog.accept)
        button_layout.addWidget(ok_button)

        cancel_button = QPushButton("Cancel", dialog)
        cancel_button.clicked.connect(dialog.reject)
        button_layout.addWidget(cancel_button)

        dialog_layout.addLayout(button_layout)

        # Show the dialog and handle user input
        if dialog.exec() == QDialog.DialogCode.Accepted:
            prefix = prefix_field.text().strip()
            suffix = suffix_field.text().strip()

            # Rename each selected file
            for item in selected_items:
                current_name = item.text(0)
                file_path = next((path for path in self.image_paths if os.path.basename(path) == current_name), None)

                if file_path:
                    # Construct the new filename
                    directory = os.path.dirname(file_path)
                    new_name = f"{prefix}{current_name}{suffix}"
                    new_file_path = os.path.join(directory, new_name)

                    try:
                        # Rename the file
                        os.rename(file_path, new_file_path)
                        print(f"File renamed from {file_path} to {new_file_path}")

                        # Update the paths and tree view
                        self.image_paths[self.image_paths.index(file_path)] = new_file_path
                        item.setText(0, new_name)

                    except Exception as e:
                        print(f"Failed to rename {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to rename the file: {e}")

            print(f"Batch renamed {len(selected_items)} items.")

    def batch_delete_flagged_images(self):
        """Delete all flagged images."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to delete.")
            return

        confirmation = QMessageBox.question(
            self,
            "Confirm Batch Deletion",
            f"Are you sure you want to permanently delete {len(flagged_images)} flagged images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if confirmation == QMessageBox.StandardButton.Yes:
            for img in flagged_images:
                file_path = img['file_path']
                try:
                    os.remove(file_path)
                    print(f"Deleted flagged image: {file_path}")
                except Exception as e:
                    print(f"Failed to delete {file_path}: {e}")
                    QMessageBox.critical(self, "Error", f"Failed to delete {file_path}: {e}")

                # Remove from data structures
                self.image_paths.remove(file_path)
                self.loaded_images.remove(img)

                # Remove from tree view
                self.remove_item_from_tree(file_path)

            QMessageBox.information(self, "Batch Deletion", f"Deleted {len(flagged_images)} flagged images.")

    def batch_move_flagged_images(self):
        """Move all flagged images to a selected directory."""
        flagged_images = [img for img in self.loaded_images if img['flagged']]
        
        if not flagged_images:
            QMessageBox.information(self, "No Flagged Images", "There are no flagged images to move.")
            return

        # Select destination directory
        destination_dir = QFileDialog.getExistingDirectory(self, "Select Destination Folder", "")
        if not destination_dir:
            return  # User canceled

        for img in flagged_images:
            src_path = img['file_path']
            file_name = os.path.basename(src_path)
            dest_path = os.path.join(destination_dir, file_name)

            try:
                os.rename(src_path, dest_path)
                print(f"Moved flagged image from {src_path} to {dest_path}")
            except Exception as e:
                print(f"Failed to move {src_path}: {e}")
                QMessageBox.critical(self, "Error", f"Failed to move {src_path}: {e}")
                continue

            # Update data structures
            self.image_paths.remove(src_path)
            self.image_paths.append(dest_path)
            img['file_path'] = dest_path
            img['flagged'] = False  # Reset flag if desired

            # Update tree view
            self.remove_item_from_tree(src_path)
            self.add_item_to_tree(dest_path)

        QMessageBox.information(self, "Batch Move", f"Moved {len(flagged_images)} flagged images.")


    def move_items(self):
        """Move selected images *and* remove them from the tree+metrics."""
        selected_items = self.fileTree.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for moving.")
            return

        # Ask where to move
        new_dir = QFileDialog.getExistingDirectory(self,
                                                "Select Destination Folder",
                                                "")
        if not new_dir:
            return

        # Keep track of which on‐disk paths we actually moved
        moved_old_paths = []

        for item in selected_items:
            name = item.text(0).lstrip("⚠️ ")
            old_path = next((p for p in self.image_paths 
                            if os.path.basename(p) == name), None)
            if not old_path:
                continue

            new_path = os.path.join(new_dir, name)
            try:
                os.rename(old_path, new_path)
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to move {old_path}: {e}")
                continue

            moved_old_paths.append(old_path)

            # 1) Remove the leaf from the tree
            parent = item.parent() or self.fileTree.invisibleRootItem()
            parent.removeChild(item)

        # 2) Purge them from your internal lists
        for old in moved_old_paths:
            idx = self.image_paths.index(old)
            del self.image_paths[idx]
            del self.loaded_images[idx]

        # 3) Update your “loaded X images” label
        self.loading_label.setText(f"Loaded {len(self.loaded_images)} images.")

        # 4) Tell metrics to re-initialize on the new list
        if self.metrics_window and self.metrics_window.isVisible():
            self.metrics_window.update_metrics(self.loaded_images)

        print(f"Moved and removed {len(moved_old_paths)} items.")



    def push_image_to_manager(self, item):
        """Push the selected image to the ImageManager."""
        file_name = item.text(0).lstrip("⚠️ ")
        file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

        if file_path and self.image_manager:
            # Load the image into ImageManager
            image, header, bit_depth, is_mono = load_image(file_path)

            # Check for Bayer pattern or RAW image type (For FITS and RAW images)
            if file_path.lower().endswith(('.fits', '.fit')):
                # For FITS, check the header for Bayer pattern
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    print(f"Bayer pattern detected in FITS image: {bayer_pattern}")
                    # Debayer the FITS image based on the Bayer pattern
                    image = self.debayer_fits(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono

            elif file_path.lower().endswith(('.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                # For RAW images, debayer directly using the raw image data
                print(f"Debayering RAW image: {file_path}")
                # We assume `header` contains the Bayer pattern info from rawpy
                bayer_pattern = header.get('BAYERPAT', None) if header else None
                if bayer_pattern:
                    # Debayer the RAW image based on the Bayer pattern
                    image = self.debayer_raw(image, bayer_pattern)
                    is_mono = False  # After debayering, the image is no longer mono
                else:
                    # If no Bayer pattern in the header, default to RGGB for debayering
                    print("No Bayer pattern found in RAW header. Defaulting to RGGB.")
                    image = self.debayer_raw(image, 'RGGB')
                    is_mono = False  # After debayering, the image is no longer mono

            # Create metadata for the image
            metadata = {
                'file_path': file_path,
                'original_header': header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }

            # Add the debayered image to ImageManager (use the current slot)
            self.image_manager.add_image(self.image_manager.current_slot, image, metadata)
            print(f"Image {file_path} pushed to ImageManager for processing.")

    def delete_items(self):
        """Delete the selected items from the tree, the loaded images list, and the file system."""
        selected_items = self.fileTree.selectedItems()

        if not selected_items:
            QMessageBox.warning(self, "Warning", "No items selected for deletion.")
            return

        # Confirmation dialog
        reply = QMessageBox.question(
            self,
            'Confirm Deletion',
            f"Are you sure you want to permanently delete {len(selected_items)} selected images? This action is irreversible.",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
            QMessageBox.StandardButton.No
        )

        if reply == QMessageBox.StandardButton.Yes:
            for item in selected_items:
                file_name = item.text(0).lstrip("⚠️ ")
                file_path = next((path for path in self.image_paths if os.path.basename(path) == file_name), None)

                if file_path:
                    try:
                        # Remove the image from image_paths
                        if file_path in self.image_paths:
                            self.image_paths.remove(file_path)
                            print(f"Image path {file_path} removed from image_paths.")
                        else:
                            print(f"Image path {file_path} not found in image_paths.")

                        # Remove the corresponding image from loaded_images
                        matching_image_data = next((entry for entry in self.loaded_images if entry['file_path'] == file_path), None)
                        if matching_image_data:
                            self.loaded_images.remove(matching_image_data)
                            print(f"Image {file_name} removed from loaded_images.")
                        else:
                            print(f"Image {file_name} not found in loaded_images.")

                        # Delete the file from the filesystem
                        os.remove(file_path)
                        print(f"File {file_path} deleted successfully.")

                    except Exception as e:
                        print(f"Failed to delete {file_path}: {e}")
                        QMessageBox.critical(self, "Error", f"Failed to delete the image file: {e}")

            # Remove the selected items from the TreeWidget
            for item in selected_items:
                parent = item.parent()
                if parent:
                    parent.removeChild(item)
                else:
                    index = self.fileTree.indexOfTopLevelItem(item)
                    if index != -1:
                        self.fileTree.takeTopLevelItem(index)

            print(f"Deleted {len(selected_items)} items.")

            # Clear the preview if the deleted items include the currently displayed image
            self.preview_label.clear()
            self.preview_label.setText('No image selected.')

            self.current_image = None

    def eventFilter(self, source, event):
        """Handle mouse events for dragging."""
        if source == self.scroll_area.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                # Start dragging
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                # Handle dragging
                delta = event.pos() - self.last_mouse_pos
                self.scroll_area.horizontalScrollBar().setValue(
                    self.scroll_area.horizontalScrollBar().value() - delta.x()
                )
                self.scroll_area.verticalScrollBar().setValue(
                    self.scroll_area.verticalScrollBar().value() - delta.y()
                )
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                # Stop dragging
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def on_selection_changed(self, selected, deselected):
        items = self.fileTree.selectedItems()
        if not items:
            return
        item = items[0]

        # if a group got selected, ignore (or auto-drill to first leaf if you prefer)
        if item.childCount() > 0:
            return

        name = item.text(0).lstrip("⚠️ ").strip()
        if self._last_preview_name == name:
            return  # no-op, same item

        # debounce: only preview the last selection after brief idle
        self._pending_preview_item = item
        self._pending_preview_timer.start()

    def _do_preview_update(self):
        item = self._pending_preview_item
        if not item:
            return
        # item might have changed selection; ensure it’s still selected/current
        cur = self.fileTree.currentItem()
        if cur is not item:
            return

        name = item.text(0).lstrip("⚠️ ").strip()
        self._last_preview_name = name

        # kick the preview (reuse your existing loader)
        self.on_item_clicked(item, 0)

    def toggle_aggressive(self):
        self.aggressive_stretch_enabled = self.aggressive_button.isChecked()
        cur = self.fileTree.currentItem()
        if cur:
            self._last_preview_name = None  # force reload even if same item
            self.on_item_clicked(cur, 0)

    def convert_to_qimage(self, img_array):
        """Convert numpy image array to QImage."""
        # 1) Bring everything into a uint8 (0–255) array
        if img_array.dtype == np.uint8:
            arr8 = img_array
        elif img_array.dtype == np.uint16:
            # downscale 16-bit → 8-bit
            arr8 = (img_array.astype(np.float32) / 65535.0 * 255.0).clip(0,255).astype(np.uint8)
        else:
            # assume float in [0..1]
            arr8 = (img_array.clip(0.0, 1.0) * 255.0).astype(np.uint8)

        h, w = arr8.shape[:2]
        buffer = arr8.tobytes()

        if arr8.ndim == 3:
            # RGB
            return QImage(buffer, w, h, 3*w, QImage.Format.Format_RGB888)
        else:
            # grayscale
            return QImage(buffer, w, h, w, QImage.Format.Format_Grayscale8)

class CosmicClarityTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.settings_file = "cosmic_clarity_folder.txt"  # Path to save the folder location
        self.zoom_factor = 1  # Zoom level
        self.drag_start_position = QPoint()  # Starting point for drag
        self.is_dragging = False  # Flag to indicate if dragging
        self.scroll_position = QPoint(0, 0)  # Initialize scroll position
        self.original_image = None  # Image before processing
        self.processed_image = None  # Most recent processed image    
        self.is_selecting_preview = False  # Initialize preview selection attribute
        self.preview_start_position = None
        self.preview_end_position = None
        self.preview_rect = None  # Stores the preview selection rectangle
        self.autostretch_enabled = False  # Track autostretch status
        self.settings = QSettings() 
        self.cosmic_clarity_folder = None
        self.cropped_operation_queue = []
        self.image = None

        self.initUI()

        self.load_cosmic_clarity_folder()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left panel for controls
        left_layout = QVBoxLayout()

        

        # Load button to load an image
        self.load_button = QPushButton("Load Image")
        self.load_button.clicked.connect(self.load_image)
        left_layout.addWidget(self.load_button)

        # AutoStretch toggle button
        self.auto_stretch_button = QPushButton("AutoStretch (Off)")
        self.auto_stretch_button.setCheckable(True)
        self.auto_stretch_button.toggled.connect(self.toggle_auto_stretch)
        left_layout.addWidget(self.auto_stretch_button)

        # Left column for Sharpen, Denoise, and Both
        left_radio_layout = QVBoxLayout()
        self.sharpen_radio = QRadioButton("Sharpen")
        self.denoise_radio = QRadioButton("Denoise")
        self.both_radio = QRadioButton("Both")
        self.sharpen_radio.setChecked(True)  # Default

        left_radio_layout.addWidget(self.sharpen_radio)
        left_radio_layout.addWidget(self.denoise_radio)
        left_radio_layout.addWidget(self.both_radio)

        # Right column for Super Resolution Upscaling
        right_radio_layout = QVBoxLayout()
        self.superres_radio = QRadioButton("Super Resolution Upscaling")
        right_radio_layout.addWidget(self.superres_radio)

        # Connect toggles to UI update method
        self.sharpen_radio.toggled.connect(self.update_ui_for_mode)
        self.denoise_radio.toggled.connect(self.update_ui_for_mode)
        self.both_radio.toggled.connect(self.update_ui_for_mode)
        self.superres_radio.toggled.connect(self.update_ui_for_mode)

        # Main horizontal layout to place columns side-by-side
        main_radio_layout = QHBoxLayout()
        main_radio_layout.addLayout(left_radio_layout)
        main_radio_layout.addLayout(right_radio_layout)

        # Add the combined layout to your parent layout
        left_layout.addLayout(main_radio_layout)


        # GPU Acceleration dropdown
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Add Sharpening specific controls
        self.sharpen_mode_label = QLabel("Sharpening Mode:")
        self.sharpen_mode_dropdown = QComboBox()
        self.sharpen_mode_dropdown.addItems(["Both", "Stellar Only", "Non-Stellar Only"])
        left_layout.addWidget(self.sharpen_mode_label)
        left_layout.addWidget(self.sharpen_mode_dropdown)

        # Dropdown for Sharpen Channels Separately option
        self.sharpen_channels_label = QLabel("Sharpen RGB Channels Separately:")
        self.sharpen_channels_dropdown = QComboBox()
        self.sharpen_channels_dropdown.addItems(["No", "Yes"])  # "No" means don't separate, "Yes" means separate

        left_layout.addWidget(self.sharpen_channels_label)
        left_layout.addWidget(self.sharpen_channels_dropdown)

        self.auto_detect_psf_checkbox = QCheckBox("Auto Detect PSF", self)
        self.auto_detect_psf_checkbox.setToolTip("Automatically measure PSF per chunk and choose the two nearest radius models")
        self.auto_detect_psf_checkbox.setChecked(True)
        left_layout.addWidget(self.auto_detect_psf_checkbox)
        self.auto_detect_psf_checkbox.toggled.connect(self._on_auto_detect_toggled)

        # Non-Stellar Sharpening PSF Slider
        self.psf_slider_label = QLabel("Non-Stellar Sharpening PSF (1-8): 3")
        self.psf_slider = QSlider(Qt.Orientation.Horizontal)
        self.psf_slider.setMinimum(10)
        self.psf_slider.setMaximum(80)
        self.psf_slider.setValue(30)
        self.psf_slider.valueChanged.connect(self.update_psf_slider_label)
        left_layout.addWidget(self.psf_slider_label)
        left_layout.addWidget(self.psf_slider)

        # Stellar Amount Slider
        self.stellar_amount_label = QLabel("Stellar Sharpening Amount (0-1): 0.50")
        self.stellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.stellar_amount_slider.setMinimum(0)
        self.stellar_amount_slider.setMaximum(100)
        self.stellar_amount_slider.setValue(50)
        self.stellar_amount_slider.valueChanged.connect(self.update_stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_label)
        left_layout.addWidget(self.stellar_amount_slider)

        # Non-Stellar Amount Slider
        self.nonstellar_amount_label = QLabel("Non-Stellar Sharpening Amount (0-1): 0.50")
        self.nonstellar_amount_slider = QSlider(Qt.Orientation.Horizontal)
        self.nonstellar_amount_slider.setMinimum(0)
        self.nonstellar_amount_slider.setMaximum(100)
        self.nonstellar_amount_slider.setValue(50)
        self.nonstellar_amount_slider.valueChanged.connect(self.update_nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_label)
        left_layout.addWidget(self.nonstellar_amount_slider)

        # Denoise Strength Slider
        self.denoise_strength_label = QLabel("Luminance Denoise Strength (0-1): 0.50")
        self.denoise_strength_slider = QSlider(Qt.Orientation.Horizontal)
        self.denoise_strength_slider.setMinimum(0)
        self.denoise_strength_slider.setMaximum(100)
        self.denoise_strength_slider.setValue(50)
        self.denoise_strength_slider.valueChanged.connect(self.update_denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_label)
        left_layout.addWidget(self.denoise_strength_slider)

        self.color_denoise_strength_label = QLabel("Color Denoise Strength (0-1): 0.50")
        self.color_denoise_strength_slider = QSlider(Qt.Orientation.Horizontal)
        self.color_denoise_strength_slider.setMinimum(0)
        self.color_denoise_strength_slider.setMaximum(100)
        self.color_denoise_strength_slider.setValue(50)
        self.color_denoise_strength_slider.valueChanged.connect(self.update_color_denoise_strength_label)
        left_layout.addWidget(self.color_denoise_strength_label)
        left_layout.addWidget(self.color_denoise_strength_slider)

        # Denoise Mode dropdown
        self.denoise_mode_label = QLabel("Denoise Mode:")
        self.denoise_mode_dropdown = QComboBox()
        self.denoise_mode_dropdown.addItems(["full", "luminance"])  # 'luminance' for luminance-only, 'full' for full YCbCr denoising
        left_layout.addWidget(self.denoise_mode_label)
        left_layout.addWidget(self.denoise_mode_dropdown)

        self.denoise_separate_checkbox = QCheckBox("Process RGB channels separately")
        self.denoise_separate_checkbox.setToolTip(
            "Run the mono model on each of R, G, B independently instead of the full‐color model"
        )
        self.denoise_separate_checkbox.setChecked(False)
        left_layout.addWidget(self.denoise_separate_checkbox)

        # Scale factor dropdown (initially hidden)
        self.scale_label = QLabel("Scale Factor:")
        self.scale_dropdown = QComboBox()
        self.scale_dropdown.addItems(["2x", "3x", "4x"])

        left_layout.addWidget(self.scale_label)
        left_layout.addWidget(self.scale_dropdown)

        # Initially hidden, only show for Super Resolution
        self.scale_label.hide()
        self.scale_dropdown.hide()

        # Execute button
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.run_cosmic_clarity)
        left_layout.addWidget(self.execute_button)

        # Save button to save the processed image
        self.save_button = QPushButton("Save Image")
        self.save_button.clicked.connect(self.save_processed_image_to_disk)
        #left_layout.addWidget(self.save_button)  

        # Spacer to push the wrench button to the bottom
        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Cosmic Clarity folder path label
        self.cosmic_clarity_folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.cosmic_clarity_folder_label)

        # Wrench button to select Cosmic Clarity folder
        self.wrench_button = QPushButton()

        # Set the path for the wrench icon
        if hasattr(sys, '_MEIPASS'):
            wrench_path = os.path.join(sys._MEIPASS, "wrench_icon.png")
        else:
            wrench_path = "wrench_icon.png"

        self.wrench_button.setIcon(QIcon(wrench_path))  # Set the wrench icon with the dynamic path
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)  



        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Right panel for image preview with zoom controls
        right_layout = QVBoxLayout()

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview with click-and-drag functionality
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scroll_area.setWidget(self.image_label)
        right_layout.addWidget(self.scroll_area)

        # Button to open the preview area selection dialog
        self.select_preview_button = QPushButton("Select Preview Area")
        self.select_preview_button.clicked.connect(self.open_preview_dialog)
        right_layout.addWidget(self.select_preview_button)        

        left_widget = QWidget()
        left_widget.setLayout(left_layout)
        left_widget.setFixedWidth(400)

        # Add left and right layouts to the main layout
        main_layout.addWidget(left_widget)
        main_layout.addLayout(right_layout)

        self.setLayout(main_layout)
        self.update_ui_for_mode()

        self.sharpen_channels_dropdown.hide()
        self.sharpen_channels_label.hide()

    def update_image_display(self):
        """
        Update the displayed image by scaling the stored base pixmap according
        to the current zoom factor.
        """
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            print("Base pixmap not available. Please update it first.")
            return

        # Calculate new dimensions using the current zoom factor.
        new_width = int(self.base_pixmap.width() * self.zoom_factor)
        new_height = int(self.base_pixmap.height() * self.zoom_factor)
        
        # Scale the base pixmap quickly.
        scaled_pixmap = self.base_pixmap.scaled(
            new_width, new_height,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        
        self.image_label.setPixmap(scaled_pixmap)


        # Optionally, adjust scroll bars to keep the view centered.
        # (You might reuse your current code for centering.)


    def update_base_pixmap(self):
        """
        Process self.image (applying autostretch if enabled) and store it as self.base_pixmap.
        If self.image is empty or not as expected, it skips processing.
        """
        if self.image is None or self.image.size == 0:
            print("[WARNING] No image available to update base pixmap.")
            self.base_pixmap = None
            return

        display_image = self.image.copy()

        # Apply autostretch if enabled.
        if self.auto_stretch_button.isChecked():
            target_median = 0.25
            # Check image dimensions to decide whether it's mono or color.
            if display_image.ndim < 3 or (display_image.ndim == 3 and display_image.shape[2] != 3):
                # Treat as grayscale: if image is 3D but not 3 channels, pick one channel
                try:
                    mono_source = display_image if display_image.ndim == 2 else display_image[:, :, 0]
                    stretched = stretch_mono_image(mono_source, target_median, normalize=True)
                    # Convert grayscale to 3-channel for display.
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            else:
                # Color image with three channels.
                try:
                    display_image = stretch_color_image(display_image, target_median, linked=False, normalize=True)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return

        try:
            display_image_uint8 = (display_image * 255).astype(np.uint8)
        except Exception as e:
            print(f"[ERROR] Converting image to uint8: {e}")
            return

        # Create a QImage from the numpy array.
        if display_image_uint8.ndim == 3 and display_image_uint8.shape[2] == 3:
            height, width, _ = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif display_image_uint8.ndim == 2:
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            print("[ERROR] Unexpected image format!")
            return

        self.base_pixmap = QPixmap.fromImage(qimage)
        print("Base pixmap updated.")

    def _on_auto_detect_toggled(self, checked):
        # whenever the box changes, re-show or hide the PSF slider
        self._update_psf_visibility()

    def _update_psf_visibility(self):
        if self.auto_detect_psf_checkbox.isChecked():
            self.psf_slider_label.hide()
            self.psf_slider.hide()
        else:
            # only show it when we’re in a sharpen mode
            if self.sharpen_radio.isChecked() or self.both_radio.isChecked():
                self.psf_slider_label.show()
                self.psf_slider.show()

    def update_psf_slider_label(self):
        """Update the label text to display the current value of the PSF slider as a non-integer."""
        psf_value = self.psf_slider.value() / 10  # Convert to a float in the range 1.0 - 8.0
        self.psf_slider_label.setText(f"Non-Stellar Sharpening PSF (1.0-8.0): {psf_value:.1f}")

    def update_stellar_amount_label(self):
        self.stellar_amount_label.setText(f"Stellar Sharpening Amount (0-1): {self.stellar_amount_slider.value() / 100:.2f}")

    def update_nonstellar_amount_label(self):
        self.nonstellar_amount_label.setText(f"Non-Stellar Sharpening Amount (0-1): {self.nonstellar_amount_slider.value() / 100:.2f}")

    def update_denoise_strength_label(self):
        self.denoise_strength_label.setText(f"Denoise Strength (0-1): {self.denoise_strength_slider.value() / 100:.2f}")

    def mousePressEvent(self, event):
        """Handle the start of the drag action or selection of a preview area."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.is_dragging = True
            self.drag_start_position = event.pos()              
                

    def mouseMoveEvent(self, event):
        """Handle dragging or adjusting the preview selection area."""
        if self.is_dragging:
            # Handle image panning
            delta = event.pos() - self.drag_start_position
            self.scroll_area.horizontalScrollBar().setValue(self.scroll_area.horizontalScrollBar().value() - delta.x())
            self.scroll_area.verticalScrollBar().setValue(self.scroll_area.verticalScrollBar().value() - delta.y())
            self.drag_start_position = event.pos()


    def mouseReleaseEvent(self, event):
        """End the drag action or finalize the preview selection area."""
        if event.button() == Qt.MouseButton.LeftButton:
            if self.is_dragging:
                self.is_dragging = False


    def open_preview_dialog(self):
        """Open a preview dialog to select a 640x480 area of the image at 100% scale."""
        if self.image is not None:
            # Pass the 32-bit numpy image directly to maintain bit depth
            self.preview_dialog = PreviewDialog(self.image, parent_tab=self, is_mono=self.is_mono)
            self.preview_dialog.show()
        else:
            print("No image loaded. Please load an image first.")



    def convert_numpy_to_qimage(self, np_img):
        """Convert a numpy array to QImage."""
        # Ensure image is in 8-bit format for QImage compatibility
        if np_img.dtype == np.float32:
            np_img = (np_img * 255).astype(np.uint8)  # Convert normalized float32 to uint8 [0, 255]
        
        if np_img.dtype == np.uint8:
            if len(np_img.shape) == 2:
                # Grayscale image
                height, width = np_img.shape
                bytes_per_line = width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            elif len(np_img.shape) == 3 and np_img.shape[2] == 3:
                # RGB image
                height, width, channels = np_img.shape
                bytes_per_line = 3 * width
                return QImage(np_img.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            print("Image format not supported for conversion to QImage.")
            return None

    def validate_cosmic_clarity_folder(self):
        """Check if the Cosmic Clarity folder is set and valid."""
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(
                self,
                "Missing Folder",
                "The Cosmic Clarity folder is not set. Please use the wrench icon to select the correct folder."
            )
            return False

        # Determine the expected executable based on the platform
        if os.name == "nt":  # Windows
            expected_executable = "SetiAstroCosmicClarity.exe"
        elif sys.platform == "darwin":  # macOS
            expected_executable = "SetiAstroCosmicClaritymac"
        else:  # Linux
            expected_executable = "SetiAstroCosmicClarity"  # Case-sensitive, no extension

        # Check if the expected executable exists in the folder
        executable_path = os.path.join(self.cosmic_clarity_folder, expected_executable)
        if not os.path.exists(executable_path):
            QMessageBox.warning(
                self,
                "Invalid Folder",
                f"Incorrect Cosmic Clarity folder. Please choose the parent folder containing the Cosmic Clarity executable:\n\n"
                f"Expected file: {expected_executable}"
            )
            return False

        return True



    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.save_cosmic_clarity_folder(folder)
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.update_image_display()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.update_image_display()

    def fit_to_preview(self):
        if not hasattr(self, 'base_pixmap') or self.base_pixmap is None:
            return
        preview_width = self.scroll_area.viewport().width()
        self.zoom_factor = preview_width / self.base_pixmap.width()
        self.update_image_display()


    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.update_image_display()  # Call without extra arguments; it will calculate dimensions based on zoom factor
    



    def restore_image(self, image_array):
        """Display a given image array, preserving the current zoom level and scroll position."""
        # Save the current zoom level and scroll position
        current_zoom = self.zoom_factor
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Display the image
        self.show_image(image_array)

        # Restore the zoom level and scroll position
        self.zoom_factor = current_zoom
        self.update_image_display()  # Refresh display with the preserved zoom level

        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])


    def save_cosmic_clarity_folder(self, folder):
        """Save the Cosmic Clarity folder path using QSettings."""
        self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
        print(f"Saved Cosmic Clarity folder to QSettings: {folder}")

    def load_cosmic_clarity_folder(self):
        """Load the saved Cosmic Clarity folder path from QSettings."""
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.cosmic_clarity_folder_label.setText(f"Folder: {folder}")
            #print(f"Loaded Cosmic Clarity folder from QSettings: {folder}")
        else:
            print("No saved Cosmic Clarity folder found in QSettings.")

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return
        if image is None:
            return        
        if slot == self.image_manager.current_slot:
            self.loaded_image_path = metadata.get('file_path', None)
            self.original_header = metadata.get('original_header', None)
            self.bit_depth = metadata.get('bit_depth', None)
            self.is_mono = metadata.get('is_mono', False)

            # Ensure image is in numpy array format
            if not isinstance(image, np.ndarray):
                image = np.array(image)

            # Handle mono and color images
            if self.is_mono:
                # Squeeze the singleton dimension for grayscale images if it exists
                if len(image.shape) == 3 and image.shape[2] == 1:
                    print(f"Mono image detected with shape: {image.shape}. Squeezing singleton dimension.")
                    image = np.squeeze(image, axis=2)  # Convert (H, W, 1) to (H, W)
                # Do not convert a mono image to 3-channel RGB; keep it as 2D.

            elif len(image.shape) == 3 and image.shape[2] not in [1, 3]:
                # Catch unexpected formats like (H, W, C) where C is not 1 or 3
                raise ValueError(f"Unexpected image format with shape {image.shape}. Must be RGB or Grayscale.")

            self.image = image

            # Show the image using the show_image method
            self.update_base_pixmap()
            # Now update the display by scaling the base pixmap.
            self.update_image_display()
            print(f"CosmicClarityTab: Image updated from ImageManager slot {slot}.")



    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    def load_image(self):
        """Load an image and set it as the current and original image."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.jpg *.tif *.tiff *.fits *.fit *.jpeg *.xisf)"
        )
        if file_path:
            print(f"Loading file: {file_path}")

            # Load the image and store it as the original image
            image, original_header, bit_depth, is_mono = load_image(file_path)
            
            # Check if the image was loaded successfully
            if image is None:
                print("Error: Failed to load the image data.")
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            print(f"Image loaded successfully. Shape: {image.shape}, Dtype: {image.dtype}")

            # Make a copy of the original image for reference
            try:
                self.original_image = image.copy()
                print("Original image copied successfully.")
            except Exception as e:
                print(f"Error copying original image: {e}")
                QMessageBox.critical(self, "Error", "Failed to copy the original image.")
                return

            # Clear any existing processed image
            self.processed_image = None

            # Attempt to display the loaded image in the preview
            try:
                self.show_image(image)  # Ensure this function can handle 32-bit float images
                print("Image displayed successfully.")
            except Exception as e:
                print(f"Error displaying image: {e}")
                QMessageBox.critical(self, "Error", "Failed to display the image.")
                return

            # Enable or disable buttons as necessary


            # Center scrollbars after a short delay
            try:
                QTimer.singleShot(50, self.center_scrollbars)  # Delay of 50 ms for centering scrollbars
                print("Scrollbars centered.")
            except Exception as e:
                print(f"Error centering scrollbars: {e}")

            # Update the display after another short delay to ensure scrollbars are centered first
            try:
                QTimer.singleShot(100, self.update_image_display)  # Delay of 100 ms for display update
                print("Image display updated.")
            except Exception as e:
                print(f"Error updating image display: {e}")

            # Update ImageManager with the new image
            metadata = {
                'file_path': file_path,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

        else:
            print("No file selected.")



    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def show_image(self, image=None):
        """
        Display the loaded image by updating the base pixmap (which applies autostretch)
        and then updating the display using that pixmap.
        """
        # Use the passed image if provided; otherwise use self.image.
        if image is not None:
            self.image = image

        if self.image is None:
            print("[ERROR] No image to display.")
            QMessageBox.warning(self, "No Image", "No image data available to display.")
            return False

        # Save the current scroll position so it can be restored.
        current_scroll_position = (
            self.scroll_area.horizontalScrollBar().value(),
            self.scroll_area.verticalScrollBar().value()
        )

        # Update the base pixmap (this applies autostretch if the auto_stretch_button is checked)
        self.update_base_pixmap()
        
        # Now update the display using the base pixmap.
        self.update_image_display()

        # Restore the scroll position.
        self.scroll_area.horizontalScrollBar().setValue(current_scroll_position[0])
        self.scroll_area.verticalScrollBar().setValue(current_scroll_position[1])

        return True


    def store_processed_image(self, processed_image):
        """Store the processed image and update the ImageManager."""
        if processed_image is not None:
            # Prepare metadata for the ImageManager
            metadata = {
                'file_path': self.loaded_image_path,      # Ensure this is correctly set elsewhere
                'original_header': self.original_header,  # Ensure this is correctly set elsewhere
                'bit_depth': self.bit_depth,              # Ensure this is correctly set elsewhere
                'is_mono': self.is_mono                   # Ensure this is correctly set elsewhere
            }

            # Use ImageManager's set_image method to manage undo/redo stack
            if self.image_manager:
                try:
                    self.image_manager.set_image(processed_image, metadata, step_name="Cosmic Clarity")
                    print("CosmicClarityTab: Processed image stored in ImageManager with undo/redo support.")
                except Exception as e:
                    # Handle potential errors during the update
                    QMessageBox.critical(self, "Error", f"Failed to store processed image in ImageManager:\n{e}")
                    print(f"Error storing processed image in ImageManager: {e}")
            else:
                print("ImageManager is not initialized.")
                QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
        else:
            print("No processed image available to store.")
            QMessageBox.warning(self, "Warning", "No processed image available to store.")


    def toggle_auto_stretch(self, checked):
        """Toggle autostretch and update the display."""
        self.autostretch_enabled = checked
        self.auto_stretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        # Recalculate the base pixmap using the new autostretch setting.
        self.update_base_pixmap()
        # Then update the displayed image.
        self.update_image_display()



    def save_input_image(self, file_path):
        """Save the current image to the specified path in TIF format."""
        if self.image is not None:
            try:
                # Force saving as `.tif` format
                if not file_path.endswith(".tif"):
                    file_path += ".tif"
                # If image is mono with shape (H, W, 1), squeeze it to (H, W)
                image_to_save = self.image.astype(np.float32)
                if image_to_save.ndim == 3 and image_to_save.shape[2] == 1:
                    image_to_save = image_to_save.squeeze(axis=2)
                imwrite(file_path, image_to_save)
                print(f"Image saved as TIFF to {file_path}")
            except Exception as e:
                print(f"Error saving input image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save input image:\n{e}")
        else:
            QMessageBox.warning(self, "Warning", "No image to save.")

    def update_ui_for_mode(self):
        if self.superres_radio.isChecked():
            self.hide_sharpen_controls()
            self.hide_denoise_controls()
            self.hide_superres_controls()
            self.show_superres_controls()
            self.gpu_label.hide()
            self.gpu_dropdown.hide()
        else:
            self.hide_superres_controls()
            self.gpu_label.show()
            self.gpu_dropdown.show()

            if self.sharpen_radio.isChecked():
                self.show_sharpen_controls()
                self.hide_denoise_controls()
            elif self.denoise_radio.isChecked():
                self.hide_sharpen_controls()
                self.show_denoise_controls()
            elif self.both_radio.isChecked():
                self.show_sharpen_controls()
                self.show_denoise_controls()

    def update_color_denoise_strength_label(self):
        val = self.color_denoise_strength_slider.value() / 100.0
        self.color_denoise_strength_label.setText(f"Color Denoise Strength (0-1): {val:.2f}")

    def show_sharpen_controls(self):
        for w in (
            self.sharpen_mode_label, self.sharpen_mode_dropdown,
            self.psf_slider_label, self.psf_slider,
            self.stellar_amount_label, self.stellar_amount_slider,
            self.nonstellar_amount_label, self.nonstellar_amount_slider,
            self.sharpen_channels_label, self.sharpen_channels_dropdown,
            self.auto_detect_psf_checkbox
        ):
            w.show()
        # now hide or show PSF slider depending on checkbox state
        self._update_psf_visibility()
        self.sharpen_channels_dropdown.hide()
        self.sharpen_channels_label.hide()

    def hide_sharpen_controls(self):
        for w in (
            self.sharpen_mode_label, self.sharpen_mode_dropdown,
            self.psf_slider_label, self.psf_slider,
            self.stellar_amount_label, self.stellar_amount_slider,
            self.nonstellar_amount_label, self.nonstellar_amount_slider,
            self.sharpen_channels_label, self.sharpen_channels_dropdown,
            self.auto_detect_psf_checkbox
        ):
            w.hide()            

    def show_denoise_controls(self):
        self.denoise_strength_label.show()
        self.denoise_strength_slider.show()
        self.color_denoise_strength_label.show()        # NEW
        self.color_denoise_strength_slider.show()       # NEW
        self.denoise_mode_label.show()
        self.denoise_mode_dropdown.show()
        self.denoise_separate_checkbox.show()

    def hide_denoise_controls(self):
        self.denoise_strength_label.hide()
        self.denoise_strength_slider.hide()
        self.color_denoise_strength_label.hide()        # NEW
        self.color_denoise_strength_slider.hide()       # NEW
        self.denoise_mode_label.hide()
        self.denoise_mode_dropdown.hide()
        self.denoise_separate_checkbox.hide()

    def show_superres_controls(self):
        self.scale_label.show()
        self.scale_dropdown.show()

    def hide_superres_controls(self):
        self.scale_label.hide()
        self.scale_dropdown.hide()


    def get_psf_value(self):
        """Convert the slider value to a float in the range 1.0 - 8.0."""
        return self.psf_slider.value() / 10.0
    
    def run_cosmic_clarity(self, input_file_path=None):
        """Run Cosmic Clarity with the current parameters."""
        if not self.validate_cosmic_clarity_folder():
            return

        if self.image is None:
            QMessageBox.warning(self, "Warning", "Please load an image first.")
            return

        if self.superres_radio.isChecked():
            self.execute_super_resolution()
            return  # Skip the rest if super-resolution mode is chosen

        psf_value = self.get_psf_value()
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return
        if self.image is None:  # Ensure an image is currently displayed
            QMessageBox.warning(self, "Warning", "Please load an image first.")
            return

        # Check the current autostretch state
        was_autostretch_enabled = self.auto_stretch_button.isChecked()

        # Disable autostretch if it was enabled
        if was_autostretch_enabled:
            self.auto_stretch_button.setChecked(False)

        # Determine mode from the radio buttons
        if self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        elif self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.operation_queue = list(zip(modes, output_suffixes))



        # Start the first operation
        if self.operation_queue:
            self._execute_cosmic_clarity(*self.operation_queue.pop(0))

    def execute_super_resolution(self):
        scale_str = self.scale_dropdown.currentText()
        scale_factor = int(scale_str.replace("x", ""))

        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        os.makedirs(input_folder, exist_ok=True)
        os.makedirs(output_folder, exist_ok=True)

        base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        input_path = os.path.join(input_folder, base_filename + ".tif")

        # Save current image
        self.save_input_image(input_path)

        if sys.platform.startswith("win"):
            executable_name = "setiastrocosmicclarity_superres.exe"
        else:
            executable_name = "setiastrocosmicclarity_superres"

        executable_path = os.path.join(self.cosmic_clarity_folder, executable_name)

        cmd = [
            executable_path,
            "--input", input_path,
            "--output_dir", output_folder,
            "--scale", str(scale_factor),
            "--model_dir", self.cosmic_clarity_folder,  # or "." if models are in executable folder
        ]

        # Directly run superres.py for debugging (assuming it's in the same folder)
        #superres_script = os.path.join(os.path.dirname(os.path.abspath(__file__)), "setiastrocosmicclarity_superres.py")

        #cmd = [
        #    sys.executable,  # path to Python interpreter
        #    superres_script,
        #    "--input", input_path,
        #    "--output_dir", output_folder,
        #    "--scale", str(scale_factor),

        #]

        print(f"Running command: {' '.join(cmd)}")

        self.process_q_superres = QProcess(self)
        self.process_q_superres.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)

        self.process_q_superres.readyReadStandardOutput.connect(self.read_superres_output)
        self.process_q_superres.finished.connect(self.superres_finished)

        self.process_q_superres.start(cmd[0], cmd[1:])

        self.wait_dialog = WaitDialog(self)
        self.wait_dialog.setWindowTitle("Super Resolution Running...")
        self.wait_dialog.cancelled.connect(self.on_wait_cancelled_superres)
        self.wait_dialog.show()


    def read_superres_output(self):
        output = self.process_q_superres.readAllStandardOutput().data().decode("utf-8", errors="replace")
        
        # Check for progress lines explicitly
        for line in output.splitlines():
            if line.startswith("PROGRESS:"):
                try:
                    progress_pct = int(line.split(":")[1].strip().replace('%', ''))
                    self.wait_dialog.set_progress(progress_pct)  # Assuming WaitDialog has set_progress()
                except ValueError:
                    pass  # Invalid progress line, skip
            else:
                self.wait_dialog.append_output(line)


    def superres_finished(self, exitCode, exitStatus):
        self.wait_dialog.close()
        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Super Resolution failed with exit code {exitCode}.")
            return

        scale_str = self.scale_dropdown.currentText()
        base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        suffix = f"_upscaled{scale_str}"
        output_file_glob = os.path.join(output_folder, base_filename + suffix + ".fit")

        matching_files = glob.glob(output_file_glob)
        if matching_files:
            output_file_path = matching_files[0]
            # Load and display the result
            final_img, hdr, bd, mono = load_image(output_file_path)
            if final_img is not None:
                self.show_image(final_img)
                self.store_processed_image(final_img)
                QMessageBox.information(self, "Success", "Super Resolution completed successfully.")
                self.cleanup_files(os.path.join(self.cosmic_clarity_folder, "input", base_filename + ".tif"), output_file_path)
            else:
                QMessageBox.warning(self, "Error", "Failed to load Super Resolution image.")
        else:
            QMessageBox.warning(self, "Error", "Output file not found.")

    def on_wait_cancelled_superres(self):
        if hasattr(self, 'process_q_superres'):
            self.process_q_superres.kill()
            QMessageBox.information(self, "Cancelled", "Super Resolution cancelled.")


    def _execute_cosmic_clarity(self, mode, output_suffix):
        if self.loaded_image_path is None:
            print("Warning: loaded_image_path is None. Using default base filename 'image'.")
            base_filename = "image"
        else:
            base_filename = os.path.splitext(os.path.basename(self.loaded_image_path))[0]
        print(f"Base filename before saving: {base_filename}")  # Debug print
        """Execute a single Cosmic Clarity operation."""
        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")


        # Save the current previewed image directly to the input folder
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")
        self.save_input_image(input_file_path)  # Save as `.tif`
        self.current_input_file_path = input_file_path

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.tif")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Use QProcess instead of subprocess
        self.process_q = QProcess(self)
        self.process_q.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q.readyReadStandardOutput.connect(self.qprocess_output_main)
        self.process_q.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished(mode, exitCode, exitStatus))

        # Start the process
        self.process_q.setProgram(exe_path)
        self.process_q.setArguments(args)
        self.process_q.start()

        if not self.process_q.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Set up file waiting worker and wait dialog
        self.wait_thread = WaitForFileWorker(output_file_glob, timeout=3000)
        self.wait_thread.fileFound.connect(self.on_file_found)
        self.wait_thread.error.connect(self.on_file_error)
        self.wait_thread.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog = WaitDialog(self)
        self.wait_dialog.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog.show()

        self.wait_thread.start()


    ########################################
    # Below are the new helper slots (methods) to handle signals from worker and dialog.
    ########################################

    def qprocess_output(self):
        if not hasattr(self, 'process_q_cropped') or self.process_q_cropped is None:
            return
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)

    def qprocess_output_main(self):
        """Handle output from the main Cosmic Clarity process."""
        output = self.process_q.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog') and self.wait_dialog:
                        self.wait_dialog.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog') and self.wait_dialog:
                    self.wait_dialog.append_output(line)


    def qprocess_output_cropped(self):
        """Handle output from the cropped Cosmic Clarity process."""
        output = self.process_q_cropped.readAllStandardOutput().data().decode("utf-8", errors="replace")
        for line in output.splitlines():
            line = line.strip()
            if not line:
                continue

            if line.startswith("Progress:"):
                # Extract the percentage and update the progress bar
                parts = line.split()
                percentage_str = parts[1].replace("%", "")
                try:
                    percentage = float(percentage_str)
                    if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                        self.wait_dialog_cropped.progress_bar.setValue(int(percentage))
                except ValueError:
                    pass
            else:
                # Append all other lines to the text box
                if hasattr(self, 'wait_dialog_cropped') and self.wait_dialog_cropped:
                    self.wait_dialog_cropped.append_output(line)


    def qprocess_finished(self, mode, exitCode, exitStatus):
        """Handle process completion for a specific mode."""

        
        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")

        


    def read_process_output(self):
        """Read output from the process and display it in the wait_dialog's text edit."""
        if self.process is None:
            return

        # Read all available lines from stdout
        while True:
            line = self.process.stdout.readline()
            if not line:
                break
            line = line.strip()
            if line:
                # Append the line to the wait_dialog's output text
                self.wait_dialog.append_output(line)

        # Check if process has finished
        if self.process.poll() is not None:
            # Process ended
            self.output_timer.stop()
            # You can handle any cleanup here if needed

    def on_file_found(self, output_file_path):
        print(f"File found: {output_file_path}")
        self.wait_dialog.close()
        self.wait_thread = None

        if getattr(self, 'is_cropped_mode', False):
            # Existing Cropped Mode handling
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                print(f"[ERROR] Failed to load cropped image from {output_file_path}")
                QMessageBox.critical(self, "Error", f"Failed to load cropped image from {output_file_path}.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Apply autostretch if requested
            if getattr(self, 'cropped_apply_autostretch', False):
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to update preview dialog: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update preview dialog:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup with known paths
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tiff")
            self.cleanup_files(input_file_path, output_file_path)

            # Reset cropped mode
            self.is_cropped_mode = False

            # Re-enable Execute button
            self.execute_button.setEnabled(True)
        else:
            # Normal mode logic
            processed_image_path = output_file_path
            self.loaded_image_path = processed_image_path

            # Attempt to load the image with retries
            processed_image, original_header, bit_depth, is_mono = self.load_image_with_retry(processed_image_path)
            if processed_image is None:
                QMessageBox.critical(self, "Error", f"Failed to load image from {processed_image_path} after multiple attempts.")
                print(f"[ERROR] Failed to load image from {processed_image_path} after multiple attempts.")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Show the processed image
            try:
                self.show_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Exception occurred while showing image: {e}")
                QMessageBox.critical(self, "Error", f"Exception occurred while showing image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Store the image in memory
            try:
                self.store_processed_image(processed_image)
            except Exception as e:
                print(f"[ERROR] Failed to store processed image: {e}")
                QMessageBox.critical(self, "Error", f"Failed to store processed image:\n{e}")
                self.execute_button.setEnabled(True)  # Re-enable Execute button
                return

            # Cleanup input and output files
            input_file_path = self.current_input_file_path
            self.cleanup_files(input_file_path, processed_image_path)

            # Check if there are more operations queued
            if hasattr(self, 'operation_queue') and self.operation_queue:
                next_mode, next_suffix = self.operation_queue.pop(0)
                self._execute_cosmic_clarity(next_mode, next_suffix)


    def qprocess_finished_on_cropped(self, mode, exitCode, exitStatus, apply_autostretch):
        """Handle process completion for a specific cropped mode."""
        print(f"Process finished for {mode} operation with exit code {exitCode} and exit status {exitStatus}.")

        if exitCode != 0:
            QMessageBox.critical(self, "Error", f"Cosmic Clarity {mode} process failed with exit code {exitCode}.")


        self.wait_dialog_cropped.close()
        print("WaitDialog_cropped closed.")



    def on_file_found_on_cropped(self, output_file_path, mode, apply_autostretch):
        print(f"File found for cropped {mode} operation: {output_file_path}")
        
        try:
            # Load the processed cropped image
            processed_image, _, _, _ = load_image(output_file_path)
            if processed_image is None:
                raise ValueError(f"Failed to load cropped image from {output_file_path}")
            print("Processed image loaded successfully.")

            # Apply autostretch if requested
            if apply_autostretch:
                if self.is_mono:
                    stretched_mono = stretch_mono_image(processed_image[:, :, 0], target_median=0.25)
                    processed_image = np.stack([stretched_mono] * 3, axis=-1)
                    print("Autostretch applied to mono image.")
                else:
                    processed_image = stretch_color_image(processed_image, target_median=0.25, linked=False)
                    print("Autostretch applied to color image.")

            # Update the preview dialog
            try:
                self.preview_dialog.display_qimage(processed_image)
                print("Preview dialog updated with processed image.")
            except Exception as e:
                raise RuntimeError(f"Failed to update preview dialog: {e}")

            # Cleanup input and output files with correct extension
            input_file_path = os.path.join(self.cosmic_clarity_folder, "input", "cropped_preview_image.tif")
            self.cleanup_files(input_file_path, output_file_path)
            print("Input and output files cleaned up.")

            # Reset cropped mode flags if necessary
            self.is_cropped_mode = False
            print("Cropped mode flags reset.")

            # Check if there are more operations queued
            if self.cropped_operation_queue:
                next_mode, next_suffix = self.cropped_operation_queue.pop(0)
                print(f"Proceeding to next operation: {next_mode} with suffix {next_suffix}.")
                # Execute the next operation
                self._execute_cosmic_clarity_on_cropped(next_mode, next_suffix, processed_image, apply_autostretch)

        except Exception as e:
            print(f"[ERROR] {e}")
            QMessageBox.critical(self, "Error", f"An error occurred: {e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button




    def on_file_error(self, msg):
        # File not found in time
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.critical(self, "Error", msg)


    def on_file_cancelled(self):
        # The worker was stopped before finding a file
        self.wait_dialog.close()
        self.wait_thread = None
        QMessageBox.information(self, "Cancelled", "File waiting was cancelled.")


    def on_wait_cancelled(self):
        # If we have a QProcess reference, terminate it
        if hasattr(self, 'process_q') and self.process_q is not None:
            self.process_q.kill()  # or self.process_q.terminate()

        QMessageBox.information(self, "Cancelled", "Operation was cancelled by the user.")




    def run_cosmic_clarity_on_cropped(self, cropped_image, apply_autostretch=False):
        """Run Cosmic Clarity on a cropped image, with an option to autostretch upon receipt."""

        if not self.validate_cosmic_clarity_folder():
            return  # Stop execution if the folder is not valid

        if cropped_image is None:  # Ensure a cropped image is provided
            QMessageBox.warning(self, "Warning", "No cropped image provided.")
            return

        # Convert the cropped image to 32-bit floating point format
        cropped_image_32bit = cropped_image.astype(np.float32) / np.max(cropped_image)  # Normalize if needed

        # Determine mode and suffix based on the selected radio button
        if self.both_radio.isChecked():
            modes = ["sharpen", "denoise"]
            output_suffixes = ["_sharpened", "_denoised"]
        elif self.sharpen_radio.isChecked():
            modes = ["sharpen"]
            output_suffixes = ["_sharpened"]
        elif self.denoise_radio.isChecked():
            modes = ["denoise"]
            output_suffixes = ["_denoised"]
        else:
            QMessageBox.warning(self, "Warning", "Please select an operation mode.")
            return

        # Initialize a queue to handle sequential operations
        self.cropped_operation_queue = list(zip(modes, output_suffixes))

 
        # Start the first operation
        if self.cropped_operation_queue:
            self._execute_cosmic_clarity_on_cropped(*self.cropped_operation_queue.pop(0), cropped_image_32bit, apply_autostretch)


    def _execute_cosmic_clarity_on_cropped(self, mode, output_suffix, cropped_image_32bit, apply_autostretch):
        """Execute a single Cosmic Clarity operation on a cropped image."""
        print(f"Starting '{mode}' operation with suffix '{output_suffix}'.")

        # Determine the correct executable name based on platform and mode
        if os.name == 'nt':
            # Windows
            if mode == "sharpen":
                exe_name = "SetiAstroCosmicClarity.exe"
            else:
                exe_name = "SetiAstroCosmicClarity_denoise.exe"
        else:
            # macOS or Linux (posix)
            if sys.platform == "darwin":
                # macOS
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClaritymac"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoisemac"
            else:
                # Linux
                if mode == "sharpen":
                    exe_name = "SetiAstroCosmicClarity"
                else:
                    exe_name = "SetiAstroCosmicClarity_denoise"

        # Define paths for input and output
        input_folder = os.path.join(self.cosmic_clarity_folder, "input")
        output_folder = os.path.join(self.cosmic_clarity_folder, "output")
        base_filename = "cropped_preview_image"  # Using a fixed name for cropped images
        input_file_path = os.path.join(input_folder, f"{base_filename}.tif")  # Changed to .tif

        # Ensure input and output directories exist
        os.makedirs(input_folder, exist_ok=True)
        os.makedirs(output_folder, exist_ok=True)

        # Save the 32-bit floating-point cropped image to the input folder
        try:
            save_image(cropped_image_32bit, input_file_path, "tiff", "32-bit floating point", self.original_header, self.is_mono)
            print(f"Saved cropped image to input path: {input_file_path}")
        except Exception as e:
            print(f"[ERROR] Failed to save cropped image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to save cropped image:\n{e}")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Construct the expected output file glob
        output_file_glob = os.path.join(output_folder, f"{base_filename}{output_suffix}.*")
        print(f"Waiting for output file matching: {output_file_glob}")  # Debug print

        # Check if the executable exists
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}. Please use the wrench icon to select the correct folder.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        # Build command arguments
        cmd = self.build_command_args(exe_name, mode)
        exe_path = cmd[0]
        args = cmd[1:]  # Separate the executable from its arguments
        print(f"Running command: {exe_path} {' '.join(args)}")  # Debug print

        # Initialize QProcess
        self.process_q_cropped = QProcess(self)
        self.process_q_cropped.setProcessChannelMode(QProcess.ProcessChannelMode.MergedChannels)  # Combine stdout/stderr

        # Connect signals
        self.process_q_cropped.readyReadStandardOutput.connect(self.qprocess_output_cropped)
        self.process_q_cropped.finished.connect(lambda exitCode, exitStatus: self.qprocess_finished_on_cropped(mode, exitCode, exitStatus, apply_autostretch))

        # Start the process
        self.process_q_cropped.setProgram(exe_path)
        self.process_q_cropped.setArguments(args)
        self.process_q_cropped.start()

        if not self.process_q_cropped.waitForStarted(3000):
            QMessageBox.critical(self, "Error", f"Failed to start the Cosmic Clarity {mode} process.")
            self.execute_button.setEnabled(True)  # Re-enable Execute button
            return

        print(f"Started Cosmic Clarity process for mode '{mode}'.")

        # Set up file waiting worker and wait dialog
        self.wait_thread_cropped = WaitForFileWorker(output_file_glob, timeout=1800)
        self.wait_thread_cropped.fileFound.connect(lambda path: self.on_file_found_on_cropped(path, mode, apply_autostretch))
        self.wait_thread_cropped.error.connect(self.on_file_error)
        self.wait_thread_cropped.cancelled.connect(self.on_file_cancelled)

        self.wait_dialog_cropped = WaitDialog(self)
        self.wait_dialog_cropped.cancelled.connect(self.on_wait_cancelled)
        self.wait_dialog_cropped.setWindowModality(Qt.WindowModality.NonModal)
        self.wait_dialog_cropped.show()

        self.wait_thread_cropped.start()
        print("WaitDialog_cropped displayed and WaitForFileWorker started.")


    def build_command_args(self, exe_name, mode):
        """Build the command line arguments for Cosmic Clarity without using a batch file."""
        # exe_name is now fully resolved (including .exe on Windows if needed)
        exe_path = os.path.join(self.cosmic_clarity_folder, exe_name)
        cmd = [exe_path]

        # Add sharpening or denoising arguments
        if mode == "sharpen":
            psf_value = self.get_psf_value()
            cmd += [
                "--sharpening_mode", self.sharpen_mode_dropdown.currentText(),
                "--stellar_amount", f"{self.stellar_amount_slider.value() / 100:.2f}",
                "--nonstellar_strength", f"{psf_value:.1f}",
                "--nonstellar_amount", f"{self.nonstellar_amount_slider.value() / 100:.2f}"
            ]
            if self.sharpen_channels_dropdown.currentText() == "Yes":
                cmd.append("--sharpen_channels_separately")
            if self.auto_detect_psf_checkbox.isChecked():
                cmd.append("--auto_detect_psf")

        elif mode == "denoise":
            cmd += [
                "--denoise_strength", f"{self.denoise_strength_slider.value() / 100:.2f}",
                "--color_denoise_strength", f"{self.color_denoise_strength_slider.value() / 100:.2f}",  # NEW
                "--denoise_mode", self.denoise_mode_dropdown.currentText()
            ]
            if self.denoise_separate_checkbox.isChecked():
                cmd.append("--separate_channels")           

        # GPU option
        if self.gpu_dropdown.currentText() == "No":
            cmd.append("--disable_gpu")

        return cmd

    def save_processed_image(self):
        """Save the current displayed image as the processed image."""
        self.processed_image = self.image.copy()


    def save_processed_image_to_disk(self):
        """Save the processed image to disk, using the correct format, bit depth, and header information."""
        if self.processed_image is None:
            QMessageBox.warning(self, "Warning", "No processed image to save.")
            return

        # Prompt user for the file path and format

        save_path, _ = QFileDialog.getSaveFileName(
            self, "Save Processed Image", "", 
            "TIFF Files (*.tif *.tiff);;PNG Files (*.png);;FITS Files (*.fits *.fit)"

        )
        
        if not save_path:
            return  # User cancelled the save dialog

        # Determine the format based on file extension
        _, file_extension = os.path.splitext(save_path)
        file_extension = file_extension.lower().lstrip('.')
        original_format = file_extension if file_extension in ['tiff', 'tif', 'png', 'fits', 'fit'] else 'tiff'

        # Call the save_image function with the necessary parameters
        try:
            save_image(
                img_array=self.processed_image,
                filename=save_path,
                original_format=original_format,
                bit_depth=self.bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            QMessageBox.information(self, "Success", f"Image saved successfully at: {save_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

    def load_image_with_retry(self, file_path, retries=5, delay=2):
        """
        Attempts to load an image multiple times with delays between attempts.

        :param file_path: Path to the image file.
        :param retries: Number of retry attempts.
        :param delay: Delay between retries in seconds.
        :return: Tuple of (image_array, original_header, bit_depth, is_mono) or (None, None, None, None) if failed.
        """

        for attempt in range(1, retries + 1):
            image, original_header, bit_depth, is_mono = load_image(file_path)
            if image is not None:

                return image, original_header, bit_depth, is_mono
            else:
                print(f"[WARNING] Attempt {attempt} failed to load image. Retrying in {delay} seconds...")
                time.sleep(delay)
        print("[ERROR] All attempts to load the image failed.")
        return None, None, None, None


    def wait_for_output_file(self, output_file_glob, timeout=3000, check_interval=1, stable_checks=3):
        """
        Wait for the output file with any extension within the specified timeout.
        Ensures the file size remains constant over a series of checks to confirm it's fully written.

        :param output_file_glob: Glob pattern to match the output file.
        :param timeout: Maximum time to wait in seconds.
        :param check_interval: Time between size checks in seconds.
        :param stable_checks: Number of consecutive checks with the same size.
        :return: Path to the output file or None if not found.
        """
        start_time = time.time()
        last_size = -1
        stable_count = 0

        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                current_size = os.path.getsize(matching_files[0])
                if current_size == last_size:
                    stable_count += 1
                    if stable_count >= stable_checks:
                        print(f"Output file found and stable: {matching_files[0]}")
                        return matching_files[0]
                else:
                    stable_count = 0
                    last_size = current_size
            time.sleep(check_interval)
        
        print("Timeout reached. Output file not found or not stable.")
        return None

    def display_image(self, file_path):
        """Load and display the output image."""
        self.image, self.original_header, self.bit_depth, self.is_mono = load_image(file_path)
        self.display_image()  # Update display with the new image

    def cleanup_files(self, input_file_path, output_file_path):
        """Delete input and output files after processing."""
        try:
            if input_file_path and os.path.exists(input_file_path):
                os.remove(input_file_path)
                print(f"Deleted input file: {input_file_path}")
            else:
                print(f"Input file not found, skipping deletion: {input_file_path}")

            if output_file_path and os.path.exists(output_file_path):
                os.remove(output_file_path)
                print(f"Deleted output file: {output_file_path}")
            else:
                print(f"Output file not found, skipping deletion: {output_file_path}")
        except Exception as e:
            print(f"Failed to delete files: {e}")

class PreviewDialog(QDialog):
    def __init__(self, np_image, parent_tab=None, is_mono=False):
        super().__init__(parent=parent_tab)
        self.setWindowTitle("Select Preview Area")
        self.setWindowFlags(self.windowFlags() | Qt.WindowType.WindowContextHelpButtonHint | Qt.WindowType.MSWindowsFixedSizeDialogHint)
        self.setFixedSize(640, 480)  # Fix the size to 640x480
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag

        # Store the 32-bit numpy image for reference
        self.np_image = np_image
        self.original_np_image = np_image.copy()  # Copy to allow undo
        self.parent_tab = parent_tab
        # Track saved scroll positions for Undo
        self.saved_h_scroll = 0
        self.saved_v_scroll = 0        

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch button
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        layout.addWidget(self.autostretch_button)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Add the Process Visible Area and Undo buttons
        button_layout = QHBoxLayout()
        
        self.process_button = QPushButton("Process Visible Area")
        self.process_button.clicked.connect(self.process_visible_area)
        button_layout.addWidget(self.process_button)

        self.undo_button = QPushButton("Undo")
        self.undo_button.clicked.connect(self.undo_last_process)
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))
        button_layout.addWidget(self.undo_button)

        layout.addLayout(button_layout)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set
                
        # Enable What's This functionality
        self.setWhatsThis(
            "Instructions:\n\n"
            "1. Use the scroll bars to center on the area of the image you want to preview.\n"
            "2. Click and drag to move around the image.\n"
            "3. When ready, click the 'Process Visible Area' button to process the selected section."
        )

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at 100% scale."""
        # Ensure the numpy array is scaled to [0, 255] and converted to uint8
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)
        
        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Display the QImage at 100% scale in QLabel
        self.image_label.setPixmap(QPixmap.fromImage(qimage))
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            # Check the dimensions of self.np_image instead of relying on is_mono.
            if self.np_image.ndim < 3:
                # 2D array: grayscale image.
                try:
                    stretched = stretch_mono_image(self.np_image, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)  # Convert to RGB for display.
                except Exception as e:
                    print(f"[ERROR] Failed to stretch mono image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 1:
                # 3D array but with one channel.
                try:
                    mono = np.squeeze(self.np_image, axis=-1)
                    stretched = stretch_mono_image(mono, target_median)
                    display_image = np.stack([stretched] * 3, axis=-1)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch single-channel image: {e}")
                    return
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 3:
                # Color image.
                try:
                    display_image = stretch_color_image(self.np_image, target_median, linked=False)
                except Exception as e:
                    print(f"[ERROR] Failed to stretch color image: {e}")
                    return
            else:
                print("[ERROR] Unexpected image shape during autostretch!")
                return
        else:
            display_image = self.np_image  # Use original image if autostretch is off

        # Convert and display the QImage.
        self.display_qimage(display_image)



    def undo_last_process(self):
        """Revert to the original image in the preview, respecting the autostretch setting."""
        print("Undo last process")
        
        # Reset to the original image
        self.np_image = self.original_np_image.copy()
        
        # Apply autostretch if it is enabled
        if self.autostretch_enabled:
            print("Applying autostretch on undo")
            self.apply_autostretch()
        else:
            # Display the original image without autostretch
            self.display_qimage(self.np_image)
        
        # Restore saved scroll positions with a slight delay
        QTimer.singleShot(0, self.restore_scrollbars)
        print("Scrollbars will be restored to saved positions")


    def restore_scrollbars(self):
        """Restore the scrollbars to the saved positions after a delay."""
        self.scroll_area.horizontalScrollBar().setValue(self.saved_h_scroll)
        self.scroll_area.verticalScrollBar().setValue(self.saved_v_scroll)
        print("Scrollbars restored to saved positions")
   
    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        # Set the horizontal and vertical scrollbar positions to center
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def process_visible_area(self):
        print("Process Visible Area button pressed")  # Initial debug print to confirm button press

        """Crop the image to the visible area and send it to CosmicClarityTab for processing."""

        self.saved_h_scroll = self.scroll_area.horizontalScrollBar().value()
        self.saved_v_scroll = self.scroll_area.verticalScrollBar().value()

        # Calculate the visible area in the original image coordinates
        h_scroll = self.scroll_area.horizontalScrollBar().value()
        v_scroll = self.scroll_area.verticalScrollBar().value()
        visible_rect = QRect(h_scroll, v_scroll, 640, 480)  # 640x480 fixed size
        print(f"Visible area rectangle: {visible_rect}")  # Debug print to confirm visible area coordinates

        # Crop the numpy image array directly using slicing
        if len(self.np_image.shape) == 2:  # Mono image (2D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
            ]
            # Convert cropped mono image to RGB for consistent handling
            cropped_np_image = np.stack([cropped_np_image] * 3, axis=-1)
        elif len(self.np_image.shape) == 3:  # Color image (3D array)
            cropped_np_image = self.np_image[
                v_scroll : v_scroll + visible_rect.height(),
                h_scroll : h_scroll + visible_rect.width(),
                :
            ]
        else:
            print("Error: Unsupported image format")
            return

        if cropped_np_image is None:
            print("Error: Failed to crop numpy image")  # Debug if cropping failed
        else:
            print("Image cropped successfully")  # Debug print to confirm cropping

        # Pass the cropped image to CosmicClarityTab for processing
        if self.parent_tab:
            print("Sending to parent class for processing")  # Debug print before sending to parent
            self.parent_tab.run_cosmic_clarity_on_cropped(cropped_np_image, apply_autostretch=self.autostretch_enabled)
        else:
            print("Error: Failed to send to parent class")  # Debug if parent reference is missing


    def convert_qimage_to_numpy(self, qimage):
        """Convert QImage to a 32-bit float numpy array, preserving the 32-bit precision."""
        qimage = qimage.convertToFormat(QImage.Format.Format_RGB888)
        
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 3)
        
        arr = np.frombuffer(ptr, dtype=np.uint8).reshape((height, width, 3)).astype(np.float32) / 255.0
        return arr

    def closeEvent(self, event):
        """Handle dialog close event if any cleanup is necessary."""
        self.dragging = False
        event.accept()

class WaitDialog(QDialog):
    cancelled = pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Processing...")
        
        self.layout = QVBoxLayout()
        
        self.label = QLabel("Processing, please wait...")
        self.layout.addWidget(self.label)
        
        # Add a QTextEdit to show process output
        self.output_text_edit = QTextEdit()
        self.output_text_edit.setReadOnly(True)
        self.layout.addWidget(self.output_text_edit)

        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.layout.addWidget(self.progress_bar)

        cancel_button = QPushButton("Cancel")
        cancel_button.clicked.connect(self.cancelled.emit)
        self.layout.addWidget(cancel_button)
        
        self.setLayout(self.layout)

    def append_output(self, text):
        self.output_text_edit.append(text)

    def set_progress(self, pct):
        self.progress_bar.setValue(pct)        

class WaitForFileWorker(QThread):
    fileFound = pyqtSignal(str)
    cancelled = pyqtSignal()
    error = pyqtSignal(str)

    def __init__(self, output_file_glob, timeout=1800, parent=None):
        super().__init__(parent)
        self.output_file_glob = output_file_glob
        self.timeout = timeout
        self._running = True

    def run(self):
        start_time = time.time()
        while self._running and (time.time() - start_time < self.timeout):
            matching_files = glob.glob(self.output_file_glob)

            if matching_files:
                self.fileFound.emit(matching_files[0])
                return
            time.sleep(1)
        if self._running:
            self.error.emit("Output file not found within timeout.")
        else:
            self.cancelled.emit()

    def stop(self):
        self._running = False

class CosmicClaritySatelliteTab(QWidget):
    def __init__(self):
        super().__init__()
        self.cosmic_clarity_folder = None
        self.input_folder = None
        self.output_folder = None
        self.settings_file = "cosmic_clarity_satellite_folder.txt"
        self.file_watcher = QFileSystemWatcher()  # Watcher for input and output folders
        self.file_watcher.directoryChanged.connect(self.on_folder_changed)  # Connect signal
        self.sensitivity = 0.1
        self.settings = QSettings() 
        self.initUI()
        self.load_cosmic_clarity_folder()

    def initUI(self):
        # Main horizontal layout
        main_layout = QHBoxLayout()

        # Left layout for controls and settings
        left_layout = QVBoxLayout()

        # Input/Output Folder Selection in a Horizontal Sizer
        folder_layout = QHBoxLayout()
        self.input_folder_button = QPushButton("Select Input Folder")
        self.input_folder_button.clicked.connect(self.select_input_folder)
        self.output_folder_button = QPushButton("Select Output Folder")
        self.output_folder_button.clicked.connect(self.select_output_folder)
        folder_layout.addWidget(self.input_folder_button)
        folder_layout.addWidget(self.output_folder_button)
        left_layout.addLayout(folder_layout)

        # GPU Acceleration
        self.gpu_label = QLabel("Use GPU Acceleration:")
        left_layout.addWidget(self.gpu_label)
        self.gpu_dropdown = QComboBox()
        self.gpu_dropdown.addItems(["Yes", "No"])
        left_layout.addWidget(self.gpu_dropdown)

        # Removal Mode
        self.mode_label = QLabel("Satellite Removal Mode:")
        left_layout.addWidget(self.mode_label)
        self.mode_dropdown = QComboBox()
        self.mode_dropdown.addItems(["Full", "Luminance"])
        left_layout.addWidget(self.mode_dropdown)

        # Clip Trail
        self.clip_trail_checkbox = QCheckBox("Clip Satellite Trail to 0.000")
        self.clip_trail_checkbox.setChecked(True)
        left_layout.addWidget(self.clip_trail_checkbox)

        # **Add Sensitivity Slider**
        sensitivity_layout = QHBoxLayout()
        sensitivity_label = QLabel("Clipping Sensitivity (Lower Values more Aggressive Clipping):")
        sensitivity_layout.addWidget(sensitivity_label)

        self.sensitivity_slider = QSlider(Qt.Orientation.Horizontal)
        self.sensitivity_slider.setMinimum(1)    # Represents 0.01
        self.sensitivity_slider.setMaximum(50)   # Represents 0.5
        self.sensitivity_slider.setValue(int(self.sensitivity * 100))  # e.g., 0.1 * 100 = 10
        self.sensitivity_slider.setTickInterval(1)
        self.sensitivity_slider.setTickPosition(QSlider.TickPosition.TicksBelow)
        self.sensitivity_slider.valueChanged.connect(self.update_sensitivity)
        sensitivity_layout.addWidget(self.sensitivity_slider)

        # Label to display current sensitivity value
        self.sensitivity_value_label = QLabel(f"{self.sensitivity:.2f}")
        sensitivity_layout.addWidget(self.sensitivity_value_label)

        left_layout.addLayout(sensitivity_layout)        

        # Skip Save
        self.skip_save_checkbox = QCheckBox("Skip Save if No Satellite Trail Detected")
        self.skip_save_checkbox.setChecked(False)
        left_layout.addWidget(self.skip_save_checkbox)

        # Process Single Image and Batch Process in a Horizontal Sizer
        process_layout = QHBoxLayout()
        self.process_single_button = QPushButton("Process Single Image")
        self.process_single_button.clicked.connect(self.process_single_image)
        process_layout.addWidget(self.process_single_button)

        self.batch_process_button = QPushButton("Batch Process Input Folder")
        self.batch_process_button.clicked.connect(self.batch_process_folder)
        process_layout.addWidget(self.batch_process_button)
        left_layout.addLayout(process_layout)

        # Live Monitor
        self.live_monitor_button = QPushButton("Live Monitor Input Folder")
        self.live_monitor_button.clicked.connect(self.live_monitor_folder)
        left_layout.addWidget(self.live_monitor_button)

        # Folder Selection
        self.folder_label = QLabel("No folder selected")
        left_layout.addWidget(self.folder_label)
        self.wrench_button = QPushButton()
        self.wrench_button.setIcon(QIcon(wrench_path))  # Ensure the icon is available
        self.wrench_button.clicked.connect(self.select_cosmic_clarity_folder)
        left_layout.addWidget(self.wrench_button)


        # Right layout for TreeBoxes
        right_layout = QVBoxLayout()

        # Input Files TreeBox
        input_files_label = QLabel("Input Folder Files:")
        right_layout.addWidget(input_files_label)
        self.input_files_tree = QTreeWidget()
        self.input_files_tree.setHeaderLabels(["Filename"])
        self.input_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.input_files_tree))
        self.input_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.input_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.input_files_tree, pos))
        right_layout.addWidget(self.input_files_tree)

        # Output Files TreeBox
        output_files_label = QLabel("Output Folder Files:")
        right_layout.addWidget(output_files_label)
        self.output_files_tree = QTreeWidget()
        self.output_files_tree.setHeaderLabels(["Filename"])
        self.output_files_tree.itemDoubleClicked.connect(lambda: self.preview_image(self.output_files_tree))
        self.output_files_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.output_files_tree.customContextMenuRequested.connect(lambda pos: self.show_context_menu(self.output_files_tree, pos))
        right_layout.addWidget(self.output_files_tree)


        # Add the left and right layouts to the main layout
        main_layout.addLayout(left_layout, stretch=2)  # More space for the left layout
        main_layout.addLayout(right_layout, stretch=1)  # Less space for the right layout

        self.setLayout(main_layout)

    def update_sensitivity(self, value):
        """
        Update the sensitivity value based on the slider's position.
        """
        self.sensitivity = value / 100.0  # Convert from integer to float (0.01 to 0.5)
        self.sensitivity_value_label.setText(f"{self.sensitivity:.2f}")  # Update label





    def preview_image(self, treebox):
        """Preview the selected image."""
        selected_item = treebox.currentItem()
        if selected_item:
            file_path = os.path.join(self.input_folder if treebox == self.input_files_tree else self.output_folder, selected_item.text(0))
            if os.path.isfile(file_path):
                try:
                    image, _, _, is_mono = load_image(file_path)
                    if image is not None:
                        self.current_preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)  # Store reference
                        self.current_preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure cleanup on close
                        self.current_preview_dialog.show()  # Open non-blocking dialog
                    else:
                        QMessageBox.critical(self, "Error", "Failed to load image for preview.")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to preview image: {e}")


    def open_preview_dialog(self, image, is_mono):
        """Open the preview dialog."""
        preview_dialog = ImagePreviewDialog(image, is_mono=is_mono)
        preview_dialog.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose)  # Ensure proper cleanup when closed
        preview_dialog.show()  # Open the dialog without blocking the main UI





    def show_context_menu(self, treebox, pos):
        """Show context menu for the treebox."""
        menu = QMenu()
        delete_action = QAction("Delete File")
        rename_action = QAction("Rename File")
        delete_action.triggered.connect(lambda: self.delete_file(treebox))
        rename_action.triggered.connect(lambda: self.rename_file(treebox))
        menu.addAction(delete_action)
        menu.addAction(rename_action)
        menu.exec(treebox.viewport().mapToGlobal(pos))

    def delete_file(self, treebox):
        """Delete the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            if os.path.exists(file_path):
                reply = QMessageBox.question(self, "Confirm Delete", f"Are you sure you want to delete {selected_item.text(0)}?",
                                             QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No, QMessageBox.StandardButton.No)
                if reply == QMessageBox.StandardButton.Yes:
                    os.remove(file_path)
                    self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def rename_file(self, treebox):
        """Rename the selected file."""
        selected_item = treebox.currentItem()
        if selected_item:
            folder = self.input_folder if treebox == self.input_files_tree else self.output_folder
            file_path = os.path.join(folder, selected_item.text(0))
            new_name, ok = QInputDialog.getText(self, "Rename File", "Enter new name:", text=selected_item.text(0))
            if ok and new_name:
                new_path = os.path.join(folder, new_name)
                os.rename(file_path, new_path)
                self.refresh_input_files() if treebox == self.input_files_tree else self.refresh_output_files()

    def refresh_input_files(self):
        """Populate the input TreeBox with files from the input folder."""
        self.input_files_tree.clear()
        if not self.input_folder:
            return
        for file_name in os.listdir(self.input_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.input_files_tree, [file_name])

    def refresh_output_files(self):
        """Populate the output TreeBox with files from the output folder."""
        self.output_files_tree.clear()
        if not self.output_folder:
            return
        for file_name in os.listdir(self.output_folder):
            if file_name.lower().endswith(('.png', '.tif', '.tiff', '.fit', '.fits', '.xisf', '.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                QTreeWidgetItem(self.output_files_tree, [file_name])



    def select_input_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Input Folder")
        if folder:
            self.input_folder = folder
            self.input_folder_button.setText(f"Input Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_input_files()

    def select_output_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Output Folder")
        if folder:
            self.output_folder = folder
            self.output_folder_button.setText(f"Output Folder: {os.path.basename(folder)}")
            self.file_watcher.addPath(folder)  # Add folder to watcher
            self.refresh_output_files()

    def on_folder_changed(self, path):
        """Refresh the TreeBox when files are added or removed from the watched folder."""
        if path == self.input_folder:
            self.refresh_input_files()
        elif path == self.output_folder:
            self.refresh_output_files()


    def select_cosmic_clarity_folder(self):
        folder = QFileDialog.getExistingDirectory(self, "Select Cosmic Clarity Folder")
        if folder:
            self.cosmic_clarity_folder = folder
            self.settings.setValue("cosmic_clarity_folder", folder)  # Save to QSettings
            self.folder_label.setText(f"Folder: {folder}")
            print(f"Selected Cosmic Clarity folder: {folder}")

    def load_cosmic_clarity_folder(self):
        folder = self.settings.value("cosmic_clarity_folder", "")  # Load from QSettings
        if folder:
            self.cosmic_clarity_folder = folder
            self.folder_label.setText(f"Folder: {folder}")
            #print(f"Loaded Cosmic Clarity folder: {folder}")
        else:
            print("No saved Cosmic Clarity folder found.")

    def process_single_image(self):
        # Step 1: Open File Dialog to Select Image
        file_path, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Image", 
            "", 
            "Image Files (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef)"
        )
        if not file_path:
            QMessageBox.warning(self, "Warning", "No file selected.")
            return

        # Create temp input and output folders
        temp_input = self.create_temp_folder()
        temp_output = self.create_temp_folder()

        # Copy the selected file to the temp input folder
        shutil.copy(file_path, temp_input)

        # Run Cosmic Clarity Satellite Removal Tool
        try:
            self.run_cosmic_clarity_satellite(temp_input, temp_output)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Error processing image: {e}")
            return

        # Locate the processed file in the temp output folder
        processed_file = glob.glob(os.path.join(temp_output, "*_satellited.*"))
        if processed_file:
            # Move the processed file back to the original folder
            original_folder = os.path.dirname(file_path)
            destination_path = os.path.join(original_folder, os.path.basename(processed_file[0]))
            shutil.move(processed_file[0], destination_path)

            # Inform the user
            QMessageBox.information(self, "Success", f"Processed image saved to: {destination_path}")
        else:
            QMessageBox.warning(self, "Warning", "No output file found.")

        # Cleanup temporary folders
        if os.path.exists(temp_input):
            shutil.rmtree(temp_input)
        if os.path.exists(temp_output):
            shutil.rmtree(temp_output)

    def batch_process_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--batch"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Batch processing finished."))
        self.satellite_thread.start()

    def live_monitor_folder(self):
        if not self.input_folder or not self.output_folder:
            QMessageBox.warning(self, "Warning", "Please select both input and output folders.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct the command
        command = [
            exe_path,
            "--input", self.input_folder,
            "--output", self.output_folder,
            "--mode", self.mode_dropdown.currentText().lower(),
            "--monitor"
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])            

        # Run the command in a separate thread
        self.sensitivity_slider.setEnabled(False)
        self.satellite_thread = SatelliteProcessingThread(command)
        self.satellite_thread.finished.connect(lambda: QMessageBox.information(self, "Success", "Live monitoring stopped."))
        self.satellite_thread.finished.connect(lambda:self.sensitivity_slider.setEnabled(True))
        self.satellite_thread.start()

        # **Disable the sensitivity slider**
        


    def on_live_monitor_finished(self):
        """
        Slot to handle actions after live monitoring has finished.
        """
        QMessageBox.information(self, "Live Monitoring", "Live monitoring has been stopped.")
        self.sensitivity_slider.setEnabled(True)

        self.live_monitor_button.setEnabled(True)
        self.stop_monitor_button.setEnabled(False)
        
    @staticmethod
    def create_temp_folder(base_folder="~"):
        """
        Create a temporary folder for processing in the user's directory.
        :param base_folder: Base folder to create the temp directory in (default is the user's home directory).
        :return: Path to the created temporary folder.
        """
        user_dir = os.path.expanduser(base_folder)
        temp_folder = os.path.join(user_dir, "CosmicClarityTemp")
        os.makedirs(temp_folder, exist_ok=True)  # Create the folder if it doesn't exist
        return temp_folder


    def run_cosmic_clarity_satellite(self, input_dir, output_dir, live_monitor=False):
        if not self.cosmic_clarity_folder:
            QMessageBox.warning(self, "Warning", "Please select the Cosmic Clarity folder.")
            return

        exe_name = "setiastrocosmicclarity_satellite"
        exe_path = os.path.join(self.cosmic_clarity_folder, f"{exe_name}.exe") if os.name == 'nt' else os.path.join(self.cosmic_clarity_folder, exe_name)

        # Check if the executable exists
        if not os.path.exists(exe_path):
            QMessageBox.critical(self, "Error", f"Executable not found: {exe_path}")
            return

        # Construct command arguments
        command = [
            exe_path,
            "--input", input_dir,
            "--output", output_dir,
            "--mode", self.mode_dropdown.currentText().lower(),
        ]
        if self.gpu_dropdown.currentText() == "Yes":
            command.append("--use-gpu")
        if self.clip_trail_checkbox.isChecked():
            command.append("--clip-trail")
            print("--clip-trail argument added.")
        else:
            command.append("--no-clip-trail")
            print("--no-clip-trail argument added.")
        if self.skip_save_checkbox.isChecked():
            command.append("--skip-save")
        if live_monitor:
            command.append("--monitor")
        else:
            command.append("--batch")

        # **Add Sensitivity Argument**
        command.extend(["--sensitivity", str(self.sensitivity)])

        # Debugging: Print the command to verify
        print(f"Running command: {' '.join(command)}")

        # Execute the command
        try:
            subprocess.run(command, check=True)
            QMessageBox.information(self, "Success", "Processing complete.")
        except subprocess.CalledProcessError as e:
            QMessageBox.critical(self, "Error", f"Processing failed: {e}")

    def execute_script(self, script_path):
        """Execute the batch or shell script."""
        if os.name == 'nt':  # Windows
            subprocess.Popen(["cmd.exe", "/c", script_path], shell=True)
        else:  # macOS/Linux
            subprocess.Popen(["/bin/sh", script_path], shell=True)

    def wait_for_output_files(self, output_file_glob, timeout=1800):
        """Wait for output files matching the glob pattern within a timeout."""
        start_time = time.time()
        while time.time() - start_time < timeout:
            matching_files = glob.glob(output_file_glob)
            if matching_files:
                time.sleep(2)
                return matching_files
            time.sleep(1)
        return None

class ImagePreviewDialog(QDialog):
    def __init__(self, np_image, is_mono=False):
        super().__init__()
        self.setWindowTitle("Image Preview")
        self.resize(640, 480)  # Set initial size
        self.autostretch_enabled = False  # Autostretch toggle for preview
        self.is_mono = is_mono  # Store is_mono flag
        self.zoom_factor = 1.0  # Track the zoom level

        # Store the 32-bit numpy image for reference
        self.np_image = np_image

        # Set up the layout and the scroll area
        layout = QVBoxLayout(self)

        # Autostretch and Zoom Buttons
        button_layout = QHBoxLayout()
        self.autostretch_button = QPushButton("AutoStretch (Off)")
        self.autostretch_button.setCheckable(True)
        self.autostretch_button.toggled.connect(self.toggle_autostretch)
        button_layout.addWidget(self.autostretch_button)

        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        button_layout.addWidget(self.zoom_in_button)

        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        button_layout.addWidget(self.zoom_out_button)

        layout.addLayout(button_layout)

        # Scroll area for displaying the image
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        layout.addWidget(self.scroll_area)

        # Set up the QLabel to display the image
        self.image_label = QLabel()
        self.display_qimage(self.np_image)  # Display the image with the initial numpy array
        self.scroll_area.setWidget(self.image_label)

        # Set up mouse dragging
        self.dragging = False
        self.drag_start_pos = QPoint()

        # Enable mouse wheel for zooming
        self.image_label.installEventFilter(self)

        # Center the scroll area on initialization
        QTimer.singleShot(0, self.center_scrollbars)  # Delay to ensure layout is set

    def display_qimage(self, np_img):
        """Convert a numpy array to QImage and display it at the current zoom level."""
        display_image_uint8 = (np.clip(np_img, 0, 1) * 255).astype(np.uint8)

        if len(display_image_uint8.shape) == 3 and display_image_uint8.shape[2] == 3:
            # RGB image
            height, width, channels = display_image_uint8.shape
            bytes_per_line = 3 * width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        elif len(display_image_uint8.shape) == 2:
            # Grayscale image
            height, width = display_image_uint8.shape
            bytes_per_line = width
            qimage = QImage(display_image_uint8.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
        else:
            raise ValueError(f"Unexpected image shape: {display_image_uint8.shape}")

        # Apply zoom
        pixmap = QPixmap.fromImage(qimage)
        scaled_width = int(pixmap.width() * self.zoom_factor)  # Convert to integer
        scaled_height = int(pixmap.height() * self.zoom_factor)  # Convert to integer
        scaled_pixmap = pixmap.scaled(scaled_width, scaled_height, Qt.AspectRatioMode.KeepAspectRatio)
        self.image_label.setPixmap(scaled_pixmap)
        self.image_label.adjustSize()


    def toggle_autostretch(self, checked):
        self.autostretch_enabled = checked
        self.autostretch_button.setText("AutoStretch (On)" if checked else "AutoStretch (Off)")
        self.apply_autostretch()

    def apply_autostretch(self):
        """Apply or remove autostretch while maintaining 32-bit precision."""
        print("applying autostretch")
        target_median = 0.25  # Target median for stretching

        if self.autostretch_enabled:
            if self.np_image.ndim == 2:
                # mono stretch path
                stretched = stretch_mono_image(self.np_image, target_median)
                display_image = np.stack([stretched]*3, axis=-1)
            elif self.np_image.ndim == 3 and self.np_image.shape[2] == 3:
                # color stretch path
                display_image = stretch_color_image(self.np_image, target_median, linked=False)
            else:
                raise ValueError(f"Unexpected image shape for autostretch: {self.np_image.shape}")
        else:
            # autostretch off: just show original
            if self.np_image.ndim == 2:
                display_image = np.stack([self.np_image]*3, axis=-1)
            else:
                display_image = self.np_image


        print(f"Debug: Display image shape before QImage conversion: {display_image.shape}")
        self.display_qimage(display_image)



    @announce_zoom
    def zoom_in(self):
        """Increase the zoom factor and refresh the display."""
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.display_qimage(self.np_image)

    @announce_zoom
    def zoom_out(self):
        """Decrease the zoom factor and refresh the display."""
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        if self.autostretch_enabled:
            self.apply_autostretch()
        else:
            self.display_qimage(self.np_image)

    def eventFilter(self, source, event):
        """Handle mouse wheel events for zooming."""
        if source == self.image_label and event.type() == QEvent.Type.Wheel:
            if event.angleDelta().y() > 0:
                self.zoom_in()
            else:
                self.zoom_out()
            return True
        return super().eventFilter(source, event)

    def mousePressEvent(self, event):
        """Start dragging if the left mouse button is pressed."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.drag_start_pos = event.pos()

    def mouseMoveEvent(self, event):
        """Handle dragging to move the scroll area."""
        if self.dragging:
            delta = event.pos() - self.drag_start_pos
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )
            self.drag_start_pos = event.pos()

    def mouseReleaseEvent(self, event):
        """Stop dragging when the left mouse button is released."""
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False

    def center_scrollbars(self):
        """Centers the scrollbars to start in the middle of the image."""
        h_scroll = self.scroll_area.horizontalScrollBar()
        v_scroll = self.scroll_area.verticalScrollBar()
        h_scroll.setValue((h_scroll.maximum() + h_scroll.minimum()) // 2)
        v_scroll.setValue((v_scroll.maximum() + v_scroll.minimum()) // 2)

    def resizeEvent(self, event):
        """Handle resizing of the dialog."""
        super().resizeEvent(event)
        self.display_qimage(self.np_image)

class SatelliteProcessingThread(QThread):
    log_signal = pyqtSignal(str)
    finished_signal = pyqtSignal()

    def __init__(self, command):
        super().__init__()
        self.command = command

    def run(self):
        try:
            self.log_signal.emit(f"Running command: {' '.join(self.command)}")
            subprocess.run(self.command, check=True)
            self.log_signal.emit("Processing complete.")
        except subprocess.CalledProcessError as e:
            self.log_signal.emit(f"Processing failed: {e}")
        except Exception as e:
            self.log_signal.emit(f"Unexpected error: {e}")
        finally:
            self.finished_signal.emit()  # Emit the finished signal            

class StatisticalStretchTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.loaded_image_path = None
        self.original_header = None
        self.bit_depth = None
        self.is_mono = False
        self.zoom_factor = 1.0
        self.image = None  # Current image (from ImageManager)
        self.stretched_image = None  # Processed image
        self.current_pixmap = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)


    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # You can adjust this width as needed

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select an image to stretch.
            2. Adjust the target median and optional settings.
            3. Preview the result.
            4. Save the stretched image in your desired format.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton('Select Image', self)
        self.fileButton.clicked.connect(self.openFileDialog)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Target median slider
        self.medianLabel = QLabel('Target Median: 0.25', self)
        self.medianSlider = QSlider(Qt.Orientation.Horizontal)
        self.medianSlider.setMinimum(1)
        self.medianSlider.setMaximum(100)
        self.medianSlider.setValue(25)
        self.medianSlider.valueChanged.connect(self.updateMedianLabel)
        left_layout.addWidget(self.medianLabel)
        left_layout.addWidget(self.medianSlider)

        # Linked/Unlinked stretch checkbox
        self.linkedCheckBox = QCheckBox('Linked Stretch', self)
        self.linkedCheckBox.setChecked(True)
        left_layout.addWidget(self.linkedCheckBox)

        # Normalization checkbox
        self.normalizeCheckBox = QCheckBox('Normalize Image', self)
        left_layout.addWidget(self.normalizeCheckBox)

        # Curves adjustment checkbox
        self.curvesCheckBox = QCheckBox('Apply Curves Adjustment', self)
        self.curvesCheckBox.setCheckState(Qt.CheckState.Unchecked)  # Explicitly set the initial state

        left_layout.addWidget(self.curvesCheckBox)

        # Curves Boost slider (initially hidden)
        self.curvesBoostLabel = QLabel('Curves Boost: 0.00', self)
        self.curvesBoostSlider = QSlider(Qt.Orientation.Horizontal)
        self.curvesBoostSlider.setMinimum(0)
        self.curvesBoostSlider.setMaximum(50)
        self.curvesBoostSlider.setValue(0)
        self.curvesBoostSlider.valueChanged.connect(self.updateCurvesBoostLabel)
        self.curvesBoostLabel.show()
        self.curvesBoostSlider.show()

        left_layout.addWidget(self.curvesBoostLabel)
        left_layout.addWidget(self.curvesBoostSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)      

        # Buttons (Undo and Preview Stretch)
        button_layout = QHBoxLayout()

        self.previewButton = QPushButton('Apply Stretch', self)
        self.previewButton.clicked.connect(self.previewStretch)
        button_layout.addWidget(self.previewButton)

        self.undoButton = QPushButton('Undo', self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undo_image)
        button_layout.addWidget(self.undoButton)

        self.mouseStatusLabel = QLabel('', self)
        left_layout.addWidget(self.mouseStatusLabel)

        left_layout.addLayout(button_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Commented out to move to the right panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton('Zoom In', self)
        # self.zoomInButton.clicked.connect(self.zoom_in)
        # zoom_layout.addWidget(self.zoomInButton)

        # self.zoomOutButton = QPushButton('Zoom Out', self)
        # self.zoomOutButton.clicked.connect(self.zoom_out)
        # zoom_layout.addWidget(self.zoomOutButton)

        # left_layout.addLayout(zoom_layout)




        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 0.25
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.imageLabel.setMouseTracking(True)
        self.imageLabel.installEventFilter(self)

        self.dragging = False
        self.last_pos = QPoint()

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.fileLabel)

            # Update the image display
            self.updateImageDisplay()

            print(f"Statistical Stretch: Image updated from ImageManager slot {slot}.")

    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.preview_image, metadata=metadata, step_name="Statistical Stretch")
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseMove:
            if source in (self.scrollArea.viewport(), self.imageLabel):
                pos = self.imageLabel.mapFrom(source, event.pos())

                if self.imageLabel.pixmap() is not None:
                    pixmap_size = self.imageLabel.pixmap().size()

                    if 0 <= pos.x() < pixmap_size.width() and 0 <= pos.y() < pixmap_size.height():
                        # Convert scaled coordinates back to original image coordinates
                        img_x = int(pos.x() / self.zoom_factor)
                        img_y = int(pos.y() / self.zoom_factor)

                        # Ensure pixel lookup stays within valid range
                        if self.image is not None:
                            h, w = self.image.shape[:2]
                            if 0 <= img_x < w and 0 <= img_y < h:
                                pixel_value = self.image[img_y, img_x]

                                # Display pixel values only when NOT dragging
                                if not self.dragging:
                                    if self.image.ndim == 3:
                                        r, g, b = pixel_value
                                        self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} R:{r:.3f} G:{g:.3f} B:{b:.3f}")
                                    else:
                                        self.mouseStatusLabel.setText(f"X:{img_x} Y:{img_y} Val:{pixel_value:.3f}")

        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
            return True  # Prevent conflicting events

        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
            return True  # Prevent conflicting events

        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()
            return True  # Prevent conflicting events

        return super().eventFilter(source, event)





    def openFileDialog(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        self.filename, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if self.filename:
            self.fileLabel.setText(self.filename)

            # Load the image using ImageManager
            image, original_header, bit_depth, is_mono = load_image(self.filename)

            if image is None:
                QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                return

            # Update ImageManager with the new image
            metadata = {
                'file_path': self.filename,
                'original_header': original_header,
                'bit_depth': bit_depth,
                'is_mono': is_mono
            }
            self.image_manager.add_image(slot=self.image_manager.current_slot, image=image, metadata=metadata)

            print("Image added to ImageManager.")

    def undo_image(self):
        """Undo the last action."""
        if self.image_manager.can_undo():
            self.image_manager.undo()  # Reverts to the previous image
            self.updateImageDisplay()  # Update the display with the reverted image
            print("Undo performed.")
        else:
            QMessageBox.information(self, "Undo", "No actions to undo.")

    def updateMedianLabel(self, value):
        self.medianLabel.setText(f'Target Median: {value / 100:.2f}')

    def updateCurvesBoostLabel(self, value):
        self.curvesBoostLabel.setText(f'Curves Boost: {value / 100:.2f}')

    def previewStretch(self):
        if self.image is not None:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = StatisticalStretchProcessingThread(self.image,
                                                                        self.medianSlider.value(),
                                                                        self.linkedCheckBox.isChecked(),
                                                                        self.normalizeCheckBox.isChecked(),
                                                                        self.curvesCheckBox.isChecked(),
                                                                        self.curvesBoostSlider.value() / 100.0)
            self.processing_thread.preview_generated.connect(self.update_preview)
            self.processing_thread.start()


    def update_preview(self, stretched_image):
        # Save the stretched image for later use in zoom functions
        self.stretched_image = stretched_image

        # Update the preview once the processing thread emits the result
        img = (stretched_image * 255).astype(np.uint8)
        h, w = img.shape[:2]

        if img.ndim == 3:
            bytes_per_line = 3 * w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
        else:
            bytes_per_line = w
            q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)

        # Create QPixmap from QImage
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()

        # Prepare metadata with safeguards
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'target_median': self.medianSlider.value() / 100.0,
                'linked_stretch': self.linkedCheckBox.isChecked(),
                'normalize_image': self.normalizeCheckBox.isChecked(),
                'curves_adjustment': self.curvesCheckBox.isChecked(),
                'curves_boost': self.curvesBoostSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.stretched_image, metadata=metadata, step_name="Statistical Stretch")
                print("StatisticalStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")


    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()    

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    @announce_zoom
    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")

    def saveImage(self):
        if hasattr(self, 'stretched_image') and self.stretched_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.stretched_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.stretched_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')

# Thread for Stat Stretch background processing
class StatisticalStretchProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)  # Signal to send the generated preview image back to the main thread

    def __init__(self, image, target_median, linked, normalize, apply_curves, curves_boost):
        super().__init__()
        self.image = image
        self.target_median = target_median / 100.0  # Ensure proper scaling
        self.linked = linked
        self.normalize = normalize
        self.apply_curves = apply_curves
        self.curves_boost = curves_boost

    def run(self):
        # Perform the image stretching in the background
        if self.image.ndim == 2:  # Mono image
            stretched_image = stretch_mono_image(self.image, self.target_median, self.normalize, self.apply_curves, self.curves_boost)
        else:  # Color image
            stretched_image = stretch_color_image(self.image, self.target_median, self.linked, self.normalize, self.apply_curves, self.curves_boost)

        # Emit the result once done
        self.preview_generated.emit(stretched_image)

# Thread for star stretch background processing
class ProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, stretch_factor, sat_amount, scnr_enabled):
        super().__init__()
        self.image = image
        self.stretch_factor = stretch_factor
        self.sat_amount = sat_amount
        self.scnr_enabled = scnr_enabled

    def run(self):
        # Apply fast pixel math
        stretched_image = applyPixelMath_numba(self.image, self.stretch_factor)

        # Apply saturation adjustment
        stretched_image = adjust_saturation_numba(stretched_image, self.sat_amount)

        # Apply SCNR if enabled
        if self.scnr_enabled:
            stretched_image = applySCNR_numba(stretched_image)

        # Emit the processed image
        self.preview_generated.emit(stretched_image)

class StarStretchTab(QWidget):
    def __init__(self, image_manager):
        super().__init__()
        self.image_manager = image_manager  # Store the ImageManager instance
        self.initUI()
        
        # Connect to ImageManager's image_changed signal
        self.image_manager.image_changed.connect(self.on_image_changed)
        self.image = None  # Store the selected image
        self.stretch_factor = 5.0
        self.sat_amount = 1.0
        self.is_mono = True
        self.remove_green = False
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.last_pos = None
        self.processing_thread = None  # Thread for background processing
        self.original_header = None
        self.current_pixmap = None  # **New Attribute**

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fix the left column width

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the stretch and optional settings.
            3. Preview the result.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Select Stars Only Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Stretch Amount slider with more precision
        self.stretchLabel = QLabel("Stretch Amount: 5.00", self)
        self.stretchSlider = QSlider(Qt.Orientation.Horizontal)
        self.stretchSlider.setMinimum(0)
        self.stretchSlider.setMaximum(800)  # Allow two decimal places of precision
        self.stretchSlider.setValue(500)  # 500 corresponds to 5.00
        self.stretchSlider.valueChanged.connect(self.updateStretchLabel)
        left_layout.addWidget(self.stretchLabel)
        left_layout.addWidget(self.stretchSlider)

        # Color Boost Amount slider
        self.satLabel = QLabel("Color Boost: 1.00", self)
        self.satSlider = QSlider(Qt.Orientation.Horizontal)
        self.satSlider.setMinimum(0)
        self.satSlider.setMaximum(200)
        self.satSlider.setValue(100)  # 100 corresponds to 1.0 boost
        self.satSlider.valueChanged.connect(self.updateSatLabel)
        left_layout.addWidget(self.satLabel)
        left_layout.addWidget(self.satSlider)

        # SCNR checkbox
        self.scnrCheckBox = QCheckBox("Remove Green via SCNR (Optional)", self)
        left_layout.addWidget(self.scnrCheckBox)

        # **Create a horizontal layout for Apply, Undo, and Redo buttons**
        action_buttons_layout = QHBoxLayout()

        # Apply button
        self.refreshButton = QPushButton("Apply", self)
        self.refreshButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.refreshButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Redo button with right arrow icon
        self.redoButton = QPushButton("Redo", self)
        redo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowForward)  # Standard right arrow icon
        self.redoButton.setIcon(redo_icon)
        self.redoButton.clicked.connect(self.redoAction)
        self.redoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.redoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)



        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def saveImage(self):
        # Use the processed/stretched image for saving
        if self.preview_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "stretched_image"
            default_save_name = os.path.splitext(base_name)[0] + '_stretched.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else os.getcwd()

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(
                            self.preview_image, 
                            save_filename, 
                            original_format, 
                            bit_depth, 
                            self.original_header, 
                            self.is_mono
                        )
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(
                        self.preview_image, 
                        save_filename, 
                        original_format
                    )
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText('No stretched image to save. Please generate a preview first.')


    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("StarStretchTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("StarStretchTab: No actions to undo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def redoAction(self):
        if self.image_manager and self.image_manager.can_redo():
            try:
                # Perform the redo operation
                self.image_manager.redo()
                print("StarStretchTab: Redo performed.")
            except Exception as e:
                print(f"Error performing redo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform redo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to redo.")
            print("StarStretchTab: No actions to redo.")

        # Update the state of the Undo and Redo buttons
        if self.image_manager:
            self.undoButton.setEnabled(self.image_manager.can_undo())
            self.redoButton.setEnabled(self.image_manager.can_redo())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return  
        if image is None:
            return              
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"StarStretchTab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())
                self.redoButton.setEnabled(self.image_manager.can_redo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')


    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(self, "Select Stars Only Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)")
        if selected_file:
            try:
                # Load image with header
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)
                self.filename = selected_file  # Store the selected file path
                self.fileLabel.setText(os.path.basename(selected_file))

                # Push the loaded image to ImageManager so it can be tracked for undo/redo
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': 'Unknown',  # You can update this if needed
                    'is_mono': self.is_mono
                }
                self.image_manager.set_image( self.image, metadata, step_name="StarStretch" )
                print(f"Image {self.filename} pushed to ImageManager.")

                # Update the display with the loaded image (before applying any stretch)
                self.updateImageDisplay()

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"Failed to load image: {e}")

    def updateStretchLabel(self, value):
        self.stretch_factor = value / 100.0  # Precision of two decimals
        self.stretchLabel.setText(f"Stretch Amount: {self.stretch_factor:.2f}")

    def updateSatLabel(self, value):
        self.sat_amount = value / 100.0
        self.satLabel.setText(f"Color Boost: {self.sat_amount:.2f}")

    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing
            self.processing_thread = ProcessingThread(self.image, self.stretch_factor, self.sat_amount, self.scnrCheckBox.isChecked())
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()

    def updatePreview(self, stretched_image):
        # Store the stretched image for saving
        self.preview_image = stretched_image

        # Update the ImageManager with the new stretched image
        metadata = {
            'file_path': self.filename if self.filename else "Stretched Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update if bit_depth is available
            'is_mono': self.is_mono,
            'processing_parameters': {
                'stretch_factor': self.stretch_factor,
                'color_boost': self.sat_amount,
                'remove_green': self.scnrCheckBox.isChecked()
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Update ImageManager with the new processed image
        if self.image_manager:
            try:
                self.image_manager.set_image(self.preview_image, metadata=metadata, step_name="StarStretch")
                print("StarStretchTab: Processed image stored in ImageManager.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")

        # Update the preview once the processing thread emits the result
        preview_image = (stretched_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # **Store the original pixmap**
        scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()


    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)
    

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.current_pixmap is not None:
            self.zoom_factor *= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom in.")
            QMessageBox.warning(self, "Warning", "No image available to zoom in.")

    @announce_zoom
    def zoom_out(self):
        if self.current_pixmap is not None:
            self.zoom_factor /= 1.2
            self.apply_zoom()
        else:
            print("No image available to zoom out.")
            QMessageBox.warning(self, "Warning", "No image available to zoom out.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.current_pixmap is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the pixmap
            image_width = self.current_pixmap.width()
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
        else:
            print("No image loaded. Cannot fit to preview.")
            QMessageBox.warning(self, "Warning", "No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the stored pixmap and update the display."""
        if self.current_pixmap is not None:
            scaled_pixmap = self.current_pixmap.scaled(
                self.current_pixmap.size() * self.zoom_factor, 
                Qt.AspectRatioMode.KeepAspectRatio, 
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())
        else:
            print("No pixmap available to apply zoom.")
            QMessageBox.warning(self, "Warning", "No pixmap available to apply zoom.")


    def applyStretch(self):
        if self.image is not None and self.image.size > 0:
            print(f"Applying stretch: {self.stretch_factor}, Color Boost: {self.sat_amount:.2f}, SCNR: {self.scnrCheckBox.isChecked()}")
            self.generatePreview()

class CommaToDotLineEdit(QLineEdit):
    def keyPressEvent(self, event: QKeyEvent):
        print("C2D got:", event.key(), repr(event.text()), event.modifiers())
        # if they hit comma (and it's not a Ctrl+Comma shortcut), turn it into a dot
        if event.text() == "," and not (event.modifiers() & Qt.KeyboardModifier.ControlModifier):
            # synthesize a “.” keypress instead
            event = QKeyEvent(
                QEvent.Type.KeyPress,
                Qt.Key.Key_Period,
                event.modifiers(),
                "."
            )
        super().keyPressEvent(event)

class CurveDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Curves Editor")
        self.setMinimumSize(400, 400)

        layout = QVBoxLayout(self)

        # 1) Curve editor canvas
        self.curveEditor = CurveEditor(self)
        layout.addWidget(self.curveEditor)

        # 2) Pixel info row
        info_row = QHBoxLayout()
        self.xLabel = QLabel("X:0");    info_row.addWidget(self.xLabel)
        self.yLabel = QLabel("Y:0");    info_row.addWidget(self.yLabel)
        self.kLabel = QLabel("K:0.000"); info_row.addWidget(self.kLabel)
        self.rLabel = QLabel("R:0.000");info_row.addWidget(self.rLabel)
        self.gLabel = QLabel("G:0.000");info_row.addWidget(self.gLabel)
        self.bLabel = QLabel("B:0.000");info_row.addWidget(self.bLabel)
        info_row.addStretch(1)
        layout.addLayout(info_row)
        self.kLabel.hide()

        # 3) Status-message line
        self.statusMsg = QLabel("", self)
        self.statusMsg.setStyleSheet("color: gray;")
        layout.addWidget(self.statusMsg)

        # 4) Instructions
        self.instructions = QLabel(
            "Double-click to add, right-click to remove, shift-click on image to add at brightness.",
            self
        )
        self.instructions.setStyleSheet("color:gray; font-style:italic;")
        layout.addWidget(self.instructions)

        # 5) Apply / Undo / Reset bar
        bar = QHBoxLayout()
        self.applyBtn = QPushButton("Apply Curve");  bar.addWidget(self.applyBtn)
        self.undoBtn  = QPushButton("Undo");         bar.addWidget(self.undoBtn)
        self.resetBtn = QPushButton("Reset");        bar.addWidget(self.resetBtn)
        self.undoBtn.setEnabled(False)
        layout.addLayout(bar)

        # wire up external callbacks
        self.applyBtn.clicked.connect(lambda: parent.startProcessing())
        self.undoBtn .clicked.connect(lambda: parent.undo())
        self.resetBtn.clicked.connect(lambda: parent.resetCurve())
        self.curveEditor.setSymmetryCallback(parent.onCurveSymmetryPoint)
        self.curveEditor.setPreviewCallback(
            lambda lut: parent.updatePreviewLUT(lut,
                                               parent.curve_mode,
                                               parent.currentGhsChannel)
        )

    def updatePixelInfo(self, x, y, r, g, b, is_mono=False):
        self.xLabel.setText(f"X:{x}")
        self.yLabel.setText(f"Y:{y}")

        if is_mono:
            self.kLabel.setText(f"K:{r:.3f}")
            self.kLabel.show()
            self.rLabel.hide()
            self.gLabel.hide()
            self.bLabel.hide()
        else:
            self.rLabel.setText(f"R:{r:.3f}")
            self.gLabel.setText(f"G:{g:.3f}")
            self.bLabel.setText(f"B:{b:.3f}")
            self.rLabel.show()
            self.gLabel.show()
            self.bLabel.show()
            self.kLabel.hide()

    def updateStatusMessage(self, text: str):
        self.statusMsg.setText(text)


class FullCurvesTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.initUI()
        self.image = None
        self.image_manager = image_manager
        self.filename = None
        self.original_image = None  # Reference to the original image
        self.preview_image = None   # Reference to the preview image        
        self.zoom_factor = 1.0
        self.original_header = None
        self.bit_depth = None
        self.is_mono = None
        self.curve_mode = "K (Brightness)"  # Default curve mode
        self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)  # Initialize with identity LUT
        self.ghs_sym_pt = None
        self._base_pixmap = None
        self.curveDialog = CurveDialog(parent=self)
        self.curveEditor = self.curveDialog.curveEditor
        self.curveEditor.setSymmetryCallback(self.onCurveSymmetryPoint)
        self.curveEditor.setPreviewCallback(lambda lut: self.updatePreviewLUT(
            lut, self.curve_mode, self.currentGhsChannel
        ))        

        # Initialize the Undo stack with a limited size
        self.undo_stack = []
        self.max_undo = 10  # Maximum number of undo steps        
        self.ghsParams = {
            "α": 1.0,
            "β": 1.0,
            "γ": 1.0,
            "LP": 0.0,
            "HP": 0.0,
            "sym_pt": None
        }
        # Precompute transformation matrices
        self.M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ], dtype=np.float32)

        self.M_inv = np.array([
            [ 3.2404542, -1.5371385, -0.4985314],
            [-0.9692660,  1.8760108,  0.0415560],
            [ 0.0556434, -0.2040259,  1.0572252]
        ], dtype=np.float32)   

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)             

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        # ——— stretch‐type toggle ———
        self.stretchTypeGroup = QButtonGroup(self)
        h = QHBoxLayout()
        for text in ("Traditional Curves", "Universal Hyperbolic"):
            btn = QRadioButton(text, self)
            h.addWidget(btn)
            self.stretchTypeGroup.addButton(btn)
        self.stretchTypeGroup.buttons()[0].setChecked(True)
        self.stretchTypeGroup.buttonToggled.connect(self.onStretchTypeChanged)
        left_layout.addLayout(h)

        # Curve Mode Selection
        self.curveModeLabel = QLabel('Select Curve Mode:', self)
        left_layout.addWidget(self.curveModeLabel)

        self.curveModeGroup = QButtonGroup(self)
        curve_modes = [
            ('K (Brightness)', 0, 0),
            ('R', 1, 0),
            ('G', 2, 0),
            ('B', 3, 0),
            ('L*', 0, 1),
            ('a*', 1, 1),
            ('b*', 2, 1),
            ('Chroma', 0, 2),
            ('Saturation', 1, 2)
        ]
        curve_mode_layout = QGridLayout()
        for mode, row, col in curve_modes:
            button = QRadioButton(mode, self)
            if mode == "K (Brightness)":
                button.setChecked(True)
            button.toggled.connect(self.set_curve_mode)
            self.curveModeGroup.addButton(button)
            curve_mode_layout.addWidget(button, row, col)
        left_layout.addLayout(curve_mode_layout)
        self.set_curve_mode()

        # ——— GHS controls ———
        self.ghsControls = QWidget(self)
        vbox = QVBoxLayout(self.ghsControls)

        # ——— Channel selector + histogram/reset buttons on one line ———
        ch_row = QHBoxLayout()
        ch_row.addWidget(QLabel("Channel:"))
        self.ghsChannelCombo = QComboBox()
        for ch in ("K (Brightness)", "R", "G", "B"):
            self.ghsChannelCombo.addItem(ch)
        ch_row.addWidget(self.ghsChannelCombo)
        ch_row.addStretch()

        # histogram & reset buttons in the same row
        histBtn = QPushButton("Histogram")
        histBtn.setFixedHeight(self.ghsChannelCombo.sizeHint().height())
        histBtn.clicked.connect(self.openHistogram)
        ch_row.addWidget(histBtn)

        resetInfBtn = QPushButton("Reset Inflection")
        resetInfBtn.setFixedHeight(self.ghsChannelCombo.sizeHint().height())
        resetInfBtn.clicked.connect(self.clearGhsPivot)
        ch_row.addWidget(resetInfBtn)

        vbox.addLayout(ch_row)

        self.ghsChannelCombo.currentTextChanged.connect(self._onGhsChannelChanged)
        self.currentGhsChannel = "K (Brightness)"


        # ——— α/β controls —————————————————————
        alpha_beta_group = QVBoxLayout()

        # α row
        alpha_row = QHBoxLayout()
        alpha_row.addWidget(QLabel("α"))

        self.alphaSlider = QSlider(Qt.Orientation.Horizontal)
        self.alphaSlider.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)
        self.alphaSlider.setRange(1, 500)
        self.alphaSlider.setValue(50)            # ← put this back!
        alpha_row.addWidget(self.alphaSlider, 1)

        self.alphaSpin = CustomDoubleSpinBox(
            minimum=0.01, maximum=10.0, initial=1.0, step=0.02, parent=self
        )
        self.alphaSpin.setSizePolicy(QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Fixed)
        alpha_row.addWidget(self.alphaSpin, 0)

        alpha_beta_group.addLayout(alpha_row)

        # β row
        beta_row = QHBoxLayout()
        beta_row.addWidget(QLabel("β"))

        self.betaSlider = QSlider(Qt.Orientation.Horizontal)
        self.betaSlider.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)
        self.betaSlider.setRange(1, 500)
        self.betaSlider.setValue(50)             # ← and this back
        beta_row.addWidget(self.betaSlider, 1)

        self.betaSpin = CustomDoubleSpinBox(
            minimum=0.01, maximum=10.0, initial=1.0, step=0.02, parent=self
        )
        self.betaSpin.setSizePolicy(QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Fixed)
        beta_row.addWidget(self.betaSpin, 0)

        alpha_beta_group.addLayout(beta_row)

        vbox.addLayout(alpha_beta_group)

        # ——— γ + help row —————————————————————
        gamma_row = QHBoxLayout()

        gamma_row.addWidget(QLabel("γ"))

        self.gammaSlider = QSlider(Qt.Orientation.Horizontal)
        self.gammaSlider.setRange(1, 500)
        self.gammaSlider.setValue(100)                              # keep your default
        # give the slider room to expand
        self.gammaSlider.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)
        gamma_row.addWidget(self.gammaSlider, 1)                    # stretch factor 1

        self.gammaSpin = CustomDoubleSpinBox(
            minimum=0.01, maximum=10.0, initial=1.0, step=0.01, parent=self
        )
        self.gammaSpin.setSizePolicy(QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Fixed)
        gamma_row.addWidget(self.gammaSpin, 0)                       # no stretch

        # help button
        self.ghsHelpBtn = QToolButton(self)
        self.ghsHelpBtn.setText("?")
        self.ghsHelpBtn.setToolTip("GHS instructions")
        self.ghsHelpBtn.setFixedSize(20, 20)
        self.ghsHelpBtn.clicked.connect(self.showGhsHelp)
        gamma_row.addWidget(self.ghsHelpBtn, 0)

        vbox.addLayout(gamma_row)


        # ——— wiring ————————————————————————
        # α
        def _onAlphaSlider(v):
            val = v / 50.0
            self.alphaSpin.blockSignals(True)
            self.alphaSpin.setValue(val)
            self.alphaSpin.blockSignals(False)
            self.ghsParams["α"] = val
            self.updateGhsCurve()
        self.alphaSlider.valueChanged.connect(_onAlphaSlider)
        self.alphaSpin.valueChanged.connect(lambda v: self.alphaSlider.setValue(int(v * 50)))

        # β
        def _onBetaSlider(v):
            val = v / 50.0
            self.betaSpin.blockSignals(True)
            self.betaSpin.setValue(val)
            self.betaSpin.blockSignals(False)
            self.ghsParams["β"] = val
            self.updateGhsCurve()
        self.betaSlider.valueChanged.connect(_onBetaSlider)
        self.betaSpin.valueChanged.connect(lambda v: self.betaSlider.setValue(int(v * 50)))

        # γ
        def _onGammaSlider(v):
            val = v / 100.0
            self.gammaSpin.blockSignals(True)
            self.gammaSpin.setValue(val)
            self.gammaSpin.blockSignals(False)
            self.ghsParams["γ"] = val
            self.updateGhsCurve()
        self.gammaSlider.valueChanged.connect(_onGammaSlider)
        self.gammaSpin.valueChanged.connect(lambda v: self.gammaSlider.setValue(int(v * 100)))


        # ─── low‐light protection LP ───────────────────────────
        lp_row = QHBoxLayout()
        self.lpSlider = QSlider(Qt.Orientation.Horizontal)
        self.lpSlider.setRange(0, 360)
        self.lpSlider.setValue(0)
        self.lpLabel = QLabel("LP:0.00")
        lp_row.addWidget(QLabel("LP"))
        lp_row.addWidget(self.lpSlider)
        lp_row.addWidget(self.lpLabel)
        vbox.addLayout(lp_row)
        self.lpSlider.valueChanged.connect(self.updateGhsCurve)

        # ─── high‐light protection HP ──────────────────────────
        hp_row = QHBoxLayout()
        self.hpSlider = QSlider(Qt.Orientation.Horizontal)
        self.hpSlider.setRange(0, 360)
        self.hpSlider.setValue(0)
        self.hpLabel = QLabel("HP:0.00")
        hp_row.addWidget(QLabel("HP"))
        hp_row.addWidget(self.hpSlider)
        hp_row.addWidget(self.hpLabel)
        vbox.addLayout(hp_row)
        self.hpSlider.valueChanged.connect(self.updateGhsCurve)

        left_layout.addWidget(self.ghsControls)
        self.ghsControls.hide()
        left_layout.addStretch(1)

        # Traditional-mode Instructions
        self.tradInstructions = QLabel(self)
        self.tradInstructions.setWordWrap(True)
        self.tradInstructions.setStyleSheet("color: gray; font-style: italic;")
        self.tradInstructions.setText(
            "Double-click to add a curve point.\n"
            "Right-click to delete a curve point.\n"
            "Shift-click on image to add a point at that brightness."
        )
        self.tradInstructions.show()
        left_layout.addWidget(self.tradInstructions)
        left_layout.addStretch(1)

        # ——— Apply/Undo/Reset ———
        button_layout = QHBoxLayout()
        self.applyButton = QPushButton('Apply Curve', self)
        self.applyButton.clicked.connect(self.startProcessing)
        button_layout.addWidget(self.applyButton)
        self.undoButton = QPushButton('Undo', self)
        self.undoButton.clicked.connect(self.undo)
        self.undoButton.setEnabled(False)
        button_layout.addWidget(self.undoButton)
        self.resetCurveButton = QToolButton(self)
        self.resetCurveButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_BrowserReload))
        self.resetCurveButton.clicked.connect(self.resetCurve)
        button_layout.addWidget(self.resetCurveButton)
        left_layout.addLayout(button_layout)

        # ——— Save/Load ———
        saveloadbutton_layout = QHBoxLayout()
        self.saveCurveBtn = QPushButton("Save Curve", self)
        self.saveCurveBtn.clicked.connect(self.saveCurve)
        saveloadbutton_layout.addWidget(self.saveCurveBtn)
        self.loadCurveBtn = QPushButton("Load Curve", self)
        self.loadCurveBtn.clicked.connect(self.loadCurve)
        saveloadbutton_layout.addWidget(self.loadCurveBtn)
        left_layout.addLayout(saveloadbutton_layout)
        # -------- Spinner Label --------
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie("spinner.gif")
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()
        left_layout.addWidget(self.spinnerLabel)


        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        # QLabel for the image preview
        self.imageLabel = ImageLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)
        self.scrollArea.setWidgetResizable(True)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.zoom_factor = 1.0
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)
        self.dragging = False
        self.last_pos = QPoint()

    # -----------------------------
    # Spinner Control Methods
    # -----------------------------
    def showSpinner(self):
        """Show the spinner animation."""
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        """Hide the spinner animation."""
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def showGhsHelp(self):
        QMessageBox.information(
            self,
            "Universal Hyperbolic (GHS) Help",
            "α controls the main S-curve shape.\n"
            "β controls the slope at the inflection point.\n"
            "γ adjusts overall brightness.\n"
            "LP/HP blend into shadows/highlights.\n"
            "Ctrl-click image, curve grid or histogram to set inflection.\n\n"
            "Use the channel dropdown to select which channel to stretch."
        )

    def _onAlphaChanged(self, value: float):
        # called whenever α spinbox changes
        self.ghsParams["α"] = value
        self.updateGhsCurve()

    def _onBetaChanged(self, value: float):
        # called whenever β spinbox changes
        self.ghsParams["β"] = value
        self.updateGhsCurve()

    def _onGammaChanged(self, value: float):
        # called whenever γ spinbox changes
        self.ghsParams["γ"] = value
        self.updateGhsCurve()

    #def showEvent(self, e):
    #    super().showEvent(e)
    #    self.curveDialog.show()

    #def hideEvent(self, e):
    #    super().hideEvent(e)
    #    self.curveDialog.hide()


    def onStretchTypeChanged(self, btn, checked):
        if not checked:
            return

        is_ghs = (btn.text() == "Universal Hyperbolic")

        # Show / hide the curve-mode UI vs GHS UI
        self.curveModeLabel.setVisible(not is_ghs)
        for b in self.curveModeGroup.buttons():
            b.setVisible(not is_ghs)
        self.curveEditor.setInteractive(not is_ghs)

        self.ghsControls.setVisible(is_ghs)

        self.tradInstructions.setVisible(not is_ghs)

        # Reinitialize handles
        if is_ghs:
            pts = self.generate_ghs_control_points(1.0, 1.0, n=20)
            self.curveEditor.setControlHandles(pts)
        else:
            self.curveEditor.initCurve()

    # ——— handlers for α/β/γ ———
    def _onAlphaSliderChanged(self, v):
        val = v / 50.0
        self.alphaEdit.setText(f"{val:.2f}")
        self.updateGhsCurve()

    def _onAlphaEditFinished(self):
        # replace any comma -> dot
        txt = self.alphaEdit.text().replace(",", ".")
        try:
            v = float(txt)
        except ValueError:
            return

        # clamp and sync slider
        v = max(0.01, min(v, 10.0))
        self.alphaEdit.setText(f"{v:.2f}")
        self.alphaSlider.setValue(int(v * 50))
        self.updateGhsCurve()

    def _onBetaSliderChanged(self, v):
        val = v / 50.0
        self.betaEdit.setText(f"{val:.2f}")
        self.updateGhsCurve()


    def _onBetaEditFinished(self):
        txt = self.betaEdit.text().replace(",", ".")
        try:
            v = float(txt)
        except ValueError:
            return
        v = max(0.01, min(v, 10.0))
        self.betaEdit.setText(f"{v:.2f}")
        self.betaSlider.setValue(int(v * 50))
        self.updateGhsCurve()

    def _onGammaSliderChanged(self, v):
        val = max(0.01, v / 100.0)
        self.gammaEdit.setText(f"{val:.2f}")
        self.updateGhsCurve()

    def _onGammaEditFinished(self):
        txt = self.gammaEdit.text().replace(",", ".")
        try:
            v = float(txt)
        except ValueError:
            return
        v = max(0.01, v)
        self.gammaEdit.setText(f"{v:.2f}")
        self.gammaSlider.setValue(int(v * 100))
        self.updateGhsCurve()

    def _onGhsChannelChanged(self, ch_name):
        self.currentGhsChannel = ch_name
        if self.stretchTypeGroup.checkedButton().text() != "Universal Hyperbolic":
            return

        # clear any pivot line if you like
        self.curveEditor.clearSymmetryLine()

        # fetch and re-overlay the *same* curve
        lut = self.curveEditor.get8bitLUT()

        # recolor the spline
        color_map = {
            "K (Brightness)": Qt.GlobalColor.white,
            "R":               Qt.GlobalColor.red,
            "G":               Qt.GlobalColor.green,
            "B":               Qt.GlobalColor.blue,
        }
        pen = QPen(color_map[ch_name])
        pen.setWidth(3)
        if getattr(self.curveEditor, "curve_item", None):
            self.curveEditor.curve_item.setPen(pen)

        # re-apply that LUT in the preview
        self.updatePreviewLUT(lut, self.curve_mode, ch_name)

    def openHistogram(self):
        # 1) If we already have one open, just raise it
        if hasattr(self, '_hist_dialog') and self._hist_dialog is not None and self._hist_dialog.isVisible():
            self._hist_dialog.raise_()
            self._hist_dialog.activateWindow()
            return

        # 2) Pull the current image out of ImageManager’s internal store
        slot = self.image_manager.current_slot
        img  = self.image_manager._images.get(slot, None)
        if img is None:
            QMessageBox.warning(self, "No Image", f"Slot {slot} does not contain an image.")
            return

        # 3) If it’s mono, make it 3-channel so the histogram dialog can handle it uniformly
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)

        # 4) Create & keep a reference so it doesn’t get GC’d
        self._hist_dialog = HistogramDialog(self.image_manager, parent=self)

        # 5) Install our event filter to catch Ctrl-clicks there
        self._hist_dialog.hist_label.installEventFilter(self)

        # 6) Connect to image_changed so it stays in sync
        def _update_hist(slot_changed, new_img, metadata):
            if slot_changed != self.image_manager.current_slot or new_img is None:
                return
            if new_img.ndim == 2:
                new_img = np.stack([new_img]*3, axis=-1)

        self.image_manager.image_changed.connect(_update_hist)

        # 7) Seed it with the current image and show non-modally
        self._hist_dialog.updateHistogram(img)
        self._hist_dialog.show()

        # 8) When it closes, drop our reference so we can make a fresh one next time
        self._hist_dialog.finished.connect(lambda _: setattr(self, '_hist_dialog', None))

    def _onHistClosed(self, result):
        # drop our reference so it can be GC’d next time
        self._hist_dialog = None

    def generate_ghs_control_points(self, alpha, beta, n=10):
        # X in [0…1], compute y = X**alpha / (X**alpha + beta*(1-X)**alpha)
        xs = np.linspace(0,1,n)
        ys = xs**alpha / (xs**alpha + beta*(1-xs)**alpha)
        # map to your 0–360 scene: x*360, (1−y)*360
        return [(x*360, (1-y)*360) for x,y in zip(xs, ys)]

    def updateGhsCurve(self):
        # ─── read sliders ────────────────────────────────────────────
        α = self.ghsParams["α"]
        β = self.ghsParams["β"]
        G = self.ghsParams["γ"]

        LP = self.lpSlider.value()      / 360.0         # low protect [0…1]
        HP = self.hpSlider.value()      / 360.0         # high protect[0…1]
        SP = 0.5 if self.ghs_sym_pt is None else self.ghs_sym_pt

        self.lpLabel   .setText(f"LP:{LP:.2f}")
        self.hpLabel   .setText(f"HP:{HP:.2f}")

        cps = self.curveEditor.control_points
        N   = len(cps)
        if N < 2:
            return

        # ─── sample domain ───────────────────────────────────────────
        us = np.linspace(0.0, 1.0, N)

        # ─── your α/β S‐curve around midpoint 0.5 ────────────────────
        raw_vs   = us**α / (us**α + β*(1.0 - us)**α)
        raw_vs_r = us**α / (us**α + (1/β)*(1.0 - us)**α)
        mid_l = (0.5**α) / (0.5**α + β*(1.0 - 0.5)**α)
        mid_r = (0.5**α) / (0.5**α + (1/β)*(1.0 - 0.5)**α)

        # ─── remap so (0.5,mid) → (SP,SP) ───────────────────────────
        up = np.empty_like(us)
        vp = np.empty_like(us)

        left  = us <= 0.5
        right = ~left

        up[left]  =   2 * SP * us[left]
        vp[left]  = raw_vs[left]   * (SP / mid_l)

        up[right] =   SP + 2*(1 - SP)*(us[right] - 0.5)
        vp[right] =   SP + (raw_vs_r[right] - mid_r)*((1 - SP)/(1 - mid_r))

        # ─── PROTECT shadows/highlights by BLENDING ────────────────
        # instead of hard-clipping, mix toward the identity line:
        #   LP=0 → no blend (full curve), LP=1 → full identity
        if LP > 0:
            mask_left = up <= SP
            # mix vp toward the identity line vp=up
            vp[mask_left] = (1 - LP) * vp[mask_left] + LP * up[mask_left]

        if HP > 0:
            mask_right = up >= SP
            vp[mask_right] = (1 - HP) * vp[mask_right] + HP * up[mask_right]

        # ─── LOCAL FOCUS AROUND SP (b) ──────────────────────────────

        # ─── GAMMA LIFT ──────────────────────────────────────────────
        if abs(G - 1.0) > 1e-6:
            vp = vp ** (1.0 / G)

        # ─── write back into your handles ────────────────────────────
        pts = [(u * 360.0, (1.0 - v) * 360.0) for u, v in zip(up, vp)]
        for handle, (x, y) in zip(cps, pts):
            handle.setPos(x, y)

        # ─── trigger redraw ──────────────────────────────────────────
        color_map = {
            "K (Brightness)": Qt.GlobalColor.white,
            "R":               Qt.GlobalColor.red,
            "G":               Qt.GlobalColor.green,
            "B":               Qt.GlobalColor.blue,
        }
        pen = QPen(color_map[self.currentGhsChannel])
        pen.setWidth(3)
        if getattr(self.curveEditor, "curve_item", None):
            self.curveEditor.curve_item.setPen(pen)
        # ─── finally update the real-time preview for THIS channel ────
        lut = self.curveEditor.get8bitLUT()
        self.updatePreviewLUT(lut, self.curve_mode, self.currentGhsChannel)


    def onCurveSymmetryPoint(self, u, v):
        # u is the brightness fraction, v == u on the true inflection point
        self.ghs_sym_pt = u
        # update your status label however you like:
        self.curveDialog.updateStatusMessage(f"Inflection @ K={u:.3f}")
        # regenerate the GHS curve around this pivot:
        self.updateGhsCurve()

    def clearGhsPivot(self):
        """Forget any custom inflection point and recenter to p=0.5."""
        # clear our stored pivot
        self.ghs_sym_pt = None
        # remove the yellow line
        self.curveEditor.clearSymmetryLine()
        # redraw the GHS handles around the default pivot=0.5
        # regenerate with pivot=0.5
        self.updateGhsCurve()
        self.curveDialog.updateStatusMessage("Symmetry reset to center (p=0.5)")

    def saveCurve(self):
        fname, _ = QFileDialog.getSaveFileName(self, "Save Curve As","", "SASC Curve (*.sasc)")
        if not fname:
            return
        if not fname.lower().endswith(".sasc"):
            fname += ".sasc"

        handles = self.curveEditor.getControlHandles()
        try:
            with open(fname, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(["x","y"])
                for x,y in handles:
                    writer.writerow([f"{x:.6f}", f"{y:.6f}"])
            QMessageBox.information(self, "Curve Saved", f"Saved {len(handles)} handles to {fname}")
        except Exception as e:
            QMessageBox.critical(self, "Error Saving Curve", str(e))

    def loadCurve(self):
        fname, _ = QFileDialog.getOpenFileName(self, "Load Curve", "", "SASC Curve (*.sasc)")
        if not fname:
            return

        handles = []
        try:
            with open(fname, newline='') as f:
                reader = csv.reader(f)
                next(reader, None)  # skip header
                for row in reader:
                    x, y = float(row[0]), float(row[1])
                    handles.append((x,y))
        except Exception as e:
            QMessageBox.critical(self, "Error Loading Curve", str(e))
            return

        # reset everything _except_ endpoints
        self.curveEditor.initCurve()

        # now restore just our saved handles
        self.curveEditor.setControlHandles(handles)

        QMessageBox.information(self, "Curve Loaded", f"Restored {len(handles)} handles from {fname}")         

    def set_curve_mode(self):
        selected_button = self.curveModeGroup.checkedButton()
        if selected_button:
            self.curve_mode = selected_button.text()
            # Assuming you have the current LUT, update the preview
            if hasattr(self, 'current_lut'):
                self.updatePreviewLUT(self.current_lut, self.curve_mode)

    def _capture_viewport(self):
        """
        Snapshot current zoom + scroll positions. Returns None if no pixmap yet.
        """
        if not self.scrollArea or not self.imageLabel or self.imageLabel.pixmap() is None:
            return None
        hbar = self.scrollArea.horizontalScrollBar()
        vbar = self.scrollArea.verticalScrollBar()
        return {
            "zoom": self.zoom_factor,
            "h_val": hbar.value(),
            "h_max": max(1, hbar.maximum()),
            "v_val": vbar.value(),
            "v_max": max(1, vbar.maximum()),
        }

    def _restore_viewport(self, state):
        """
        Restore zoom + scroll positions (scaled if content size changed).
        """
        if not state:
            return
        # 1) restore zoom (this re-scales the pixmap)
        self.zoom_factor = state["zoom"]
        self._update_displayed_pixmap()

        # 2) restore scrollbars proportionally to new content size
        hbar = self.scrollArea.horizontalScrollBar()
        vbar = self.scrollArea.verticalScrollBar()
        new_hmax = max(1, hbar.maximum())
        new_vmax = max(1, vbar.maximum())

        h_target = int((state["h_val"] / state["h_max"]) * new_hmax)
        v_target = int((state["v_val"] / state["v_max"]) * new_vmax)

        hbar.setValue(h_target)
        vbar.setValue(v_target)


    def get_visible_region(self):
        """Retrieve the coordinates of the visible region in the image."""
        viewport = self.scrollArea.viewport()
        # Top-left corner of the visible area
        x = self.scrollArea.horizontalScrollBar().value()
        y = self.scrollArea.verticalScrollBar().value()
        # Size of the visible area
        w = viewport.width()
        h = viewport.height()
        return x, y, w, h


    def updatePreviewLUT(self, lut, curve_mode, ghschannel=None):
        """Apply the 8-bit LUT to the preview image for real-time updates on slot 0."""

        # Access slot0 (recombined image) from ImageManager
        if self.image is None:
            return

        if ghschannel is None:
            ghschannel = self.currentGhsChannel

        if (self.stretchTypeGroup.checkedButton().text() == "Universal Hyperbolic"
                and ghschannel in ("R","G","B")):
            # grab the existing LUT (which was built for K)
            # and apply it just to the selected channel:
            idx = {"R":0, "G":1, "B":2}[ghschannel]
            img8 = (self.image*255).astype(np.uint8)
            out = img8.copy()
            out[...,idx] = lut[out[...,idx]]
            self.show_image(out.astype(np.float32)/255.0)
            return

        try:
            current_scroll_x = self.scrollArea.horizontalScrollBar().value()
            current_scroll_y = self.scrollArea.verticalScrollBar().value()

            # 1) Copy the entire preview in float [0..1]
            base_image = self.image.copy()  # shape: (H, W, 3 or 2)

            # 2) Convert the entire base_image to 8-bit
            image_8bit = (base_image * 255).astype(np.uint8)

            # 3) Make a working copy for transformation
            adjusted_8bit = image_8bit.copy()

            if adjusted_8bit.ndim == 3:  # RGB image
                adjusted_image = adjusted_8bit.copy()

                if curve_mode == "K (Brightness)":
                    # Apply LUT to all channels equally (Brightness)
                    for channel in range(3):
                        adjusted_image[:, :, channel] = lut[adjusted_8bit[:, :, channel]]

                elif curve_mode in ["R", "G", "B"]:
                    # Apply LUT to a single channel
                    channel_index = {"R": 0, "G": 1, "B": 2}[curve_mode]
                    adjusted_image[:, :, channel_index] = lut[adjusted_8bit[:, :, channel_index]]

                elif curve_mode in ["L*", "a*", "b*"]:
                    # Manual RGB to Lab Conversion
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Apply LUT to the respective channel
                    if curve_mode == "L*":
                        # L* typically ranges from 0 to 100
                        L_normalized = np.clip(L / 100.0, 0, 1)  # Normalize to [0,1]
                        L_lut_indices = (L_normalized * 255).astype(np.uint8)
                        L_adjusted = lut[L_lut_indices].astype(np.float32) * 100.0 / 255.0  # Scale back to [0,100]
                        L = L_adjusted

                    elif curve_mode == "a*":
                        # a* typically ranges from -128 to +127
                        a_normalized = np.clip((a + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        a_lut_indices = (a_normalized * 255).astype(np.uint8)
                        a_adjusted = lut[a_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        a = a_adjusted

                    elif curve_mode == "b*":
                        # b* typically ranges from -128 to +127
                        b_normalized = np.clip((b + 128.0) / 255.0, 0, 1)  # Normalize to [0,1]
                        b_lut_indices = (b_normalized * 255).astype(np.uint8)
                        b_adjusted = lut[b_lut_indices].astype(np.float32) - 128.0  # Scale back to [-128,127]
                        b = b_adjusted

                    # Update Lab channels
                    lab_new = np.stack([L, a, b], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Chroma":
                    # === Manual RGB to Lab Conversion ===
                    M = self.M
                    M_inv = self.M_inv

                    # Normalize RGB to [0,1]
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Convert RGB to XYZ
                    xyz = np.dot(rgb.reshape(-1, 3), M.T).reshape(rgb.shape)

                    # Reference white point (D65)
                    Xn, Yn, Zn = 0.95047, 1.00000, 1.08883

                    # Normalize XYZ
                    X = xyz[:, :, 0] / Xn
                    Y = xyz[:, :, 1] / Yn
                    Z = xyz[:, :, 2] / Zn

                    # Define the f(t) function
                    delta = 6 / 29
                    def f(t):
                        return np.where(t > delta**3, np.cbrt(t), (t / (3 * delta**2)) + (4 / 29))

                    fx = f(X)
                    fy = f(Y)
                    fz = f(Z)

                    # Compute L*, a*, b*
                    L = 116 * fy - 16
                    a = 500 * (fx - fy)
                    b = 200 * (fy - fz)

                    # Compute Chroma
                    chroma = np.sqrt(a**2 + b**2)

                    # Define a fixed maximum Chroma for normalization to prevent over-scaling
                    fixed_max_chroma = 200.0  # Adjust this value as needed

                    # Normalize Chroma to [0,1] using fixed_max_chroma
                    chroma_norm = np.clip(chroma / fixed_max_chroma, 0, 1)

                    # Apply LUT to Chroma
                    chroma_lut_indices = (chroma_norm * 255).astype(np.uint8)
                    chroma_adjusted = lut[chroma_lut_indices].astype(np.float32)  # Ensure float32

                    # Compute scaling factor, avoiding division by zero
                    scale = np.ones_like(chroma_adjusted, dtype=np.float32)
                    mask = chroma > 0
                    scale[mask] = chroma_adjusted[mask] / chroma[mask]

                    # Scale a* and b* channels
                    a_new = a * scale
                    b_new = b * scale

                    # Update Lab channels
                    lab_new = np.stack([L, a_new, b_new], axis=2)

                    # Convert Lab back to XYZ
                    fy_new = (lab_new[:, :, 0] + 16) / 116
                    fx_new = fy_new + lab_new[:, :, 1] / 500
                    fz_new = fy_new - lab_new[:, :, 2] / 200

                    def f_inv(ft):
                        return np.where(ft > delta, ft**3, 3 * delta**2 * (ft - 4 / 29))

                    X_new = f_inv(fx_new) * Xn
                    Y_new = f_inv(fy_new) * Yn
                    Z_new = f_inv(fz_new) * Zn

                    # Stack XYZ channels
                    xyz_new = np.stack([X_new, Y_new, Z_new], axis=2)

                    # Convert XYZ back to RGB
                    rgb_new = np.dot(xyz_new.reshape(-1, 3), M_inv.T).reshape(xyz_new.shape)

                    # Clip RGB to [0,1]
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                elif curve_mode == "Saturation":
                    # === Manual RGB to HSV Conversion ===
                    rgb = adjusted_8bit.astype(np.float32) / 255.0

                    # Split channels
                    R, G, B = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]

                    # Compute Cmax, Cmin, Delta
                    Cmax = np.maximum.reduce([R, G, B])
                    Cmin = np.minimum.reduce([R, G, B])
                    Delta = Cmax - Cmin

                    # Initialize Hue (H), Saturation (S), and Value (V)
                    H = np.zeros_like(Cmax)
                    S = np.zeros_like(Cmax)
                    V = Cmax.copy()

                    # Compute Hue (H)
                    mask = Delta != 0
                    H[mask & (Cmax == R)] = ((G[mask & (Cmax == R)] - B[mask & (Cmax == R)]) / Delta[mask & (Cmax == R)]) % 6
                    H[mask & (Cmax == G)] = ((B[mask & (Cmax == G)] - R[mask & (Cmax == G)]) / Delta[mask & (Cmax == G)]) + 2
                    H[mask & (Cmax == B)] = ((R[mask & (Cmax == B)] - G[mask & (Cmax == B)]) / Delta[mask & (Cmax == B)]) + 4
                    H = H / 6.0  # Normalize Hue to [0,1]

                    # Compute Saturation (S)
                    S[Cmax != 0] = Delta[Cmax != 0] / Cmax[Cmax != 0]

                    # Apply LUT to Saturation (S) channel
                    S_normalized = np.clip(S, 0, 1)  # Ensure S is within [0,1]
                    S_lut_indices = (S_normalized * 255).astype(np.uint8)
                    S_adjusted = lut[S_lut_indices].astype(np.float32) / 255.0  # Normalize back to [0,1]
                    S = S_adjusted

                    # Convert HSV back to RGB
                    C = V * S
                    X = C * (1 - np.abs((H * 6) % 2 - 1))
                    m = V - C

                    # Initialize RGB channels
                    R_new = np.zeros_like(R)
                    G_new = np.zeros_like(G)
                    B_new = np.zeros_like(B)

                    # Define masks for different sectors of Hue
                    mask0 = (H >= 0) & (H < 1/6)
                    mask1 = (H >= 1/6) & (H < 2/6)
                    mask2 = (H >= 2/6) & (H < 3/6)
                    mask3 = (H >= 3/6) & (H < 4/6)
                    mask4 = (H >= 4/6) & (H < 5/6)
                    mask5 = (H >= 5/6) & (H < 1)

                    # Assign RGB values based on the sector of Hue
                    R_new[mask0] = C[mask0]
                    G_new[mask0] = X[mask0]
                    B_new[mask0] = 0

                    R_new[mask1] = X[mask1]
                    G_new[mask1] = C[mask1]
                    B_new[mask1] = 0

                    R_new[mask2] = 0
                    G_new[mask2] = C[mask2]
                    B_new[mask2] = X[mask2]

                    R_new[mask3] = 0
                    G_new[mask3] = X[mask3]
                    B_new[mask3] = C[mask3]

                    R_new[mask4] = X[mask4]
                    G_new[mask4] = 0
                    B_new[mask4] = C[mask4]

                    R_new[mask5] = C[mask5]
                    G_new[mask5] = 0
                    B_new[mask5] = X[mask5]

                    # Add m to match the Value (V)
                    R_new += m
                    G_new += m
                    B_new += m

                    # Stack the channels back together
                    rgb_new = np.stack([R_new, G_new, B_new], axis=2)

                    # Clip RGB to [0,1] to maintain valid color ranges
                    rgb_new = np.clip(rgb_new, 0, 1)

                    # Convert back to 8-bit
                    adjusted_image = (rgb_new * 255).astype(np.uint8)

                else:
                    # Unsupported curve mode
                    print(f"Unsupported curve mode: {curve_mode}")
                    QMessageBox.warning(self, "Unsupported Mode", f"Unsupported curve mode: {curve_mode}")
                    return

            else:  # Grayscale image
                # For grayscale images, apply LUT directly
                adjusted_image = lut[adjusted_8bit]

            # Convert adjusted_image back to float [0..1]
            preview_image = adjusted_image.astype(np.float32) / 255.0

            # 5) Retrieve the active mask
            mask = self.get_active_mask()


            if mask is not None:
                # 5a) Downsample the mask to match the preview image dimensions
                downsampled_mask = self.downsample_for_preview(mask, max_width=1080)

                # 5b) Ensure mask is properly formatted and normalized
                if downsampled_mask.dtype != np.float32 and downsampled_mask.dtype != np.float64:
                    downsampled_mask = downsampled_mask.astype(np.float32) / 255.0

                # 5c) If preview_image is multi-channel but mask is single-channel, expand mask dimensions
                if preview_image.ndim == 3 and downsampled_mask.ndim == 2:
                    downsampled_mask = np.expand_dims(downsampled_mask, axis=-1)

                # 5d) Ensure mask dimensions match the preview image dimensions
                if downsampled_mask.shape[:2] != preview_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Downsampled mask dimensions do not match the preview image dimensions.")
                    return

                # 5e) Blend the adjusted preview_image with the base_image using the mask
                # Formula: blended_preview = adjusted_image * mask + base_image * (1 - mask)
                blended_preview = preview_image * downsampled_mask + base_image * (1 - downsampled_mask)
                blended_preview = np.clip(blended_preview, 0.0, 1.0)  # Ensure values are within [0,1]
            else:
                # No mask applied; use the adjusted image directly
                blended_preview = preview_image

            # 6) Finally, show the blended preview image
            self.show_image(blended_preview)
            self.scrollArea.horizontalScrollBar().setValue(current_scroll_x)
            self.scrollArea.verticalScrollBar().setValue(current_scroll_y)              

        except Exception as e:
            print(f"Error in updatePreviewLUT: {e}")
            QMessageBox.critical(self, "Error", f"Failed to update preview: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.original_image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.original_image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None

    def startProcessing(self):
        if self.original_image is None:
            
            return

        is_ghs = (self.stretchTypeGroup.checkedButton().text() == "Universal Hyperbolic")
        source_image = self.original_image.copy()

        # Push onto undo stack
        self.pushUndo(source_image.copy())
        self.showSpinner()

        curve_func = self.curveEditor.getCurveFunction()
        # for GHS mode, the “curve_mode” is just which channel to apply:
        if is_ghs:
            curve_mode = self.currentGhsChannel  # “K (Brightness)”, “R”, “G” or “B”
        else:
            curve_mode = self.curveModeGroup.checkedButton().text()

        self.processing_thread = FullCurvesProcessingThread(
            source_image,
            curve_mode=curve_mode,
            curve_func=curve_func
        )
 
        self.processing_thread.result_ready.connect(self.finishProcessing)
        self.processing_thread.start()
        print("Started processing thread.")

    def finishProcessing(self, adjusted_image):
        # snapshot the view BEFORE we change the pixmap
        view = self._capture_viewport()
        self.hideSpinner()

        if adjusted_image is None:
            QMessageBox.critical(self, "Error", "Image processing failed.")
            return

        # — Blend with mask if present —
        mask = self.get_active_mask()
        if mask is not None:
            if mask.dtype not in (np.float32, np.float64):
                mask = mask.astype(np.float32) / 255.0
            if self.original_image.ndim == 3 and mask.ndim == 2:
                mask = mask[..., None]
            if mask.shape[:2] != self.original_image.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                return
            if self.original_image.ndim == 3 and mask.shape[2] == 1:
                mask = np.repeat(mask, self.original_image.shape[2], axis=2)

            blended = adjusted_image * mask + self.original_image * (1 - mask)
            blended = np.clip(blended, 0.0, 1.0)
        else:
            blended = adjusted_image

        # — Update master copy and preview —
        self.original_image = blended.copy()
        self.preview_image  = self.downsample_for_preview(blended, max_width=1080)
        self.image          = self.preview_image.copy()

        # draw without losing zoom/pan
        self.show_image(self.image, preserve_view_state=view)

        # Reset the curve UI state, but DO NOT disturb the viewport (updatePreviewLUT already restores its own)
        if self.stretchTypeGroup.checkedButton().text() == "Universal Hyperbolic":
            self.resetCurve()
        else:
            self.curveEditor.initCurve()

        # push back into ImageManager (this may trigger on_image_changed; that method now also preserves view)
        if self.image_manager:
            meta = dict(
                file_path=self.loaded_image_path,
                original_header=self.original_header,
                bit_depth=self.bit_depth,
                is_mono=self.is_mono
            )
            self.image_manager.set_image_with_step_name(
                self.original_image.copy(), meta, step_name="Curves Adjustment"
            )
            print("FullCurvesTab: Image updated in ImageManager with step name.")




    def pushUndo(self, image_state):
        """Push the current image state onto the undo stack."""
        if len(self.undo_stack) >= self.max_undo:
            # Remove the oldest state to maintain the stack size
            self.undo_stack.pop(0)
        self.undo_stack.append(image_state)
        self.updateUndoButtonState()

    def updateUndoButtonState(self):
        """Enable or disable the Undo button based on the undo stack."""
        if hasattr(self, 'undoButton'):
            self.undoButton.setEnabled(len(self.undo_stack) > 0)

    def undo(self):
        """Revert the image to the last state in the undo stack."""
        if not self.undo_stack:
            QMessageBox.information(self, "Undo", "No actions to undo.")
            return

        # Pop the last state from the stack
        last_state = self.undo_stack.pop()

        # Update ImageManager with the previous image state
        if self.image_manager:
            metadata = {
                'file_path': self.loaded_image_path,  # Update as needed
                'original_header': self.original_header,
                'bit_depth': self.bit_depth,
                'is_mono': self.is_mono
            }
            self.image_manager.update_image(updated_image=last_state, metadata=metadata)
            print("Undo: Image reverted in ImageManager.")

        # Update the Undo button state
        self.updateUndoButtonState()


    def resetCurve(self):
        """
        Resets the draggable points in the curve editor.
        — In traditional mode, behaves as before.
        — In generalized hyperbolic mode, resets α/β, clears inflection,
        and redraws exactly 20 GHS handles.
        """
        try:
            is_ghs = self.stretchTypeGroup.checkedButton().text() == "Universal Hyperbolic"

            if is_ghs:
                # 1) reset α/β/γ sliders & labels
                self.alphaSlider.setValue(50)
                self.betaSlider .setValue(50)
                self.gammaSlider.setValue(100)

                # 2) reset LP/HP sliders & labels
                self.lpSlider.setValue(0)
                self.hpSlider.setValue(0)
                self.lpLabel.setText("LP:0.00")
                self.hpLabel.setText("HP:0.00")

                # 2) clear any inflection pivot
                self.ghs_sym_pt = None
                self.curveEditor.clearSymmetryLine()

                # 3) regenerate the default GHS control points using normalized α,β
                α = self.alphaSlider.value() / 50.0   # -> 1.0
                β = self.betaSlider.value()  / 50.0   # -> 1.0
                pts = self.generate_ghs_control_points(α, β, n=20)
                self.curveEditor.setControlHandles(pts)

            else:
                # traditional curves → back to a clean bezier
                self.curveEditor.initCurve()

            # 4) clear preview LUT & redraw
            self.current_lut = np.linspace(0, 255, 256, dtype=np.uint8)
            self.updatePreviewLUT(self.current_lut, self.curve_mode)

        except Exception as e:
            print(f"Error during curve reset: {e}")
            QMessageBox.critical(self, "Error", f"Failed to reset curve: {e}")

    def eventFilter(self, source, event):
        if self.image is None:
            return super().eventFilter(source, event)        
        # ——— 1) Histogram Ctrl-click to set inflection ———
        hist = getattr(self, "_hist_dialog", None)
        if ( hist is not None
            and source is hist.hist_label
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ControlModifier ):

            x = event.pos().x()
            w = hist.hist_label.width()
            frac = max(0.0, min(1.0, x / w))

            if hist.log_scale:
                # use *exactly* the same eps/log_min/log_max you drew with
                eps     = hist._hist_eps
                log_min = hist._hist_log_min
                log_max = hist._hist_log_max
                log_val = log_min + frac * (log_max - log_min)
                k = 10 ** log_val
            else:
                k = frac

            # store pivot and redraw GHS
            self.ghs_sym_pt = k
            self.curveEditor.setSymmetryPoint(k*360.0, 0)
            self.curveDialog.updateStatusMessage(f"Symmetry K={k:.4f}")
            self.updateGhsCurve()
            return True

        # ——— 2) Image-view Ctrl-click to set pivot from pixel brightness ———
        if (
            source is self.scrollArea.viewport()
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ControlModifier
        ):
            pos = self.imageLabel.mapFrom(self.scrollArea.viewport(), event.pos())
            pix = self.imageLabel.pixmap()
            if pix and 0 <= pos.x() < pix.width() and 0 <= pos.y() < pix.height():
                img_x = pos.x() / self.zoom_factor
                img_y = pos.y() / self.zoom_factor
                h, w = self.image.shape[:2]
                if 0 <= img_x < w and 0 <= img_y < h:
                    pv = self.image[int(img_y), int(img_x)]
                    k = float(np.mean(pv))
                    self.ghs_sym_pt = k
                    self.curveEditor.setSymmetryPoint(k * 360.0, 0)
                    self.curveDialog.updateStatusMessage(f"Symmetry at K={k:.3f}")
                    self.updateGhsCurve()
                    return True

        # ——— 3) Shift-click to add control point ———
        if (
            source is self.scrollArea.viewport()
            and event.type() == QEvent.Type.MouseButtonPress
            and event.button() == Qt.MouseButton.LeftButton
            and event.modifiers() & Qt.KeyboardModifier.ShiftModifier
        ):
            pos = self.imageLabel.mapFrom(self.scrollArea.viewport(), event.pos())
            pix = self.imageLabel.pixmap()
            if pix and 0 <= pos.x() < pix.width() and 0 <= pos.y() < pix.height():
                img_x = int(pos.x() / self.zoom_factor)
                img_y = int(pos.y() / self.zoom_factor)
                h, w = self.image.shape[:2]
                if 0 <= img_x < w and 0 <= img_y < h:
                    pv = self.image[img_y, img_x]
                    avg = float(np.mean(pv))
                    new_x, new_y = avg * 360.0, (1 - avg) * 360.0
                    self.curveEditor.addControlPoint(new_x, new_y)
                    self.curveDialog.updateStatusMessage(f"Added control point @ X:{new_x:.1f} Y:{new_y:.1f}")
                    return True

        # ——— 4) Fall back to pan/drag ———
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(
                self.scrollArea.horizontalScrollBar().value() - delta.x()
            )
            self.scrollArea.verticalScrollBar().setValue(
                self.scrollArea.verticalScrollBar().value() - delta.y()
            )
            self.last_pos = event.pos()

        # ——— 5) Hover-move for pixel readout ———
        if source is self.scrollArea.viewport() and event.type() == QEvent.Type.MouseMove:
            # 1) get viewport coords
            vp_pt = event.pos()
            # 2) map to label coords
            lbl_pt = self.imageLabel.mapFrom(self.scrollArea.viewport(), vp_pt)

            pix = self.imageLabel.pixmap()
            if pix is None:
                return super().eventFilter(source, event)

            pw, ph = pix.width(), pix.height()
            iw, ih = self.image.shape[1], self.image.shape[0]

            x, y = lbl_pt.x(), lbl_pt.y()
            if not (0 <= x < pw and 0 <= y < ph):
                return super().eventFilter(source, event)

            # 3) un-scale into image coords
            img_x = int(x * iw / pw)
            img_y = int(y * ih / ph)

            pv = self.image[img_y, img_x]
            if self.image.ndim == 3:
                r, g, b = pv
                self.curveEditor.updateValueLines(r, g, b, grayscale=False)
                self.curveDialog.updatePixelInfo(img_x, img_y, r, g, b, is_mono=False)

                self.curveDialog.updateStatusMessage("")  # clear older messages
            else:
                v = float(pv)
                self.curveEditor.updateValueLines(v, v, v, grayscale=True)
                # fallback r=g=b=v for grayscale
                self.curveDialog.updatePixelInfo(img_x, img_y, v, v, v, is_mono=True)
                self.curveDialog.updateStatusMessage("")  # clear older messages


            return True

        return super().eventFilter(source, event)




    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)
    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Keeps current zoom/pan stable.
        """
        if not self.isVisible() or image is None:
            return
        if slot != self.image_manager.current_slot:
            return

        # ensure ndarray
        if not isinstance(image, np.ndarray):
            image = np.array(image)

        # snapshot view BEFORE changing pixmap (if any)
        view = self._capture_viewport()

        # Set master images
        self.loaded_image_path = metadata.get('file_path', "") or ""
        self.original_image = image.copy()
        self.original_header = metadata.get('original_header', None)
        self.bit_depth = metadata.get('bit_depth', None)
        self.is_mono = metadata.get('is_mono', False)

        # build preview shown on screen
        self.preview_image = self.downsample_for_preview(self.original_image, max_width=1080)
        self.image = self.preview_image.copy()

        # single draw; restore view
        self.show_image(self.image, preserve_view_state=view)

        # enable buttons
        self.applyButton.setEnabled(True)
        self.undoButton.setEnabled(len(self.undo_stack) > 0)

        print(f"FullCurvesTab: Image updated from ImageManager slot {slot}.")


    def downsample_for_preview(self, image_float32, max_width=1080):
        """
        If image width > max_width, scale it down proportionally.
        Returns a new float32 image in [0..1].
        """


        h, w = image_float32.shape[:2]

        if w <= max_width:
            # No need to downsample
            return image_float32.copy()

        scale_factor = max_width / float(w)
        new_w = max_width
        new_h = int(h * scale_factor)

        # Convert [0..1] float to [0..255] uint8 for OpenCV resizing
        temp_8u = (image_float32 * 255).clip(0,255).astype(np.uint8)

        # Resize with INTER_AREA for best downsampling
        resized_8u = cv2.resize(temp_8u, (new_w, new_h), interpolation=cv2.INTER_AREA)

        # Convert back to float32 in [0..1]
        return resized_8u.astype(np.float32) / 255.0



    def show_image(self, image, preserve_view_state=None):
        """
        Display image without losing current zoom/pan.
        Pass in a 'preserve_view_state' captured via _capture_viewport() when you
        know the view will change (e.g., before Apply). If None, it will capture now.
        """
        # capture BEFORE changing the pixmap
        state = preserve_view_state or self._capture_viewport()

        try:
            # Normalize image to 0-255 and convert to uint8
            display_image = (image * 255).astype(np.uint8)

            # If the image has a singleton third dimension, squeeze it out
            if display_image.ndim == 3 and display_image.shape[2] == 1:
                display_image = display_image.squeeze(axis=2)

            if display_image.ndim == 3 and display_image.shape[2] == 3:
                # RGB Image
                height, width, _ = display_image.shape
                bytes_per_line = 3 * width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            elif display_image.ndim == 2:
                # Grayscale Image
                height, width = display_image.shape
                bytes_per_line = width
                q_image = QImage(display_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                QMessageBox.critical(self, "Error", "Unsupported image format for display.")
                return

            pixmap = QPixmap.fromImage(q_image)
            # keep the un-zoomed copy
            self._base_pixmap = pixmap

            # draw at current zoom
            self._update_displayed_pixmap()

            # restore view (zoom again & scrollbars proportionally)
            self._restore_viewport(state)

        except Exception as e:
            print(f"Error displaying image: {e}")
            QMessageBox.critical(self, "Error", f"Failed to display the image: {e}")



    def _update_displayed_pixmap(self):
        """Take _base_pixmap × zoom_factor → self.imageLabel."""
        if self._base_pixmap is None:
            return
        sz = self._base_pixmap.size() * self.zoom_factor
        scaled = self._base_pixmap.scaled(
            sz, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled)

    def update_image_display(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoom_in(self):
        """Zoom into the image by increasing zoom_factor and re‐drawing."""
        if not hasattr(self, "_base_pixmap") or self._base_pixmap is None:
            QMessageBox.warning(self, "Warning", "Nothing to zoom in.")
            return

        self.zoom_factor *= 1.2
        self._update_displayed_pixmap()

        pct = int(self.zoom_factor * 100)
        vp = self.scrollArea.viewport()
        global_pt = vp.mapToGlobal(vp.rect().center())
        QToolTip.showText(global_pt, f"{pct}%")
        print(f"Zoomed in → {pct}%")

    def zoom_out(self):
        """Zoom out of the image by decreasing zoom_factor and re‐drawing."""
        if not hasattr(self, "_base_pixmap") or self._base_pixmap is None:
            QMessageBox.warning(self, "Warning", "Nothing to zoom out.")
            return

        self.zoom_factor /= 1.2
        self._update_displayed_pixmap()

        pct = int(self.zoom_factor * 100)
        vp = self.scrollArea.viewport()
        global_pt = vp.mapToGlobal(vp.rect().center())
        QToolTip.showText(global_pt, f"{pct}%")
        print(f"Zoomed out → {pct}%")

    def fit_to_preview(self):
        """Set zoom_factor so the image width exactly fits the viewport."""
        if not hasattr(self, "_base_pixmap") or self._base_pixmap is None:
            QMessageBox.warning(self, "Warning", "Nothing to fit.")
            return

        vpw = self.scrollArea.viewport().width()
        imgw = self._base_pixmap.width()
        if imgw == 0:
            return

        self.zoom_factor = vpw / imgw
        self._update_displayed_pixmap()
        print(f"Fit to preview → zoom_factor={self.zoom_factor:.2f}")

    def refresh_display(self):
        """
        Refresh the image display based on the current zoom factor.
        """
        if self.stretched_image is None:
            print("No stretched image to display.")
            return

        try:
            # Normalize and convert to uint8 for display
            img = (self.stretched_image * 255).astype(np.uint8)
            h, w = img.shape[:2]

            if img.ndim == 3 and img.shape[2] == 3:
                bytes_per_line = 3 * w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_RGB888)
            elif img.ndim == 2:
                bytes_per_line = w
                q_image = QImage(img.tobytes(), w, h, bytes_per_line, QImage.Format.Format_Grayscale8)
            else:
                raise ValueError("Unsupported image format for display.")

            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

            print("Display refreshed successfully.")
        except Exception as e:
            print(f"Error refreshing display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to refresh display: {e}")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updatePreview()  # Call without extra arguments; it will calculate dimensions based on zoom factor            

    def saveImage(self):
        if self.image is not None:
            # Open the file save dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 'Save Image As', '', 
                'Images (*.tiff *.tif *.png *.fit *.fits *.xisf);;All Files (*)'
            )
            
            if save_filename:
                # Extract the file extension from the user-provided filename
                file_extension = save_filename.split('.')[-1].lower()

                # Map the extension to the format expected by save_image
                if file_extension in ['tif', 'tiff']:
                    file_format = 'tiff'
                elif file_extension == 'png':
                    file_format = 'png'
                elif file_extension in ['fit', 'fits']:
                    file_format = 'fits'
                elif file_extension == 'xisf':
                    file_format = 'xisf'
                else:
                    QMessageBox.warning(self, "Error", f"Unsupported file format: .{file_extension}")
                    return
                
                try:
                    # Initialize metadata if not already set (e.g., for PNG)
                    if not hasattr(self, 'image_meta') or self.image_meta is None:
                        self.image_meta = [{
                            'geometry': (self.image.shape[1], self.image.shape[0], self.image.shape[2] if not self.is_mono else 1),
                            'colorSpace': 'Gray' if self.is_mono else 'RGB'
                        }]

                    if not hasattr(self, 'file_meta') or self.file_meta is None:
                        self.file_meta = {}

                    # Initialize a default header for FITS if none exists
                    if not hasattr(self, 'original_header') or self.original_header is None:
                        print("Creating default FITS header...")
                        self.original_header = {
                            'SIMPLE': True,
                            'BITPIX': -32 if self.bit_depth == "32-bit floating point" else 16,
                            'NAXIS': 2 if self.is_mono else 3,
                            'NAXIS1': self.image.shape[1],
                            'NAXIS2': self.image.shape[0],
                            'NAXIS3': 1 if self.is_mono else self.image.shape[2],
                            'BZERO': 0.0,
                            'BSCALE': 1.0,
                            'COMMENT': "Default header created by Seti Astro Suite"
                        }

                    # Call save_image with the appropriate arguments
                    save_image(
                        self.image,
                        save_filename,
                        file_format,  # Use the user-specified format
                        self.bit_depth,
                        self.original_header,
                        self.is_mono,
                        self.image_meta,
                        self.file_meta
                    )
                    print(f"Image saved successfully to {save_filename}")
                except Exception as e:
                    QMessageBox.critical(self, "Error", f"Failed to save image: {e}")

class DraggablePoint(QGraphicsEllipseItem):
    def __init__(self, curve_editor, x, y, color=Qt.GlobalColor.green, lock_axis=None, position_type=None):
        super().__init__(-5, -5, 10, 10)
        self.curve_editor = curve_editor
        self.lock_axis = lock_axis
        self.position_type = position_type
        self.setBrush(QBrush(color))
        self.setFlags(QGraphicsItem.GraphicsItemFlag.ItemIsMovable | QGraphicsItem.GraphicsItemFlag.ItemSendsScenePositionChanges)
        self.setCursor(Qt.CursorShape.OpenHandCursor)
        self.setAcceptedMouseButtons(Qt.MouseButton.LeftButton | Qt.MouseButton.RightButton)
        self.setPos(x, y)

    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.RightButton:
            if self in self.curve_editor.control_points:
                self.curve_editor.control_points.remove(self)
                self.curve_editor.scene.removeItem(self)
                self.curve_editor.updateCurve()
            return
        super().mousePressEvent(event)

    def itemChange(self, change, value):
        if change == QGraphicsItem.GraphicsItemChange.ItemPositionHasChanged:
            new_pos = value
            x = new_pos.x()
            y = new_pos.y()

            if self.position_type == 'top_right':
                dist_to_top = abs(y-0)
                dist_to_right = abs(x-360)
                if dist_to_right<dist_to_top:
                    nx=360
                    ny=min(max(y,0),360)
                else:
                    ny=0
                    nx=min(max(x,0),360)
                x,y=nx,ny
            elif self.position_type=='bottom_left':
                dist_to_left=abs(x-0)
                dist_to_bottom=abs(y-360)
                if dist_to_left<dist_to_bottom:
                    nx=0
                    ny=min(max(y,0),360)
                else:
                    ny=360
                    nx=min(max(x,0),360)
                x,y=nx,ny

            all_points=self.curve_editor.end_points+self.curve_editor.control_points
            other_points=[p for p in all_points if p is not self]
            other_points_sorted=sorted(other_points,key=lambda p:p.scenePos().x())

            insert_index=0
            for i,p in enumerate(other_points_sorted):
                if p.scenePos().x()<x:
                    insert_index=i+1
                else:
                    break

            if insert_index>0:
                left_p=other_points_sorted[insert_index-1]
                left_x=left_p.scenePos().x()
                if x<=left_x:
                    x=left_x+0.0001

            if insert_index<len(other_points_sorted):
                right_p=other_points_sorted[insert_index]
                right_x=right_p.scenePos().x()
                if x>=right_x:
                    x=right_x-0.0001

            x=max(0,min(x,360))
            y=max(0,min(y,360))

            super().setPos(x,y)
            self.curve_editor.updateCurve()

        return super().itemChange(change, value)

class ImageLabel(QLabel):
    mouseMoved = pyqtSignal(float, float)
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setMouseTracking(True)
    def mouseMoveEvent(self, event):
        self.mouseMoved.emit(event.position().x(), event.position().y())
        super().mouseMoveEvent(event)

class CurveEditor(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.scene = QGraphicsScene(self)
        self.setScene(self.scene)
        self.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.setFixedSize(380, 425)
        self.preview_callback = None  # To trigger real-time updates
        self.symmetry_callback = None

        # Initialize control points and curve path
        self.end_points = []  # Start and end points with axis constraints
        self.control_points = []  # Dynamically added control points
        self.curve_path = QPainterPath()
        self.curve_item = None  # Stores the curve line
        self.sym_line = None

        # Set scene rectangle
        self.scene.setSceneRect(0, 0, 360, 360)

        self.initGrid()
        self.initCurve()

    def initGrid(self):
        pen = QPen(Qt.GlobalColor.gray)
        pen.setStyle(Qt.PenStyle.DashLine)
        for i in range(0, 361, 45):  # Grid lines at 0,45,...,360
            self.scene.addLine(i, 0, i, 360, pen)  # Vertical lines
            self.scene.addLine(0, i, 360, i, pen)  # Horizontal lines

        # Add X-axis labels
        # Each line corresponds to i/360.0
        for i in range(0, 361, 45):
            val = i/360.0
            label = QGraphicsTextItem(f"{val:.3f}")
            # Position label slightly below the x-axis (360 is bottom)
            # For X-axis, put them near bottom at y=365 for example
            label.setPos(i-5, 365) 
            self.scene.addItem(label)

        # Optionally add Y-axis labels if needed
        # Similar approach for the Y-axis if you want

    def initCurve(self):
        # Remove existing items from the scene
        # First remove control points
        for p in self.control_points:
            self.scene.removeItem(p)
        # Remove end points
        for p in self.end_points:
            self.scene.removeItem(p)
        # Remove the curve item if any
        if self.curve_item:
            self.scene.removeItem(self.curve_item)
            self.curve_item = None

        # Clear existing point lists
        self.end_points = []
        self.control_points = []

        # Add the default endpoints again
        self.addEndPoint(0, 360, lock_axis=None, position_type='bottom_left', color=Qt.GlobalColor.black)
        self.addEndPoint(360, 0, lock_axis=None, position_type='top_right', color=Qt.GlobalColor.white)

        # Redraw the initial line
        self.updateCurve()

    def getControlHandles(self):
        """Return just the user-added handles (not the endpoints)."""
        # control_points are your green, draggable handles:
        return [(p.scenePos().x(), p.scenePos().y()) for p in self.control_points]

    def setControlHandles(self, handles):
        """Clear existing controls (but keep endpoints), then re-add."""
        # remove any existing controls
        for p in list(self.control_points):
            self.scene.removeItem(p)
        self.control_points.clear()

        # now add back each one
        for x,y in handles:
            self.addControlPoint(x, y)

        # finally redraw spline once
        self.updateCurve()

    def clearSymmetryLine(self):
        """Remove any drawn symmetry line and reset."""
        if self.sym_line:
            self.scene.removeItem(self.sym_line)
            self.sym_line = None
            # redraw without symmetry aid
            self.updateCurve()

    def addEndPoint(self, x, y, lock_axis=None, position_type=None, color=Qt.GlobalColor.red):
        point = DraggablePoint(self, x, y, color=color, lock_axis=lock_axis, position_type=position_type)
        self.scene.addItem(point)
        self.end_points.append(point)

    def addControlPoint(self, x, y, lock_axis=None):

        point = DraggablePoint(self, x, y, color=Qt.GlobalColor.green, lock_axis=lock_axis, position_type=None)
        self.scene.addItem(point)
        self.control_points.append(point)
        self.updateCurve()

    def setSymmetryCallback(self, fn):
        """fn will be called with (u, v) in [0..1] when user ctrl+clicks the grid."""
        self.symmetry_callback = fn

    def setSymmetryPoint(self, x, y):
        pen = QPen(Qt.GlobalColor.yellow)
        pen.setStyle(Qt.PenStyle.DashLine)
        pen.setWidth(2)
        if self.sym_line is None:
            # draw a vertical symmetry line at scene X==x
            self.sym_line = self.scene.addLine(x, 0, x, 360, pen)
        else:
            self.sym_line.setLine(x, 0, x, 360)
        # if you want to re-draw the curve mirrored around x,
        # you can trigger updateCurve() here or elsewhere
        self.updateCurve()

    def catmull_rom_spline(self, p0, p1, p2, p3, t):
        """
        Compute a point on a Catmull-Rom spline segment at parameter t (0<=t<=1).
        Each p is a QPointF.
        """
        t2 = t * t
        t3 = t2 * t

        x = 0.5 * (2*p1.x() + (-p0.x() + p2.x()) * t +
                    (2*p0.x() - 5*p1.x() + 4*p2.x() - p3.x()) * t2 +
                    (-p0.x() + 3*p1.x() - 3*p2.x() + p3.x()) * t3)
        y = 0.5 * (2*p1.y() + (-p0.y() + p2.y()) * t +
                    (2*p0.y() - 5*p1.y() + 4*p2.y() - p3.y()) * t2 +
                    (-p0.y() + 3*p1.y() - 3*p2.y() + p3.y()) * t3)

        # Clamp to bounding box
        x = max(0, min(360, x))
        y = max(0, min(360, y))

        return QPointF(x, y)

    def generateSmoothCurvePoints(self, points):
        """
        Given a sorted list of QGraphicsItems (endpoints + control points),
        generate a list of smooth points approximating a Catmull-Rom spline
        through these points.
        """
        if len(points) < 2:
            return []
        if len(points) == 2:
            # Just a straight line between two points
            p0 = points[0].scenePos()
            p1 = points[1].scenePos()
            return [p0, p1]

        # Extract scene positions
        pts = [p.scenePos() for p in points]

        # For Catmull-Rom, we need points before the first and after the last
        # We'll duplicate the first and last points.
        extended_pts = [pts[0]] + pts + [pts[-1]]

        smooth_points = []
        steps_per_segment = 20  # increase for smoother curve
        for i in range(len(pts) - 1):
            p0 = extended_pts[i]
            p1 = extended_pts[i+1]
            p2 = extended_pts[i+2]
            p3 = extended_pts[i+3]

            # Sample the spline segment between p1 and p2
            for step in range(steps_per_segment+1):
                t = step / steps_per_segment
                pos = self.catmull_rom_spline(p0, p1, p2, p3, t)
                smooth_points.append(pos)

        return smooth_points

    # Add a callback for the preview
    def setPreviewCallback(self, callback):
        self.preview_callback = callback

    def get8bitLUT(self):
        # 8-bit LUT size
        lut_size = 256

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 255, lut_size, dtype=np.uint8)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:, 0]   # X from 0 to 360
        ys = curve_array[:, 1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys

        # Input positions for interpolation (0..255 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..255
        output_values = (output_values / 360.0) * 255.0
        output_values = np.clip(output_values, 0, 255).astype(np.uint8)

        return output_values

    def updateCurve(self):
        """Update the curve by redrawing based on endpoints and control points."""
        
        all_points = self.end_points + self.control_points
        if not all_points:
            # No points, no curve
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        # Sort points by X coordinate
        sorted_points = sorted(all_points, key=lambda p: p.scenePos().x())

        # Extract arrays of X and Y
        xs = [p.scenePos().x() for p in sorted_points]
        ys = [p.scenePos().y() for p in sorted_points]

        # Ensure X values are strictly increasing
        unique_xs, unique_ys = [], []
        for i in range(len(xs)):
            if i == 0 or xs[i] > xs[i - 1]:  # Skip duplicate X values
                unique_xs.append(xs[i])
                unique_ys.append(ys[i])

        # If there's only one point or none, we can't interpolate
        if len(unique_xs) < 2:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None

            if len(unique_xs) == 1:
                # Optionally draw a single point
                single_path = QPainterPath()
                single_path.addEllipse(unique_xs[0]-2, unique_ys[0]-2, 4, 4)
                pen = QPen(Qt.GlobalColor.white)
                pen.setWidth(3)
                self.curve_item = self.scene.addPath(single_path, pen)
            return

        try:
            # Create a PCHIP interpolator
            interpolator = PchipInterpolator(unique_xs, unique_ys)
            self.curve_function = interpolator

            # Sample the curve
            sample_xs = np.linspace(unique_xs[0], unique_xs[-1], 361)
            sample_ys = interpolator(sample_xs)

        except ValueError as e:
            print(f"Interpolation Error: {e}")  # Log the error instead of crashing
            return  # Exit gracefully

        curve_points = [QPointF(float(x), float(y)) for x, y in zip(sample_xs, sample_ys)]
        self.curve_points = curve_points

        if not curve_points:
            if self.curve_item:
                self.scene.removeItem(self.curve_item)
                self.curve_item = None
            return

        self.curve_path = QPainterPath()
        self.curve_path.moveTo(curve_points[0])
        for pt in curve_points[1:]:
            self.curve_path.lineTo(pt)

        if self.curve_item:
            self.scene.removeItem(self.curve_item)
        pen = QPen(Qt.GlobalColor.white)
        pen.setWidth(3)
        self.curve_item = self.scene.addPath(self.curve_path, pen)

        # Trigger the preview callback
        if hasattr(self, 'preview_callback') and self.preview_callback:
            # Generate the 8-bit LUT and pass it to the callback
            lut = self.get8bitLUT()
            self.preview_callback(lut)

    def getCurveFunction(self):
        return self.curve_function

    def getCurvePoints(self):
        if not hasattr(self, 'curve_points') or not self.curve_points:
            return []
        return [(pt.x(), pt.y()) for pt in self.curve_points]

    def getLUT(self):
        # 16-bit LUT size
        lut_size = 65536

        curve_pts = self.getCurvePoints()
        if len(curve_pts) == 0:
            # No curve points, return a linear LUT
            lut = np.linspace(0, 65535, lut_size, dtype=np.uint16)
            return lut

        curve_array = np.array(curve_pts, dtype=np.float64)
        xs = curve_array[:,0]   # X from 0 to 360
        ys = curve_array[:,1]   # Y from 0 to 360

        ys_for_lut = 360.0 - ys


        # Input positions for interpolation (0..65535 mapped to 0..360)
        input_positions = np.linspace(0, 360, lut_size, dtype=np.float64)

        # Interpolate using the inverted Y
        output_values = np.interp(input_positions, xs, ys_for_lut)

        # Map 0..360 to 0..65535
        output_values = (output_values / 360.0) * 65535.0
        output_values = np.clip(output_values, 0, 65535).astype(np.uint16)

        return output_values
    
    def mousePressEvent(self, event):
        # ctrl+left click on the grid → pick inflection point
        if (event.button() == Qt.MouseButton.LeftButton
                and event.modifiers() & Qt.KeyboardModifier.ControlModifier):
            scene_pt = self.mapToScene(event.pos())
            # clamp into scene rect
            x = max(0, min(360, scene_pt.x()))
            y = max(0, min(360, scene_pt.y()))
            # draw the yellow symmetry line
            self.setSymmetryPoint(x, y)
            # compute normalized (u, v)
            u = x / 360.0
            v = 1.0 - (y / 360.0)
            # tell anyone who cares
            if self.symmetry_callback:
                self.symmetry_callback(u, v)
            return  # consume
        super().mousePressEvent(event)

    def mouseDoubleClickEvent(self, event):
        """
        Handle double-click events to add a new control point.
        """
        scene_pos = self.mapToScene(event.pos())

        self.addControlPoint(scene_pos.x(), scene_pos.y())
        super().mouseDoubleClickEvent(event)

    def keyPressEvent(self, event):
        """Remove selected points on Delete key press."""
        if event.key() == Qt.Key.Key_Delete:
            for point in self.control_points[:]:
                if point.isSelected():
                    self.scene.removeItem(point)
                    self.control_points.remove(point)
            self.updateCurve()
        super().keyPressEvent(event)

    def updateValueLines(self, r, g, b, grayscale=False):
        """
        Update vertical lines on the curve scene.
        For color images (grayscale=False), three lines (red, green, blue) are drawn.
        For grayscale images (grayscale=True), a single gray line is drawn.
        
        Values are assumed to be in the range [0, 1] and mapped to 0–360.
        """
        if grayscale:
            # Map the 0–1 grayscale value to the scene's X coordinate (0–360)
            x = r * 360.0
            if not hasattr(self, "gray_line") or self.gray_line is None:
                self.gray_line = self.scene.addLine(x, 0, x, 360, QPen(Qt.GlobalColor.gray))
            else:
                self.gray_line.setLine(x, 0, x, 360)
            # Hide any color lines if present
            for attr in ("r_line", "g_line", "b_line"):
                if hasattr(self, attr) and getattr(self, attr) is not None:
                    getattr(self, attr).setVisible(False)
        else:
            # Hide grayscale line if present
            if hasattr(self, "gray_line") and self.gray_line is not None:
                self.gray_line.setVisible(False)
            
            # Map each 0–1 value to X coordinate on scene (0–360)
            r_x = r * 360.0
            g_x = g * 360.0
            b_x = b * 360.0

            # Create or update the red line
            if not hasattr(self, "r_line") or self.r_line is None:
                self.r_line = self.scene.addLine(r_x, 0, r_x, 360, QPen(Qt.GlobalColor.red))
            else:
                self.r_line.setLine(r_x, 0, r_x, 360)
            self.r_line.setVisible(True)

            # Create or update the green line
            if not hasattr(self, "g_line") or self.g_line is None:
                self.g_line = self.scene.addLine(g_x, 0, g_x, 360, QPen(Qt.GlobalColor.green))
            else:
                self.g_line.setLine(g_x, 0, g_x, 360)
            self.g_line.setVisible(True)

            # Create or update the blue line
            if not hasattr(self, "b_line") or self.b_line is None:
                self.b_line = self.scene.addLine(b_x, 0, b_x, 360, QPen(Qt.GlobalColor.blue))
            else:
                self.b_line.setLine(b_x, 0, b_x, 360)
            self.b_line.setVisible(True)


def build_curve_lut(curve_func, size=65536):
    """
    Build a LUT of length 'size' that maps float in [0..1] to [0..1],
    using your existing PCHIP curve_func(x) which is defined on x in [0..360].
    We'll do:
       mapped = 360 - curve_func(x)
       out = clamp( mapped / 360, [0..1] )
    """
    lut = np.zeros(size, dtype=np.float32)
    for i in range(size):
        v = i / (size - 1)  # in [0..1]
        x = v * 360.0
        mapped = 360.0 - curve_func(x)
        outv = mapped / 360.0
        if outv < 0.0: outv = 0.0
        elif outv > 1.0: outv = 1.0
        lut[i] = outv
    return lut


class FullCurvesProcessingThread(QThread):
    result_ready = pyqtSignal(np.ndarray)

    def __init__(self, image, curve_mode, curve_func):
        super().__init__()
        self.image = image
        self.curve_mode = curve_mode
        self.curve_func = curve_func

    def run(self):
        print("Full curves thread started")
        adjusted_image = self.process_curve(self.image, self.curve_mode, self.curve_func)
        self.result_ready.emit(adjusted_image)

    @staticmethod
    def process_curve(image, curve_mode, curve_func):

        if image is None or curve_func is None:
            return image

        # Ensure image is float32 [0..1]
        if image.dtype != np.float32:
            image = image.astype(np.float32, copy=False)

        # Build a big LUT
        lut = build_curve_lut(curve_func, size=65536)

        # Determine if image is mono
        is_gray = (image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1))
        if is_gray:
            # Convert to 2D if needed
            if image.ndim == 3:
                image = image.reshape(image.shape[0], image.shape[1])
            # For mono images, no matter if the mode is "R", "G", "B", or "K (Brightness)",
            # we simply apply the LUT to the entire image.
            out = image.copy()
            apply_lut_mono_inplace(out, lut)
            return out  # Return a 2D array for mono images.



        # ----------------------------------------------------------------------
        # R/G/B/K (Brightness) => direct LUT application
        # ----------------------------------------------------------------------
        mode = curve_mode.lower()
        if mode == 'r':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 0], lut)
            return out
        elif mode == 'g':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 1], lut)
            return out
        elif mode == 'b':
            out = image.copy()
            apply_lut_mono_inplace(out[..., 2], lut)
            return out
        elif mode == 'k (brightness)':
            out = image.copy()
            apply_lut_color_inplace(out, lut)
            return out

        # -------------------------------------------------------
        # L*, a*, b*, Chroma => do color transform => apply LUT => transform back
        # -------------------------------------------------------
        elif mode in ["l*", "a*", "b*", "chroma"]:
            # 1) Convert RGB -> XYZ -> Lab via Numba
            xyz = rgb_to_xyz_numba(image)             # Numba-based
            lab = xyz_to_lab_numba(xyz)               # Numba-based

            if mode == "l*":
                # L in [0..100]
                L = lab[..., 0] / 100.0
                apply_lut_mono_inplace(L, lut)
                lab[..., 0] = L * 100.0

            elif mode == "a*":
                # a in [-128..127], shift => [0..255], then /255 => [0..1]
                a = lab[..., 1]
                a_norm = (a + 128.0) / 255.0
                a_norm = np.clip(a_norm, 0, 1)
                apply_lut_mono_inplace(a_norm, lut)
                lab[..., 1] = a_norm * 255.0 - 128.0

            elif mode == "b*":
                # b in [-128..127]
                b = lab[..., 2]
                b_norm = (b + 128.0) / 255.0
                b_norm = np.clip(b_norm, 0, 1)
                apply_lut_mono_inplace(b_norm, lut)
                lab[..., 2] = b_norm * 255.0 - 128.0

            elif mode == "chroma":
                a_ = lab[..., 1]
                b_ = lab[..., 2]
                C = np.sqrt(a_ * a_ + b_ * b_)
                C_norm = np.clip(C / 200.0, 0, 1)
                apply_lut_mono_inplace(C_norm, lut)
                C_new = C_norm * 200.0
                ratio = np.divide(C_new, C, out=np.zeros_like(C), where=(C != 0))
                lab[..., 1] = a_ * ratio
                lab[..., 2] = b_ * ratio

            # Convert Lab -> XYZ -> RGB
            xyz_new = lab_to_xyz_numba(lab)           # Numba-based
            out = xyz_to_rgb_numba(xyz_new)           # Numba-based
            return out

        # -------------------------------------------------------
        # HSV saturation => same approach
        # -------------------------------------------------------
        elif mode == "saturation":
            hsv = rgb_to_hsv_numba(image)             # Numba-based
            S = hsv[..., 1]
            apply_lut_mono_inplace(S, lut)
            hsv[..., 1] = S
            out = hsv_to_rgb_numba(hsv)               # Numba-based
            return out

        # If none matched, just return the image
        return image

    @staticmethod
    def rgb_to_xyz(rgb):
        M = np.array([[0.4124564, 0.3575761, 0.1804375],
                      [0.2126729, 0.7151522, 0.0721750],
                      [0.0193339, 0.1191920, 0.9503041]], dtype=np.float32)
        shape = rgb.shape
        out = rgb.reshape(-1,3) @ M.T
        return out.reshape(shape)

    @staticmethod
    def xyz_to_rgb(xyz):
        M_inv = np.array([[ 3.2404542, -1.5371385, -0.4985314],
                          [-0.9692660,  1.8760108,  0.0415560],
                          [ 0.0556434, -0.2040259,  1.0572252]], dtype=np.float32)
        shape = xyz.shape
        out = xyz.reshape(-1,3) @ M_inv.T
        out = np.clip(out, 0, 1)
        return out.reshape(shape)

    @staticmethod
    def f_lab(t):
        delta = 6/29
        mask = t > delta**3
        f = np.zeros_like(t)
        f[mask] = np.cbrt(t[mask])
        f[~mask] = t[~mask]/(3*delta*delta)+4/29
        return f

    @staticmethod
    def xyz_to_lab(xyz):
        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = xyz[:,:,0]/Xn
        Y = xyz[:,:,1]/Yn
        Z = xyz[:,:,2]/Zn

        fx = FullCurvesProcessingThread.f_lab(X)
        fy = FullCurvesProcessingThread.f_lab(Y)
        fz = FullCurvesProcessingThread.f_lab(Z)

        L = (116 * fy - 16)
        a = 500*(fx - fy)
        b = 200*(fy - fz)
        return np.dstack([L, a, b]).astype(np.float32)

    @staticmethod
    def lab_to_xyz(lab):
        L = lab[:,:,0]
        a = lab[:,:,1]
        b = lab[:,:,2]

        delta = 6/29
        fy = (L+16)/116
        fx = fy + a/500
        fz = fy - b/200

        def f_inv(ft):
            return np.where(ft > delta, ft**3, 3*delta*delta*(ft - 4/29))

        Xn, Yn, Zn = 0.95047, 1.00000, 1.08883
        X = Xn*f_inv(fx)
        Y = Yn*f_inv(fy)
        Z = Zn*f_inv(fz)
        return np.dstack([X, Y, Z]).astype(np.float32)

    @staticmethod
    def rgb_to_hsv(rgb):
        cmax = rgb.max(axis=2)
        cmin = rgb.min(axis=2)
        delta = cmax - cmin

        H = np.zeros_like(cmax)
        S = np.zeros_like(cmax)
        V = cmax

        mask = delta != 0
        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]
        H[mask & (cmax==r)] = 60*(((g[mask&(cmax==r)]-b[mask&(cmax==r)])/delta[mask&(cmax==r)])%6)
        H[mask & (cmax==g)] = 60*(((b[mask&(cmax==g)]-r[mask&(cmax==g)])/delta[mask&(cmax==g)])+2)
        H[mask & (cmax==b)] = 60*(((r[mask&(cmax==b)]-g[mask&(cmax==b)])/delta[mask&(cmax==b)])+4)

        S[cmax>0] = delta[cmax>0]/cmax[cmax>0]
        return np.dstack([H,S,V]).astype(np.float32)

    @staticmethod
    def hsv_to_rgb(hsv):
        H, S, V = hsv[:,:,0], hsv[:,:,1], hsv[:,:,2]
        C = V*S
        X = C*(1-np.abs((H/60.0)%2-1))
        m = V-C

        R = np.zeros_like(H)
        G = np.zeros_like(H)
        B = np.zeros_like(H)

        cond0 = (H<60)
        cond1 = (H>=60)&(H<120)
        cond2 = (H>=120)&(H<180)
        cond3 = (H>=180)&(H<240)
        cond4 = (H>=240)&(H<300)
        cond5 = (H>=300)

        R[cond0]=C[cond0]; G[cond0]=X[cond0]; B[cond0]=0
        R[cond1]=X[cond1]; G[cond1]=C[cond1]; B[cond1]=0
        R[cond2]=0; G[cond2]=C[cond2]; B[cond2]=X[cond2]
        R[cond3]=0; G[cond3]=X[cond3]; B[cond3]=C[cond3]
        R[cond4]=X[cond4]; G[cond4]=0; B[cond4]=C[cond4]
        R[cond5]=C[cond5]; G[cond5]=0; B[cond5]=X[cond5]

        rgb = np.dstack([R+m, G+m, B+m])
        rgb = np.clip(rgb, 0, 1)
        return rgb

class FrequencySeperationTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the shared ImageManager
        self.filename = None
        self.image = None  # Original input image
        self.low_freq_image = None
        self.high_freq_image = None
        self.original_header = None
        self.is_mono = False
        self.processing_thread = None
        self.hfEnhancementThread = None
        self.hf_history = []

        # Default parameters
        self.method = 'Gaussian'
        self.radius = 25
        self.mirror = False
        self.tolerance = 50  # new tolerance param

        # Zoom/pan control
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        # For the preview
        self.spinnerLabel = None
        self.spinnerMovie = None

        # A guard variable to avoid infinite scroll loops
        self.syncing_scroll = False

        self.initUI()

        # Connect to ImageManager's image_changed signal if available
        if self.image_manager:
            self.image_manager.image_changed.connect(self.on_image_changed)
            # Load the existing image from ImageManager, if any
            if self.image_manager.image is not None:
                self.on_image_changed(
                    slot=self.image_manager.current_slot,
                    image=self.image_manager.image,
                    metadata=self.image_manager.current_metadata
                )

    def initUI(self):
        """
        Set up the GUI layout:
          - Left panel with controls (Load, Method, Radius, Mirror, Tolerance, Apply, Save, etc.)
          - Right panel with two scroll areas for HF/LF previews
        """
        main_layout = QHBoxLayout(self)
        self.setLayout(main_layout)

        # -----------------------------
        # Left side: Controls
        # -----------------------------
        left_widget = QWidget(self)
        left_widget.setFixedWidth(250)
        left_layout = QVBoxLayout(left_widget)

        # 1) Load image
        #self.loadButton = QPushButton("Load Image", self)
        #self.loadButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DirOpenIcon))
        #self.loadButton.clicked.connect(self.selectImage)
        #left_layout.addWidget(self.loadButton)

        self.fileLabel = QLabel("", self)
        left_layout.addWidget(self.fileLabel)

        # Method Combo
        self.method_combo = QComboBox(self)
        self.method_combo.addItems(['Gaussian', 'Median', 'Bilateral'])
        self.method_combo.currentTextChanged.connect(self.on_method_changed)
        left_layout.addWidget(QLabel("Method:", self))
        left_layout.addWidget(self.method_combo)

        # Radius Slider + Label
        self.radiusSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.radiusSlider.setRange(1, 100)
        self.radiusSlider.setValue(10)  # or whatever integer in [1..100] you want
        self.radiusSlider.valueChanged.connect(self.on_radius_changed)

        self.radiusLabel = QLabel("Radius:", self)
        left_layout.addWidget(self.radiusLabel)   
        left_layout.addWidget(self.radiusSlider)

        # Now force an initial update so label is correct from the start
        self.on_radius_changed(self.radiusSlider.value())

        # Tolerance Slider + Label
        self.toleranceSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.toleranceSlider.setRange(0, 100)
        self.toleranceSlider.setValue(self.tolerance)
        self.toleranceSlider.valueChanged.connect(self.on_tolerance_changed)
        self.toleranceLabel = QLabel(f"Tolerance: {self.tolerance}%", self)
        self.toleranceSlider.setEnabled(False)
        self.toleranceLabel.setEnabled(False)
        left_layout.addWidget(self.toleranceLabel)
        left_layout.addWidget(self.toleranceSlider)

        # Apply button
        self.applyButton = QPushButton("Apply - Split HF and LF", self)
        self.applyButton.clicked.connect(self.apply_frequency_separation)
        left_layout.addWidget(self.applyButton)        

        # -----------------------------------
        # *** New Sharpening Controls ***
        # -----------------------------------
        # 1) Checkbox for "Enable Sharpen Scale"
        self.sharpenScaleCheckBox = QCheckBox("Enable Sharpen Scale", self)
        self.sharpenScaleCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.sharpenScaleCheckBox)

        # Sharpen Scale Label + Slider
        self.sharpenScaleLabel = QLabel("Sharpen Scale: 1.00", self)
        left_layout.addWidget(self.sharpenScaleLabel)

        self.sharpenScaleSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.sharpenScaleSlider.setRange(10, 300)  # => 0.1..3.0
        self.sharpenScaleSlider.setValue(100)      # 1.00 initially
        self.sharpenScaleSlider.valueChanged.connect(self.onSharpenScaleChanged)
        left_layout.addWidget(self.sharpenScaleSlider)

        # 2) Checkbox for "Enable Wavelet Sharpening"
        self.waveletCheckBox = QCheckBox("Enable Wavelet Sharpening", self)
        self.waveletCheckBox.setChecked(True)  # or False by default
        left_layout.addWidget(self.waveletCheckBox)

        # Wavelet Sharpening Sliders
        wavelet_title = QLabel("<b>Wavelet Sharpening:</b>", self)
        left_layout.addWidget(wavelet_title)

        self.waveletLevelLabel = QLabel("Wavelet Level: 2", self)
        left_layout.addWidget(self.waveletLevelLabel)

        self.waveletLevelSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletLevelSlider.setRange(1, 5)
        self.waveletLevelSlider.setValue(2)
        self.waveletLevelSlider.valueChanged.connect(self.onWaveletLevelChanged)
        left_layout.addWidget(self.waveletLevelSlider)

        self.waveletBoostLabel = QLabel("Wavelet Boost: 1.20", self)
        left_layout.addWidget(self.waveletBoostLabel)

        self.waveletBoostSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.waveletBoostSlider.setRange(50, 300)  # => 0.5..3.0
        self.waveletBoostSlider.setValue(120)      # 1.20 initially
        self.waveletBoostSlider.valueChanged.connect(self.onWaveletBoostChanged)
        left_layout.addWidget(self.waveletBoostSlider)

        self.enableDenoiseCheckBox = QCheckBox("Enable HF Denoise", self)
        self.enableDenoiseCheckBox.setChecked(False)  # default off or on, your choice
        left_layout.addWidget(self.enableDenoiseCheckBox)

        # Label + Slider for denoise strength
        self.denoiseStrengthLabel = QLabel("Denoise Strength: 3.00", self)
        left_layout.addWidget(self.denoiseStrengthLabel)

        self.denoiseStrengthSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.denoiseStrengthSlider.setRange(0, 50)  # Example range -> 1..50 => 1.0..50.0
        self.denoiseStrengthSlider.setValue(3)      # default 3
        self.denoiseStrengthSlider.valueChanged.connect(self.onDenoiseStrengthChanged)
        left_layout.addWidget(self.denoiseStrengthSlider)
        self.onDenoiseStrengthChanged(self.denoiseStrengthSlider.value())

        # Create a horizontal layout for HF Enhancements and Undo
        hfEnhance_hlayout = QHBoxLayout()

        # Apply HF Enhancements button
        self.applyHFEnhancementsButton = QPushButton("Apply HF Enhancements", self)
        self.applyHFEnhancementsButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        self.applyHFEnhancementsButton.clicked.connect(self.applyHFEnhancements)
        hfEnhance_hlayout.addWidget(self.applyHFEnhancementsButton)

        # Undo button (tool button with back arrow icon)
        self.undoHFButton = QToolButton(self)
        self.undoHFButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack))
        self.undoHFButton.setToolTip("Undo last HF enhancement")
        self.undoHFButton.clicked.connect(self.undoHFEnhancement)
        self.undoHFButton.setEnabled(False)  # Initially disabled
        hfEnhance_hlayout.addWidget(self.undoHFButton)

        # Now add this horizontal layout to the main left_layout
        left_layout.addLayout(hfEnhance_hlayout)

        # ------------------------------------
        # Save HF / LF - in a horizontal layout
        # ------------------------------------
        save_hlayout = QHBoxLayout()

        self.saveHFButton = QPushButton("Save HF", self)
        self.saveHFButton.clicked.connect(self.save_high_frequency)
        save_hlayout.addWidget(self.saveHFButton)

        self.saveLFButton = QPushButton("Save LF", self)
        self.saveLFButton.clicked.connect(self.save_low_frequency)
        save_hlayout.addWidget(self.saveLFButton)

        left_layout.addLayout(save_hlayout)

        # ------------------------------------
        # Import HF / LF - in a separate horizontal layout
        # ------------------------------------
        load_hlayout = QHBoxLayout()

        self.importHFButton = QPushButton("Load HF", self)
        self.importHFButton.clicked.connect(self.loadHF)
        load_hlayout.addWidget(self.importHFButton)

        self.importLFButton = QPushButton("Load LF", self)
        self.importLFButton.clicked.connect(self.loadLF)
        load_hlayout.addWidget(self.importLFButton)

        left_layout.addLayout(load_hlayout)

        # Combine HF + LF
        self.combineButton = QPushButton("Combine HF + LF", self)
        self.combineButton.setIcon(self.style().standardIcon(QStyle.StandardPixmap.SP_DialogYesButton))
        self.combineButton.clicked.connect(self.combineHFandLF)
        left_layout.addWidget(self.combineButton)

        # Spinner for background processing
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Provide your spinner path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()
        left_layout.addWidget(self.spinnerLabel)

        # Spacer
        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # -----------------------------
        # Right Panel (vertical layout)
        # -----------------------------
        right_widget = QWidget(self)
        right_vbox = QVBoxLayout(right_widget)

        # 1) Zoom Buttons row (top)
        zoom_hbox = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In")
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        zoom_hbox.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out")
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        zoom_hbox.addWidget(self.zoom_out_btn)

        right_vbox.addLayout(zoom_hbox)

        # 2) HF / LF previews row (below)
        scroll_hbox = QHBoxLayout()

        self.scrollHF = QScrollArea(self)
        self.scrollHF.setWidgetResizable(False)
        self.labelHF = QLabel("High Frequency", self)
        self.labelHF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelHF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollHF.setWidget(self.labelHF)

        self.scrollLF = QScrollArea(self)
        self.scrollLF.setWidgetResizable(False)
        self.labelLF = QLabel("Low Frequency", self)
        self.labelLF.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.labelLF.setStyleSheet("background-color: #333; color: #CCC;")
        self.scrollLF.setWidget(self.labelLF)

        scroll_hbox.addWidget(self.scrollHF, stretch=1)
        scroll_hbox.addWidget(self.scrollLF, stretch=1)

        right_vbox.addLayout(scroll_hbox, stretch=1)
        main_layout.addWidget(right_widget, stretch=1)

        # Sync scrollbars
        self.scrollHF.horizontalScrollBar().valueChanged.connect(self.syncHFHScroll)
        self.scrollHF.verticalScrollBar().valueChanged.connect(self.syncHFVScroll)
        self.scrollLF.horizontalScrollBar().valueChanged.connect(self.syncLFHScroll)
        self.scrollLF.verticalScrollBar().valueChanged.connect(self.syncLFVScroll)

        # Mouse drag panning
        self.scrollHF.viewport().installEventFilter(self)
        self.scrollLF.viewport().installEventFilter(self)

        # Force initial label update
        self.on_radius_changed(self.radiusSlider.value())
        self.on_tolerance_changed(self.toleranceSlider.value())

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    # -----------------------------
    # Image Manager Integration
    # -----------------------------
    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the FrequencySeperationTab if the change is relevant.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if needed

            # Update internal state with the new image and metadata
            self.loaded_image_path = metadata.get('file_path', None)
            self.image = image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = self.loaded_image_path

            # Reset HF / LF placeholders
            self.low_freq_image = None
            self.high_freq_image = None

            # Update UI label to show the file name or indicate no file
            # Update the fileLabel in the Frequency Separation Tab (or any other tab)
            if self.image_manager.image is not None:
                # Retrieve the file path from the metadata in ImageManager
                file_path = self.image_manager._metadata[self.image_manager.current_slot].get('file_path', None)

                # If file_path is a string, get the basename; otherwise, use a default message.
                if file_path and isinstance(file_path, str):
                    display_name = os.path.basename(file_path)
                else:
                    display_name = "No file selected"

                self.fileLabel.setText(display_name)
            else:
                self.fileLabel.setText("No file selected")


            # Automatically apply frequency separation
            self.apply_frequency_separation()

            print(f"FrequencySeperationTab: Image updated from ImageManager slot {slot}.")


    def map_slider_to_radius(self, slider_pos):
        """
        Convert a slider position (0..100) into a non-linear float radius.
        Segment A: [0..10]   -> [0.1..1.0]
        Segment B: [10..50]  -> [1.0..10.0]
        Segment C: [50..100] -> [10.0..100.0]
        """
        if slider_pos <= 10:
            # Scale 0..10 -> 0.1..1.0
            t = slider_pos / 10.0           # t in [0..1]
            radius = 0.1 + t*(1.0 - 0.1)    # 0.1 -> 1.0
        elif slider_pos <= 50:
            # Scale 10..50 -> 1.0..10.0
            t = (slider_pos - 10) / 40.0    # t in [0..1]
            radius = 1.0 + t*(10.0 - 1.0)   # 1.0 -> 10.0
        else:
            # Scale 50..100 -> 10.0..100.0
            t = (slider_pos - 50) / 50.0    # t in [0..1]
            radius = 10.0 + t*(100.0 - 10.0)  # 10.0 -> 100.0
        
        return radius

    def onSharpenScaleChanged(self, val):
        scale = val / 100.0  # 10..300 => 0.1..3.0
        self.sharpenScaleLabel.setText(f"Sharpen Scale: {scale:.2f}")

    def onWaveletLevelChanged(self, val):
        self.waveletLevelLabel.setText(f"Wavelet Level: {val}")

    def onWaveletBoostChanged(self, val):
        boost = val / 100.0  # e.g. 50..300 => 0.50..3.00
        self.waveletBoostLabel.setText(f"Wavelet Boost: {boost:.2f}")

    def onDenoiseStrengthChanged(self, val):
        # Map 0..50 => 0..5.0 by dividing by 10
        denoise_strength = val / 10.0
        self.denoiseStrengthLabel.setText(f"Denoise Strength: {denoise_strength:.2f}")

    # -------------------------------------------------
    # Event Filter for Drag Panning
    # -------------------------------------------------
    def eventFilter(self, obj, event):
        if obj in (self.scrollHF.viewport(), self.scrollLF.viewport()):
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()

                if obj == self.scrollHF.viewport():
                    # Move HF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync LF
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollHF.horizontalScrollBar().value()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollHF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                else:
                    # Move LF scrollbars
                    self.syncing_scroll = True
                    try:
                        self.scrollLF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value() - delta.x()
                        )
                        self.scrollLF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value() - delta.y()
                        )
                        # Sync HF
                        self.scrollHF.horizontalScrollBar().setValue(
                            self.scrollLF.horizontalScrollBar().value()
                        )
                        self.scrollHF.verticalScrollBar().setValue(
                            self.scrollLF.verticalScrollBar().value()
                        )
                    finally:
                        self.syncing_scroll = False
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(obj, event)

    # -----------------------------
    # Scrolling Sync
    # -----------------------------
    def syncHFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncHFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollLF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFHScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.horizontalScrollBar().setValue(value)
            self.syncing_scroll = False

    def syncLFVScroll(self, value):
        if not self.syncing_scroll:
            self.syncing_scroll = True
            self.scrollHF.verticalScrollBar().setValue(value)
            self.syncing_scroll = False

    # -----------------------------
    # Zooming
    # -----------------------------

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.25
        self.update_previews()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.25
        self.update_previews()

    # -----------------------------
    # Control Handlers
    # -----------------------------
    def on_method_changed(self, text):
        """
        Called whenever the method dropdown changes (Gaussian, Median, Bilateral).
        Enable the tolerance slider only for 'Bilateral'.
        """
        self.method = text
        if self.method == 'Bilateral':
            self.toleranceSlider.setEnabled(True)
            self.toleranceLabel.setEnabled(True)
        else:
            self.toleranceSlider.setEnabled(False)
            self.toleranceLabel.setEnabled(False)

    def on_radius_changed(self, value):
        new_radius = self.map_slider_to_radius(value)  # use self.
        self.radius = new_radius
        self.radiusLabel.setText(f"Radius: {new_radius:.2f}")


    def on_tolerance_changed(self, value):
        self.tolerance = value
        self.toleranceLabel.setText(f"Tolerance: {value}%")  # Update label

    def undoHFEnhancement(self):
        """
        Revert HF to the last state from hf_history, if available.
        Disable Undo if no more history is left.
        """
        if len(self.hf_history) == 0:
            return  # No history to revert
        
        # Pop the last saved HF
        old_hf = self.hf_history.pop()

        # Restore it
        self.high_freq_image = old_hf
        self.update_previews()
        self.fileLabel.setText("Undid last HF enhancement.")

        # If no more states are left, disable the Undo button again
        if len(self.hf_history) == 0:
            self.undoHFButton.setEnabled(False)


    def applyHFEnhancements(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No HF image to enhance.")
            return
        
        self.hf_history.append(self.high_freq_image.copy())

        # Enable the Undo button because now we have at least one state
        self.undoHFButton.setEnabled(True)

        self.showSpinner()

        # If a previous thread is running, kill it safely
        if self.hfEnhancementThread and self.hfEnhancementThread.isRunning():
            self.hfEnhancementThread.quit()
            self.hfEnhancementThread.wait()

        # Check Sharpen Scale
        enable_scale = self.sharpenScaleCheckBox.isChecked()
        sharpen_scale = self.sharpenScaleSlider.value() / 100.0

        # Wavelet
        enable_wavelet = self.waveletCheckBox.isChecked()
        wavelet_level = self.waveletLevelSlider.value()
        wavelet_boost = self.waveletBoostSlider.value() / 100.0

        # Denoise
        enable_denoise = self.enableDenoiseCheckBox.isChecked()
        denoise_strength = float(self.denoiseStrengthSlider.value()/10.0)  # or do /10 if you want finer steps

        # Instantiate HFEnhancementThread with denoise params
        self.hfEnhancementThread = HFEnhancementThread(
            hf_image=self.high_freq_image,
            enable_scale=enable_scale,
            sharpen_scale=sharpen_scale,
            enable_wavelet=enable_wavelet,
            wavelet_level=wavelet_level,
            wavelet_boost=wavelet_boost,
            wavelet_name='db2',
            enable_denoise=enable_denoise,
            denoise_strength=denoise_strength
        )
        self.hfEnhancementThread.enhancement_done.connect(self.onHFEnhancementDone)
        self.hfEnhancementThread.error_signal.connect(self.onHFEnhancementError)
        self.hfEnhancementThread.start()


    def onHFEnhancementDone(self, newHF):
        self.hideSpinner()
        self.high_freq_image = newHF  # updated HF
        self.update_previews()
        self.fileLabel.setText("HF enhancements applied (thread).")

    def onHFEnhancementError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"HF enhancement error: {msg}")

    # -----------------------------
    # Image Selection and Preview Methods
    # -----------------------------
    def selectImage(self):
        if not self.image_manager:
            QMessageBox.warning(self, "Warning", "ImageManager not initialized.")
            return

        selected_file, _ = QFileDialog.getOpenFileName(self, "Open Image", "", 
                                            "Images (*.png *.tif *.tiff *.fit *.fits *.xisf *.cr2 *.nef *.arw *.dng *.orf *.rw2 *.pef);;All Files (*)")
        if selected_file:
            try:
                img, header, bit_depth, is_mono = load_image(selected_file)
                if img is None:
                    QMessageBox.critical(self, "Error", "Failed to load the image. Please try a different file.")
                    return

                print(f"FrequencySeperationTab: Image loaded successfully. Shape: {img.shape}, Dtype: {img.dtype}")

                self.image = img
                self.original_header = header
                self.is_mono = is_mono
                self.filename = selected_file
                self.fileLabel.setText(os.path.basename(selected_file))

                # Reset HF / LF placeholders
                self.low_freq_image = None
                self.high_freq_image = None

                # Update ImageManager with the new image
                metadata = {
                    'file_path': self.filename,
                    'original_header': self.original_header,
                    'bit_depth': bit_depth,
                    'is_mono': self.is_mono
                }
                self.image_manager.set_current_image(image=img, metadata=metadata)
                print("FrequencySeperationTab: Image updated in ImageManager.")

            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                print(f"FrequencySeperationTab: Error loading image: {e}")

    def save_high_frequency(self):
        if self.high_freq_image is None:
            self.fileLabel.setText("No high-frequency image to save.")
            return
        self._save_image_with_dialog(self.high_freq_image, suffix="_HF")

    def save_low_frequency(self):
        if self.low_freq_image is None:
            self.fileLabel.setText("No low-frequency image to save.")
            return
        self._save_image_with_dialog(self.low_freq_image, suffix="_LF")

    def _save_image_with_dialog(self, image_to_save, suffix=""):
        """
        Always save HF in 32-bit floating point, either .tif or .fits.
        """
        if self.filename:
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + suffix + '.tif'
            original_dir = os.path.dirname(self.filename)
        else:
            default_save_name = "untitled" + suffix + '.tif'
            original_dir = os.getcwd()

        # Restrict the file dialog to TIF/FITS by default,
        # but let's keep .png, etc., in case user tries to pick it.
        # We'll override if they do.
        save_filename, _ = QFileDialog.getSaveFileName(
            self,
            'Save HF Image as 32-bit Float',
            os.path.join(original_dir, default_save_name),
            'TIFF or FITS (*.tif *.tiff *.fits *.fit);;All Files (*)'
        )
        if save_filename:
            # Identify extension
            file_ext = os.path.splitext(save_filename)[1].lower().strip('.')  # e.g. 'tif', 'fits', etc.

            # If user picks something else (png/jpg), override to .tif
            if file_ext not in ['tif', 'tiff', 'fit', 'fits']:
                file_ext = 'tif'
                # Force the filename to end with .tif
                save_filename = os.path.splitext(save_filename)[0] + '.tif'

            # We skip prompting for bit depth since we always want 32-bit float
            bit_depth = "32-bit floating point"

            # Force original_format to the extension we ended up with
            save_image(
                image_to_save,
                save_filename,
                original_format=file_ext,     # e.g. 'tif' or 'fits'
                bit_depth=bit_depth,
                original_header=self.original_header,
                is_mono=self.is_mono
            )
            self.fileLabel.setText(f"Saved 32-bit float HF: {os.path.basename(save_filename)}")


    def loadHF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load High Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                hf, _, _, _ = load_image(selected_file)
                self.high_freq_image = hf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading HF: {str(e)}")

    def loadLF(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, "Load Low Frequency Image", "", "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                lf, _, _, _ = load_image(selected_file)
                self.low_freq_image = lf
                self.update_previews()
            except Exception as e:
                self.fileLabel.setText(f"Error loading LF: {str(e)}")

    def combineHFandLF(self):
        if self.low_freq_image is None or self.high_freq_image is None:
            self.fileLabel.setText("Cannot combine; LF or HF is missing.")
            return

        # Check shape
        if self.low_freq_image.shape != self.high_freq_image.shape:
            self.fileLabel.setText("Error: LF and HF dimensions do not match.")
            return

        # Combine
        combined = self.low_freq_image + self.high_freq_image
        combined = np.clip(combined, 0, 1)  # Ensure values are within [0,1]

        # Retrieve the active mask
        mask = self.get_active_mask()

        if mask is not None:
            # If combined image is multi-channel but mask is single-channel, expand mask dimensions
            if combined.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)

            # Ensure mask dimensions match the combined image dimensions
            if mask.shape[:2] != combined.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match the combined image dimensions.")
                return

            # Blend the combined image with the original image using the mask
            # Formula: blended_combined = combined * mask + original_image * (1 - mask)
            blended_combined = combined * mask + self.image * (1 - mask)
            blended_combined = np.clip(blended_combined, 0.0, 1.0)  # Ensure values are within [0,1]
            print("Combined image with mask applied.")
        else:
            # No mask applied; use the combined image directly
            blended_combined = combined
            print("Combined image without mask.")

        # Create a new preview window (non-modal) with the blended combined image
        self.combined_window = CombinedPreviewWindow(
            blended_combined, 
            image_manager=self.image_manager,
            original_header=self.original_header,
            is_mono=self.is_mono
        )
        # Show it. Because we use `show()`, it won't block the main UI
        self.combined_window.show()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Combined image with mask applied.")
        else:
            self.fileLabel.setText("Combined image without mask.")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    # -----------------------------
    # Applying Frequency Separation (background thread)
    # -----------------------------
    def apply_frequency_separation(self):
        if self.image is None:
            self.fileLabel.setText("No input image loaded.")
            return

        self.showSpinner()

        if self.processing_thread and self.processing_thread.isRunning():
            self.processing_thread.quit()
            self.processing_thread.wait()

        # pass in 'tolerance' too
        self.processing_thread = FrequencySeperationThread(
            image=self.image,
            method=self.method,
            radius=self.radius,
            tolerance=self.tolerance
        )
        self.processing_thread.separation_done.connect(self.onSeparationDone)
        self.processing_thread.error_signal.connect(self.onSeparationError)
        self.processing_thread.start()

    def onSeparationDone(self, lf, hf):
        self.hideSpinner()
        self.low_freq_image = lf
        self.high_freq_image = hf
        self.update_previews()

    def onSeparationError(self, msg):
        self.hideSpinner()
        self.fileLabel.setText(f"Error during separation: {msg}")

    # -----------------------------
    # Spinner control
    # -----------------------------
    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # -----------------------------
    # Preview
    # -----------------------------
    def update_previews(self):
        """
        Render HF/LF images with current zoom_factor.
        HF gets an offset of +0.5 for display.
        """
        # Low Frequency
        if self.low_freq_image is not None:
            lf_disp = np.clip(self.low_freq_image, 0, 1)
            pixmap_lf = self._numpy_to_qpixmap(lf_disp)
            # Scale by zoom_factor (cast to int)
            scaled_lf = pixmap_lf.scaled(
                int(pixmap_lf.width() * self.zoom_factor),
                int(pixmap_lf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelLF.setPixmap(scaled_lf)
            self.labelLF.resize(scaled_lf.size())
        else:
            self.labelLF.setText("Low Frequency")
            self.labelLF.resize(self.labelLF.sizeHint())

        # High Frequency
        if self.high_freq_image is not None:
            hf_disp = self.high_freq_image + 0.5
            hf_disp = np.clip(hf_disp, 0, 1)
            pixmap_hf = self._numpy_to_qpixmap(hf_disp)
            scaled_hf = pixmap_hf.scaled(
                int(pixmap_hf.width() * self.zoom_factor),
                int(pixmap_hf.height() * self.zoom_factor),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.labelHF.setPixmap(scaled_hf)
            self.labelHF.resize(scaled_hf.size())
        else:
            self.labelHF.setText("High Frequency")
            self.labelHF.resize(self.labelHF.sizeHint())

    def _numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to a QPixmap for display.
        """
        if img_float32.ndim == 2:
            img_float32 = np.stack([img_float32]*3, axis=-1)

        img_ubyte = (img_float32 * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_img = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_img)

class CombinedPreviewWindow(QWidget):
    """
    A pop-out window that shows the combined HF+LF image in a scrollable, zoomable preview.
    """
    def __init__(self, combined_image, image_manager, original_header=None, is_mono=False, parent=None):
        """
        :param combined_image: Float32 numpy array in [0,1], shape = (H,W) or (H,W,3).
        :param original_header: Optional metadata (for saving as FITS, etc.).
        :param is_mono: Boolean indicating grayscale vs. color.
        """
        super().__init__(parent)
        self.setWindowTitle("Combined HF + LF Preview")
        self.combined_image = combined_image
        self.image_manager = image_manager  # Reference to ImageManage
        self.original_header = original_header
        self.is_mono = is_mono

        # Zoom/panning
        self.zoom_factor = 1.0
        self.dragging = False
        self.last_mouse_pos = QPoint()

        self.initUI()
        # Render the combined image initially
        self.updatePreview()

    def initUI(self):
        main_layout = QVBoxLayout(self)
        self.setLayout(main_layout)

        # --- Top: Zoom / Fit / Save Buttons ---
        top_btn_layout = QHBoxLayout()
        self.zoom_in_btn = QPushButton("Zoom In", self)
        self.zoom_in_btn.clicked.connect(self.zoom_in)
        top_btn_layout.addWidget(self.zoom_in_btn)

        self.zoom_out_btn = QPushButton("Zoom Out", self)
        self.zoom_out_btn.clicked.connect(self.zoom_out)
        top_btn_layout.addWidget(self.zoom_out_btn)

        self.fit_btn = QPushButton("Fit to Preview", self)
        self.fit_btn.clicked.connect(self.fit_to_preview)
        top_btn_layout.addWidget(self.fit_btn)

        # New "Apply Changes" button
        self.apply_btn = QPushButton("Apply Changes/Push for Processing", self)
        self.apply_btn.clicked.connect(self.apply_changes)
        top_btn_layout.addWidget(self.apply_btn)

        main_layout.addLayout(top_btn_layout)

        # --- Scroll Area with a QLabel for image ---
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(False)
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Put the label inside the scroll area
        self.scrollArea.setWidget(self.imageLabel)
        main_layout.addWidget(self.scrollArea)

        # Enable mouse-drag panning
        self.scrollArea.viewport().installEventFilter(self)

        # Provide a decent default window size
        self.resize(1000, 600)

    def eventFilter(self, source, event):
        if source == self.scrollArea.viewport():
            if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = True
                self.last_mouse_pos = event.pos()
                return True
            elif event.type() == QEvent.Type.MouseMove and self.dragging:
                delta = event.pos() - self.last_mouse_pos
                self.last_mouse_pos = event.pos()
                # Adjust scrollbars
                self.scrollArea.horizontalScrollBar().setValue(
                    self.scrollArea.horizontalScrollBar().value() - delta.x()
                )
                self.scrollArea.verticalScrollBar().setValue(
                    self.scrollArea.verticalScrollBar().value() - delta.y()
                )
                return True
            elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
                self.dragging = False
                return True
        return super().eventFilter(source, event)

    def updatePreview(self):
        """
        Render the combined image into self.imageLabel at the current zoom_factor.
        """
        if self.combined_image is None:
            self.imageLabel.setText("No combined image.")
            return

        # Convert float32 [0,1] -> QPixmap
        pixmap = self.numpy_to_qpixmap(self.combined_image)
        # Scale by zoom_factor
        new_width = int(pixmap.width() * self.zoom_factor)
        new_height = int(pixmap.height() * self.zoom_factor)
        scaled = pixmap.scaled(new_width, new_height, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Update label
        self.imageLabel.setPixmap(scaled)
        self.imageLabel.resize(scaled.size())

    def numpy_to_qpixmap(self, img_float32):
        """
        Convert float32 [0,1] array (H,W) or (H,W,3) to QPixmap.
        """
        if img_float32.ndim == 2:
            # grayscale
            img_float32 = np.stack([img_float32]*3, axis=-1)
        img_ubyte = (np.clip(img_float32, 0, 1) * 255).astype(np.uint8)
        h, w, ch = img_ubyte.shape
        bytes_per_line = ch * w
        q_image = QImage(img_ubyte.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
        return QPixmap.fromImage(q_image)

    # -----------------------------
    # Zoom
    # -----------------------------
    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()


    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.2
        self.updatePreview()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.2
        self.updatePreview()

    def fit_to_preview(self):
        """
        Adjust zoom_factor so the combined image width fits in the scrollArea width.
        """
        if self.combined_image is None:
            return

        # Get the actual image size
        h, w = self.combined_image.shape[:2]
        # The scrollArea's viewport is how much space we have to show it
        viewport_width = self.scrollArea.viewport().width()

        # Estimate new zoom factor so image fits horizontally
        # (You could also consider fitting by height or whichever is smaller.)
        # Must convert w from image to display pixel scale.
        # We'll guess the "base" is 1.0 => original width => we guess that is w pixels wide
        # So new_zoom = viewport_width / (w in original scale).
        new_zoom = viewport_width / float(w)
        if new_zoom < 0.01:
            new_zoom = 0.01

        self.zoom_factor = new_zoom
        self.updatePreview()

    def apply_changes(self):
        """
        Push the combined image to ImageManager's slot 0 for further processing.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "No Image", "There is no combined image to apply.")
            return

        # Metadata for the combined image
        metadata = {
            'file_path': "Combined HF+LF Applied",
            'original_header': self.original_header,
            'is_mono': self.is_mono,
            'bit_depth': "32-bit floating point"
        }

        # Push the combined image to slot 0
        self.image_manager.set_image(self.combined_image, metadata, step_name="Frequency Separation")
        QMessageBox.information(self, "Changes Applied", "The combined image has been pushed to slot 0 for processing.")

        # Close the preview window (optional)
        self.close()       

class HFEnhancementThread(QThread):
    """
    A QThread that can:
      1) Scale HF by 'sharpen_scale' (if enabled)
      2) Wavelet-sharpen HF (if enabled)
      3) Denoise HF (if enabled)
    """
    enhancement_done = pyqtSignal(np.ndarray)
    error_signal = pyqtSignal(str)

    def __init__(
        self, 
        hf_image, 
        enable_scale=True,
        sharpen_scale=1.0, 
        enable_wavelet=True,
        wavelet_level=2, 
        wavelet_boost=1.2, 
        wavelet_name='db2',
        enable_denoise=False,
        denoise_strength=3.0,
        parent=None
    ):
        super().__init__(parent)
        self.hf_image = hf_image
        self.enable_scale = enable_scale
        self.sharpen_scale = sharpen_scale
        self.enable_wavelet = enable_wavelet
        self.wavelet_level = wavelet_level
        self.wavelet_boost = wavelet_boost
        self.wavelet_name = wavelet_name
        self.enable_denoise = enable_denoise
        self.denoise_strength = denoise_strength

    def run(self):
        try:
            # Make a copy so we don't mutate the original
            enhanced_hf = self.hf_image.copy()

            # 1) Sharpen Scale
            if self.enable_scale:
                enhanced_hf *= self.sharpen_scale

            # 2) Wavelet Sharpen
            if self.enable_wavelet:
                enhanced_hf = self.wavelet_sharpen(
                    enhanced_hf,
                    wavelet=self.wavelet_name,
                    level=self.wavelet_level,
                    boost=self.wavelet_boost
                )

            # 3) Denoise
            if self.enable_denoise:
                enhanced_hf = self.denoise_hf(enhanced_hf, self.denoise_strength)

            self.enhancement_done.emit(enhanced_hf.astype(np.float32))
        except Exception as e:
            self.error_signal.emit(str(e))

    # -------------------------------------
    # Wavelet Sharpen Methods
    # -------------------------------------
    def wavelet_sharpen(self, hf, wavelet='db2', level=2, boost=1.2):
        """
        Apply wavelet sharpening to the HF image.
        Handles both color and monochrome images.
        """
        # Check if the image is color or mono
        if hf.ndim == 3 and hf.shape[2] == 3:
            # Color image: process each channel separately
            channels = []
            for c in range(3):
                c_data = hf[..., c]
                c_sharp = self.wavelet_sharpen_mono(c_data, wavelet, level, boost)
                channels.append(c_sharp)
            # Stack the channels back into a color image
            return np.stack(channels, axis=-1)
        else:
            # Monochrome image
            return self.wavelet_sharpen_mono(hf, wavelet, level, boost)

    def wavelet_sharpen_mono(self, mono_hf, wavelet, level, boost):
        """
        Apply wavelet sharpening to a single-channel (monochrome) HF image.
        Ensures that the output image has the same dimensions as the input.
        """
        # Perform wavelet decomposition with 'periodization' mode to preserve dimensions
        coeffs = pywt.wavedec2(mono_hf, wavelet=wavelet, level=level, mode='periodization')

        # Boost the detail coefficients
        new_coeffs = [coeffs[0]]  # Approximation coefficients remain unchanged
        for detail in coeffs[1:]:
            cH, cV, cD = detail
            cH *= boost
            cV *= boost
            cD *= boost
            new_coeffs.append((cH, cV, cD))

        # Reconstruct the image with 'periodization' mode
        result = pywt.waverec2(new_coeffs, wavelet=wavelet, mode='periodization')

        # Ensure the reconstructed image has the same shape as the original
        original_shape = mono_hf.shape
        reconstructed_shape = result.shape

        if reconstructed_shape != original_shape:
            # Calculate the difference in dimensions                                            
            delta_h = reconstructed_shape[0] - original_shape[0]
            delta_w = reconstructed_shape[1] - original_shape[1]

            # Crop the excess pixels if the reconstructed image is larger
            if delta_h > 0 or delta_w > 0:
                result = result[:original_shape[0], :original_shape[1]]
            # Pad the image with zeros if it's smaller (rare, but for robustness)
            elif delta_h < 0 or delta_w < 0:
                pad_h = max(-delta_h, 0)
                pad_w = max(-delta_w, 0)
                result = np.pad(result, 
                               ((0, pad_h), (0, pad_w)), 
                               mode='constant', 
                               constant_values=0)

        return result

    # -------------------------------------
    # Denoise HF
    # -------------------------------------
    def denoise_hf(self, hf, strength=3.0):
        """
        Use OpenCV's fastNlMeansDenoisingColored or fastNlMeansDenoising for HF.
        Because HF can be negative, we offset +0.5 -> [0..1], scale -> [0..255].
        """
        # If color
        if hf.ndim == 3 and hf.shape[2] == 3:
            bgr = cv2.cvtColor(hf, cv2.COLOR_RGB2BGR)
            tmp = np.clip(bgr + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            # fastNlMeansDenoisingColored(src, None, hColor, hLuminance, templateWindowSize, searchWindowSize)
            denoised8 = cv2.fastNlMeansDenoisingColored(tmp8, None, strength, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            denoised_rgb = cv2.cvtColor(denoised_f32, cv2.COLOR_BGR2RGB)
            return denoised_rgb
        else:
            # Mono
            tmp = np.clip(hf + 0.5, 0, 1)
            tmp8 = (tmp * 255).astype(np.uint8)
            denoised8 = cv2.fastNlMeansDenoising(tmp8, None, strength, 7, 21)
            denoised_f32 = denoised8.astype(np.float32) / 255.0 - 0.5
            return denoised_f32

class FrequencySeperationThread(QThread):
    """
    A QThread that performs frequency separation on a float32 [0,1] image array.
    This keeps the GUI responsive while processing.

    Signals:
        separation_done(np.ndarray, np.ndarray):
            Emitted with (low_freq, high_freq) images when finished.
        error_signal(str):
            Emitted if an error or exception occurs.
    """

    # Signal emitted when separation is complete. 
    # The arguments are low-frequency (LF) and high-frequency (HF) images.
    separation_done = pyqtSignal(np.ndarray, np.ndarray)

    # Signal emitted if there's an error during processing
    error_signal = pyqtSignal(str)

    def __init__(self, image, method='Gaussian', radius=5, tolerance=50, parent=None):
        """
        :param image: Float32 NumPy array in [0,1], shape = (H,W) or (H,W,3).
        :param method: 'Gaussian', 'Median', or 'Bilateral' (default: 'Gaussian').
        :param radius: Numeric value controlling the filter's strength (e.g., Gaussian sigma).
        :param mirror: Boolean to indicate if border handling is mirrored (optional example param).
        """
        super().__init__(parent)
        self.image = image
        self.method = method
        self.radius = radius
        self.tolerance = tolerance

    def run(self):
        try:
            # Convert the input image from RGB to BGR if it's 3-channel
            if self.image.ndim == 3 and self.image.shape[2] == 3:
                bgr = cv2.cvtColor(self.image, cv2.COLOR_RGB2BGR)
            else:
                # If mono, just use it as is
                bgr = self.image.copy()

            # Choose the filter based on self.method
            if self.method == 'Gaussian':
                # For Gaussian, interpret radius as sigma
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)
            elif self.method == 'Median':
                # For Median, the radius is the kernel size (must be odd)
                ksize = max(1, int(self.radius) // 2 * 2 + 1)
                low_bgr = cv2.medianBlur(bgr, ksize)
            elif self.method == 'Bilateral':
                # Example usage: interpret "tolerance" as a fraction of the default 50
                # so if tolerance=50 => sigmaColor=50*(50/100)=25, sigmaSpace=25
                # Or do your own logic for how tolerance modifies Bilateral
                sigma = 50 * (self.tolerance / 100.0)
                d = int(self.radius)
                low_bgr = cv2.bilateralFilter(bgr, d, sigma, sigma)
            else:
                # Fallback to Gaussian if unknown
                low_bgr = cv2.GaussianBlur(bgr, (0, 0), self.radius)

            # Convert low frequency image back to RGB if it's 3-channel
            if low_bgr.ndim == 3 and low_bgr.shape[2] == 3:
                low_rgb = cv2.cvtColor(low_bgr, cv2.COLOR_BGR2RGB)
            else:
                low_rgb = low_bgr

            # Calculate the high frequency
            # (note: keep in float32 to preserve negative/positive values)
            high_rgb = self.image - low_rgb

            # Emit the results
            self.separation_done.emit(low_rgb, high_rgb)

        except Exception as e:
            # Any error gets reported via the error_signal
            self.error_signal.emit(str(e))



class PalettePickerProcessingThread(QThread):
    """
    Thread for processing images to prevent UI freezing.
    """
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image, oiii_image, sii_image, osc1_image, osc2_image, ha_to_oii_ratio, enable_star_stretch, stretch_factor):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc1_image = osc1_image  # Added for OSC1
        self.osc2_image = osc2_image  # Added for OSC2
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        """
        Perform image processing to generate a combined preview.
        """
        try:
            combined_ha = self.ha_image.copy() if self.ha_image is not None else None
            combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None

            # Process OSC1 if available
            if self.osc1_image is not None:
                # Extract synthetic Ha and OIII from OSC1
                ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
                oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc1 = stretch_mono_image(ha_osc1, target_median=self.stretch_factor)
                    oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
                else:
                    combined_ha = ha_osc1

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
                else:
                    combined_oiii = oiii_osc1

            # Process OSC2 if available
            if self.osc2_image is not None:
                # Extract synthetic Ha and OIII from OSC2
                ha_osc2 = self.osc2_image[:, :, 0]  # Red channel -> Ha
                oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    ha_osc2 = stretch_mono_image(ha_osc2, target_median=self.stretch_factor)
                    oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=self.stretch_factor)

                # Combine with existing Ha and OIII
                if combined_ha is not None:
                    combined_ha = (combined_ha * 0.5) + (ha_osc2 * 0.5)
                else:
                    combined_ha = ha_osc2

                if combined_oiii is not None:
                    combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
                else:
                    combined_oiii = oiii_osc2

            # Ensure that combined Ha and OIII are present
            if combined_ha is not None and combined_oiii is not None:
                # Combine Ha and OIII based on the specified ratio
                combined = (combined_ha * self.ha_to_oii_ratio) + (combined_oiii * (1 - self.ha_to_oii_ratio))

                # Apply stretching if enabled
                if self.enable_star_stretch:
                    combined = stretch_mono_image(combined, target_median=self.stretch_factor)

                # Incorporate SII channel if available
                if self.sii_image is not None:
                    combined = combined + self.sii_image
                    # Normalize to prevent overflow
                    combined = self.normalize_image(combined)

                self.preview_generated.emit(combined)
            else:
                # If required channels are missing, emit a dummy image or handle accordingly
                combined = np.zeros((100, 100, 3))  # Dummy image
                self.preview_generated.emit(combined)
        except Exception as e:
            print(f"Error in PalettePickerProcessingThread: {e}")
            self.preview_generated.emit(None)

    @staticmethod
    def normalize_image(image):
        return image

class PaletteAdjustDialog(QDialog):
    adjusted_image = pyqtSignal(np.ndarray)

    def __init__(self, base_rgb, palette_name, ha_src, oiii_src, sii_src, owner_tab):
        super().__init__(owner_tab)
        self.setWindowTitle("Adjust Palette Intensities")
        self.setModal(True)

        # store args
        self.base_rgb     = base_rgb.astype(np.float32)
        self.palette_name = palette_name
        self.ha_src       = ha_src
        self.oiii_src     = oiii_src
        self.sii_src      = sii_src
        self.owner        = owner_tab

        # sliders state
        self.ha_factor   = 1.0
        self.oiii_factor = 1.0
        self.sii_factor  = 1.0

        # debounce timer
        self._debounce = QTimer(self)
        self._debounce.setInterval(300)
        self._debounce.setSingleShot(True)
        self._debounce.timeout.connect(self._update_preview)

        # zoom & pan state
        self.zoom_factor = 1.0
        self._dragging = False
        self._last_pos = QPoint()

        vlayout = QVBoxLayout(self)

        # ─── Zoom / Fit Controls ─────────────────────────
        zoom_layout = QHBoxLayout()
        btn_zoom_in  = QPushButton("Zoom In")
        btn_zoom_out = QPushButton("Zoom Out")
        btn_fit      = QPushButton("Fit to Preview")
        btn_zoom_in.clicked.connect(lambda: self._change_zoom(1.25))
        btn_zoom_out.clicked.connect(lambda: self._change_zoom(0.8))
        btn_fit.clicked.connect(self._fit_to_preview)
        zoom_layout.addWidget(btn_zoom_in)
        zoom_layout.addWidget(btn_zoom_out)
        zoom_layout.addWidget(btn_fit)
        vlayout.addLayout(zoom_layout)

        # ─── Preview Area ────────────────────────────────
        self.preview_area = QScrollArea(self)
        self.preview_area.setWidgetResizable(True)
        self.preview_label = QLabel(alignment=Qt.AlignmentFlag.AlignCenter)
        self.preview_label.setCursor(Qt.CursorShape.OpenHandCursor)
        self.preview_label.setMouseTracking(True)
        self.preview_area.setWidget(self.preview_label)
        vlayout.addWidget(self.preview_area, stretch=1)

        # allow pan & wheel on the label
        self.preview_label.installEventFilter(self)

        # ─── Sliders ─────────────────────────────────────
        for name in ("Ha","OIII","SII"):
            row = QHBoxLayout()
            row.addWidget(QLabel(f"{name} Intensity:", self))
            slider = QSlider(Qt.Orientation.Horizontal, self)
            slider.setRange(0,200)
            slider.setValue(100)
            slider.valueChanged.connect(self._on_slider_change)
            setattr(self, f"_{name.lower()}_slider", slider)
            row.addWidget(slider)
            vlayout.addLayout(row)

        # ─── Accept / Reset / Discard ─────────────────────
        btns = QHBoxLayout()
        btns.addStretch()
        accept  = QPushButton("Accept",  self)
        reset   = QPushButton("Reset",   self)
        discard = QPushButton("Discard", self)
        btns.addWidget(accept); btns.addWidget(reset); btns.addWidget(discard)
        vlayout.addLayout(btns)
        accept.clicked.connect(self._on_accept)
        reset.clicked.connect(self._on_reset)
        discard.clicked.connect(self.reject)

        # Trigger first draw
        self._update_preview()


    def _on_slider_change(self, _):
        self.ha_factor   = self._ha_slider.value()   / 100.0
        self.oiii_factor = self._oiii_slider.value() / 100.0
        self.sii_factor  = self._sii_slider.value()  / 100.0
        self._debounce.start()


    def _update_preview(self):
        """ Recompute full‐res image (heavy) and store as self._base_pixmap. """
        # 1) build scaled mono channels
        ha = (self.ha_src   * self.ha_factor)   if self.ha_src   is not None else None
        oo = (self.oiii_src * self.oiii_factor) if self.oiii_src is not None else None
        si = (self.sii_src  * self.sii_factor)  if self.sii_src  is not None else None

        # 2) map into RGB channels
        if self.palette_name in self.owner.palette_names[:9]:
            r,g,b = self.owner.map_channels(self.palette_name, ha, oo, si)
        else:
            r,g,b = self.owner.map_special_palettes(self.palette_name, ha, oo, si)

        # 3) pack into float32 array and normalize
        img = np.zeros_like(self.base_rgb, dtype=np.float32)
        if r is not None: img[...,0] = r
        if g is not None: img[...,1] = g
        if b is not None: img[...,2] = b
        mx = img.max() or 1.0
        img = np.clip(img/mx, 0.0, 1.0)

        # 4) convert to QPixmap at native size
        qimg = self.owner.numpy_to_qimage(img)
        self._base_pixmap = QPixmap.fromImage(qimg)

        # 5) now do a cheap rescale to current zoom
        self._rescale_pixmap()


    def _rescale_pixmap(self):
        """ Just rescale last base_pixmap to zoom_factor. """
        if not hasattr(self, "_base_pixmap"): 
            return
        w = int(self._base_pixmap.width()  * self.zoom_factor)
        h = int(self._base_pixmap.height() * self.zoom_factor)
        scaled = self._base_pixmap.scaled(
            w, h,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self._current_pixmap = scaled
        self.preview_label.setPixmap(scaled)
        self.preview_label.resize(scaled.size())


    def _change_zoom(self, factor: float):
        """ Called by buttons or wheel; just adjust zoom and rescale. """
        self.zoom_factor = max(0.1, min(10.0, self.zoom_factor * factor))
        self._rescale_pixmap()


    def _fit_to_preview(self):
        """ Fit the base image to the viewport width. """
        if not hasattr(self, "_base_pixmap"): return
        vp_w = self.preview_area.viewport().width()
        self.zoom_factor = vp_w / self._base_pixmap.width()
        self._rescale_pixmap()


    def _on_reset(self):
        for s in (self._ha_slider, self._oiii_slider, self._sii_slider):
            s.setValue(100)
        self._on_slider_change(None)


    def _on_accept(self):
        """
        Rebuild final float‐32 image once, emit it, and close.
        """
        # same build logic as _update_preview but emit array instead of pixmap
        ha = (self.ha_src   * self.ha_factor)   if self.ha_src   is not None else None
        oo = (self.oiii_src * self.oiii_factor) if self.oiii_src is not None else None
        si = (self.sii_src  * self.sii_factor)  if self.sii_src  is not None else None

        if self.palette_name in self.owner.palette_names[:9]:
            r,g,b = self.owner.map_channels(self.palette_name, ha, oo, si)
        else:
            r,g,b = self.owner.map_special_palettes(self.palette_name, ha, oo, si)

        final = np.zeros_like(self.base_rgb, dtype=np.float32)
        if r is not None: final[...,0] = r
        if g is not None: final[...,1] = g
        if b is not None: final[...,2] = b

        m = final.max() or 1.0
        final = np.clip(final/m, 0.0, 1.0)

        self.adjusted_image.emit(final)
        self.accept()


    def eventFilter(self, obj, evt):
        """ Pan & wheel‐zoom on the preview_label. """
        if obj is self.preview_label:
            if evt.type() == QEvent.Type.MouseButtonPress and evt.button() == Qt.MouseButton.LeftButton:
                self._dragging = True
                self._last_pos = evt.pos()
                self.preview_label.setCursor(Qt.CursorShape.ClosedHandCursor)
                return True

            if evt.type() == QEvent.Type.MouseMove and self._dragging:
                delta = evt.pos() - self._last_pos
                self._last_pos = evt.pos()
                self.preview_area.horizontalScrollBar().setValue(
                    self.preview_area.horizontalScrollBar().value() - delta.x()
                )
                self.preview_area.verticalScrollBar().setValue(
                    self.preview_area.verticalScrollBar().value() - delta.y()
                )
                return True

            if evt.type() == QEvent.Type.MouseButtonRelease and evt.button() == Qt.MouseButton.LeftButton:
                self._dragging = False
                self.preview_label.setCursor(Qt.CursorShape.OpenHandCursor)
                return True

            if evt.type() == QEvent.Type.Wheel:
                delta = evt.angleDelta().y()
                factor = 1.1 if delta > 0 else 0.9
                self.zoom_factor = max(0.1, min(10.0, self.zoom_factor * factor))
                self._rescale_pixmap()
                return True

        return super().eventFilter(obj, evt)

class PerfectPalettePickerTab(QWidget):
    """
    Perfect Palette Picker Tab for Seti Astro Suite.
    Creates 12 popular NB palettes from Ha/OIII/SII or OSC channels.
    """
    def __init__(self, image_manager=None, parent=None):
        super().__init__(parent)
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc1_image = None  # Added for OSC1
        self.osc2_image = None  # Added for OSC2
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc1_filename = None  # Added for OSC1
        self.osc2_filename = None  # Added for OSC2      
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"
        self.dragging = False
        self.last_mouse_position = None
        self.selected_palette_button = None
        self.selected_palette = None  # To track the currently selected palette
        
        # Preview scale factor
        self.preview_scale = 1  # Start at no scaling

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            # self.image_manager.image_changed.connect(self.on_image_changed)
            pass

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(300)

        # Instruction label
        instruction_label = QLabel(self)
        instruction_label.setText(
            "Instructions:\n"
            "1. Add narrowband images or an OSC camera image.\n"
            "2. Check the 'Linear Input Data' checkbox if the images are linear.\n"
            "3. Click 'Create Palettes' to generate the palettes.\n"
            "4. Use the Zoom buttons to zoom in and out.\n"
            "5. Resize the UI by dragging the lower right corner.\n"
            "6. Click on a palette from the preview selection to generate that palette.\n\n"
            "Multiple palettes can be generated."
        )
        instruction_label.setWordWrap(True)
        instruction_label.setAlignment(Qt.AlignmentFlag.AlignLeft)
        instruction_label.setStyleSheet(
            "font-size: 8pt; padding: 10px;"
        )
        #instruction_label.setFixedHeight(200)
        left_layout.addWidget(instruction_label)

        # "Linear Input Data" checkbox
        self.linear_checkbox = QCheckBox("Linear Input Data", self)
        self.linear_checkbox.setChecked(True)
        self.linear_checkbox.setToolTip(
            "When checked, we apply the 0.25 stretch for previews/final images."
        )
        left_layout.addWidget(self.linear_checkbox)

        # Load buttons for Ha, OIII, SII, OSC
        self.load_ha_button = QPushButton("Load Ha Image", self)
        self.load_ha_button.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.load_ha_button)

        self.ha_label = QLabel("No Ha image loaded.", self)
        self.ha_label.setWordWrap(True)
        left_layout.addWidget(self.ha_label)

        self.load_oiii_button = QPushButton("Load OIII Image", self)
        self.load_oiii_button.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.load_oiii_button)

        self.oiii_label = QLabel("No OIII image loaded.", self)
        self.oiii_label.setWordWrap(True)
        left_layout.addWidget(self.oiii_label)

        self.load_sii_button = QPushButton("Load SII Image", self)
        self.load_sii_button.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.load_sii_button)

        self.sii_label = QLabel("No SII image loaded.", self)
        self.sii_label.setWordWrap(True)
        left_layout.addWidget(self.sii_label)

        # **Add OSC1 Load Button and Label**
        self.load_osc1_button = QPushButton("Load OSC HaO3 Image", self)
        self.load_osc1_button.clicked.connect(lambda: self.load_image('OSC1'))
        left_layout.addWidget(self.load_osc1_button)

        self.osc1_label = QLabel("No OSC HaO3 image loaded.", self)
        self.osc1_label.setWordWrap(True)
        left_layout.addWidget(self.osc1_label)

        # **Add OSC2 Load Button and Label**
        self.load_osc2_button = QPushButton("Load OSC S2O3 Image", self)
        self.load_osc2_button.clicked.connect(lambda: self.load_image('OSC2'))
        left_layout.addWidget(self.load_osc2_button)

        self.osc2_label = QLabel("No OSC S2O3 image loaded.", self)
        self.osc2_label.setWordWrap(True)
        left_layout.addWidget(self.osc2_label)

        # "Create Palettes" button
        create_palettes_button = QPushButton("Create Palettes", self)
        create_palettes_button.clicked.connect(self.prepare_preview_palettes)
        left_layout.addWidget(create_palettes_button)

        # Spacer
        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        self.push_palette_button = QPushButton("Push Final Palette for Further Processing")
        self.push_palette_button.clicked.connect(self.push_final_palette_to_image_manager)
        left_layout.addWidget(self.push_palette_button)

        # Spacer
        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))

        # Add a "Clear All Images" button
        self.clear_all_button = QPushButton("Clear All Images", self)
        self.clear_all_button.clicked.connect(self.clear_all_images)
        left_layout.addWidget(self.clear_all_button)


        # Add the left widget to the main layout
        main_layout.addWidget(left_widget)

        # Right column for previews and controls
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls
        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In", self)
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out", self)
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        fit_to_preview_button = QPushButton("Fit to Preview", self)
        fit_to_preview_button.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(fit_to_preview_button)

        right_layout.addLayout(zoom_layout)

        # Scroll area for image preview
        self.scroll_area = QScrollArea(self)
        self.scroll_area.setWidgetResizable(True)
        self.image_label = QLabel(self)
        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.image_label.installEventFilter(self)
        self.image_label.setMouseTracking(True)

        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setMinimumHeight(100)
        right_layout.addWidget(self.scroll_area, stretch=1)


        # Preview thumbnails grid
        self.thumbs_grid = QGridLayout()
        self.palette_names = [
            "SHO", "HOO", "HSO", "HOS",
            "OSS", "OHH", "OSH", "OHS",
            "HSS", "Realistic1", "Realistic2", "Foraxx"
        ]
        self.thumbnail_buttons = []
        row = 0
        col = 0

        for palette in self.palette_names:
            button = QPushButton(palette, self)
            button.setMinimumSize(200, 100)  # Minimum size for buttons
            button.setMaximumHeight(100)  # Fixed height for buttons
            button.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Fixed)  # Expand width, fixed height
            button.setIcon(QIcon())  # Placeholder, will be set later
            button.clicked.connect(lambda checked, p=palette: self.generate_final_palette_image(p))
            button.setIconSize(QSize(200, 100))
            button.setIcon(QIcon())  # Placeholder, will be set later
            self.thumbnail_buttons.append(button)
            self.thumbs_grid.addWidget(button, row, col)
            col += 1
            if col >= 4:
                col = 0
                row += 1

        # Wrap the grid in a QWidget for better layout handling
        thumbs_widget = QWidget()
        thumbs_widget.setLayout(self.thumbs_grid)
        thumbs_widget.setSizePolicy(QSizePolicy.Policy.Preferred, QSizePolicy.Policy.Fixed)

        # Add the thumbnails widget to the layout
        right_layout.addWidget(thumbs_widget, stretch=0)


        # Status label
        self.status_label = QLabel("", self)
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        right_layout.addWidget(self.status_label)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.setWindowTitle("Perfect Palette Picker v1.0")

    def clear_all_images(self):
        """
        Clears all loaded images (Ha, OIII, SII, OSC1, OSC2).
        """
        # Clear Ha image and reset filename and label
        self.ha_image = None
        self.ha_filename = None
        self.ha_label.setText("No Ha image loaded.")

        # Clear OIII image and reset filename and label
        self.oiii_image = None
        self.oiii_filename = None
        self.oiii_label.setText("No OIII image loaded.")

        # Clear SII image and reset filename and label
        self.sii_image = None
        self.sii_filename = None
        self.sii_label.setText("No SII image loaded.")

        # Clear OSC1 image and reset filename and label
        self.osc1_image = None
        self.osc1_filename = None
        self.osc1_label.setText("No OSC HaO3 image loaded.")

        # Clear OSC2 image and reset filename and label
        self.osc2_image = None
        self.osc2_filename = None
        self.osc2_label.setText("No OSC S2O3 image loaded.")

        # Clean up preview windows
        self.cleanup_preview_windows()        

        # Update the status label
        self.status_label.setText("All images cleared.")


    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.
        
        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC1', 'OSC2').
        """
        try:
            print(f"Initiating load process for {image_type} image.")
            
            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From Slot", "From File"],
                editable=False
            )
            
            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return
            
            print(f"{image_type} image source selected: {source_choice}")
            
            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return
            
            if result is None:
                # Loading was unsuccessful or cancelled
                return
            
            image, original_header, bit_depth, is_mono, file_path = result
            
            # 🔹 **NEW: Check if grayscale is stored in 3 channels and extract the first channel**
            if image.ndim == 3 and np.all(image[:, :, 0] == image[:, :, 1]) and np.all(image[:, :, 0] == image[:, :, 2]):
                print(f"{image_type} is stored as a 3-channel grayscale image. Extracting the first channel.")
                image = image[:, :, 0]  # Convert to single-channel grayscale

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.ha_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.sii_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC1':
                self.osc1_image = image
                self.osc1_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc1_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC2':
                self.osc2_image = image
                self.osc2_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.osc2_label.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return
            
            # Apply stretching if linear input is checked
            if self.linear_checkbox.isChecked():
                if is_mono:
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha':
                        self.ha_image = stretch_func(self.ha_image, target_median=0.25)
                    elif image_type == 'OIII':
                        self.oiii_image = stretch_func(self.oiii_image, target_median=0.25)
                    elif image_type == 'SII':
                        self.sii_image = stretch_func(self.sii_image, target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Assuming OSC has multiple channels; stretching would be handled during processing
                        pass
                else:
                    # For multi-channel images, apply stretching to the first channel
                    stretch_func = stretch_mono_image
                    if image_type == 'Ha' and self.ha_image is not None and self.ha_image.ndim == 3:
                        self.ha_image[:, :, 0] = stretch_func(self.ha_image[:, :, 0], target_median=0.25)
                    elif image_type == 'OIII' and self.oiii_image is not None and self.oiii_image.ndim == 3:
                        self.oiii_image[:, :, 0] = stretch_func(self.oiii_image[:, :, 0], target_median=0.25)
                    elif image_type == 'SII' and self.sii_image is not None and self.sii_image.ndim == 3:
                        self.sii_image[:, :, 0] = stretch_func(self.sii_image[:, :, 0], target_median=0.25)
                    elif image_type in ['OSC1', 'OSC2']:
                        # Handle stretching for OSC images if necessary
                        pass
        
        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_slot(self, image_type):
        """
        Prompt the user to pick one of the ImageManager’s slots (using
        custom names if defined) and load that image.
        """
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Look up the main window’s custom slot names
        parent = self.parent_window or self.window()
        slot_names = getattr(parent, "slot_names", {})

        # Build the list of display names (zero-based)
        display_names = [
            slot_names.get(i, f"Slot {i}")
            for i in range(self.image_manager.max_slots)
        ]

        # Ask the user to choose one
        choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type}",
            "Choose a slot:",
            display_names,
            editable=False
        )
        if not ok:
            return None

        # Map back to the numeric index
        idx = display_names.index(choice)

        # Retrieve the image and metadata
        image = self.image_manager._images.get(idx)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{choice} is empty.")
            return None

        metadata = self.image_manager._metadata.get(idx, {})
        original_header = metadata.get("header", None)
        bit_depth       = metadata.get("bit_depth", "Unknown")
        is_mono         = metadata.get("is_mono", False)
        file_path       = metadata.get("file_path", None)

        # Only collapse multi-channel down to mono for NB slots,
        # but keep full RGB for OSC1/OSC2
        if image.ndim == 3 and image_type not in ("OSC1", "OSC2"):
            # if it's truly grayscale stored in 3 channels, or just NB RGB
            # we only want a single plane for NB
            print(f"[DEBUG] {image_type}: collapsing 3-channel image → channel 0 only")
            image = image[:, :, 0]
            is_mono = True

        print(f"[DEBUG] {image_type} final shape = {image.shape}, is_mono = {is_mono}")
        return image, original_header, bit_depth, is_mono, file_path

    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.
        
        Parameters:
            image_type (str): The type of image to load.
        
        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter
        )
        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None

        print(f"{image_type} image file selected: {file_path}")

        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None

        # Only collapse to single‐channel for NB slots; preserve full RGB for OSC1/OSC2
        if image.ndim == 3 and image_type not in ("OSC1", "OSC2"):
            print(f"[DEBUG] {image_type}: collapsing 3-channel image → channel 0 only")
            image = image[:, :, 0]
            is_mono = True

        print(f"[DEBUG] {image_type} final shape = {image.shape}, is_mono = {is_mono}")
        return image, original_header, bit_depth, is_mono, file_path


    def get_image_shape(self, image):
        """Returns the shape of the image or None if not set."""
        return image.shape if image is not None else None


    def prepare_preview_palettes(self):
        """
        
        Prepares the preview thumbnails for each palette based on selected images.
        """
        have_ha = self.ha_image is not None
        have_oiii = self.oiii_image is not None
        have_sii = self.sii_image is not None
        have_osc1 = self.osc1_image is not None
        have_osc2 = self.osc2_image is not None

        print(f"prepare_preview_palettes() => Ha: {have_ha} | OIII: {have_oiii} | SII: {have_sii} | OSC1: {have_osc1} | OSC2: {have_osc2}")

        # ———————————————————————————————————————————————————————
        # 0) Force all loaded images down to single-channel if they’re 3-channel arrays
        # ———————————————————————————————————————————————————————
        def squeeze_to_mono(img):
            if img is not None and img.ndim == 3:
                return img[:, :, 0]
            return img

        self.ha_image   = squeeze_to_mono(self.ha_image)
        self.oiii_image = squeeze_to_mono(self.oiii_image)
        self.sii_image  = squeeze_to_mono(self.sii_image)

        # 🔹 **NEW: Check for image size mismatches**
        image_shapes = {
            'Ha': self.get_image_shape(self.ha_image),
            'OIII': self.get_image_shape(self.oiii_image),
            'SII': self.get_image_shape(self.sii_image),
            'OSC1': self.get_image_shape(self.osc1_image),
            'OSC2': self.get_image_shape(self.osc2_image),
        }

        # Filter out None values (only check actual loaded images)
        valid_shapes = {k: v for k, v in image_shapes.items() if v is not None}

        # If different shapes are found, show an error and return
        if len(set(valid_shapes.values())) > 1:
            QMessageBox.critical(
                self,
                "Image Size Mismatch",
                f"Error: The selected images have mismatched dimensions!\n\n"
                f"{valid_shapes}"
            )
            self.status_label.setText("Error: Image sizes must match.")
            print(f"[ERROR] Image size mismatch: {valid_shapes}")
            return

        # Initialize combined channels
        combined_ha = self.ha_image.copy() if self.ha_image is not None else None
        combined_oiii = self.oiii_image.copy() if self.oiii_image is not None else None
        combined_sii = self.sii_image.copy() if self.sii_image is not None else None  # Initialize combined SII

        # Process OSC1 if available
        if have_osc1:
            # Extract synthetic Ha and OIII from OSC1
            ha_osc1 = self.osc1_image[:, :, 0]  # Red channel -> Ha
            oiii_osc1 = np.mean(self.osc1_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                ha_osc1 = stretch_mono_image(ha_osc1, target_median=0.25)
                oiii_osc1 = stretch_mono_image(oiii_osc1, target_median=0.25)

            # Combine with existing Ha and OIII
            if combined_ha is not None:
                combined_ha = (combined_ha * 0.5) + (ha_osc1 * 0.5)
            else:
                combined_ha = ha_osc1

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc1 * 0.5)
            else:
                combined_oiii = oiii_osc1

        # Process OSC2 if available
        if have_osc2:
            # Extract synthetic SII from OSC2 red channel
            sii_osc2 = self.osc2_image[:, :, 0]  # Red channel -> SII
            oiii_osc2 = np.mean(self.osc2_image[:, :, 1:3], axis=2)  # Average of green and blue channels -> OIII

            # Apply stretching if enabled
            if self.linear_checkbox.isChecked():
                sii_osc2 = stretch_mono_image(sii_osc2, target_median=0.25)
                oiii_osc2 = stretch_mono_image(oiii_osc2, target_median=0.25)

            # Combine with existing SII
            if combined_sii is not None:
                combined_sii = (combined_sii * 0.5) + (sii_osc2 * 0.5)
            else:
                combined_sii = sii_osc2

            if combined_oiii is not None:
                combined_oiii = (combined_oiii * 0.5) + (oiii_osc2 * 0.5)
            else:
                combined_oiii = oiii_osc2    

        # Assign combined images back to self.ha_image, self.oiii_image, and self.sii_image
        self.ha_image = combined_ha
        self.oiii_image = combined_oiii
        self.sii_image = combined_sii  # Updated SII image

        # Ensure images are single-channel
        def ensure_single_channel(image, image_type):
            if image is not None:
                if image.ndim == 3:
                    if image.shape[2] == 1:
                        image = image[:, :, 0]
                        print(f"Converted {image_type} image to single channel: {image.shape}")
                    else:
                        # If image has multiple channels, retain the first channel
                        image = image[:, :, 0]
                        print(f"Extracted first channel from multi-channel {image_type} image: {image.shape}")
                return image
            return None

        self.ha_image = ensure_single_channel(self.ha_image, 'Ha')
        self.oiii_image = ensure_single_channel(self.oiii_image, 'OIII')
        self.sii_image = ensure_single_channel(self.sii_image, 'SII')

        print(f"Combined Ha image shape: {self.ha_image.shape if self.ha_image is not None else 'None'}")
        print(f"Combined OIII image shape: {self.oiii_image.shape if self.oiii_image is not None else 'None'}")
        print(f"Combined SII image shape: {self.sii_image.shape if self.sii_image is not None else 'None'}")

        # Validate required channels
        # Allow if (Ha and OIII) or (SII and OIII) are present
        if not ((self.ha_image is not None and self.oiii_image is not None) or
                (self.sii_image is not None and self.oiii_image is not None)):
            QMessageBox.warning(
                self,
                "Warning",
                "Please load at least Ha and OIII images or SII and OIII images to create palettes."
            )
            self.status_label.setText("Insufficient images loaded.")
            return

        # Start processing thread to generate previews
        ha_to_oii_ratio = 0.3  # Example ratio; adjust as needed
        enable_star_stretch = self.linear_checkbox.isChecked()
        stretch_factor = 0.25  # Example stretch factor; adjust as needed

        self.processing_thread = PalettePickerProcessingThread(
            ha_image=self.ha_image,
            oiii_image=self.oiii_image,
            sii_image=self.sii_image,
            osc1_image=None,  # OSC1 is already processed
            osc2_image=None,  # OSC2 is already processed
            ha_to_oii_ratio=ha_to_oii_ratio,
            enable_star_stretch=enable_star_stretch,
            stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.update_preview_thumbnails)
        self.processing_thread.start()

        self.status_label.setText("Generating preview palettes...")



    def update_preview_thumbnails(self, combined_preview):
        """
        Updates the preview thumbnails with the generated combined preview.
        Downsamples the images for efficient processing of mini-previews.
        """
        if combined_preview is None:
            # Only update the text overlays
            for i, palette in enumerate(self.palette_names):
                pixmap = self.thumbnail_buttons[i].icon().pixmap(self.thumbnail_buttons[i].iconSize())
                if pixmap.isNull():
                    print(f"Failed to retrieve pixmap for palette '{palette}'. Skipping.")
                    continue
                text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white
                painter = QPainter(pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()
                self.thumbnail_buttons[i].setIcon(QIcon(pixmap))
                QApplication.processEvents()

            return

        def downsample_image(image, factor=8):
            """
            Downsample the image by an integer factor using cv2.resize.
            """
            if image is not None:
                height, width = image.shape[:2]
                new_size = (max(1, width // factor), max(1, height // factor))  # Ensure size is at least 1x1
                return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
            return image

        # Downsample images
        ha = downsample_image(self.ha_image)
        oiii = downsample_image(self.oiii_image)
        sii = downsample_image(self.sii_image)

        # Helper function to extract single channel
        def extract_channel(image):
            return image if image is not None and image.ndim == 2 else (image[:, :, 0] if image is not None else None)

        # Helper function for channel substitution
        def get_channel(preferred, substitute):
            return preferred if preferred is not None else substitute

        for i, palette in enumerate(self.palette_names):
            text_color = Qt.GlobalColor.green if self.selected_palette == palette else Qt.GlobalColor.white

            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None

            # Define substitution channels
            substituted_ha = sii if not ha_available and sii_available else ha
            substituted_sii = ha if not sii_available and ha_available else sii

            # Map channels based on palette
            if palette == "SHO":
                r = get_channel(extract_channel(sii), substituted_ha)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = extract_channel(oiii)
            elif palette == "HOO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = extract_channel(oiii)
            elif palette == "HSO":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = extract_channel(oiii)
            elif palette == "HOS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = extract_channel(oiii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OSS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "OHH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OSH":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(ha), substituted_sii)
            elif palette == "OHS":
                r = extract_channel(oiii)
                g = get_channel(extract_channel(ha), substituted_sii)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette == "HSS":
                r = get_channel(extract_channel(ha), substituted_sii)
                g = get_channel(extract_channel(sii), substituted_ha)
                b = get_channel(extract_channel(sii), substituted_ha)
            elif palette in ["Realistic1", "Realistic2", "Foraxx"]:
                r, g, b = self.map_special_palettes(palette, ha, oiii, sii)
            else:
                # Fallback to SHO
                r, g, b = self.map_channels("SHO", ha, oiii, sii)

            # Replace NaNs and clip to [0, 1]
            r = np.clip(np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if r is not None else None
            g = np.clip(np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if g is not None else None
            b = np.clip(np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1) if b is not None else None

            if r is None or g is None or b is None:
                print(f"One of the channels is None for palette '{palette}'. Skipping this palette.")
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)
                continue

            combined = self.combine_channels_to_color([r, g, b], f"Preview_{palette}")
            if combined is not None:
                # Convert NumPy array to QImage
                q_image = self.numpy_to_qimage(combined)
                if q_image.isNull():
                    print(f"Failed to convert preview for palette '{palette}' to QImage.")
                    continue

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    print(f"Failed to create QPixmap for palette '{palette}'.")
                    continue

                # Scale pixmap
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.preview_scale),
                    int(pixmap.height() * self.preview_scale),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Add text overlay
                painter = QPainter(scaled_pixmap)
                painter.setRenderHint(QPainter.RenderHint.Antialiasing)
                painter.setPen(QPen(text_color))
                painter.setFont(QFont("Helvetica", 8))
                painter.drawText(scaled_pixmap.rect(), Qt.AlignmentFlag.AlignCenter, palette)
                painter.end()

                # Set pixmap to the corresponding button
                self.thumbnail_buttons[i].setIcon(QIcon(scaled_pixmap))
                self.thumbnail_buttons[i].setIconSize(scaled_pixmap.size())
                self.thumbnail_buttons[i].setToolTip(f"Palette: {palette}")
                QApplication.processEvents()
            else:
                self.thumbnail_buttons[i].setIcon(QIcon())
                self.thumbnail_buttons[i].setText(palette)

        self.status_label.setText("Preview palettes generated successfully.")

    def generate_final_palette_image(self, palette_name):
        """
        Generates the final combined image for the selected palette.
        Handles substitution of SII for Ha or Ha for SII if one is missing.
        """
        try:
            print(f"Generating final palette image for: {palette_name}")
            
            # Determine availability
            ha_available = self.ha_image is not None
            sii_available = self.sii_image is not None
            
            # Define substitution
            if not ha_available and sii_available:
                # Substitute SII for Ha
                substituted_ha = self.sii_image
                substituted_sii = self.sii_image
                print("Substituting SII for Ha.")
            elif not sii_available and ha_available:
                # Substitute Ha for SII
                substituted_sii = self.ha_image
                substituted_ha = self.ha_image
                print("Substituting Ha for SII.")
            else:
                substituted_ha = self.ha_image
                substituted_sii = self.sii_image
            
            # Temporarily assign substituted channels
            original_ha = self.ha_image
            original_sii = self.sii_image
            
            self.ha_image = substituted_ha
            self.sii_image = substituted_sii
            
            # Combine channels
            combined_image = self.combine_channels(palette_name)
            
            # Restore original channels
            self.ha_image = original_ha
            self.sii_image = original_sii
            
            if combined_image is not None:
                # Ensure the combined image has the correct shape
                if combined_image.ndim == 4 and combined_image.shape[3] == 3:
                    combined_image = combined_image[:, :, :, 0]  # Remove the extra dimension

                # Convert to QImage
                q_image = self.numpy_to_qimage(combined_image)
                if q_image.isNull():
                    raise ValueError(f"Failed to convert combined image for palette '{palette_name}' to QImage.")

                pixmap = QPixmap.fromImage(q_image)
                if pixmap.isNull():
                    raise ValueError(f"Failed to create QPixmap for palette '{palette_name}'.")

                # Scale the pixmap based on zoom factor
                scaled_pixmap = pixmap.scaled(
                    int(pixmap.width() * self.zoom_factor),
                    int(pixmap.height() * self.zoom_factor),
                    Qt.AspectRatioMode.KeepAspectRatio,
                    Qt.TransformationMode.SmoothTransformation
                )

                # Display the scaled pixmap in the main preview area
                self.image_label.setPixmap(scaled_pixmap)
                self.image_label.resize(scaled_pixmap.size())
                self.combined_image = combined_image
                self.status_label.setText(f"Final palette '{palette_name}' generated successfully.")

                self.selected_palette = palette_name
                self.update_preview_thumbnails(None)  # Trigger re-render with updated text colors

            else:
                raise ValueError(f"Failed to generate combined image for palette '{palette_name}'.")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to generate final image: {e}")
            self.status_label.setText(f"Failed to generate palette '{palette_name}'.")
            print(f"[Error] {e}")

    def highlight_selected_button(self, palette_name):
        """
        Highlights the clicked button by changing its text color and resets others.
        """
        for button in self.thumbnail_buttons:
            if button.text() == palette_name:
                # Change text color to indicate selection
                button.setStyleSheet("color: green; font-weight: bold;")
                self.selected_palette_button = button
            else:
                # Reset text color for non-selected buttons
                button.setStyleSheet("")


    def combine_channels(self, palette_name):
        """
        Combines Ha, OIII, SII channels based on the palette name.
        Ensures that all combined channel values are within the [0, 1] range.
        """
        if palette_name in self.palette_names[:9]:  # Standard palettes
            r, g, b = self.map_channels(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        elif palette_name in self.palette_names[9:]:  # Special palettes
            r, g, b = self.map_special_palettes(palette_name, self.ha_image, self.oiii_image, self.sii_image)
        else:
            # Fallback to SHO
            r, g, b = self.map_channels("SHO", self.ha_image, self.oiii_image, self.sii_image)

        if r is not None and g is not None and b is not None:
            # Replace NaN and Inf with 0
            r = np.nan_to_num(r, nan=0.0, posinf=1.0, neginf=0.0)
            g = np.nan_to_num(g, nan=0.0, posinf=1.0, neginf=0.0)
            b = np.nan_to_num(b, nan=0.0, posinf=1.0, neginf=0.0)

            # Normalize to [0,1]
            r = np.clip(r, 0, 1)
            g = np.clip(g, 0, 1)
            b = np.clip(b, 0, 1)

            # Ensure single-channel
            if r.ndim == 3:
                r = r[:, :, 0]
            if g.ndim == 3:
                g = g[:, :, 0]
            if b.ndim == 3:
                b = b[:, :, 0]

            combined = np.stack([r, g, b], axis=2)
            return combined
        else:
            return None


    def combine_channels_to_color(self, channels, output_id):
        """
        Combines three grayscale images into an RGB image.
        Ensures that all channels are consistent and have no extra dimensions.
        """
        try:
            # Validate input channels
            if len(channels) != 3:
                raise ValueError(f"Expected 3 channels, got {len(channels)}")
            
            # Ensure all channels have the same shape
            for i, channel in enumerate(channels):
                if channel is None:
                    raise ValueError(f"Channel {i} is None.")
                if channel.shape != channels[0].shape:
                    raise ValueError(f"Channel {i} has shape {channel.shape}, expected {channels[0].shape}")
            
            # Ensure all channels are 2D
            channels = [channel[:, :, 0] if channel.ndim == 3 else channel for channel in channels]
            
            # Debugging: Print channel shapes after extraction
            for idx, channel in enumerate(channels):
                print(f"Channel {idx} shape after extraction: {channel.shape}")
            
            # Stack channels along the third axis to create RGB
            rgb_image = np.stack(channels, axis=2)
            print(f"Combined RGB image shape: {rgb_image.shape}")
            return rgb_image
        except Exception as e:
            print(f"Error in combine_channels_to_color: {e}")
            return None

    def map_channels(self, palette_name, ha, oiii, sii):
        """
        Maps the Ha, OIII, SII channels based on the palette name.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        # Substitute SII for Ha if Ha is missing
        if ha is None and sii is not None:
            ha = sii
            print("Ha is missing. Substituting SII for Ha.")
        
        # Substitute Ha for SII if SII is missing
        if sii is None and ha is not None:
            sii = ha
            print("SII is missing. Substituting Ha for SII.")
        
        # Define the channel mappings
        mapping = {
            "SHO": [sii, ha, oiii],
            "HOO": [ha, oiii, oiii],
            "HSO": [ha, sii, oiii],
            "HOS": [ha, oiii, sii],
            "OSS": [oiii, sii, sii],
            "OHH": [oiii, ha, ha],
            "OSH": [oiii, sii, ha],
            "OHS": [oiii, ha, sii],
            "HSS": [ha, sii, sii],
        }
        
        # Retrieve the mapped channels based on the palette name
        mapped_channels = mapping.get(palette_name, [ha, oiii, sii])
             
        return mapped_channels


    def map_special_palettes(self, palette_name, ha, oiii, sii):
        """
        Maps channels for special palettes like Realistic1, Realistic2, Foraxx.
        Ensures all expressions produce values within the [0, 1] range.
        Substitutes SII for Ha or Ha for SII if one is missing.
        """
        try:
            # Substitute SII for Ha if Ha is missing
            if ha is None and sii is not None:
                ha = sii
                print("Ha is missing in special palette. Substituting SII for Ha.")
        
            # Substitute Ha for SII if SII is missing
            if sii is None and ha is not None:
                sii = ha
                print("SII is missing in special palette. Substituting Ha for SII.")
        
            # Realistic1 mapping
            if palette_name == "Realistic1":
                expr_r = (ha + sii) / 2 if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * ha) + (0.7 * oiii) if (ha is not None and oiii is not None) else (ha if ha is not None else 0)
                expr_b = (0.9 * oiii) + (0.1 * ha) if (ha is not None and oiii is not None) else (oiii if oiii is not None else 0)
        
            # Realistic2 mapping
            elif palette_name == "Realistic2":
                expr_r = (0.7 * ha + 0.3 * sii) if (ha is not None and sii is not None) else (ha if ha is not None else 0)
                expr_g = (0.3 * sii + 0.7 * oiii) if (sii is not None and oiii is not None) else (oiii if oiii is not None else 0)
                expr_b = oiii if oiii is not None else 0
        
            # Foraxx mapping
            elif palette_name == "Foraxx":
                if ha is not None and oiii is not None and sii is None:
                    expr_r = ha
                    temp = ha * oiii
                    expr_g = (temp ** (1 - temp)) * ha + (1 - (temp ** (1 - temp))) * oiii
                    expr_b = oiii
                elif ha is not None and oiii is not None and sii is not None:
                    temp = oiii ** (1 - oiii)
                    expr_r = (temp * sii) + ((1 - temp) * ha)
                    temp_ha_oiii = ha * oiii
                    expr_g = (temp_ha_oiii ** (1 - temp_ha_oiii)) * ha + (1 - (temp_ha_oiii ** (1 - temp_ha_oiii))) * oiii
                    expr_b = oiii
                else:
                    # Fallback to SHO
                    return self.map_channels("SHO", ha, oiii, sii)
        
            else:
                # Fallback to SHO for any undefined palette
                return self.map_channels("SHO", ha, oiii, sii)
        
            # Replace invalid values and normalize
            expr_r = np.clip(np.nan_to_num(expr_r, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_g = np.clip(np.nan_to_num(expr_g, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
            expr_b = np.clip(np.nan_to_num(expr_b, nan=0.0, posinf=1.0, neginf=0.0), 0, 1)
        
            return expr_r, expr_g, expr_b
        except Exception as e:
            print(f"[Error] Failed to map palette {palette_name}: {e}")
            return None, None, None


    def extract_oscc_channels(self, osc_image, base_id):
        """
        Extracts R, G, B channels from the OSC image and assigns unique postfixes.
        
        Parameters:
            osc_image (numpy.ndarray): The OSC image array.
            base_id (str): The base identifier for naming.
        
        Returns:
            list: A list containing the extracted R, G, B channels as NumPy arrays.
        """
        if osc_image is None or osc_image.shape[2] < 3:
            print(f"[!] OSC image {base_id} has fewer than 3 channels—skipping extraction.")
            return []

        # Extract channels
        R = osc_image[:, :, 0]  # Red channel
        G = osc_image[:, :, 1]  # Green channel
        B = osc_image[:, :, 2]  # Blue channel

        # Assign unique postfixes
        R_name = f"{base_id}_pppR"
        G_name = f"{base_id}_pppG"
        B_name = f"{base_id}_pppB"

        # For Seti Astro Suite, we might need to create separate image objects or handle naming differently
        # Here, we'll assume that we can manage the names via dictionaries or similar structures

        # Store the extracted channels with their names
        extracted_channels = {
            R_name: R,
            G_name: G,
            B_name: B
        }

        # Optionally, hide these images in the GUI or manage them as needed
        # For example, you might add them to an internal list for cleanup

        # For demonstration, we'll return the list of channels
        return [R, G, B]




    def numpy_to_qimage(self, image_array):
        """
        Converts a NumPy array to QImage.
        Assumes image_array is in the range [0, 1] and in RGB format.
        """
        try:
            # Validate input shape
            if image_array.ndim == 2:
                # Grayscale image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width = image_uint8.shape
                bytes_per_line = width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_Grayscale8)
                return q_image.copy()
            elif image_array.ndim == 3 and image_array.shape[2] == 3:
                # RGB image
                
                image_uint8 = (np.clip(image_array, 0, 1) * 255).astype(np.uint8)
                height, width, channels = image_uint8.shape
                if channels != 3:
                    raise ValueError(f"Expected 3 channels for RGB, got {channels}")
                bytes_per_line = 3 * width
                q_image = QImage(image_uint8.data, width, height, bytes_per_line, QImage.Format.Format_RGB888)
                return q_image.copy()
            else:
                # Invalid shape
                raise ValueError(f"Invalid image shape for QImage conversion: {image_array.shape}")
        except Exception as e:
            print(f"Error converting NumPy array to QImage: {e}")
            return QImage()



    def save_image(self):
        """
        Save the current combined image to a selected path.
        """
        if self.combined_image is not None:
            save_file, _ = QFileDialog.getSaveFileName(
                self,
                "Save As",
                "",
                "Images (*.png *.tif *.tiff *.fits *.fit);;All Files (*)"
            )

            if save_file:
                # Prompt the user for bit depth
                bit_depth, ok = QInputDialog.getItem(
                    self,
                    "Select Bit Depth",
                    "Choose bit depth for saving:",
                    ["16-bit", "32-bit floating point"],
                    0,
                    False
                )
                if ok:
                    # Determine the user-selected format from the filename
                    _, ext = os.path.splitext(save_file)
                    selected_format = ext.lower().strip('.')

                    # Validate the selected format
                    valid_formats = ['png', 'tif', 'tiff', 'fits', 'fit']
                    if selected_format not in valid_formats:
                        QMessageBox.critical(
                            self,
                            "Error",
                            f"Unsupported file format: {selected_format}. Supported formats are: {', '.join(valid_formats)}"
                        )
                        return

                    # Ensure correct data ordering for FITS format
                    final_image = self.combined_image
                    if selected_format in ['fits', 'fit']:
                        if self.combined_image.ndim == 3:  # RGB image
                            # Transpose to (channels, height, width)
                            final_image = np.transpose(self.combined_image, (2, 0, 1))
                            print(f"Transposed for FITS: {final_image.shape}")
                        elif self.combined_image.ndim == 2:  # Mono image
                            print(f"Mono image, no transposition needed: {final_image.shape}")
                        else:
                            QMessageBox.critical(
                                self,
                                "Error",
                                "Unsupported image dimensions for FITS saving."
                            )
                            return

                    # Check if any loaded image file paths have the `.xisf` extension
                    loaded_file_paths = [
                        self.ha_filename, self.oiii_filename,
                        self.sii_filename, self.osc1_filename, self.osc2_filename
                    ]
                    contains_xisf = any(
                        file_path.lower().endswith('.xisf') for file_path in loaded_file_paths if file_path
                    )

                    # Create a minimal header if any loaded image is XISF
                    sanitized_header = self.original_header if not contains_xisf else self.create_minimal_fits_header(final_image)

                    # Pass the correctly ordered image to the global save_image function
                    try:
                        save_image(
                            img_array=final_image,
                            filename=save_file,
                            original_format=selected_format,
                            bit_depth=bit_depth,
                            original_header=sanitized_header,  # Pass minimal or original header
                            is_mono=self.is_mono
                        )
                        print(f"Image successfully saved to {save_file}.")
                        self.status_label.setText(f"Image saved to: {save_file}")
                    except Exception as e:
                        QMessageBox.critical(self, "Error", f"Failed to save image: {e}")
                        print(f"Error saving image: {e}")
            else:
                self.status_label.setText("Save canceled.")
        else:
            QMessageBox.warning(self, "Warning", "No combined image to save.")
            self.status_label.setText("No combined image to save.")


    def create_minimal_fits_header(self, img_array):
        """
        Creates a minimal FITS header when the original header is missing.
        """

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if self.is_mono else 3
        header['NAXIS1'] = self.combined_image.shape[1]  # Image width
        header['NAXIS2'] = self.combined_image.shape[0]  # Image height
        if not self.is_mono:
            header['NAXIS3'] = self.combined_image.shape[2]  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header['COMMENT'] = "Minimal FITS header generated by Perfect Palette Picker."

        return header

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        """
        Zooms into the main preview image.
        """
        if self.zoom_factor < 5.0:  # Maximum zoom factor
            self.zoom_factor *= 1.25
            self.update_main_preview()
        else:
            print("Maximum zoom level reached.")
            self.status_label.setText("Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        """
        Zooms out of the main preview image.
        """
        if self.zoom_factor > 0.2:  # Minimum zoom factor
            self.zoom_factor /= 1.25
            self.update_main_preview()
        else:
            print("Minimum zoom level reached.")
            self.status_label.setText("Minimum zoom level reached.")

    def fit_to_preview(self):
        """
        Fits the main preview image to the scroll area.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            if q_image.isNull():
                QMessageBox.critical(self, "Error", "Cannot fit image to preview due to conversion error.")
                return
            pixmap = QPixmap.fromImage(q_image)
            scroll_area_width = self.scroll_area.viewport().width()
            self.zoom_factor = scroll_area_width / pixmap.width()
            self.update_main_preview()
            self.status_label.setText("Image fitted to preview area.")
        else:
            QMessageBox.warning(self, "Warning", "No image loaded to fit.")

    def update_main_preview(self):
        """
        Updates the main preview image based on the current zoom factor.
        """
        if self.combined_image is not None:
            q_image = self.numpy_to_qimage(self.combined_image)
            pixmap = QPixmap.fromImage(q_image)
            if pixmap.isNull():
                QMessageBox.critical(self, "Error", "Failed to update main preview. Invalid QPixmap.")
                return

            # Ensure dimensions are integers
            scaled_width = int(pixmap.width() * self.zoom_factor)
            scaled_height = int(pixmap.height() * self.zoom_factor)

            scaled_pixmap = pixmap.scaled(
                scaled_width,
                scaled_height,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.image_label.setPixmap(scaled_pixmap)
            self.image_label.resize(scaled_pixmap.size())
        else:
            self.image_label.clear()





    def create_palette_preview(self, palette_name):
        """
        Creates a mini-preview image for the given palette.
        Returns the combined RGB image as a NumPy array.
        """
        print(f"Creating mini-preview for palette: {palette_name}")
        combined = self.combine_channels(palette_name)
        return combined

    def push_final_palette_to_image_manager(self):
        if self.combined_image is None:
            QMessageBox.warning(self, "Warning", "No final palette image to push.")
            return

        dlg = PaletteAdjustDialog(
            base_rgb      = self.combined_image,
            palette_name  = self.selected_palette,
            ha_src        = self.ha_image,
            oiii_src      = self.oiii_image,
            sii_src       = self.sii_image,
            owner_tab     = self
        )
        dlg.adjusted_image.connect(self._on_palette_adjusted)
        dlg.exec()

    def _on_palette_adjusted(self, adjusted_rgb: np.ndarray):
        # show it live
        self.combined_image = adjusted_rgb
        self.update_main_preview()
        # and finally hand it off exactly as before:
        self._do_push(self.combined_image)

    def _do_push(self, final_rgb: np.ndarray):
        """
        This contains all of your previous “temp‐file, metadata, image_manager.update_image” logic.
        It writes out a temp TIFF if needed, builds the metadata dict, and calls the ImageManager.
        """
        # 1) decide header drop
        loaded = [self.ha_filename, self.oiii_filename, self.sii_filename,
                  self.osc1_filename, self.osc2_filename]
        was_xisf = any(fp and fp.lower().endswith(".xisf") for fp in loaded)
        header = None if was_xisf or self.original_header is None else self.original_header

        # 2) pick a source file path or write temp TIFF
        file_path = None
        for src in ("ha", "osc1", "osc2"):
            fn = getattr(self, f"{src}_filename")
            img = getattr(self, f"{src}_image")
            if img is not None and fn:
                file_path = fn
                break

        if file_path is None:
            temp_dir = tempfile.gettempdir()
            ts = int(time.time())
            file_path = os.path.join(temp_dir, f"palette_{ts}.tif")
            save_image(
                img_array=final_rgb,
                filename=file_path,
                original_format="tif",
                bit_depth=self.bit_depth,
                original_header=header,
                is_mono=self.is_mono
            )

        # 3) build metadata
        metadata = {
            "file_path": file_path,
            "original_header": header,
            "bit_depth": getattr(self, "bit_depth", "Unknown"),
            "is_mono": False,
            "processing_parameters": {
                "zoom_factor": self.zoom_factor,
                "preview_scale": self.preview_scale,
            },
            "processing_timestamp": datetime.now().isoformat(),
            "source_images": {
                "Ha":   self.ha_filename   or "Not Provided",
                "OIII": self.oiii_filename or "Not Provided",
                "SII":  self.sii_filename  or "Not Provided",
                "OSC1": self.osc1_filename or "Not Provided",
                "OSC2": self.osc2_filename or "Not Provided",
            },
        }

        # 4) hand off to the ImageManager
        if self.image_manager:
            try:
                self.image_manager.set_image_with_step_name(
                    new_image=final_rgb,
                    metadata=metadata,
                    step_name=self.selected_palette
                )
                self.status_label.setText("Final palette image pushed for further processing.")
            except Exception as e:
                QMessageBox.critical(self, "Error",
                                     f"Failed to update ImageManager:\n{e}")
        else:
            QMessageBox.warning(self, "Warning",
                                "ImageManager is not initialized.")



    def mousePressEvent(self, event):
        """
        Starts dragging when the left mouse button is pressed.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_mouse_position = event.pos()
            self.image_label.setCursor(Qt.CursorShape.ClosedHandCursor)

    def mouseMoveEvent(self, event):
        """
        Handles dragging by adjusting the scroll area's position.
        """
        if self.dragging and self.last_mouse_position is not None:
            # Calculate the difference in mouse movement
            delta = event.pos() - self.last_mouse_position
            self.last_mouse_position = event.pos()

            # Adjust the scroll area's scroll position
            self.scroll_area.horizontalScrollBar().setValue(
                self.scroll_area.horizontalScrollBar().value() - delta.x()
            )
            self.scroll_area.verticalScrollBar().setValue(
                self.scroll_area.verticalScrollBar().value() - delta.y()
            )

    def mouseReleaseEvent(self, event):
        """
        Stops dragging when the left mouse button is released.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
            self.last_mouse_position = None
            self.image_label.setCursor(Qt.CursorShape.OpenHandCursor)


    def cleanup_preview_windows(self):
        """
        Cleans up temporary preview images by resetting image variables and clearing GUI elements.
        """
        print("Cleaning up preview windows...")
        
        # 1. Reset Temporary Image Variables
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        print("Temporary preview images (Ha, OIII, SII) have been cleared.")
        
        # 2. Clear GUI Elements Displaying Previews
        # Update the list below with the actual names of your preview labels or buttons
        preview_labels = ['ha_preview_label', 'oiii_preview_label', 'sii_preview_label']
        for label_name in preview_labels:
            if hasattr(self, label_name):
                label = getattr(self, label_name)
                label.clear()  # Removes the pixmap or any displayed content
                print(f"{label_name} has been cleared.")
        
        # 3. Clear Final Image Display (if applicable)
        # Update 'final_image_label' with your actual final image display widget name
        if hasattr(self, 'image_label'):
            self.image_label.clear()
            print("Final image label has been cleared.")
        
        # 4. Reset Thumbnail Buttons (if used for previews)
        # Ensure 'self.thumbnail_buttons' is a list of your thumbnail QPushButtons
        for button in self.thumbnail_buttons:
            button.setIcon(QIcon())    # Remove existing icon



        print("Thumbnail buttons have been reset.")
        
        # 5. Update Status Label
        self.status_label.setText("Preview windows cleaned up.")
        print("Status label updated to indicate cleanup.")
        
        # 6. Process UI Events to Reflect Changes Immediately
        QApplication.processEvents()


    def closeEvent(self, event):
        """
        Handle the close event to perform cleanup.
        """
        self.cleanup_preview_windows()
        event.accept()

class NBtoRGBstarsTab(QWidget):
    def __init__(self, image_manager=None, parent=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager
        self.parent_window = parent
        self.initUI()
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc_image = None
        self.combined_image = None
        self.is_mono = False
        # Filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc_filename = None        
        self.filename = None  # Store the selected file path
        self.zoom_factor = 1.0  # Initialize to 1.0 for normal size
        self.dragging = False
        self.last_pos = QPoint()
        self.processing_thread = None
        self.original_header = None
        self.original_pixmap = None  # To store the original QPixmap for zooming
        self.bit_depth = "Unknown"

        if self.image_manager:
            # Connect to ImageManager's image_changed signal if needed
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)

        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select Ha, OIII, and SII (optional) narrowband images, or an OSC stars-only image.
            2. Adjust the Ha to OIII Ratio if needed.
            3. Preview the combined result.
            4. Save the final composite image.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # Ha, OIII, SII image selections
        self.haButton = QPushButton('Select Ha Image', self)
        self.haButton.clicked.connect(lambda: self.load_image('Ha'))
        left_layout.addWidget(self.haButton)
        self.haLabel = QLabel('No Ha image selected', self)
        left_layout.addWidget(self.haLabel)

        self.oiiiButton = QPushButton('Select OIII Image', self)
        self.oiiiButton.clicked.connect(lambda: self.load_image('OIII'))
        left_layout.addWidget(self.oiiiButton)
        self.oiiiLabel = QLabel('No OIII image selected', self)
        left_layout.addWidget(self.oiiiLabel)

        self.siiButton = QPushButton('Select SII Image (Optional)', self)
        self.siiButton.clicked.connect(lambda: self.load_image('SII'))
        left_layout.addWidget(self.siiButton)
        self.siiLabel = QLabel('No SII image selected', self)
        left_layout.addWidget(self.siiLabel)

        self.oscButton = QPushButton('Select OSC Stars Image (Optional)', self)
        self.oscButton.clicked.connect(lambda: self.load_image('OSC'))
        left_layout.addWidget(self.oscButton)
        self.oscLabel = QLabel('No OSC stars image selected', self)
        left_layout.addWidget(self.oscLabel)

        # Ha to OIII Ratio slider
        self.haToOiiRatioLabel, self.haToOiiRatioSlider = self.createRatioSlider("Ha to OIII Ratio", 30)
        left_layout.addWidget(self.haToOiiRatioLabel)
        left_layout.addWidget(self.haToOiiRatioSlider)

        # Star Stretch checkbox and sliders
        self.starStretchCheckBox = QCheckBox("Enable Star Stretch", self)
        self.starStretchCheckBox.setChecked(True)
        self.starStretchCheckBox.toggled.connect(self.toggleStarStretchControls)
        left_layout.addWidget(self.starStretchCheckBox)

        self.stretchSliderLabel, self.stretchSlider = self.createStretchSlider("Stretch Factor", 5.0)
        left_layout.addWidget(self.stretchSliderLabel)
        left_layout.addWidget(self.stretchSlider)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # Preview and Save buttons
        self.previewButton = QPushButton('Preview Combined Image', self)
        self.previewButton.clicked.connect(self.previewCombine)
        left_layout.addWidget(self.previewButton)

        # File label for displaying save status
        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        self.pushButton = QPushButton('Push to Active Slot', self)
        self.pushButton.clicked.connect(self.pushToActiveSlot)
        left_layout.addWidget(self.pushButton)

        # **Remove Zoom Buttons from Left Panel (Not present)**
        # No existing zoom buttons to remove in the left panel

        self.clearButton = QPushButton("Clear All Inputs", self)
        self.clearButton.clicked.connect(self.clearInputs)
        left_layout.addWidget(self.clearButton)

        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoom_in)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoom_out)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)

        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def clearInputs(self):
        # 1) Drop all loaded data
        self.ha_image = None
        self.oiii_image = None
        self.sii_image = None
        self.osc_image = None
        self.combined_image = None

        # 2) Clear filenames
        self.ha_filename = None
        self.oiii_filename = None
        self.sii_filename = None
        self.osc_filename = None

        # 3) Reset headers/metadata
        self.original_header = None
        self.bit_depth = "Unknown"
        self.is_mono = False

        # 4) Reset labels
        self.haLabel.setText("No Ha image selected")
        self.oiiiLabel.setText("No OIII image selected")
        self.siiLabel.setText("No SII image selected")
        self.oscLabel.setText("No OSC stars image selected")
        self.fileLabel.clear()

        # 5) Clear preview
        self.imageLabel.clear()
        self.original_pixmap = None

        # 6) Reset controls to defaults
        self.haToOiiRatioSlider.setValue(30)
        self.starStretchCheckBox.setChecked(True)
        self.stretchSlider.setValue(500)      # assuming default 5.0 → 500
        self.zoom_factor = 1.0

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return       
        if image is None:
            return         
        if slot == self.image_manager.current_slot:

            print(f"NBtoRGBstarsTab: Image updated from ImageManager slot {slot}.")

    def pushToActiveSlot(self):
        """
        Pushes the current combined image to the active slot in the ImageManager,
        along with the associated metadata.
        """
        if self.combined_image is None:
            QMessageBox.warning(self, "Warning", "No combined image available to push.")
            return

        # Check if any of the loaded file paths have an XISF extension
        loaded_files = [self.ha_filename, self.oiii_filename, self.sii_filename, self.osc_filename]
        was_xisf = any(file_path and file_path.lower().endswith('.xisf') for file_path in loaded_files)

        # Generate a minimal FITS header if the original header is missing or if the format was XISF
        sanitized_header = self.original_header
        if was_xisf or sanitized_header is None:
            sanitized_header = None  # Use None to avoid saving an empty header

        # Determine the valid file path:
        # Prioritize Ha, then OSC (if available)
        file_path = None
        if self.ha_image is not None and self.ha_filename:
            file_path = self.ha_filename
            print("Using Ha filename as file_path.")
        elif self.osc_image is not None and self.osc_filename:
            file_path = self.osc_filename
            print("Using OSC filename as file_path.")
        else:
            # No valid source file, save combined_image to a temporary file
            try:
                temp_dir = tempfile.gettempdir()
                timestamp = int(time.time())
                temp_file_path = os.path.join(temp_dir, f"combined_image_{timestamp}.tif")

                # Save the combined image using `save_image()`
                save_image(
                    img_array=self.combined_image,
                    filename=temp_file_path,
                    original_format='tif',
                    bit_depth=self.bit_depth if self.bit_depth in ["16-bit", "32-bit unsigned", "32-bit floating point"] else "32-bit floating point",
                    original_header=self.original_header,
                    is_mono=self.is_mono
                )

                file_path = temp_file_path
                print(f"Combined image saved to temporary file: {file_path}")
            except Exception as e:
                print(f"Failed to save combined image to temporary file: {e}")
                QMessageBox.critical(self, "Error", f"Failed to save combined image to temporary file:\n{e}")
                return

        # Create metadata for the combined image
        metadata = {
            'file_path': file_path,
            'original_header': sanitized_header,  # Use the sanitized or minimal header
            'bit_depth': self.bit_depth if hasattr(self, 'bit_depth') else "Unknown",
            'is_mono': False,  # Assume the combined image is color
            'processing_parameters': {
                'ha_to_oii_ratio': self.haToOiiRatioSlider.value() / 100.0,
                'enable_star_stretch': self.starStretchCheckBox.isChecked(),
                'stretch_factor': self.stretchSlider.value() / 100.0
            },
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Ha': self.ha_filename if self.ha_image is not None else "Not Provided",
                'OIII': self.oiii_filename if self.oiii_image is not None else "Not Provided",
                'SII': self.sii_filename if self.sii_image is not None else "Not Provided",
                'OSC': self.osc_filename if self.osc_image is not None else "Not Provided"
            }
        }

        # Push the image and metadata into the ImageManager
        if self.image_manager:
            try:
                self.image_manager.update_image(
                    updated_image=self.combined_image, metadata=metadata
                )
                print(f"Image pushed to ImageManager with metadata: {metadata}")
                QMessageBox.information(self, "Success", "Combined image pushed to active slot.")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the combined image.")


    def createRatioSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value / 100:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(100)
        slider.setValue(default_value)
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def createStretchSlider(self, label_text, default_value):
        label = QLabel(f"{label_text}: {default_value:.2f}", self)
        slider = QSlider(Qt.Orientation.Horizontal)
        slider.setMinimum(0)
        slider.setMaximum(800)
        slider.setValue(int(default_value * 100))  # Scale to handle float values
        slider.valueChanged.connect(lambda value: label.setText(f"{label_text}: {value / 100:.2f}"))
        return label, slider

    def toggleStarStretchControls(self):
        enabled = self.starStretchCheckBox.isChecked()
        self.stretchSliderLabel.setVisible(enabled)
        self.stretchSlider.setVisible(enabled)

    def load_image(self, image_type):
        """
        Opens a dialog to load an image either from a file or from a slot based on user choice.

        Parameters:
            image_type (str): The type of image to load ('Ha', 'OIII', 'SII', 'OSC').
        """
        try:
            print(f"Initiating load process for {image_type} image.")

            # Step 1: Prompt user to choose the source
            source_choice, ok = QInputDialog.getItem(
                self,
                f"Select {image_type} Image Source",
                "Choose the source of the image:",
                ["From File", "From Slot"],
                editable=False
            )

            if not ok or not source_choice:
                QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
                print(f"{image_type} image loading cancelled by the user.")
                return

            print(f"{image_type} image source selected: {source_choice}")

            if source_choice == "From File":
                result = self.load_image_from_file(image_type)
            elif source_choice == "From Slot":
                result = self.load_image_from_slot(image_type)
            else:
                QMessageBox.warning(self, "Invalid Choice", "Invalid source choice. Operation cancelled.")
                print("Invalid source choice. Exiting load process.")
                return

            if result is None:
                # Loading was unsuccessful or cancelled
                return

            image, original_header, bit_depth, is_mono, file_path = result

            # Assign the loaded image to the appropriate attribute and update the label
            if image_type == 'Ha':
                self.ha_image = image
                self.ha_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.haLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OIII':
                self.oiii_image = image
                self.oiii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oiiiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'SII':
                self.sii_image = image
                self.sii_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.siiLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            elif image_type == 'OSC':
                self.osc_image = image
                self.osc_filename = file_path
                self.original_header = original_header
                self.bit_depth = bit_depth
                self.is_mono = is_mono
                self.oscLabel.setText(f"Loaded: {os.path.basename(file_path) if file_path else 'From Slot'}")
            else:
                QMessageBox.warning(self, "Unknown Image Type", f"Image type '{image_type}' is not recognized.")
                print(f"Unknown image type: {image_type}")
                return

        except Exception as e:
            QMessageBox.critical(self, "Error", f"An unexpected error occurred while loading {image_type} image:\n{e}")
            print(f"An unexpected error occurred while loading {image_type} image: {e}")

    def load_image_from_file(self, image_type):
        """
        Handles loading an image from a file.

        Parameters:
            image_type (str): The type of image to load.

        Returns:
            tuple: (image, original_header, bit_depth, is_mono, file_path) or None on failure.
        """
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            f"Select {image_type} Image File",
            "",
            file_filter
        )

        if not file_path:
            QMessageBox.warning(self, "No File Selected", f"No {image_type} image file selected. Operation cancelled.")
            print(f"No {image_type} image file selected.")
            return None

        print(f"{image_type} image file selected: {file_path}")

        # Load the image using your existing load_image function
        image, original_header, bit_depth, is_mono = load_image(file_path)
        if image is None:
            QMessageBox.critical(self, "Error", f"Failed to load {image_type} image from file.")
            print(f"Failed to load {image_type} image from file: {file_path}")
            return None

        return image, original_header, bit_depth, is_mono, file_path

    def load_image_from_slot(self, image_type):
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            print("ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Build the list using the parent's slot_names dictionary.
        available_slots = []
        slot_names = self.parent_window.slot_names if self.parent_window else {}
        for i in range(self.image_manager.max_slots):
            slot_name = slot_names.get(i, f"Slot {i+1}")
            available_slots.append(slot_name)

        slot_choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {image_type} Image",
            "Choose a slot:",
            available_slots,
            editable=False
        )

        if not ok or not slot_choice:
            QMessageBox.warning(self, "Cancelled", f"{image_type} image loading cancelled.")
            print(f"{image_type} image loading cancelled by the user.")
            return None

        # Find the slot index that matches the chosen display name.
        target_slot_num = None
        for i in range(self.image_manager.max_slots):
            current_name = slot_names.get(i, f"Slot {i+1}")
            if current_name == slot_choice:
                target_slot_num = i
                break

        if target_slot_num is None:
            QMessageBox.critical(self, "Error", f"Invalid slot selection: {slot_choice}")
            print(f"Error: Could not map slot name '{slot_choice}' to a slot number.")
            return None

        image = self.image_manager._images.get(target_slot_num, None)
        if image is None:
            QMessageBox.warning(self, "Empty Slot", f"{slot_choice} does not contain an image.")
            print(f"{slot_choice} is empty. Cannot load {image_type} image.")
            return None

        print(f"{image_type} image selected from {slot_choice}.")

        # Retrieve metadata.
        metadata = self.image_manager._metadata.get(target_slot_num, {})
        original_header = metadata.get('header', None)
        bit_depth = metadata.get('bit_depth', "Unknown")
        is_mono = metadata.get('is_mono', False)
        file_path = metadata.get('file_path', None)

        return image, original_header, bit_depth, is_mono, file_path


    def previewCombine(self):
        # Check if required images are loaded prior to starting the processing thread
        if not ((self.ha_image is not None and self.oiii_image is not None) or (self.osc_image is not None)):
            QMessageBox.warning(self, "Missing Images", "Please Select Images Before Combining")
            return    
        ha_to_oii_ratio = self.haToOiiRatioSlider.value() / 100.0
        enable_star_stretch = self.starStretchCheckBox.isChecked()
        stretch_factor = self.stretchSlider.value() / 100.0

        # Show spinner before starting processing
        self.showSpinner()

        # Reset zoom factor when a new preview is generated
        self.zoom_factor = 1.0

        # Start background processing
        self.processing_thread = NBtoRGBProcessingThread(
            self.ha_image, self.oiii_image, self.sii_image, self.osc_image,
            ha_to_oii_ratio=ha_to_oii_ratio, enable_star_stretch=enable_star_stretch, stretch_factor=stretch_factor
        )
        self.processing_thread.preview_generated.connect(self.updatePreview)
        self.processing_thread.start()

    def updatePreview(self, combined_image):
        # Set the combined image for saving
        self.combined_image = combined_image

        # Convert the image to display format
        try:
            preview_image = (combined_image * 255).astype(np.uint8)
            h, w = preview_image.shape[:2]
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        except Exception as e:
            print(f"Error converting combined image for display: {e}")
            QMessageBox.critical(self, "Error", f"Failed to prepare image for display:\n{e}")
            self.hideSpinner()
            return

        # Store original pixmap for zooming
        self.original_pixmap = QPixmap.fromImage(q_image)

        # Apply initial zoom
        scaled_pixmap = self.original_pixmap.scaled(
            self.original_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is done
        self.hideSpinner()



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    def saveImage(self):
        if self.combined_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename) if self.filename else "output"
            default_save_name = 'NBtoRGBstars.tif'
            original_dir = os.path.dirname(self.filename) if self.filename else ""

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                if original_format in ['tiff', 'tif', 'fits', 'fit']:
                    bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                    bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                    
                    if ok and bit_depth:
                        # Call save_image with the necessary parameters
                        save_image(self.combined_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                        self.fileLabel.setText(f'Image saved as: {save_filename}')
                    else:
                        self.fileLabel.setText('Save canceled.')
                else:
                    # For non-TIFF/FITS formats, save directly without bit depth selection
                    save_image(self.combined_image, save_filename, original_format)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
            else:
                self.fileLabel.setText('Save canceled.')
        else:
            self.fileLabel.setText("No combined image to save.")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    @announce_zoom
    def zoom_in(self):
        if self.zoom_factor < 20.0:  # Set a maximum zoom limit (e.g., 500%)
            self.zoom_factor *= 1.25  # Increase zoom by 25%
            self.updateImageDisplay()
        else:
            print("Maximum zoom level reached.")

    @announce_zoom
    def zoom_out(self):
        if self.zoom_factor > 0.01:  # Set a minimum zoom limit (e.g., 20%)
            self.zoom_factor /= 1.25  # Decrease zoom by 20%
            self.updateImageDisplay()
        else:
            print("Minimum zoom level reached.")

    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.combined_image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.combined_image.ndim == 3:
                image_width = self.combined_image.shape[1]
            elif self.combined_image.ndim == 2:
                image_width = self.combined_image.shape[1]
            else:
                print("Unexpected image dimensions!")

                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()  # Call without extra arguments; it will calculate dimensions based on zoom factor

    def reset_zoom(self):
        self.zoom_factor = 1.0
        self.updateImageDisplay()

    def updateImageDisplay(self):
        if self.original_pixmap:
            scaled_pixmap = self.original_pixmap.scaled(
                self.original_pixmap.size() * self.zoom_factor,
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())

    # Add event filter for mouse dragging in preview area
    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)

    # Placeholder methods for functionalities
    def handleImageMouseMove(self, x, y):
        # Implement handling mouse movement over the image
        pass


class NBtoRGBProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, ha_image=None, oiii_image=None, sii_image=None, osc_image=None, ha_to_oii_ratio=0.3, enable_star_stretch=True, stretch_factor=5.0):
        super().__init__()
        self.ha_image = ha_image
        self.oiii_image = oiii_image
        self.sii_image = sii_image
        self.osc_image = osc_image
        self.ha_to_oii_ratio = ha_to_oii_ratio
        self.enable_star_stretch = enable_star_stretch
        self.stretch_factor = stretch_factor

    def run(self):
        # Preprocess input images to ensure mono images are single-channel
        self.ha_image = preprocess_narrowband_image(self.ha_image)
        self.oiii_image = preprocess_narrowband_image(self.oiii_image)
        self.sii_image = preprocess_narrowband_image(self.sii_image)

        # Normalize input images to [0, 1]
        if self.ha_image is not None:
            self.ha_image = np.clip(self.ha_image, 0, 1)
        if self.oiii_image is not None:
            self.oiii_image = np.clip(self.oiii_image, 0, 1)
        if self.sii_image is not None:
            self.sii_image = np.clip(self.sii_image, 0, 1)
        if self.osc_image is not None:
            self.osc_image = np.clip(self.osc_image, 0, 1)

        # Combined RGB logic
        if self.osc_image is not None:
            r_channel = self.osc_image[..., 0]
            g_channel = self.osc_image[..., 1]
            b_channel = self.osc_image[..., 2]

            r_combined = 0.5 * r_channel + 0.5 * (self.sii_image if self.sii_image is not None else r_channel)
            g_combined = self.ha_to_oii_ratio * (self.ha_image if self.ha_image is not None else r_channel) + \
                        (1 - self.ha_to_oii_ratio) * g_channel
            b_combined = b_channel if self.oiii_image is None else self.oiii_image
        else:
            r_combined = 0.5 * self.ha_image + 0.5 * (self.sii_image if self.sii_image is not None else self.ha_image)
            g_combined = self.ha_to_oii_ratio * self.ha_image + (1 - self.ha_to_oii_ratio) * self.oiii_image
            b_combined = self.oiii_image

        # Debugging: Check shapes
        print(f"R combined shape: {r_combined.shape}")
        print(f"G combined shape: {g_combined.shape}")
        print(f"B combined shape: {b_combined.shape}")

        # Normalize combined channels to [0, 1]
        r_combined = np.clip(r_combined, 0, 1)
        g_combined = np.clip(g_combined, 0, 1)
        b_combined = np.clip(b_combined, 0, 1)

        # Stack the channels to create an RGB image
        try:
            combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)
        except ValueError as e:
            print(f"Error while stacking channels: {e}")
            print(f"R: {r_combined.shape}, G: {g_combined.shape}, B: {b_combined.shape}")
            return

        print(f"Combined image shape: {combined_image.shape}")

        # Apply star stretch if enabled
        if self.enable_star_stretch:
            combined_image = self.apply_star_stretch(combined_image)

        # Ensure combined_image is 3-channel
        if combined_image.ndim != 3 or combined_image.shape[2] != 3:
            raise ValueError("Combined image must have three channels (RGB).")

        # Apply SCNR (remove green cast)
        apply_average_neutral_scnr(combined_image)

        # Emit the processed image for preview
        self.preview_generated.emit(combined_image)


    def apply_star_stretch(self, image):
        # Ensure input image is in the range [0, 1]
        assert np.all(image >= 0) and np.all(image <= 1), "Image must be normalized to [0, 1] before star stretch."
        stretched = ((3 ** self.stretch_factor) * image) / ((3 ** self.stretch_factor - 1) * image + 1)
        return np.clip(stretched, 0, 1)

    def apply_scnr(self, image):
        green_channel = image[..., 1]
        max_rg = np.maximum(image[..., 0], image[..., 2])
        green_channel[green_channel > max_rg] = max_rg[green_channel > max_rg]
        image[..., 1] = green_channel
        return image

class HaloBGonTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager  # Reference to the ImageManager

        self.image = None  # Selected image
        self.filename = None  # Store the selected file path
        self.preview_image = None  # Store the preview result
        self.processed_image = None
        self.zoom_factor = 0.25  # Initialize zoom factor for preview scaling
        self.dragging = False
        self.is_mono = True
        self.last_pos = None
        self.processing_thread = None  # For background processing
        self.original_header = None
        self.initUI()

        if self.image_manager:
            # Connect to ImageManager's image_changed signal
            self.image_manager.image_changed.connect(self.on_image_changed)
        

    def initUI(self):
        main_layout = QHBoxLayout()

        # Left column for controls
        left_widget = QWidget(self)
        left_layout = QVBoxLayout(left_widget)
        left_widget.setFixedWidth(400)  # Fixed width for left column

        # Instructions label
        instruction_box = QLabel(self)
        instruction_box.setText("""
            Instructions:
            1. Select a stars-only image.
            2. Adjust the reduction amount as needed.
            3. Click Refresh Preview to apply the halo reduction.
        """)
        instruction_box.setWordWrap(True)
        left_layout.addWidget(instruction_box)

        # File selection button
        self.fileButton = QPushButton("Load Image", self)
        self.fileButton.clicked.connect(self.selectImage)
        left_layout.addWidget(self.fileButton)

        self.fileLabel = QLabel('', self)
        left_layout.addWidget(self.fileLabel)

        # Reduction amount slider
        self.reductionLabel = QLabel("Reduction Amount: Extra Low", self)
        self.reductionSlider = QSlider(Qt.Orientation.Horizontal, self)
        self.reductionSlider.setMinimum(0)
        self.reductionSlider.setMaximum(3)
        self.reductionSlider.setValue(0)  # 0: Extra Low, 1: Low, 2: Medium, 3: High
        self.reductionSlider.setToolTip("Adjust the amount of halo reduction (Extra Low, Low, Medium, High)")
        self.reductionSlider.valueChanged.connect(self.updateReductionLabel)
        left_layout.addWidget(self.reductionLabel)
        left_layout.addWidget(self.reductionSlider)

        # Linear data checkbox
        self.linearDataCheckbox = QCheckBox("Linear Data", self)
        self.linearDataCheckbox.setToolTip("Check if the data is linear")
        left_layout.addWidget(self.linearDataCheckbox)

        # Progress indicator (spinner) label
        self.spinnerLabel = QLabel(self)
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        # Use the resource path function to access the GIF
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))  # Updated path
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # Hide spinner by default
        left_layout.addWidget(self.spinnerLabel)

        # **Create a horizontal layout for Refresh Preview and Undo buttons**
        action_buttons_layout = QHBoxLayout()

        # Refresh Preview button
        self.executeButton = QPushButton("Refresh Preview", self)
        self.executeButton.clicked.connect(self.generatePreview)
        action_buttons_layout.addWidget(self.executeButton)

        # Undo button with left arrow icon
        self.undoButton = QPushButton("Undo", self)
        undo_icon = self.style().standardIcon(QStyle.StandardPixmap.SP_ArrowBack)  # Standard left arrow icon
        self.undoButton.setIcon(undo_icon)
        self.undoButton.clicked.connect(self.undoAction)
        self.undoButton.setEnabled(False)  # Disabled by default
        action_buttons_layout.addWidget(self.undoButton)

        # Add the horizontal layout to the left layout
        left_layout.addLayout(action_buttons_layout)

        # **Remove Zoom Buttons from Left Panel**
        # Comment out or remove the existing zoom buttons in the left panel
        # zoom_layout = QHBoxLayout()
        # self.zoomInButton = QPushButton("Zoom In", self)
        # self.zoomInButton.clicked.connect(self.zoomIn)
        # zoom_layout.addWidget(self.zoomInButton)
        #
        # self.zoomOutButton = QPushButton("Zoom Out", self)
        # self.zoomOutButton.clicked.connect(self.zoomOut)
        # zoom_layout.addWidget(self.zoomOutButton)
        # left_layout.addLayout(zoom_layout)


        #left_layout.addSpacerItem(QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding))
        main_layout.addWidget(left_widget)

        # **Create Right Panel Layout**
        right_widget = QWidget(self)
        right_layout = QVBoxLayout(right_widget)

        # Zoom controls

        zoom_layout = QHBoxLayout()
        zoom_in_button = QPushButton("Zoom In")
        zoom_in_button.clicked.connect(self.zoomIn)
        zoom_layout.addWidget(zoom_in_button)

        zoom_out_button = QPushButton("Zoom Out")
        zoom_out_button.clicked.connect(self.zoomOut)
        zoom_layout.addWidget(zoom_out_button)

        # **Add "Fit to Preview" Button**
        self.fitToPreviewButton = QPushButton("Fit to Preview")
        self.fitToPreviewButton.clicked.connect(self.fit_to_preview)
        zoom_layout.addWidget(self.fitToPreviewButton)

        right_layout.addLayout(zoom_layout)

        # Right side for the preview inside a QScrollArea
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAsNeeded)
        self.scrollArea.viewport().installEventFilter(self)

        # QLabel for the image preview
        self.imageLabel = QLabel(self)
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        self.scrollArea.setMinimumSize(400, 400)

        right_layout.addWidget(self.scrollArea)

        # Add the right widget to the main layout
        main_layout.addWidget(right_widget)

        self.setLayout(main_layout)
        self.scrollArea.viewport().setMouseTracking(True)
        self.scrollArea.viewport().installEventFilter(self)

    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            current_slot = self.image_manager.current_slot
            image, metadata = self.image_manager.get_current_image_and_metadata()
            self.on_image_changed(current_slot, image, metadata)

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        if not self.isVisible():
            return   
        if image is None:
            return             
        if slot == self.image_manager.current_slot:
            # Ensure the image is a numpy array before proceeding
            if not isinstance(image, np.ndarray):
                image = np.array(image)  # Convert to numpy array if necessary
            
            self.image = image  # Set the original image
            self.preview_image = None  # Reset the preview image
            self.original_header = metadata.get('original_header', None)
            self.is_mono = metadata.get('is_mono', False)
            self.filename = metadata.get('file_path', self.filename)

            # Update the image display
            self.updateImageDisplay()

            print(f"Halo-B-Gon Tab: Image updated from ImageManager slot {slot}.")

            # **Update Undo and Redo Button States**
            if self.image_manager:
                self.undoButton.setEnabled(self.image_manager.can_undo())



    def updateImageDisplay(self):
        if self.image is not None:
            # Prepare the image for display by normalizing and converting to uint8
            display_image = (self.image * 255).astype(np.uint8)
            h, w = display_image.shape[:2]

            if display_image.ndim == 3:  # RGB Image
                # Convert the image to QImage format
                q_image = QImage(display_image.tobytes(), w, h, 3 * w, QImage.Format.Format_RGB888)
            else:  # Grayscale Image
                q_image = QImage(display_image.tobytes(), w, h, w, QImage.Format.Format_Grayscale8)

            # Create a QPixmap from QImage
            pixmap = QPixmap.fromImage(q_image)
            self.current_pixmap = pixmap  # Store the original pixmap for future reference

            # Scale the pixmap based on the zoom factor
            scaled_pixmap = pixmap.scaled(pixmap.size() * self.zoom_factor, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

            # Set the pixmap on the image label
            self.imageLabel.setPixmap(scaled_pixmap)
            self.imageLabel.resize(scaled_pixmap.size())  # Resize the label to fit the image
        else:
            # If no image is available, clear the label and show a message
            self.imageLabel.clear()
            self.imageLabel.setText('No image loaded.')



    def undoAction(self):
        if self.image_manager and self.image_manager.can_undo():
            try:
                # Perform the undo operation
                self.image_manager.undo()
                print("HaloBGonTab: Undo performed.")
            except Exception as e:
                print(f"Error performing undo: {e}")
                QMessageBox.critical(self, "Error", f"Failed to perform undo:\n{e}")
        else:
            QMessageBox.information(self, "Info", "Nothing to undo.")
            print("HaloBGonTab: No actions to undo.")

        # Update the state of the Undo button
        self.undoButton.setEnabled(self.image_manager.can_undo())

    def updateReductionLabel(self, value):
        labels = ["Extra Low", "Low", "Medium", "High"]
        if 0 <= value < len(labels):
            self.reductionLabel.setText(f"Reduction Amount: {labels[value]}")
        else:
            self.reductionLabel.setText("Reduction Amount: Unknown")

    def wheelEvent(self, event: QWheelEvent):
        # Check the vertical delta to determine zoom direction.
        if event.angleDelta().y() > 0:
            self.zoomIn()
        else:
            self.zoomOut()
        # Accept the event so it isn’t propagated further (e.g. to the scroll area).
        event.accept()

    def zoomIn(self):
        self.zoom_factor *= 1.2  # Increase zoom by 20%
        self.updateImageDisplay()

    def zoomOut(self):
        self.zoom_factor /= 1.2  # Decrease zoom by 20%
        self.updateImageDisplay()
    
    def fit_to_preview(self):
        """Adjust the zoom factor so that the image's width fits within the preview area's width."""
        if self.image is not None:
            # Get the width of the scroll area's viewport (preview area)
            preview_width = self.scrollArea.viewport().width()
            
            # Get the original image width from the numpy array
            # Assuming self.image has shape (height, width, channels) or (height, width) for grayscale
            if self.image.ndim == 3:
                image_width = self.image.shape[1]
            elif self.image.ndim == 2:
                image_width = self.image.shape[1]
            else:
                print("Unexpected image dimensions!")
                self.statusLabel.setText("Cannot fit image to preview due to unexpected dimensions.")
                return
            
            # Calculate the required zoom factor to fit the image's width into the preview area
            new_zoom_factor = preview_width / image_width
            
            # Update the zoom factor without enforcing any limits
            self.zoom_factor = new_zoom_factor
            
            # Apply the new zoom factor to update the display
            self.apply_zoom()
            
            # Update the status label to reflect the new zoom level
        else:
            print("No image loaded. Cannot fit to preview.")

    def apply_zoom(self):
        """Apply the current zoom level to the image."""
        self.updateImageDisplay()

    def selectImage(self):
        selected_file, _ = QFileDialog.getOpenFileName(
            self, 
            "Select Stars Only Image", 
            "", 
            "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        )
        if selected_file:
            try:
                # Load the image with header information
                self.image, self.original_header, _, self.is_mono = load_image(selected_file)  # Ensure load_image returns (image, header, bit_depth, is_mono)
                self.filename = selected_file 
                self.fileLabel.setText(os.path.basename(selected_file))
                
                # Update ImageManager with the loaded image
                if self.image_manager:
                    metadata = {
                        'file_path': selected_file,
                        'original_header': self.original_header,
                        'bit_depth': 'Unknown',  # Update if available
                        'is_mono': self.is_mono
                    }
                    self.image_manager.set_image(self.image, metadata, step_name="load_stars_only")
                    print(f"HaloBGonTab: Loaded image stored in ImageManager.")
                
                self.generatePreview()  # Generate preview after loading
            except Exception as e:
                self.fileLabel.setText(f"Error: {str(e)}")
                QMessageBox.critical(self, "Error", f"Failed to load image:\n{e}")
                print(f"Failed to load image: {e}")

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager.
        
        Returns:
            np.ndarray or None: The active mask as a NumPy array normalized between 0 and 1,
                                or None if no mask is applied.
        """
        if self.image_manager and self.image_manager.mask_manager:
            mask = self.image_manager.mask_manager.get_applied_mask()
            if mask is not None:
                print("Active mask retrieved.")
                # Ensure mask is normalized between 0 and 1
                if mask.dtype != np.float32 and mask.dtype != np.float64:
                    mask = mask.astype(np.float32) / 255.0
                # If mask is single-channel but image is multi-channel, expand dimensions
                if self.image.ndim == 3 and mask.ndim == 2:
                    mask = np.expand_dims(mask, axis=-1)
                # Ensure mask dimensions match the image dimensions
                if mask.shape[:2] != self.image.shape[:2]:
                    QMessageBox.critical(self, "Error", "Mask dimensions do not match the image dimensions.")
                    return None
                return mask
        return None



    def applyHaloReduction(self):
        if self.image is None:
            print("No image selected.")
            return

        reduction_amount = self.reductionSlider.value()
        is_linear = self.linearDataCheckbox.isChecked()

        # Show spinner and start background processing
        self.showSpinner()
        self.processing_thread = QThread()
        self.processing_worker = self.HaloProcessingWorker(self.image, reduction_amount, is_linear)
        self.processing_worker.moveToThread(self.processing_thread)
        self.processing_worker.processing_complete.connect(self.updateImage)
        self.processing_thread.started.connect(self.processing_worker.process)
        self.processing_thread.start()

    def updatePreview(self, processed_image):
        """
        Updates the preview with the processed image and applies the active mask if available.
        """
        # Retrieve the active mask
        mask = self.get_active_mask()
        
        if mask is not None:
            print("Applying mask to the processed image.")
            # Ensure mask and image have the same number of channels
            if self.image.ndim == 3 and mask.ndim == 2:
                mask = np.expand_dims(mask, axis=-1)
            
            # Blend the processed image with the original image using the mask
            # Formula: blended_image = processed_image * mask + original_image * (1 - mask)
            blended_image = processed_image * mask + self.image * (1 - mask)
            blended_image = np.clip(blended_image, 0.0, 1.0)  # Ensure values are within [0,1]
        else:
            print("No mask applied. Using the processed image directly.")
            blended_image = processed_image
        
        # Create metadata for the new image
        metadata = {
            'file_path': self.filename if self.filename else "Processed Image",
            'original_header': self.original_header if self.original_header else {},
            'bit_depth': "Unknown",  # Update dynamically if available
            'is_mono': self.is_mono,
            'processing_timestamp': datetime.now().isoformat(),
            'source_images': {
                'Original': self.filename if self.filename else "Not Provided"
            }
        }

        # Ensure ImageManager is initialized
        if self.image_manager:
            try:
                # Set the new image and metadata using the ImageManager
                self.image_manager.set_image(blended_image, metadata, step_name="halo_reduction")
                print("HaloBGonTab: Processed and masked image stored in ImageManager (undoable).")
            except Exception as e:
                print(f"Error updating ImageManager: {e}")
                QMessageBox.critical(self, "Error", f"Failed to update ImageManager:\n{e}")
                self.hideSpinner()
                return
        else:
            print("ImageManager is not initialized.")
            QMessageBox.warning(self, "Warning", "ImageManager is not initialized. Cannot store the processed image.")
            self.hideSpinner()
            return

        # Convert the blended image to 8-bit for display in the preview
        preview_image = (blended_image * 255).astype(np.uint8)
        h, w = preview_image.shape[:2]
        if preview_image.ndim == 3:
            q_image = QImage(preview_image.data, w, h, 3 * w, QImage.Format.Format_RGB888)
        else:
            q_image = QImage(preview_image.data, w, h, w, QImage.Format.Format_Grayscale8)

        # Update the pixmap and scale it for the preview label
        pixmap = QPixmap.fromImage(q_image)
        self.current_pixmap = pixmap  # Store the original pixmap
        scaled_pixmap = pixmap.scaled(
            pixmap.size() * self.zoom_factor, 
            Qt.AspectRatioMode.KeepAspectRatio, 
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled_pixmap)
        self.imageLabel.resize(scaled_pixmap.size())

        # Hide the spinner after processing is complete
        self.hideSpinner()

        # Update the file label to indicate masking status
        if mask is not None:
            self.fileLabel.setText("Halo reduction applied with mask.")
        else:
            self.fileLabel.setText("Halo reduction applied without mask.")
        
        print("HaloBGonTab: Preview updated with processed image.")



    def saveImage(self):
        if self.processed_image is not None:
            # Pre-populate the save dialog with the original image name
            base_name = os.path.basename(self.filename)
            default_save_name = os.path.splitext(base_name)[0] + '_reduced.tif'
            original_dir = os.path.dirname(self.filename)

            # Open the save file dialog
            save_filename, _ = QFileDialog.getSaveFileName(
                self, 
                'Save Image As', 
                os.path.join(original_dir, default_save_name), 
                'Images (*.tiff *.tif *.png *.fit *.fits);;All Files (*)'
            )

            if save_filename:
                original_format = save_filename.split('.')[-1].lower()

                # For TIFF and FITS files, prompt the user to select the bit depth
                bit_depth_options = ["16-bit", "32-bit unsigned", "32-bit floating point"]
                bit_depth, ok = QInputDialog.getItem(self, "Select Bit Depth", "Choose bit depth for saving:", bit_depth_options, 0, False)
                
                if ok and bit_depth:
                    # If linear data is checked, revert to linear before saving
                    if self.linearDataCheckbox.isChecked():
                        saved_image = np.clip(self.processed_image ** 5, 0, 1)  # Revert to linear state
                    else:
                        saved_image = self.processed_image  # Save as is (non-linear)

                    # Call save_image with the necessary parameters
                    save_image(saved_image, save_filename, original_format, bit_depth, self.original_header, self.is_mono)
                    self.fileLabel.setText(f'Image saved as: {save_filename}')
                else:
                    self.fileLabel.setText('Save canceled.')
            else:
                self.fileLabel.setText('Save canceled.')



    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()

    # Updated generatePreview method in HaloBGonTab to use HaloProcessingThread
    def generatePreview(self):
        if self.image is not None and self.image.size > 0:
            # Show spinner before starting processing
            self.showSpinner()

            # Start background processing with HaloProcessingThread
            self.processing_thread = HaloProcessingThread(
                self.image, 
                self.reductionSlider.value(), 
                self.linearDataCheckbox.isChecked()
            )
            self.processing_thread.preview_generated.connect(self.updatePreview)
            self.processing_thread.start()
        else:
            QMessageBox.warning(self, "Warning", "No image loaded. Please load an image first.")
            print("HaloBGonTab: No image loaded. Cannot generate preview.")

    def eventFilter(self, source, event):
        if event.type() == QEvent.Type.MouseButtonPress and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = True
            self.last_pos = event.pos()
        elif event.type() == QEvent.Type.MouseButtonRelease and event.button() == Qt.MouseButton.LeftButton:
            self.dragging = False
        elif event.type() == QEvent.Type.MouseMove and self.dragging:
            delta = event.pos() - self.last_pos
            self.scrollArea.horizontalScrollBar().setValue(self.scrollArea.horizontalScrollBar().value() - delta.x())
            self.scrollArea.verticalScrollBar().setValue(self.scrollArea.verticalScrollBar().value() - delta.y())
            self.last_pos = event.pos()

        return super().eventFilter(source, event)


    def createLightnessMask(self, image):
        # Check if the image is already single-channel (grayscale)
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Normalize the grayscale image
            lightness_mask = image.astype(np.float32) / 255.0
        else:
            # Convert to grayscale to create a lightness mask
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0

        # Apply a Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        lightness_mask = cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)

        return lightness_mask

    def createDuplicateImage(self, original):
        return np.copy(original)

    def invert_mask(mask):
        return 1.0 - mask  # Assuming mask is normalized between 0 and 1


    def apply_mask_to_image(image, mask):
        # Ensure mask is 3-channel to match the image dimensions
        mask_rgb = np.stack([mask] * 3, axis=-1)
        return cv2.multiply(image, mask_rgb)


    def apply_curves_to_image(image, reduction_amount):
        # Define the curve based on reduction amount
        if reduction_amount == 0:
            curve = [int((i / 255.0) ** 0.575 * 255) for i in range(256)]
        else:
            curve = [int((i / 255.0) ** 0.4 * 255) for i in range(256)]
        
        lut = np.array(curve, dtype=np.uint8)
        return cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0


    def load_image(self, filename):
        original_header = None
        file_extension = filename.split('.')[-1].lower()

        # Handle different file types and normalize them to [0, 1] range
        if file_extension in ['tif', 'tiff']:
            image = tiff.imread(filename).astype(np.float32) / 65535.0  # For 16-bit TIFF images
        elif file_extension == 'png':
            image = np.array(Image.open(filename).convert('RGB')).astype(np.float32) / 255.0  # Normalize to [0, 1]
        elif file_extension in ['fits', 'fit']:
            with fits.open(filename) as hdul:
                image = hdul[0].data.astype(np.float32)
                original_header = hdul[0].header
                # Normalize if data is 16-bit or higher
                if image.max() > 1:
                    image /= np.max(image)
        else:
            raise ValueError(f"Unsupported file format: {file_extension}")

        return image, original_header

    def save_image(self, image, filename, file_format, bit_depth="16-bit", original_header=None):
        img = Image.fromarray((image * 255).astype(np.uint8))
        img.save(filename)

class HaloProcessingThread(QThread):
    preview_generated = pyqtSignal(np.ndarray)

    def __init__(self, image, reduction_amount, is_linear):
        super().__init__()
        self.image = image
        self.reduction_amount = reduction_amount
        self.is_linear = is_linear


    def run(self):
        processed_image = self.applyHaloReduction(self.image, self.reduction_amount, self.is_linear)
        self.preview_generated.emit(processed_image)

    def applyHaloReduction(self, image, reduction_amount, is_linear):
        # Ensure the image values are in range [0, 1]
        image = np.clip(image, 0, 1)

        # Convert linear to non-linear if the image is linear
        if is_linear:
            image = image ** (1 / 5)  # Gamma correction for linear data

        # Apply halo reduction logic
        lightness_mask = self.createLightnessMask(image)  # Single-channel mask
        inverted_mask = 1.0 - lightness_mask
        duplicated_mask = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)
        enhanced_mask = inverted_mask - duplicated_mask * reduction_amount * 0.33

        # Expand the mask to match the number of channels in the image
        if image.ndim == 3 and image.shape[2] == 3:  # Color image
            enhanced_mask = np.expand_dims(enhanced_mask, axis=-1)  # Add a channel dimension
            enhanced_mask = np.repeat(enhanced_mask, 3, axis=-1)  # Repeat for all 3 channels

        # Ensure the mask matches the data type of the image
        enhanced_mask = enhanced_mask.astype(image.dtype)

        # Verify that the image and mask dimensions match
        if image.shape != enhanced_mask.shape:
            raise ValueError(
                f"Shape mismatch between image {image.shape} and enhanced_mask {enhanced_mask.shape}"
            )

        # Apply the mask to the image
        masked_image = cv2.multiply(image, enhanced_mask)

        # Apply curves to the resulting image
        final_image = self.applyCurvesToImage(masked_image, reduction_amount)

        # Ensure the final image values are within [0, 1]
        return np.clip(final_image, 0, 1)



    def createLightnessMask(self, image):
        # Ensure the image is in a supported format (float32)
        image = image.astype(np.float32)

        # Check if the image is already grayscale
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            # Image is already grayscale; normalize it
            lightness_mask = image / 255.0
        else:
            # Convert RGB image to grayscale
            lightness_mask = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255.0

        # Apply Gaussian blur to smooth the mask
        blurred = cv2.GaussianBlur(lightness_mask, (0, 0), sigmaX=2)

        # Apply an unsharp mask for enhancement
        return cv2.addWeighted(lightness_mask, 1.66, blurred, -0.66, 0)



    def createDuplicateMask(self, mask):
        # Duplicate the mask and apply additional processing (simulating MMT)
        duplicated_mask = cv2.GaussianBlur(mask, (0, 0), sigmaX=2)
        return duplicated_mask

    def applyMaskToImage(self, image, mask):
        # Blend the original image with the mask based on the reduction level
        mask_rgb = np.stack([mask] * 3, axis=-1)  # Convert to 3-channel
        return cv2.multiply(image, mask_rgb)

    def applyCurvesToImage(self, image, reduction_amount):
        # Apply a curves transformation based on reduction_amount
        if reduction_amount == 0:
            # Extra Low setting, mild curve
            curve = [int((i / 255.0) ** 1.2 * 255) for i in range(256)]
        elif reduction_amount == 1:
            # Low setting, slightly stronger darkening
            curve = [int((i / 255.0) ** 1.5 * 255) for i in range(256)]
        elif reduction_amount == 2:
            # Medium setting, moderate darkening
            curve = [int((i / 255.0) ** 1.8 * 255) for i in range(256)]
        else:
            # High setting, strong darkening effect
            curve = [int((i / 255.0) ** 2.2 * 255) for i in range(256)]

        # Apply the curve transformation as a lookup table
        lut = np.array(curve, dtype=np.uint8)
        transformed_image = cv2.LUT((image * 255).astype(np.uint8), lut).astype(np.float32) / 255.0
        return transformed_image



class ContinuumSubtractTab(QWidget):
    def __init__(self, image_manager, parent=None):
        super().__init__(parent)
        self.parent_window = parent
        self.image_manager = image_manager
        self.initUI()
        self._threads = []
        # — initialize every loadable image to None —
        self.ha_image    = None
        self.sii_image   = None
        self.oiii_image  = None
        self.red_image   = None
        self.green_image = None
        self.osc_image   = None

        self.filename = None
        self.is_mono = True
        self.combined_image = None
        self.processing_thread = None
        self.original_header = None
        self._clickable_images = {}

        if self.image_manager:
            self.image_manager.image_changed.connect(self.on_image_changed)

    def initUI(self):
        self.spinnerLabel = QLabel()
        self.spinnerLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.spinnerMovie = QMovie(resource_path("spinner.gif"))
        self.spinnerLabel.setMovie(self.spinnerMovie)
        self.spinnerLabel.hide()  # hidden until we start processing

        self.statusLabel = QLabel("")  
        self.statusLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        main_layout = QVBoxLayout()  # overall vertical: columns + bottom row
        columns_layout = QHBoxLayout()  # holds the three groups

        # — NB group —
        nb_group = QGroupBox("Narrowband Filters")
        nb_l = QVBoxLayout()
        for name, attr in [("Ha","ha"), ("SII","sii"), ("OIII","oiii")]:
            btn = QPushButton(f"Load {name}")
            lbl = QLabel(f"No {name}")
            setattr(self, f"{attr}Button", btn)
            setattr(self, f"{attr}Label", lbl)
            btn.clicked.connect(lambda _,n=name: self.loadImage(n))
            nb_l.addWidget(btn)
            nb_l.addWidget(lbl)

        self.linear_output_checkbox = QCheckBox("Output Linear Image Only")
        nb_l.addWidget(self.linear_output_checkbox)    
        nb_l.addStretch(1)
        
        # ** clear-all button **
        self.clear_button = QPushButton("Clear Loaded Images")
        self.clear_button.clicked.connect(self.clear_loaded_images)
        nb_l.addWidget(self.clear_button)
        nb_group.setLayout(nb_l)

        # — Continuum group —
        cont_group = QGroupBox("Continuum Sources")
        cont_l = QVBoxLayout()
        for name, attr in [("Red","red"), ("Green","green"), ("OSC","osc")]:
            btn = QPushButton(f"Load {name}")
            lbl = QLabel(f"No {name}")
            setattr(self, f"{attr}Button", btn)
            setattr(self, f"{attr}Label", lbl)
            btn.clicked.connect(lambda _,n=name: self.loadImage(n))
            cont_l.addWidget(btn)
            cont_l.addWidget(lbl)
        cont_l.addStretch(1)
        cont_group.setLayout(cont_l)

        # — White balance diagnostics —
        wb_group   = QGroupBox("Star-Based WB")
        self.wb_l  = QVBoxLayout()
        self.wb_l.setAlignment(Qt.AlignmentFlag.AlignTop)
        wb_group.setLayout(self.wb_l)

        # put it in a scroll area so many entries won't overflow
        wb_scroll = QScrollArea()
        wb_scroll.setWidgetResizable(True)
        wb_container = QWidget()
        wb_container.setLayout(self.wb_l)
        wb_scroll.setWidget(wb_container)

        # assemble columns
        columns_layout.addWidget(nb_group,    1)  # stretch factor 1
        columns_layout.addWidget(cont_group,  1)  # stretch factor 1
        columns_layout.addWidget(wb_scroll,   2)  # stretch factor 2 (wider)

        # — Bottom row: Execute & status —
        bottom_layout = QHBoxLayout()
        self.execute_button = QPushButton("Execute")
        self.execute_button.clicked.connect(self.startContinuumSubtraction)
        bottom_layout.addWidget(self.execute_button, stretch=1)
        # statusLabel must already exist
        bottom_layout.addWidget(self.spinnerLabel, stretch=1)
        bottom_layout.addWidget(self.statusLabel,   stretch=3)

        # — Footer —
        footer = QLabel(
            "Written by Franklin Marek<br>"
            "<a href='http://www.setiastro.com'>www.setiastro.com</a>"
        )
        footer.setAlignment(Qt.AlignmentFlag.AlignCenter)
        footer.setOpenExternalLinks(True)
        footer.setStyleSheet("font-size: 10px;")

        # put it all together
        main_layout.addLayout(columns_layout)
        main_layout.addLayout(bottom_layout)
        main_layout.addWidget(footer)
        self.setLayout(main_layout)
        self.installEventFilter(self)


    def refresh(self):
        if self.image_manager:
            # You might have a way to retrieve the current image and metadata.
            # For example, if your image_manager stores the current image,
            # you could do something like:
            return

    def on_image_changed(self, slot, image, metadata):
        """
        Slot to handle image changes from ImageManager.
        Updates the display if the current slot is affected.
        """
        return

    def clear_loaded_images(self):
        """Clear all loaded NB and continuum images and reset the UI."""
        # 1) Clear all image attributes
        for attr in ("ha_image", "sii_image", "oiii_image",
                    "red_image", "green_image", "osc_image"):
            setattr(self, attr, None)

        # 2) Reset all labels
        self.haLabel    .setText("No Ha image")
        self.siiLabel   .setText("No SII image")
        self.oiiiLabel  .setText("No OIII image")
        self.redLabel   .setText("No Red image")
        self.greenLabel .setText("No Green image")
        self.oscLabel   .setText("No OSC image")

        # 3) Clear any preview state
        self.combined_image = None
        self.original_pixmap = None
        self.imageLabel.clear()

        # 4) Reset zoom
        self.zoom_factor = 1.0
        self.apply_zoom()
        self.zoomInButton .setEnabled(False)
        self.zoomOutButton.setEnabled(False)

        # 5) Disable save/push
        self.save_button   .setEnabled(False)
        self.pushButton    .setEnabled(False)  # if you have a push-to-slot button

        # 6) Reset status
        self.statusLabel.setText("All loaded images cleared.")
        print("All loaded images cleared.")


    def loadImage(self, channel: str):
        """
        Prompt the user to load either from file or from ImageManager slots,
        for the given channel ("Ha", "SII", "OIII", "Red", "Green", "OSC").
        """
        source, ok = QInputDialog.getItem(
            self,
            f"Select {channel} Image Source",
            "Load image from:",
            ["From File", "From Slot"],
            editable=False
        )
        if not ok:
            return

        if source == "From File":
            result = self.loadImageFromFile(channel)
        else:
            result = self.loadImageFromSlot(channel)

        if not result:
            return

        image, header, bit_depth, is_mono, path = result

        # Store into the right attribute & update the right label:
        label_text = os.path.basename(path) if path else "From Slot"
        if channel == "Ha":
            self.ha_image = image
            self.haLabel .setText(label_text)
        elif channel == "SII":
            self.sii_image = image
            self.siiLabel.setText(label_text)
        elif channel == "OIII":
            self.oiii_image = image
            self.oiiiLabel.setText(label_text)
        elif channel == "Red":
            self.red_image = image
            self.redLabel.setText(label_text)
        elif channel == "Green":
            self.green_image = image
            self.greenLabel.setText(label_text)
        elif channel == "OSC":
            self.osc_image = image
            self.oscLabel.setText(label_text)
        else:
            # unexpected channel string
            QMessageBox.critical(self, "Error", f"Unknown channel '{channel}'.")
            return

        # Store header and mono-flag for later saving
        self.original_header = header
        self.is_mono         = is_mono


    def loadImageFromFile(self, channel: str):
        file_filter = "Images (*.png *.tif *.tiff *.fits *.fit *.xisf)"
        path, _ = QFileDialog.getOpenFileName(self, f"Select {channel} Image", "", file_filter)
        if not path:
            return None

        try:
            image, header, bit_depth, is_mono = load_image(path)
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to load {channel} image:\n{e}")
            return None

        return image, header, bit_depth, is_mono, path

    def loadImageFromSlot(self, channel: str):
        """
        Prompt the user to pick one of the ImageManager’s slots (using custom names if defined)
        and load that image.
        """
        if not self.image_manager:
            QMessageBox.critical(self, "Error", "ImageManager is not initialized. Cannot load image from slot.")
            return None

        # Look up the main window’s custom slot names
        main_win = getattr(self, "parent_window", None) or self.window()
        slot_names = getattr(main_win, "slot_names", {})

        # Build the list of display names (zero-based)
        display_names = [
            slot_names.get(i, f"Slot {i}") 
            for i in range(self.image_manager.max_slots)
        ]

        # Ask the user to choose one
        choice, ok = QInputDialog.getItem(
            self,
            f"Select Slot for {channel}",
            "Choose a slot:",
            display_names,
            0,
            False
        )
        if not ok or not choice:
            return None

        # Map back to the numeric index
        idx = display_names.index(choice)

        # Retrieve the image and metadata
        img = self.image_manager._images.get(idx)
        if img is None:
            QMessageBox.warning(self, "Empty Slot", f"{choice} is empty.")
            return None

        meta = self.image_manager._metadata.get(idx, {})
        return (
            img,
            meta.get("original_header"),
            meta.get("bit_depth", "Unknown"),
            meta.get("is_mono", False),
            meta.get("file_path", None)
        )


    def startContinuumSubtraction(self):
        # — build continuum channels with explicit None checks —
        if hasattr(self, "red_image") and self.red_image is not None:
            cont_red = self.red_image
        elif hasattr(self, "osc_image") and self.osc_image is not None:
            cont_red = self.osc_image[..., 0]
        else:
            cont_red = None

        if hasattr(self, "green_image") and self.green_image is not None:
            cont_green = self.green_image
        elif hasattr(self, "osc_image") and self.osc_image is not None:
            cont_green = self.osc_image[..., 1]
        else:
            cont_green = None

        # — build tasks as before —
        tasks = []
        if self.ha_image is not None and cont_red is not None:
            tasks.append(("Ha",  self.ha_image,  cont_red))
        if self.sii_image is not None and cont_red is not None:
            tasks.append(("SII", self.sii_image, cont_red))
        if self.oiii_image is not None and cont_green is not None:
            tasks.append(("OIII", self.oiii_image, cont_green))

        if not tasks:
            self.statusLabel.setText("Load at least one NB + matching continuum channel (or OSC).")
            return


        self.showSpinner()

        self._threads.clear()
        self._pending = len(tasks)
        self._results = []

        for name, nb, cont in tasks:
            t = ContinuumProcessingThread(nb, cont, self.linear_output_checkbox.isChecked())
            t.status_update.connect(self.update_status_label)
            t.processing_complete.connect(
                lambda img, stars, overlay, raw, after, n=name:
                    self._onOneResult(n, img, stars, overlay, raw, after)
            )
            t.finished.connect(self._onThreadFinished)
            self._threads.append(t)      # keep a reference
            t.start()

    def _onOneResult(self, filt, img, star_count, overlay_qimg, raw_pixels, after_pixels):
        # stash for later slot‐pushing
        self._results.append({
            "filter":  filt,
            "image":   img,
            "stars":   star_count,
            "overlay": overlay_qimg,
            "raw":     raw_pixels,
            "after":   after_pixels
        })

        # build scatter‐plot
        nb_flux   = raw_pixels[:, 0]
        cont_flux = raw_pixels[:, 1]
        h, w = 200, 200
        scatter_img = np.ones((h, w, 3), np.uint8) * 255

        # 1) Compute best-fit in flux space: NB ≈ m·BB + c
        m, c = np.polyfit(cont_flux, nb_flux, 1)

        # 2) Choose two BB positions to draw the line at (0 and 1)
        x0f, y0f = 0.0, c
        x1f, y1f = 1.0, m*1.0 + c

        # clip so we stay within [0,1]
        y0f = np.clip(y0f, 0.0, 1.0)
        y1f = np.clip(y1f, 0.0, 1.0)

        # map to pixel coords
        x0 = int(x0f * (w - 1))
        y0 = int((1 - y0f) * (h - 1))
        x1 = int(x1f * (w - 1))
        y1 = int((1 - y1f) * (h - 1))

        # draw the fit line (in blue, thickness 2)
        cv2.line(scatter_img, (x0, y0), (x1, y1), (255, 0, 0), 2)

        # 3) Plot points
        xs = (cont_flux * (w - 1)).astype(int)
        ys = ((1 - nb_flux) * (h - 1)).astype(int)
        for x, y in zip(xs, ys):
            cv2.circle(scatter_img, (x, y), 2, (0, 0, 255), -1)
        # draw axes
        cv2.line(scatter_img, (0, h - 1), (w - 1, h - 1), (0, 0, 0), 1)  # x-axis
        cv2.line(scatter_img, (0, 0),       (0, h - 1),     (0, 0, 0), 1)  # y-axis

        # put “BB Flux” centered on the x-axis
        font = cv2.FONT_HERSHEY_SIMPLEX
        text = "BB Flux"
        ((tw, th), _) = cv2.getTextSize(text, font, 0.5, 1)
        x_text = (w - tw) // 2
        y_text = h - 5  # just above bottom
        cv2.putText(scatter_img, text, (x_text, y_text), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # put “NB Flux” vertically along the left
        vert_text = "NB Flux"
        # draw each character, stepping down
        for i, ch in enumerate(vert_text):
            # x is a few pixels right of the y-axis, y steps by 15px
            cv2.putText(scatter_img, ch, (2, 15 + i*15), font, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # convert to QPixmap
        qscatter = QImage(scatter_img.data, w, h, 3*w, QImage.Format.Format_RGB888).copy()
        scatter_pix = QPixmap.fromImage(qscatter)

        # overlay thumbnail
        thumb_pix = QPixmap.fromImage(overlay_qimg).scaled(
            200, 200,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )

        # assemble entry row
        entry = QWidget()
        elay  = QHBoxLayout(entry)

        # 1) star count label
        elay.addWidget(QLabel(f"{filt}: {star_count} stars"))

        # 2) scatter thumbnail
        scatter_label = QLabel()
        scatter_label.setPixmap(scatter_pix)
        scatter_label.setCursor(Qt.CursorShape.PointingHandCursor)
        elay.addWidget(scatter_label)
        # remember it & install filter
        self._clickable_images[scatter_label] = scatter_pix
        scatter_label.installEventFilter(self)

        # 3) overlay thumbnail
        overlay_label = QLabel()
        overlay_label.setPixmap(thumb_pix)
        overlay_label.setCursor(Qt.CursorShape.PointingHandCursor)
        elay.addWidget(overlay_label)
        self._clickable_images[overlay_label] = QPixmap.fromImage(overlay_qimg)
        overlay_label.installEventFilter(self)

        elay.addStretch(1)
        entry.setLayout(elay)

        # add to the WB column
        self.wb_l.addWidget(entry)

    def eventFilter(self, source, event):
        # catch mouse releases on any of our clickable labels
        if event.type() == QEvent.Type.MouseButtonRelease and source in self._clickable_images:
            pix = self._clickable_images[source]
            self._showEnlarged(pix)
            return True
        return super().eventFilter(source, event)

    def _showEnlarged(self, pixmap):
        # simple dialog that just shows the pixmap at window-fitting size
        dlg = QDialog(self)
        dlg.setWindowTitle("Detail View")
        layout = QVBoxLayout(dlg)
        lbl = QLabel()
        lbl.setPixmap(pixmap.scaled(800, 800, Qt.AspectRatioMode.KeepAspectRatio,
                                     Qt.TransformationMode.SmoothTransformation))
        layout.addWidget(lbl)
        dlg.resize(820, 820)
        dlg.exec()  # modal; user closes when done

    def _onThreadFinished(self):
        self._pending -= 1
        if self._pending == 0:
            self.hideSpinner()
            self._pushResultsToSlots(self._results)

    def _pushResultsToSlots(self, results):
        max_slots = self.image_manager.max_slots
        pushed = []
        # make sure we have a place to keep our preview dialogs alive
        if not hasattr(self, '_preview_dialogs'):
            self._preview_dialogs = {}

        for entry in results:
            filt = entry["filter"]
            img  = entry["image"]
            # ensure mono
            if img.ndim == 3 and img.shape[2] == 3:
                img = img[..., 0]  # take one channel for the preview
            for slot in range(max_slots):
                existing = self.image_manager._images.get(slot)
                if existing is None or (isinstance(existing, np.ndarray) and existing.size <= 100):
                    name = f"{filt}_ContSub"
                    meta = {
                        'file_path': name,
                        'is_mono': True,
                        'bit_depth': "32-bit floating point",
                        'source': name
                    }
                    # store and emit
                    self.image_manager._images[slot]   = img
                    self.image_manager._metadata[slot] = meta
                    self.image_manager.image_changed.emit(slot, img, meta)

                    # rename toolbar & menubar
                    mw = self.window()  # AstroEditingSuite
                    mw.slot_names[slot] = name
                    if slot in mw.slot_actions:
                        act = mw.slot_actions[slot]
                        act.setText(name)
                        act.setStatusTip(f"Open preview for {name}")
                    if slot in mw.menubar_slot_actions:
                        mact = mw.menubar_slot_actions[slot]
                        mact.setText(name)
                        mact.setStatusTip(f"Open preview for {name}")
                    mw.menuBar().update()

                    pushed.append(slot)
                    break
            if len(pushed) >= min(3, len(results)):
                break

        self.statusLabel.setText(f"Pushed {len(pushed)} images to slots.")

        # show non-modal previews and keep them alive
        for slot in pushed:
            img  = self.image_manager._images[slot]
            mono = self.image_manager._metadata[slot].get('is_mono', False)
            dlg  = ImagePreviewDialog(img, is_mono=mono)
            title = f"Slot {slot+1}: {mw.slot_names[slot]}"
            dlg.setWindowTitle(title)
            dlg.show()
            # store a reference so it doesn’t get garbage-collected
            self._preview_dialogs[slot] = dlg

        return pushed


    def update_status_label(self, message):
        self.statusLabel.setText(message)

    def showSpinner(self):
        self.spinnerLabel.show()
        self.spinnerMovie.start()

    def hideSpinner(self):
        self.spinnerLabel.hide()
        self.spinnerMovie.stop()



class ContinuumProcessingThread(QThread):
    processing_complete = pyqtSignal(np.ndarray, int, QImage, np.ndarray, np.ndarray)
    status_update = pyqtSignal(str)

    def __init__(self, nb_image, continuum_image, output_linear):
        super().__init__()
        self.nb_image = nb_image
        self.continuum_image = continuum_image
        self.output_linear = output_linear
        self.background_reference = None  # Store the background reference



    def run(self):
        # Ensure both images are mono
        if self.nb_image.ndim == 3 and self.nb_image.shape[2] == 3:
            self.nb_image = self.nb_image[..., 0]  # Take one channel for the NB image

        if self.continuum_image.ndim == 3 and self.continuum_image.shape[2] == 3:
            self.continuum_image = self.continuum_image[..., 0]  # Take one channel for the continuum image

        # Create RGB image
        r_combined = self.nb_image  # Use the normalized NB image as the Red channel
        g_combined = self.continuum_image # Use the normalized continuum image as the Green channel
        b_combined = self.continuum_image  # Use the normalized continuum image as the Blue channel


        # Stack the channels into a single RGB image
        combined_image = np.stack((r_combined, g_combined, b_combined), axis=-1)

        self.status_update.emit("Performing background neutralization...")
        QCoreApplication.processEvents()
            # Perform background neutralization
        self.background_neutralization(combined_image)

        # Normalize the red channel to the green channel
        combined_image[..., 0] = self.normalize_channel(combined_image[..., 0], combined_image[..., 1])

        self.status_update.emit("Performing star-based white balance…")
        balanced_rgb, star_count, star_overlay, raw_star_pixels, after_star_pixels = \
            apply_star_based_white_balance(
                combined_image,
                threshold=1.5,
                autostretch=False,
                reuse_cached_sources=True,
                return_star_colors=True
            )
        combined_image[:] = balanced_rgb   # replace working image with the white-balanced one
        
        self.status_update.emit(f"White balance complete ({star_count} stars).")
        QCoreApplication.processEvents()

        # Perform continuum subtraction
        linear_image = combined_image[..., 0] - 0.9*(combined_image[..., 1]-np.median(combined_image[..., 1]))

            # Check if the Output Linear checkbox is checked
        if self.output_linear:
            # Emit the linear image for preview
            self.processing_complete.emit(np.clip(linear_image, 0, 1))
            return  # Exit the method if we only want to output the linear image

        self.status_update.emit("Subtraction complete.")
        QCoreApplication.processEvents()

        # Perform statistical stretch
        target_median = 0.25
        stretched_image = stretch_color_image(linear_image, target_median, True, False)

        # Final image adjustment
        final_image = stretched_image - 0.7*np.median(stretched_image)

        # Clip the final image to stay within [0, 1]
        final_image = np.clip(final_image, 0, 1)

        # Applies Curves Boost
        final_image = apply_curves_adjustment(final_image, np.median(final_image), 0.5)

        self.status_update.emit("Linear to Non-Linear Stretch complete.")
        QCoreApplication.processEvents()

        overlay_uint8 = (star_overlay * 255).astype(np.uint8)
        h2, w2 = overlay_uint8.shape[:2]
        bytes_per_line = 3 * w2
        qimg = QImage(
            overlay_uint8.data, w2, h2, bytes_per_line,
            QImage.Format.Format_RGB888
        ).copy()
        # Emit the final image for preview
        self.processing_complete.emit(
            final_image,          # → np.ndarray
            star_count,           # → int
            qimg,                 # → QImage
            np.array(raw_star_pixels),   # → np.ndarray
            np.array(after_star_pixels)  # → np.ndarray
        )

    def background_neutralization(self, rgb_image):
        height, width, _ = rgb_image.shape
        num_boxes = 200
        box_size = 25
        iterations = 25

        boxes = [(np.random.randint(0, height - box_size), np.random.randint(0, width - box_size)) for _ in range(num_boxes)]
        best_means = np.full(num_boxes, np.inf)

        for _ in range(iterations):
            for i, (y, x) in enumerate(boxes):
                if y + box_size <= height and x + box_size <= width:
                    patch = rgb_image[y:y + box_size, x:x + box_size]
                    patch_median = np.median(patch) if patch.size > 0 else np.inf

                    if patch_median < best_means[i]:
                        best_means[i] = patch_median

                    surrounding_values = []
                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            surrounding_y = y + dy * box_size
                            surrounding_x = x + dx * box_size
                            
                            if (0 <= surrounding_y < height - box_size) and (0 <= surrounding_x < width - box_size):
                                surrounding_patch = rgb_image[surrounding_y:surrounding_y + box_size, surrounding_x:surrounding_x + box_size]
                                if surrounding_patch.size > 0:
                                    surrounding_values.append(np.median(surrounding_patch))

                    if surrounding_values:
                        dimmest_index = np.argmin(surrounding_values)
                        new_y = y + (dimmest_index // 3 - 1) * box_size
                        new_x = x + (dimmest_index % 3 - 1) * box_size
                        boxes[i] = (new_y, new_x)

        # After iterations, find the darkest box median
        darkest_value = np.inf
        background_box = None

        for box in boxes:
            y, x = box
            if y + box_size <= height and x + box_size <= width:
                patch = rgb_image[y:y + box_size, x:y + box_size]
                patch_median = np.median(patch) if patch.size > 0 else np.inf

                if patch_median < darkest_value:
                    darkest_value = patch_median
                    background_box = patch

        if background_box is not None:
            self.background_reference = np.median(background_box.reshape(-1, 3), axis=0)
            
            # Adjust the channels based on the median reference
            channel_medians = np.median(rgb_image, axis=(0, 1))

            # Adjust channels based on the red channel
            for channel in range(3):
                if self.background_reference[channel] < channel_medians[channel]:
                    pedestal = channel_medians[channel] - self.background_reference[channel]
                    rgb_image[..., channel] += pedestal

            # Specifically adjust G and B to match R
            r_median = self.background_reference[0]
            for channel in [1, 2]:  # Green and Blue channels
                if self.background_reference[channel] < r_median:
                    rgb_image[..., channel] += (r_median - self.background_reference[channel])

        self.status_update.emit("Background neutralization complete.")
        QCoreApplication.processEvents()
        return rgb_image
    
    def normalize_channel(self, image_channel, reference_channel):
        mad_image = np.mean(np.abs(image_channel - np.mean(image_channel)))
        mad_ref = np.mean(np.abs(reference_channel - np.mean(reference_channel)))

        median_image = np.median(image_channel)
        median_ref = np.median(reference_channel)

        # Apply the normalization formula
        normalized_channel = (
            image_channel * mad_ref / mad_image
            - (mad_ref / mad_image) * median_image
            + median_ref
        )

        self.status_update.emit("Color calibration complete.")
        QCoreApplication.processEvents()
        return np.clip(normalized_channel, 0, 1)  



    def continuum_subtraction(self, rgb_image):
        red_channel = rgb_image[..., 0]
        green_channel = rgb_image[..., 1]
        
        # Determine Q based on the selection (modify condition based on actual UI element)
        Q = 0.9 if self.output_linear else 1.0

        # Perform the continuum subtraction
        median_green = np.median(green_channel)
        result_image = red_channel - Q * (green_channel - median_green)
        
        return np.clip(result_image, 0, 1)  # Ensure values stay within [0, 1]


class ImageCombineTab(QWidget):
    def __init__(self, image_manager=None):
        super().__init__()
        self.image_manager = image_manager
        self.zoom_factor = 1.0
        self.current_pixmap = None

        if self.image_manager:
            # re-populate slot names whenever images change
            self.image_manager.image_changed.connect(lambda *a: self.populateSlots())

        self._pan_start = None
        self._hstart    = 0
        self._vstart    = 0
        self.initUI()        

    def initUI(self):
        layout = QVBoxLayout(self)

        # 1) Source selectors
        src_row = QHBoxLayout()
        src_row.addWidget(QLabel("Source A:"))
        self.srcA = QComboBox()
        src_row.addWidget(self.srcA)
        src_row.addWidget(QLabel("Source B:"))
        self.srcB = QComboBox()
        src_row.addWidget(self.srcB)
        layout.addLayout(src_row)

        # 2) Blend mode + opacity
        blend_row = QHBoxLayout()
        blend_row.addWidget(QLabel("Mode:"))
        self.blendMode = QComboBox()
        self.blendMode.addItems([
            "Average","Add","Subtract","Blend","Multiply","Divide",
            "Screen","Overlay","Difference"
        ])
        blend_row.addWidget(self.blendMode)
        blend_row.addWidget(QLabel("Opacity:"))
        self.opacity = QSlider(Qt.Orientation.Horizontal)
        self.opacity.setRange(0, 100)
        self.opacity.setValue(100)
        blend_row.addWidget(self.opacity)
        layout.addLayout(blend_row)

        # 3) Preview widget
        # 3) Preview in scroll area
        self.scrollArea = QScrollArea(self)
        self.scrollArea.setWidgetResizable(True)
        self.imageLabel = ImageLabel(self)            # or your ImagePreviewWidget
        self.imageLabel.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.scrollArea.setWidget(self.imageLabel)
        layout.addWidget(self.scrollArea, stretch=1)

        # 6) Zoom buttons
        zoom_row = QHBoxLayout()
        zoom_in_btn  = QPushButton("Zoom In ＋")
        zoom_out_btn = QPushButton("Zoom Out －")
        fit_btn      = QPushButton("⧉ Fit to Preview")
        zoom_in_btn.clicked.connect(self.zoom_in)
        zoom_out_btn.clicked.connect(self.zoom_out)
        fit_btn.clicked.connect(self.fit_to_preview)
        zoom_row.addWidget(zoom_out_btn)
        zoom_row.addWidget(fit_btn)
        zoom_row.addWidget(zoom_in_btn)
        layout.addLayout(zoom_row)

        # 5) Output & apply
        out_row = QHBoxLayout()
        out_row.addWidget(QLabel("Output →"))
        self.outSlot = QComboBox()
        out_row.addWidget(self.outSlot)
        self.applyBtn = QPushButton("Apply Combination")
        out_row.addWidget(self.applyBtn)
        layout.addLayout(out_row)

        # hookups
        self.srcA     .currentIndexChanged.connect(self.updatePreview)
        self.srcB     .currentIndexChanged.connect(self.updatePreview)
        self.blendMode.currentIndexChanged.connect(self.updatePreview)
        self.opacity  .valueChanged     .connect(self.updatePreview)

        self.applyBtn.clicked.connect(self.commitCombination)
        self.scrollArea.viewport().installEventFilter(self)

    def populateSlots(self):
        if not self.image_manager:
            return

        # block those currentIndexChanged -> updatePreview calls
        for cb in (self.srcA, self.srcB, self.outSlot):
            cb.blockSignals(True)
            cb.clear()

        main_win   = self.window()
        slot_names = getattr(main_win, "slot_names", {})

        for i in range(self.image_manager.max_slots):
            name = slot_names.get(i, f"Slot {i}")
            for cb in (self.srcA, self.srcB, self.outSlot):
                cb.addItem(name, userData=i)

        for cb in (self.srcA, self.srcB, self.outSlot):
            cb.blockSignals(False)

        # if this tab is visible, manually trigger a single update
        if self.isVisible():
            self.updatePreview()


    def refresh(self):
        """Called each time the tab becomes active."""
        self.populateSlots()
        # also re-draw the preview in case A/B/mode/opacity didn't change
        self.updatePreview()

    def updatePreview(self, *_):
        # bail out if we're not the current tab
        tabwidget = self.parent()  # should be the QTabWidget
        if hasattr(tabwidget, "currentWidget") and tabwidget.currentWidget() is not self:
            return

        idxA = self.srcA.currentData()
        idxB = self.srcB.currentData()
        if idxA is None or idxB is None:
            return

        imgA = self.image_manager.get_image_for_slot(idxA)
        imgB = self.image_manager.get_image_for_slot(idxB)
        if imgA is None or imgB is None:
            return

        A = imgA.astype(np.float32, copy=False)
        B = imgB.astype(np.float32, copy=False)
        alpha = self.opacity.value() / 100.0
        mode  = self.blendMode.currentText()


        # right after loading A and B...
        orig_ndim = A.ndim

        # if grayscale, make them H×W×1 so Numba will be happy
        if A.ndim == 2:
            A = A[..., None]
            B = B[..., None]

        # now you can safely do the Numba blend
        result = self.dispatch_blend(A, B, mode, alpha)

        # if you originally had a 2-D image, squeeze the channel back out
        if orig_ndim == 2:
            result = result[..., 0]

        blended = result
        # — Blend with mask if present —
        mask = self.get_active_mask()
        if mask is not None:
            h, w = blended.shape[:2]

            # expand 2D → 3D if needed
            if mask.ndim == 2:
                mask = mask[..., None]

            # check shape
            if mask.shape[0] != h or mask.shape[1] != w:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match image.")
                return

            # if it's single-channel but blended is 3-channel, replicate
            if blended.ndim == 3 and mask.shape[2] == 1:
                mask = np.repeat(mask, blended.shape[2], axis=2)

            # blend: inside mask use `blended`, outside use original A
            blended = blended * mask + A * (1.0 - mask)
            blended = np.clip(blended, 0.0, 1.0)

        # convert to 8-bit preview
        h, w = blended.shape[:2]
        arr8 = (blended*255).astype(np.uint8)
        if arr8.ndim == 2:
            qimg = QImage(arr8.data, w, h, w, QImage.Format.Format_Grayscale8)
        else:
            qimg = QImage(arr8.data, w, h, 3*w, QImage.Format.Format_RGB888)

        pix = QPixmap.fromImage(qimg)
        # store for zoom/pan, then just reapply the current zoom
        self.current_pixmap = pix
        self.apply_zoom()

    def apply_zoom(self):
        """Scale the stored pixmap by zoom_factor and set on the label."""
        if self.current_pixmap is None:
            return
        scaled = self.current_pixmap.scaled(
            self.current_pixmap.size() * self.zoom_factor,
            Qt.AspectRatioMode.KeepAspectRatio,
            Qt.TransformationMode.SmoothTransformation
        )
        self.imageLabel.setPixmap(scaled)

    @announce_zoom
    def zoom_in(self):
        self.zoom_factor *= 1.25
        self.apply_zoom()

    @announce_zoom
    def zoom_out(self):
        self.zoom_factor /= 1.25
        self.apply_zoom()


    def eventFilter(self, source, event):
        # only intercept on the scrollArea’s viewport
        if source is self.scrollArea.viewport():
            # mouse-down: start panning
            if (event.type() == QEvent.Type.MouseButtonPress
                    and event.button() == Qt.MouseButton.LeftButton):
                self._pan_start = event.pos()
                self._hstart   = self.scrollArea.horizontalScrollBar().value()
                self._vstart   = self.scrollArea.verticalScrollBar().value()
                return True

            # mouse-move: drag
            elif (event.type() == QEvent.Type.MouseMove
                  and self._pan_start is not None):
                delta = event.pos() - self._pan_start
                self.scrollArea.horizontalScrollBar().setValue(self._hstart - delta.x())
                self.scrollArea.verticalScrollBar().setValue(self._vstart - delta.y())
                return True

            # mouse-up: stop panning
            elif (event.type() == QEvent.Type.MouseButtonRelease
                  and event.button() == Qt.MouseButton.LeftButton):
                self._pan_start = None
                return True

            # any other event on this source: explicitly don’t handle
            return False

        # for everything else, fallback to default
        return super().eventFilter(source, event)

    def fit_to_preview(self):
        """Reset zoom so the image fits the available viewport."""
        if self.current_pixmap is None:
            return
        area = self.scrollArea.viewport().size()
        pix = self.current_pixmap.size()
        # choose the smaller scale factor that fits both dims
        sx = area.width()  / pix.width()
        sy = area.height() / pix.height()
        self.zoom_factor = min(sx, sy, 1.0)
        self.apply_zoom()

    def get_active_mask(self):
        """
        Retrieves the currently applied mask from MaskManager, normalized to [0..1].
        Returns None if no mask is applied.
        """
        if not (self.image_manager and self.image_manager.mask_manager):
            return None

        mask = self.image_manager.mask_manager.get_applied_mask()
        if mask is None:
            return None

        # normalize to float [0..1]
        if mask.dtype not in (np.float32, np.float64):
            mask = mask.astype(np.float32) / 255.0
        return mask

    def commitCombination(self):
        """Run the exact same blend (full-res, njit) and shove into outSlot."""
        idxA   = self.srcA.currentData()
        idxB   = self.srcB.currentData()
        outIdx = self.outSlot.currentData()
        if None in (idxA, idxB, outIdx):
            return

        # 1) fetch & prepare
        A     = self.image_manager.get_image_for_slot(idxA).astype(np.float32, copy=False)
        B     = self.image_manager.get_image_for_slot(idxB).astype(np.float32, copy=False)
        alpha = self.opacity.value() / 100.0
        mode  = self.blendMode.currentText()

        # right after loading A and B...
        orig_ndim = A.ndim

        # if grayscale, make them H×W×1 so Numba will be happy
        if A.ndim == 2:
            A = A[..., None]
            B = B[..., None]

        # now you can safely do the Numba blend
        result = self.dispatch_blend(A, B, mode, alpha)

        # if you originally had a 2-D image, squeeze the channel back out
        if orig_ndim == 2:
            result = result[..., 0]

        blended = result

        # 3) mask post-processing
        mask = self.get_active_mask()
        if mask is not None:
            m = mask.astype(np.float32)
            # normalize
            if m.max() > 1.0:
                m /= 255.0
            # make it (H,W,1) if needed
            if m.ndim == 2:
                m = m[..., None]
            # broadcast to all channels
            if result.ndim == 3 and m.shape[2] == 1:
                m = np.repeat(m, result.shape[2], axis=2)
            # shape check
            if m.shape[:2] != result.shape[:2]:
                QMessageBox.critical(self, "Error", "Mask dimensions do not match image.")
                return
            # inside mask = blended, outside = original A
            result = result * m + A * (1.0 - m)
            result = np.clip(result, 0.0, 1.0)

        # 4) build metadata
        meta = {
            'file_path': f"Combined_{mode}",
            'is_mono':   (result.ndim == 2),
            'bit_depth': "32-bit floating point",
            'source':    f"Combine: {mode}"
        }

        # 5) store into slot (emits image_changed)
        self.image_manager.set_image_for_slot(outIdx, result, meta)

        # 6) rename that slot in the UI, just like ContinuumSubtract
        mw   = self.window()  # AstroEditingSuite
        name = f"{mode} Combine"
        mw.slot_names[outIdx] = name

        # toolbar
        if outIdx in mw.slot_actions:
            btn = mw.slot_actions[outIdx]
            btn.setText(name)
            btn.setStatusTip(f"Open preview for {name}")

        # menubar
        if outIdx in mw.menubar_slot_actions:
            act = mw.menubar_slot_actions[outIdx]
            act.setText(name)
            act.setStatusTip(f"Open preview for {name}")

        mw.menuBar().update()

        print(f"Combined → slot {outIdx+1}: {name}")


    def dispatch_blend(self, A, B, mode, alpha):
        """
        Blend two float32 images A and B according to the selected mode.
        'Average'    : simple (A + B) / 2
        'Blend'      : standard alpha blend A*(1−alpha) + B*alpha
        other modes  : various NumPy/Numba-accelerated operations
        """
        # Average mode: ignore the alpha slider
        if mode == "Average":
            out = (A + B) * 0.5
            return np.clip(out, 0.0, 1.0)

        # Blend mode: use the alpha slider
        if mode == "Blend":
            out = A * (1.0 - alpha) + B * alpha
            return np.clip(out, 0.0, 1.0)

        # All the existing specialized modescha
        if   mode == "Add":        return blend_add_numba(A, B, alpha)
        elif mode == "Subtract":   return blend_subtract_numba(A, B, alpha)
        elif mode == "Multiply":   return blend_multiply_numba(A, B, alpha)
        elif mode == "Divide":     return blend_divide_numba(A, B, alpha)
        elif mode == "Screen":     return blend_screen_numba(A, B, alpha)
        elif mode == "Overlay":    return blend_overlay_numba(A, B, alpha)
        elif mode == "Difference": return blend_difference_numba(A, B, alpha)

        # Fallback: simple add-blend
        out = A * (1.0 - alpha) + B * alpha
        return np.clip(out, 0.0, 1.0)

def preprocess_narrowband_image(image):
    """
    Preprocess narrowband images to ensure they are single-channel.
    If the image is detected as a mono image stored in 3-channel format, the red channel is used.
    """
    if image is not None:
        if image.ndim == 3:
            if image.shape[2] == 3:
                # Use the red channel if the image is multi-channel
                print("Detected multi-channel RGB data. Using the red channel as mono.")
                image = image[..., 0]
            elif image.shape[2] == 1:
                # Squeeze single redundant channel
                print("Detected 1-channel image with extra dimension. Squeezing to single channel.")
                image = np.squeeze(image, axis=-1)
        elif image.ndim != 2:
            raise ValueError(f"Unexpected image shape: {image.shape}")
    return image



def apply_standard_white_balance(image: np.ndarray, r_gain: float = 1.0, g_gain: float = 1.0, b_gain: float = 1.0) -> np.ndarray:
    """
    Applies standard white balance by adjusting the gain of each color channel.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        r_gain (float): Gain for the Red channel.
        g_gain (float): Gain for the Green channel.
        b_gain (float): Gain for the Blue channel.

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    balanced = image.copy()
    balanced[:, :, 0] *= r_gain
    balanced[:, :, 1] *= g_gain
    balanced[:, :, 2] *= b_gain
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

def apply_auto_white_balance(image: np.ndarray) -> np.ndarray:
    """
    Applies automatic white balance using the Gray World Assumption.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].

    Returns:
        np.ndarray: White-balanced RGB image.
    """
    # Calculate the mean of each channel
    mean_r = np.mean(image[:, :, 0])
    mean_g = np.mean(image[:, :, 1])
    mean_b = np.mean(image[:, :, 2])
    
    # Calculate the overall mean
    mean_all = (mean_r + mean_g + mean_b) / 3
    
    # Calculate gains
    gain_r = mean_all / mean_r if mean_r != 0 else 1.0
    gain_g = mean_all / mean_g if mean_g != 0 else 1.0
    gain_b = mean_all / mean_b if mean_b != 0 else 1.0
    
    # Apply gains
    balanced = image.copy()
    balanced[:, :, 0] *= gain_r
    balanced[:, :, 1] *= gain_g
    balanced[:, :, 2] *= gain_b
    balanced = np.clip(balanced, 0.0, 1.0)
    return balanced

cached_star_sources = None
cached_flux_radii = None


def plot_star_color_ratios_comparison(raw_pixels: np.ndarray, after_pixels: np.ndarray):


    def compute_ratios(pixels):
        rb = pixels[:, 0] / (pixels[:, 2] + 1e-8)
        gb = pixels[:, 1] / (pixels[:, 2] + 1e-8)
        return rb, gb

    rb_before, gb_before = compute_ratios(raw_pixels)
    rb_after, gb_after = compute_ratios(after_pixels)

    # Define plot bounds
    rmin, rmax = 0.5, 2.0
    gmin, gmax = 0.5, 2.0
    res = 200  # resolution of the background grid

    # Create background color grid
    rb_vals = np.linspace(rmin, rmax, res)
    gb_vals = np.linspace(gmin, gmax, res)
    rb_grid, gb_grid = np.meshgrid(rb_vals, gb_vals)

    rgb_image = np.stack([rb_grid, gb_grid, np.ones_like(rb_grid)], axis=-1)
    rgb_image /= np.max(rgb_image, axis=2, keepdims=True)  # Normalize to [0,1]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)

    def plot_panel(ax, rb_data, gb_data, title):
        ax.imshow(rgb_image, extent=(rmin, rmax, gmin, gmax), origin='lower', aspect='auto')

        ax.scatter(rb_data, gb_data, alpha=0.6, edgecolors='k', label="Stars")

        # Fit best line
        m, b = np.polyfit(rb_data, gb_data, 1)
        x_vals = np.linspace(rmin, rmax, 100)
        ax.plot(x_vals, m * x_vals + b, 'r--', label=f"Best Fit\ny = {m:.2f}x + {b:.2f}")

        # Neutral indicators
        ax.axhline(1.0, color='gray', linestyle=':', linewidth=1)
        ax.axvline(1.0, color='gray', linestyle=':', linewidth=1)
        ax.add_patch(Circle((1.0, 1.0), 0.2, fill=False, edgecolor='blue', linestyle='--', linewidth=1.5))
        ax.text(1.03, 1.17, "Neutral Region", color='blue', fontsize=9)

        ax.set_xlim(rmin, rmax)
        ax.set_ylim(gmin, gmax)
        ax.set_title(f"{title} White Balance")
        ax.set_xlabel("Red / Blue Ratio")
        ax.set_ylabel("Green / Blue Ratio")
        ax.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax.yaxis.set_major_locator(MaxNLocator(integer=True))
        ax.grid(True)
        ax.legend()

    plot_panel(ax1, rb_before, gb_before, "Before")
    plot_panel(ax2, rb_after, gb_after, "After")

    plt.suptitle("Star Color Ratios with RGB Mapping", fontsize=14)
    plt.tight_layout()
    plt.show()


def apply_star_based_white_balance(
    image: np.ndarray,
    threshold: float = 1.5,
    autostretch: bool = True,
    reuse_cached_sources: bool = False,
    return_star_colors: bool = False
) -> tuple:
    global cached_star_sources, cached_flux_radii

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("Input must be an RGB image.")

    # Step 1: Neutralize background using darkest patch
    patch_size = 10
    h, w = image.shape[:2]
    patch_h = h // patch_size
    patch_w = w // patch_size

    min_median_sum = float("inf")
    best_patch = None

    for i in range(patch_size):
        for j in range(patch_size):
            y0 = i * patch_h
            x0 = j * patch_w
            y1 = min(y0 + patch_h, h)
            x1 = min(x0 + patch_w, w)

            patch = image[y0:y1, x0:x1, :]
            medians = np.median(patch, axis=(0, 1))
            if np.sum(medians) < min_median_sum:
                min_median_sum = np.sum(medians)
                best_patch = medians

    if best_patch is None:
        raise RuntimeError("Failed to find a neutral background patch.")

    avg_median = np.mean(best_patch)

    # Apply tone-preserving background neutralization (first pass)
    bg_neutralized = image.copy()
    for c in range(3):
        diff = best_patch[c] - avg_median
        denom = 1.0 - diff if abs(1.0 - diff) > 1e-8 else 1e-8
        bg_neutralized[:, :, c] = np.clip((bg_neutralized[:, :, c] - diff) / denom, 0.0, 1.0)

    # Step 2: Detect or reuse star positions
    # 2) Detect or reuse star positions
    gray_neutral = np.mean(bg_neutralized, axis=2).astype(np.float32)
    bkg2        = sep.Background(gray_neutral)
    data_sub    = gray_neutral - bkg2.back()
    err_val     = bkg2.globalrms

    sources, r = None, None
    if reuse_cached_sources and cached_star_sources is not None:
        sources = cached_star_sources
        r       = cached_flux_radii
    else:
        sources = sep.extract(data_sub, threshold, err=err_val)
        if len(sources) == 0:
            raise ValueError("No stars detected for Star-Based White Balance.")
        r, _ = sep.flux_radius(
            gray_neutral,
            sources['x'], sources['y'],
            2.0 * sources['a'], 0.2,
            normflux=sources['flux'],
            subpix=5
        )
        cached_star_sources  = sources
        cached_flux_radii    = r

    # → throw away anything too big to be a star:
    mask    = (r > 0) & (r <= 10)
    sources = sources[mask]
    r       = r[mask]

    if len(sources) == 0:
        raise ValueError("All detected sources were too large; no valid stars for White Balance.")


    # NEW: Sample star colors from original image (before any adjustments)
    raw_star_pixels = []
    for i in range(len(sources)):
        x = int(sources['x'][i])
        y = int(sources['y'][i])
        if r[i] > 0 and 0 <= y < h and 0 <= x < w:
            raw_star_pixels.append(image[y, x, :])  # use original image here

    # Step 3: Create preview with ellipses
    display_image = stretch_color_image(bg_neutralized.copy(), 0.25) if autostretch else bg_neutralized.copy()
    image_with_stars = cv2.cvtColor((display_image * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

    star_pixels = []
    for i in range(len(sources)):
        x = sources['x'][i]
        y = sources['y'][i]
        a = sources['a'][i]
        b = sources['b'][i]
        theta = sources['theta'][i] * 180. / np.pi

        if r[i] > 0 and 0 <= int(y) < h and 0 <= int(x) < w:
            star_pixels.append(bg_neutralized[int(y), int(x), :])
            center = (int(x), int(y))
            axes = (int(3 * a), int(3 * b))
            cv2.ellipse(image_with_stars, center, axes, angle=theta, startAngle=0, endAngle=360,
                        color=(0, 0, 255), thickness=1)

    star_count = len(star_pixels)
    if star_count == 0:
        raise ValueError("No stars passed filtering for white balance.")

    # Step 4: White balance using brightest average channel
    star_pixels = np.array(star_pixels)
    avg_color = np.mean(star_pixels, axis=0)
    max_val = np.max(avg_color)
    scaling_factors = max_val / avg_color

    balanced = bg_neutralized.copy()
    for ch in range(3):
        balanced[:, :, ch] *= scaling_factors[ch]
    balanced = np.clip(balanced, 0.0, 1.0)

    # Step 5: Final background neutralization using updated image
    patch_size = 10
    h, w = balanced.shape[:2]
    patch_h = h // patch_size
    patch_w = w // patch_size

    min_median_sum = float("inf")
    best_patch = None

    for i in range(patch_size):
        for j in range(patch_size):
            y0 = i * patch_h
            x0 = j * patch_w
            y1 = min(y0 + patch_h, h)
            x1 = min(x0 + patch_w, w)

            patch = balanced[y0:y1, x0:x1, :]
            medians = np.median(patch, axis=(0, 1))
            if np.sum(medians) < min_median_sum:
                min_median_sum = np.sum(medians)
                best_patch = medians

    if best_patch is not None:
        avg_median = np.mean(best_patch)
        for c in range(3):
            diff = best_patch[c] - avg_median
            denom = 1.0 - diff if abs(1.0 - diff) > 1e-8 else 1e-8
            balanced[:, :, c] = np.clip((balanced[:, :, c] - diff) / denom, 0.0, 1.0)

  # Step 6: Collect "after" star pixels from balanced image            
    after_star_pixels = []
    for i in range(len(sources)):
        x = int(sources['x'][i])
        y = int(sources['y'][i])
        if r[i] > 0 and 0 <= y < h and 0 <= x < w:
            after_star_pixels.append(balanced[y, x, :])

    if return_star_colors:
        return balanced, star_count, image_with_stars, np.array(raw_star_pixels), np.array(after_star_pixels)
    return balanced, star_count, image_with_stars

def apply_morphology(image: np.ndarray, operation: str = 'erosion', kernel_size: int = 3, iterations: int = 1) -> np.ndarray:
    """
    Applies a morphological operation to the image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        operation (str): Morphological operation ('erosion', 'dilation', 'opening', 'closing').
        kernel_size (int): Size of the structuring element.
        iterations (int): Number of times the operation is applied.

    Returns:
        np.ndarray: Morphologically processed RGB image.
    """
    # Define the structuring element
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))

    # Convert image to uint8
    image_uint8 = (image * 255).astype(np.uint8)

    # Apply the selected operation
    if operation == 'erosion':
        processed = cv2.erode(image_uint8, kernel, iterations=iterations)
    elif operation == 'dilation':
        processed = cv2.dilate(image_uint8, kernel, iterations=iterations)
    elif operation == 'opening':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif operation == 'closing':
        processed = cv2.morphologyEx(image_uint8, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    else:
        raise ValueError("Unsupported morphological operation.")

    # Convert back to float [0,1]
    processed_image = processed.astype(np.float32) / 255.0
    return processed_image

def apply_clahe(image: np.ndarray, clip_limit: float = 2.0, tile_grid_size: tuple = (8, 8)) -> np.ndarray:
    """
    Applies CLAHE to the image for adaptive contrast enhancement.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array normalized to [0,1].
        clip_limit (float): Threshold for contrast limiting.
        tile_grid_size (tuple): Size of grid for histogram equalization.

    Returns:
        np.ndarray: Contrast-enhanced RGB image.
    """
    if image.ndim == 2:
        # Grayscale image
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        enhanced = clahe.apply((image * 255).astype(np.uint8))
        return enhanced / 255.0
    elif image.ndim == 3 and image.shape[2] == 3:
        # Convert to LAB color space
        lab = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2LAB)
        # Split the channels
        l, a, b = cv2.split(lab)
        # Apply CLAHE to the L-channel
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
        cl = clahe.apply(l)
        # Merge the channels back
        limg = cv2.merge((cl, a, b))
        # Convert back to RGB
        enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB) / 255.0
        return enhanced
    else:
        raise ValueError("Input image must be either grayscale or RGB.")

def apply_average_neutral_scnr(image: np.ndarray, amount: float = 1.0) -> np.ndarray:
    """
    Applies the Average Neutral SCNR method to remove green noise from an RGB image.

    Parameters:
        image (np.ndarray): Input RGB image as a NumPy array with shape (H, W, 3).
                            The image should be normalized to the [0, 1] range.
        amount (float): Blending factor between the original and SCNR-processed image.
                        0.0 returns the original image, 1.0 returns the fully SCNR-processed image.

    Returns:
        np.ndarray: The SCNR-processed RGB image.
    """
    if not isinstance(image, np.ndarray):
        raise TypeError("Input image must be a NumPy array.")

    if image.ndim != 3 or image.shape[2] != 3:
        print(f"apply_average_neutral_scnr received invalid image shape: {image.shape}")
        raise ValueError("Input image must have three channels (RGB).")

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("Input image must have three channels (RGB).")

    if not (0.0 <= amount <= 1.0):
        raise ValueError("Amount parameter must be between 0.0 and 1.0.")

    # Ensure the image is in float format
    image = image.astype(np.float32)

    # Separate the channels
    R, G, B = image[..., 0], image[..., 1], image[..., 2]

    # Apply the Average Neutral SCNR formula: G' = min(G, 0.5*(R + B))
    G_scnr = np.minimum(G, 0.5 * (R + B))

    # Create the SCNR image
    scnr_image = image.copy()
    scnr_image[..., 1] = G_scnr  # Replace the green channel

    # Blend the original and SCNR images based on the amount parameter
    final_image = (1.0 - amount) * image + amount * scnr_image

    # Ensure the final image is still within [0, 1]
    final_image = np.clip(final_image, 0.0, 1.0)

    return final_image


def load_image(filename, max_retries=3, wait_seconds=3):
    """
    Loads an image from the specified filename with support for various formats.
    If a "buffer is too small for requested array" error occurs, it retries loading after waiting.

    Parameters:
        filename (str): Path to the image file.
        max_retries (int): Number of times to retry on specific buffer error.
        wait_seconds (int): Seconds to wait before retrying.

    Returns:
        tuple: (image, original_header, bit_depth, is_mono) or (None, None, None, None) on failure.
    """
    attempt = 0
    while attempt <= max_retries:
        try:
            image = None  # Ensure 'image' is explicitly declared
            bit_depth = None
            is_mono = False
            original_header = None

            # --- Unified FITS handling ---
            if filename.lower().endswith(('.fits', '.fit', '.fits.gz', '.fit.gz', '.fz', '.fz')):
                # Use get_valid_header to retrieve the header and extension index.
                original_header, ext_index = get_valid_header(filename)

                
                # Open the file appropriately.
                if filename.lower().endswith(('.fits.gz', '.fit.gz')):
                    print(f"Loading compressed FITS file: {filename}")
                    with gzip.open(filename, 'rb') as f:
                        file_content = f.read()
                    hdul = fits.open(BytesIO(file_content))
                else:
                    if filename.lower().endswith(('.fz', '.fz')):
                        print(f"Loading Rice-compressed FITS file: {filename}")
                    else:
                        print(f"Loading FITS file: {filename}")
                    hdul = fits.open(filename)

                with hdul as hdul:
                    # Retrieve image data from the extension indicated by get_valid_header.
                    image_data = hdul[ext_index].data
                    if image_data is None:
                        raise ValueError(f"No image data found in FITS file in extension {ext_index}.")

                    # Ensure native byte order
                    if image_data.dtype.byteorder not in ('=', '|'):
                        image_data = image_data.astype(image_data.dtype.newbyteorder('='))

                    # ---------------------------------------------------------------------
                    # 1) Detect bit depth and convert to float32
                    # ---------------------------------------------------------------------
                    if image_data.dtype == np.uint8:
                        bit_depth = "8-bit"
                        print("Identified 8-bit FITS image.")
                        image = image_data.astype(np.float32) / 255.0

                    elif image_data.dtype == np.uint16:
                        bit_depth = "16-bit"
                        print("Identified 16-bit FITS image.")
                        image = image_data.astype(np.float32) / 65535.0

                    elif image_data.dtype == np.int32:
                        bit_depth = "32-bit signed"
                        print("Identified 32-bit signed FITS image.")
                        bzero  = original_header.get('BZERO', 0)
                        bscale = original_header.get('BSCALE', 1)
                        image = image_data.astype(np.float32) * bscale + bzero

                    elif image_data.dtype == np.uint32:
                        bit_depth = "32-bit unsigned"
                        print("Identified 32-bit unsigned FITS image.")
                        bzero  = original_header.get('BZERO', 0)
                        bscale = original_header.get('BSCALE', 1)
                        image = image_data.astype(np.float32) * bscale + bzero

                    elif image_data.dtype == np.float32:
                        bit_depth = "32-bit floating point"
                        print("Identified 32-bit floating point FITS image.")
                        image = image_data
                    else:
                        raise ValueError(f"Unsupported FITS data type: {image_data.dtype}")

                    # ---------------------------------------------------------------------
                    # 2) Squeeze out any singleton dimensions (fix weird NAXIS combos)
                    # ---------------------------------------------------------------------
                    image = np.squeeze(image)

                    if image.dtype == np.float32:
                        max_val = image.max()
                        if max_val > 1.0:
                            print(f"Detected float image with max value {max_val:.3f} > 1.0; rescales to [0,1]")
                            image = image / max_val
                    # ---------------------------------------------------------------------
                    # 3) Interpret final shape to decide if mono or color
                    # ---------------------------------------------------------------------
                    if image.ndim == 2:
                        is_mono = True
                    elif image.ndim == 3:
                        if image.shape[0] == 3 and image.shape[1] > 1 and image.shape[2] > 1:
                            image = np.transpose(image, (1, 2, 0))
                            is_mono = False
                        elif image.shape[-1] == 3:
                            is_mono = False
                        else:
                            raise ValueError(f"Unsupported 3D shape after squeeze: {image.shape}")
                    else:
                        raise ValueError(f"Unsupported FITS dimensions after squeeze: {image.shape}")

                    print(f"Loaded FITS image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
                    return image, original_header, bit_depth, is_mono



            elif filename.lower().endswith(('.tiff', '.tif')):
                print(f"Loading TIFF file: {filename}")
                image_data = tiff.imread(filename)
                print(f"Loaded TIFF image with dtype: {image_data.dtype}")

                # Determine bit depth and normalize
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    image = image_data.astype(np.float32) / 255.0
                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    image = image_data.astype(np.float32) / 65535.0
                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    image = image_data.astype(np.float32) / 4294967295.0
                elif image_data.dtype == np.float32:
                    bit_depth = "32-bit floating point"
                    image = image_data
                else:
                    raise ValueError("Unsupported TIFF format!")

                if image.dtype == np.float32:
                    max_val = image.max()
                    if max_val > 1.0:
                        print(f"Detected float image with max value {max_val:.3f} > 1.0; rescales to [0,1]")
                        image = image / max_val

                # Handle mono or RGB TIFFs
                if image_data.ndim == 2:  # Mono
                    is_mono = True
                elif image_data.ndim == 3 and image_data.shape[2] == 3:  # RGB
                    is_mono = False
                else:
                    raise ValueError("Unsupported TIFF image dimensions!")

            elif filename.lower().endswith('.xisf'):
                print(f"Loading XISF file: {filename}")
                xisf = XISF(filename)

                # Read image data (assuming the first image in the XISF file)
                image_data = xisf.read_image(0)  # Adjust the index if multiple images are present

                # Retrieve metadata
                image_meta = xisf.get_images_metadata()[0]  # Assuming single image
                file_meta = xisf.get_file_metadata()


                # Here we check the maximum pixel value to determine bit depth
                # --- Detect the bit depth by dtype ---
                if image_data.dtype == np.uint8:
                    bit_depth = "8-bit"
                    print("Debug: Detected 8-bit dtype. Normalizing by 255.")
                    image = image_data.astype(np.float32) / 255.0

                elif image_data.dtype == np.uint16:
                    bit_depth = "16-bit"
                    print("Debug: Detected 16-bit dtype. Normalizing by 65535.")
                    image = image_data.astype(np.float32) / 65535.0

                elif image_data.dtype == np.uint32:
                    bit_depth = "32-bit unsigned"
                    print("Debug: Detected 32-bit unsigned dtype. Normalizing by 4294967295.")
                    image = image_data.astype(np.float32) / 4294967295.0

                elif image_data.dtype == np.float32 or image_data.dtype == np.float64:
                    bit_depth = "32-bit floating point"
                    print("Debug: Detected float dtype. Casting to float32 (no normalization).")
                    image = image_data.astype(np.float32)

                else:
                    raise ValueError(f"Unsupported XISF data type: {image_data.dtype}")

                # Handle mono or RGB XISF
                if image_data.ndim == 2:
                    # We know it's mono. Already normalized in `image`.
                    is_mono = True
                    # If you really want to store it in an RGB shape:
                    #image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 1:
                    # It's mono with shape (H, W, 1)
                    is_mono = True
                    # Squeeze the normalized image, not the original image_data
                    image = np.squeeze(image, axis=2)
                    # If you want an RGB shape, you can do:
                    #image = np.stack([image] * 3, axis=-1)

                elif image_data.ndim == 3 and image_data.shape[2] == 3:
                    is_mono = False
                    # We already stored the normalized float32 data in `image`.
                    # So no change needed if it’s already shape (H, W, 3).

                else:
                    raise ValueError("Unsupported XISF image dimensions!")

                # ─── Build FITS header from PixInsight XISFProperties ─────────────────
                # ─── Build FITS header from XISFProperties, then fallback to FITSKeywords & Pixel‐Scale ─────────────────
                props = image_meta.get('XISFProperties', {})
                hdr   = fits.Header()
                _filled = set()

                # 1) PixInsight astrometric solution
                try:
                    im0, im1 = props['PCL:AstrometricSolution:ReferenceImageCoordinates']['value']
                    w0,  w1  = props['PCL:AstrometricSolution:ReferenceCelestialCoordinates']['value']
                    hdr['CRPIX1'], hdr['CRPIX2'] = float(im0), float(im1)
                    hdr['CRVAL1'], hdr['CRVAL2'] = float(w0), float(w1)
                    hdr['CTYPE1'], hdr['CTYPE2'] = 'RA---TAN-SIP','DEC--TAN-SIP'
                    _filled |= {'CRPIX1','CRPIX2','CRVAL1','CRVAL2','CTYPE1','CTYPE2'}
                    print("🔷 Injected CRPIX/CRVAL from XISFProperties")
                except KeyError:
                    print("⚠️ Missing reference coords in XISFProperties")

                # 2) CD matrix
                try:
                    lin = np.asarray(props['PCL:AstrometricSolution:LinearTransformationMatrix']['value'], float)
                    hdr['CD1_1'], hdr['CD1_2'] = lin[0,0], lin[0,1]
                    hdr['CD2_1'], hdr['CD2_2'] = lin[1,0], lin[1,1]
                    _filled |= {'CD1_1','CD1_2','CD2_1','CD2_2'}
                    print("🔷 Injected CD matrix from XISFProperties")
                except KeyError:
                    print("⚠️ Missing CD matrix in XISFProperties")

                # 3) SIP polynomial fitting
                try:
                    gx = np.array(props['PCL:AstrometricSolution:SplineWorldTransformation:'
                                        'PointGridInterpolation:ImageToNative:GridX']['value'], dtype=float)
                    gy = np.array(props['PCL:AstrometricSolution:SplineWorldTransformation:'
                                        'PointGridInterpolation:ImageToNative:GridY']['value'], dtype=float)
                    grid = np.stack([gx, gy], axis=-1)
                    crpix = (hdr['CRPIX1'], hdr['CRPIX2'])
                    def fit_sip(grid, cr, order):
                        rows, cols, _ = grid.shape
                        u = np.repeat(np.arange(cols), rows) - cr[0]
                        v = np.tile(np.arange(rows), cols)   - cr[1]
                        dx = grid[:,:,0].ravel(); dy = grid[:,:,1].ravel()
                        terms = [(i,j) for i in range(order+1) for j in range(order+1-i) if (i,j)!=(0,0)]
                        M = np.vstack([(u**i)*(v**j) for (i,j) in terms]).T
                        a, *_ = np.linalg.lstsq(M, dx, rcond=None)
                        b, *_ = np.linalg.lstsq(M, dy, rcond=None)
                        rms = np.hypot(dx - M.dot(a), dy - M.dot(b)).std()
                        return a, b, terms, rms

                    best = {'order':None, 'rms':np.inf}
                    for order in range(2,7):
                        a, b, terms, rms = fit_sip(grid, crpix, order)
                        if rms < best['rms']:
                            best.update(order=order, a=a, b=b, terms=terms, rms=rms)
                    o = best['order']
                    hdr['A_ORDER'] = o; hdr['B_ORDER'] = o
                    _filled |= {'A_ORDER','B_ORDER'}
                    for (i,j), coef in zip(best['terms'], best['a']):
                        hdr[f'A_{i}_{j}'] = float(coef)
                        _filled.add(f'A_{i}_{j}')
                    for (i,j), coef in zip(best['terms'], best['b']):
                        hdr[f'B_{i}_{j}'] = float(coef)
                        _filled.add(f'B_{i}_{j}')
                    print(f"🔷 Injected SIP order {o}")
                except KeyError:
                    print("⚠️ No SIP grid in XISFProperties; skipping SIP")

                # Helper: look in FITSKeywords dicts
                def _lookup_kw(key):
                    for meta in (image_meta, file_meta):
                        fk = meta.get('FITSKeywords',{})
                        if key in fk and fk[key]:
                            return fk[key][0]['value']
                    return None

                # 4) Fallback WCS/CD from FITSKeywords
                for key in ('CRPIX1','CRPIX2','CRVAL1','CRVAL2','CTYPE1','CTYPE2',
                            'CD1_1','CD1_2','CD2_1','CD2_2'):
                    if key not in hdr:
                        v = _lookup_kw(key)
                        if v is not None:
                            hdr[key] = v
                            _filled.add(key)
                            print(f"🔷 Injected {key} from FITSKeywords")

                # 5) Generic RA/DEC fallback
                if 'CRVAL1' not in hdr or 'CRVAL2' not in hdr:
                    for ra_kw, dec_kw in (('RA','DEC'),('OBJCTRA','OBJCTDEC')):
                        ra = _lookup_kw(ra_kw); dec = _lookup_kw(dec_kw)
                        if ra and dec:
                            try:
                                ra_deg = float(ra); dec_deg = float(dec)
                            except ValueError:
                                from astropy.coordinates import Angle
                                ra_deg  = Angle(str(ra), unit='hourangle').degree
                                dec_deg = Angle(str(dec), unit='deg').degree
                            hdr['CRVAL1'], hdr['CRVAL2'] = ra_deg, dec_deg
                            hdr.setdefault('CTYPE1','RA---TAN'); hdr.setdefault('CTYPE2','DEC--TAN')
                            print(f"🔷 Fallback CRVAL from {ra_kw}/{dec_kw}")
                            break

                # 6) Pixel‐scale fallback → inject CDELT if no CD or CDELT
                if not any(k in hdr for k in ('CD1_1','CDELT1')):
                    pix_arcsec = None
                    for kw in ('PIXSCALE','SCALE'):
                        val = _lookup_kw(kw)
                        if val:
                            pix_arcsec = float(val); break
                    if pix_arcsec is None:
                        xpsz = _lookup_kw('XPIXSZ'); foc = _lookup_kw('FOCALLEN')
                        if xpsz and foc:
                            pix_arcsec = float(xpsz)*1e-3/float(foc)*206265
                    if pix_arcsec:
                        degpix = pix_arcsec / 3600.0
                        hdr['CDELT1'], hdr['CDELT2'] = -degpix, degpix
                        print(f"🔷 Injected pixel scale {pix_arcsec:.3f}\"/px → CDELT={degpix:.6f}°")

                # 7) Copy any remaining simple FITSKeywords
                for kw, vals in file_meta.get('FITSKeywords',{}).items():
                    if kw in hdr: continue
                    v = vals[0].get('value')
                    if isinstance(v, (int,float,str)):
                        hdr[kw] = v

                # 8) Binning
                bx = int(_lookup_kw('XBINNING') or 1)
                by = int(_lookup_kw('YBINNING') or bx)
                if bx!=by: print(f"⚠️ Unequal binning {bx}×{by}, averaging")
                hdr['XBINNING'], hdr['YBINNING'] = bx, by

                original_header = hdr
                print(f"Loaded XISF header with keys: {_filled}")
                return image, original_header, bit_depth, is_mono

            elif filename.lower().endswith(('.cr2', '.cr3', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef')):
                print(f"Loading RAW file: {filename}")
                with rawpy.imread(filename) as raw:
                    # 1) Read the raw Bayer data (no demosaic)
                    bayer_image = raw.raw_image_visible.astype(np.float32)
                    print(f"Raw Bayer image dtype: {bayer_image.dtype}, "
                        f"min: {bayer_image.min():.2f}, max: {bayer_image.max():.2f}")

                    # 2) Get camera black/white levels
                    black_levels = raw.black_level_per_channel  # e.g. [512, 512, 512, 512]
                    white_level  = raw.white_level              # e.g. 16383 for 14-bit
                    avg_black = float(np.mean(black_levels))    # Simple average

                    # 3) Subtract black level, clip negatives to 0
                    bayer_image -= avg_black
                    bayer_image = np.clip(bayer_image, 0, None)

                    # 4) Divide by (white_level - black_level) to normalize to [0..1]
                    scale = float(white_level - avg_black)
                    if scale <= 0:
                        # Safety check if black >= white
                        scale = 1.0
                    bayer_image /= scale

                    # Now dark frames should hover near 0.0 instead of ~0.7

                    # 5) Check shape to decide if mono vs. color mosaic
                    #    Usually it's 2D for a raw Bayer pattern
                    if bayer_image.ndim == 2:
                        image = bayer_image
                        is_mono = True
                    elif bayer_image.ndim == 3 and bayer_image.shape[2] == 3:
                        # Rare case if raw.raw_image_visible is already color
                        image = bayer_image
                        is_mono = False
                    else:
                        raise ValueError(f"Unexpected RAW Bayer image shape: {bayer_image.shape}")

                    # 6) Assume 16-bit raw data (typical for DSLRs)
                    bit_depth = "16-bit"

                    # 7) Build a minimal header from raw metadata
                    original_header_dict = {
                        'CAMERA': raw.camera_whitebalance[0] if raw.camera_whitebalance else 'Unknown',
                        'EXPTIME': raw.shutter if hasattr(raw, 'shutter') else 0.0,
                        'ISO': raw.iso_speed if hasattr(raw, 'iso_speed') else 0,
                        'FOCAL': raw.focal_len if hasattr(raw, 'focal_len') else 0.0,
                        'DATE': raw.timestamp if hasattr(raw, 'timestamp') else 'Unknown',
                    }

                    # 8) Extract the CFA pattern
                    cfa_pattern = raw.raw_colors_visible  # 2D array of 0/1/2
                    cfa_mapping = {0: 'R', 1: 'G', 2: 'B'}
                    cfa_description = ''.join([cfa_mapping.get(color, '?')
                                            for color in cfa_pattern.flatten()[:4]])
                    original_header_dict['CFA'] = (cfa_description, 'Color Filter Array pattern')

                    # 9) Convert dict → FITS Header
                    original_header = fits.Header()
                    for key, value in original_header_dict.items():
                        original_header[key] = value

                    print(f"RAW file loaded with CFA pattern: {cfa_description}, "
                        f"dark frames ~0, bright frames ~1 now.")
                    return image, original_header, bit_depth, is_mono

            elif filename.lower().endswith('.png'):
                print(f"Loading PNG file: {filename}")
                img = Image.open(filename)

                # Convert unsupported modes to RGB
                if img.mode not in ('L', 'RGB'):
                    print(f"Unsupported PNG mode: {img.mode}, converting to RGB")
                    img = img.convert("RGB")

                # Convert image to numpy array and normalize pixel values to [0, 1]
                image = np.array(img, dtype=np.float32) / 255.0
                bit_depth = "8-bit"

                # Determine if the image is grayscale or RGB
                if len(image.shape) == 2:  # Grayscale image
                    is_mono = True
                elif len(image.shape) == 3 and image.shape[2] == 3:  # RGB image
                    is_mono = False
                else:
                    raise ValueError(f"Unsupported PNG dimensions: {image.shape}")

                print(f"Loaded PNG image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")

            elif filename.lower().endswith(('.jpg', '.jpeg')):
                print(f"Loading JPG file: {filename}")
                img = Image.open(filename)
                if img.mode == 'L':  # Grayscale
                    is_mono = True
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                elif img.mode == 'RGB':  # RGB
                    is_mono = False
                    image = np.array(img, dtype=np.float32) / 255.0
                    bit_depth = "8-bit"
                else:
                    raise ValueError("Unsupported JPG format!")            

            else:
                raise ValueError("Unsupported file format!")

            print(f"Loaded image: shape={image.shape}, bit depth={bit_depth}, mono={is_mono}")
            return image, original_header, bit_depth, is_mono

        except Exception as e:
            error_message = str(e)
            if "buffer is too small for requested array" in error_message.lower():
                if attempt < max_retries:
                    attempt += 1
                    print(f"Error reading image {filename}: {e}")
                    print(f"Retrying in {wait_seconds} seconds... (Attempt {attempt}/{max_retries})")
                    time.sleep(wait_seconds)
                    continue  # Retry loading the image
                else:
                    print(f"Error reading image {filename} after {max_retries} retries: {e}")
            else:
                print(f"Error reading image {filename}: {e}")
            return None, None, None, None

def get_valid_header(file_path):
    """
    Opens the FITS file (handling compressed files as needed), finds the first HDU
    with image data, and then searches through all HDUs for additional keywords (e.g. BAYERPAT).
    Returns a composite header (a copy of the image HDU header updated with extra keywords)
    and the extension index of the image data.
    """
    # Open file appropriately for compressed files
    if file_path.lower().endswith(('.fits.gz', '.fit.gz')):
        
        with gzip.open(file_path, 'rb') as f:
            file_content = f.read()
        hdul = fits.open(BytesIO(file_content))
    else:
        
        hdul = fits.open(file_path)

    with hdul as hdul:
        image_hdu = None
        image_index = None
        # First, find the HDU that contains image data
        for i, hdu in enumerate(hdul):
            
            if hdu.data is not None:
                image_hdu = hdu
                image_index = i
                
                break
        if image_hdu is None:
            raise ValueError("No image data found in FITS file.")

        # Start with a copy of the image HDU header
        composite_header = image_hdu.header.copy()


        # Now search all HDUs for extra keywords (e.g. BAYERPAT)
        for i, hdu in enumerate(hdul):
            if 'BAYERPAT' in hdu.header:
                composite_header['BAYERPAT'] = hdu.header['BAYERPAT']

                break

    return composite_header, image_index

def get_bayer_header(file_path):
    """
    Iterates through all HDUs in the FITS file (handling compressed files if needed)
    to find a header that contains the 'BAYERPAT' keyword.
    Returns the header if found, otherwise None.
    """


    try:
        # Check for compressed files first.
        if file_path.lower().endswith(('.fits.gz', '.fit.gz')):
            with gzip.open(file_path, 'rb') as f:
                file_content = f.read()
            hdul = fits.open(BytesIO(file_content))
        else:
            hdul = fits.open(file_path)
        with hdul as hdul:
            for hdu in hdul:
                if 'BAYERPAT' in hdu.header:
                    return hdu.header
    except Exception as e:
        print(f"Error in get_bayer_header: {e}")
    return None

def save_image(img_array, filename, original_format, bit_depth=None, original_header=None, is_mono=False, image_meta=None, file_meta=None):
 
    """
    Save an image array to a file in the specified format and bit depth.
    """
    img_array = ensure_native_byte_order(img_array)  # Ensure correct byte order
    is_xisf = False  # Flag to determine if the original file was XISF

    # **🔹 Detect If Original File Was XISF**
    if original_header:
        for key in original_header.keys():
            if key.startswith("XISF:"):
                is_xisf = True
                break

    if image_meta and "XISFProperties" in image_meta:
        is_xisf = True  # Confirm XISF metadata exists

    try:
        if original_format == 'png':
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit PNG image to: {filename}")
        elif original_format in ['jpg', 'jpeg']:
            img = Image.fromarray((img_array * 255).astype(np.uint8))  # Convert to 8-bit and save as PNG
            img.save(filename)
            print(f"Saved 8-bit JPG image to: {filename}")        
        elif original_format in ['tiff', 'tif']:
            # Save TIFF files based on bit depth
            if bit_depth == "8-bit":
                tiff.imwrite(filename, (img_array * 255).astype(np.uint8))  # Save as 8-bit TIFF
            elif bit_depth == "16-bit":
                tiff.imwrite(filename, (img_array * 65535).astype(np.uint16))  # Save as 16-bit TIFF
            elif bit_depth == "32-bit unsigned":
                tiff.imwrite(filename, (img_array * 4294967295).astype(np.uint32))  # Save as 32-bit unsigned TIFF
            elif bit_depth == "32-bit floating point":
                tiff.imwrite(filename, img_array.astype(np.float32))  # Save as 32-bit floating point TIFF
            else:
                raise ValueError("Unsupported bit depth for TIFF!")
            print(f"Saved {bit_depth} TIFF image to: {filename}")

        elif original_format in ['fits', 'fit']:
            # Preserve the original extension
            if not filename.lower().endswith(f".{original_format}"):
                filename = filename.rsplit('.', 1)[0] + f".{original_format}"

            # **📌 CASE 1: ORIGINAL FILE WAS XISF → CONVERT TO FITS HEADER**
            if is_xisf:
                print("Detected XISF metadata. Converting to FITS header...")
                fits_header = fits.Header()

                if 'XISFProperties' in image_meta:
                    xisf_props = image_meta['XISFProperties']

                    # Extract WCS parameters
                    if 'PCL:AstrometricSolution:ReferenceCoordinates' in xisf_props:
                        ref_coords = xisf_props['PCL:AstrometricSolution:ReferenceCoordinates']['value']
                        fits_header['CRVAL1'] = ref_coords[0]
                        fits_header['CRVAL2'] = ref_coords[1]

                    if 'PCL:AstrometricSolution:ReferenceLocation' in xisf_props:
                        ref_pixel = xisf_props['PCL:AstrometricSolution:ReferenceLocation']['value']
                        fits_header['CRPIX1'] = ref_pixel[0]
                        fits_header['CRPIX2'] = ref_pixel[1]

                    if 'PCL:AstrometricSolution:PixelSize' in xisf_props:
                        pixel_size = xisf_props['PCL:AstrometricSolution:PixelSize']['value']
                        fits_header['CDELT1'] = -pixel_size / 3600.0
                        fits_header['CDELT2'] = pixel_size / 3600.0

                    if 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_props:
                        linear_transform = xisf_props['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
                        fits_header['CD1_1'] = linear_transform[0][0]
                        fits_header['CD1_2'] = linear_transform[0][1]
                        fits_header['CD2_1'] = linear_transform[1][0]
                        fits_header['CD2_2'] = linear_transform[1][1]

                # Ensure essential WCS headers exist
                fits_header.setdefault('CTYPE1', 'RA---TAN')
                fits_header.setdefault('CTYPE2', 'DEC--TAN')

                print("Converted XISF metadata to FITS header.")

            # **📌 CASE 2: ORIGINAL FILE WAS FITS → PRESERVE HEADER**
            elif original_header is not None:
                print("Detected FITS format. Preserving original FITS header.")
                fits_header = fits.Header()
                for key, value in original_header.items():
                    if key.startswith("XISF:"):
                        continue  # Skip XISF metadata

                    if key in ["RANGE_LOW", "RANGE_HIGH"]:
                        print(f"Removing {key} from header to prevent overflow.")
                        continue  # Skip adding RANGE_LOW and RANGE_HIGH

                    if isinstance(value, dict) and 'value' in value:
                        value = value['value']

                    try:
                        fits_header[key] = value
                    except Exception as e:
                        print(f"Skipping problematic key {key} due to error: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

            # **📌 Image Processing for FITS**
            fits_header['BSCALE'] = 1.0
            fits_header['BZERO'] = 0.0

            if is_mono or img_array.ndim == 2:
                img_array_fits = img_array[:, :, 0] if len(img_array.shape) == 3 else img_array
                fits_header['NAXIS'] = 2
            else:
                img_array_fits = np.transpose(img_array, (2, 0, 1))
                fits_header['NAXIS'] = 3
                fits_header['NAXIS3'] = 3

            fits_header['NAXIS1'] = img_array.shape[1]
            fits_header['NAXIS2'] = img_array.shape[0]

            # force 32-bit floats and update header
            img_array_fits = img_array_fits.astype(np.float32)
            fits_header['BITPIX'] = -32

            # **💾 Save the FITS File**
            hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
            hdu.writeto(filename, overwrite=True)
            print(f"Saved FITS image to: {filename}")
            return



        elif original_format in ['.cr2', '.nef', '.arw', '.dng', '.orf', '.rw2', '.pef']:
            # Save as FITS file with metadata
            print("RAW formats are not writable. Saving as FITS instead.")
            filename = filename.rsplit('.', 1)[0] + ".fits"

            if original_header is not None:
                # Convert original_header (dictionary) to astropy Header object
                fits_header = fits.Header()
                for key, value in original_header.items():
                    fits_header[key] = value
                fits_header['BSCALE'] = 1.0  # Scaling factor
                fits_header['BZERO'] = 0.0   # Offset for brightness    

                if is_mono:  # Grayscale FITS
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array[:, :, 0] * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = (img_array[:, :, 0].astype(np.float32) * bscale + bzero).astype(np.uint32)
                    else:  # 32-bit float
                        img_array_fits = img_array[:, :, 0].astype(np.float32)

                    # Update header for a 2D (grayscale) image
                    fits_header['NAXIS'] = 2
                    fits_header['NAXIS1'] = img_array.shape[1]  # Width
                    fits_header['NAXIS2'] = img_array.shape[0]  # Height
                    fits_header.pop('NAXIS3', None)  # Remove if present

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)
                else:  # RGB FITS
                    img_array_transposed = np.transpose(img_array, (2, 0, 1))  # Channels, Height, Width
                    if bit_depth == "16-bit":
                        img_array_fits = (img_array_transposed * 65535).astype(np.uint16)
                    elif bit_depth == "32-bit unsigned":
                        bzero = fits_header.get('BZERO', 0)
                        bscale = fits_header.get('BSCALE', 1)
                        img_array_fits = img_array_transposed.astype(np.float32) * bscale + bzero
                        fits_header['BITPIX'] = -32
                    else:  # Default to 32-bit float
                        img_array_fits = img_array_transposed.astype(np.float32)

                    # Update header for a 3D (RGB) image
                    fits_header['NAXIS'] = 3
                    fits_header['NAXIS1'] = img_array_transposed.shape[2]  # Width
                    fits_header['NAXIS2'] = img_array_transposed.shape[1]  # Height
                    fits_header['NAXIS3'] = img_array_transposed.shape[0]  # Channels

                    hdu = fits.PrimaryHDU(img_array_fits, header=fits_header)

                # Write the FITS file
                try:
                    hdu.writeto(filename, overwrite=True)
                    print(f"RAW processed and saved as FITS to: {filename}")
                except Exception as e:
                    print(f"Error saving FITS file: {e}")
            else:
                raise ValueError("Original header is required for FITS format!")

        elif original_format == 'xisf':
            try:
                print(f"Original image shape: {img_array.shape}, dtype: {img_array.dtype}")
                print(f"Bit depth: {bit_depth}")

                # Adjust bit depth for saving
                if bit_depth == "16-bit":
                    processed_image = (img_array * 65535).astype(np.uint16)
                elif bit_depth == "32-bit unsigned":
                    processed_image = (img_array * 4294967295).astype(np.uint32)
                else:  # Default to 32-bit float
                    processed_image = img_array.astype(np.float32)

                # Handle mono images explicitly
                if is_mono:
                    print("Detected mono image. Preparing for XISF...")
                    if processed_image.ndim == 3 and processed_image.shape[2] > 1:
                        processed_image = processed_image[:, :, 0]  # Extract single channel
                    processed_image = processed_image[:, :, np.newaxis]  # Add back channel dimension

                    # Update metadata for mono images
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], 1)
                        image_meta[0]['colorSpace'] = 'Gray'
                    else:
                        # Create default metadata for mono images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], 1),
                            'colorSpace': 'Gray'
                        }]

                # Handle RGB images
                else:
                    if image_meta and isinstance(image_meta, list):
                        image_meta[0]['geometry'] = (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2])
                        image_meta[0]['colorSpace'] = 'RGB'
                    else:
                        # Create default metadata for RGB images
                        image_meta = [{
                            'geometry': (processed_image.shape[1], processed_image.shape[0], processed_image.shape[2]),
                            'colorSpace': 'RGB'
                        }]

                # Ensure fallback for `image_meta` and `file_meta`
                if image_meta is None or not isinstance(image_meta, list):
                    image_meta = [{
                        'geometry': (processed_image.shape[1], processed_image.shape[0], 1 if is_mono else 3),
                        'colorSpace': 'Gray' if is_mono else 'RGB'
                    }]
                if file_meta is None:
                    file_meta = {}

                # Debug: Print processed image details and metadata
                print(f"Processed image shape for XISF: {processed_image.shape}, dtype: {processed_image.dtype}")

                # Save the image using XISF.write
                XISF.write(
                    filename,                    # Output path
                    processed_image,             # Final processed image
                    creator_app="Seti Astro Cosmic Clarity",
                    image_metadata=image_meta[0],  # First block of image metadata
                    xisf_metadata=file_meta,       # File-level metadata
                    shuffle=True
                )

                print(f"Saved {bit_depth} XISF image to: {filename}")

            except Exception as e:
                print(f"Error saving XISF file: {e}")
                raise


        else:
            raise ValueError("Unsupported file format!")

    except Exception as e:
        print(f"Error saving image to {filename}: {e}")
        raise




def stretch_mono_image(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Stretches a single-channel (2D) image so that its median ends up near `target_median`.
    Uses the old formula, but with the final math done in a Numba function.
    """
    # 1) Compute black_point from old logic
    black_point = max(np.min(image), np.median(image) - 2.7 * np.std(image))

    # 2) Rescale in Python
    #    r = (val - black_point) / (1 - black_point)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Compute median of *this* rescaled data
    median_rescaled = np.median(rescaled_image)

    # 4) Final stretch in Numba
    stretched_image = numba_mono_final_formula(rescaled_image, median_rescaled, target_median)

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    # 7) Clip result [0..1]
    return np.clip(stretched_image, 0, 1)

def stretch_color_image(image, target_median, linked=True, normalize=False, apply_curves=False, curves_boost=0.0):
    # If image is mono or single-channel, treat as mono
    if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
        mono = image.squeeze()
        mono_stretched = stretch_mono_image(mono, target_median,
                                            normalize=normalize,
                                            apply_curves=apply_curves,
                                            curves_boost=curves_boost)
        # Replicate into 3 channels if you want a 3-channel result
        return np.stack([mono_stretched] * 3, axis=-1)

    # If it's actually color (H, W, 3):
    if linked:
        stretched_image = stretch_color_image_linked(image, target_median,
                                                     normalize=normalize,
                                                     apply_curves=apply_curves,
                                                     curves_boost=curves_boost)
    else:
        stretched_image = stretch_color_image_unlinked(image, target_median,
                                                       normalize=normalize,
                                                       apply_curves=apply_curves,
                                                       curves_boost=curves_boost)
    return stretched_image

def stretch_color_image_linked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Linked color stretch: uses one black_point and one median for all channels.
    """
    # 1) Compute black_point from the combined median, std
    combined_median = np.median(image)
    combined_std = np.std(image)
    black_point = max(np.min(image), combined_median - 2.7 * combined_std)

    # 2) Rescale
    #    (H, W, 3)
    denom_bp = 1.0 - black_point
    rescaled_image = (image - black_point) / denom_bp

    # 3) Median of the entire rescaled array
    median_rescaled = np.median(rescaled_image)

    # 4) Final formula in Numba
    stretched_image = numba_color_final_formula_linked(
        rescaled_image, 
        median_rescaled, 
        target_median
    )

    # 5) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 6) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)

def stretch_color_image_unlinked(image, target_median, normalize=False, apply_curves=False, curves_boost=0.0):
    """
    Unlinked color stretch: each channel has its own black_point, own median.
    """
    H, W, _ = image.shape
    rescaled_image = np.zeros_like(image, dtype=np.float32)
    black_points = np.zeros(3, dtype=np.float32)
    medians_rescaled = np.zeros(3, dtype=np.float32)

    # 1) For each channel, compute black point, rescale, find median
    for c in range(3):
        channel = image[..., c]
        channel_median = np.median(channel)
        channel_std = np.std(channel)
        bp = max(channel.min(), channel_median - 2.7 * channel_std)

        # Store black point
        black_points[c] = bp

        # Rescale that channel
        denom_bp = 1.0 - bp
        rescaled_image[..., c] = (channel - bp) / denom_bp

    # 2) For each channel, compute median of the rescaled version
    for c in range(3):
        medians_rescaled[c] = np.median(rescaled_image[..., c])

    # 3) Final formula in Numba
    stretched_image = numba_color_final_formula_unlinked(
        rescaled_image,
        medians_rescaled,
        target_median
    )

    # 4) Optional curves
    if apply_curves:
        stretched_image = apply_curves_adjustment(stretched_image, target_median, curves_boost)

    # 5) Optional normalize
    if normalize:
        max_val = stretched_image.max()
        if max_val > 0:
            stretched_image /= max_val

    return np.clip(stretched_image, 0, 1)



def apply_curves_adjustment(image, target_median, curves_boost):
    """
    Original signature unchanged, but now uses a Numba helper
    to do the pixel-by-pixel interpolation.

    'image' can be 2D (H,W) or 3D (H,W,3).
    """
    # Build the curve array as before
    curve = [
        [0.0, 0.0],
        [0.5 * target_median, 0.5 * target_median],
        [target_median, target_median],
        [
            (1/4 * (1 - target_median) + target_median),
            np.power((1/4 * (1 - target_median) + target_median), (1 - curves_boost))
        ],
        [
            (3/4 * (1 - target_median) + target_median),
            np.power(np.power((3/4 * (1 - target_median) + target_median), (1 - curves_boost)), (1 - curves_boost))
        ],
        [1.0, 1.0]
    ]
    # Convert to arrays
    xvals = np.array([p[0] for p in curve], dtype=np.float32)
    yvals = np.array([p[1] for p in curve], dtype=np.float32)

    # Ensure 'image' is float32
    image_32 = image.astype(np.float32, copy=False)

    # Now apply the piecewise linear function in Numba
    adjusted_image = apply_curves_numba(image_32, xvals, yvals)
    return adjusted_image

def resource_path(relative_path):
    """ Get the absolute path to the resource, works for dev and for PyInstaller """
    try:
        # PyInstaller creates a temporary folder and stores path in _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)

def ensure_native_byte_order(array):
    """
    Ensures that the array is in the native byte order.
    If the array is in a non-native byte order, it will convert it.
    """
    if array.dtype.byteorder == '=':  # Already in native byte order
        return array
    elif array.dtype.byteorder in ('<', '>'):  # Non-native byte order
        return array.byteswap().view(array.dtype.newbyteorder('='))
    return array


# Determine if running inside a PyInstaller bundle
if hasattr(sys, '_MEIPASS'):
    # Set path for PyInstaller bundle
    data_path = os.path.join(sys._MEIPASS, "astroquery", "simbad", "data")
else:
    # Set path for regular Python environment
    data_path = "C:/Users/Gaming/Desktop/Python Code/venv/Lib/site-packages/astroquery/simbad/data"

# Ensure the final path doesn't contain 'data/data' duplication
if 'data/data' in data_path:
    data_path = data_path.replace('data/data', 'data')

conf.dataurl = f'file://{data_path}/'

# Access wrench_icon.png, adjusting for PyInstaller executable
if hasattr(sys, '_MEIPASS'):
    wrench_path = os.path.join(sys._MEIPASS, 'wrench_icon.png')
    eye_icon_path = os.path.join(sys._MEIPASS, 'eye.png')
    disk_icon_path = os.path.join(sys._MEIPASS, 'disk.png')
    nuke_path = os.path.join(sys._MEIPASS, 'nuke.png')  
    hubble_path = os.path.join(sys._MEIPASS, 'hubble.png') 
    collage_path = os.path.join(sys._MEIPASS, 'collage.png') 
    annotated_path = os.path.join(sys._MEIPASS, 'annotated.png') 
    colorwheel_path = os.path.join(sys._MEIPASS, 'colorwheel.png')
    font_path = os.path.join(sys._MEIPASS, 'font.png')
    csv_icon_path = os.path.join(sys._MEIPASS, 'cvs.png')
else:
    wrench_path = 'wrench_icon.png'  # Path for running as a script
    eye_icon_path = 'eye.png'  # Path for running as a script
    disk_icon_path = 'disk.png'   
    nuke_path = 'nuke.png' 
    hubble_path = 'hubble.png'
    collage_path = 'collage.png'
    annotated_path = 'annotated.png'
    colorwheel_path = 'colorwheel.png'
    font_path = 'font.png'
    csv_icon_path = 'cvs.png'

# Constants for comoving radial distance calculation
H0 = 69.6  # Hubble constant in km/s/Mpc
WM = 0.286  # Omega(matter)
WV = 0.714  # Omega(vacuum)
c = 299792.458  # speed of light in km/s
Tyr = 977.8  # coefficient to convert 1/H into Gyr
Mpc_to_Gly = 3.262e-3  # Conversion from Mpc to Gly

otype_long_name_lookup = {
    "ev": "transient event",
    "Rad": "Radio-source",
    "mR": "metric Radio-source",
    "cm": "centimetric Radio-source",
    "mm": "millimetric Radio-source",
    "smm": "sub-millimetric source",
    "HI": "HI (21cm) source",
    "rB": "radio Burst",
    "Mas": "Maser",
    "IR": "Infra-Red source",
    "FIR": "Far-Infrared source",
    "MIR": "Mid-Infrared source",
    "NIR": "Near-Infrared source",
    "blu": "Blue object",
    "UV": "UV-emission source",
    "X": "X-ray source",
    "UX?": "Ultra-luminous X-ray candidate",
    "ULX": "Ultra-luminous X-ray source",
    "gam": "gamma-ray source",
    "gB": "gamma-ray Burst",
    "err": "Not an object (error, artefact, ...)",
    "grv": "Gravitational Source",
    "Lev": "(Micro)Lensing Event",
    "LS?": "Possible gravitational lens System",
    "Le?": "Possible gravitational lens",
    "LI?": "Possible gravitationally lensed image",
    "gLe": "Gravitational Lens",
    "gLS": "Gravitational Lens System (lens+images)",
    "GWE": "Gravitational Wave Event",
    "..?": "Candidate objects",
    "G?": "Possible Galaxy",
    "SC?": "Possible Supercluster of Galaxies",
    "C?G": "Possible Cluster of Galaxies",
    "Gr?": "Possible Group of Galaxies",
    "**?": "Physical Binary Candidate",
    "EB?": "Eclipsing Binary Candidate",
    "Sy?": "Symbiotic Star Candidate",
    "CV?": "Cataclysmic Binary Candidate",
    "No?": "Nova Candidate",
    "XB?": "X-ray binary Candidate",
    "LX?": "Low-Mass X-ray binary Candidate",
    "HX?": "High-Mass X-ray binary Candidate",
    "Pec?": "Possible Peculiar Star",
    "Y*?": "Young Stellar Object Candidate",
    "TT?": "T Tau star Candidate",
    "C*?": "Possible Carbon Star",
    "S*?": "Possible S Star",
    "OH?": "Possible Star with envelope of OH/IR type",
    "WR?": "Possible Wolf-Rayet Star",
    "Be?": "Possible Be Star",
    "Ae?": "Possible Herbig Ae/Be Star",
    "HB?": "Possible Horizontal Branch Star",
    "RR?": "Possible Star of RR Lyr type",
    "Ce?": "Possible Cepheid",
    "WV?": "Possible Variable Star of W Vir type",
    "RB?": "Possible Red Giant Branch star",
    "sg?": "Possible Supergiant star",
    "s?r": "Possible Red supergiant star",
    "s?y": "Possible Yellow supergiant star",
    "s?b": "Possible Blue supergiant star",
    "AB?": "Asymptotic Giant Branch Star candidate",
    "LP?": "Long Period Variable candidate",
    "Mi?": "Mira candidate",
    "pA?": "Post-AGB Star Candidate",
    "BS?": "Candidate blue Straggler Star",
    "HS?": "Hot subdwarf candidate",
    "WD?": "White Dwarf Candidate",
    "N*?": "Neutron Star Candidate",
    "BH?": "Black Hole Candidate",
    "SN?": "SuperNova Candidate",
    "LM?": "Low-mass star candidate",
    "BD?": "Brown Dwarf Candidate",
    "mul": "Composite object",
    "reg": "Region defined in the sky",
    "vid": "Underdense region of the Universe",
    "SCG": "Supercluster of Galaxies",
    "ClG": "Cluster of Galaxies",
    "GrG": "Group of Galaxies",
    "CGG": "Compact Group of Galaxies",
    "PaG": "Pair of Galaxies",
    "IG": "Interacting Galaxies",
    "C?*": "Possible (open) star cluster",
    "Gl?": "Possible Globular Cluster",
    "Cl*": "Cluster of Stars",
    "GlC": "Globular Cluster",
    "OpC": "Open (galactic) Cluster",
    "As*": "Association of Stars",
    "St*": "Stellar Stream",
    "MGr": "Moving Group",
    "**": "Double or multiple star",
    "EB*": "Eclipsing binary",
    "Al*": "Eclipsing binary of Algol type",
    "bL*": "Eclipsing binary of beta Lyr type",
    "WU*": "Eclipsing binary of W UMa type",
    "SB*": "Spectroscopic binary",
    "El*": "Ellipsoidal variable Star",
    "Sy*": "Symbiotic Star",
    "CV*": "Cataclysmic Variable Star",
    "DQ*": "CV DQ Her type (intermediate polar)",
    "AM*": "CV of AM Her type (polar)",
    "NL*": "Nova-like Star",
    "No*": "Nova",
    "DN*": "Dwarf Nova",
    "XB*": "X-ray Binary",
    "LXB": "Low Mass X-ray Binary",
    "HXB": "High Mass X-ray Binary",
    "ISM": "Interstellar matter",
    "PoC": "Part of Cloud",
    "PN?": "Possible Planetary Nebula",
    "CGb": "Cometary Globule",
    "bub": "Bubble",
    "EmO": "Emission Object",
    "Cld": "Cloud",
    "GNe": "Galactic Nebula",
    "DNe": "Dark Cloud (nebula)",
    "RNe": "Reflection Nebula",
    "MoC": "Molecular Cloud",
    "glb": "Globule (low-mass dark cloud)",
    "cor": "Dense core",
    "SFR": "Star forming region",
    "HVC": "High-velocity Cloud",
    "HII": "HII (ionized) region",
    "PN": "Planetary Nebula",
    "sh": "HI shell",
    "SR?": "SuperNova Remnant Candidate",
    "SNR": "SuperNova Remnant",
    "of?": "Outflow candidate",
    "out": "Outflow",
    "HH": "Herbig-Haro Object",
    "*": "Star",
    "V*?": "Star suspected of Variability",
    "Pe*": "Peculiar Star",
    "HB*": "Horizontal Branch Star",
    "Y*O": "Young Stellar Object",
    "Ae*": "Herbig Ae/Be star",
    "Em*": "Emission-line Star",
    "Be*": "Be Star",
    "BS*": "Blue Straggler Star",
    "RG*": "Red Giant Branch star",
    "AB*": "Asymptotic Giant Branch Star (He-burning)",
    "C*": "Carbon Star",
    "S*": "S Star",
    "sg*": "Evolved supergiant star",
    "s*r": "Red supergiant star",
    "s*y": "Yellow supergiant star",
    "s*b": "Blue supergiant star",
    "HS*": "Hot subdwarf",
    "pA*": "Post-AGB Star (proto-PN)",
    "WD*": "White Dwarf",
    "LM*": "Low-mass star (M<1solMass)",
    "BD*": "Brown Dwarf (M<0.08solMass)",
    "N*": "Confirmed Neutron Star",
    "OH*": "OH/IR star",
    "TT*": "T Tau-type Star",
    "WR*": "Wolf-Rayet Star",
    "PM*": "High proper-motion Star",
    "HV*": "High-velocity Star",
    "V*": "Variable Star",
    "Ir*": "Variable Star of irregular type",
    "Or*": "Variable Star of Orion Type",
    "Er*": "Eruptive variable Star",
    "RC*": "Variable Star of R CrB type",
    "RC?": "Variable Star of R CrB type candidate",
    "Ro*": "Rotationally variable Star",
    "a2*": "Variable Star of alpha2 CVn type",
    "Psr": "Pulsar",
    "BY*": "Variable of BY Dra type",
    "RS*": "Variable of RS CVn type",
    "Pu*": "Pulsating variable Star",
    "RR*": "Variable Star of RR Lyr type",
    "Ce*": "Cepheid variable Star",
    "dS*": "Variable Star of delta Sct type",
    "RV*": "Variable Star of RV Tau type",
    "WV*": "Variable Star of W Vir type",
    "bC*": "Variable Star of beta Cep type",
    "cC*": "Classical Cepheid (delta Cep type)",
    "gD*": "Variable Star of gamma Dor type",
    "SX*": "Variable Star of SX Phe type (subdwarf)",
    "LP*": "Long-period variable star",
    "Mi*": "Variable Star of Mira Cet type",
    "SN*": "SuperNova",
    "su*": "Sub-stellar object",
    "Pl?": "Extra-solar Planet Candidate",
    "Pl": "Extra-solar Confirmed Planet",
    "G": "Galaxy",
    "PoG": "Part of a Galaxy",
    "GiC": "Galaxy in Cluster of Galaxies",
    "BiC": "Brightest galaxy in a Cluster (BCG)",
    "GiG": "Galaxy in Group of Galaxies",
    "GiP": "Galaxy in Pair of Galaxies",
    "rG": "Radio Galaxy",
    "H2G": "HII Galaxy",
    "LSB": "Low Surface Brightness Galaxy",
    "AG?": "Possible Active Galaxy Nucleus",
    "Q?": "Possible Quasar",
    "Bz?": "Possible Blazar",
    "BL?": "Possible BL Lac",
    "EmG": "Emission-line galaxy",
    "SBG": "Starburst Galaxy",
    "bCG": "Blue compact Galaxy",
    "LeI": "Gravitationally Lensed Image",
    "LeG": "Gravitationally Lensed Image of a Galaxy",
    "LeQ": "Gravitationally Lensed Image of a Quasar",
    "AGN": "Active Galaxy Nucleus",
    "LIN": "LINER-type Active Galaxy Nucleus",
    "SyG": "Seyfert Galaxy",
    "Sy1": "Seyfert 1 Galaxy",
    "Sy2": "Seyfert 2 Galaxy",
    "Bla": "Blazar",
    "BLL": "BL Lac - type object",
    "OVV": "Optically Violently Variable object",
    "QSO": "Quasar"
}


# ────────────────────────────────────────────────
# 1a) Map each SIMBAD otype → one of our high-level categories
# ────────────────────────────────────────────────
OTYPE_TO_CATEGORY = {
    # Transient & Explosive Events
    "ev":   "Transient & Explosive",
    "rB":   "Transient & Explosive",
    "gB":   "Transient & Explosive",
    "GWE":  "Transient & Explosive",
    "SN*":  "Transient & Explosive",
    "SN?":  "Transient & Explosive",
    "SR?":  "Transient & Explosive",
    "SNR":  "Transient & Explosive",
    "Lev":  "Transient & Explosive",

    # High-Energy / X-ray / γ-ray
    "X":    "High-Energy / X-ray / γ-ray",
    "UX?":  "High-Energy / X-ray / γ-ray",
    "ULX":  "High-Energy / X-ray / γ-ray",
    "gam":  "High-Energy / X-ray / γ-ray",
    "grv":  "High-Energy / X-ray / γ-ray",
    "Psr":  "High-Energy / X-ray / γ-ray",
    "N*?":  "High-Energy / X-ray / γ-ray",
    "BH?":  "High-Energy / X-ray / γ-ray",

    # Radio & sub-millimetric
    "Rad":  "Radio & Sub-mm",
    "mR":   "Radio & Sub-mm",
    "cm":   "Radio & Sub-mm",
    "mm":   "Radio & Sub-mm",
    "smm":  "Radio & Sub-mm",
    "HI":   "Radio & Sub-mm",
    "Mas":  "Radio & Sub-mm",

    # IR / Optical / UV / Blue
    "IR":   "IR / Optical / UV",
    "FIR":  "IR / Optical / UV",
    "MIR":  "IR / Optical / UV",
    "NIR":  "IR / Optical / UV",
    "UV":   "IR / Optical / UV",
    "blu":  "IR / Optical / UV",

    # Gravitational Lensing & Microlensing
    "Lev":  "Gravitational Lensing",
    "LS?":  "Gravitational Lensing",
    "Le?":  "Gravitational Lensing",
    "LI?":  "Gravitational Lensing",
    "gLe":  "Gravitational Lensing",
    "gLS":  "Gravitational Lensing",

    # Stars & Stellar Objects
    "*":    "Stars & Stellar",
    "V*":   "Stars & Stellar",
    "Pe*":  "Stars & Stellar",
    "HB*":  "Stars & Stellar",
    "Y*O":  "Stars & Stellar",
    "Ae*":  "Stars & Stellar",
    "Em*":  "Stars & Stellar",
    "Be*":  "Stars & Stellar",
    "BS*":  "Stars & Stellar",
    "RG*":  "Stars & Stellar",
    "AB*":  "Stars & Stellar",
    "C*":   "Stars & Stellar",
    "S*":   "Stars & Stellar",
    "sg*":  "Stars & Stellar",
    "s*r":  "Stars & Stellar",
    "s*y":  "Stars & Stellar",
    "s*b":  "Stars & Stellar",
    "HS*":  "Stars & Stellar",
    "pA*":  "Stars & Stellar",
    "WD*":  "Stars & Stellar",
    "LM*":  "Stars & Stellar",
    "BD*":  "Stars & Stellar",
    "N*":   "Stars & Stellar",
    "OH*":  "Stars & Stellar",
    "TT*":  "Stars & Stellar",
    "WR*":  "Stars & Stellar",
    "PM*":  "Stars & Stellar",
    "HV*":  "Stars & Stellar",
    "C?*":  "Stars & Stellar",
    "Pec?": "Stars & Stellar",
    "Y*?":  "Stars & Stellar",
    "TT?":  "Stars & Stellar",
    "C*?":  "Stars & Stellar",
    "S*?":  "Stars & Stellar",
    "OH?":  "Stars & Stellar",
    "WR?":  "Stars & Stellar",
    "Be?":  "Stars & Stellar",
    "Ae?":  "Stars & Stellar",
    "HB?":  "Stars & Stellar",
    "RB?":  "Stars & Stellar",
    "sg?":  "Stars & Stellar",
    "s?r":  "Stars & Stellar",
    "s?y":  "Stars & Stellar",
    "s?b":  "Stars & Stellar",
    "pA?":  "Stars & Stellar",
    "BS?":  "Stars & Stellar",
    "HS?":  "Stars & Stellar",
    "WD?":  "Stars & Stellar",    

    # Binaries & Multiples / Variables
    "**":   "Binaries & Variables",
    "EB*":  "Binaries & Variables",
    "Al*":  "Binaries & Variables",
    "bL*":  "Binaries & Variables",
    "WU*":  "Binaries & Variables",
    "SB*":  "Binaries & Variables",
    "El*":  "Binaries & Variables",
    "Sy*":  "Binaries & Variables",
    "CV*":  "Binaries & Variables",
    "DQ*":  "Binaries & Variables",
    "AM*":  "Binaries & Variables",
    "NL*":  "Binaries & Variables",
    "No*":  "Binaries & Variables",
    "DN*":  "Binaries & Variables",
    "XB*":  "Binaries & Variables",
    "LXB":  "Binaries & Variables",
    "HXB":  "Binaries & Variables",
    "Pl?":  "Binaries & Variables",
    "Ce?":  "Binaries & Variables",
    "Ce*":  "Binaries & Variables",
    "cC*":  "Binaries & Variables",
    "**?":  "Binaries & Variables",
    "EB?":  "Binaries & Variables",
    "Sy?":  "Binaries & Variables",
    "CV?":  "Binaries & Variables",
    "No?":  "Binaries & Variables",
    "XB?":  "Binaries & Variables",
    "LX?":  "Binaries & Variables",
    "HX?":  "Binaries & Variables",
    "RR?":  "Binaries & Variables",
    "WV?":  "Binaries & Variables",
    "LP?":  "Binaries & Variables",
    "Mi?":  "Binaries & Variables",
    "Ce?":  "Binaries & Variables",
    "cC*":  "Binaries & Variables",
    "Pl?":  "Binaries & Variables",    

    # Clusters & Associations
    "Cl*":  "Clusters & Associations",
    "GlC":  "Clusters & Associations",
    "OpC":  "Clusters & Associations",
    "As*":  "Clusters & Associations",
    "St*":  "Clusters & Associations",
    "MGr":  "Clusters & Associations",
    "C?*":  "Clusters & Associations",
    "Gl?":  "Clusters & Associations",    

    # Nebulae & Interstellar Matter
    "PN":   "Nebulae & ISM",
    "PN?":  "Nebulae & ISM",
    "EmO":  "Nebulae & ISM",
    "GNe":  "Nebulae & ISM",
    "DNe":  "Nebulae & ISM",
    "RNe":  "Nebulae & ISM",
    "MoC":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "bub":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "Cld":  "Nebulae & ISM",
    "sh":   "Nebulae & ISM",
    "SFR":  "Nebulae & ISM",
    "HVC":  "Nebulae & ISM",
    "CGb":  "Nebulae & ISM",
    "PoC":  "Nebulae & ISM",
    "glb":  "Nebulae & ISM",
    "cor":  "Nebulae & ISM",
    "out":  "Nebulae & ISM",
    "HH":   "Nebulae & ISM",
    "HII":  "Nebulae & ISM",
    "ISM":  "Nebulae & ISM",
    "of?":  "Nebulae & ISM",    

    # Galaxies & Active Nuclei
    "G":    "Galaxies & AGN",
    "PoG":  "Galaxies & AGN",
    "EmG":  "Galaxies & AGN",
    "SBG":  "Galaxies & AGN",
    "LSB":  "Galaxies & AGN",
    "AGN":  "Galaxies & AGN",
    "LIN":  "Galaxies & AGN",
    "SyG":  "Galaxies & AGN",
    "Sy1":  "Galaxies & AGN",
    "Sy2":  "Galaxies & AGN",
    "Bla":  "Galaxies & AGN",
    "BLL":  "Galaxies & AGN",
    "OVV":  "Galaxies & AGN",
    "QSO":  "Galaxies & AGN",
    "Q?":   "Galaxies & AGN",
    "AG?":  "Galaxies & AGN",
    "G?":   "Galaxies & AGN",
    "IG":   "Galaxies & AGN",
    "GiC":  "Galaxies & AGN",
    "BiC":  "Galaxies & AGN",
    "GiP":  "Galaxies & AGN",
    "rG":   "Galaxies & AGN",
    "H2G":  "Galaxies & AGN",
    "Bz?":  "Galaxies & AGN",
    "BL?":  "Galaxies & AGN",    


    # Large-Scale Structure: clusters, superclusters, voids
    "ClG":  "Large-Scale Structure",
    "GrG":  "Large-Scale Structure",
    "CGG":  "Large-Scale Structure",
    "PaG":  "Large-Scale Structure",
    "SCG":  "Large-Scale Structure",
    "SC?":  "Large-Scale Structure",
    "C?G":  "Large-Scale Structure",
    "Gr?":  "Large-Scale Structure",
    "vid":  "Large-Scale Structure",
    "GiG":  "Large-Scale Structure",

    # Regions, Clouds & Artefacts
    "reg":  "Regions & Clouds",
    "mul":  "Regions & Clouds",

    # Errors & Artefacts / Unknown
    "err":  "Errors & Artefacts",
    "..?":  "Errors & Artefacts",  
}

# ────────────────────────────────────────────────
# 1b) Assign each category a distinct QColor
# ────────────────────────────────────────────────
CATEGORY_TO_COLOR = {
    "Transient & Explosive":        QColor(255,   0,   0),  # red
    "High-Energy / X-ray / γ-ray":  QColor(255, 165,   0),  # orange
    "Radio & Sub-mm":               QColor(128,   0, 128),  # purple
    "IR / Optical / UV":            QColor(  0, 128,   0),  # green
    "Gravitational Lensing":        QColor(218, 112, 214),  # orchid
    "Stars & Stellar":              QColor(  0,   0, 255),  # blue
    "Binaries & Variables":         QColor(255, 255,   0),  # yellow
    "Clusters & Associations":      QColor(165,  42,  42),  # brown
    "Nebulae & ISM":                QColor(  0, 128, 128),  # teal
    "Galaxies & AGN":               QColor(255,   0, 255),  # magenta
    "Large-Scale Structure":        QColor( 200,  200,  200),  # dark gray
    "Regions & Clouds":             QColor( 95, 158, 160),  # cadet blue
    "Errors & Artefacts":           QColor(128, 128, 128),  # gray
}



Simbad.ROW_LIMIT = 0  # Remove row limit for full results
Simbad.TIMEOUT = 300  # Increase timeout for long queries

# Astrometry.net API constants
ASTROMETRY_API_URL = "http://nova.astrometry.net/api/"
ASTROMETRY_API_KEY_FILE = "astrometry_api_key.txt"

settings = QSettings("Seti Astro", "Seti Astro Suite")

def save_api_key(api_key):
    settings.setValue("astrometry_api_key", api_key)  # Save to QSettings
    print("API key saved.")

def load_api_key():
    api_key = settings.value("astrometry_api_key", "")  # Load from QSettings
    if api_key:
        print("API key loaded.")
    return api_key




class CustomGraphicsView(QGraphicsView):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.setMouseTracking(True)  # Enable mouse tracking
        self.setDragMode(QGraphicsView.DragMode.NoDrag)  # Disable default drag mode to avoid hand cursor
        self.setCursor(Qt.CursorShape.ArrowCursor)  # Set default cursor to arrow
        self.drawing_item = None
        self.start_pos = None     
        self.annotation_items = []  # Store annotation items  
        self.drawing_measurement = False
        self.measurement_start = QPointF()    
         

        self.selected_object = None  # Initialize selected_object to None
        self.show_names = False 

        # Variables for drawing the circle
        self.circle_center = None
        self.circle_radius = 0
        self.drawing_circle = False  # Flag to check if we're currently drawing a circle
        self.dragging = False  # Flag to manage manual dragging


    def mousePressEvent(self, event):
        if event.button() == Qt.MouseButton.LeftButton:
            if event.modifiers() == Qt.KeyboardModifier.ControlModifier:
                # Start annotation mode with the current tool
                self.start_pos = self.mapToScene(event.pos())

                # Check which tool is currently selected
                if self.parent.current_tool == "Ellipse":
                    self.drawing_item = QGraphicsEllipseItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Rectangle":
                    self.drawing_item = QGraphicsRectItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Arrow":
                    self.drawing_item = QGraphicsLineItem()
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Freehand":
                    self.drawing_item = QGraphicsPathItem()
                    path = QPainterPath(self.start_pos)
                    self.drawing_item.setPath(path)
                    self.drawing_item.setPen(QPen(self.parent.selected_color, 2))
                    self.parent.main_scene.addItem(self.drawing_item)

                elif self.parent.current_tool == "Text":
                    text, ok = QInputDialog.getText(self, "Add Text", "Enter text:")
                    if ok and text:
                        text_item = QGraphicsTextItem(text)
                        text_item.setPos(self.start_pos)
                        text_item.setDefaultTextColor(self.parent.selected_color)  # Use selected color
                        text_item.setFont(self.parent.selected_font)  # Use selected font
                        self.parent.main_scene.addItem(text_item)
                        
                        # Store as ('text', text, position, color)
                        self.annotation_items.append(('text', text, self.start_pos, self.parent.selected_color))


                elif self.parent.current_tool == "Compass":
                    self.place_celestial_compass(self.start_pos)

            elif event.modifiers() == Qt.KeyboardModifier.ShiftModifier:
                # Start drawing a circle for Shift+Click
                self.drawing_circle = True
                self.circle_center = self.mapToScene(event.pos())
                self.circle_radius = 0
                self.parent.status_label.setText("Drawing circle: Shift + Drag")
                self.update_circle()

            elif event.modifiers() == Qt.KeyboardModifier.AltModifier:
                # Start celestial measurement for Alt+Click
                self.measurement_start = self.mapToScene(event.pos())
                self.drawing_measurement = True
                self.drawing_item = None  # Clear any active annotation item
    

            else:
                # Detect if an object circle was clicked without Shift or Ctrl
                scene_pos = self.mapToScene(event.pos())
                clicked_object = self.get_object_at_position(scene_pos)
                
                if clicked_object:
                    # Select the clicked object and redraw
                    self.parent.selected_object = clicked_object
                    self.select_object(clicked_object)
                    self.draw_query_results()
                    self.update_mini_preview()
                    
                    # Highlight the corresponding row in the TreeWidget
                    for i in range(self.parent.results_tree.topLevelItemCount()):
                        item = self.parent.results_tree.topLevelItem(i)
                        if item.text(2) == clicked_object["name"]:  # Assuming third element is 'Name'
                            self.parent.results_tree.setCurrentItem(item)
                            break
                else:
                    # Start manual dragging if no modifier is held
                    self.dragging = True
                    self.setCursor(Qt.CursorShape.ClosedHandCursor)  # Use closed hand cursor to indicate dragging
                    self.drag_start_pos = event.pos()  # Store starting position

        super().mousePressEvent(event)


    def mouseDoubleClickEvent(self, event):
        """Handle double-click event on an object in the main image to open SIMBAD or NED URL based on source."""
        scene_pos = self.mapToScene(event.pos())
        clicked_object = self.get_object_at_position(scene_pos)

        if clicked_object:
            object_name = clicked_object.get("name")  # Access 'name' key from the dictionary
            ra = float(clicked_object.get("ra"))  # Ensure RA is a float for precision
            dec = float(clicked_object.get("dec"))  # Ensure Dec is a float for precision
            source = clicked_object.get("source", "Simbad")  # Default to "Simbad" if source not specified

            if source == "Simbad" and object_name:
                # Open Simbad URL with encoded object name
                encoded_name = quote(object_name)
                url = f"https://simbad.cds.unistra.fr/simbad/sim-basic?Ident={encoded_name}&submit=SIMBAD+search"
                webbrowser.open(url)
            elif source == "Vizier":
                # Format the NED search URL with proper RA, Dec, and radius
                radius = 5 / 60  # Radius in arcminutes (5 arcseconds)
                dec_sign = "%2B" if dec >= 0 else "-"  # Determine sign for declination
                ned_url = (
                    f"http://ned.ipac.caltech.edu/conesearch?search_type=Near%20Position%20Search"
                    f"&ra={ra:.6f}d&dec={dec_sign}{abs(dec):.6f}d&radius={radius:.3f}"
                    "&in_csys=Equatorial&in_equinox=J2000.0"
                )
                webbrowser.open(ned_url)
            elif source == "Mast":
                # Open MAST URL using RA and Dec with a small radius for object lookup
                mast_url = f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
                webbrowser.open(mast_url)                
        else:
            super().mouseDoubleClickEvent(event)

    def mouseMoveEvent(self, event):
        scene_pos = self.mapToScene(event.pos())

        if self.drawing_circle:
            # Update the circle radius as the mouse moves
            self.circle_radius = np.sqrt(
                (scene_pos.x() - self.circle_center.x()) ** 2 +
                (scene_pos.y() - self.circle_center.y()) ** 2
            )
            self.update_circle()

        elif self.drawing_measurement:
            # Update the measurement line dynamically as the mouse moves
            if self.drawing_item:
                self.parent.main_scene.removeItem(self.drawing_item)  # Remove previous line if exists
            self.drawing_item = QGraphicsLineItem(QLineF(self.measurement_start, scene_pos))
            self.drawing_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))  # Use green dashed line for measurement
            self.parent.main_scene.addItem(self.drawing_item)

        elif self.drawing_item:
            # Update the current drawing item based on the selected tool and mouse position
            if isinstance(self.drawing_item, QGraphicsEllipseItem) and self.parent.current_tool == "Ellipse":
                # For Ellipse tool, update the ellipse dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsRectItem) and self.parent.current_tool == "Rectangle":
                # For Rectangle tool, update the rectangle dimensions
                rect = QRectF(self.start_pos, scene_pos).normalized()
                self.drawing_item.setRect(rect)

            elif isinstance(self.drawing_item, QGraphicsLineItem) and self.parent.current_tool == "Arrow":
                # For Arrow tool, set the line from start_pos to current mouse position
                line = QLineF(self.start_pos, scene_pos)
                self.drawing_item.setLine(line)

            elif isinstance(self.drawing_item, QGraphicsPathItem) and self.parent.current_tool == "Freehand":
                # For Freehand tool, add a line to the path to follow the mouse movement
                path = self.drawing_item.path()
                path.lineTo(scene_pos)
                self.drawing_item.setPath(path)

        elif self.dragging:
            # Handle manual dragging by scrolling the view
            delta = event.pos() - self.drag_start_pos
            self.horizontalScrollBar().setValue(self.horizontalScrollBar().value() - delta.x())
            self.verticalScrollBar().setValue(self.verticalScrollBar().value() - delta.y())
            self.drag_start_pos = event.pos()
        else:
            # Update RA/Dec display as the cursor moves
            self.parent.update_ra_dec_from_mouse(event)
            
        super().mouseMoveEvent(event)
                

    def mouseReleaseEvent(self, event):
        if self.drawing_circle and event.button() == Qt.MouseButton.LeftButton:
            # Stop drawing the circle
            self.drawing_circle = False
            self.parent.circle_center = self.circle_center
            self.parent.circle_radius = self.circle_radius

            # Calculate RA/Dec for the circle center
            ra, dec = self.parent.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            if ra is not None and dec is not None:
                self.parent.ra_label.setText(f"RA: {self.parent.convert_ra_to_hms(ra)}")
                self.parent.dec_label.setText(f"Dec: {self.parent.convert_dec_to_dms(dec)}")

                if self.parent.pixscale:
                    radius_arcmin = self.circle_radius * self.parent.pixscale / 60.0
                    self.parent.status_label.setText(
                        f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
                    )
                else:
                    self.parent.status_label.setText("Pixscale not available for radius calculation.")
            else:
                self.parent.status_label.setText("Unable to determine RA/Dec due to missing WCS.")

            # Update circle data and redraw
            self.parent.update_circle_data()
            self.update_circle()

        elif self.drawing_measurement and event.button() == Qt.MouseButton.LeftButton:
            # Complete the measurement when the mouse is released
            self.drawing_measurement = False
            measurement_end = self.mapToScene(event.pos())

            # Calculate celestial distance between start and end points
            ra1, dec1 = self.parent.calculate_ra_dec_from_pixel(self.measurement_start.x(), self.measurement_start.y())
            ra2, dec2 = self.parent.calculate_ra_dec_from_pixel(measurement_end.x(), measurement_end.y())
            
            if ra1 is not None and dec1 is not None and ra2 is not None and dec2 is not None:
                # Compute the angular distance
                angular_distance = self.parent.calculate_angular_distance(ra1, dec1, ra2, dec2)
                distance_text = self.parent.format_distance_as_dms(angular_distance)

                # Create and add the line item for display
                measurement_line_item = QGraphicsLineItem(QLineF(self.measurement_start, measurement_end))
                measurement_line_item.setPen(QPen(Qt.GlobalColor.green, 2, Qt.PenStyle.DashLine))
                self.parent.main_scene.addItem(measurement_line_item)

                # Create a midpoint position for the distance text
                midpoint = QPointF(
                    (self.measurement_start.x() + measurement_end.x()) / 2,
                    (self.measurement_start.y() + measurement_end.y()) / 2
                )

                # Create and add the text item at the midpoint
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(midpoint)
                text_item.setDefaultTextColor(Qt.GlobalColor.green)
                text_item.setFont(self.parent.selected_font)  # Use the selected font
                self.parent.main_scene.addItem(text_item)

                # Store the line and text in annotation items for future reference
                measurement_line = QLineF(self.measurement_start, measurement_end)
                self.annotation_items.append(('line', measurement_line))  # Store QLineF, not QGraphicsLineItem
                self.annotation_items.append(('text', distance_text, midpoint, Qt.GlobalColor.green))

            # Clear the temporary measurement line item without removing the final line
            self.drawing_item = None



        elif self.drawing_item and event.button() == Qt.MouseButton.LeftButton:
            # Finalize the shape drawing and add its properties to annotation_items
            if isinstance(self.drawing_item, QGraphicsEllipseItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('ellipse', rect, color))
            elif isinstance(self.drawing_item, QGraphicsRectItem):
                rect = self.drawing_item.rect()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('rect', rect, color))
            elif isinstance(self.drawing_item, QGraphicsLineItem):
                line = self.drawing_item.line()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('line', line, color))
            elif isinstance(self.drawing_item, QGraphicsTextItem):
                pos = self.drawing_item.pos()
                text = self.drawing_item.toPlainText()
                color = self.drawing_item.defaultTextColor()
                self.annotation_items.append(('text', pos, text, color))
            elif isinstance(self.drawing_item, QGraphicsPathItem):  # Handle Freehand
                path = self.drawing_item.path()
                color = self.drawing_item.pen().color()
                self.annotation_items.append(('freehand', path, color))        

            # Clear the temporary drawing item
            self.drawing_item = None

        # Stop manual dragging and reset cursor to arrow
        self.dragging = False
        self.setCursor(Qt.CursorShape.ArrowCursor)
        
        # Update the mini preview to reflect any changes
        self.update_mini_preview()

        super().mouseReleaseEvent(event)


    def draw_measurement_line_and_label(self, distance_ddmmss):
        """Draw the measurement line and label with the celestial distance."""
        # Draw line
        line_item = QGraphicsLineItem(
            QLineF(self.measurement_start, self.measurement_end)
        )
        line_item.setPen(QPen(QColor(0, 255, 255), 2))  # Cyan color for measurement
        self.parent.main_scene.addItem(line_item)

        # Place distance text at the midpoint of the line
        midpoint = QPointF(
            (self.measurement_start.x() + self.measurement_end.x()) / 2,
            (self.measurement_start.y() + self.measurement_end.y()) / 2
        )
        text_item = QGraphicsTextItem(distance_ddmmss)
        text_item.setDefaultTextColor(QColor(0, 255, 255))  # Same color as line
        text_item.setPos(midpoint)
        self.parent.main_scene.addItem(text_item)
        
        # Append both line and text to annotation_items
        self.annotation_items.append(('line', line_item))
        self.annotation_items.append(('text', midpoint, distance_ddmmss, QColor(0, 255, 255)))


    
    def wheelEvent(self, event):
        """Handle zoom in and out with the mouse wheel."""
        if event.angleDelta().y() > 0:
            self.parent.zoom_in()
        else:
            self.parent.zoom_out()        

    def update_circle(self):
        """Draws the search circle on the main scene if circle_center and circle_radius are set."""
        if self.parent.main_image and self.circle_center is not None and self.circle_radius > 0:
            # Clear the main scene and add the main image back
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)        

                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)

                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)                                
                        
            
            # Draw the search circle
            pen_circle = QPen(QColor(255, 0, 0), 2)
            self.parent.main_scene.addEllipse(
                int(self.circle_center.x() - self.circle_radius),
                int(self.circle_center.y() - self.circle_radius),
                int(self.circle_radius * 2),
                int(self.circle_radius * 2),
                pen_circle
            )
            self.update_mini_preview()
        else:
            # If circle is disabled (e.g., during save), clear without drawing
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

    def delete_selected_object(self):
        if self.selected_object is None:
            self.parent.status_label.setText("No object selected to delete.")
            return

        # Remove the selected object from the results list
        self.parent.results = [obj for obj in self.parent.results if obj != self.selected_object]

        # Remove the corresponding row from the TreeBox
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == self.selected_object["name"]:  # Match the name in the third column
                self.parent.results_tree.takeTopLevelItem(i)
                break

        # Clear the selection
        self.selected_object = None
        self.parent.results_tree.clearSelection()

        # Redraw the main and mini previews without the deleted marker
        self.draw_query_results()
        self.update_mini_preview()

        # Update the status label
        self.parent.status_label.setText("Selected object and marker removed.")



    def scrollContentsBy(self, dx, dy):
        """Called whenever the main preview scrolls, ensuring the green box updates in the mini preview."""
        super().scrollContentsBy(dx, dy)
        self.parent.update_green_box()

    def update_mini_preview(self):
        """Update the mini preview with the current view rectangle and any additional mirrored elements."""
        if self.parent.main_image:
            # Scale the main image to fit in the mini preview
            mini_pixmap = self.parent.main_image.scaled(
                self.parent.mini_preview.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )
            mini_painter = QPainter(mini_pixmap)

            try:
                # Define scale factors based on main image dimensions
                if self.parent.main_image.width() > 0 and self.parent.main_image.height() > 0:
                    scale_factor_x = mini_pixmap.width() / self.parent.main_image.width()
                    scale_factor_y = mini_pixmap.height() / self.parent.main_image.height()

                    # Draw the search circle if it's defined
                    if self.circle_center is not None and self.circle_radius > 0:
                        pen_circle = QPen(QColor(255, 0, 0), 2)
                        mini_painter.setPen(pen_circle)
                        mini_painter.drawEllipse(
                            int(self.circle_center.x() * scale_factor_x - self.circle_radius * scale_factor_x),
                            int(self.circle_center.y() * scale_factor_y - self.circle_radius * scale_factor_y),
                            int(self.circle_radius * 2 * scale_factor_x),
                            int(self.circle_radius * 2 * scale_factor_y)
                        )

                    # Draw the green box representing the current view
                    mini_painter.setPen(QPen(QColor(0, 255, 0), 2))
                    view_rect = self.parent.main_preview.mapToScene(
                        self.parent.main_preview.viewport().rect()
                    ).boundingRect()
                    mini_painter.drawRect(
                        int(view_rect.x() * scale_factor_x),
                        int(view_rect.y() * scale_factor_y),
                        int(view_rect.width() * scale_factor_x),
                        int(view_rect.height() * scale_factor_y)
                    )


                    # Draw dots for each result with a color based on selection status
                    for obj in self.parent.results:
                        ra, dec = obj['ra'], obj['dec']
                        x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                        if x is not None and y is not None:
                            # Change color to green if this is the selected object
                            dot_color = QColor(0, 255, 0) if obj == getattr(self.parent, 'selected_object', None) else QColor(255, 0, 0)
                            mini_painter.setPen(QPen(dot_color, 4))
                            mini_painter.drawPoint(
                                int(x * scale_factor_x),
                                int(y * scale_factor_y)
                            )

                    # Redraw annotation items on the mini preview
                    for item in self.annotation_items:
                        pen = QPen(self.parent.selected_color, 1)  # Use a thinner pen for mini preview
                        mini_painter.setPen(pen)

                        # Interpret item type and draw accordingly
                        if item[0] == 'ellipse':
                            rect = item[1]
                            mini_painter.drawEllipse(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'rect':
                            rect = item[1]
                            mini_painter.drawRect(
                                int(rect.x() * scale_factor_x), int(rect.y() * scale_factor_y),
                                int(rect.width() * scale_factor_x), int(rect.height() * scale_factor_y)
                            )
                        elif item[0] == 'line':
                            line = item[1]
                            mini_painter.drawLine(
                                int(line.x1() * scale_factor_x), int(line.y1() * scale_factor_y),
                                int(line.x2() * scale_factor_x), int(line.y2() * scale_factor_y)
                            )
                        elif item[0] == 'text':
                            text = item[1]            # The text string
                            pos = item[2]             # A QPointF for the position
                            color = item[3]           # The color for the text

                            # Create a smaller font for the mini preview
                            mini_font = QFont(self.parent.selected_font)
                            mini_font.setPointSize(int(self.parent.selected_font.pointSize() * 0.2))  # Scale down font size

                            mini_painter.setFont(mini_font)
                            mini_painter.setPen(color)  # Set the color for the text
                            mini_painter.drawText(
                                int(pos.x() * scale_factor_x), int(pos.y() * scale_factor_y),
                                text
                            )

                        elif item[0] == 'freehand':
                            # Scale the freehand path and draw it
                            path = item[1]
                            scaled_path = QPainterPath()
                            
                            # Scale each point in the path to fit the mini preview
                            for i in range(path.elementCount()):
                                point = path.elementAt(i)
                                if i == 0:
                                    scaled_path.moveTo(point.x * scale_factor_x, point.y * scale_factor_y)
                                else:
                                    scaled_path.lineTo(point.x * scale_factor_x, point.y * scale_factor_y)

                            mini_painter.drawPath(scaled_path)

                        elif item[0] == 'compass':
                            compass = item[1]
                            # Draw the North line
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_line = compass["north_line"]
                            mini_painter.drawLine(
                                int(north_line[0] * scale_factor_x), int(north_line[1] * scale_factor_y),
                                int(north_line[2] * scale_factor_x), int(north_line[3] * scale_factor_y)
                            )

                            # Draw the East line
                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_line = compass["east_line"]
                            mini_painter.drawLine(
                                int(east_line[0] * scale_factor_x), int(east_line[1] * scale_factor_y),
                                int(east_line[2] * scale_factor_x), int(east_line[3] * scale_factor_y)
                            )

                            # Draw North and East labels
                            mini_painter.setPen(QPen(Qt.GlobalColor.red, 1))
                            north_label = compass["north_label"]
                            mini_painter.drawText(
                                int(north_label[0] * scale_factor_x), int(north_label[1] * scale_factor_y), north_label[2]
                            )

                            mini_painter.setPen(QPen(Qt.GlobalColor.blue, 1))
                            east_label = compass["east_label"]
                            mini_painter.drawText(
                                int(east_label[0] * scale_factor_x), int(east_label[1] * scale_factor_y), east_label[2]
                            )                            

            finally:
                mini_painter.end()  # Ensure QPainter is properly ended

            self.parent.mini_preview.setPixmap(mini_pixmap)

    def place_celestial_compass(self, center):
        """Draw a celestial compass at a given point aligned with celestial North and East."""
        compass_radius = 50  # Length of the compass lines

        # Get the orientation in radians (assuming `self.parent.orientation` is in degrees)
        orientation_radians = math.radians(self.parent.orientation)

        # Calculate North vector (upwards, adjusted for orientation)
        north_dx = math.sin(orientation_radians) * compass_radius
        north_dy = -math.cos(orientation_radians) * compass_radius

        # Calculate East vector (rightwards, adjusted for orientation)
        east_dx = math.cos(orientation_radians) * -compass_radius
        east_dy = math.sin(orientation_radians) * -compass_radius

        # Draw North line
        north_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + north_dx, center.y() + north_dy
        )
        north_line.setPen(QPen(Qt.GlobalColor.red, 2))
        self.parent.main_scene.addItem(north_line)

        # Draw East line
        east_line = QGraphicsLineItem(
            center.x(), center.y(),
            center.x() + east_dx, center.y() + east_dy
        )
        east_line.setPen(QPen(Qt.GlobalColor.blue, 2))
        self.parent.main_scene.addItem(east_line)

        # Add labels for North and East
        text_north = QGraphicsTextItem("N")
        text_north.setDefaultTextColor(Qt.GlobalColor.red)
        text_north.setPos(center.x() + north_dx - 10, center.y() + north_dy - 10)
        self.parent.main_scene.addItem(text_north)

        text_east = QGraphicsTextItem("E")
        text_east.setDefaultTextColor(Qt.GlobalColor.blue)
        text_east.setPos(center.x() + east_dx - 15, center.y() + east_dy - 10)
        self.parent.main_scene.addItem(text_east)

        # Append all compass components as a tuple to annotation_items for later redrawing
        self.annotation_items.append((
            "compass", {
                "center": center,
                "north_line": (center.x(), center.y(), center.x() + north_dx, center.y() + north_dy),
                "east_line": (center.x(), center.y(), center.x() + east_dx, center.y() + east_dy),
                "north_label": (center.x() + north_dx - 10, center.y() + north_dy - 10, "N"),
                "east_label": (center.x() + east_dx - 15, center.y() + east_dy - 10, "E"),
                "orientation": self.parent.orientation
            }
        ))

    def zoom_to_coordinates(self, ra, dec):
        """Zoom to the specified RA/Dec coordinates and center the view on that position."""
        # Calculate the pixel position from RA and Dec
        pixel_x, pixel_y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
        
        if pixel_x is not None and pixel_y is not None:
            # Center the view on the calculated pixel position
            self.centerOn(pixel_x, pixel_y)
            
            # Reset the zoom level to 1.0 by adjusting the transformation matrix
            self.resetTransform()
            self.scale(1.0, 1.0)

            # Optionally, update the mini preview to reflect the new zoom and center
            self.update_mini_preview()

    def draw_query_results(self):
        """Draw query results with or without names based on the show_names setting."""
        if self.parent.main_image:
            # Clear the main scene and re-add the main image
            self.parent.main_scene.clear()
            self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw all shapes and annotations from stored properties
            for item in self.annotation_items:
                if item[0] == 'ellipse':
                    rect = item[1]
                    color = item[2]
                    ellipse = QGraphicsEllipseItem(rect)
                    ellipse.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(ellipse)
                elif item[0] == 'rect':
                    rect = item[1]
                    color = item[2]
                    rect_item = QGraphicsRectItem(rect)
                    rect_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(rect_item)
                elif item[0] == 'line':
                    line = item[1]
                    color = item[2]
                    line_item = QGraphicsLineItem(line)
                    line_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(line_item)
                elif item[0] == 'text':
                    text = item[1]            # The text string
                    pos = item[2]             # A QPointF for the position
                    color = item[3]           # The color for the text

                    text_item = QGraphicsTextItem(text)
                    text_item.setPos(pos)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)

                elif item[0] == 'freehand':  # Redraw Freehand
                    path = item[1]
                    color = item[2]
                    freehand_item = QGraphicsPathItem(path)
                    freehand_item.setPen(QPen(color, 2))
                    self.parent.main_scene.addItem(freehand_item)                      
                elif item[0] == 'measurement':  # Redraw celestial measurement line
                    line = item[1]
                    color = item[2]
                    text_position = item[3]
                    distance_text = item[4]
                    
                    # Draw the measurement line
                    measurement_line_item = QGraphicsLineItem(line)
                    measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                    self.parent.main_scene.addItem(measurement_line_item)
                    
                    # Draw the distance text label
                    text_item = QGraphicsTextItem(distance_text)
                    text_item.setPos(text_position)
                    text_item.setDefaultTextColor(color)
                    text_item.setFont(self.parent.selected_font)
                    self.parent.main_scene.addItem(text_item)        
                elif item[0] == 'compass':
                    compass = item[1]
                    # North Line
                    north_line_coords = compass['north_line']
                    north_line_item = QGraphicsLineItem(
                        north_line_coords[0], north_line_coords[1], north_line_coords[2], north_line_coords[3]
                    )
                    north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                    self.parent.main_scene.addItem(north_line_item)
                    
                    # East Line
                    east_line_coords = compass['east_line']
                    east_line_item = QGraphicsLineItem(
                        east_line_coords[0], east_line_coords[1], east_line_coords[2], east_line_coords[3]
                    )
                    east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                    self.parent.main_scene.addItem(east_line_item)
                    
                    # North Label
                    text_north = QGraphicsTextItem(compass['north_label'][2])
                    text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                    text_north.setDefaultTextColor(Qt.GlobalColor.red)
                    self.parent.main_scene.addItem(text_north)
                    
                    # East Label
                    text_east = QGraphicsTextItem(compass['east_label'][2])
                    text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                    text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                    self.parent.main_scene.addItem(text_east)                               
            # Ensure the search circle is drawn if circle data is available
            #if self.circle_center is not None and self.circle_radius > 0:
            #    self.update_circle()

            # Draw object markers (circle or crosshair)
            for obj in self.parent.results:
                ra, dec, name = obj["ra"], obj["dec"], obj["name"]
                x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
                if x is not None and y is not None:
                    # Determine color: green if selected, red otherwise
                    base_color = obj["color"]
                    pen_color  = QColor(0,255,0) if obj is self.selected_object else base_color
                    pen = QPen(pen_color, 2)

                    if self.parent.marker_style == "Circle":
                        # Draw a circle around the object
                        self.parent.main_scene.addEllipse(int(x - 5), int(y - 5), 10, 10, pen)
                    elif self.parent.marker_style == "Crosshair":
                        # Draw crosshair with a 5-pixel gap in the middle
                        crosshair_size = 10
                        gap = 5
                        line1 = QLineF(x - crosshair_size, y, x - gap, y)
                        line2 = QLineF(x + gap, y, x + crosshair_size, y)
                        line3 = QLineF(x, y - crosshair_size, x, y - gap)
                        line4 = QLineF(x, y + gap, x, y + crosshair_size)
                        for line in [line1, line2, line3, line4]:
                            crosshair_item = QGraphicsLineItem(line)
                            crosshair_item.setPen(pen)
                            self.parent.main_scene.addItem(crosshair_item)
                    if self.parent.show_names:
                        #print(f"Drawing name: {name} at ({x}, {y})")  # Debugging statement
                        text_color = obj.get("color", QColor(Qt.GlobalColor.white))
                        text_item = QGraphicsTextItem(name)
                        text_item.setPos(x + 10, y + 10)  # Offset to avoid overlapping the marker
                        text_item.setDefaultTextColor(text_color)
                        text_item.setFont(self.parent.selected_font)
                        self.parent.main_scene.addItem(text_item)                            
    

    def clear_query_results(self):
        """Clear query markers from the main image without removing annotations."""
        # Clear the main scene and add the main image back
        self.parent.main_scene.clear()
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)
        
        # Redraw the stored annotation items
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item)  
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)       
            elif item[0] == 'compass':
                compass = item[1]
                # North line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                # East line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                # North label
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                # East label
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)
        
        # Update the circle data, if any
        self.parent.update_circle_data()
                        

    def set_query_results(self, results):
        """Store results, assign each object a category & color, then redraw."""
        self.parent.results = results

        for obj in self.parent.results:
            # use the same key you populated in MainWindow.query_simbad
            short_type = obj.get("short_type", "")
            category   = OTYPE_TO_CATEGORY.get(short_type, "Errors & Artefacts")
            obj["category"] = category

            # lookup the QColor for that category (fallback to white)
            obj["color"]    = CATEGORY_TO_COLOR.get(category, QColor(255,255,255))

        self.draw_query_results()

    def get_object_at_position(self, pos):
        """Find the object at the given position in the main preview."""
        for obj in self.parent.results:
            ra, dec = obj["ra"], obj["dec"]
            x, y = self.parent.calculate_pixel_from_ra_dec(ra, dec)
            if x is not None and y is not None:
                if abs(pos.x() - x) <= 5 and abs(pos.y() - y) <= 5:
                    return obj
        return None


    def select_object(self, selected_obj):
        """Select or deselect the specified object and update visuals."""
        self.selected_object = selected_obj if self.selected_object != selected_obj else None
        self.draw_query_results()  # Redraw to reflect selection

        # Update the TreeWidget selection in MainWindow
        for i in range(self.parent.results_tree.topLevelItemCount()):
            item = self.parent.results_tree.topLevelItem(i)
            if item.text(2) == selected_obj["name"]:  # Assuming 'name' is the unique identifier
                self.parent.results_tree.setCurrentItem(item if self.selected_object else None)
                break

    def undo_annotation(self):
        """Remove the last annotation item from the scene and annotation_items list."""
        if self.annotation_items:
            # Remove the last item from annotation_items
            self.annotation_items.pop()

            # Clear the scene and redraw all annotations except the last one
            self.parent.main_scene.clear()
            if self.parent.main_image:
                self.parent.main_scene.addPixmap(self.parent.main_image)

            # Redraw remaining annotations
            self.redraw_annotations()

            # Optionally, update the mini preview to reflect changes
            self.update_mini_preview()

    def clear_annotations(self):
        """Clear all annotation items from the scene and annotation_items list."""
        # Clear all items in annotation_items and update the scene
        self.annotation_items.clear()
        self.parent.main_scene.clear()
        
        # Redraw only the main image
        if self.parent.main_image:
            self.parent.main_scene.addPixmap(self.parent.main_image)

        # Optionally, update the mini preview to reflect changes
        self.update_mini_preview()

    def redraw_annotations(self):
        """Helper function to redraw all annotations from annotation_items."""
        for item in self.annotation_items:
            if item[0] == 'ellipse':
                rect = item[1]
                color = item[2]
                ellipse = QGraphicsEllipseItem(rect)
                ellipse.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(ellipse)
            elif item[0] == 'rect':
                rect = item[1]
                color = item[2]
                rect_item = QGraphicsRectItem(rect)
                rect_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(rect_item)
            elif item[0] == 'line':
                line = item[1]
                color = item[2]
                line_item = QGraphicsLineItem(line)
                line_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(line_item)
            elif item[0] == 'text':
                text = item[1]            # The text string
                pos = item[2]             # A QPointF for the position
                color = item[3]           # The color for the text

                text_item = QGraphicsTextItem(text)
                text_item.setPos(pos)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)

            elif item[0] == 'freehand':  # Redraw Freehand
                path = item[1]
                color = item[2]
                freehand_item = QGraphicsPathItem(path)
                freehand_item.setPen(QPen(color, 2))
                self.parent.main_scene.addItem(freehand_item) 
            elif item[0] == 'measurement':  # Redraw celestial measurement line
                line = item[1]
                color = item[2]
                text_position = item[3]
                distance_text = item[4]
                
                # Draw the measurement line
                measurement_line_item = QGraphicsLineItem(line)
                measurement_line_item.setPen(QPen(color, 2, Qt.PenStyle.DashLine))  # Dashed line for measurement
                self.parent.main_scene.addItem(measurement_line_item)
                
                # Draw the distance text label
                text_item = QGraphicsTextItem(distance_text)
                text_item.setPos(text_position)
                text_item.setDefaultTextColor(color)
                text_item.setFont(self.parent.selected_font)
                self.parent.main_scene.addItem(text_item)                                        
            elif item[0] == 'compass':
                compass = item[1]
                # Redraw north line
                north_line_item = QGraphicsLineItem(
                    compass['north_line'][0], compass['north_line'][1],
                    compass['north_line'][2], compass['north_line'][3]
                )
                north_line_item.setPen(QPen(Qt.GlobalColor.red, 2))
                self.parent.main_scene.addItem(north_line_item)
                
                # Redraw east line
                east_line_item = QGraphicsLineItem(
                    compass['east_line'][0], compass['east_line'][1],
                    compass['east_line'][2], compass['east_line'][3]
                )
                east_line_item.setPen(QPen(Qt.GlobalColor.blue, 2))
                self.parent.main_scene.addItem(east_line_item)
                
                # Redraw labels
                text_north = QGraphicsTextItem(compass['north_label'][2])
                text_north.setPos(compass['north_label'][0], compass['north_label'][1])
                text_north.setDefaultTextColor(Qt.GlobalColor.red)
                self.parent.main_scene.addItem(text_north)
                
                text_east = QGraphicsTextItem(compass['east_label'][2])
                text_east.setPos(compass['east_label'][0], compass['east_label'][1])
                text_east.setDefaultTextColor(Qt.GlobalColor.blue)
                self.parent.main_scene.addItem(text_east)        

class ThreeDSettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("3D Model Settings")
        layout = QVBoxLayout(self)

        # Image Plane Style
        layout.addWidget(QLabel("Image Plane Style:"))
        self.plane_style_cb = QComboBox()
        self.plane_style_cb.addItems([
            "Mesh RGB Scatter Plane",
            "Smooth Grayscale Image Plane"
        ])
        layout.addWidget(self.plane_style_cb)

        # Resolution
        res_layout = QHBoxLayout()
        res_layout.addWidget(QLabel("Resolution:"))
        self.res_spin = QSpinBox()
        self.res_spin.setRange(50, 2000)
        self.res_spin.setSingleStep(50)
        self.res_spin.setValue(500)
        res_layout.addWidget(self.res_spin)
        layout.addLayout(res_layout)

        # Z-Axis Range Options (Min-Max/Custom as before)
        layout.addWidget(QLabel("Z-Axis Range:"))
        self.zaxis_cb = QComboBox()
        self.zaxis_cb.addItems(["Default", "Min-Max", "Custom"])
        layout.addWidget(self.zaxis_cb)

        self.custom_widget = QWidget()
        cl = QHBoxLayout(self.custom_widget)
        cl.addWidget(QLabel("Min:"))
        self.zmin_spin = QDoubleSpinBox()
        self.zmin_spin.setRange(-1e6, 1e6)
        self.zmin_spin.setValue(0.0)
        cl.addWidget(self.zmin_spin)
        cl.addWidget(QLabel("Max:"))
        self.zmax_spin = QDoubleSpinBox()
        self.zmax_spin.setRange(-1e6, 1e6)
        self.zmax_spin.setValue(10.0)
        cl.addWidget(self.zmax_spin)
        layout.addWidget(self.custom_widget)
        self.custom_widget.setVisible(False)
        self.zaxis_cb.currentIndexChanged.connect(
            lambda idx: self.custom_widget.setVisible(self.zaxis_cb.currentText() == "Custom")
        )

        # Z-Axis Scale: Log vs Linear
        layout.addWidget(QLabel("Z-Axis Scale:"))
        self.zscale_cb = QComboBox()
        self.zscale_cb.addItems(["Logarithmic", "Linear"])
        layout.addWidget(self.zscale_cb)

        # Linear max input
        self.linear_widget = QWidget()
        ll = QHBoxLayout(self.linear_widget)
        ll.addWidget(QLabel("Linear Z-Max:"))
        self.linear_max_spin = QDoubleSpinBox()
        self.linear_max_spin.setRange(0.1, 1e12)
        self.linear_max_spin.setValue(1e4)
        ll.addWidget(self.linear_max_spin)
        layout.addWidget(self.linear_widget)
        self.linear_widget.setVisible(False)
        self.zscale_cb.currentIndexChanged.connect(
            lambda idx: self.linear_widget.setVisible(self.zscale_cb.currentText() == "Linear")
        )

        self.reverse_cb = QCheckBox("Reverse Z-Axis")
        self.reverse_cb.setChecked(False)
        layout.addWidget(self.reverse_cb)

        # Object Color
        layout.addWidget(QLabel("Object Color:"))
        self.color_cb = QComboBox()
        self.color_cb.addItems(["Image-Based", "Legend Color", "Solid (Custom)"])
        layout.addWidget(self.color_cb)

        self.color_btn = QPushButton("Choose Color…")
        self.custom_color = QColor(255, 0, 0)
        self.color_btn.setVisible(False)
        layout.addWidget(self.color_btn)
        self.color_btn.clicked.connect(self._choose_color)
        self.color_cb.currentIndexChanged.connect(
            lambda idx: self.color_btn.setVisible(self.color_cb.currentText() == "Solid (Custom)")
        )

        # Z-Axis Height control
        layout.addWidget(QLabel("Z-Axis Height (aspect ratio z):"))
        self.zheight_spin = QDoubleSpinBox()
        self.zheight_spin.setRange(0.1, 10.0)
        self.zheight_spin.setSingleStep(0.1)
        self.zheight_spin.setValue(0.5)
        layout.addWidget(self.zheight_spin)

        # ─── Show Connector Lines ─────────────────────────────
        self.lines_cb = QCheckBox("Show Connector Lines")
        self.lines_cb.setChecked(True)
        layout.addWidget(self.lines_cb)

        # OK / Cancel
        btns = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok |
                                QDialogButtonBox.StandardButton.Cancel)
        btns.accepted.connect(self.accept)
        btns.rejected.connect(self.reject)
        layout.addWidget(btns)

    def _choose_color(self):
        col = QColorDialog.getColor(self.custom_color, self, "Select Object Color")
        if col.isValid():
            self.custom_color = col

    def getSettings(self):
        if self.exec() == QDialog.DialogCode.Accepted:
            return {
                "plane_style": self.plane_style_cb.currentText(),
                "resolution": self.res_spin.value(),
                "z_option":   self.zaxis_cb.currentText(),
                "z_min":      self.zmin_spin.value(),
                "z_max":      self.zmax_spin.value(),
                "z_scale":    self.zscale_cb.currentText(),
                "linear_max": self.linear_max_spin.value(),
                "object_color": self.color_cb.currentText(),
                "custom_color": self.custom_color,      # QColor
                "z_height":   self.zheight_spin.value(),
                "show_lines": self.lines_cb.isChecked(),
                "reverse_z":   self.reverse_cb.isChecked(),
            }
        return None

class HRSettingsDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("H-R Diagram Settings")
        layout = QVBoxLayout(self)

        # 1) Star Color Mode
        layout.addWidget(QLabel("Star Color Mode:"))
        self.color_mode_cb = QComboBox()
        self.color_mode_cb.addItems(["Realistic (blackbody)", "Solid (Custom)"])
        layout.addWidget(self.color_mode_cb)

        self.color_btn = QPushButton("Choose Solid Color…")
        self.custom_color = QColor(255, 255, 255)
        self.color_btn.setVisible(False)
        layout.addWidget(self.color_btn)
        self.color_btn.clicked.connect(self._choose_color)
        self.color_mode_cb.currentIndexChanged.connect(
            lambda idx: self.color_btn.setVisible(
                self.color_mode_cb.currentText().startswith("Solid")
            )
        )

        # 2) Background Choice
        layout.addWidget(QLabel("Background:"))
        self.bg_mode_cb = QComboBox()
        self.bg_mode_cb.addItems(["HR Diagram Image", "Solid Black"])
        layout.addWidget(self.bg_mode_cb)

        # 3) Axis Range Mode
        layout.addWidget(QLabel("Axis Range:"))
        self.range_mode_cb = QComboBox()
        self.range_mode_cb.addItems(["Default (–0.3→2.25, –9→19)", "Custom"])
        layout.addWidget(self.range_mode_cb)

        self.custom_range_widget = QWidget()
        cr_layout = QHBoxLayout(self.custom_range_widget)
        cr_layout.addWidget(QLabel("X Min:"))
        self.xmin_spin = QDoubleSpinBox()
        self.xmin_spin.setRange(-10.0, 10.0)
        self.xmin_spin.setDecimals(3)
        self.xmin_spin.setValue(-0.3)
        cr_layout.addWidget(self.xmin_spin)

        cr_layout.addWidget(QLabel("X Max:"))
        self.xmax_spin = QDoubleSpinBox()
        self.xmax_spin.setRange(-10.0, 10.0)
        self.xmax_spin.setDecimals(3)
        self.xmax_spin.setValue(2.25)
        cr_layout.addWidget(self.xmax_spin)

        cr_layout.addWidget(QLabel("Y Min:"))
        self.ymin_spin = QDoubleSpinBox()
        self.ymin_spin.setRange(-50.0, 50.0)
        self.ymin_spin.setDecimals(3)
        self.ymin_spin.setValue(-9.0)
        cr_layout.addWidget(self.ymin_spin)

        cr_layout.addWidget(QLabel("Y Max:"))
        self.ymax_spin = QDoubleSpinBox()
        self.ymax_spin.setRange(-50.0, 50.0)
        self.ymax_spin.setDecimals(3)
        self.ymax_spin.setValue(19.0)
        cr_layout.addWidget(self.ymax_spin)

        layout.addWidget(self.custom_range_widget)
        self.custom_range_widget.setVisible(False)
        self.range_mode_cb.currentIndexChanged.connect(
            lambda idx: self.custom_range_widget.setVisible(
                self.range_mode_cb.currentText().startswith("Custom")
            )
        )

        layout.addWidget(QLabel("Show Sun:"))
        self.show_sun_cb = QCheckBox("Include Sun on diagram")
        self.show_sun_cb.setChecked(True)       # default ON
        layout.addWidget(self.show_sun_cb)

        # 4) OK / Cancel Buttons
        btns = QDialogButtonBox(
            QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel
        )
        btns.accepted.connect(self.accept)
        btns.rejected.connect(self.reject)
        layout.addWidget(btns)

    def _choose_color(self):
        col = QColorDialog.getColor(self.custom_color, self, "Select Marker Color")
        if col.isValid():
            self.custom_color = col

    def getSettings(self):
        """
        Pops up the dialog. Returns a dict:
        {
            "color_mode":    "Realistic (blackbody)" or "Solid (Custom)",
            "custom_color":  QColor,
            "bg_mode":       "HR Diagram Image" or "Solid Black",
            "range_mode":    "Default" or "Custom",
            "x_min":         float,
            "x_max":         float,
            "y_min":         float,
            "y_max":         float
        }
        or None if the user canceled.
        """
        if self.exec() == QDialog.DialogCode.Accepted:
            return {
                "color_mode": self.color_mode_cb.currentText(),
                "custom_color": self.custom_color,
                "bg_mode": self.bg_mode_cb.currentText(),
                "range_mode": self.range_mode_cb.currentText(),
                "x_min": self.xmin_spin.value(),
                "x_max": self.xmax_spin.value(),
                "y_min": self.ymin_spin.value(),
                "y_max": self.ymax_spin.value(),
                "show_sun":      self.show_sun_cb.isChecked(),
            }
        return None

class LegendDialog(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Object Type Legend")
        self.swatches = {}
        layout = QVBoxLayout(self)

        # Build one row per category
        for category, color in CATEGORY_TO_COLOR.items():
            row = QHBoxLayout()

            # color swatch
            swatch = QLabel()
            swatch.setFixedSize(16, 16)
            swatch.setStyleSheet(f"background-color: {color.name()}; border:1px solid #000;")
            row.addWidget(swatch)
            self.swatches[category] = swatch

            # category name
            row.addWidget(QLabel(category))

            # edit‐color button
            btn = QPushButton("Edit…")
            btn.clicked.connect(lambda _, cat=category: self.change_color(cat))
            row.addWidget(btn)

            row.addStretch()
            layout.addLayout(row)

        # OK / Cancel buttons
        btn_row = QHBoxLayout()
        ok = QPushButton("OK")
        ok.clicked.connect(self.accept)
        cancel = QPushButton("Cancel")
        cancel.clicked.connect(self.reject)
        btn_row.addStretch()
        btn_row.addWidget(ok)
        btn_row.addWidget(cancel)
        layout.addLayout(btn_row)

    def change_color(self, category):
        """Open a QColorDialog, update the swatch and CATEGORY_TO_COLOR."""
        initial = CATEGORY_TO_COLOR[category]
        c = QColorDialog.getColor(initial, self, f"Select color for {category}")
        if c.isValid():
            CATEGORY_TO_COLOR[category] = c
            sw = self.swatches[category]
            sw.setStyleSheet(f"background-color: {c.name()}; border:1px solid #000;")

def kelvin_to_rgb(T):
    """Approximate conversion from black‐body temperature (K) to sRGB tuple."""
    # based on Tanner Helland's approximation
    # Clamp input
    T = max(1000, min(T, 40000)) / 100.0
    # red
    if T <= 66:
        r = 255
    else:
        r = 329.698727446 * ((T - 60) ** -0.1332047592)
    # green
    if T <= 66:
        g = 99.4708025861 * math.log(T) - 161.1195681661
    else:
        g = 288.1221695283 * ((T - 60) ** -0.0755148492)
    # blue
    if T >= 66:
        b = 255
    elif T <= 19:
        b = 0
    else:
        b = 138.5177312231 * math.log(T - 10) - 305.0447927307

    # clamp and return CSS‐style rgb()
    def clamp(x): return int(max(0, min(x, 255)))
    return f"rgb({clamp(r)},{clamp(g)},{clamp(b)})"

class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("What's In My Image")
        #self.setGeometry(100, 100, 800, 600)
        # Track the theme status
        self.is_dark_mode = True
        self.metadata = {}
        self.circle_center = None
        self.circle_radius = 0    
        self.show_names = False  # Boolean to toggle showing names on the main image
        self.max_results = 100  # Default maximum number of query results     
        self.current_tool = None  # Track the active annotation tool
        self.header = Header()
        self.marker_style = "Circle" 
        self.settings = QSettings() 
            

        main_layout = QHBoxLayout()

        # Left Column Layout
        left_panel = QVBoxLayout()

        # Load the image using the resource_path function
        wimilogo_path = resource_path("wimilogo.png")

        # Create a QLabel to display the logo
        self.logo_label = QLabel()

        # Set the logo image to the label
        logo_pixmap = QPixmap(wimilogo_path)

        # Scale the pixmap to fit within a desired size, maintaining the aspect ratio
        scaled_pixmap = logo_pixmap.scaled(100, 50, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)

        # Set the scaled pixmap to the label
        self.logo_label.setPixmap(scaled_pixmap)

        # Set alignment to center the logo horizontally
        self.logo_label.setAlignment(Qt.AlignmentFlag.AlignCenter)

        # Optionally, you can set a fixed size for the label (this is for layout purposes)
        #self.logo_label.setFixedSize(200, 100)  # Adjust the size as needed

        # Add the logo_label to your layout
        left_panel.addWidget(self.logo_label)
       
        button_layout = QHBoxLayout()
        
        # Load button
        self.load_button = QPushButton("Load Image")
        self.load_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogStart))
        self.load_button.clicked.connect(self.open_image)

        # AutoStretch button
        self.auto_stretch_button = QPushButton("AutoStretch")
        self.auto_stretch_button.clicked.connect(self.toggle_autostretch)

        # Add both buttons to the horizontal layout
        button_layout.addWidget(self.load_button)
        button_layout.addWidget(self.auto_stretch_button)

        # Add the button layout to the left panel
        left_panel.addLayout(button_layout)

        # Create the instruction QLabel for search region
        search_region_instruction_label = QLabel("Shift+Click to define a search region")
        search_region_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        search_region_instruction_label.setStyleSheet("font-size: 15px; color: gray;")

        # Add this QLabel to your layout at the appropriate position above RA/Dec
        left_panel.addWidget(search_region_instruction_label)  



        # Query Simbad button
        self.query_button = QPushButton("Query Simbad")
        self.query_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogApplyButton))
        left_panel.addWidget(self.query_button)
        self.query_button.clicked.connect(lambda: self.query_simbad(self.get_defined_radius()))

        self.legend_button = QPushButton("Legend")
        self.legend_button.clicked.connect(self.show_legend)
        left_panel.addWidget(self.legend_button)

        # Create a horizontal layout for the show names checkbox and clear results button
        show_clear_layout = QHBoxLayout()

        # Create the Show Object Names checkbox
        self.show_names_checkbox = QCheckBox("Show Object Names")
        self.show_names_checkbox.stateChanged.connect(self.toggle_object_names)  # Connect to a function to toggle names
        show_clear_layout.addWidget(self.show_names_checkbox)

        # Create the Clear Results button
        self.clear_results_button = QPushButton("Clear Results")
        self.clear_results_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))
        self.clear_results_button.clicked.connect(self.clear_search_results)  # Connect to a function to clear results
        show_clear_layout.addWidget(self.clear_results_button)

        # Add this horizontal layout to the left panel layout (or wherever you want it to appear)
        left_panel.addLayout(show_clear_layout)   

        # Create a horizontal layout for the two buttons
        button_layout = QHBoxLayout()

        # Show Visible Objects Only button
        self.toggle_visible_objects_button = QPushButton("Show Visible Objects Only")
        self.toggle_visible_objects_button.setCheckable(True)  # Toggle button state
        self.toggle_visible_objects_button.setIcon(QIcon(eye_icon_path))
        self.toggle_visible_objects_button.clicked.connect(self.filter_visible_objects)
        self.toggle_visible_objects_button.setToolTip("Toggle the visibility of objects based on brightness.")
        button_layout.addWidget(self.toggle_visible_objects_button)

        # Save CSV button
        self.save_csv_button = QPushButton("Save CSV")
        self.save_csv_button.setIcon(QIcon(csv_icon_path))
        self.save_csv_button.clicked.connect(self.save_results_as_csv)
        button_layout.addWidget(self.save_csv_button)

        # Add the button layout to the left panel or main layout
        left_panel.addLayout(button_layout)  

        # Advanced Search Button
        self.advanced_search_button = QPushButton("Advanced Search")
        self.advanced_search_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_FileDialogDetailedView))
        self.advanced_search_button.setCheckable(True)
        self.advanced_search_button.clicked.connect(self.toggle_advanced_search)
        left_panel.addWidget(self.advanced_search_button)

        # Advanced Search Panel (initially hidden)
        self.advanced_search_panel = QVBoxLayout()
        self.advanced_search_panel_widget = QWidget()
        self.advanced_search_panel_widget.setLayout(self.advanced_search_panel)
        self.advanced_search_panel_widget.setFixedWidth(300)
        self.advanced_search_panel_widget.setVisible(False)  # Hide initially        

        # Status label
        self.status_label = QLabel("Status: Ready")
        left_panel.addWidget(self.status_label)

        # Create a horizontal layout
        button_layout = QHBoxLayout()

        # Copy RA/Dec to Clipboard button
        self.copy_button = QPushButton("Copy RA/Dec to Clipboard", self)
        self.copy_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_CommandLink))
        self.copy_button.clicked.connect(self.copy_ra_dec_to_clipboard)
        button_layout.addWidget(self.copy_button)

        # Settings button (wrench icon)
        self.settings_button = QPushButton()
        self.settings_button.setIcon(QIcon(wrench_path))  # Adjust icon path as needed
        self.settings_button.clicked.connect(self.open_settings_dialog)
        button_layout.addWidget(self.settings_button)

        # Add the horizontal layout to the main layout or the desired parent layout
        left_panel.addLayout(button_layout)
        
         # Save Plate Solved Fits Button
        self.save_plate_solved_button = QPushButton("Save Plate Solved Fits")
        self.save_plate_solved_button.setIcon(QIcon(disk_icon_path))
        self.save_plate_solved_button.clicked.connect(self.save_plate_solved_fits)
        left_panel.addWidget(self.save_plate_solved_button)       

        # RA/Dec Labels
        ra_dec_layout = QHBoxLayout()
        self.ra_label = QLabel("RA: N/A")
        self.dec_label = QLabel("Dec: N/A")
        self.orientation_label = QLabel("Orientation: N/A°")
        ra_dec_layout.addWidget(self.ra_label)
        ra_dec_layout.addWidget(self.dec_label)
        ra_dec_layout.addWidget(self.orientation_label)
        left_panel.addLayout(ra_dec_layout)

        # Mini Preview
        self.mini_preview = QLabel("Mini Preview")
        self.mini_preview.setMaximumSize(300, 300)
        self.mini_preview.mousePressEvent = self.on_mini_preview_press
        self.mini_preview.mouseMoveEvent = self.on_mini_preview_drag
        self.mini_preview.mouseReleaseEvent = self.on_mini_preview_release
        left_panel.addWidget(self.mini_preview)

  


        # Right Column Layout
        right_panel = QVBoxLayout()

        # Zoom buttons above the main preview
        zoom_controls_layout = QHBoxLayout()
        self.zoom_in_button = QPushButton("Zoom In")
        self.zoom_in_button.clicked.connect(self.zoom_in)
        self.zoom_out_button = QPushButton("Zoom Out")
        self.zoom_out_button.clicked.connect(self.zoom_out)
        zoom_controls_layout.addWidget(self.zoom_in_button)
        zoom_controls_layout.addWidget(self.zoom_out_button)
        right_panel.addLayout(zoom_controls_layout)        

        # Main Preview
        self.main_preview = CustomGraphicsView(self)
        self.main_scene = QGraphicsScene(self.main_preview)
        self.main_preview.setScene(self.main_scene)
        self.main_preview.setRenderHint(QPainter.RenderHint.Antialiasing)
        self.main_preview.setTransformationAnchor(QGraphicsView.ViewportAnchor.AnchorUnderMouse)
        right_panel.addWidget(self.main_preview)

        # Save Annotated Image and Save Collage of Objects Buttons in a Horizontal Layout between main image and treebox
        save_buttons_layout = QHBoxLayout()

        # Button to toggle annotation tools section
        self.show_annotations_button = QPushButton("Show Annotation Tools")
        self.show_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogResetButton))
        self.show_annotations_button.clicked.connect(self.toggle_annotation_tools)
        save_buttons_layout.addWidget(self.show_annotations_button)
        
        self.save_annotated_button = QPushButton("Save Annotated Image")
        self.save_annotated_button.setIcon(QIcon(annotated_path))
        self.save_annotated_button.clicked.connect(self.save_annotated_image)
        save_buttons_layout.addWidget(self.save_annotated_button)
        
        self.save_collage_button = QPushButton("Save Collage of Objects")
        self.save_collage_button.setIcon(QIcon(collage_path))
        self.save_collage_button.clicked.connect(self.save_collage_of_objects)
        save_buttons_layout.addWidget(self.save_collage_button)

        # New 3D View Button
        self.show_3d_view_button = QPushButton("3D Distance Model")
        self.show_3d_view_button.clicked.connect(self.show_3d_model_view)
        self.show_3d_view_button.setIcon(    QApplication.style().standardIcon(QStyle.StandardPixmap.SP_TitleBarNormalButton))
        save_buttons_layout.addWidget(self.show_3d_view_button)

        self.show_hr_button = QPushButton("H-R Diagram")
        # Optionally give it an icon:
        self.show_hr_button.setIcon(QApplication.style().standardIcon(
            QStyle.StandardPixmap.SP_DesktopIcon))
        self.show_hr_button.clicked.connect(self.show_hr_diagram)
        save_buttons_layout.addWidget(self.show_hr_button)

        right_panel.addLayout(save_buttons_layout)        

        # Connect scroll events to update the green box in the mini preview
        self.main_preview.verticalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)
        self.main_preview.horizontalScrollBar().valueChanged.connect(self.main_preview.update_mini_preview)

        # Create a horizontal layout for the labels
        label_layout = QHBoxLayout()

        # Create the label to display the count of objects
        self.object_count_label = QLabel("Objects Found: 0")

        # Create the label with instructions
        self.instructions_label = QLabel("Right Click a Row for More Options")

        # Add both labels to the horizontal layout
        label_layout.addWidget(self.object_count_label)
        label_layout.addWidget(self.instructions_label)

        # Add the horizontal layout to the main panel layout
        right_panel.addLayout(label_layout)

        self.results_tree = QTreeWidget()
        self.results_tree.setHeaderLabels(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])
        self.results_tree.setFixedHeight(150)
        self.results_tree.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
        self.results_tree.customContextMenuRequested.connect(self.open_context_menu)
        self.results_tree.itemClicked.connect(self.on_tree_item_clicked)
        self.results_tree.itemDoubleClicked.connect(self.on_tree_item_double_clicked)
        self.results_tree.setSortingEnabled(True)
        right_panel.addWidget(self.results_tree)

        self.annotation_buttons = []

        # Annotation Tools Section (initially hidden)
        self.annotation_tools_section = QWidget()
        annotation_tools_layout = QGridLayout(self.annotation_tools_section)

        annotation_instruction_label = QLabel("Ctrl+Click to add items, Alt+Click to measure distance")
        annotation_instruction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        annotation_instruction_label.setStyleSheet("font-size: 10px; color: gray;")        

        self.draw_ellipse_button = QPushButton("Draw Ellipse")
        self.draw_ellipse_button.tool_name = "Ellipse"
        self.draw_ellipse_button.clicked.connect(lambda: self.set_tool("Ellipse"))
        self.annotation_buttons.append(self.draw_ellipse_button)

        self.freehand_button = QPushButton("Freehand (Lasso)")
        self.freehand_button.tool_name = "Freehand"
        self.freehand_button.clicked.connect(lambda: self.set_tool("Freehand"))
        self.annotation_buttons.append(self.freehand_button)

        self.draw_rectangle_button = QPushButton("Draw Rectangle")
        self.draw_rectangle_button.tool_name = "Rectangle"
        self.draw_rectangle_button.clicked.connect(lambda: self.set_tool("Rectangle"))
        self.annotation_buttons.append(self.draw_rectangle_button)

        self.draw_arrow_button = QPushButton("Draw Arrow")
        self.draw_arrow_button.tool_name = "Arrow"
        self.draw_arrow_button.clicked.connect(lambda: self.set_tool("Arrow"))
        self.annotation_buttons.append(self.draw_arrow_button)

        self.place_compass_button = QPushButton("Place Celestial Compass")
        self.place_compass_button.tool_name = "Compass"
        self.place_compass_button.clicked.connect(lambda: self.set_tool("Compass"))
        self.annotation_buttons.append(self.place_compass_button)

        self.add_text_button = QPushButton("Add Text")
        self.add_text_button.tool_name = "Text"
        self.add_text_button.clicked.connect(lambda: self.set_tool("Text"))
        self.annotation_buttons.append(self.add_text_button)

        # Add Color and Font buttons
        self.color_button = QPushButton("Select Color")
        self.color_button.setIcon(QIcon(colorwheel_path))
        self.color_button.clicked.connect(self.select_color)

        self.font_button = QPushButton("Select Font")
        self.font_button.setIcon(QIcon(font_path))
        self.font_button.clicked.connect(self.select_font)

        # Undo button
        self.undo_button = QPushButton("Undo")
        self.undo_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_ArrowLeft))  # Left arrow icon for undo
        self.undo_button.clicked.connect(self.main_preview.undo_annotation)  # Connect to undo_annotation in CustomGraphicsView

        # Clear Annotations button
        self.clear_annotations_button = QPushButton("Clear Annotations")
        self.clear_annotations_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_TrashIcon))  # Trash icon
        self.clear_annotations_button.clicked.connect(self.main_preview.clear_annotations)  # Connect to clear_annotations in CustomGraphicsView

        # Delete Selected Object button
        self.delete_selected_object_button = QPushButton("Delete Selected Object")
        self.delete_selected_object_button.setIcon(QApplication.style().standardIcon(QStyle.StandardPixmap.SP_DialogCloseButton))  # Trash icon
        self.delete_selected_object_button.clicked.connect(self.main_preview.delete_selected_object)  # Connect to delete_selected_object in CustomGraphicsView

        # Add the instruction label to the top of the grid layout (row 0, spanning multiple columns)
        annotation_tools_layout.addWidget(annotation_instruction_label, 0, 0, 1, 4)  # Span 5 columns to center it

        # Shift all other widgets down by one row
        annotation_tools_layout.addWidget(self.draw_ellipse_button, 1, 0)
        annotation_tools_layout.addWidget(self.freehand_button, 1, 1)
        annotation_tools_layout.addWidget(self.draw_rectangle_button, 2, 0)
        annotation_tools_layout.addWidget(self.draw_arrow_button, 2, 1)
        annotation_tools_layout.addWidget(self.place_compass_button, 3, 0)
        annotation_tools_layout.addWidget(self.add_text_button, 3, 1)
        annotation_tools_layout.addWidget(self.color_button, 4, 0)
        annotation_tools_layout.addWidget(self.font_button, 4, 1)
        annotation_tools_layout.addWidget(self.undo_button, 1, 4)
        annotation_tools_layout.addWidget(self.clear_annotations_button, 2, 4)
        annotation_tools_layout.addWidget(self.delete_selected_object_button, 3, 4)

        self.annotation_tools_section.setVisible(False)  # Initially hidden
        right_panel.addWidget(self.annotation_tools_section)

        # Advanced Search Panel
        self.advanced_param_label = QLabel("Advanced Search Parameters")
        self.advanced_search_panel.addWidget(self.advanced_param_label)

        # TreeWidget for object types
        self.object_tree = QTreeWidget()
        self.object_tree.setHeaderLabels(["Object Type", "Description"])
        self.object_tree.setColumnWidth(0, 150)
        self.object_tree.setSortingEnabled(True)

        # Populate the TreeWidget with object types from otype_long_name_lookup
        for obj_type, description in otype_long_name_lookup.items():
            item = QTreeWidgetItem([obj_type, description])
            item.setCheckState(0, Qt.CheckState.Checked)  # Start with all items unchecked
            self.object_tree.addTopLevelItem(item)

        self.advanced_search_panel.addWidget(self.object_tree)

        # Buttons for toggling selections
        toggle_buttons_layout = QHBoxLayout()

        # Toggle All
        self.toggle_all_button = QPushButton("Toggle All")
        self.toggle_all_button.clicked.connect(self.toggle_all_items)
        toggle_buttons_layout.addWidget(self.toggle_all_button)

        # Save Custom List
        self.save_list_button = QPushButton("Save List…")
        self.save_list_button.clicked.connect(self.save_custom_list)
        toggle_buttons_layout.addWidget(self.save_list_button)

        # Load Custom List
        self.load_list_button = QPushButton("Load List…")
        self.load_list_button.clicked.connect(self.load_custom_list)
        toggle_buttons_layout.addWidget(self.load_list_button)

        self.advanced_search_panel.addLayout(toggle_buttons_layout)   

        # Add Simbad Search buttons below the toggle buttons
        search_button_layout = QHBoxLayout()

        self.simbad_defined_region_button = QPushButton("Search Defined Region")
        self.simbad_defined_region_button.clicked.connect(self.search_defined_region)
        search_button_layout.addWidget(self.simbad_defined_region_button)

        self.simbad_entire_image_button = QPushButton("Search Entire Image")
        self.simbad_entire_image_button.clicked.connect(self.search_entire_image)
        search_button_layout.addWidget(self.simbad_entire_image_button)

        self.advanced_search_panel.addLayout(search_button_layout)

        # Adding the "Deep Vizier Search" button below the other search buttons
        self.deep_vizier_button = QPushButton("Caution - Deep Vizier Search")
        self.deep_vizier_button.setIcon(QIcon(nuke_path))  # Assuming `nuke_path` is the correct path for the icon
        self.deep_vizier_button.setToolTip("Perform a deep search with Vizier. Caution: May return large datasets.")

        # Connect the button to a placeholder method for the deep Vizier search
        self.deep_vizier_button.clicked.connect(self.perform_deep_vizier_search)

        # Add the Deep Vizier button to the advanced search layout
        self.advanced_search_panel.addWidget(self.deep_vizier_button)

        self.mast_search_button = QPushButton("Search M.A.S.T Database")
        self.mast_search_button.setIcon(QIcon(hubble_path))
        self.mast_search_button.clicked.connect(self.perform_mast_search)
        self.mast_search_button.setToolTip("Search Hubble, JWST, Spitzer, TESS and More.")
        self.advanced_search_panel.addWidget(self.mast_search_button)                        

        # Combine left and right panels
        main_layout.addLayout(left_panel)
        main_layout.addLayout(right_panel)
        main_layout.addWidget(self.advanced_search_panel_widget)
        
        container = QWidget()
        container.setLayout(main_layout)
        self.setCentralWidget(container)

        self.image_path = None
        self.zoom_level = 1.0
        self.main_image = None
        self.green_box = None
        self.dragging = False
        self.center_ra = None
        self.center_dec = None
        self.pixscale = None
        self.orientation = None
        self.parity = None  
        self.circle_center = None
        self.circle_radius = 0  
        self.results = []
        self.wcs = None  # Initialize WCS to None
        # Initialize selected color and font with default values
        self.selected_color = QColor(Qt.GlobalColor.red)  # Default annotation color
        self.selected_font = QFont("Arial", 12)  # Default font for text annotations   
        self.populate_object_tree()     
        #self._legend_dock = QDockWidget("Object Type Legend", self)
        legend = LegendDialog(self)
        legend.setModal(False)
    

    def show_legend(self):
        # keep a persistent reference so it doesn't get garbage-collected
        if not hasattr(self, "_legend_dialog"):
            self._legend_dialog = LegendDialog(self)
            self._legend_dialog.setModal(False)
        self._legend_dialog.show()
        self._legend_dialog.raise_()
        self._legend_dialog.activateWindow()




    def populate_object_tree(self):
        self.object_tree.blockSignals(True)
        self.object_tree.clear()

        # 1) Build reverse map: category → list of short codes
        cat_to_types = defaultdict(list)

        # Pre-sort patterns so more specific (longer) come first
        patterns = list(OTYPE_TO_CATEGORY.items())
        patterns.sort(key=lambda x: len(x[0]), reverse=True)

        for code, longname in otype_long_name_lookup.items():
            # first try exact
            cat = OTYPE_TO_CATEGORY.get(code)
            if cat is None:
                # then try wildcard patterns (but skip the lone "*" pattern)
                for pat, candidate_cat in patterns:
                    if any(c in pat for c in "*?") and pat != "*" and fnmatch.fnmatch(code, pat):
                        cat = candidate_cat
                        break
            if cat is None:
                cat = "Errors & Artefacts"
            cat_to_types[cat].append(code)

        # 2) Populate tree
        for category, codes in cat_to_types.items():
            color  = CATEGORY_TO_COLOR.get(category, QColor(200,200,200))
            parent = QTreeWidgetItem(self.object_tree, [category, ""])
            parent.setFlags(parent.flags() | Qt.ItemFlag.ItemIsUserCheckable)
            parent.setCheckState(0, Qt.CheckState.Checked)
            parent.setForeground(0, QBrush(color))
            parent.setFirstColumnSpanned(True)

            for code in sorted(codes):
                desc  = otype_long_name_lookup[code]
                child = QTreeWidgetItem(parent, [code, desc])
                child.setFlags(child.flags() | Qt.ItemFlag.ItemIsUserCheckable)
                child.setCheckState(0, Qt.CheckState.Checked)
                pix = QPixmap(12,12)
                pix.fill(color)
                child.setIcon(0, QIcon(pix))

        self.object_tree.blockSignals(False)

        # wire up a very simple parent→children handler (no partial logic)
        try:
            self.object_tree.itemChanged.disconnect(self.on_object_tree_item_changed)
        except TypeError:
            pass
        self.object_tree.itemChanged.connect(self.on_object_tree_item_changed)


    def get_selected_object_types(self) -> list:
        """
        Return all the otype codes (children) whose checkboxes are checked.
        """
        checked = []
        root = self.object_tree.invisibleRootItem()
        # iterate over each category
        for i in range(root.childCount()):
            category_item = root.child(i)
            # iterate over that category's children
            for j in range(category_item.childCount()):
                child = category_item.child(j)
                if child.checkState(0) == Qt.CheckState.Checked:
                    checked.append(child.text(0))
        return checked


    def update_object_count(self):
        count = self.results_tree.topLevelItemCount()
        self.object_count_label.setText(f"Objects Found: {count}")

    def open_context_menu(self, position):
        
        # Get the item at the mouse position
        item = self.results_tree.itemAt(position)
        if not item:
            return  # If no item is clicked, do nothing
        
        self.on_tree_item_clicked(item)

        # Create the context menu
        menu = QMenu(self)

        # Define actions
        open_website_action = QAction("Open Website", self)
        open_website_action.triggered.connect(lambda: self.results_tree.itemDoubleClicked.emit(item, 0))
        menu.addAction(open_website_action)

        zoom_to_object_action = QAction("Zoom to Object", self)
        zoom_to_object_action.triggered.connect(lambda: self.zoom_to_object(item))
        menu.addAction(zoom_to_object_action)

        copy_info_action = QAction("Copy Object Information", self)
        copy_info_action.triggered.connect(lambda: self.copy_object_information(item))
        menu.addAction(copy_info_action)

        # Display the context menu at the cursor position
        menu.exec(self.results_tree.viewport().mapToGlobal(position))

    def toggle_autostretch(self):
        if not hasattr(self, 'original_image'):
            # Store the original image the first time AutoStretch is applied
            self.original_image = self.image_data.copy()
        
        # Determine if the image is mono or color based on the number of dimensions
        if self.image_data.ndim == 2:
            # Call stretch_mono_image if the image is mono

            stretched_image = stretch_mono_image(self.image_data, target_median=0.25, normalize=True)
        else:
            # Call stretch_color_image if the image is color

            stretched_image = stretch_color_image(self.image_data, target_median=0.25, linked=True, normalize=True)
        
        # If the AutoStretch is toggled off (using the same button), restore the original image
        if self.auto_stretch_button.text() == "AutoStretch":
            # Store the stretched image and update the button text to indicate it's on
            self.stretched_image = stretched_image
            self.auto_stretch_button.setText("Turn Off AutoStretch")
        else:
            # Revert to the original image and update the button text to indicate it's off
            stretched_image = self.original_image
            self.auto_stretch_button.setText("AutoStretch")
        

        stretched_image = (stretched_image * 255).astype(np.uint8)


        # Update the display with the stretched image (or original if toggled off)

        height, width = stretched_image.shape[:2]
        bytes_per_line = 3 * width

        # Ensure the image has 3 channels (RGB)
        if stretched_image.ndim == 2:
            stretched_image = np.stack((stretched_image,) * 3, axis=-1)
        elif stretched_image.shape[2] == 1:
            stretched_image = np.repeat(stretched_image, 3, axis=2)



        qimg = QImage(stretched_image.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
        if qimg.isNull():
            print("Failed to create QImage")
            return

        pixmap = QPixmap.fromImage(qimg)
        if pixmap.isNull():
            print("Failed to create QPixmap")
            return

        self.main_image = pixmap
        scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
        self.mini_preview.setPixmap(scaled_pixmap)

        self.main_scene.clear()
        self.main_scene.addPixmap(pixmap)
        self.main_preview.setSceneRect(QRectF(pixmap.rect()))
        self.zoom_level = 1.0
        self.main_preview.resetTransform()
        self.main_preview.centerOn(self.main_scene.sceneRect().center())
        self.update_green_box()

        # Optionally, you can also update any other parts of the UI after stretching the image
        print(f"AutoStretch {'applied to' if self.auto_stretch_button.text() == 'Turn Off AutoStretch' else 'removed from'} the image.")


    def zoom_to_object(self, item):
        """Zoom to the object in the main preview."""
        ra = float(item.text(0))  # Assuming RA is in the first column
        dec = float(item.text(1))  # Assuming Dec is in the second column
        self.main_preview.zoom_to_coordinates(ra, dec)
        

    def copy_object_information(self, item):
        """Copy object information to the clipboard."""
        info = f"RA: {item.text(0)}, Dec: {item.text(1)}, Name: {item.text(2)}, Diameter: {item.text(3)}, Type: {item.text(4)}"
        clipboard = QApplication.clipboard()
        clipboard.setText(info)

    def set_tool(self, tool_name):
        """Sets the current tool and updates button states."""
        self.current_tool = tool_name

        # Reset button styles and highlight the selected button
        for button in self.annotation_buttons:
            if button.tool_name == tool_name:
                button.setStyleSheet("background-color: lightblue;")  # Highlight selected button
            else:
                button.setStyleSheet("")  # Reset other buttons


    def select_color(self):
        """Opens a color dialog to choose annotation color."""
        color = QColorDialog.getColor(self.selected_color, self, "Select Annotation Color")
        if color.isValid():
            self.selected_color = color

    def select_font(self):
        """Opens a font dialog to choose text annotation font."""
        font, ok = QFontDialog.getFont(self.selected_font, self, "Select Annotation Font")
        if ok:
            self.selected_font = font                

    def toggle_annotation_tools(self):
        """Toggle the visibility of the annotation tools section."""
        is_visible = self.annotation_tools_section.isVisible()
        self.annotation_tools_section.setVisible(not is_visible)
        self.show_annotations_button.setText("Hide Annotation Tools" if not is_visible else "Show Annotation Tools")

    def save_plate_solved_fits(self):
        """Save the plate-solved FITS file with WCS header data and the desired bit depth."""
        # Prompt user to select bit depth
        bit_depth, ok = QInputDialog.getItem(
            self, 
            "Select Bit Depth", 
            "Choose the bit depth for the FITS file:",
            ["8-bit", "16-bit", "32-bit"], 
            0, False
        )

        if not ok:
            return  # User cancelled the selection

        # Open file dialog to select where to save the FITS file
        output_image_path, _ = QFileDialog.getSaveFileName(
            self, "Save Plate Solved FITS", "", "FITS Files (*.fits *.fit)"
        )

        if not output_image_path:
            return  # User cancelled save file dialog

        # Verify WCS header data is available
        if not hasattr(self, 'wcs') or self.wcs is None:
            QMessageBox.warning(self, "WCS Data Missing", "WCS header data is not available.")
            return

        # Retrieve image data and WCS header
        image_data = self.image_data  # Raw image data
        wcs_header = self.wcs.to_header(relax=True)  # WCS header, including non-standard keywords
        combined_header = self.original_header.copy() if self.original_header else fits.Header()
        combined_header.update(wcs_header)  # Combine original header with WCS data

        # Convert image data based on selected bit depth
        if self.is_mono:
            # Grayscale (2D) image
            if bit_depth == "8-bit":
                scaled_image = (image_data[:, :, 0] / np.max(image_data) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (image_data[:, :, 0] * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = image_data[:, :, 0].astype(np.float32)
                combined_header['BITPIX'] = -32
        else:
            # RGB (3D) image: Transpose to FITS format (channels, height, width)
            transformed_image = np.transpose(image_data, (2, 0, 1))
            if bit_depth == "8-bit":
                scaled_image = (transformed_image / np.max(transformed_image) * 255).astype(np.uint8)
                combined_header['BITPIX'] = 8
            elif bit_depth == "16-bit":
                scaled_image = (transformed_image * 65535).astype(np.uint16)
                combined_header['BITPIX'] = 16
            elif bit_depth == "32-bit":
                scaled_image = transformed_image.astype(np.float32)
                combined_header['BITPIX'] = -32

            # Update header to reflect 3D structure
            combined_header['NAXIS'] = 3
            combined_header['NAXIS1'] = transformed_image.shape[2]
            combined_header['NAXIS2'] = transformed_image.shape[1]
            combined_header['NAXIS3'] = transformed_image.shape[0]

        # Save the image with combined header (including WCS and original data)
        hdu = fits.PrimaryHDU(scaled_image, header=combined_header)
        try:
            hdu.writeto(output_image_path, overwrite=True)
            QMessageBox.information(self, "File Saved", f"FITS file saved as {output_image_path}")
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Failed to save FITS file: {str(e)}")



    def save_annotated_image(self):
        """Save the annotated image as a full or cropped view, excluding the search circle."""
        # Create a custom message box
        msg_box = QMessageBox(self)
        msg_box.setWindowTitle("Save Annotated Image")
        msg_box.setText("Do you want to save the Full Image or Cropped Only?")
        
        # Add custom buttons
        full_image_button = msg_box.addButton("Save Full", QMessageBox.ButtonRole.AcceptRole)
        cropped_image_button = msg_box.addButton("Save Cropped", QMessageBox.ButtonRole.DestructiveRole)
        msg_box.addButton(QMessageBox.StandardButton.Cancel)

        # Show the message box and get the user's response
        msg_box.exec()

        # Determine the save type based on the selected button
        if msg_box.clickedButton() == full_image_button:
            save_full_image = True
        elif msg_box.clickedButton() == cropped_image_button:
            save_full_image = False
        else:
            return  # User cancelled

        # Open a file dialog to select the file name and format
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Annotated Image",
            "",
            "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )
        
        if not file_path:
            return  # User cancelled the save dialog

        # Temporarily disable the search circle in the custom graphics view
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.main_preview.circle_center = None  # Hide the circle temporarily
        self.main_preview.circle_radius = 0

        # Redraw annotations without the search circle
        self.main_preview.draw_query_results()

        # Create a QPixmap to render the annotations
        if save_full_image:
            # Save the entire main image with annotations
            pixmap = QPixmap(self.main_image.size())
            pixmap.fill(Qt.GlobalColor.transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter)  # Render the entire scene without the search circle
        else:
            # Save only the currently visible area (cropped view)
            rect = self.main_preview.viewport().rect()
            scene_rect = self.main_preview.mapToScene(rect).boundingRect()
            pixmap = QPixmap(int(scene_rect.width()), int(scene_rect.height()))
            pixmap.fill(Qt.GlobalColor.transparent)
            painter = QPainter(pixmap)
            self.main_scene.render(painter, QRectF(0, 0, pixmap.width(), pixmap.height()), scene_rect)

        painter.end()  # End QPainter to finalize drawing

        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle

        # Save the QPixmap as an image file in the selected format
        try:
            if pixmap.save(file_path, file_path.split('.')[-1].upper()):
                QMessageBox.information(self, "Save Successful", f"Annotated image saved as {file_path}")
            else:
                raise Exception("Failed to save image due to format or file path issues.")
        except Exception as e:
            QMessageBox.critical(self, "Save Failed", f"An error occurred while saving the image: {str(e)}")


    def save_collage_of_objects(self):
        """Save a collage of 128x128 pixel patches centered around each object, with dynamically spaced text below."""
        # Options for display
        options = ["Name", "RA", "Dec", "Short Type", "Long Type", "Redshift", "Comoving Distance"]

        # Create a custom dialog to select information to display
        dialog = QDialog(self)
        dialog.setWindowTitle("Select Information to Display")
        layout = QVBoxLayout(dialog)
        
        # Add checkboxes for each option
        checkboxes = {}
        for option in options:
            checkbox = QCheckBox(option)
            checkbox.setChecked(True)  # Default to checked
            layout.addWidget(checkbox)
            checkboxes[option] = checkbox

        # Add OK and Cancel buttons
        button_box = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        layout.addWidget(button_box)
        button_box.accepted.connect(dialog.accept)
        button_box.rejected.connect(dialog.reject)

        # Show the dialog and get the user's response
        if dialog.exec() == QDialog.DialogCode.Rejected:
            return  # User cancelled

        # Determine which fields to display based on user selection
        selected_fields = [key for key, checkbox in checkboxes.items() if checkbox.isChecked()]

        # Calculate required vertical space for text based on number of selected fields
        text_row_height = 15
        text_block_height = len(selected_fields) * text_row_height
        patch_size = 128
        space_between_patches = max(64, text_block_height + 20)  # Ensure enough space for text between patches

        # Set parameters for collage layout
        number_of_objects = len(self.results)

        if number_of_objects == 0:
            QMessageBox.warning(self, "No Objects", "No objects available to create a collage.")
            return

        # Determine grid size for the collage
        grid_size = math.ceil(math.sqrt(number_of_objects))
        collage_width = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128
        collage_height = patch_size * grid_size + space_between_patches * (grid_size - 1) + 128

        # Create an empty black RGB image for the collage
        collage_image = Image.new("RGB", (collage_width, collage_height), (0, 0, 0))

        # Temporarily disable annotations
        original_show_names = self.show_names
        original_circle_center = self.main_preview.circle_center
        original_circle_radius = self.main_preview.circle_radius
        self.show_names = False
        self.main_preview.circle_center = None
        self.main_preview.circle_radius = 0

        try:
            for i, obj in enumerate(self.results):
                # Calculate position in the grid
                row = i // grid_size
                col = i % grid_size
                offset_x = 64 + col * (patch_size + space_between_patches)
                offset_y = 64 + row * (patch_size + space_between_patches)

                # Calculate pixel coordinates around the object
                ra, dec = obj["ra"], obj["dec"]
                x, y = self.calculate_pixel_from_ra_dec(ra, dec)

                # Render the main image without annotations onto a QPixmap
                patch = QPixmap(self.main_image.size())
                patch.fill(Qt.GlobalColor.black)
                painter = QPainter(patch)
                self.main_scene.clear()  # Clear any previous drawings on the scene
                self.main_scene.addPixmap(self.main_image)  # Add only the main image without annotations
                self.main_scene.render(painter)  # Render the scene onto the patch

                # End the painter early to prevent QPaintDevice errors
                painter.end()

                # Crop the relevant area for the object
                rect = QRectF(x - patch_size // 2, y - patch_size // 2, patch_size, patch_size)
                cropped_patch = patch.copy(rect.toRect())
                cropped_image = cropped_patch.toImage().scaled(patch_size, patch_size).convertToFormat(QImage.Format.Format_RGB888)

                # Convert QImage to PIL format for adding to the collage
                bytes_img = cropped_image.bits().asstring(cropped_image.width() * cropped_image.height() * 3)
                pil_patch = Image.frombytes("RGB", (patch_size, patch_size), bytes_img)

                # Paste the patch in the correct location on the collage
                collage_image.paste(pil_patch, (offset_x, offset_y))

                # Draw the selected information below the patch
                draw = ImageDraw.Draw(collage_image)
                font = ImageFont.truetype("arial.ttf", 12)  # Adjust font path as needed
                text_y = offset_y + patch_size + 5

                for field in selected_fields:
                    # Retrieve data and only display if not "N/A"
                    if field == "Name" and obj.get("name") != "N/A":
                        text = obj["name"]
                    elif field == "RA" and obj.get("ra") is not None:
                        text = f"RA: {obj['ra']:.6f}"
                    elif field == "Dec" and obj.get("dec") is not None:
                        text = f"Dec: {obj['dec']:.6f}"
                    elif field == "Short Type" and obj.get("short_type") != "N/A":
                        text = f"Type: {obj['short_type']}"
                    elif field == "Long Type" and obj.get("long_type") != "N/A":
                        text = f"{obj['long_type']}"
                    elif field == "Redshift" and obj.get("redshift") != "N/A":
                        text = f"Redshift: {float(obj['redshift']):.5f}"  # Limit redshift to 5 decimal places
                    elif field == "Comoving Distance" and obj.get("comoving_distance") != "N/A":
                        text = f"Distance: {obj['comoving_distance']} GLy"
                    else:
                        continue  # Skip if field is not available or set to "N/A"

                    # Draw the text and increment the Y position
                    draw.text((offset_x + 10, text_y), text, (255, 255, 255), font=font)
                    text_y += text_row_height  # Space between lines

        finally:
            # Restore the original annotation and search circle settings
            self.show_names = original_show_names
            self.main_preview.circle_center = original_circle_center
            self.main_preview.circle_radius = original_circle_radius

        # Save the collage
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save Collage of Objects", "", "JPEG (*.jpg *.jpeg);;PNG (*.png);;TIFF (*.tiff *.tif)"
        )

        if file_path:
            collage_image.save(file_path)
            QMessageBox.information(self, "Save Successful", f"Collage saved as {file_path}")


        # Restore the search circle in the custom graphics view
        self.main_preview.circle_center = original_circle_center
        self.main_preview.circle_radius = original_circle_radius
        self.main_preview.draw_query_results()  # Redraw the scene with the circle

    def show_3d_model_view(self):
        # ─── 0) Engineering‐notation helper ────────────────────────────
        def eng_notation(x):
            if x == 0:
                return "0"
            exp = int(math.floor(math.log10(abs(x)) / 3) * 3)
            val = x / (10 ** exp)
            prefixes = {
                -12: "p", -9: "n", -6: "µ", -3: "m",
                0: "",  3: "k",  6: "M",  9: "G",
                12: "T", 15: "P"
            }
            return f"{val:.2f}{prefixes.get(exp, f'e{exp}')}"

        # ─── 1) Sanity checks ─────────────────────────────────────────
        if not self.results or self.image_data is None:
            QMessageBox.warning(self, "Data Error", "No image or results available.")
            return
        if self.wcs is None:
            QMessageBox.warning(self, "WCS Missing", "WCS data is required to generate the 3D plot.")
            return

        # ─── 2) Get user settings ────────────────────────────────────
        settings = ThreeDSettingsDialog(self).getSettings()
        if not settings:
            return
        (plane_style, max_res, z_option, z_min, z_max,
        z_scale, linear_max, obj_color, custom_col,
        z_height, show_lines, reverse_z) = (
            settings[k] for k in (
                "plane_style","resolution","z_option","z_min","z_max",
                "z_scale","linear_max","object_color","custom_color",
                "z_height","show_lines","reverse_z"
            )
        )

        # ─── 3) Normalize & downsample image ──────────────────────────
        img = self.image_data
        if img.ndim == 2:
            img = np.stack([img]*3, axis=-1)
        img_norm = np.clip((img - img.min())/(np.ptp(img)+1e-8), 0, 1)
        full_h, full_w = img.shape[:2]
        scale = min(max_res/full_h, max_res/full_w, 1.0)
        img_ds = np.stack([zoom(img_norm[..., i], scale, order=1) for i in range(3)], axis=-1)
        h_ds, w_ds, _ = img_ds.shape

        # ─── 4) Build plane coordinates ───────────────────────────────
        xs = np.linspace(0, full_w-1, w_ds)
        ys = np.linspace(0, full_h-1, h_ds)
        Xp, Yp = np.meshgrid(xs, ys)
        RA, DEC = self.wcs.pixel_to_world_values(Xp, Yp)
        ra_min, ra_max = float(RA.min()), float(RA.max())
        dec_min, dec_max = float(DEC.min()), float(DEC.max())

        # ─── 5) Gather objects into rows (keep fields together) ───────
        rows = []
        for obj in self.results:
            try:
                name = obj["name"]
                ra   = float(obj["ra"])
                dec  = float(obj["dec"])

                # distance in ly (robust parse; always positive; +10 to avoid log10(0))
                try:
                    d_gy = float(obj["comoving_distance"])  # e.g., GLy
                    d_ly = abs(d_gy) * 1e9 + 10
                except (ValueError, TypeError):
                    raw_cd = str(obj["comoving_distance"]).strip()
                    if raw_cd.endswith("GLy"):
                        d_ly = abs(float(raw_cd[:-3].strip())) * 1e9 + 10
                    elif raw_cd.endswith("Ly"):
                        d_ly = abs(float(raw_cd[:-2].strip())) + 10
                    else:
                        d_ly = abs(float(raw_cd)) + 10
                if d_ly <= 0:
                    continue

                zshift = float(obj.get("redshift", 0.0))

                px, py = self.wcs.world_to_pixel_values(ra, dec)
                if not (0 <= px < full_w and 0 <= py < full_h):
                    continue

                zval = math.log10(d_ly) if z_scale == "Logarithmic" else d_ly
                ra0, dec0 = self.wcs.pixel_to_world_values(px, py)

                label = (
                    f"<b>{name}</b><br>"
                    f"RA: {ra:.6f}<br>"
                    f"Dec: {dec:.6f}<br>"
                    f"Distance: {eng_notation(d_ly)} ly<br>"
                    f"Redshift: {zshift:.5f}"
                )
                enc = urllib.parse.quote(name)
                url = (
                    "https://simbad.cds.unistra.fr/simbad/sim-basic?"
                    f"Ident={enc}&submit=SIMBAD+search"
                )

                rows.append(dict(
                    name=name, x=ra0, y=dec0, z=zval, url=url, label=label,
                    px=px, py=py, legend_qcolor=obj.get("color", QColor(128, 128, 128))
                ))
            except Exception:
                continue

        if not rows:
            QMessageBox.warning(self, "No Objects", "No valid distance objects to plot.")
            return

        # ─── 6) Filter rows by finite z (and optional range) ──────────
        rows = [r for r in rows if math.isfinite(r["z"])]
        if not rows:
            QMessageBox.warning(self, "No Objects", "All distance values are invalid.")
            return

        if z_option == "Custom":
            rows = [r for r in rows if z_min <= r["z"] <= z_max]
            if not rows:
                QMessageBox.warning(self, "No Objects", "No objects fall within the custom Z range.")
                return
            plane_z = z_min
            z_range = (z_min, z_max)
        elif z_option == "Min-Max":
            z_vals = np.array([r["z"] for r in rows], dtype=float)
            plane_z = float(np.nanmin(z_vals))
            z_range = (float(np.nanmin(z_vals)), float(np.nanmax(z_vals)))
        else:  # Default
            plane_z = 0
            z_range = None

        if z_scale == "Linear" and z_option == "Default":
            z_range = (0, linear_max)

        # ─── 7) Build image‐plane layer ───────────────────────────────
        if "Grayscale" in plane_style:
            Zp = np.full_like(RA, plane_z)
            plane = go.Surface(
                x=RA, y=DEC, z=Zp,
                surfacecolor=np.mean(img_ds, axis=2),
                colorscale="gray", showscale=False, opacity=1.0,
                contours={"x": {"show": False}, "y": {"show": False}, "z": {"show": False}}
            )
        else:
            flat = (img_ds * 255).astype(int).reshape(-1, 3)
            cols = [f"rgb({r},{g},{b})" for r, g, b in flat]
            plane = go.Scatter3d(
                x=RA.flatten(), y=DEC.flatten(), z=[plane_z] * RA.size,
                mode="markers",
                marker=dict(symbol="square", size=2, line=dict(width=0), color=cols, opacity=1.0),
                hoverinfo="skip", showlegend=False
            )

        # ─── 8) Object colors (after filtering) ───────────────────────
        H, W = img_norm.shape[:2]
        if obj_color == "Image-Based":
            patch_r = 5
            def patch_color(r):
                cx, cy = int(r["px"]), int(r["py"])
                x0, x1 = max(0, cx - patch_r), min(W, cx + patch_r + 1)
                y0, y1 = max(0, cy - patch_r), min(H, cy + patch_r + 1)
                patch = img_norm[y0:y1, x0:x1]
                if patch.size:
                    mr, mg, mb = (patch.reshape(-1, 3).mean(axis=0) * 255).astype(int)
                else:
                    mr = mg = mb = 0
                return f"rgb({mr},{mg},{mb})"
            obj_cols = [patch_color(r) for r in rows]
        elif obj_color == "Legend Color":
            obj_cols = [f"rgb({c.red()},{c.green()},{c.blue()})" for c in (r["legend_qcolor"] for r in rows)]
        elif obj_color == "Solid (Custom)":
            c = custom_col
            obj_cols = [f"rgb({c.red()},{c.green()},{c.blue()})"] * len(rows)
        else:
            obj_cols = ["red"] * len(rows)

        # ─── 9) Build arrays (all same length) and optional lines ─────
        world_xs = [r["x"] for r in rows]
        world_ys = [r["y"] for r in rows]
        zs       = np.array([r["z"] for r in rows], dtype=float)
        labels   = [r["label"] for r in rows]
        urls     = [r["url"] for r in rows]
        names    = [r["name"] for r in rows]

        lines = []
        if show_lines:
            for r in rows:
                lines.append(go.Scatter3d(
                    x=[r["x"], r["x"]], y=[r["y"], r["y"]], z=[plane_z, r["z"]],
                    mode="lines", line=dict(color="gray", width=1),
                    hoverinfo="skip", showlegend=False
                ))

        # ─── 10) Scatter objects ───────────────────────────────────────
        scatter = go.Scatter3d(
            x=world_xs, y=world_ys, z=zs,
            mode="markers",
            marker=dict(size=4, color=obj_cols),
            hovertext=labels, hoverinfo="text",
            customdata=urls, name="Objects"
        )

        # ─── 11) Compose figure ───────────────────────────────────────
        fig = go.Figure(data=[plane] + lines + [scatter])
        scene = dict(
            xaxis_title="RA (deg)",
            xaxis=dict(range=[ra_min, ra_max], autorange=False),
            yaxis_title="Dec (deg)",
            yaxis=dict(range=[dec_max, dec_min], autorange=False),
            aspectmode="manual",
            aspectratio=dict(x=1, y=1, z=z_height),
            zaxis=dict(
                title=("log10(Distance in ly)" if z_scale == "Logarithmic" else "Distance (ly)"),
                tickformat="~s",
                **({"range": list(z_range)} if z_range else {}),
                **({"autorange": "reversed"} if reverse_z else {})
            )
        )
        fig.update_layout(title="3D Distance Model", autosize=True, scene=scene,
                        margin=dict(l=0, r=0, b=0, t=40))

        # ─── 12) Build & inject HTML ───────────────────────────────────
        html = fig.to_html(include_plotlyjs="cdn", full_html=True)
        items = "".join(f'<li><a href="{u}" target="_blank">{n}</a></li>' for n, u in zip(names, urls))
        sidebar = (
            '<div style="padding:10px;font-family:sans-serif;'
            'margin-top:20px;border-top:1px solid #ccc;">'
            '<h3>Objects</h3><ul>' + items + '</ul></div>'
        )
        js = """
        <script>
        var gd = document.getElementsByClassName('plotly-graph-div')[0];
        gd.on('plotly_click', function(e){
            var url = e.points[0].customdata;
            if (url) window.open(url, '_blank');
        });
        </script>
        """
        html = html.replace("</body>", sidebar + js + "</body>")

        # Save & preview
        default = os.path.expanduser("~/3d_distance_model.html")
        fn, _ = QFileDialog.getSaveFileName(self, "Save 3D Plot As", default, "HTML Files (*.html)")
        if fn:
            if not fn.lower().endswith(".html"):
                fn += ".html"
            with open(fn, "w", encoding="utf-8") as f:
                f.write(html)

        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".html", mode="w", encoding="utf-8")
        tmp.write(html); tmp.close()
        webbrowser.open("file://" + tmp.name)



    def show_hr_diagram(self):
        """H-R Diagram: B–V vs Abs V, with selectable color, background, and axis ranges."""
        # Pop up the settings dialog
        settings = HRSettingsDialog(self).getSettings()
        if settings is None:
            return

        use_realistic = settings["color_mode"].startswith("Realistic")
        use_image_bg = settings["bg_mode"].startswith("HR Diagram")
        solid_qcolor = settings["custom_color"]
        show_sun = settings["show_sun"]

        # Determine axis bounds
        if settings["range_mode"].startswith("Default"):
            x0, x1 = -0.3, 2.25
            y0, y1 = -9.0, 19.0
        else:
            x0 = settings["x_min"]
            x1 = settings["x_max"]
            y0 = settings["y_min"]
            y1 = settings["y_max"]

        # Sanity: ensure query_results exist
        if not getattr(self, 'query_results', None):
            QMessageBox.information(self, "No Data",
                "Run a SIMBAD query first to gather B, V, and distance data.")
            return

        # Collect data
        B, V, Mv, names = [], [], [], []
        for obj in self.query_results:
            try:
                b = float(obj['Bmag'])
                v = float(obj['Vmag'])
                m = float(obj['absolute_mag'])
            except (TypeError, ValueError, KeyError):
                continue
            B.append(b); V.append(v); Mv.append(m); names.append(obj['name'])
        if not B:
            QMessageBox.warning(self, "Insufficient Data",
                "No objects have valid B-mag, V-mag and absolute magnitude.")
            return

        # Compute B−V & T_eff & colors
        bv = [b - v for b, v in zip(B, V)]
        T_eff = [4600.0 * (1/(0.92*x + 1.7) + 1/(0.92*x + 0.62)) for x in bv]
        if use_realistic:
            colors = [kelvin_to_rgb(T) for T in T_eff]
        else:
            hex_color = solid_qcolor.name()
            colors = [hex_color] * len(bv)

        # Prepare hover & URLs
        hover_texts, urls = [], []
        for nm, b, v, m, T in zip(names, B, V, Mv, T_eff):
            hover_texts.append(
                f"<b>{nm}</b><br>"
                f"B: {b:.2f}  V: {v:.2f}<br>"
                f"Abs V: {m:.2f}<br>"
                f"Tₑff: {T:.0f} K"
            )
            enc = urllib.parse.quote(nm)
            urls.append(
                f"https://simbad.cds.unistra.fr/simbad/sim-basic?"
                f"Ident={enc}&submit=SIMBAD+search"
            )

        # Create scatter
        scatter = go.Scatter(
            x=bv, y=Mv, mode='markers',
            marker_color=colors, marker_size=20,
            hovertext=hover_texts, customdata=urls,
            name="Stars"
        )
        fig = go.Figure(scatter)


        # 1) Dense BV grid over x0→x1
        bv_grid = np.linspace(x0, x1, 300)
        # 2) Compute Teff at each BV
        T_grid = 4600.0 * (1.0/(0.92*bv_grid + 1.7) + 1.0/(0.92*bv_grid + 0.62))
        # 3) Solar Teff for normalization
        T_sun = 5772.0

        # 4) Radii in R_sun
        radii = [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]
        # 5) Corresponding gray shades for each contour
        gray_colors = [
            "#444444",  # darkest gray for R=0.01
            "#666666",  # R=0.1
            "#888888",  # R=1.0
            "#AAAAAA",  # R=10
            "#CCCCCC",  # R=100
            "#EEEEEE"   # R=1000 (lightest)
        ]

        for idx, R_rs in enumerate(radii):
            # compute L/L_sun
            L_over_Lsun = (R_rs**2) * (T_grid / T_sun)**4
            # convert to M_V
            MV_line = 4.83 - 2.5 * np.log10(L_over_Lsun)

            fig.add_trace(
                go.Scatter(
                    x=bv_grid,
                    y=MV_line,
                    mode='lines',
                    line=dict(
                        color=gray_colors[idx],
                        dash='dash'
                    ),
                    name=f"R = {R_rs:g} R⊙",   # plain text “R⊙”
                    hoverinfo='none'
                )
            )
        # ───────────────────────────────────────────────────────────────────

        # Build tick labels
        bv_ticks = [-0.3, 0.0, 0.5, 1.0, 1.5, 2.0, 2.25]
        t_ticks = [4600.0*(1/(0.92*x+1.7)+1/(0.92*x+0.62)) for x in bv_ticks]
        tick_labels = [f"{x:.2f}<br>{int(t):,} K" for x,t in zip(bv_ticks, t_ticks)]

        # If using image background, load via PIL
        if use_image_bg:
            pil_img = Image.open(hrdiagram_path)

        # Force the specified x & y axis ranges
        fig.update_xaxes(
            title_text="B−V color (mag) ↔ Tₑff",
            tickvals=bv_ticks,
            ticktext=tick_labels,
            tickfont_color='white',
            title_font=dict(color='white'),
            gridcolor='gray',
            zerolinecolor='gray',
            range=[x0, x1]
        )
        fig.update_yaxes(
            title_text="Absolute V magnitude (mag)",
            range=[y1, y0],         # reversed on purpose: y1 (–9) at top, y0 (19) at bottom
            autorange=False,
            tickfont_color='white',
            title_font=dict(color='white'),
            gridcolor='gray',
            zerolinecolor='gray',
        )

        # Add the image behind the plot if chosen
        if use_image_bg:
            fig.add_layout_image(
                dict(
                    source=pil_img,
                    xref="x", yref="y",
                    x=x0, y=y0,
                    sizex=(x1 - x0),
                    sizey=(y1 - y0),
                    xanchor="left", yanchor="top",
                    sizing="stretch",
                    opacity=1.0,
                    layer="below"
                )
            )

        # Add a special marker for the Sun (B−V=0.66, Mv=4.8)
        if show_sun:
            sun_scatter = go.Scatter(
                x=[0.66], y=[4.8],
                mode='markers+text',
                marker=dict(
                    color='gold',
                    size=30,
                    symbol='star'
                ),
                name="Sun"
            )
            fig.add_trace(sun_scatter)

        # Style axes & background
        if use_image_bg:
            fig.update_layout(
                title=dict(text="Hertzsprung–Russell Diagram", font_color='white'),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='black',
                margin=dict(l=40, r=20, t=60, b=60)
            )
        else:
            fig.update_layout(
                title=dict(text="Hertzsprung–Russell Diagram", font_color='white'),
                plot_bgcolor='black',
                paper_bgcolor='black',
                margin=dict(l=40, r=20, t=60, b=60)
            )

        # Sidebar & click behaviour
        items = "".join(
            f'<li><a href="{u}" style="color:cyan" target="_blank">{n}</a></li>'
            for n,u in zip(names, urls)
        )
        sidebar = (
            '<div style="padding:10px;font-family:sans-serif;'
            'margin-top:10px;border-top:1px solid #444; background:black; color:white;">'
            '<h3>Objects</h3><ul>' + items + '</ul></div>'
        )
        js = """
        <script>
        var gd = document.getElementsByClassName('plotly-graph-div')[0];
        gd.on('plotly_click', function(e){
            var url = e.points[0].customdata;
            if(url) window.open(url,'_blank');
        });
        </script>
        """

        html = fig.to_html(include_plotlyjs='cdn', full_html=True)
        html = html.replace("</body>", sidebar + js + "</body>")

        # Save & preview
        default = os.path.join(os.path.expanduser("~"), "hr_diagram.html")
        fn, _ = QFileDialog.getSaveFileName(self, "Save H-R Diagram As",
                                            default, "HTML Files (*.html)")
        if fn:
            if not fn.lower().endswith('.html'):
                fn += '.html'
            with open(fn, 'w', encoding='utf-8') as f:
                f.write(html)

        tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.html',
                                        mode='w', encoding='utf-8')
        tmp.write(html); tmp.close()
        webbrowser.open("file://" + tmp.name)

    
    def search_defined_region(self):
        """Perform a Simbad search for the defined region and filter by selected object types."""
        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate the radius in degrees for the defined region (circle radius)
        radius_deg = self.get_defined_radius()

        # Perform the Simbad search in the defined region with the calculated radius
        self.query_simbad(radius_deg)


    def search_entire_image(self):
        """Search the entire image using Simbad with selected object types."""
        selected_types = self.get_selected_object_types()  # Get selected types from the advanced search panel
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected", "Please select at least one object type.")
            return

        # Calculate radius as the distance from the image center to a corner
        width, height = self.main_image.width(), self.main_image.height()
        center_x, center_y = width / 2, height / 2
        corner_x, corner_y = width, height  # Bottom-right corner
        # Calculate distance in pixels from center to corner
        radius_px = np.sqrt((corner_x - center_x) ** 2 + (corner_y - center_y) ** 2)
        # Convert radius from pixels to degrees
        radius_deg = float((radius_px * self.pixscale) / 3600.0)

        # Automatically set circle_center and circle_radius for the entire image
        self.circle_center = QPointF(center_x, center_y)  # Assuming QPointF is used
        self.circle_radius = radius_px  # Set this to allow the check in `query_simbad`

        # Perform the query with the calculated radius
        self.query_simbad(radius_deg, max_results=100000)


    def _iterate_leaf_items(self):
        """Yield every otype (child) under every category parent."""
        root = self.object_tree.invisibleRootItem()
        for i in range(root.childCount()):
            parent = root.child(i)
            for j in range(parent.childCount()):
                yield parent.child(j)


    def _update_parent_states(self):
        """Parents become checked if any child is checked, else unchecked."""
        root = self.object_tree.invisibleRootItem()
        for i in range(root.childCount()):
            parent = root.child(i)
            # if any child checked → parent checked, else unchecked
            any_checked = any(
                parent.child(j).checkState(0) == Qt.CheckState.Checked
                for j in range(parent.childCount())
            )
            parent.setCheckState(0, Qt.CheckState.Checked if any_checked else Qt.CheckState.Unchecked)


    def on_object_tree_item_changed(self, item, column):
        # parent toggled → mirror to all children
        if item.childCount() > 0:
            state = item.checkState(0)
            blocker = QSignalBlocker(self.object_tree)
            for i in range(item.childCount()):
                item.child(i).setCheckState(0, state)
            blocker.unblock()
        # child toggled → recompute only its parent
        else:
            parent = item.parent()
            if not parent:
                return
            # parent checked if any child is
            any_checked = any(
                parent.child(i).checkState(0) == Qt.CheckState.Checked
                for i in range(parent.childCount())
            )
            blocker = QSignalBlocker(self.object_tree)
            parent.setCheckState(0, Qt.CheckState.Checked if any_checked else Qt.CheckState.Unchecked)
            blocker.unblock()


    def toggle_all_items(self):
        """Check/uncheck all otype leaf items."""
        leaves      = list(self._iterate_leaf_items())
        all_checked = all(li.checkState(0) == Qt.CheckState.Checked for li in leaves)
        new_state   = Qt.CheckState.Unchecked if all_checked else Qt.CheckState.Checked

        blocker = QSignalBlocker(self.object_tree)
        for li in leaves:
            li.setCheckState(0, new_state)
        blocker.unblock()

        self._update_parent_states()


    def save_custom_list(self):
        """
        Serializes the currently checked otypes to a .json file.
        """
        types = self.get_selected_object_types()
        path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Custom Type List",
            "",
            "JSON Files (*.json)"
        )
        if not path:
            return
        if not path.lower().endswith(".json"):
            path += ".json"
        try:
            with open(path, "w") as f:
                json.dump(types, f, indent=2)
            self.status_label.setText(f"👍 Saved list to {os.path.basename(path)}")
        except Exception as e:
            QMessageBox.critical(self, "Save Failed", str(e))


    def load_custom_list(self):
        """
        Reads a .json of otype codes and re-checks only those.
        """
        path, _ = QFileDialog.getOpenFileName(
            self,
            "Load Custom Type List",
            "",
            "JSON Files (*.json)"
        )
        if not path:
            return

        try:
            with open(path, "r") as f:
                types = set(json.load(f))
        except Exception as e:
            QMessageBox.critical(self, "Load Failed", str(e))
            return

        # block signals so we don't recurse
        blocker = QSignalBlocker(self.object_tree)
        for li in self._iterate_leaf_items():
            li.setCheckState(
                0,
                Qt.CheckState.Checked if li.text(0) in types else Qt.CheckState.Unchecked
            )
        blocker.unblock()

        # now update parents
        self._update_parent_states()
        self.status_label.setText(f"📂 Loaded list from {os.path.basename(path)}")

    def toggle_advanced_search(self):
        """Toggle the visibility of the advanced search panel."""
        is_visible = self.advanced_search_panel_widget.isVisible()
        self.advanced_search_panel_widget.setVisible(not is_visible)

    def save_results_as_csv(self):
        """Save the results from the TreeWidget as a CSV file."""
        path, _ = QFileDialog.getSaveFileName(self, "Save CSV", "", "CSV Files (*.csv)")
        if path:
            with open(path, mode='w', newline='') as file:
                writer = csv.writer(file)
                # Write header
                writer.writerow(["RA", "Dec", "Name", "Diameter", "Type", "Long Type", "Redshift", "Comoving Radial Distance (GLy)"])

                # Write data from TreeWidget
                for i in range(self.results_tree.topLevelItemCount()):
                    item = self.results_tree.topLevelItem(i)
                    row_data = [item.text(column) for column in range(self.results_tree.columnCount())]
                    writer.writerow(row_data)

            QMessageBox.information(self, "CSV Saved", f"Results successfully saved to {path}")        

    def filter_visible_objects(self):
        """Filter objects based on visibility threshold."""
        if not self.main_image:  # Ensure there's an image loaded
            QMessageBox.warning(self, "No Image", "Please load an image first.")
            return

        n = 0.2  # Threshold multiplier, adjust as needed
        median, std_dev = self.calculate_image_statistics(self.main_image)

        # Remove objects below threshold from results
        filtered_results = []
        for obj in self.results:
            if self.is_marker_visible(obj, median, std_dev, n):
                filtered_results.append(obj)

        # Update the results and redraw the markers
        self.results = filtered_results
        self.update_results_tree()
        self.main_preview.draw_query_results()

    def calculate_image_statistics(self, image):
        """Calculate median and standard deviation for a grayscale image efficiently using OpenCV."""
        
        # Convert QPixmap to QImage if necessary
        qimage = image.toImage()

        # Convert QImage to a format compatible with OpenCV
        width = qimage.width()
        height = qimage.height()
        ptr = qimage.bits()
        ptr.setsize(height * width * 4)  # 4 channels (RGBA)
        img_array = np.array(ptr).reshape(height, width, 4)  # Convert to RGBA array

        # Convert to grayscale for analysis
        gray_image = cv2.cvtColor(img_array, cv2.COLOR_RGBA2GRAY)

        # Calculate median and standard deviation
        median = np.median(gray_image)
        _, std_dev = cv2.meanStdDev(gray_image)

        return median, std_dev[0][0]  # std_dev returns a 2D array, so we extract the single value
    
    def is_marker_visible(self, marker, median, std_dev, n):
        """Check if the marker's brightness is above the threshold."""
        threshold = median + n * std_dev
        check_size = 8  # Define a 4x4 region around the marker

        # Convert QPixmap to QImage to access pixel colors
        image = self.main_image.toImage()

        # Get marker coordinates in pixel space
        ra, dec = marker.get('ra'), marker.get('dec')
        if ra is not None and dec is not None:
            x, y = self.calculate_pixel_from_ra_dec(ra, dec)
            if x is None or y is None:
                return False  # Skip marker if it can't be converted to pixels
        else:
            return False

        # Calculate brightness in a 4x4 region around marker coordinates
        brightness_values = []
        for dx in range(-check_size // 2, check_size // 2):
            for dy in range(-check_size // 2, check_size // 2):
                px = x + dx
                py = y + dy
                if 0 <= px < image.width() and 0 <= py < image.height():
                    color = image.pixelColor(px, py)  # Get color from QImage
                    brightness = color.value() if color.isValid() else 0  # Adjust for grayscale
                    brightness_values.append(brightness)

        if brightness_values:
            average_brightness = sum(brightness_values) / len(brightness_values)
            return average_brightness > threshold
        else:
            return False



    def update_results_tree(self):
        """Refresh the TreeWidget to reflect current results."""
        self.results_tree.clear()
        for obj in self.results:
            item = QTreeWidgetItem([
                str(obj['ra']),
                str(obj['dec']),
                obj['name'],
                str(obj['diameter']),
                obj['short_type'],
                obj['long_type'],
                str(obj['redshift']),
                str(obj['comoving_distance'])
            ])
            self.results_tree.addTopLevelItem(item)

    def toggle_object_names(self, state):
        """Toggle the visibility of object names based on the checkbox state."""
        self.show_names = state == Qt.CheckState.Checked
        self.show_names = bool(state)        
        self.main_preview.draw_query_results()  # Redraw to apply the change


    # Function to clear search results and remove markers
    def clear_search_results(self):
        """Clear the search results and remove all markers."""
        self.results_tree.clear()        # Clear the results from the tree
        self.results = []                # Clear the results list
        self.main_preview.results = []   # Clear results from the main preview
        self.main_preview.selected_object = None
        self.main_preview.draw_query_results()  # Redraw the main image without markers
        self.status_label.setText("Results cleared.")

    def on_tree_item_clicked(self, item):
        """Handle item click in the TreeWidget to highlight the associated object."""
        object_name = item.text(2)

        # Find the object in results
        selected_object = next(
            (obj for obj in self.results if obj.get("name") == object_name), None
        )

        if selected_object:
            # Set the selected object in MainWindow and update views
            self.selected_object = selected_object
            self.main_preview.select_object(selected_object)
            self.main_preview.draw_query_results()
            self.main_preview.update_mini_preview() 
            
            

    def on_tree_item_double_clicked(self, item):
        """Handle double-click event on a TreeWidget item to open SIMBAD or NED URL based on source."""
        object_name = item.text(2)  # Assuming 'Name' is in the third column

        # parse only if float() fails
        def parse_value(txt):
            try:
                return float(txt)
            except ValueError:
                parts = txt.strip().split()
                if len(parts) == 3:
                    a, b, c = parts
                    sign = -1 if a.startswith('-') else 1
                    return sign * (abs(float(a)) + float(b)/60 + float(c)/3600)
                raise

        ra  = parse_value(item.text(0).strip())
        dec = parse_value(item.text(1).strip())

        # lookup, falling back to string→float only on failure
        def get_parsed(result, key):
            try:
                return float(result[key])
            except ValueError:
                return parse_value(result[key])

        entry = next(
            (r for r in self.query_results
            if get_parsed(r, 'ra') == ra and get_parsed(r, 'dec') == dec),
            None
        )
        source = (entry.get('source') if entry else 'Simbad') or 'Simbad'
        print(f"[DEBUG] Matched source: {source!r}")  # ← debug print

        s = source.strip().lower()

        if s == "simbad" and object_name:
            encoded = quote(object_name)
            webbrowser.open(
                f"https://simbad.cds.unistra.fr/simbad/sim-basic?"
                f"Ident={encoded}&submit=SIMBAD+search"
            )

        elif "viz" in s:   # catches 'Vizier', etc.
            radius   = 5/60  # arcminutes
            dec_sign = "%2B" if dec >= 0 else "-"
            webbrowser.open(
                f"http://ned.ipac.caltech.edu/conesearch?"
                f"search_type=Near%20Position%20Search&"
                f"ra={ra:.6f}d&"
                f"dec={dec_sign}{abs(dec):.6f}d&"
                f"radius={radius:.3f}&"
                "in_csys=Equatorial&in_equinox=J2000.0"
            )

        elif s == "mast":
            webbrowser.open(
                f"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html?"
                f"searchQuery={ra}%2C{dec}%2Cradius%3D0.0006"
            )
           

    def copy_ra_dec_to_clipboard(self):
        """Copy the currently displayed RA and Dec to the clipboard."""
        # Access the RA and Dec labels directly
        ra_text = self.ra_label.text()
        dec_text = self.dec_label.text()
        
        # Combine RA and Dec text for clipboard
        clipboard_text = f"{ra_text}, {dec_text}"
        
        clipboard = QApplication.instance().clipboard()
        clipboard.setText(clipboard_text)
        
        QMessageBox.information(self, "Copied", "Current RA/Dec copied to clipboard!")
    

    @pyqtSlot()
    def open_image(self):
        """Slot for the “Load...” button — always pops up the file dialog."""
        path, _ = QFileDialog.getOpenFileName(
            self, "Open Image", "", 
            "Images (*.png *.jpg *.jpeg *.tif *.tiff *.fit *.fits *.xisf)"
        )
        if path:
            self._load_image(path)

    def load_image_path(self, path: str):
        """Call this when you already know the filename."""
        if path:
            self._load_image(path)

    def _sanitize_wcs_header(self, header):
        """
        Coerce WCS/SIP keywords to proper numeric types and fix common SIP issues.
        If SIP remains inconsistent, drop SIP keywords so astropy WCS can still load.
        """
        from copy import deepcopy
        import numpy as np

        hdr = deepcopy(header)

        def _to_int(key):
            if key in hdr:
                try:
                    v = hdr[key]
                    if isinstance(v, (int, np.integer)):
                        return
                    # handle strings like '2' or '2.0'
                    hdr[key] = int(float(str(v).strip().strip("'\"")))
                except Exception:
                    # if it's garbage, remove it so we can fall back cleanly
                    del hdr[key]

        def _to_float(key):
            if key in hdr:
                try:
                    v = hdr[key]
                    if isinstance(v, (float, int, np.floating, np.integer)):
                        hdr[key] = float(v)
                    else:
                        hdr[key] = float(str(v).strip().strip("'\""))
                except Exception:
                    # if it's truly bad, just leave it; astropy may ignore it
                    pass

        # 1) Ensure core integer fields
        for k in ("NAXIS", "NAXIS1", "NAXIS2", "A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"):
            _to_int(k)

        # 2) Mirror missing A/B order if only one is present
        a_order = hdr.get("A_ORDER")
        b_order = hdr.get("B_ORDER")
        if (a_order is None) ^ (b_order is None):
            try:
                val = int(a_order if a_order is not None else b_order)
                hdr["A_ORDER"] = val
                hdr["B_ORDER"] = val
            except Exception:
                # will be handled by SIP drop step below
                pass

        # 3) Coerce SIP coefficients to float
        for key in list(hdr.keys()):
            if key in ("A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"):
                continue
            if key.startswith(("A_", "B_", "AP_", "BP_")):
                try:
                    _to_float(key)
                except Exception:
                    # if a specific coeff is junk, remove it
                    try:
                        del hdr[key]
                    except Exception:
                        pass

        # 4) Coerce standard WCS numeric keywords to float
        for key in list(hdr.keys()):
            if key.startswith(("CD", "PC", "CDELT", "CRVAL", "CRPIX", "CROTA")) or key in ("EQUINOX", "EPOCH", "LONPOLE", "LATPOLE"):
                _to_float(key)

        # 5) If SIP is still inconsistent, drop SIP so WCS loads without distortion
        a_order = hdr.get("A_ORDER")
        b_order = hdr.get("B_ORDER")
        sip_ok = (a_order is not None and b_order is not None)
        if not sip_ok:
            for key in list(hdr.keys()):
                if key in ("A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER") or key.startswith(("A_", "B_", "AP_", "BP_")):
                    del hdr[key]
            # Also remove "-SIP" tag from CTYPE if present to avoid implying SIP
            for c in ("CTYPE1", "CTYPE2"):
                if c in hdr and isinstance(hdr[c], str) and "SIP" in hdr[c]:
                    hdr[c] = hdr[c].replace("-SIP", "")

        return hdr

    def _load_image(self, path: str):
        img_array, original_header, bit_depth, is_mono = load_image(path)
        self.image_path = path
        if img_array is not None:

            self.image_data = img_array
            self.original_header = original_header
            self.bit_depth = bit_depth
            self.is_mono = is_mono

            # Prepare image for display
            if img_array.ndim == 2:  # Single-channel image
                img_array = np.stack([img_array] * 3, axis=-1)  # Expand to 3 channels


            # Prepare image for display
            img = (img_array * 255).astype(np.uint8)
            height, width, _ = img.shape
            bytes_per_line = 3 * width
            qimg = QImage(img.tobytes(), width, height, bytes_per_line, QImage.Format.Format_RGB888)
            pixmap = QPixmap.fromImage(qimg)

            self.main_image = pixmap
            scaled_pixmap = pixmap.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            self.mini_preview.setPixmap(scaled_pixmap)

            self.main_scene.clear()
            self.main_scene.addPixmap(pixmap)
            self.main_preview.setSceneRect(QRectF(pixmap.rect()))
            self.zoom_level = 1.0
            self.main_preview.resetTransform()
            self.main_preview.centerOn(self.main_scene.sceneRect().center())
            self.update_green_box()

            # Initialize WCS from FITS header if it is a FITS file
            if self.image_path.lower().endswith(('.fits', '.fit')):
                with fits.open(self.image_path) as hdul:
                    raw_header = hdul[0].header
                    self.header = self._sanitize_wcs_header(raw_header) 
                    
                    try:
                        # Use only the first two dimensions for WCS
                        self.wcs = WCS(self.header, naxis=2, relax=True)
                        
                        # Calculate and set pixel scale
                        pixel_scale_matrix = self.wcs.pixel_scale_matrix
                        self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
                        self.center_ra, self.center_dec = self.wcs.wcs.crval
                        self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
                        self.print_corner_coordinates()
                        
                        print(f"Header CROTA2 Value: {self.header.get('CROTA2', 'Not Found')}")

                        # Display WCS information
                        # Set orientation based on WCS data if available
                        if 'CROTA2' in self.header:
                            try:
                                self.orientation = float(self.header['CROTA2'])  # Convert to float
                            except (ValueError, TypeError):
                                self.orientation = None
                                print("CROTA2 found, but could not convert to float.")
                        else:
                            # Use calculate_orientation if CROTA2 is not present
                            self.orientation = calculate_orientation(self.header)
                            if self.orientation is None:
                                print("Orientation: CD matrix elements not found in WCS header.")

                        # --- ✅ Ensure `self.orientation` is a float before using it ---
                        if self.orientation is not None:
                            try:
                                self.orientation = float(self.orientation)  # Final conversion check
                                print(f"Orientation: {self.orientation:.2f}°")
                                self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                            except (ValueError, TypeError):
                                print(f"Failed to format orientation: {self.orientation}")
                                self.orientation_label.setText("Orientation: N/A")
                        else:
                            self.orientation_label.setText("Orientation: N/A")


                        print(f"WCS data loaded from FITS header: RA={self.center_ra}, Dec={self.center_dec}, "
                            f"Pixel Scale={self.pixscale} arcsec/px")
                        
                        
                    except ValueError as e:
                        print("Error initializing WCS:", e)
                        QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from FITS header.")
            elif self.image_path.lower().endswith('.xisf'):
                # Load WCS from XISF properties
                xisf_meta = self.extract_xisf_metadata(self.image_path)
                self.metadata = xisf_meta  # Ensure metadata is stored in self.metadata for later use

                # Construct WCS header from XISF properties
                header = self.construct_fits_header_from_xisf(xisf_meta)
                if header:
                    try:
                        header = self._sanitize_wcs_header(header)
                        self.initialize_wcs_from_header(header)
                    except ValueError as e:
                        print("Error initializing WCS from XISF:", e)
                        QMessageBox.warning(self, "WCS Error", "Failed to load WCS data from XISF properties.")
            else:
                # For non-FITS images (e.g., JPEG, PNG), prompt directly for a blind solve
                self.prompt_blind_solve()

    def extract_xisf_metadata(self, xisf_path):
        """
        Extract metadata from a .xisf file, focusing on WCS and essential image properties.
        """
        try:
            # Load the XISF file
            xisf = XISF(xisf_path)
            
            # Extract file and image metadata
            self.file_meta = xisf.get_file_metadata()
            self.image_meta = xisf.get_images_metadata()[0]  # Get metadata for the first image
            return self.image_meta
        except Exception as e:
            print(f"Error reading XISF metadata: {e}")
            return None

    def initialize_wcs_from_header(self, header):
        """ Initialize WCS data from a FITS header or constructed XISF header """
        try:
            # Use only the first two dimensions for WCS
            self.wcs = WCS(header, naxis=2, relax=True)
            
            # Calculate and set pixel scale
            pixel_scale_matrix = self.wcs.pixel_scale_matrix
            self.pixscale = np.sqrt(pixel_scale_matrix[0, 0]**2 + pixel_scale_matrix[1, 0]**2) * 3600  # arcsec/pixel
            self.center_ra, self.center_dec = self.wcs.wcs.crval
            self.wcs_header = self.wcs.to_header(relax=True)  # Store the full WCS header, including non-standard keywords
            self.print_corner_coordinates()

            # --- 🔍 Debugging Output ---
            print(f"Header CROTA2 Value: {header.get('CROTA2', 'Not Found')}")

            # Display WCS information
            if 'CROTA2' in header:
                try:
                    self.orientation = float(header['CROTA2'])  # Convert to float
                except (ValueError, TypeError):
                    self.orientation = None
                    print("CROTA2 found, but could not convert to float.")
            else:
                self.orientation = calculate_orientation(header)
                if self.orientation is None:
                    print("Orientation: CD matrix elements not found in WCS header.")

            # --- ✅ Ensure `self.orientation` is a float before using it ---
            if self.orientation is not None:
                try:
                    self.orientation = float(self.orientation)  # Final conversion check
                    print(f"Orientation: {self.orientation:.2f}°")
                    self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                except (ValueError, TypeError):
                    print("Final conversion failed. Orientation is not a float.")
                    self.orientation_label.setText("Orientation: N/A")
            else:
                print("Orientation is None.")
                self.orientation_label.setText("Orientation: N/A")

            print(f"WCS data loaded: RA={self.center_ra}, Dec={self.center_dec}, Pixel Scale={self.pixscale} arcsec/px")

        except ValueError as e:
            raise ValueError(f"WCS initialization error: {e}")

    def construct_fits_header_from_xisf(self, xisf_meta):
        """ Convert XISF metadata to a FITS header compatible with WCS """
        header = fits.Header()

        # numeric‐only keys (everything except CTYPE1/2)
        numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2",
            "CDELT1", "CDELT2", "A_ORDER", "B_ORDER",
            "AP_ORDER", "BP_ORDER"
        }

        for keyword, entries in xisf_meta.get('FITSKeywords', {}).items():
            for entry in entries:
                if 'value' not in entry:
                    continue
                val = entry['value']
                if keyword in ("CTYPE1", "CTYPE2"):
                    # always a string
                    header[keyword] = val
                elif keyword in numeric_keys:
                    # try integer, then float
                    try:
                        header[keyword] = int(val)
                    except (ValueError, TypeError):
                        header[keyword] = float(val)
                else:
                    # anything else just store raw
                    header[keyword] = val

        # ensure CTYPEs exist
        header.setdefault('CTYPE1', 'RA---TAN')
        header.setdefault('CTYPE2', 'DEC--TAN')

        # Add SIP distortion suffix if SIP coefficients are present
        if any(key in header for key in ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]):
            header['CTYPE1'] = 'RA---TAN-SIP'
            header['CTYPE2'] = 'DEC--TAN-SIP'

        # Set default reference pixel to the center of the image
        header.setdefault('CRPIX1', self.image_data.shape[1] / 2)
        header.setdefault('CRPIX2', self.image_data.shape[0] / 2)

        # Retrieve RA and DEC values if available
        if 'RA' in xisf_meta['FITSKeywords']:
            header['CRVAL1'] = float(xisf_meta['FITSKeywords']['RA'][0]['value'])  # Reference RA
        if 'DEC' in xisf_meta['FITSKeywords']:
            header['CRVAL2'] = float(xisf_meta['FITSKeywords']['DEC'][0]['value'])  # Reference DEC

        # Calculate pixel scale if focal length and pixel size are available
        if 'FOCALLEN' in xisf_meta['FITSKeywords'] and 'XPIXSZ' in xisf_meta['FITSKeywords']:
            focal_length = float(xisf_meta['FITSKeywords']['FOCALLEN'][0]['value'])  # in mm
            pixel_size = float(xisf_meta['FITSKeywords']['XPIXSZ'][0]['value'])  # in μm
            pixel_scale = (pixel_size * 206.265) / focal_length  # arcsec/pixel
            header['CDELT1'] = -pixel_scale / 3600.0
            header['CDELT2'] = pixel_scale / 3600.0
        else:
            header['CDELT1'] = -2.77778e-4  # ~1 arcsecond/pixel
            header['CDELT2'] = 2.77778e-4

        # Populate CD matrix using the XISF LinearTransformationMatrix if available
        if 'XISFProperties' in xisf_meta and 'PCL:AstrometricSolution:LinearTransformationMatrix' in xisf_meta['XISFProperties']:
            linear_transform = xisf_meta['XISFProperties']['PCL:AstrometricSolution:LinearTransformationMatrix']['value']
            header['CD1_1'] = linear_transform[0][0]
            header['CD1_2'] = linear_transform[0][1]
            header['CD2_1'] = linear_transform[1][0]
            header['CD2_2'] = linear_transform[1][1]
        else:
            # Use pixel scale for CD matrix if no linear transformation is defined
            header['CD1_1'] = header['CDELT1']
            header['CD1_2'] = 0.0
            header['CD2_1'] = 0.0
            header['CD2_2'] = header['CDELT2']

        # Ensure numeric types for SIP distortion keywords if present
        sip_keywords = ["A_ORDER", "B_ORDER", "AP_ORDER", "BP_ORDER"]
        for sip_key in sip_keywords:
            if sip_key in xisf_meta['XISFProperties']:
                try:
                    value = xisf_meta['XISFProperties'][sip_key]['value']
                    header[sip_key] = int(value) if isinstance(value, str) and value.isdigit() else float(value)
                except ValueError:
                    pass  # Ignore any invalid conversion

        return header

    def print_corner_coordinates(self):
        """Print the RA/Dec coordinates of the four corners of the image for debugging purposes."""
        if not hasattr(self, 'wcs'):
            print("WCS data is incomplete, cannot calculate corner coordinates.")
            return

        width = self.main_image.width()
        height = self.main_image.height()

        # Define the corner coordinates
        corners = {
            "Top-Left": (0, 0),
            "Top-Right": (width, 0),
            "Bottom-Left": (0, height),
            "Bottom-Right": (width, height)
        }

        print("Corner RA/Dec coordinates:")
        for corner_name, (x, y) in corners.items():
            ra, dec = self.calculate_ra_dec_from_pixel(x, y)
            ra_hms = self.convert_ra_to_hms(ra)
            dec_dms = self.convert_dec_to_dms(dec)
            print(f"{corner_name}: RA={ra_hms}, Dec={dec_dms}")

    def calculate_ra_dec_from_pixel(self, x, y):
        """Convert pixel coordinates (x, y) to RA/Dec using Astropy WCS."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert pixel coordinates to sky coordinates
        ra, dec = self.wcs.all_pix2world(x, y, 0)

        return ra, dec
                        


    def update_ra_dec_from_mouse(self, event):
        """Update RA and Dec based on mouse position over the main preview."""
        if self.main_image and self.wcs:
            pos = self.main_preview.mapToScene(event.pos())
            x, y = int(pos.x()), int(pos.y())

            if 0 <= x < self.main_image.width() and 0 <= y < self.main_image.height():
                ra, dec = self.calculate_ra_dec_from_pixel(x, y)
                ra_hms = self.convert_ra_to_hms(ra)
                dec_dms = self.convert_dec_to_dms(dec)

                # Update RA/Dec labels
                self.ra_label.setText(f"RA: {ra_hms}")
                self.dec_label.setText(f"Dec: {dec_dms}")

                # --- 🔍 Debugging Output ---
                #print(f"Current Orientation Type: {type(self.orientation)}, Value: {self.orientation}")

                # ✅ Ensure `self.orientation` is a float before formatting
                if self.orientation is not None:
                    try:
                        self.orientation = float(self.orientation)  # Final safeguard conversion
                        self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
                    except (ValueError, TypeError):
                        print(f"Failed to format orientation: {self.orientation}")
                        self.orientation_label.setText("Orientation: N/A")
                else:
                    self.orientation_label.setText("Orientation: N/A")
        else:
            self.ra_label.setText("RA: N/A")
            self.dec_label.setText("Dec: N/A")
            self.orientation_label.setText("Orientation: N/A")



    def convert_ra_to_hms(self, ra_deg):
        """Convert Right Ascension in degrees to Hours:Minutes:Seconds format."""
        ra_hours = ra_deg / 15.0  # Convert degrees to hours
        hours = int(ra_hours)
        minutes = int((ra_hours - hours) * 60)
        seconds = (ra_hours - hours - minutes / 60.0) * 3600
        return f"{hours:02d}h{minutes:02d}m{seconds:05.2f}s"

    def convert_dec_to_dms(self, dec_deg):
        """Convert Declination in degrees to Degrees:Minutes:Seconds format."""
        sign = "-" if dec_deg < 0 else "+"
        dec_deg = abs(dec_deg)
        degrees = int(dec_deg)
        minutes = int((dec_deg - degrees) * 60)
        seconds = (dec_deg - degrees - minutes / 60.0) * 3600
        degree_symbol = "\u00B0"
        return f"{sign}{degrees:02d}{degree_symbol}{minutes:02d}m{seconds:05.2f}s"                 

    def check_astrometry_data(self, header):
        return "CTYPE1" in header and "CTYPE2" in header

    def prompt_blind_solve(self):
        reply = QMessageBox.question(
            self, "Astrometry Data Missing",
            "No astrometry data found in the image. Would you like to perform a blind solve?",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        if reply == QMessageBox.StandardButton.Yes:
            self.perform_blind_solve()

    def perform_blind_solve2(self):
        """
        First attempts to plate-solve the loaded image using ASTAP.
        If that fails, falls back to performing a blind solve via Astrometry.net.
        Updates the WCS (self.wcs) and header (self.header) accordingly.
        """
        # --- First, try ASTAP plate solve ---
        solved_header = self.plate_solve_image()  # This method should try to solve via ASTAP and return a header (or None).
        if solved_header is not None:
            # instead of manually doing header.update + WCS(...)
            self.apply_wcs_header(solved_header)
            return

        # --- If ASTAP plate solve failed, fall back to blind solve via Astrometry.net ---

        # Load or prompt for API key
        api_key = load_api_key()
        if not api_key:
            api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
            if ok and api_key:
                save_api_key(api_key)
            else:
                self.status_label.setText("API Key Required: Blind solve cannot proceed without an API key.")
                QApplication.processEvents()
                return

        try:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()

            # Step 1: Login to Astrometry.net
            session_key = self.login_to_astrometry(api_key)

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()
            
            # Step 2: Upload the image and get submission ID
            subid = self.upload_image_to_astrometry(self.image_path, session_key)

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            
            # Step 3: Poll for the job ID until it's available
            job_id = self.poll_submission_status(subid)
            if not job_id:
                raise TimeoutError("Failed to retrieve job ID from Astrometry.net after multiple attempts.")
            
            self.status_label.setText("Status: Job ID found, processing image...")
            QApplication.processEvents()

            # Step 4a: Poll for the calibration data, ensuring RA/Dec are available
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                raise TimeoutError("Calibration data did not complete in the expected timeframe.")
            
            # Set pixscale and other necessary attributes from calibration data
            self.pixscale = calibration_data.get('pixscale')

            self.status_label.setText("Status: Calibration complete, downloading WCS file...")
            QApplication.processEvents()

            # Step 4b: Download the WCS FITS file for complete calibration data
            wcs_header = self.retrieve_and_apply_wcs(job_id)
            if not wcs_header:
                raise TimeoutError("Failed to retrieve WCS FITS file from Astrometry.net.")

            self.status_label.setText("Status: Applying astrometric solution to the image...")
            QApplication.processEvents()

            # Apply calibration data to the WCS
            self.apply_wcs_header(wcs_header)
            self.status_label.setText("Status: Blind Solve Complete.")
            #QMessageBox.information(self, "Blind Solve Complete", "Astrometric solution applied successfully.")
        except Exception as e:
            self.status_label.setText("Status: Blind Solve Failed.")
            #QMessageBox.critical(self, "Blind Solve Failed", f"An error occurred: {str(e)}")

    def perform_blind_solve(self):
        """
        First attempts to plate-solve the loaded image using ASTAP.
        If that fails, falls back to performing a blind solve via Astrometry.net.
        Updates the WCS (self.wcs) and header (self.header) accordingly.
        """
        # --- First, try ASTAP plate solve ---
        self.status_label.setText("Status: Attempting ASTAP plate solve...")
        QApplication.processEvents()
        solved_header = self.plate_solve_image()  # This method should try to solve via ASTAP and return a header (or None).
        if solved_header is not None:
            self.status_label.setText("ASTAP plate solve succeeded.")
            # instead of manually doing header.update + WCS(...)
            self.apply_wcs_header(solved_header)
            QMessageBox.information(self, "Plate Solve", 
                                    "ASTAP plate solve succeeded. WCS, orientation, and pixscale updated.")
            return

        # --- If ASTAP plate solve failed, fall back to blind solve via Astrometry.net ---
        self.status_label.setText("Status: ASTAP failed. Proceeding with blind solve via Astrometry.net...")
        QApplication.processEvents()

        # Load or prompt for API key
        api_key = load_api_key()
        if not api_key:
            api_key, ok = QInputDialog.getText(self, "Enter API Key", "Please enter your Astrometry.net API key:")
            if ok and api_key:
                save_api_key(api_key)
            else:
                self.status_label.setText("API Key Required: Blind solve cannot proceed without an API key.")
                QApplication.processEvents()
                return

        try:
            self.status_label.setText("Status: Logging in to Astrometry.net...")
            QApplication.processEvents()

            # Step 1: Login to Astrometry.net
            session_key = self.login_to_astrometry(api_key)

            self.status_label.setText("Status: Uploading image to Astrometry.net...")
            QApplication.processEvents()
            
            # Step 2: Upload the image and get submission ID
            subid = self.upload_image_to_astrometry(self.image_path, session_key)

            self.status_label.setText("Status: Waiting for job ID...")
            QApplication.processEvents()
            
            # Step 3: Poll for the job ID until it's available
            job_id = self.poll_submission_status(subid)
            if not job_id:
                raise TimeoutError("Failed to retrieve job ID from Astrometry.net after multiple attempts.")
            
            self.status_label.setText("Status: Job ID found, processing image...")
            QApplication.processEvents()

            # Step 4a: Poll for the calibration data, ensuring RA/Dec are available
            calibration_data = self.poll_calibration_data(job_id)
            if not calibration_data:
                raise TimeoutError("Calibration data did not complete in the expected timeframe.")
            
            # Set pixscale and other necessary attributes from calibration data
            self.pixscale = calibration_data.get('pixscale')

            self.status_label.setText("Status: Calibration complete, downloading WCS file...")
            QApplication.processEvents()

            # Step 4b: Download the WCS FITS file for complete calibration data
            wcs_header = self.retrieve_and_apply_wcs(job_id)
            if not wcs_header:
                raise TimeoutError("Failed to retrieve WCS FITS file from Astrometry.net.")

            self.status_label.setText("Status: Applying astrometric solution to the image...")
            QApplication.processEvents()

            # Apply calibration data to the WCS
            self.apply_wcs_header(wcs_header)
            self.status_label.setText("Status: Blind Solve Complete.")
            QMessageBox.information(self, "Blind Solve Complete", "Astrometric solution applied successfully.")
        except Exception as e:
            self.status_label.setText("Status: Blind Solve Failed.")
            QMessageBox.critical(self, "Blind Solve Failed", f"An error occurred: {str(e)}")

    def plate_solve_image(self):
        """
        Attempts to plate-solve the loaded image using ASTAP,
        first trying a seeded solve (RA, SPD, scale, binning),
        then falling back to a blind solve if anything is missing.
        On success, updates self.header and self.wcs.
        """
        if not hasattr(self, 'image_path') or not self.image_path:
            return

        # 1) Ensure ASTAP path
        astap_exe = self.settings.value("astap/exe_path", "", type=str)
        if not astap_exe or not os.path.exists(astap_exe):
            filt = "Executables (*.exe);;All Files (*)" if sys.platform.startswith("win") else "Executables (astap);;All Files (*)"
            new_path, _ = QFileDialog.getOpenFileName(self, "Select ASTAP Executable", "", filt)
            if not new_path:
                return
            astap_exe = new_path
            self.settings.setValue("astap/exe_path", astap_exe)

        # 2) Write out the normalized FITS for ASTAP
        normalized = self.stretch_image(self.image_data.astype(np.float32))
        try:
            tmp_path = self.save_temp_fits_image(normalized, self.image_path)
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error saving temp FITS: {e}")
            return

        # 3) Seed arguments from header
        raw_hdr = None
        if isinstance(self.original_header, fits.Header):
            raw_hdr = self.original_header
        elif self.image_path.lower().endswith(('.fits','.fit')):
            with fits.open(self.image_path, memmap=False) as hdul:
                raw_hdr = hdul[0].header

        seed_args = []
        if isinstance(raw_hdr, fits.Header):
            # debug-dump
            print("🔍 Raw header contents:")
            for k,v in raw_hdr.items():
                print(f"    {k} = {v}")

            try:
                # RA→hours, SPD
                ra_deg = float(raw_hdr["CRVAL1"])
                dec_deg= float(raw_hdr["CRVAL2"])
                ra_h    = ra_deg / 15.0
                spd     = dec_deg + 90.0

                # plate scale from CD matrix (°/px→″/px)
                cd1 = float(raw_hdr.get("CD1_1", raw_hdr.get("CDELT1",0)))
                cd2 = float(raw_hdr.get("CD2_1", raw_hdr.get("CDELT2",0)))
                scale = np.hypot(cd1, cd2) * 3600.0

                # apply XBINNING/YBINNING
                bx = int(raw_hdr.get("XBINNING", 1))
                by = int(raw_hdr.get("YBINNING", bx))
                if bx != by:
                    print(f"⚠️ Unequal binning: {bx}×{by}, averaging.")
                binf = (bx+by)/2.0
                scale *= binf

                seed_args = [
                    "-ra",    f"{ra_h:.6f}",
                    "-spd",   f"{spd:.6f}",
                    "-scale", f"{scale:.3f}"
                ]
                print(f"🔸 Seeding ASTAP: RA={ra_h:.6f}h, SPD={spd:.6f}°, scale={scale:.3f}\"/px (×{binf} bin)")
            except Exception as e:
                print("⚠️ Failed to build seed args, will do blind solve:", e)

        # 4) Build ASTAP args
        if seed_args:
            args = ["-f", tmp_path] + seed_args + ["-wcs", "-sip"]
        else:
            args = ["-f", tmp_path, "-r", "179", "-fov", "0", "-z", "0", "-wcs", "-sip"]

        print("▶️ Running ASTAP with arguments:", args)

        # create and launch the process
        process = QProcess(self)
        process.start(astap_exe, args)
        if not process.waitForStarted(5000):
            #QMessageBox.critical(self, "Plate Solve", "Failed to start ASTAP process.")
            os.remove(tmp_path)
            
            return None
        if not process.waitForFinished(300000):
            #QMessageBox.critical(self, "Plate Solve", "ASTAP process timed out.")
            os.remove(tmp_path)
            return None

        exit_code = process.exitCode()
        stdout = process.readAllStandardOutput().data().decode()
        stderr = process.readAllStandardError().data().decode()
        print("ASTAP exit code:", exit_code)
        print("ASTAP STDOUT:\n", stdout)
        print("ASTAP STDERR:\n", stderr)
        
        if exit_code != 0:
            os.remove(tmp_path)
            #QMessageBox.warning(self, "Plate Solve", "ASTAP failed. Falling back to blind solve.")
            
            return None

        # --- Retrieve the initial solved header from the temporary FITS file ---
        try:
            with fits.open(tmp_path, memmap=False) as hdul:
                solved_header = dict(hdul[0].header)
            for key in ["COMMENT", "HISTORY", "END"]:
                solved_header.pop(key, None)
            print("Initial solved header retrieved from temporary FITS file:")
            for key, value in solved_header.items():
                print(f"{key} = {value}")
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error reading solved header: {e}")
            os.remove(tmp_path)
            
            return None

        # --- Check for a .wcs file and merge its header if present ---
        wcs_path = os.path.splitext(tmp_path)[0] + ".wcs"
        if os.path.exists(wcs_path):
            try:
                wcs_header = {}
                with open(wcs_path, "r") as f:
                    text = f.read()
                    # Matches a FITS header keyword and its value (with an optional comment).
                    pattern = r"(\w+)\s*=\s*('?[^/']*'?)[\s/]"
                    for match in re.finditer(pattern, text):
                        key = match.group(1).strip().upper()
                        val = match.group(2).strip()
                        if val.startswith("'") and val.endswith("'"):
                            val = val[1:-1].strip()
                        wcs_header[key] = val
                wcs_header.pop("END", None)
                print("WCS header retrieved from .wcs file:")
                for key, value in wcs_header.items():
                    print(f"{key} = {value}")
                # Merge the parsed WCS header into the solved header.
                solved_header.update(wcs_header)
            except Exception as e:
                print("Error reading .wcs file:", e)
        else:
            print("No .wcs file found; using header from temporary FITS.")

        # --- If loaded from a slot, merge the original file path from slot metadata ---
        if getattr(self, "_from_slot", False) and hasattr(self, "_slot_meta"):
            if "file_path" not in solved_header and "file_path" in self._slot_meta:
                solved_header["file_path"] = self._slot_meta["file_path"]
                print("Merged file_path from slot metadata into solved header.")

        # --- Add any missing required WCS keywords ---
        required_keys = {
            "CTYPE1": "RA---TAN",
            "CTYPE2": "DEC--TAN",
            "RADECSYS": "ICRS",
            "WCSAXES": 2,
            # CRVAL1, CRVAL2, CRPIX1, CRPIX2 are ideally provided by ASTAP.
        }
        for key, default in required_keys.items():
            if key not in solved_header:
                solved_header[key] = default
                print(f"Added missing key {key} with default value {default}.")

        # --- Convert keys that are expected to be numeric from strings to numbers ---
        expected_numeric_keys = {
            "CRPIX1", "CRPIX2", "CRVAL1", "CRVAL2", "CROTA1", "CROTA2",
            "CDELT1", "CDELT2", "CD1_1", "CD1_2", "CD2_1", "CD2_2", "WCSAXES"
        }
        for key in expected_numeric_keys:
            if key in solved_header:
                try:
                    # For keys that should be integers, you can use int(float(...)) if necessary.
                    solved_header[key] = float(solved_header[key])
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to float.")

        # --- Ensure integer keywords are stored as integers ---
        for key in ["WCSAXES", "NAXIS", "NAXIS1", "NAXIS2", "NAXIS3"]:
            if key in solved_header:
                try:
                    solved_header[key] = int(float(solved_header[key]))
                except ValueError:
                    print(f"Warning: Could not convert {key} value '{solved_header[key]}' to int.")


        os.remove(tmp_path)
        print("ASTAP plate solving successful. Final solved header:")
        for key, value in solved_header.items():
            print(f"{key} = {value}")

        # --------------------------------------------------------------------
        # 1) Make sure A_ORDER/B_ORDER exist in pairs:
        if "B_ORDER" in solved_header and "A_ORDER" not in solved_header:
            solved_header["A_ORDER"] = solved_header["B_ORDER"]
        if "A_ORDER" in solved_header and "B_ORDER" not in solved_header:
            solved_header["B_ORDER"] = solved_header["A_ORDER"]

        # 2) Convert SIP‐order keywords to ints:
        for key in ("A_ORDER","B_ORDER","AP_ORDER","BP_ORDER"):
            if key in solved_header:
                solved_header[key] = int(float(solved_header[key]))

        # 3) Convert every SIP coefficient to float:
        for k in list(solved_header):
            if re.match(r"^(?:A|B|AP|BP)_[0-9]+_[0-9]+$", k):
                solved_header[k] = float(solved_header[k])

        # --------------------------------------------------------------------
        # 4) Now rebuild your FITS header from the dict, preserving ordering:
        new_hdr = fits.Header()
        for key, val in solved_header.items():
            # skip any stray non‑FITS metadata
            if key == "file_path":
                continue
            new_hdr[key] = val

        # 5) Finally swap in the new header and re-init WCS (with SIP!)
        self.header = new_hdr
        try:
            self.wcs = WCS(self.header, naxis=2, relax=True)
        except Exception as e:
            QMessageBox.critical(self, "Plate Solve", f"Error initializing WCS from solved header:\n{e}")
            return

        return solved_header


    def save_temp_fits_image(self, normalized_image, image_path: str):
        """
        Save the normalized_image as a FITS file to a temporary file.
        
        If the original image is FITS, this method retrieves the stored metadata
        from the ImageManager and passes it directly to save_image().
        If not, it generates a minimal header.
        
        Returns the path to the temporary FITS file.
        """
        # Always save as FITS.
        selected_format = "fits"
        bit_depth = "32-bit floating point"
        is_mono = (normalized_image.ndim == 2 or 
                   (normalized_image.ndim == 3 and normalized_image.shape[2] == 1))
        
        # If the original image is FITS, try to get its stored metadata.
        original_header = None
        if image_path.lower().endswith((".fits", ".fit")):
            if self.parent() and hasattr(self.parent(), "image_manager"):
                # Use the metadata from the current slot.
                _, meta = self.parent().image_manager.get_current_image_and_metadata()
                # Assume that meta already contains a proper 'original_header'
                # (or the entire meta is the header).
                original_header = meta.get("original_header", None)
            # If nothing is stored, fall back to creating a minimal header.
            if original_header is None:
                print("No stored FITS header found; creating a minimal header.")
                original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        else:
            # For non-FITS images, generate a minimal header.
            original_header = self.create_minimal_fits_header(normalized_image, is_mono)
        
        # Create a temporary filename.
        tmp_file = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp_path = tmp_file.name
        tmp_file.close()
        
        try:
            # Call your global save_image() exactly as in AstroEditingSuite.
            save_image(
                img_array=normalized_image,
                filename=tmp_path,
                original_format=selected_format,
                bit_depth=bit_depth,
                original_header=original_header,
                is_mono=is_mono
                # (image_meta and file_meta can be omitted if not needed)
            )
            print(f"Temporary normalized FITS saved to: {tmp_path}")
        except Exception as e:
            print("Error saving temporary FITS file using save_image():", e)
            raise e
        return tmp_path

    def create_minimal_fits_header(self, img_array, is_mono=False):
        """
        Creates a minimal FITS header when the original header is missing.
        """

        header = Header()
        header['SIMPLE'] = (True, 'Standard FITS file')
        header['BITPIX'] = -32  # 32-bit floating-point data
        header['NAXIS'] = 2 if is_mono else 3
        header['NAXIS1'] = img_array.shape[2] if img_array.ndim == 3 and not is_mono else img_array.shape[1]  # Image width
        header['NAXIS2'] = img_array.shape[1] if img_array.ndim == 3 and not is_mono else img_array.shape[0]  # Image height
        if not is_mono:
            header['NAXIS3'] = img_array.shape[0] if img_array.ndim == 3 else 1  # Number of color channels
        header['BZERO'] = 0.0  # No offset
        header['BSCALE'] = 1.0  # No scaling
        header.add_comment("Minimal FITS header generated by AstroEditingSuite.")

        return header

    def stretch_image(self, image):
        """
        Perform an unlinked linear stretch on the image.
        Each channel is stretched independently by subtracting its own minimum,
        recording its own median, and applying the stretch formula.
        Returns the stretched image in [0,1].
        """
        was_single_channel = False  # Flag to check if image was single-channel

        # If the image is 2D or has one channel, convert to 3-channel
        if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1):
            was_single_channel = True
            image = np.stack([image] * 3, axis=-1)

        image = image.astype(np.float32).copy()
        stretched_image = image.copy()
        self.stretch_original_mins = []
        self.stretch_original_medians = []
        target_median = 0.02

        for c in range(3):
            channel_min = np.min(stretched_image[..., c])
            self.stretch_original_mins.append(channel_min)
            stretched_image[..., c] -= channel_min
            channel_median = np.median(stretched_image[..., c])
            self.stretch_original_medians.append(channel_median)
            if channel_median != 0:
                numerator = (channel_median - 1) * target_median * stretched_image[..., c]
                denominator = (
                    channel_median * (target_median + stretched_image[..., c] - 1)
                    - target_median * stretched_image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                stretched_image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median is zero. Skipping stretch.")

        stretched_image = np.clip(stretched_image, 0.0, 1.0)
        self.was_single_channel = was_single_channel
        return stretched_image

    def unstretch_image(self, image):
        """
        Undo the unlinked linear stretch using stored parameters.
        Returns the unstretched image.
        """
        original_mins = self.stretch_original_mins
        original_medians = self.stretch_original_medians
        was_single_channel = self.was_single_channel

        image = image.astype(np.float32).copy()

        if image.ndim == 2:
            channel_median = np.median(image)
            original_median = original_medians[0]
            original_min = original_mins[0]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image
                denominator = channel_median * (original_median + image - 1) - original_median * image
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image = numerator / denominator
            else:
                print("Channel median or original median is zero. Skipping unstretch.")
            image += original_min
            image = np.clip(image, 0, 1)
            return image

        for c in range(3):
            channel_median = np.median(image[..., c])
            original_median = original_medians[c]
            original_min = original_mins[c]
            if channel_median != 0 and original_median != 0:
                numerator = (channel_median - 1) * original_median * image[..., c]
                denominator = (
                    channel_median * (original_median + image[..., c] - 1)
                    - original_median * image[..., c]
                )
                denominator = np.where(denominator == 0, 1e-6, denominator)
                image[..., c] = numerator / denominator
            else:
                print(f"Channel {c} - Median or original median is zero. Skipping unstretch.")
            image[..., c] += original_min

        image = np.clip(image, 0, 1)
        if was_single_channel and image.ndim == 3:
            image = np.mean(image, axis=2, keepdims=True)
        return image

    def retrieve_and_apply_wcs(self, job_id):
        """Download the wcs.fits file from Astrometry.net, extract WCS header data, and apply it."""
        try:
            wcs_url = f"https://nova.astrometry.net/wcs_file/{job_id}"
            wcs_filepath = "wcs.fits"
            max_retries = 10
            delay = 10  # seconds
            
            for attempt in range(max_retries):
                # Attempt to download the file
                response = requests.get(wcs_url, stream=True)
                response.raise_for_status()

                # Save the WCS file locally
                with open(wcs_filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)

                # Check if the downloaded file is a valid FITS file
                try:
                    with fits.open(wcs_filepath, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
                        # If it opens correctly, return the header
                        wcs_header = hdul[0].header
                        print("WCS header successfully retrieved.")
                        self.wcs = WCS(wcs_header)
                        return wcs_header
                except Exception as e:
                    print(f"Attempt {attempt + 1}: Failed to process WCS file - possibly HTML instead of FITS. Retrying in {delay} seconds...")
                    print(f"Error: {e}")
                    time.sleep(delay)  # Wait and retry
            
            print("Failed to download a valid WCS FITS file after multiple attempts.")
            return None

        except requests.exceptions.RequestException as e:
            print(f"Error downloading WCS file: {e}")
        except Exception as e:
            print(f"Error processing WCS file: {e}")
            
        return None



    def apply_wcs_header(self, wcs_header):
        """
        Apply a solved WCS header.  Sets self.wcs, self.pixscale (arcsec/pix),
        self.orientation, and updates the orientation label.
        """
        # 1) Initialize the WCS object
        self.wcs = WCS(wcs_header, naxis=2, relax=True)

        # 2) Derive pixel scale (arcsec/pixel)
        if 'CDELT1' in wcs_header:
            # CDELT1 is degrees/pixel
            self.pixscale = abs(float(wcs_header['CDELT1'])) * 3600.0
        elif 'CD1_1' in wcs_header and 'CD2_2' in wcs_header:
            # approximate from CD matrix determinant
            det = (wcs_header['CD1_1'] * wcs_header['CD2_2']
                - wcs_header['CD1_2'] * wcs_header['CD2_1'])
            pixscale_deg = math.sqrt(abs(det))
            self.pixscale = pixscale_deg * 3600.0
        else:
            self.pixscale = None
            print("Warning: could not derive pixscale from header.")

        # 3) Extract orientation (CROTA2 if present)
        if 'CROTA2' in wcs_header:
            self.orientation = float(wcs_header['CROTA2'])
        else:
            # fallback to your custom function
            self.orientation = calculate_orientation(wcs_header)

        # 4) Update the GUI label
        if self.orientation is not None:
            self.orientation_label.setText(f"Orientation: {self.orientation:.2f}°")
        else:
            self.orientation_label.setText("Orientation: N/A")

        print(f" -> pixscale = {self.pixscale} arcsec/pixel")
        print(f" -> orientation = {self.orientation}°")
        try:
            cr1 = wcs_header.get('CRVAL1')
            cr2 = wcs_header.get('CRVAL2')
            if cr1 is not None and cr2 is not None:
                self.center_ra  = float(cr1)
                self.center_dec = float(cr2)
                print(f" -> center RA/Dec = {self.center_ra:.6f}, {self.center_dec:.6f}")
        except Exception:
            print("Warning: could not extract CRVAL1/CRVAL2")        


    def calculate_pixel_from_ra_dec(self, ra, dec):
        """Convert RA/Dec to pixel coordinates using the WCS data."""
        if not hasattr(self, 'wcs'):
            print("WCS not initialized.")
            return None, None

        # Convert RA and Dec to pixel coordinates using the WCS object
        sky_coord = SkyCoord(ra, dec, unit=(u.deg, u.deg), frame='icrs')
        x, y = self.wcs.world_to_pixel(sky_coord)
        
        return int(x), int(y)

    def login_to_astrometry(self, api_key):
        try:
            response = requests.post(
                ASTROMETRY_API_URL + "login",
                data={'request-json': json.dumps({"apikey": api_key})}
            )
            response_data = response.json()
            if response_data.get("status") == "success":
                return response_data["session"]
            else:
                raise ValueError("Login failed: " + response_data.get("error", "Unknown error"))
        except Exception as e:
            raise Exception("Login to Astrometry.net failed: " + str(e))


    def upload_image_to_astrometry(self, image_path, session_key):
        try:
            # Check if the file is XISF format
            file_extension = os.path.splitext(image_path)[-1].lower()
            if file_extension == ".xisf":
                # Load the XISF image
                xisf = XISF(image_path)
                im_data = xisf.read_image(0)
                
                # Convert to a temporary TIFF file for upload
                temp_image_path = os.path.splitext(image_path)[0] + "_converted.tif"
                if im_data.dtype == np.float32 or im_data.dtype == np.float64:
                    im_data = np.clip(im_data, 0, 1) * 65535
                im_data = im_data.astype(np.uint16)

                # Save as TIFF
                if im_data.shape[-1] == 1:  # Grayscale
                    tiff.imwrite(temp_image_path, np.squeeze(im_data, axis=-1))
                else:  # RGB
                    tiff.imwrite(temp_image_path, im_data)

                print(f"Converted XISF file to TIFF at {temp_image_path} for upload.")
                image_path = temp_image_path  # Use the converted file for upload

            # Upload the image file
            with open(image_path, 'rb') as image_file:
                files = {'file': image_file}
                data = {
                    'request-json': json.dumps({
                        "publicly_visible": "y",
                        "allow_modifications": "d",
                        "session": session_key,
                        "allow_commercial_use": "d"
                    })
                }
                response = requests.post(ASTROMETRY_API_URL + "upload", files=files, data=data)
                response_data = response.json()
                if response_data.get("status") == "success":
                    return response_data["subid"]
                else:
                    raise ValueError("Image upload failed: " + response_data.get("error", "Unknown error"))

        except Exception as e:
            raise Exception("Image upload to Astrometry.net failed: " + str(e))

        finally:
            # Clean up temporary file if created
            if file_extension == ".xisf" and os.path.exists(temp_image_path):
                os.remove(temp_image_path)
                print(f"Temporary TIFF file {temp_image_path} deleted after upload.")



    def poll_submission_status(self, subid):
        """Poll Astrometry.net to retrieve the job ID once the submission is processed."""
        max_retries = 90  # Adjust as necessary
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"submissions/{subid}")
                response_data = response.json()
                jobs = response_data.get("jobs", [])
                if jobs and jobs[0] is not None:
                    return jobs[0]
                else:
                    print(f"Polling attempt {retries + 1}: Job not ready yet.")
            except Exception as e:
                print(f"Error while polling submission status: {e}")
            
            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries
        
        return None

    def poll_calibration_data(self, job_id):
        """Poll Astrometry.net to retrieve the calibration data once it's available."""
        max_retries = 90  # Retry for up to 15 minutes (90 * 10 seconds)
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(ASTROMETRY_API_URL + f"jobs/{job_id}/calibration/")
                response_data = response.json()
                if response_data and 'ra' in response_data and 'dec' in response_data:
                    print("Calibration data retrieved:", response_data)
                    return response_data  # Calibration data is complete
                else:
                    print(f"Calibration data not available yet (Attempt {retries + 1})")
            except Exception as e:
                print(f"Error retrieving calibration data: {e}")

            retries += 1
            time.sleep(10)  # Wait 10 seconds between retries

        return None


    #If originally a fits file update the header
    def update_fits_with_wcs(self, filepath, calibration_data):
        if not filepath.lower().endswith(('.fits', '.fit')):
            print("File is not a FITS file. Skipping WCS header update.")
            return

        print("Updating image with calibration data:", calibration_data)
        with fits.open(filepath, mode='update') as hdul:
            header = hdul[0].header
            header['CTYPE1'] = 'RA---TAN'
            header['CTYPE2'] = 'DEC--TAN'
            header['CRVAL1'] = calibration_data['ra']
            header['CRVAL2'] = calibration_data['dec']
            header['CRPIX1'] = hdul[0].data.shape[1] / 2
            header['CRPIX2'] = hdul[0].data.shape[0] / 2
            scale = calibration_data['pixscale'] / 3600
            orientation = np.radians(calibration_data['orientation'])
            header['CD1_1'] = -scale * np.cos(orientation)
            header['CD1_2'] = scale * np.sin(orientation)
            header['CD2_1'] = -scale * np.sin(orientation)
            header['CD2_2'] = -scale * np.cos(orientation)
            header['RADECSYS'] = 'ICRS'

    def on_mini_preview_press(self, event):
        # Set dragging flag and scroll the main preview to the position in the mini preview.
        self.dragging = True
        self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_drag(self, event):
        # Scroll to the new position while dragging in the mini preview.
        if self.dragging:
            self.scroll_main_preview_to_mini_position(event)

    def on_mini_preview_release(self, event):
        # Stop dragging
        self.dragging = False

    def scroll_main_preview_to_mini_position(self, event):
        """Scrolls the main preview to the corresponding position based on the mini preview click."""
        if self.main_image:
            # Get the click position in the mini preview
            click_x = event.pos().x()
            click_y = event.pos().y()
            
            # Calculate scale factors based on the difference in dimensions between main image and mini preview
            scale_factor_x = self.main_scene.sceneRect().width() / self.mini_preview.width()
            scale_factor_y = self.main_scene.sceneRect().height() / self.mini_preview.height()
            
            # Scale the click position to the main preview coordinates
            scaled_x = click_x * scale_factor_x
            scaled_y = click_y * scale_factor_y
            
            # Center the main preview on the calculated position
            self.main_preview.centerOn(scaled_x, scaled_y)
            
            # Update the green box after scrolling
            self.main_preview.update_mini_preview()

    def update_green_box(self):
        if self.main_image:
            factor_x = self.mini_preview.width() / self.main_image.width()
            factor_y = self.mini_preview.height() / self.main_image.height()
            
            # Get the current view rectangle in the main preview (in scene coordinates)
            view_rect = self.main_preview.mapToScene(self.main_preview.viewport().rect()).boundingRect()
            
            # Calculate the green box rectangle, shifted upward by half its height to center it
            green_box_rect = QRectF(
                view_rect.x() * factor_x,
                view_rect.y() * factor_y,
                view_rect.width() * factor_x,
                view_rect.height() * factor_y
            )
            
            # Scale the main image for the mini preview and draw the green box on it
            pixmap = self.main_image.scaled(self.mini_preview.size(), Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            painter = QPainter(pixmap)
            pen = QPen(QColor(0, 255, 0), 2)
            painter.setPen(pen)
            painter.drawRect(green_box_rect)
            painter.end()
            self.mini_preview.setPixmap(pixmap)

    @staticmethod
    def calculate_angular_distance(ra1, dec1, ra2, dec2):
        # Convert degrees to radians
        ra1, dec1, ra2, dec2 = map(math.radians, [ra1, dec1, ra2, dec2])

        # Haversine formula for angular distance
        delta_ra = ra2 - ra1
        delta_dec = dec2 - dec1
        a = (math.sin(delta_dec / 2) ** 2 +
            math.cos(dec1) * math.cos(dec2) * math.sin(delta_ra / 2) ** 2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
        angular_distance = math.degrees(c)
        return angular_distance
    
    @staticmethod
    def format_distance_as_dms(angle):
        degrees = int(angle)
        minutes = int((angle - degrees) * 60)
        seconds = (angle - degrees - minutes / 60) * 3600
        return f"{degrees}° {minutes}' {seconds:.2f}\""


    def wheel_zoom(self, event):
        if event.angleDelta().y() > 0:
            self.zoom_in()
        else:
            self.zoom_out()


    def zoom_in(self):
        self.zoom_level *= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()
        

    def zoom_out(self):
        self.zoom_level /= 1.2
        self.main_preview.setTransform(QTransform().scale(self.zoom_level, self.zoom_level))
        self.update_green_box()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.update_green_box()


    def compute_pixscale(self):
        """
        Computes the pixel scale (arcsec/pixel) from the header's CD keywords.
        """
        try:
            cd1_1 = float(self.header.get('CD1_1', 0))
            cd1_2 = float(self.header.get('CD1_2', 0))
            # Calculate scale in degrees per pixel and convert to arcsec.
            pixscale = math.sqrt(cd1_1**2 + cd1_2**2) * 3600.0
            print("Calculated pixscale from header:", pixscale)
            return pixscale
        except Exception as e:
            print("Error calculating pixscale:", e)
            return None

    def get_defined_radius(self):
        """
        Returns the radius (in arcminutes) for the current circle.
        If self.pixscale is None, attempt to calculate it manually.
        """
        if self.pixscale is None:
            self.pixscale = self.compute_pixscale()
            if self.pixscale is None:
                print("Warning: Could not compute pixscale from header.")
                return None

        # The circle_radius is in pixels; convert to arcminutes.
        return float((self.circle_radius * self.pixscale) / 3600.0)

    def update_circle_data(self):
        """Updates the status based on the circle's center and radius."""
        if self.circle_center and self.circle_radius > 0:
            # Make sure we have a valid pixscale.
            if self.pixscale is None:
                self.pixscale = self.compute_pixscale()
                if self.pixscale is None:
                    self.status_label.setText("No pixscale available for radius calculation.")
                    print("Warning: Pixscale is None. Cannot calculate radius in arcminutes.")
                    return

            # Convert circle center to RA/Dec and radius to arcminutes.
            ra, dec = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
            radius_arcmin = self.circle_radius * self.pixscale / 60.0  # from arcsec to arcmin
            self.status_label.setText(
                f"Circle set at center RA={ra:.6f}, Dec={dec:.6f}, radius={radius_arcmin:.2f} arcmin"
            )
        else:
            self.status_label.setText("No search area defined.")



    def get_defined_radius(self):
        """Calculate radius in degrees for the defined region (circle radius)."""
        if self.circle_radius <= 0:
            return 0
        return float((self.circle_radius * self.pixscale) / 3600.0)


    def query_simbad(self, radius_deg, max_results=None):
        """Two-step SIMBAD lookup with debug prints for flux/plx/sp data."""
        max_results = max_results if max_results is not None else self.max_results

        # ——— 1) Validate inputs ———
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area",
                                "Please define a search circle by Shift-clicking and dragging.")
            return

        ra_center, dec_center = self.calculate_ra_dec_from_pixel(
            self.circle_center.x(), self.circle_center.y()
        )
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates",
                                "Could not determine the RA/Dec of the circle center.")
            return

        selected_types = self.get_selected_object_types()
        if not selected_types:
            QMessageBox.warning(self, "No Object Types Selected",
                                "Please select at least one object type.")
            return

        # ——— 2) TAP query on BASIC ———
        query = f"""
            SELECT TOP {max_results}
                ra, dec, main_id,
                rvz_redshift, otype, galdim_majaxis
            FROM basic
            WHERE CONTAINS(
                POINT('ICRS', basic.ra, basic.dec),
                CIRCLE('ICRS', {ra_center}, {dec_center}, {radius_deg})
            ) = 1
        """
        for attempt in range(5):
            try:
                result = Simbad.query_tap(query)
                break
            except Exception as e:
                if attempt < 4:
                    time.sleep(1)
                else:
                    QMessageBox.critical(
                        self,
                        "Query Failed",
                        f"Try again later:\n{e}"
            )

        if result is None or len(result) == 0:
            QMessageBox.information(self, "No Results",
                                    "No objects found in the specified area.")
            return

        # ——— 3a) list of all “star” & binary/variable OTYPE codes ———
        star_codes = [
            "*","V*","Pe*","HB*","Y*O","Ae*","Em*","Be*","BS*","RG*","AB*",
            "C*","S*","sg*","s*r","s*y","s*b","HS*","pA*","WD*","LM*","BD*",
            "N*","OH*","TT*","WR*","PM*","HV*","C?*","Pec?","Y*?","TT?","C*?",
            "S*?","OH?","WR?","Be?","Ae?","HB?","RB?","sg?","s?r","s?y","s?b",
            "pA?","BS?","HS?","WD?",
            "**","EB*","Ce*","Ce?","cC*","**?",
            "EB?","Sy?","CV?","No?","XB?","LX?","HX?","RR?","WV?","LP?","Mi?"
        ]

        # 3b) build the two sub-criteria, un-encoded:
        ra_str  = f"{ra_center:.8f}"
        dec_str = f"{dec_center:+.8f}"   # keep the +/– sign
        rad_str = f"{radius_deg:.8f}d"

        region_crit = f"region(CIRCLE,{ra_str} {dec_str},{rad_str})"
        codes_list  = ",".join(f"'{c}'" for c in star_codes)
        otype_crit  = f"otypes in ({codes_list})"

        # combine with a literal '&' (not "AND")
        criteria = f"{region_crit}&{otype_crit}"

        # ——— 3c) fetch _only_ those via sim-sam ———
        sam_url = "https://simbad.cds.unistra.fr/simbad/sim-sam"
        params = {
            "Criteria":      criteria,
            "OutputMode":    "LIST",
            "maxObject":     str(max_results),
            "output.format": "votable",
            "output.params": ",".join([
                "MAIN_ID","RA","DEC",
                "FLUX(B)","FLUX(V)",
                "PLX_VALUE","RVZ_REDSHIFT",
                "OTYPE","SP_TYPE"
            ])
        }

        try:
            resp = requests.get(sam_url, params=params, timeout=300)
            resp.raise_for_status()

            vot = parse_single_table(BytesIO(resp.content))
            tbl = vot.to_table(use_names_over_ids=True)
            extras = { row["MAIN_ID"]: row for row in tbl }

        except Exception as e:
            print(f"DEBUG: sim-sam failed: {e}")
            QMessageBox.warning(
                self,
                "Star-only Extras Failed",
                "Could not fetch star flux/parallax—continuing without them."
            )
            extras = {}

        # ——— 4) Merge & populate results_tree exactly as before ———
        self.results_tree.clear()
        query_results = []

        for row in result:
            name       = row["main_id"]
            short_type = row["otype"]
            if short_type not in selected_types:
                continue

            # basics
            ra, dec = float(row["ra"]), float(row["dec"])
            diam     = row.get("galdim_majaxis", "N/A")
            rz       = row["rvz_redshift"]
            red_z    = float(rz) if rz is not None else None

            # pull extras only if it’s a star
            extra = extras.get(name, {})
            Bmag  = extra.get("FLUX_B")
            Vmag  = extra.get("FLUX_V")
            plx   = extra.get("PLX_VALUE")
            spec  = extra.get("SP_TYPE")

            if plx is not None:
                pv = abs(float(plx))          # <— absolute value here
                if pv > 0:
                    dist_pc  = 1000.0 / pv
                    dist_ly  = dist_pc * 3.261563777
                    # store comoving distance in Gyr for consistency with your zs_raw pipeline:
                    distance = round(dist_ly / 1e9, 9)
                    red_val  = pv              # use the positive parallax in the "redshift" column
                else:
                    # parallax was 0⇒ no distance
                    red_val  = red_z if red_z is not None else "--"
                    distance = (calculate_comoving_distance(red_val)
                                if red_val != "--" else "N/A")
            else:
                red_val  = red_z if red_z is not None else "--"
                distance = (calculate_comoving_distance(red_val)
                            if red_val != "--" else "N/A")

            # absolute V magnitude if we have Vmag & plx
            absV = None
            if Vmag is not None and plx and plx > 0:
                absV = Vmag - (5 * np.log10(1000.0 / plx) - 5)

            long_type = otype_long_name_lookup.get(short_type, short_type)

            # add to tree
            item = QTreeWidgetItem([
                f"{ra:.6f}", f"{dec:.6f}", name,
                str(diam), short_type, long_type,
                f"{red_val:.6f}" if isinstance(red_val, (int,float)) else str(red_val),
                f"{distance:.6f}" if isinstance(distance, float) else str(distance)
            ])
            self.results_tree.addTopLevelItem(item)

            query_results.append({
                'ra': ra, 'dec': dec, 'name': name,
                'diameter': diam,
                'short_type': short_type,
                'long_type': long_type,
                'redshift': red_val,
                'comoving_distance': distance,
                'source': "Simbad",
                'Bmag': Bmag, 'Vmag': Vmag,
                'parallax_mas': plx,
                'spectral_type': spec,
                'absolute_mag': absV
            })

        # ——— 5) Finally hand off to your preview/plotter ———
        self.main_preview.set_query_results(query_results)
        self.query_results = query_results
        self.update_object_count()



    def perform_deep_vizier_search(self):
        CATALOG_NAMES = {
            "J/ApJS/199/26":    "2MRS",
            "VII/259/6dfgs":    "6dF Galaxy Survey",
            "V/147/sdss12":     "SDSS DR12",
            "VII/250/2dfgrs":   "2dFGRS",
            "J/MNRAS/474/3875": "GAMA DR3",
            "VII/291/gladep":   "GLADE+",
            "VII/237":          "HyperLEDA",
            "VII/221/psc":      "IRAS PSCz",
            "II/246":           "2MASS PSC",
            "I/350/gaiaedr3":   "Gaia EDR3",
            "I/322A":           "UCAC4",
            "V/154":            "Pan-STARRS 1",
        }        
        """Perform a Vizier catalog search and parse results, querying redshift surveys first."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area",
                                "Please define a search circle by Shift-clicking and dragging.")
            return

        # Convert center to RA/Dec
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(
            self.circle_center.x(), self.circle_center.y()
        )
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates",
                                "Could not determine the RA/Dec of the circle center.")
            return

        radius_arcmin = float((self.circle_radius * self.pixscale) / 60.0)

        # Query true-redshift surveys first
        catalog_ids = [
            # 1) Major spectroscopic redshift surveys
            "J/ApJS/199/26",     # 2MASS Redshift Survey (2MRS)
            "VII/259/6dfgs",     # 6dF Galaxy Survey
            "V/147/sdss12",      # SDSS DR12 spectroscopic
            "VII/250/2dfgrs",    # 2dF Galaxy Redshift Survey (2dFGRS)
            "J/MNRAS/474/3875",  # GAMA DR3

            # 2) Meta-catalogs & composites
            "VII/291/gladep",    # GLADE+
            "VII/237",           # HyperLEDA
            "VII/221/psc",       # IRAS PSCz

            # 3) Photometric & astrometric surveys
            "II/246",            # 2MASS PSC
            "I/350/gaiaedr3",    # Gaia EDR3
            "I/322A",            # UCAC4
            "V/154"              # Pan-STARRS 1
        ]


        coord = SkyCoord(ra_center, dec_center, unit="deg")
        unique_entries = {}

        try:
            for catalog_id in catalog_ids:
                result = Vizier.query_region(
                    coord, radius=radius_arcmin * u.arcmin, catalog=catalog_id
                )
                if not result:
                    continue

                for row in result[0]:
                    # RA / Dec
                    ra = row.get("RAJ2000", row.get("RA_ICRS", None))
                    dec = row.get("DEJ2000", row.get("DE_ICRS", None))
                    if ra is None or dec is None:
                        continue
                    ra_str, dec_str = str(ra), str(dec)
                    key = (ra_str, dec_str)

                    # Name & types
                    name       = str(row.get("_2MASS", "") or row.get("Source", "") or row.get("SDSS12", ""))
                    type_short = CATALOG_NAMES.get(catalog_id, catalog_id)
                    long_type  = str(row.get("SpType", "N/A"))
                    diameter   = catalog_id

                    # ——— robust redshift/parallax parsing ———
                    if "cz" in row.colnames:
                        raw = row["cz"]
                        try:
                            cz = float(raw)
                            zval = cz / 299792.458
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "z" in row.colnames:
                        raw = row["z"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zhelio" in row.colnames:
                        raw = row["zhelio"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zcmb" in row.colnames:
                        raw = row["zcmb"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "zph" in row.colnames:
                        raw = row["zph"]
                        try:
                            zval = float(raw)
                            if np.isnan(zval):
                                raise ValueError
                            redshift = f"{zval:.6f}"
                            comoving_distance = f"{calculate_comoving_distance(zval):.5f} GLy"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    elif "Plx" in row.colnames:
                        raw = row["Plx"]
                        try:
                            pv = abs(float(raw))
                            redshift = f"{pv:.3f} (Parallax mas)"
                            comoving_distance = f"{1000/pv * 3.2615637769:.5f} Ly"
                        except Exception:
                            redshift = str(raw)
                            comoving_distance = "N/A"

                    else:
                        redshift = "N/A"
                        comoving_distance = "N/A"
                    # ——— end parsing block ———

                    # Duplicate handling: first entry wins, SDSS overrides Pan-STARRS
                    if key not in unique_entries:
                        unique_entries[key] = {
                            "ra": ra_str,
                            "dec": dec_str,
                            "name": name,
                            "diameter": diameter,
                            "short_type": type_short,
                            "long_type": long_type,
                            "redshift": redshift,
                            "comoving_distance": comoving_distance,
                            "source": "Vizier"
                        }
                    else:
                        existing = unique_entries[key]["diameter"]
                        if existing == "V/154" and diameter == "V/147/sdss12":
                            unique_entries[key].update({
                                "name": name,
                                "diameter": diameter,
                                "short_type": type_short,
                                "long_type": long_type,
                                "redshift": redshift,
                                "comoving_distance": comoving_distance,
                                "source": "Vizier"
                            })

            # Populate tree & preview
            all_results = []
            for e in unique_entries.values():
                item = QTreeWidgetItem([
                    e["ra"], e["dec"], e["name"], e["diameter"],
                    e["short_type"], e["long_type"],
                    e["redshift"], e["comoving_distance"]
                ])
                self.results_tree.addTopLevelItem(item)
                all_results.append(e)

            self.main_preview.set_query_results(all_results)
            self.query_results = all_results
            self.update_object_count()

        except Exception as err:
            QMessageBox.critical(self, "Vizier Search Failed", f"Failed to query Vizier: {err}")



    def perform_mast_search(self):
        """Perform a MAST cone search in the user-defined region using astroquery."""
        if not self.circle_center or self.circle_radius <= 0:
            QMessageBox.warning(self, "No Search Area", "Please define a search circle by Shift-clicking and dragging.")
            return

        # Calculate RA and Dec for the center point
        ra_center, dec_center = self.calculate_ra_dec_from_pixel(self.circle_center.x(), self.circle_center.y())
        if ra_center is None or dec_center is None:
            QMessageBox.warning(self, "Invalid Coordinates", "Could not determine the RA/Dec of the circle center.")
            return

        # Convert radius from arcseconds to degrees (MAST uses degrees)
        search_radius_deg = float((self.circle_radius * self.pixscale) / 3600.0)  # Convert to degrees
        ra_center = float(ra_center)  # Ensure it's a regular float
        dec_center = float(dec_center)  # Ensure it's a regular float

        try:
            # Perform the MAST cone search using Mast.mast_query for the 'Mast.Caom.Cone' service
            observations = Mast.mast_query(
                'Mast.Caom.Cone',
                ra=ra_center,
                dec=dec_center,
                radius=search_radius_deg
            )

            # Limit the results to the first 100 rows
            limited_observations = observations[:100]

            if len(observations) == 0:
                QMessageBox.information(self, "No Results", "No objects found in the specified area on MAST.")
                return

            # Clear previous results
            self.results_tree.clear()
            query_results = []

            # Process each observation in the results
            for obj in limited_observations:

                def safe_get(value):
                    return "N/A" if np.ma.is_masked(value) else str(value)


                ra = safe_get(obj.get("s_ra", "N/A"))
                dec = safe_get(obj.get("s_dec", "N/A"))
                target_name = safe_get(obj.get("target_name", "N/A"))
                instrument = safe_get(obj.get("instrument_name", "N/A"))
                jpeg_url = safe_get(obj.get("dataURL", "N/A"))  # Adjust URL field as needed

                # Add to TreeWidget
                item = QTreeWidgetItem([
                    ra,
                    dec,
                    target_name,
                    instrument,
                    "N/A",  # Placeholder for observation date if needed
                    "N/A",  # Other placeholder
                    jpeg_url,  # URL in place of long type
                    "MAST"  # Source
                ])
                self.results_tree.addTopLevelItem(item)

                # Append full details as a dictionary to query_results
                query_results.append({
                    'ra': ra,
                    'dec': dec,
                    'name': target_name,
                    'diameter': instrument,
                    'short_type': "N/A",
                    'long_type': jpeg_url,
                    'redshift': "N/A",
                    'comoving_distance': "N/A",
                    'source': "Mast"
                })

            # Set query results in the CustomGraphicsView for display
            self.main_preview.set_query_results(query_results)
            self.query_results = query_results  # Keep a reference to results in MainWindow
            self.update_object_count()

        except Exception as e:
            QMessageBox.critical(self, "MAST Query Failed", f"Failed to query MAST: {str(e)}")

    def toggle_show_names(self, state):
        """Toggle showing/hiding names on the main image."""
        self.show_names = state == Qt.CheckState.Checked
        self.main_preview.draw_query_results()  # Redraw with or without names

    def clear_results(self):
        """Clear the search results and remove markers from the main image."""
        self.results_tree.clear()
        self.main_preview.clear_query_results()
        self.status_label.setText("Results cleared.")

    def open_settings_dialog(self):
        """Open settings dialog to adjust max results and marker type."""
        dialog = QDialog(self)
        dialog.setWindowTitle("Settings")
        
        layout = QFormLayout(dialog)
        

        # Max Results setting using CustomSpinBox
        max_results_spinbox = CustomSpinBox(minimum=1, maximum=100000, initial=self.max_results, step=1)
        layout.addRow("Max Results:", max_results_spinbox)

        
        # Marker Style selection
        marker_style_combo = QComboBox()
        marker_style_combo.addItems(["Circle", "Crosshair"])
        marker_style_combo.setCurrentText(self.marker_style)
        layout.addRow("Marker Style:", marker_style_combo)

        # Force Blind Solve button
        force_blind_solve_button = QPushButton("Force Blind Solve")
        force_blind_solve_button.clicked.connect(lambda: self.force_blind_solve(dialog))
        layout.addWidget(force_blind_solve_button)
        
        # OK and Cancel buttons
        buttons = QDialogButtonBox(QDialogButtonBox.StandardButton.Ok | QDialogButtonBox.StandardButton.Cancel)
        buttons.accepted.connect(lambda: self.update_settings(max_results_spinbox.value, marker_style_combo.currentText(), dialog))
        buttons.rejected.connect(dialog.reject)
        layout.addWidget(buttons)
        
        dialog.setLayout(layout)
        dialog.exec()

    def update_settings(self, max_results, marker_style, dialog):
        """Update settings based on dialog input."""
        self.max_results = max_results
        self.marker_style = marker_style  # Store the selected marker style
        self.main_preview.draw_query_results()
        dialog.accept()

    def force_blind_solve(self, dialog):
        """Force a blind solve on the currently loaded image."""
        dialog.accept()  # Close the settings dialog
        self.perform_blind_solve()  # Call the blind solve function


def extract_wcs_data(file_path):
    try:
        # Open the FITS file with minimal validation to ignore potential errors in non-essential parts
        with fits.open(file_path, ignore_missing_simple=True, ignore_missing_end=True) as hdul:
            header = hdul[0].header

            # Extract essential WCS parameters
            wcs_params = {}
            keys_to_extract = [
                'WCSAXES', 'CTYPE1', 'CTYPE2', 'EQUINOX', 'LONPOLE', 'LATPOLE',
                'CRVAL1', 'CRVAL2', 'CRPIX1', 'CRPIX2', 'CUNIT1', 'CUNIT2',
                'CD1_1', 'CD1_2', 'CD2_1', 'CD2_2', 'A_ORDER', 'A_0_0', 'A_0_1', 
                'A_0_2', 'A_1_0', 'A_1_1', 'A_2_0', 'B_ORDER', 'B_0_0', 'B_0_1', 
                'B_0_2', 'B_1_0', 'B_1_1', 'B_2_0', 'AP_ORDER', 'AP_0_0', 'AP_0_1', 
                'AP_0_2', 'AP_1_0', 'AP_1_1', 'AP_2_0', 'BP_ORDER', 'BP_0_0', 
                'BP_0_1', 'BP_0_2', 'BP_1_0', 'BP_1_1', 'BP_2_0'
            ]
            for key in keys_to_extract:
                if key in header:
                    wcs_params[key] = header[key]

            # Manually create a minimal header with WCS information
            wcs_header = fits.Header()
            for key, value in wcs_params.items():
                wcs_header[key] = value

            # Initialize WCS with this custom header
            wcs = WCS(wcs_header)
            print("WCS successfully initialized with minimal header.")
            return wcs

    except Exception as e:
        print(f"Error processing WCS file: {e}")
        return None

# Function to calculate comoving radial distance (in Gly)
def calculate_comoving_distance(z):
    z = abs(z)
    # Initialize variables
    WR = 4.165E-5 / ((H0 / 100) ** 2)  # Omega radiation
    WK = 1 - WM - WV - WR  # Omega curvature
    az = 1.0 / (1 + z)
    n = 1000  # number of points in integration

    # Comoving radial distance
    DCMR = 0.0
    for i in range(n):
        a = az + (1 - az) * (i + 0.5) / n
        adot = sqrt(WK + (WM / a) + (WR / (a ** 2)) + (WV * a ** 2))
        DCMR += 1 / (a * adot)
    
    DCMR = (1 - az) * DCMR / n
    DCMR_Gly = (c / H0) * DCMR * Mpc_to_Gly

    return round(DCMR_Gly, 6)  # Round to three decimal places for display

def calculate_orientation(header):
    """Calculate orientation from CD or PC matrix."""
    cd1_1 = header.get('CD1_1')
    cd1_2 = header.get('CD1_2')
    cd2_1 = header.get('CD2_1')
    cd2_2 = header.get('CD2_2')

    if all(v is not None for v in [cd1_1, cd1_2, cd2_1, cd2_2]):
        orientation = (np.degrees(np.arctan2(cd1_2, cd1_1)) + 180) % 360
        return orientation

    # Try PC matrix fallback
    pc1_1 = header.get('PC1_1')
    pc1_2 = header.get('PC1_2')
    cdelt1 = header.get('CDELT1')
    cdelt2 = header.get('CDELT2')

    if pc1_1 is not None and pc1_2 is not None and cdelt1 is not None and cdelt2 is not None:
        cd1_1 = pc1_1 * cdelt1
        cd1_2 = pc1_2 * cdelt1
        orientation = (np.degrees(np.arctan2(cd1_2, cd1_1)) + 180) % 360
        return orientation

    print("CD or PC matrix not found in header.")
    return None




# Set the directory for the images in the /imgs folder
if getattr(sys, 'frozen', False):  # Check if running as a PyInstaller bundle
    phase_folder = os.path.join(sys._MEIPASS, "imgs")  # Use PyInstaller's temporary directory with /imgs
else:
    phase_folder = os.path.join(os.path.dirname(__file__), "imgs")  # Use the directory of the script file with /imgs


# Set precision for Decimal operations
getcontext().prec = 24

# Suppress warnings
warnings.filterwarnings("ignore")


class CalculationThread(QThread):
    calculation_complete = pyqtSignal(pd.DataFrame, str)
    lunar_phase_calculated = pyqtSignal(int, str)  # phase_percentage, phase_image_name
    lst_calculated = pyqtSignal(str)
    status_update = pyqtSignal(str)

    def __init__(self, latitude, longitude, date, time, timezone, min_altitude, catalog_filters, object_limit):
        super().__init__()
        self.latitude = latitude
        self.longitude = longitude
        self.date = date
        self.time = time
        self.timezone = timezone
        self.min_altitude = min_altitude
        self.catalog_filters = catalog_filters
        self.object_limit = object_limit

    def get_catalog_file_path(self):
        # Define a user-writable location for the catalog (e.g., in the user's home directory)
        user_catalog_path = os.path.join(os.path.expanduser("~"), "celestial_catalog.csv")

        # Check if we are running in a PyInstaller bundle
        if not os.path.exists(user_catalog_path):
            bundled_catalog = os.path.join(getattr(sys, '_MEIPASS', os.path.dirname(__file__)), "celestial_catalog.csv")
            if os.path.exists(bundled_catalog):
                # Copy the bundled catalog to a writable location
                shutil.copyfile(bundled_catalog, user_catalog_path)

        return user_catalog_path  # Return the path to the user-writable catalog

    def run(self):
        try:
            # Convert date and time to astropy Time
            datetime_str = f"{self.date} {self.time}"
            local = pytz.timezone(self.timezone)
            naive_datetime = datetime.strptime(datetime_str, "%Y-%m-%d %H:%M")
            local_datetime = local.localize(naive_datetime)
            astropy_time = Time(local_datetime)

            # Define observer's location
            location = EarthLocation(lat=self.latitude * u.deg, lon=self.longitude * u.deg, height=0 * u.m)

            # Calculate Local Sidereal Time (LST)
            lst = astropy_time.sidereal_time('apparent', self.longitude * u.deg)
            self.lst_calculated.emit(f"Local Sidereal Time: {lst.to_string(unit=u.hour, precision=3)}")

            # Calculate lunar phase
            phase_percentage, phase_image_name = self.calculate_lunar_phase(astropy_time, location)
            self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)

            # Load celestial catalog
            catalog_file = self.get_catalog_file_path()
            if not os.path.exists(catalog_file):
                self.calculation_complete.emit(pd.DataFrame(), "Catalog file not found.")
                return

            df = pd.read_csv(catalog_file, encoding='ISO-8859-1')

            # Apply catalog filters **AFTER reading to avoid index mismatch**
            df = df[df['Catalog'].isin(self.catalog_filters)]
            df.dropna(subset=['RA', 'Dec'], inplace=True)

            # Ensure DataFrame is contiguous
            df.reset_index(drop=True, inplace=True)

            # Convert RA/Dec into SkyCoord objects **vectorized**
            sky_coords = SkyCoord(ra=df['RA'].values * u.deg, dec=df['Dec'].values * u.deg, frame='icrs')

            # Create an AltAz frame for observer location
            altaz_frame = AltAz(obstime=astropy_time, location=location)

            # **Vectorized altitude and azimuth calculation**
            altaz = sky_coords.transform_to(altaz_frame)
            df['Altitude'] = np.round(altaz.alt.deg, 1)
            df['Azimuth'] = np.round(altaz.az.deg, 1)

            # 1) Transform all catalog objects to AltAz:
            altaz_coords = sky_coords.transform_to(altaz_frame)

            # 2) Transform the Moon to AltAz, too:
            moon_altaz = get_body("moon", astropy_time, location).transform_to(altaz_frame)

            # 3) Now calculate separation in AltAz space:
            df['Degrees from Moon'] = np.round(altaz_coords.separation(moon_altaz).deg, 2)

            # **Apply altitude filter after calculations**
            df = df[df['Altitude'] >= self.min_altitude]

            # **Vectorized calculation of "Minutes to Transit"**
            ra_hours = df['RA'].values * (24 / 360.0)  # Convert degrees to hours
            time_diff = ((ra_hours - lst.hour) * u.hour) % (24 * u.hour)  # Hour difference
            df['Minutes to Transit'] = np.round(time_diff.value * 60, 1)

            # Correct Before/After Transit flags efficiently
            df['Before/After Transit'] = np.where(df['Minutes to Transit'] > 720, "After", "Before")
            df['Minutes to Transit'] = np.where(df['Minutes to Transit'] > 720, 1440 - df['Minutes to Transit'], df['Minutes to Transit'])

            # **Optimized Sorting & Selection**
            df = df.nsmallest(self.object_limit, 'Minutes to Transit')  # Faster than full sort

            self.calculation_complete.emit(df, "Calculation complete.")
        except Exception as e:
            self.calculation_complete.emit(pd.DataFrame(), f"Error: {str(e)}")




    def calculate_lunar_phase(self, astropy_time, location):
        moon = get_body("moon", astropy_time, location)
        sun = get_sun(astropy_time)
        elongation = moon.separation(sun).deg

        # Determine lunar phase percentage
        phase_percentage = (1 - np.cos(np.radians(elongation))) / 2 * 100
        phase_percentage = round(phase_percentage)

        # Determine if it is waxing or waning
        future_time = astropy_time + (6 * u.hour)
        future_moon = get_body("moon", future_time, location)
        future_sun = get_sun(future_time)
        future_elongation = future_moon.separation(future_sun).deg
        is_waxing = future_elongation > elongation

        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")


        # Select appropriate lunar phase image based on phase angle
        phase_image_name = "new_moon.png"  # Default

        if 0 <= elongation < 9:
            phase_image_name = "new_moon.png"
        elif 9 <= elongation < 18:
            phase_image_name = "waxing_crescent_1.png" if is_waxing else "waning_crescent_5.png"
        elif 18 <= elongation < 27:
            phase_image_name = "waxing_crescent_2.png" if is_waxing else "waning_crescent_4.png"
        elif 27 <= elongation < 36:
            phase_image_name = "waxing_crescent_3.png" if is_waxing else "waning_crescent_3.png"
        elif 36 <= elongation < 45:
            phase_image_name = "waxing_crescent_4.png" if is_waxing else "waning_crescent_2.png"
        elif 45 <= elongation < 54:
            phase_image_name = "waxing_crescent_5.png" if is_waxing else "waning_crescent_1.png"
        elif 54 <= elongation < 90:
            phase_image_name = "first_quarter.png"
        elif 90 <= elongation < 108:
            phase_image_name = "waxing_gibbous_1.png" if is_waxing else "waning_gibbous_4.png"
        elif 108 <= elongation < 126:
            phase_image_name = "waxing_gibbous_2.png" if is_waxing else "waning_gibbous_3.png"
        elif 126 <= elongation < 144:
            phase_image_name = "waxing_gibbous_3.png" if is_waxing else "waning_gibbous_2.png"
        elif 144 <= elongation < 162:
            phase_image_name = "waxing_gibbous_4.png" if is_waxing else "waning_gibbous_1.png"
        elif 162 <= elongation <= 180:
            phase_image_name = "full_moon.png"


        self.lunar_phase_calculated.emit(phase_percentage, phase_image_name)
        return phase_percentage, phase_image_name



class WhatsInMySky(QWidget):
    def __init__(self):
        super().__init__()
        self.settings_file = os.path.join(os.path.expanduser("~"), "sky_settings.json")
        self.settings = QSettings() 
        self.initUI()  # Build the UI
        self.load_settings()  # Load settings after UI is built
        self.object_limit = self.settings.value("object_limit", 100, type=int)

    def initUI(self):
        layout = QGridLayout()
        fixed_width = 150

        # Latitude, Longitude, Date, Time, Time Zone
        self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo = self.setup_basic_info_fields(layout, fixed_width)

        # Minimum Altitude, Catalog Filters, RA/Dec format
        self.min_altitude_entry, self.catalog_vars, self.ra_dec_format = self.setup_filters(layout, fixed_width)

        # Calculate Button, Status Label, Sidereal Time, Treeview for Results, Custom Object and Save Buttons
        self.setup_controls(layout, fixed_width)

        self.setLayout(layout)
        self.setMinimumWidth(1000)  # Ensures a wide enough starting window

    def setup_basic_info_fields(self, layout, fixed_width):
        self.latitude_entry = QLineEdit()
        self.latitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Latitude:"), 0, 0)
        layout.addWidget(self.latitude_entry, 0, 1)

        self.longitude_entry = QLineEdit()
        self.longitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Longitude:"), 1, 0)
        layout.addWidget(self.longitude_entry, 1, 1)

        self.date_entry = QLineEdit()
        self.date_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Date (YYYY-MM-DD):"), 2, 0)
        layout.addWidget(self.date_entry, 2, 1)

        self.time_entry = QLineEdit()
        self.time_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time (HH:MM):"), 3, 0)
        layout.addWidget(self.time_entry, 3, 1)

        self.timezone_combo = QComboBox()
        self.timezone_combo.addItems(pytz.all_timezones)
        self.timezone_combo.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Time Zone:"), 4, 0)
        layout.addWidget(self.timezone_combo, 4, 1)

        return self.latitude_entry, self.longitude_entry, self.date_entry, self.time_entry, self.timezone_combo

    def setup_filters(self, layout, fixed_width):
        self.min_altitude_entry = QLineEdit()
        self.min_altitude_entry.setFixedWidth(fixed_width)
        layout.addWidget(QLabel("Min Altitude (0-90 degrees):"), 5, 0)
        layout.addWidget(self.min_altitude_entry, 5, 1)

        catalog_frame = QScrollArea()
        catalog_widget = QWidget()
        catalog_layout = QGridLayout()
        self.catalog_vars = {}
        for i, catalog in enumerate(["Messier", "NGC", "IC", "Caldwell", "Abell", "Sharpless", "LBN", "LDN", "PNG", "User"]):
            chk = QCheckBox(catalog)
            chk.setChecked(False)
            catalog_layout.addWidget(chk, i // 5, i % 5)
            self.catalog_vars[catalog] = chk
        catalog_widget.setLayout(catalog_layout)
        catalog_frame.setWidget(catalog_widget)
        catalog_frame.setFixedWidth(fixed_width + 250)
        layout.addWidget(QLabel("Catalog Filters:"), 6, 0)
        layout.addWidget(catalog_frame, 6, 1)

        # RA/Dec format setup
        self.ra_dec_degrees = QRadioButton("Degrees")
        self.ra_dec_hms = QRadioButton("H:M:S / D:M:S")
        ra_dec_group = QButtonGroup()
        ra_dec_group.addButton(self.ra_dec_degrees)
        ra_dec_group.addButton(self.ra_dec_hms)
        self.ra_dec_degrees.setChecked(True)  # Default to Degrees format
        ra_dec_layout = QHBoxLayout()
        ra_dec_layout.addWidget(self.ra_dec_degrees)
        ra_dec_layout.addWidget(self.ra_dec_hms)
        layout.addWidget(QLabel("RA/Dec Format:"), 7, 0)
        layout.addLayout(ra_dec_layout, 7, 1)

        # Connect the radio buttons to the update function
        self.ra_dec_degrees.toggled.connect(self.update_ra_dec_format)
        self.ra_dec_hms.toggled.connect(self.update_ra_dec_format)

        return self.min_altitude_entry, self.catalog_vars, self.ra_dec_degrees

    def setup_controls(self, layout, fixed_width):
        # Calculate button
        calculate_button = QPushButton("Calculate")
        calculate_button.setFixedWidth(fixed_width)
        layout.addWidget(calculate_button, 8, 0)
        calculate_button.clicked.connect(self.start_calculation)

        # Status label
        self.status_label = QLabel("Status: Idle")
        layout.addWidget(self.status_label, 9, 0, 1, 2)

        # Sidereal time label
        self.lst_label = QLabel("Local Sidereal Time: {:.3f}".format(0.0))
        layout.addWidget(self.lst_label, 10, 0, 1, 2)

        # Lunar phase image and label
        self.lunar_phase_image_label = QLabel()
        layout.addWidget(self.lunar_phase_image_label, 0, 2, 4, 1)  # Position it appropriately

        self.lunar_phase_label = QLabel("Lunar Phase: N/A")
        layout.addWidget(self.lunar_phase_label, 4, 2)

        # Treeview for results (expand dynamically)
        self.tree = QTreeWidget()
        self.tree.setHeaderLabels([
            "Name", "RA", "Dec", "Altitude", "Azimuth", "Minutes to Transit", "Before/After Transit",
            "Degrees from Moon", "Alt Name", "Type", "Magnitude", "Size (arcmin)"
        ])
        self.tree.setSortingEnabled(True)
        header = self.tree.header()
        header.setSectionResizeMode(QHeaderView.ResizeMode.Interactive)  # Allow users to resize columns
        header.setStretchLastSection(False)  # Ensure last column is not stretched automatically

        self.tree.sortByColumn(5, Qt.SortOrder.AscendingOrder)
        layout.addWidget(self.tree, 11, 0, 1, 3)
        self.tree.itemDoubleClicked.connect(self.on_row_double_click)

        # Buttons at the bottom
        add_object_button = QPushButton("Add Custom Object")
        add_object_button.setFixedWidth(fixed_width)
        layout.addWidget(add_object_button, 12, 0)
        add_object_button.clicked.connect(self.add_custom_object)

        save_button = QPushButton("Save to CSV")
        save_button.setFixedWidth(fixed_width)
        layout.addWidget(save_button, 12, 1)
        save_button.clicked.connect(self.save_to_csv)

        # Settings button to change the number of objects displayed
        settings_button = QPushButton()
        settings_button.setIcon(QIcon(wrench_path))  # Use icon_path for the button's icon
        settings_button.setFixedWidth(fixed_width)
        layout.addWidget(settings_button, 12, 2)
        settings_button.clicked.connect(self.open_settings)        

        # Allow the main window to expand
        layout.setColumnStretch(2, 1)  # Makes the right column (with tree widget) expand as the window grows


    def start_calculation(self):
        # Gather the inputs
        latitude = float(self.latitude_entry.text())
        longitude = float(self.longitude_entry.text())
        date_str = self.date_entry.text()
        time_str = self.time_entry.text()
        timezone_str = self.timezone_combo.currentText()
        min_altitude = float(self.min_altitude_entry.text())

        # Validate inputs
        try:
            latitude = float(latitude)
            longitude = float(longitude)
            min_altitude = float(min_altitude)
        except ValueError:
            self.update_status("Invalid input: Latitude, Longitude, and Min Altitude must be numeric.")
            return

        # Save the settings
        self.save_settings(latitude, longitude, date_str, time_str, timezone_str, min_altitude)


        catalog_filters = [catalog for catalog, var in self.catalog_vars.items() if var.isChecked()]
        object_limit = self.object_limit

        # Set up and start the calculation thread
        self.calc_thread = CalculationThread(
            latitude, longitude, date_str, time_str, timezone_str,
            min_altitude, catalog_filters, object_limit
        )
        self.calc_thread.calculation_complete.connect(self.on_calculation_complete)
        self.calc_thread.lunar_phase_calculated.connect(self.update_lunar_phase)
        self.calc_thread.lst_calculated.connect(self.update_lst) 
        self.calc_thread.status_update.connect(self.update_status)
        self.update_status("Calculating...")
        self.calc_thread.start()


    def update_lunar_phase(self, phase_percentage, phase_image_name):
        # Update the lunar phase label
        self.lunar_phase_label.setText(f"Lunar Phase: {phase_percentage}% illuminated")

        # Define the path to the image
        phase_folder = os.path.join(sys._MEIPASS, "imgs") if getattr(sys, 'frozen', False) else os.path.join(os.path.dirname(__file__), "imgs")
        phase_image_path = os.path.join(phase_folder, phase_image_name)

        # Load and display the lunar phase image if it exists
        if os.path.exists(phase_image_path):
            pixmap = QPixmap(phase_image_path).scaled(100, 100, Qt.AspectRatioMode.KeepAspectRatio, Qt.TransformationMode.SmoothTransformation)
            self.lunar_phase_image_label.setPixmap(pixmap)
        else:
            print(f"Image not found: {phase_image_path}")     

    def on_calculation_complete(self, df, message):
        # Handle the data received from the calculation thread
        self.update_status(message)
        if not df.empty:
            self.tree.clear()
            for _, row in df.iterrows():
                # Prepare RA and Dec display based on selected format
                ra_display = row['RA']
                dec_display = row['Dec']

                if self.ra_dec_hms.isChecked():
                    # Convert degrees to H:M:S format
                    sky_coord = SkyCoord(ra=row['RA'] * u.deg, dec=row['Dec'] * u.deg)
                    ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                    dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')

                # Calculate Before/After Transit string
                before_after = row['Before/After Transit']

                # Ensure Size (arcmin) displays correctly as a string
                size_arcmin = row.get('Info', '')
                if pd.notna(size_arcmin):
                    size_arcmin = str(size_arcmin)  # Ensure it's treated as a string

                # Populate each row with the calculated data
                values = [
                    str(row['Name']) if pd.notna(row['Name']) else '',  # Ensure Name is a string or empty
                    str(ra_display),  # RA in either H:M:S or degrees format
                    str(dec_display),  # Dec in either H:M:S or degrees format
                    str(row['Altitude']) if pd.notna(row['Altitude']) else '',  # Altitude as string or empty
                    str(row['Azimuth']) if pd.notna(row['Azimuth']) else '',  # Azimuth as string or empty
                    str(int(row['Minutes to Transit'])) if pd.notna(row['Minutes to Transit']) else '',  # Minutes to Transit as integer string
                    before_after,  # Before/After Transit (already a string)
                    str(round(row['Degrees from Moon'], 2)) if pd.notna(row['Degrees from Moon']) else '',  # Degrees from Moon as rounded string or empty
                    row.get('Alt Name', '') if pd.notna(row.get('Alt Name', '')) else '',  # Alt Name as string or empty
                    row.get('Type', '') if pd.notna(row.get('Type', '')) else '',  # Type as string or empty
                    str(row.get('Magnitude', '')) if pd.notna(row.get('Magnitude', '')) else '',  # Magnitude as string or empty
                    str(size_arcmin) if pd.notna(size_arcmin) else ''  # Size in arcmin as string or empty
                ]

                # Use SortableTreeWidgetItem instead of QTreeWidgetItem
                item = SortableTreeWidgetItem(values)
                self.tree.addTopLevelItem(item)


    def update_status(self, message):
        self.status_label.setText(f"Status: {message}")

    def update_lst(self, message):
        self.lst_label.setText(message)


    def save_settings(self, latitude, longitude, date, time, timezone, min_altitude):
        self.settings.setValue("latitude", latitude)
        self.settings.setValue("longitude", longitude)
        self.settings.setValue("date", date)
        self.settings.setValue("time", time)
        self.settings.setValue("timezone", timezone)
        self.settings.setValue("min_altitude", min_altitude)
        print("Settings saved.")

    def load_settings(self):
        """Load settings from QSettings and populate UI fields."""
        def safe_cast(value, default, cast_type):
            """Safely cast a value to a specific type."""
            try:
                return cast_type(value)
            except (ValueError, TypeError):
                return default

        # Load and cast settings with fallbacks
        self.latitude = safe_cast(self.settings.value("latitude", 0.0), 0.0, float)
        self.longitude = safe_cast(self.settings.value("longitude", 0.0), 0.0, float)
        self.date = self.settings.value("date", datetime.now().strftime("%Y-%m-%d"))
        self.time = self.settings.value("time", "00:00")
        self.timezone = self.settings.value("timezone", "UTC")
        self.min_altitude = safe_cast(self.settings.value("min_altitude", 0.0), 0.0, float)
        self.object_limit = safe_cast(self.settings.value("object_limit", 100), 100, int)

        # Populate fields in the UI
        self.latitude_entry.setText(str(self.latitude))
        self.longitude_entry.setText(str(self.longitude))
        self.date_entry.setText(self.date)
        self.time_entry.setText(self.time)
        self.timezone_combo.setCurrentText(self.timezone)
        self.min_altitude_entry.setText(str(self.min_altitude))

        #print("Settings loaded:", {
        #    "latitude": self.latitude,
        #    "longitude": self.longitude,
        #    "date": self.date,
        #    "time": self.time,
        #    "timezone": self.timezone,
        #    "min_altitude": self.min_altitude,
        #    "object_limit": self.object_limit,
        #})




    def open_settings(self):
        object_limit, ok = QInputDialog.getInt(self, "Settings", "Enter number of objects to display:", value=self.object_limit, min=1, max=1000)
        if ok:
            self.object_limit = object_limit

    def treeview_sort_column(self, tv, col, reverse):
        l = [(tv.set(k, col), k) for k in tv.get_children('')]
        try:
            l.sort(key=lambda t: float(t[0]) if t[0] else float('inf'), reverse=reverse)
        except ValueError:
            l.sort(reverse=reverse)

        for index, (val, k) in enumerate(l):
            tv.move(k, '', index)

        tv.heading(col, command=lambda: self.treeview_sort_column(tv, col, not reverse))

    def on_row_double_click(self, item: QTreeWidgetItem, column: int):
        """Handle double-clicking an item in the tree view."""
        object_name = item.text(0).replace(" ", "")  # Assuming the name is in the first column
        search_url = f"https://www.astrobin.com/search/?q={object_name}"
        print(f"Opening URL: {search_url}")  # Debugging output
        webbrowser.open(search_url)

    def add_custom_object(self):
        # Gather information for the custom object
        name, ok_name = QInputDialog.getText(self, "Add Custom Object", "Enter object name:")
        if not ok_name or not name:
            return

        ra, ok_ra = QInputDialog.getDouble(self, "Add Custom Object", "Enter RA (in degrees):", decimals=3)
        if not ok_ra:
            return

        dec, ok_dec = QInputDialog.getDouble(self, "Add Custom Object", "Enter Dec (in degrees):", decimals=3)
        if not ok_dec:
            return

        # Create the custom object entry
        new_object = {
            "Name": name,
            "RA": ra,
            "Dec": dec,
            "Catalog": "User Defined",
            "Alt Name": "User Defined",
            "Type": "Custom",
            "Magnitude": "",
            "Info": ""
        }

        # Load the catalog, add the custom object, and save it back
        df = pd.read_csv(self.calc_thread.catalog_file, encoding='ISO-8859-1')
        df = pd.concat([df, pd.DataFrame([new_object])], ignore_index=True)
        df.to_csv(self.calc_thread.catalog_file, index=False, encoding='ISO-8859-1')
        self.update_status(f"Added custom object: {name}")

    def update_ra_dec_format(self):
        """Update the RA/Dec format in the tree based on the selected radio button."""
        is_degrees_format = self.ra_dec_degrees.isChecked()  # Check if degrees format is selected

        for i in range(self.tree.topLevelItemCount()):
            item = self.tree.topLevelItem(i)
            ra_value = item.text(1)  # RA is in the second column
            dec_value = item.text(2)  # Dec is in the third column

            try:
                if is_degrees_format:
                    # Convert H:M:S to degrees only if in H:M:S format
                    if ":" in ra_value:
                        # Conversion from H:M:S format to degrees
                        sky_coord = SkyCoord(ra=ra_value, dec=dec_value, unit=(u.hourangle, u.deg))
                        ra_display = str(round(sky_coord.ra.deg, 3))
                        dec_display = str(round(sky_coord.dec.deg, 3))
                    else:
                        # Already in degrees format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value
                else:
                    # Convert degrees to H:M:S only if in degrees format
                    if ":" not in ra_value:
                        # Conversion from degrees to H:M:S format
                        ra_deg = float(ra_value)
                        dec_deg = float(dec_value)
                        sky_coord = SkyCoord(ra=ra_deg * u.deg, dec=dec_deg * u.deg)
                        ra_display = sky_coord.ra.to_string(unit=u.hour, sep=':')
                        dec_display = sky_coord.dec.to_string(unit=u.deg, sep=':')
                    else:
                        # Already in H:M:S format; no conversion needed
                        ra_display = ra_value
                        dec_display = dec_value

            except ValueError as e:
                print(f"Conversion error: {e}")
                ra_display = ra_value
                dec_display = dec_value
            except Exception as e:
                print(f"Unexpected error: {e}")
                ra_display = ra_value
                dec_display = dec_value

            # Update item with the new RA/Dec display format
            item.setText(1, ra_display)
            item.setText(2, dec_display)



    def save_to_csv(self):
        # Ask user where to save the CSV file
        file_path, _ = QFileDialog.getSaveFileName(self, "Save CSV File", "", "CSV files (*.csv);;All Files (*)")
        if file_path:
            # Extract data from QTreeWidget
            columns = [self.tree.headerItem().text(i) for i in range(self.tree.columnCount())]
            data = [columns]
            for i in range(self.tree.topLevelItemCount()):
                item = self.tree.topLevelItem(i)
                row = [item.text(j) for j in range(self.tree.columnCount())]
                data.append(row)

            # Convert data to DataFrame and save as CSV
            df = pd.DataFrame(data[1:], columns=data[0])
            df.to_csv(file_path, index=False)
            self.update_status(f"Data saved to {file_path}")

class SortableTreeWidgetItem(QTreeWidgetItem):
    def __lt__(self, other):
        # Get the column index being sorted
        column = self.treeWidget().sortColumn()

        # Columns with numeric data for custom sorting (adjust column indices as needed)
        numeric_columns = [3, 4, 5, 7, 10]  # Altitude, Azimuth, Minutes to Transit, Degrees from Moon, Magnitude

        # Check if the column is in numeric_columns for numeric sorting
        if column in numeric_columns:
            try:
                # Attempt to compare as floats
                return float(self.text(column)) < float(other.text(column))
            except ValueError:
                # If conversion fails, fall back to string comparison
                return self.text(column) < other.text(column)
        else:
            # Default string comparison for other columns
            return self.text(column) < other.text(column)


if __name__ == '__main__':
    # ——— Multiprocessing “freeze” support for Windows executables ———
    multiprocessing.freeze_support()
    multiprocessing.set_start_method('spawn', force=True)

    # Configure logging to capture errors for debugging
    logging.basicConfig(
        filename="astro_editing_suite.log",
        level=logging.ERROR,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Start Qt application
    app = QApplication(sys.argv)
    app.setWindowIcon(QIcon(icon_path))

    # ===================== SPLASH SCREEN CODE HERE =====================
    splash_pix = QPixmap(resource_path("astrosuite.png"))
    splash = QSplashScreen(splash_pix)
    splash.show()
    app.processEvents()

    QCoreApplication.setOrganizationName("Seti Astro")
    QCoreApplication.setApplicationName  ("Seti Astro Suite")

    try:
        # Initialize main window
        window = AstroEditingSuite()
        window.show()

        # Close the splash screen once the main window is ready
        splash.finish(window)
        print(f"Seti Astro Suite v{VERSION} up and running!")

        sys.exit(app.exec())
    except Exception as e:
        logging.error("Unhandled exception occurred", exc_info=True)
        QMessageBox.critical(
            None,
            "Application Error",
            f"An unexpected error occurred:\n{str(e)}\n\nPlease check the log file for more details."
        )
        sys.exit(1)
